From 7dd036e7f0023a4f64f8d9dab285a9426d9240d6 Mon Sep 17 00:00:00 2001
From: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date: Wed, 10 Jul 2019 17:17:13 +0530
Subject: [PATCH 04/18] zheap on undoprocessing v2

Squashed commit of the following:

commit 80b236ed47809f9cbc3f52b9b5376f8173a2cee8
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Mon Jul 8 17:00:29 2019 +0530

    Fixed a bug in ZHeapTupleSatisfiesOldestXmin

    In ZHeapTupleSatisfiesOldestXmin, when we fetch tuple from undo
    then tuple can be null because in some cases, we free the tuple
    in GetTupleFromUndo.  We were trying to free that null tuple in
    ZHeapTupleSatisfiesOldestXmin, hence we were getting assert
    failure, so added null check while freeing the tuple.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 5844e351b154298aeae4f9a3365b00892c3cf4e7
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Mon Jul 8 10:50:51 2019 +0530

    Fixed a bug in ZIsAnyMultiLockMemberRunning

    In ZIsAnyMultiLockMemberRunning, to apply pending actions of aborted
    transaction, we were passing incorrect slot, so that we were not
    applying actions but still clearing multi-locker bit and getting
    assert failure in rollback of XID_LOCK_ONLY.  So fixed this.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 9867d706b73feda227ece0e7fe07cceae28e22e4
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Sun Jul 7 02:40:52 2019 +0530

    Removed unused parameter slot_no from process_and_execute_undo_actions_page

    In process_and_execute_undo_actions_page, we were not using passed slot,
    instead of that we are finding slot from fxid, because slot can be moved
    to TPD.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 5a3f9795bc2dad9a4af08af7edb3c717296105b7
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Fri Jun 28 15:15:20 2019 +0530

    Added "ORDER BY" to fix zheap.sql regression failure

    Patch by Mahendra Singh Thalor

commit 78a08010cfaa8d65c3b723fed45bcca93ba88c1f
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Fri Jun 21 17:24:53 2019 +0530

    Fixed a bug in compute_new_xid_infomask

    In compute_new_xid_infomask, in case of lock only, we were checking
    that tuple slot should be our new slot, but if tuple is updated by
    same transaction, and tuple has multilocker, then slot can be moved
    into TPD, because before calling PageReserveTransactionSlot, we are
    releasing buffer lock so corrected assert.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 2ac06c83d137a202692d18fa49ad40cd2a0fd69d
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   Wed Jun 19 17:03:39 2019 +0530

    Add some recovery tests for zheap

    This commit adds few TAP-tests that intends to cover the recovery paths
    of zheap as part of the regression tests.

    Patch by Neha Sharma.

commit 7aacb6e8f0175af423345d05fbe4913e9f099dc9
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   Wed Jun 19 15:54:01 2019 +0530

    Add some comments in zheap_lock_tuple

commit 59d7e299732691eda2b1fb7b6d0dd2b5b65646a6
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Mon Jun 17 14:20:23 2019 +0530

    Fixed random regression failure rules.sql and isolation failue zheap_tpd.spec

    To fix rules.sql failure, now updating one tuple at a time so that
    output will be consistent.

    Patch by Mahendra Singh Thalor

commit b0499ea49f8e32aa3681b8218caaf1437d1adcdd
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Fri Jun 14 13:42:01 2019 +0530

    Added new structure TPDEntryInfo to pass TPDEntryUpdate and TPDAllocatePageAndAddEntry functions.

    Patch by me and Beena Emerson, reviewed by Amit Kapila

commit b82190fda7c1d81c04bf674131c24c73b41da2ab
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Fri Jun 14 13:34:48 2019 +0530

    Avoid locking of meta page in RelationGetBufferForZTuple and fixed 2 ZBORKED in same function.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit cfea5e1a09f8a757c4d85bb3b66a61d26c39d407
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Thu Jun 13 17:58:05 2019 +0530

    Added "ORDER BY" in zheap_mvcc.spec and zheap_tpd.spec to fix random isolation failures

    Patch by Mahendra Singh Thalor

commit 497e57e2af1055be2e1a204bffff6a81dd1c84f3
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Thu Jun 13 09:35:34 2019 +0530

    Fixed a bug in ZHeapTupleSatisfiesUpdate for single_locker_xid

    In ZHeapTupleSatisfiesUpdate, when tuple is non in-place updated
    by current transaction and then we want to lock it for update, we
    were not setting single_locker_xid so we were getting hang.
    Fixed this.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 4433076819ddced497b974e9caaa5e16cba2ef48
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Wed Jun 12 23:44:56 2019 +0530

    Fixed a bug in zheap_update to set lockmode when ItemIdDeleted

    In zheap_update, from commit 007f31470dd384d0b, ItemIdIsDeleted
    check is moved into ZHeapTupleSatisfiesUpdate and we missed to
    set lockmode as LockTupleExclusive for deleted item id, so we
    were getting segment fault in heap_acquire_tuplock due to garbadge
    value of lockmode.  So fixed this.
    This was random failure and isolation test is already added for
    this bug in commit 7c2412f68a5bab4668.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila.

commit 10d35912e1fc349ae74c50a77a9d9820e6bdf5c8
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   Wed Jul 10 17:09:52 2019 +0530

    Fixed some warnings for uninitialized used variables

    Reported and patch by Rafia Sabih, reviewed by Mahendra Singh Thalor

commit a43e2d00366182d71b2fc0614a2a01213538f2eb
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Wed Jun 12 15:11:17 2019 +0530

    Fixed some warnings for uninitialized variables

    Observed into CentOS-6

    Patch by Mahendra Singh Thalor

commit b7ccc53235fa79359f86f5b71463951af85f0397
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Wed Jun 12 14:09:14 2019 +0530

    Removed unused function PageGetTransactionSlotInfo

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 1e36422472cd8c681358bcdff65e5e88ba1c5b61
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Wed Jun 12 13:58:29 2019 +0530

    Support fxid to PageGetTransactionSlotInfo and TPDPageGetTransactionSlotInfo

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 0a17444244ae9058ecf8ff94ade8fa64981b5bed
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   Tue Jun 11 17:39:41 2019 +0530

    Fixed a bug in zheap_undo_xlog_page

    In zheap_undo_xlog_page, we were using sizeof operator to calculate
    size of structure xl_zundo_page so it was corrupting tpd offset map
    due to wrong size.  Fixed this.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila
---
 src/backend/access/zheap/tpd.c                | 155 ++++++++++++++------------
 src/backend/access/zheap/zheapam.c            | 145 ++++++++++--------------
 src/backend/access/zheap/zheapam_handler.c    |   2 +-
 src/backend/access/zheap/zheapam_visibility.c |  13 ++-
 src/backend/access/zheap/zheapamxlog.c        |   4 +-
 src/backend/access/zheap/zhio.c               |  54 +++++----
 src/backend/access/zheap/zmultilocker.c       |  14 ++-
 src/backend/access/zheap/zundo.c              |  10 +-
 src/include/access/tpd.h                      |   2 +-
 src/include/access/zheap.h                    |   6 +-
 src/include/access/zmultilocker.h             |   2 +-
 src/test/isolation/expected/zheap_mvcc.out    |  52 ++++-----
 src/test/isolation/expected/zheap_tpd.out     |  38 +++----
 src/test/isolation/specs/zheap_mvcc.spec      |   6 +-
 src/test/isolation/specs/zheap_tpd.spec       |  10 +-
 src/test/recovery/t/018_zheap_recovery.pl     | 146 ++++++++++++++++++++++++
 src/test/regress/expected/rules.out           |  33 +++---
 src/test/regress/expected/rules_1.out         |  33 +++---
 src/test/regress/expected/zheap.out           |  12 +-
 src/test/regress/sql/rules.sql                |  13 ++-
 src/test/regress/sql/zheap.sql                |   4 +-
 21 files changed, 463 insertions(+), 291 deletions(-)
 create mode 100644 src/test/recovery/t/018_zheap_recovery.pl

diff --git a/src/backend/access/zheap/tpd.c b/src/backend/access/zheap/tpd.c
index 58a1ac7..ce429ed 100644
--- a/src/backend/access/zheap/tpd.c
+++ b/src/backend/access/zheap/tpd.c
@@ -61,6 +61,15 @@ typedef struct TPDBuffers
 	Buffer		buf;			/* buffer allocated for the block */
 } TPDBuffers;
 
+/* Used to allocate/update TPD entry. */
+typedef struct TPDEntryInfo
+{
+	char			*new_tpd_entry;
+	Buffer			old_tpd_buf;
+	OffsetNumber	old_tpd_item_off;
+	Size			new_size_tpd_entry;
+}TPDEntryInfo;
+
 /*
  * GetTPDBuffer operations
  *
@@ -86,14 +95,13 @@ static int	tpd_buf_idx;
 static int	registered_tpd_buf_idx;
 static int	GetTPDBuffer(Relation rel, BlockNumber blk, Buffer tpd_buf,
 						 TPDACTION tpd_action, bool *already_exists);
-static void TPDEntryUpdate(Relation relation, Buffer tpd_buf,
-						   uint16 tpd_e_offset, OffsetNumber tpd_item_off,
-						   char *tpd_entry, Size size_tpd_entry);
+static void TPDEntryUpdate(Relation relation, TPDEntryInfo *tpd_info,
+						   uint16 tpd_e_offset);
 static void TPDAllocatePageAndAddEntry(Relation relation, Buffer metabuf,
-									   Buffer pagebuf, Buffer old_tpd_buf,
-									   OffsetNumber old_off_num, char *tpd_entry,
-									   Size size_tpd_entry, bool add_new_tpd_page,
-									   bool delete_old_entry, bool always_extend);
+									   Buffer pagebuf, TPDEntryInfo *tpd_info,
+									   bool add_new_tpd_page,
+									   bool delete_old_entry,
+									   bool always_extend);
 static bool TPDBufferAlreadyRegistered(Buffer tpd_buf);
 static void ReleaseLastTPDBuffer(Buffer buf, bool locked);
 static void LogAndClearTPDLocation(Relation relation, Buffer heapbuf,
@@ -423,6 +431,7 @@ ExtendTPDEntry(Relation relation, Buffer heapbuf, TransInfo *trans_slots,
 	bool		allocate_new_tpd_page = false;
 	bool		update_tpd_inplace,
 				tpd_pruned;
+	TPDEntryInfo	tpd_info;
 
 	heappage = BufferGetPage(heapbuf);
 	max_page_offnum = PageGetMaxOffsetNumber(heappage);
@@ -682,19 +691,21 @@ ExtendTPDEntry(Relation relation, Buffer heapbuf, TransInfo *trans_slots,
 		Assert(false);
 	}
 
+	/* Copy required info here to add new TPD entry. */
+	tpd_info.new_tpd_entry = tpd_entry;
+	tpd_info.new_size_tpd_entry = new_size_tpd_entry;
+	tpd_info.old_tpd_buf = old_tpd_buf;
+	tpd_info.old_tpd_item_off = tpdItemOff;
+
 	if (update_tpd_inplace)
-	{
-		TPDEntryUpdate(relation, old_tpd_buf, tpd_e_offset, tpdItemOff,
-					   tpd_entry, new_size_tpd_entry);
-	}
+		TPDEntryUpdate(relation, &tpd_info, tpd_e_offset);
 	else
 	{
 		/*
 		 * Note that if we have to allocate a new page, we must delete the old
 		 * tpd entry in old tpd buffer.
 		 */
-		TPDAllocatePageAndAddEntry(relation, metabuf, heapbuf, old_tpd_buf,
-								   tpdItemOff, tpd_entry, new_size_tpd_entry,
+		TPDAllocatePageAndAddEntry(relation, metabuf, heapbuf, &tpd_info,
 								   allocate_new_tpd_page,
 								   allocate_new_tpd_page, always_extend);
 	}
@@ -1252,30 +1263,30 @@ TPDFreePage(Relation rel, Buffer buf, BufferAccessStrategy bstrategy)
  *					the same.
  */
 static void
-TPDEntryUpdate(Relation relation, Buffer tpd_buf, uint16 tpd_e_offset,
-			   OffsetNumber tpd_item_off, char *tpd_entry,
-			   Size size_tpd_entry)
+TPDEntryUpdate(Relation relation, TPDEntryInfo *tpd_info, uint16 tpd_e_offset)
 {
-	Page		tpd_page = BufferGetPage(tpd_buf);
-	ItemId		itemId = PageGetItemId(tpd_page, tpd_item_off);
+	Page		tpd_page = BufferGetPage(tpd_info->old_tpd_buf);
+	ItemId		itemId = PageGetItemId(tpd_page, tpd_info->old_tpd_item_off);
 
 	START_CRIT_SECTION();
 
 	memcpy((char *) (tpd_page + tpd_e_offset),
-		   tpd_entry,
-		   size_tpd_entry);
-	ItemIdChangeLen(itemId, size_tpd_entry);
+		   tpd_info->new_tpd_entry,
+		   tpd_info->new_size_tpd_entry);
+	ItemIdChangeLen(itemId, tpd_info->new_size_tpd_entry);
 
-	MarkBufferDirty(tpd_buf);
+	MarkBufferDirty(tpd_info->old_tpd_buf);
 
 	if (RelationNeedsWAL(relation))
 	{
 		XLogRecPtr	recptr;
 
 		XLogBeginInsert();
-		XLogRegisterBuffer(0, tpd_buf, REGBUF_STANDARD);
-		XLogRegisterBufData(0, (char *) &tpd_item_off, sizeof(OffsetNumber));
-		XLogRegisterBufData(0, (char *) tpd_entry, size_tpd_entry);
+		XLogRegisterBuffer(0, tpd_info->old_tpd_buf, REGBUF_STANDARD);
+		XLogRegisterBufData(0, (char *) &tpd_info->old_tpd_item_off,
+							sizeof(OffsetNumber));
+		XLogRegisterBufData(0, (char *) tpd_info->new_tpd_entry,
+							tpd_info->new_size_tpd_entry);
 
 		recptr = XLogInsert(RM_TPD_ID, XLOG_INPLACE_UPDATE_TPD_ENTRY);
 
@@ -1316,8 +1327,7 @@ TPDEntryUpdate(Relation relation, Buffer tpd_buf, uint16 tpd_e_offset,
  */
 static void
 TPDAllocatePageAndAddEntry(Relation relation, Buffer metabuf, Buffer pagebuf,
-						   Buffer old_tpd_buf, OffsetNumber old_off_num,
-						   char *tpd_entry, Size size_tpd_entry,
+						   TPDEntryInfo *tpd_info,
 						   bool add_new_tpd_page, bool delete_old_entry,
 						   bool always_extend)
 {
@@ -1326,7 +1336,7 @@ TPDAllocatePageAndAddEntry(Relation relation, Buffer metabuf, Buffer pagebuf,
 				last_tpdopaque;
 	TPDEntryHeader old_tpd_entry;
 	Buffer		last_used_tpd_buf = InvalidBuffer;
-	Buffer		tpd_buf;
+	Buffer		tpd_buf = InvalidBuffer;
 	Page		tpdpage;
 	BlockNumber prevblk = InvalidBlockNumber;
 	BlockNumber nextblk = InvalidBlockNumber;
@@ -1346,8 +1356,8 @@ TPDAllocatePageAndAddEntry(Relation relation, Buffer metabuf, Buffer pagebuf,
 		 * While adding a new page, if we've to delete the old entry, the old
 		 * buffer must be valid. Else, it should be invalid.
 		 */
-		Assert(!delete_old_entry || BufferIsValid(old_tpd_buf));
-		Assert(delete_old_entry || !BufferIsValid(old_tpd_buf));
+		Assert(!delete_old_entry || BufferIsValid(tpd_info->old_tpd_buf));
+		Assert(delete_old_entry || !BufferIsValid(tpd_info->old_tpd_buf));
 
 		/*
 		 * FIXME: We can allow the free pages to be used from FSM once we fix
@@ -1495,8 +1505,8 @@ recheck_meta:
 	else
 	{
 		/* old buffer must be valid */
-		Assert(BufferIsValid(old_tpd_buf));
-		tpd_buf = old_tpd_buf;
+		Assert(BufferIsValid(tpd_info->old_tpd_buf));
+		tpd_buf = tpd_info->old_tpd_buf;
 	}
 
 	/* No ereport(ERROR) from here till changes are logged */
@@ -1553,17 +1563,18 @@ recheck_meta:
 
 		/* We must be adding new TPD entry into a new page. */
 		Assert(add_new_tpd_page);
-		Assert(old_tpd_buf != tpd_buf);
+		Assert(tpd_info->old_tpd_buf != tpd_buf);
 
-		otpdpage = BufferGetPage(old_tpd_buf);
-		old_item_id = PageGetItemId(otpdpage, old_off_num);
+		otpdpage = BufferGetPage(tpd_info->old_tpd_buf);
+		old_item_id = PageGetItemId(otpdpage, tpd_info->old_tpd_item_off);
 		old_tpd_entry = (TPDEntryHeader) PageGetItem(otpdpage, old_item_id);
 		old_tpd_entry->tpe_flags |= TPE_DELETED;
-		MarkBufferDirty(old_tpd_buf);
+		MarkBufferDirty(tpd_info->old_tpd_buf);
 	}
 
 	/* Add tpd entry to page */
-	offset_num = TPDPageAddEntry(tpdpage, tpd_entry, size_tpd_entry,
+	offset_num = TPDPageAddEntry(tpdpage, tpd_info->new_tpd_entry,
+								 tpd_info->new_size_tpd_entry,
 								 InvalidOffsetNumber);
 	if (offset_num == InvalidOffsetNumber)
 		elog(PANIC, "failed to add TPD entry");
@@ -1604,7 +1615,8 @@ recheck_meta:
 		XLogBeginInsert();
 		XLogRegisterData((char *) &xlrec, SizeOfTPDAllocateEntry);
 		XLogRegisterBuffer(0, tpd_buf, REGBUF_STANDARD | bufflags);
-		XLogRegisterBufData(0, (char *) tpd_entry, size_tpd_entry);
+		XLogRegisterBufData(0, (char *) tpd_info->new_tpd_entry,
+							tpd_info->new_size_tpd_entry);
 		XLogRegisterBuffer(1, pagebuf, REGBUF_STANDARD);
 		if (add_new_tpd_page)
 		{
@@ -1623,15 +1635,17 @@ recheck_meta:
 				 * If the last tpd buffer and the old tpd buffer are same, we
 				 * don't need to register old_tpd_buf.
 				 */
-				if (last_used_tpd_buf == old_tpd_buf)
+				if (last_used_tpd_buf == tpd_info->old_tpd_buf)
 				{
 					xlrec.flags = XLOG_OLD_TPD_BUF_EQ_LAST_TPD_BUF;
-					XLogRegisterBufData(3, (char *) &old_off_num, sizeof(OffsetNumber));
+					XLogRegisterBufData(3, (char *) &tpd_info->old_tpd_item_off,
+										sizeof(OffsetNumber));
 				}
 				else
 				{
-					XLogRegisterBuffer(4, old_tpd_buf, REGBUF_STANDARD);
-					XLogRegisterBufData(4, (char *) &old_off_num, sizeof(OffsetNumber));
+					XLogRegisterBuffer(4, tpd_info->old_tpd_buf, REGBUF_STANDARD);
+					XLogRegisterBufData(4, (char *) &tpd_info->old_tpd_item_off,
+										sizeof(OffsetNumber));
 				}
 			}
 		}
@@ -1646,7 +1660,7 @@ recheck_meta:
 			if (BufferIsValid(last_used_tpd_buf))
 				PageSetLSN(BufferGetPage(last_used_tpd_buf), recptr);
 			if (delete_old_entry)
-				PageSetLSN(BufferGetPage(old_tpd_buf), recptr);
+				PageSetLSN(BufferGetPage(tpd_info->old_tpd_buf), recptr);
 		}
 	}
 
@@ -1684,17 +1698,15 @@ TPDAllocateAndReserveTransSlot(Relation relation, Buffer pagebuf,
 {
 	ZHeapMetaPage metapage;
 	Buffer		metabuf;
-	Buffer		tpd_buf = InvalidBuffer;
 	Page		heappage;
 	uint32		first_used_tpd_page;
 	uint32		last_used_tpd_page;
-	char	   *tpd_entry;
-	Size		size_tpd_entry;
 	int			reserved_slot = InvalidXactSlotId;
 	int			buf_idx;
 	bool		allocate_new_tpd_page = false;
 	bool		update_meta = false;
 	bool		already_exists;
+	TPDEntryInfo	tpd_info;
 
 	metabuf = ReadBuffer(relation, ZHEAP_METAPAGE);
 	LockBuffer(metabuf, BUFFER_LOCK_SHARE);
@@ -1731,15 +1743,15 @@ TPDAllocateAndReserveTransSlot(Relation relation, Buffer pagebuf,
 
 		buf_idx = GetTPDBuffer(relation, last_used_tpd_page, InvalidBuffer,
 							   TPD_BUF_FIND_OR_ENTER, &already_exists);
-		tpd_buf = tpd_buffers[buf_idx].buf;
+		tpd_info.old_tpd_buf = tpd_buffers[buf_idx].buf;
 		/* We don't need to lock the buffer, if it is already locked */
 		if (!already_exists)
-			LockBuffer(tpd_buf, BUFFER_LOCK_EXCLUSIVE);
+			LockBuffer(tpd_info.old_tpd_buf, BUFFER_LOCK_EXCLUSIVE);
 
 		/* Page should be a TPD page. */
-		Assert(IsTPDPage(BufferGetPage(tpd_buf)));
+		Assert(IsTPDPage(BufferGetPage(tpd_info.old_tpd_buf)));
 
-		tpdpageFreeSpace = PageGetTPDFreeSpace(BufferGetPage(tpd_buf));
+		tpdpageFreeSpace = PageGetTPDFreeSpace(BufferGetPage(tpd_info.old_tpd_buf));
 
 		if (tpdpageFreeSpace < size_tpd_entry)
 		{
@@ -1751,12 +1763,12 @@ TPDAllocateAndReserveTransSlot(Relation relation, Buffer pagebuf,
 			 * accommodated on the page. We can't afford to free the page
 			 * while pruning as we need to use it to insert the TPD entry.
 			 */
-			entries_removed = TPDPagePrune(relation, tpd_buf, NULL,
-										   InvalidOffsetNumber, 0, false, NULL,
-										   NULL);
+			entries_removed = TPDPagePrune(relation, tpd_info.old_tpd_buf,
+										   NULL, InvalidOffsetNumber, 0, false,
+										   NULL, NULL);
 
 			if (entries_removed > 0)
-				tpdpageFreeSpace = PageGetTPDFreeSpace(BufferGetPage(tpd_buf));
+				tpdpageFreeSpace = PageGetTPDFreeSpace(BufferGetPage(tpd_info.old_tpd_buf));
 
 			if (tpdpageFreeSpace < size_tpd_entry)
 			{
@@ -1769,7 +1781,7 @@ TPDAllocateAndReserveTransSlot(Relation relation, Buffer pagebuf,
 				 * isn't free either.
 				 */
 				if (!already_exists)
-					ReleaseLastTPDBuffer(tpd_buf, true);
+					ReleaseLastTPDBuffer(tpd_info.old_tpd_buf, true);
 				allocate_new_tpd_page = true;
 			}
 		}
@@ -1779,17 +1791,20 @@ TPDAllocateAndReserveTransSlot(Relation relation, Buffer pagebuf,
 		(last_used_tpd_page == InvalidBlockNumber &&
 		 first_used_tpd_page == InvalidBlockNumber))
 	{
-		tpd_buf = InvalidBuffer;
+		tpd_info.old_tpd_buf = InvalidBuffer;
 		update_meta = true;
 	}
 
 	/* Allocate a new TPD entry */
-	tpd_entry = AllocateAndFormTPDEntry(pagebuf, offnum, &size_tpd_entry,
+	tpd_info.new_tpd_entry = AllocateAndFormTPDEntry(pagebuf, offnum,
+										&tpd_info.new_size_tpd_entry,
 										&reserved_slot);
-	Assert(tpd_entry != NULL);
+	Assert(tpd_info.new_tpd_entry != NULL);
+
+	tpd_info.old_tpd_item_off = InvalidOffsetNumber;
 
-	TPDAllocatePageAndAddEntry(relation, metabuf, pagebuf, tpd_buf,
-							   InvalidOffsetNumber, tpd_entry, size_tpd_entry,
+	/* Now add TPD entry into TPD page. */
+	TPDAllocatePageAndAddEntry(relation, metabuf, pagebuf, &tpd_info,
 							   update_meta, false, always_extend);
 
 	ReleaseBuffer(metabuf);
@@ -1801,7 +1816,7 @@ TPDAllocateAndReserveTransSlot(Relation relation, Buffer pagebuf,
 	 * TPDPageSetUndo to update the required information.
 	 */
 
-	pfree(tpd_entry);
+	pfree(tpd_info.new_tpd_entry);
 
 	/*
 	 * As this is always a fresh transaction slot, so we can assume that there
@@ -2337,9 +2352,9 @@ TPDPageGetSlotIfExists(Relation relation, Buffer heapbuf, OffsetNumber offnum,
  */
 int
 TPDPageGetTransactionSlotInfo(Buffer heapbuf, int trans_slot,
-							  OffsetNumber offset, uint32 *epoch,
-							  TransactionId *xid, UndoRecPtr *urec_ptr,
-							  bool NoTPDBufLock, bool keepTPDBufLock)
+							  OffsetNumber offset, FullTransactionId *fxid,
+							  UndoRecPtr *urec_ptr, bool NoTPDBufLock,
+							  bool keepTPDBufLock)
 {
 	TransInfo	trans_slot_info;
 	RelFileNode rnode;
@@ -2517,10 +2532,8 @@ TPDPageGetTransactionSlotInfo(Buffer heapbuf, int trans_slot,
 		   sizeof(TransInfo));
 
 	/* Update the required output */
-	if (epoch)
-		*epoch = EpochFromFullTransactionId(trans_slot_info.fxid);
-	if (xid)
-		*xid = XidFromFullTransactionId(trans_slot_info.fxid);
+	if (fxid)
+		*fxid = trans_slot_info.fxid;
 	if (urec_ptr)
 		*urec_ptr = trans_slot_info.urec_ptr;
 
@@ -2535,10 +2548,8 @@ slot_is_frozen:
 
 slot_is_frozen_and_buf_not_locked:
 	trans_slot_id = ZHTUP_SLOT_FROZEN;
-	if (epoch)
-		*epoch = 0;
-	if (xid)
-		*xid = InvalidTransactionId;
+	if (fxid)
+		*fxid = InvalidFullTransactionId;
 	if (urec_ptr)
 		*urec_ptr = InvalidUndoRecPtr;
 
diff --git a/src/backend/access/zheap/zheapam.c b/src/backend/access/zheap/zheapam.c
index 7a99084..561b1ce 100644
--- a/src/backend/access/zheap/zheapam.c
+++ b/src/backend/access/zheap/zheapam.c
@@ -1100,7 +1100,7 @@ zheap_delete_wait_helper(Relation relation, Buffer buffer, ZHeapTuple zheaptup,
 			}
 
 			*any_multi_locker_member_alive =
-				ZIsAnyMultiLockMemberRunning(relation, xwait_trans_slot,
+				ZIsAnyMultiLockMemberRunning(relation,
 											 new_mlmembers, zheaptup,
 											 buffer, &pending_actions_applied);
 			list_free_deep(mlmembers);
@@ -1236,8 +1236,8 @@ zheap_update(Relation relation, ItemPointer otid, ZHeapTuple newtup,
 				newbuf,
 				vmbuffer = InvalidBuffer,
 				vmbuffer_new = InvalidBuffer;
-	Size		newtupsize,
-				oldtupsize,
+	Size		newtupsize = 0,
+				oldtupsize = 0,
 				pagefree;
 	int			oldtup_new_trans_slot,
 				newtup_trans_slot,
@@ -1261,7 +1261,7 @@ zheap_update(Relation relation, ItemPointer otid, ZHeapTuple newtup,
 	bool		locker_remains = false;
 	bool		any_multi_locker_member_alive = false;
 	bool		lock_reacquired;
-	bool		need_toast;
+	bool		need_toast = false;
 	bool		hasSubXactLock = false;
 	uint8		vm_status;
 	uint8		vm_status_new = 0;
@@ -1330,19 +1330,34 @@ check_tup_satisfies_update:
 									   &single_locker_trans_slot, false,
 									   snapshot, &in_place_updated_or_locked);
 	/* Determine columns modified by the update, if not yet done. */
-	if (!computed_modified_attrs && oldtup.t_data != NULL)
+	if (!computed_modified_attrs)
 	{
-		computed_modified_attrs = true;
-		modified_attrs =
-			ZHeapDetermineModifiedColumns(relation, interesting_attrs,
-										  &oldtup, newtup);
+		if (oldtup.t_data != NULL)
+		{
+			computed_modified_attrs = true;
+			modified_attrs =
+				ZHeapDetermineModifiedColumns(relation, interesting_attrs,
+											  &oldtup, newtup);
 
-		/*
-		 * Similar to heap, if we're not updating any "key" column, we can
-		 * grab weaker lock type.  See heap_update.
-		 */
-		key_intact = !bms_overlap(modified_attrs, key_attrs);
-		*lockmode = key_intact ? LockTupleNoKeyExclusive : LockTupleExclusive;
+			/*
+			 * Similar to heap, if we're not updating any "key" column, we can
+			 * grab weaker lock type.  See heap_update.
+			 */
+			key_intact = !bms_overlap(modified_attrs, key_attrs);
+			*lockmode = key_intact ? LockTupleNoKeyExclusive :
+				LockTupleExclusive;
+		}
+		else
+		{
+			/*
+			 * Since tuple data is gone let's be conservative about lock mode.
+			 *
+			 * XXX We could optimize here by checking whether the key column is
+			 * not updated and if so, then use lower lock level, but this case
+			 * should be rare enough that it won't matter.
+			 */
+			*lockmode = LockTupleExclusive;
+		}
 	}
 
 	if (result == TM_Invisible)
@@ -2383,7 +2398,7 @@ zheap_update_wait_helper(Relation relation,
 				}
 
 				*any_multi_locker_member_alive =
-					ZIsAnyMultiLockMemberRunning(relation, xwait_trans_slot,
+					ZIsAnyMultiLockMemberRunning(relation,
 												 new_mlmembers, zheaptup,
 												 buffer,
 												 &pending_actions_applied);
@@ -2722,6 +2737,11 @@ check_tup_satisfies_update:
 			tuple->t_data = palloc0(tuple->t_len);
 			memcpy(tuple->t_data, zhtup.t_data, zhtup.t_len);
 
+			/*
+			 * We reach here when the tuple is inserted/inplace updated
+			 * by current transaction and there are no other concurrent
+			 * locker on the tuple.
+			 */
 			switch (mode)
 			{
 				case LockTupleKeyShare:
@@ -2932,6 +2952,11 @@ zheap_tuple_already_locked(ZHeapTuple zhtup, UndoRecPtr urec_ptr,
 	}
 	else if (TransactionIdIsCurrentTransactionId(xid))
 	{
+		/*
+		 * We reach here when the current transaction is the sole locker
+		 * on the tuple.  In that case, ZHeapTupleSatisfiesUpdate returns
+		 * TM_BeingModified and eventually we come here.
+		 */
 		switch (mode)
 		{
 			case LockTupleKeyShare:
@@ -3409,7 +3434,7 @@ zheap_lock_wait_helper(Relation relation, Buffer buffer, ZHeapTuple zhtup,
 			}
 
 			*any_multi_locker_member_alive =
-				ZIsAnyMultiLockMemberRunning(relation, xwait_trans_slot,
+				ZIsAnyMultiLockMemberRunning(relation,
 											 new_mlmembers, zhtup,
 											 buffer,
 											 &pending_actions_applied);
@@ -4477,8 +4502,17 @@ compute_new_xid_infomask(ZHeapTuple zhtup, Buffer buf, TransactionId tup_xid,
 	/*
 	 * We store the reserved transaction slot only when we update the tuple.
 	 * For lock only, we keep the old transaction slot in the tuple.
-	 */
-	Assert(is_update || new_trans_slot == tup_trans_slot);
+	 *
+	 * For lock only, if tuple is updated by current transaction and has
+	 * multilocker, then it is possible that tuple slot is moved into TPD
+	 * because before calling PageReserveTransactionSlot, we are releasing
+	 * buffer lock so in such case we should get previous slot_no + 1.
+	 */
+	Assert(is_update || new_trans_slot == tup_trans_slot ||
+		   (tup_xid == add_to_xid &&
+			ZHeapPageHasTPDSlot((PageHeader) BufferGetPage(buf)) &&
+			tup_trans_slot == ZHEAP_PAGE_TRANS_SLOTS &&
+			new_trans_slot == tup_trans_slot + 1));
 }
 
 /*
@@ -6189,7 +6223,6 @@ GetTransactionSlotInfo(Buffer buf, OffsetNumber offset, int trans_slot_id,
 	ZHeapPageOpaque opaque;
 	Page		page;
 	PageHeader	phdr PG_USED_FOR_ASSERTS_ONLY;
-	uint32		epoch = 0;
 
 	zinfo->trans_slot = trans_slot_id;
 	zinfo->cid = InvalidCommandId;
@@ -6204,7 +6237,7 @@ GetTransactionSlotInfo(Buffer buf, OffsetNumber offset, int trans_slot_id,
 	 */
 	if (trans_slot_id == ZHTUP_SLOT_FROZEN)
 	{
-		zinfo->xid = InvalidTransactionId;
+		zinfo->epoch_xid = InvalidFullTransactionId;
 		zinfo->urec_ptr = InvalidUndoRecPtr;
 	}
 	else if (trans_slot_id < ZHEAP_PAGE_TRANS_SLOTS ||
@@ -6213,8 +6246,7 @@ GetTransactionSlotInfo(Buffer buf, OffsetNumber offset, int trans_slot_id,
 	{
 		TransInfo  *thistrans = &opaque->transinfo[trans_slot_id - 1];
 
-		epoch = EpochFromFullTransactionId(thistrans->fxid);
-		zinfo->xid = XidFromFullTransactionId(thistrans->fxid);
+		zinfo->epoch_xid = thistrans->fxid;
 		zinfo->urec_ptr = thistrans->urec_ptr;
 	}
 	else
@@ -6233,8 +6265,7 @@ GetTransactionSlotInfo(Buffer buf, OffsetNumber offset, int trans_slot_id,
 				TPDPageGetTransactionSlotInfo(buf,
 											  trans_slot_id,
 											  InvalidOffsetNumber,
-											  &epoch,
-											  &zinfo->xid,
+											  &zinfo->epoch_xid,
 											  &zinfo->urec_ptr,
 											  NoTPDBufLock,
 											  false);
@@ -6246,15 +6277,14 @@ GetTransactionSlotInfo(Buffer buf, OffsetNumber offset, int trans_slot_id,
 				TPDPageGetTransactionSlotInfo(buf,
 											  trans_slot_id,
 											  offset,
-											  &epoch,
-											  &zinfo->xid,
+											  &zinfo->epoch_xid,
 											  &zinfo->urec_ptr,
 											  NoTPDBufLock,
 											  false);
 		}
 	}
 
-	zinfo->epoch_xid = FullTransactionIdFromEpochAndXid(epoch, zinfo->xid);
+	zinfo->xid = XidFromFullTransactionId(zinfo->epoch_xid);
 }
 
 /*
@@ -6439,54 +6469,6 @@ PageGetTransactionSlotId(Relation rel, Buffer buf, FullTransactionId fxid,
 }
 
 /*
- * PageGetTransactionSlotInfo - Get the transaction slot info for the given
- *	slot no.
- */
-void
-PageGetTransactionSlotInfo(Buffer buf, int slot_no, uint32 *epoch,
-						   TransactionId *xid, UndoRecPtr *urec_ptr,
-						   bool keepTPDBufLock)
-{
-	ZHeapPageOpaque opaque;
-	Page		page;
-	PageHeader	phdr;
-
-	page = BufferGetPage(buf);
-	phdr = (PageHeader) page;
-	opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
-
-	/*
-	 * Fetch the required information from the transaction slot. The
-	 * transaction slot can either be on the heap page or TPD page.
-	 */
-	if (slot_no < ZHEAP_PAGE_TRANS_SLOTS ||
-		(slot_no == ZHEAP_PAGE_TRANS_SLOTS &&
-		 !ZHeapPageHasTPDSlot(phdr)))
-	{
-		TransInfo  *thistrans = &opaque->transinfo[slot_no - 1];
-
-		if (epoch)
-			*epoch = EpochFromFullTransactionId(thistrans->fxid);
-		if (xid)
-			*xid = XidFromFullTransactionId(thistrans->fxid);
-		if (urec_ptr)
-			*urec_ptr = thistrans->urec_ptr;
-	}
-	else
-	{
-		Assert((ZHeapPageHasTPDSlot(phdr)));
-		(void) TPDPageGetTransactionSlotInfo(buf,
-											 slot_no,
-											 InvalidOffsetNumber,
-											 epoch,
-											 xid,
-											 urec_ptr,
-											 false,
-											 true);
-	}
-}
-
-/*
  *  MultiPageReserveTransSlot - Reserve the transaction slots on old and
  *		new buffer.
  *
@@ -6951,7 +6933,7 @@ zheap_freeze_or_invalidate_tuples(Buffer buf, int nSlots, int *slots,
 			 * info from the TPD.
 			 */
 			trans_slot = TPDPageGetTransactionSlotInfo(buf, trans_slot, offnum,
-													   NULL, NULL, NULL, false,
+													   NULL, NULL, false,
 													   false);
 
 			/*
@@ -7392,7 +7374,6 @@ PageFreezeTransSlots(Relation relation, Buffer buf, bool *lock_reacquired,
 	else if (nAbortedXactSlots)
 	{
 		int			i;
-		int			slot_no;
 		UndoRecPtr *urecptr = palloc(nAbortedXactSlots * sizeof(UndoRecPtr));
 		FullTransactionId *fxid = palloc(nAbortedXactSlots * sizeof(FullTransactionId));
 
@@ -7451,14 +7432,10 @@ PageFreezeTransSlots(Relation relation, Buffer buf, bool *lock_reacquired,
 		UnlockReleaseTPDBuffers();
 
 		for (i = 0; i < nAbortedXactSlots; i++)
-		{
-			slot_no = aborted_xact_slots[i] + 1;
 			process_and_execute_undo_actions_page(urecptr[i],
 												  relation,
 												  buf,
-												  fxid[i],
-												  slot_no);
-		}
+												  fxid[i]);
 
 		LockBuffer(buf, BUFFER_LOCK_EXCLUSIVE);
 		*lock_reacquired = true;
@@ -8567,7 +8544,7 @@ zheap_compute_xid_horizon_for_tuples(Relation rel,
 	TransactionId latestRemovedXid = InvalidTransactionId;
 	BlockNumber hblkno;
 	Buffer		buf = InvalidBuffer;
-	Page		hpage;
+	Page		hpage = NULL;
 
 	/*
 	 * Sort to avoid repeated lookups for the same page, and to make it more
diff --git a/src/backend/access/zheap/zheapam_handler.c b/src/backend/access/zheap/zheapam_handler.c
index 5b1bba5..47267e2 100644
--- a/src/backend/access/zheap/zheapam_handler.c
+++ b/src/backend/access/zheap/zheapam_handler.c
@@ -1509,7 +1509,7 @@ zheap_scan_sample_next_tuple(TableScanDesc sscan, struct SampleScanState *scanst
 	TsmRoutine *tsm = scanstate->tsmroutine;
 	BlockNumber blockno = scan->rs_cblock;
 	bool		pagemode = (sscan->rs_flags & SO_ALLOW_PAGEMODE) != 0;
-	Page		page;
+	Page		page = NULL;
 	bool		all_visible = false;
 	OffsetNumber maxoffset;
 	uint8		vmstatus;
diff --git a/src/backend/access/zheap/zheapam_visibility.c b/src/backend/access/zheap/zheapam_visibility.c
index 194811f..cdbfab3 100644
--- a/src/backend/access/zheap/zheapam_visibility.c
+++ b/src/backend/access/zheap/zheapam_visibility.c
@@ -1374,6 +1374,15 @@ ZHeapTupleSatisfiesUpdate(Relation rel, ItemPointer tid, ZHeapTuple zhtup,
 			{
 				if (ZHEAP_XID_IS_LOCKED_ONLY(tuple->t_infomask))
 				{
+					FullTransactionId	single_locker_fxid = InvalidFullTransactionId;
+
+					if (!ZHeapTupleHasMultiLockers(tuple->t_infomask))
+						GetLockerTransInfo(rel, &zhtup->t_self, buffer,
+										   single_locker_trans_slot,
+										   &single_locker_fxid);
+					*single_locker_xid =
+						XidFromFullTransactionId(single_locker_fxid);
+
 					/*
 					 * Locked before scan;  caller can check if it is locked
 					 * in lock mode higher or equal to the required mode, then
@@ -1689,7 +1698,7 @@ ZHeapTupleSatisfiesOldestXmin(ZHeapTuple zhtup, TransactionId OldestXmin,
 
 			if (preabort_tuple)
 				*preabort_tuple = undo_tuple;
-			else if (undo_tuple != zhtup)
+			else if (undo_tuple != NULL && undo_tuple != zhtup)
 				pfree(undo_tuple);
 
 			if (undo_tuple != NULL)
@@ -1767,7 +1776,7 @@ ZHeapTupleSatisfiesOldestXmin(ZHeapTuple zhtup, TransactionId OldestXmin,
 
 			if (preabort_tuple)
 				*preabort_tuple = undo_tuple;
-			else if (undo_tuple != zhtup)
+			else if (undo_tuple != NULL && undo_tuple != zhtup)
 				pfree(undo_tuple);
 
 			if (undo_tuple != NULL)
diff --git a/src/backend/access/zheap/zheapamxlog.c b/src/backend/access/zheap/zheapamxlog.c
index 0c87778..6e15eaf 100644
--- a/src/backend/access/zheap/zheapamxlog.c
+++ b/src/backend/access/zheap/zheapamxlog.c
@@ -30,7 +30,7 @@ static void
 zheap_xlog_insert(XLogReaderState *record)
 {
 	XLogRecPtr	lsn = record->EndRecPtr;
-	xl_undo_header *xlundohdr;
+	xl_undo_header *xlundohdr = NULL;
 	xl_zheap_insert *xlrec = (xl_zheap_insert *) XLogRecGetData(record);
 	Buffer		buffer;
 	Page		page;
@@ -1973,7 +1973,7 @@ zheap_undo_xlog_page(XLogReaderState *record)
 		if (*flags & XLU_PAGE_CONTAINS_TPD_SLOT)
 		{
 			xlrec = (xl_zundo_page *) data;
-			data += sizeof(xl_zundo_page);
+			data += SizeOfZUndoPage;
 		}
 		if (*flags & XLU_CONTAINS_TPD_OFFSET_MAP)
 			offsetmap = data;
diff --git a/src/backend/access/zheap/zhio.c b/src/backend/access/zheap/zhio.c
index a47cab1..9a0ec15 100644
--- a/src/backend/access/zheap/zhio.c
+++ b/src/backend/access/zheap/zhio.c
@@ -118,7 +118,12 @@ RelationGetBufferForZTuple(Relation relation, Size len,
 		{
 			BlockNumber nblocks = RelationGetNumberOfBlocks(relation);
 
-			if (nblocks > 0)
+			/*
+			 * In zheap, first page is always a meta page, so we need to skip
+			 * it for tuple insertions.
+			 */
+			Assert(nblocks > 0);
+			if (nblocks > ZHEAP_METAPAGE + 1)
 				targetBlock = nblocks - 1;
 		}
 	}
@@ -129,6 +134,16 @@ loop:
 		bool		other_buffer_locked = false;
 
 		/*
+		 * targetBlock can't be same as ZHEAP_METAPAGE because we never
+		 * insert/update free-space of meta page in FSM, so we will not get
+		 * meta page from FSM.
+		 *
+		 * Above we already skipped meta page in case of only 1 block in
+		 * relation.
+		 */
+		Assert(targetBlock != ZHEAP_METAPAGE);
+
+		/*
 		 * Read and exclusive-lock the target block, as well as the other
 		 * block if one was given, taking suitable care with lock ordering and
 		 * the possibility they are the same block.
@@ -173,18 +188,6 @@ loop:
 			LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
 
 			/*
-			 * ZBORKED: This is my (Andres') adaption of the previously (in
-			 * code) undocumented workaround around lock-ordering issue in tpd
-			 * pages that was originally added in
-			 * https://github.com/EnterpriseDB/zheap/commit/e4d3f718991b673ca3f6b02f5562366f7bc67b6d
-			 *
-			 * Whenever we need two buffers for updating a tuple
-			 * (non-inplace), we use the rule "lock lower numbered buffer
-			 * first" to avoid deadlocks. But, in zheap this is not the
-			 * sufficient condition.  It's possible that the new buffer is a
-			 * pruned TPD buffer and some other backend is trying to use it
-			 * while holding lock on a zheap buffer with higher block number.
-			 *
 			 * To avoid deadlocking, we simply don't lock otherBuffer.  First
 			 * we will check that target block is TPD block or not, if TPD
 			 * block then we will not lock otherBuffer.
@@ -211,15 +214,26 @@ loop:
 			}
 		}
 
-		if (targetBlock == ZHEAP_METAPAGE || IsTPDPage(BufferGetPage(buffer)))
+		if (IsTPDPage(BufferGetPage(buffer)))
 		{
 			/*
-			 * ZBORKED: I (Andres) had to implement this because the previous
-			 * code was plainly broken, and caused problems due to the newer
-			 * fsm_local_map() logic.  We could handle the ZHEAP_METAPAGE case
-			 * before locking (but be careful, it needs to be in the loop),
-			 * but I'm doubtful it's worth it, because we still need to update
-			 * the FSM etc.
+			 * XXX: This is a TPD page, so we have to skip it.
+			 *
+			 * If this TPD page is an empty then we can use it after removing
+			 * from meta list but removal is costly and we will rarely get an
+			 * empty TPD page here(only when we will not get any page from FSM
+			 * and trying with last block of relation, that can be empty TPD
+			 * page (See ExtendTPDEntry)).  So we are skipping empty TPD page
+			 * also.
+			 *
+			 * Ideally, we don't need to update free-space for TPD page in FSM
+			 * because at the time of making the page as TPD page, we always
+			 * update free-space for that page as zero in FSM so we will never
+			 * get same TPD page from FSM. (See TPDAllocatePageAndAddEntry).
+			 * So we can directly call GetPageWithFreeSpace to get a new page.
+			 * However, doing so need some additional checks in the code which
+			 * don't seem necessary as this is not a common scenario for which
+			 * we need to optimize.
 			 */
 			pageFreeSpace = 0;
 		}
diff --git a/src/backend/access/zheap/zmultilocker.c b/src/backend/access/zheap/zmultilocker.c
index 8b47b30..cdddc38 100644
--- a/src/backend/access/zheap/zmultilocker.c
+++ b/src/backend/access/zheap/zmultilocker.c
@@ -452,7 +452,7 @@ ConditionalZMultiLockMembersWait(Relation rel, List *mlmembers,
  * transaction.
  */
 bool
-ZIsAnyMultiLockMemberRunning(Relation rel, int xwait_trans_slot,
+ZIsAnyMultiLockMemberRunning(Relation rel,
 							 List *mlmembers, ZHeapTuple zhtup, Buffer buf,
 							 bool *pending_actions_applied)
 {
@@ -490,10 +490,14 @@ ZIsAnyMultiLockMemberRunning(Relation rel, int xwait_trans_slot,
 		{
 			bool		action_applied;
 
+			/* Slot must be valid. */
+			Assert(mlmember->trans_slot_id != InvalidXactSlotId);
+
+			/* Apply the actions. */
 			action_applied = zheap_exec_pending_rollback(rel, buf,
-														 xwait_trans_slot,
-														 memxid,
-														 NULL);
+													mlmember->trans_slot_id,
+													memxid,
+													NULL);
 
 			/*
 			 * If actions are applied, then set pending_actions_applied flag
@@ -639,7 +643,7 @@ GetLockerTransInfo(Relation rel, ItemPointer tid, Buffer buf,
 	TransInfo  *trans_slots = NULL;
 	FullTransactionId fxid;
 	FullTransactionId oldestXidWithEpochHavingUndo;
-	int			trans_slot_id;
+	int			trans_slot_id = InvalidXactSlotId;
 	uint8		uur_type;
 	int			slot_no;
 	int			total_trans_slots = 0;
diff --git a/src/backend/access/zheap/zundo.c b/src/backend/access/zheap/zundo.c
index 6ffe294..5f71d6f 100644
--- a/src/backend/access/zheap/zundo.c
+++ b/src/backend/access/zheap/zundo.c
@@ -438,8 +438,7 @@ zheap_exec_pending_rollback(Relation rel, Buffer buf, int trans_slot_id,
 				BlockNumberIsValid(*tpd_blkno))
 				any_tpd_slot_rolled_back = true;
 
-			process_and_execute_undo_actions_page(urec_ptr, rel, buf,
-												  fxid, slot_no);
+			process_and_execute_undo_actions_page(urec_ptr, rel, buf, fxid);
 		}
 	}
 
@@ -469,14 +468,13 @@ zheap_exec_pending_rollback(Relation rel, Buffer buf, int trans_slot_id,
  * from_urecptr - undo record pointer from where to start applying the undo.
  * rel			- relation descriptor for which undo to be applied.
  * buffer		- buffer for which unto to be processed.
- * epoch		- epoch of the xid passed.
- * xid			- aborted transaction id whose effects needs to be reverted.
- * slot_no		- transaction slot number of xid.
+ * fxid			- aborted full transaction id whose effects needs to be
+ * 				  reverted.
  */
 void
 process_and_execute_undo_actions_page(UndoRecPtr from_urecptr, Relation rel,
 									  Buffer buffer,
-									  FullTransactionId fxid, int slot_no)
+									  FullTransactionId fxid)
 {
 	UndoRecPtr	urec_ptr = from_urecptr;
 	UndoRecInfo *urp_array;
diff --git a/src/include/access/tpd.h b/src/include/access/tpd.h
index 304931a..048f703 100644
--- a/src/include/access/tpd.h
+++ b/src/include/access/tpd.h
@@ -110,7 +110,7 @@ extern int	TPDPageGetSlotIfExists(Relation relation, Buffer heapbuf, OffsetNumbe
 								   FullTransactionId fxid, UndoRecPtr *urec_ptr,
 								   bool keepTPDBufLock, bool checkOffset);
 extern int	TPDPageGetTransactionSlotInfo(Buffer heapbuf, int trans_slot,
-										  OffsetNumber offset, uint32 *epoch, TransactionId *xid,
+										  OffsetNumber offset, FullTransactionId *fxid,
 										  UndoRecPtr *urec_ptr, bool NoTPDBufLock, bool keepTPDBufLock);
 extern void TPDPageSetTransactionSlotInfo(Buffer heapbuf, int trans_slot_id,
 										  FullTransactionId fxid, UndoRecPtr urec_ptr);
diff --git a/src/include/access/zheap.h b/src/include/access/zheap.h
index 1fc7906..70986d5 100644
--- a/src/include/access/zheap.h
+++ b/src/include/access/zheap.h
@@ -226,10 +226,6 @@ extern int	PageGetTransactionSlotId(Relation rel, Buffer buf,
 									 FullTransactionId fxid, UndoRecPtr *urec_ptr,
 									 bool keepTPDBufLock, bool locktpd,
 									 bool *tpd_page_locked);
-extern void PageGetTransactionSlotInfo(Buffer buf, int slot_no,
-									   uint32 *epoch, TransactionId *xid,
-									   UndoRecPtr *urec_ptr,
-									   bool keepTPDBufLock);
 extern TransInfo *GetTransactionsSlotsForPage(Relation rel, Buffer buf,
 											  int *total_trans_slots,
 											  BlockNumber *tpd_blkno);
@@ -334,7 +330,7 @@ extern bool zheap_exec_pending_rollback(Relation rel, Buffer buffer,
 										int slot_no, TransactionId xwait, BlockNumber *tpd_blkno);
 extern void process_and_execute_undo_actions_page(UndoRecPtr from_urecptr,
 												  Relation rel, Buffer buffer,
-												  FullTransactionId fxid, int slot_no);
+												  FullTransactionId fxid);
 
 /* in zheap/zvacuumlazy.c */
 struct VacuumParams;
diff --git a/src/include/access/zmultilocker.h b/src/include/access/zmultilocker.h
index 8bebb5d..13a09c1 100644
--- a/src/include/access/zmultilocker.h
+++ b/src/include/access/zmultilocker.h
@@ -36,7 +36,7 @@ extern bool ConditionalZMultiLockMembersWait(Relation rel, List *mlmembers,
 											 Buffer buf, TransactionId update_xact,
 											 LockTupleMode required_mode, int *remaining,
 											 bool *upd_xact_aborted);
-extern bool ZIsAnyMultiLockMemberRunning(Relation rel, int xwait_trans_slot,
+extern bool ZIsAnyMultiLockMemberRunning(Relation rel,
 										 List *mlmembers, ZHeapTuple zhtup,
 										 Buffer buf, bool *pending_actions_applied);
 extern bool ZMultiLockMembersSame(List *old_members, List *new_members);
diff --git a/src/test/isolation/expected/zheap_mvcc.out b/src/test/isolation/expected/zheap_mvcc.out
index 5253cb4..dfde49f 100644
--- a/src/test/isolation/expected/zheap_mvcc.out
+++ b/src/test/isolation/expected/zheap_mvcc.out
@@ -1,34 +1,34 @@
 Parsed test spec with 3 sessions
 
 starting permutation: r1 w2 r2 r1 c2 r1 c1 r1 c3
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            1              
 monkey         1              
 step w2: UPDATE animals SET counter = counter + 1 WHERE name = 'cat';
-step r2: SELECT * FROM animals;
+step r2: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            2              
 dog            1              
 monkey         1              
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            1              
 monkey         1              
 step c2: COMMIT;
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            2              
 dog            1              
 monkey         1              
 step c1: COMMIT;
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            2              
@@ -37,54 +37,54 @@ monkey         1
 step c3: COMMIT;
 
 starting permutation: r1 w2 r2 r1 c2 r1 w3 r3 r1 c3 r1 c1 r1
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            1              
 monkey         1              
 step w2: UPDATE animals SET counter = counter + 1 WHERE name = 'cat';
-step r2: SELECT * FROM animals;
+step r2: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            2              
 dog            1              
 monkey         1              
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            1              
 monkey         1              
 step c2: COMMIT;
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            2              
 dog            1              
 monkey         1              
 step w3: UPDATE animals SET counter = counter + 1 WHERE name = 'cat';
-step r3: SELECT * FROM animals;
+step r3: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            3              
 dog            1              
 monkey         1              
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            2              
 dog            1              
 monkey         1              
 step c3: COMMIT;
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            3              
 dog            1              
 monkey         1              
 step c1: COMMIT;
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            3              
@@ -92,32 +92,32 @@ dog            1
 monkey         1              
 
 starting permutation: r1 d2 r2 r1 c2 r1 c1 r1 c3
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            1              
 monkey         1              
 step d2: DELETE FROM animals WHERE name = 'dog';
-step r2: SELECT * FROM animals;
+step r2: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 monkey         1              
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            1              
 monkey         1              
 step c2: COMMIT;
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 monkey         1              
 step c1: COMMIT;
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
@@ -125,40 +125,40 @@ monkey         1
 step c3: COMMIT;
 
 starting permutation: r1 i3 r3 r1 c3 r1 c1 r1 c2
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            1              
 monkey         1              
 step i3: INSERT INTO animals VALUES ('kangaroo', 1);
-step r3: SELECT * FROM animals;
+step r3: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            1              
-monkey         1              
 kangaroo       1              
-step r1: SELECT * FROM animals;
+monkey         1              
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            1              
 monkey         1              
 step c3: COMMIT;
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            1              
-monkey         1              
 kangaroo       1              
+monkey         1              
 step c1: COMMIT;
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            1              
-monkey         1              
 kangaroo       1              
+monkey         1              
 step c2: COMMIT;
diff --git a/src/test/isolation/expected/zheap_tpd.out b/src/test/isolation/expected/zheap_tpd.out
index f7abb80..63ffaf1 100644
--- a/src/test/isolation/expected/zheap_tpd.out
+++ b/src/test/isolation/expected/zheap_tpd.out
@@ -7,7 +7,7 @@ step i3: INSERT INTO ANIMALS VALUES ('panther', 33);
 step i4: INSERT INTO ANIMALS VALUES ('giraffe', 44);
 step i5: INSERT INTO ANIMALS VALUES('tiger', 55);
 step c5: COMMIT;
-step r5: SELECT * FROM animals;
+step r5: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
@@ -15,46 +15,46 @@ dog            10
 monkey         100            
 tiger          55             
 step c4: COMMIT;
-step r4: SELECT * FROM animals;
+step r4: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            10             
-monkey         100            
 giraffe        44             
+monkey         100            
 tiger          55             
 step c2: COMMIT;
-step r2: SELECT * FROM animals;
+step r2: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            10             
-monkey         100            
-lion           22             
 giraffe        44             
+lion           22             
+monkey         100            
 tiger          55             
 step c3: COMMIT;
-step r3: SELECT * FROM animals;
+step r3: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
 dog            10             
-monkey         100            
+giraffe        44             
 lion           22             
+monkey         100            
 panther        33             
-giraffe        44             
 tiger          55             
 step c1: COMMIT;
-step r1: SELECT * FROM animals;
+step r1: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
-dog            10             
-monkey         100            
 cow            11             
+dog            10             
+giraffe        44             
 lion           22             
+monkey         100            
 panther        33             
-giraffe        44             
 tiger          55             
 
 starting permutation: i1 i2 i3 i4 i5 w5 c5 r5 w2 d2 r2 w3 c3 r3 c1 c4
@@ -65,7 +65,7 @@ step i4: INSERT INTO ANIMALS VALUES ('giraffe', 44);
 step i5: INSERT INTO ANIMALS VALUES('tiger', 55);
 step w5: UPDATE animals SET counter = counter + 5 WHERE name = 'cat';
 step c5: COMMIT;
-step r5: SELECT * FROM animals;
+step r5: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            6              
@@ -74,7 +74,7 @@ monkey         100
 tiger          55             
 step w2: UPDATE animals SET counter = counter + 2 WHERE name = 'cat';
 step d2: ROLLBACK;
-step r2: SELECT * FROM animals;
+step r2: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            6              
@@ -83,7 +83,7 @@ monkey         100
 tiger          55             
 step w3: UPDATE animals SET counter = counter + 3 WHERE name = 'cat';
 step c3: COMMIT;
-step r3: SELECT * FROM animals;
+step r3: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            9              
@@ -102,7 +102,7 @@ step i4: INSERT INTO ANIMALS VALUES ('giraffe', 44);
 step i5: INSERT INTO ANIMALS VALUES('tiger', 55);
 step t5: DELETE FROM ANIMALS WHERE name = 'dog';
 step c5: COMMIT;
-step r5: SELECT * FROM animals;
+step r5: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
@@ -110,7 +110,7 @@ monkey         100
 tiger          55             
 step t2: DELETE FROM ANIMALS WHERE name = 'lion';
 step d2: ROLLBACK;
-step r2: SELECT * FROM animals;
+step r2: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 cat            1              
@@ -118,7 +118,7 @@ monkey         100
 tiger          55             
 step t3: DELETE FROM ANIMALS WHERE counter < 3;
 step c3: COMMIT;
-step r3: SELECT * FROM animals;
+step r3: SELECT * FROM animals ORDER BY 1,2;
 name           counter        
 
 monkey         100            
diff --git a/src/test/isolation/specs/zheap_mvcc.spec b/src/test/isolation/specs/zheap_mvcc.spec
index db88ab6..0b5d861 100644
--- a/src/test/isolation/specs/zheap_mvcc.spec
+++ b/src/test/isolation/specs/zheap_mvcc.spec
@@ -13,20 +13,20 @@ teardown
 
 session "s1"
 setup		{ BEGIN; }
-step "r1"	{ SELECT * FROM animals; }
+step "r1"	{ SELECT * FROM animals ORDER BY 1,2; }
 step "c1"	{ COMMIT; }
 
 session "s2"
 setup       { BEGIN; }
 step "w2"	{ UPDATE animals SET counter = counter + 1 WHERE name = 'cat'; }
-step "r2"	{ SELECT * FROM animals; }
+step "r2"	{ SELECT * FROM animals ORDER BY 1,2; }
 step "d2"	{ DELETE FROM animals WHERE name = 'dog'; }
 step "c2"	{ COMMIT; }
 
 session "s3"
 setup       { BEGIN; }
 step "w3"	{ UPDATE animals SET counter = counter + 1 WHERE name = 'cat'; }
-step "r3"	{ SELECT * FROM animals; }
+step "r3"	{ SELECT * FROM animals ORDER BY 1,2; }
 step "i3"	{ INSERT INTO animals VALUES ('kangaroo', 1); }
 step "c3"	{ COMMIT; }
 
diff --git a/src/test/isolation/specs/zheap_tpd.spec b/src/test/isolation/specs/zheap_tpd.spec
index 96be779..5d54db9 100644
--- a/src/test/isolation/specs/zheap_tpd.spec
+++ b/src/test/isolation/specs/zheap_tpd.spec
@@ -12,7 +12,7 @@ teardown
 
 session "s1"
 setup		{ BEGIN; }
-step "r1"	{ SELECT * FROM animals; }
+step "r1"	{ SELECT * FROM animals ORDER BY 1,2; }
 step "i1"	{ INSERT INTO ANIMALS VALUES ('cow', 11); }
 step "t1"	{ DELETE FROM ANIMALS WHERE name = 'dog'; }
 step "c1"	{ COMMIT; }
@@ -22,7 +22,7 @@ session "s2"
 setup       { BEGIN; }
 step "w2"	{ UPDATE animals SET counter = counter + 2 WHERE name = 'cat'; }
 step "i2"	{ INSERT INTO ANIMALS VALUES ('lion', 22); }
-step "r2"	{ SELECT * FROM animals; }
+step "r2"	{ SELECT * FROM animals ORDER BY 1,2; }
 step "t2"	{ DELETE FROM ANIMALS WHERE name = 'lion'; }
 step "c2"	{ COMMIT; }
 step "d2"	{ ROLLBACK; }
@@ -33,7 +33,7 @@ setup       { BEGIN; }
 step "i3"	{ INSERT INTO ANIMALS VALUES ('panther', 33); }
 step "w3"	{ UPDATE animals SET counter = counter + 3 WHERE name = 'cat'; }
 step "t3"	{ DELETE FROM ANIMALS WHERE counter < 3; }
-step "r3"	{ SELECT * FROM animals; }
+step "r3"	{ SELECT * FROM animals ORDER BY 1,2; }
 step "c3"	{ COMMIT; }
 
 # index key update
@@ -41,7 +41,7 @@ session "s4"
 setup       { BEGIN; }
 step "i4"	{ INSERT INTO ANIMALS VALUES ('giraffe', 44); }
 step "w4"	{ UPDATE animals SET counter = counter + 4 WHERE name = 'cat'; }
-step "r4"	{ SELECT * FROM animals; }
+step "r4"	{ SELECT * FROM animals ORDER BY 1,2; }
 step "c4"	{ COMMIT; }
 
 # insert and index key update
@@ -49,7 +49,7 @@ session "s5"
 setup       { BEGIN; }
 step "i5"	{ INSERT INTO ANIMALS VALUES('tiger', 55); }
 step "w5"	{ UPDATE animals SET counter = counter + 5 WHERE name = 'cat'; }
-step "r5"	{ SELECT * FROM animals; }
+step "r5"	{ SELECT * FROM animals ORDER BY 1,2; }
 step "t5"	{ DELETE FROM ANIMALS WHERE name = 'dog'; }
 step "c5"	{ COMMIT; }
 
diff --git a/src/test/recovery/t/018_zheap_recovery.pl b/src/test/recovery/t/018_zheap_recovery.pl
new file mode 100644
index 0000000..a873b74
--- /dev/null
+++ b/src/test/recovery/t/018_zheap_recovery.pl
@@ -0,0 +1,146 @@
+# Tests to verify replication and recovery in zheap
+# Tests added are to verify tpdxlog.c,zheapamxlog.c,undoactionxlog.c,undoworker.c and undorequest.c
+use strict;
+use warnings;
+use PostgresNode;
+use TestLib;
+use Test::More tests => 17;
+
+# Initialize master node, doing archives
+my $node_master = get_new_node('master');
+$node_master->init(has_archiving => 1, allows_streaming => 1);
+
+#append zheap related params
+#modify rollback_overflow_size so that the tasks are pushed to undo workers
+$node_master->append_conf('postgresql.conf', "wal_level = hot_standby \n");
+$node_master->append_conf('postgresql.conf', "default_table_access_method = 'zheap'\n");
+$node_master->append_conf('postgresql.conf', "rollback_overflow_size = 0\n");
+
+# Start master
+$node_master->start;
+
+sub pgbench
+{
+	local $Test::Builder::Level = $Test::Builder::Level + 1;
+
+	my ($opts, $stat, $out, $err, $name, $files, @args) = @_;
+	my @cmd = ('pgbench', split /\s+/, $opts);
+	my @filenames = ();
+	if (defined $files)
+	{
+		for my $fn (sort keys %$files)
+		{
+			my $filename = $node_master->basedir . '/' . $fn;
+			push @cmd, '-f', $filename;
+
+			# cleanup file weight
+			$filename =~ s/\@\d+$//;
+
+			#push @filenames, $filename;
+			# filenames are expected to be unique on a test
+			if (-e $filename)
+			{
+				ok(0, "$filename must not already exists");
+				unlink $filename or die "cannot unlink $filename: $!";
+			}
+			append_to_file($filename, $$files{$fn});
+		}
+	}
+
+	push @cmd, @args;
+
+	$node_master->command_checks_all(\@cmd, $stat, $out, $err, $name);
+
+	# cleanup?
+	#unlink @filenames or die "cannot unlink files (@filenames): $!";
+
+	return;
+}
+
+# Take backup from which all operations will be run
+$node_master->backup('my_backup');
+
+# Initialize standby node from backup, fetching WAL from archives
+my $node_standby = get_new_node('standby');
+$node_standby->init_from_backup($node_master, 'my_backup',has_streaming => 1);
+$node_standby->append_conf('postgresql.conf',"wal_retrieve_retry_interval = '100ms'");
+
+#start standby
+$node_standby->start;
+
+# create history table,to log data.
+$node_master->safe_psql('postgres','CREATE  TABLE pgbench_history (tid integer,bid integer,aid integer,delta integer,mtime timestamp without time zone,filler character(22))');
+
+#Create data
+pgbench (
+	'-i -s 10 --foreign-keys',
+	0,
+	[qr{^$}i],
+	[
+		qr{dropping old tables},
+		qr{creating tables},
+		qr{vacuuming},
+		qr{creating primary keys},
+		qr{done\.}
+	],
+	'pgbench scale 10 initialization');
+
+#Check that only READ-only queries can run on standbys
+is($node_standby->psql('postgres', "INSERT INTO pgbench_accounts VALUES (1001,1001,1001,'aa');"),
+	3, 'read-only queries on standby');
+
+#start transactions on master,so that the WAL replay happens on standby
+pgbench(
+	"-M prepared -c8 -j8 -T 20 ",
+	0,
+	[
+			qr{type: multiple scripts},
+			qr{mode: prepared},
+			qr{script 1: .*/custom_script_zheap_1},
+			qr{weight: 5},
+			qr{script 2: .*/custom_script_zheap_2},
+			qr{weight: 5}
+	],
+	[qr{starting vacuum...end.}],
+	'zheap pgbench custom scripts',
+	{
+		'custom_script_zheap_1@1' => q{-- custom_script
+		\set aid random(1, 1000000)
+		\set bid random(1, 10)
+		\set tid random(1, 100)
+		\set delta random(1, 5000)
+		BEGIN;
+		UPDATE pgbench_accounts SET abalance = abalance + :delta WHERE aid = :aid;
+		SELECT abalance FROM pgbench_accounts WHERE aid = :aid;
+		UPDATE pgbench_tellers SET tbalance = tbalance + :delta WHERE tid = :tid;
+		UPDATE pgbench_branches SET bbalance = bbalance + :delta WHERE bid = :bid;
+		INSERT INTO pgbench_history (tid, bid, aid, delta, mtime) VALUES (:tid, :bid, :aid, :delta, CURRENT_TIMESTAMP);
+		END;
+},
+		'custom_script_zheap_2@5' => q{-- custom_script_rb
+		\set aid random(1, 1000000)
+		\set bid random(1, 10)
+		\set tid random(1, 100)
+		\set delta random(1, 5000)
+		BEGIN;
+		UPDATE pgbench_accounts SET abalance = abalance + :delta WHERE aid = :aid;
+		SELECT abalance FROM pgbench_accounts WHERE aid = :aid;
+		UPDATE pgbench_tellers SET tbalance = tbalance + :delta WHERE tid = :tid;
+		UPDATE pgbench_branches SET bbalance = bbalance + :delta WHERE bid = :bid;
+		rollback;
+}
+	});
+
+#restart master,this will apply undoactions
+$node_master->stop('immediate');
+$node_master->start;
+
+
+#check data on standby
+my $result =$node_standby->safe_psql('postgres', "SELECT count(*) FROM pgbench_accounts");
+ print "standby: $result\n";
+is($result, qq(1000000), 'check streamed content on standby');
+
+$node_master->stop;
+$node_standby->stop;
+done_testing();
diff --git a/src/test/regress/expected/rules.out b/src/test/regress/expected/rules.out
index 92fe829..e6ad7b3 100644
--- a/src/test/regress/expected/rules.out
+++ b/src/test/regress/expected/rules.out
@@ -2880,59 +2880,66 @@ create rule r1 as on update to rules_src do also
   insert into rules_log values(old.*, 'old'), (new.*, 'new');
 update rules_src set f2 = f2 + 1;
 update rules_src set f2 = f2 * 10;
-select * from rules_src;
+select * from rules_src ORDER BY 1,2;
  f1 | f2  
 ----+-----
   1 |  30
  11 | 130
 (2 rows)
 
-select * from rules_log;
+select * from rules_log ORDER BY 1,2,3;
  f1 | f2  | tag 
 ----+-----+-----
   1 |   2 | old
   1 |   3 | new
- 11 |  12 | old
- 11 |  13 | new
   1 |   3 | old
   1 |  30 | new
+ 11 |  12 | old
+ 11 |  13 | new
  11 |  13 | old
  11 | 130 | new
 (8 rows)
 
 create rule r2 as on update to rules_src do also
   values(old.*, 'old'), (new.*, 'new');
-update rules_src set f2 = f2 / 10;
+-- To make output consistancey, we will update one row at a time because in
+-- zheap, some time due to non in-place updates, rows order will be differnt.
+update rules_src set f2 = f2 / 10 WHERE f2 = 30;
  column1 | column2 | column3 
 ---------+---------+---------
        1 |      30 | old
        1 |       3 | new
+(2 rows)
+
+update rules_src set f2 = f2 / 10 WHERE f2 = 130;
+ column1 | column2 | column3 
+---------+---------+---------
       11 |     130 | old
       11 |      13 | new
-(4 rows)
+(2 rows)
 
-select * from rules_src;
+select * from rules_src ORDER BY 1,2;
  f1 | f2 
 ----+----
   1 |  3
  11 | 13
 (2 rows)
 
-select * from rules_log;
+select * from rules_log ORDER BY 1,2,3;
  f1 | f2  | tag 
 ----+-----+-----
   1 |   2 | old
   1 |   3 | new
- 11 |  12 | old
- 11 |  13 | new
+  1 |   3 | new
   1 |   3 | old
   1 |  30 | new
+  1 |  30 | old
+ 11 |  12 | old
+ 11 |  13 | new
+ 11 |  13 | new
  11 |  13 | old
  11 | 130 | new
-  1 |  30 | old
-  1 |   3 | new
  11 | 130 | old
- 11 |  13 | new
 (12 rows)
 
 create rule r3 as on delete to rules_src do notify rules_src_deletion;
diff --git a/src/test/regress/expected/rules_1.out b/src/test/regress/expected/rules_1.out
index 4f309e6..c755098 100644
--- a/src/test/regress/expected/rules_1.out
+++ b/src/test/regress/expected/rules_1.out
@@ -2755,59 +2755,66 @@ create rule r1 as on update to rules_src do also
   insert into rules_log values(old.*, 'old'), (new.*, 'new');
 update rules_src set f2 = f2 + 1;
 update rules_src set f2 = f2 * 10;
-select * from rules_src;
+select * from rules_src ORDER BY 1,2;
  f1 | f2  
 ----+-----
   1 |  30
  11 | 130
 (2 rows)
 
-select * from rules_log;
+select * from rules_log ORDER BY 1,2,3;
  f1 | f2  | tag 
 ----+-----+-----
   1 |   2 | old
   1 |   3 | new
- 11 |  12 | old
- 11 |  13 | new
   1 |   3 | old
   1 |  30 | new
+ 11 |  12 | old
+ 11 |  13 | new
  11 |  13 | old
  11 | 130 | new
 (8 rows)
 
 create rule r2 as on update to rules_src do also
   values(old.*, 'old'), (new.*, 'new');
-update rules_src set f2 = f2 / 10;
+-- To make output consistancey, we will update one row at a time because in
+-- zheap, some time due to non in-place updates, rows order will be differnt.
+update rules_src set f2 = f2 / 10 WHERE f2 = 30;
  column1 | column2 | column3 
 ---------+---------+---------
        1 |      30 | old
        1 |       3 | new
+(2 rows)
+
+update rules_src set f2 = f2 / 10 WHERE f2 = 130;
+ column1 | column2 | column3 
+---------+---------+---------
       11 |     130 | old
       11 |      13 | new
-(4 rows)
+(2 rows)
 
-select * from rules_src;
+select * from rules_src ORDER BY 1,2;
  f1 | f2 
 ----+----
   1 |  3
  11 | 13
 (2 rows)
 
-select * from rules_log;
+select * from rules_log ORDER BY 1,2,3;
  f1 | f2  | tag 
 ----+-----+-----
   1 |   2 | old
   1 |   3 | new
- 11 |  12 | old
- 11 |  13 | new
+  1 |   3 | new
   1 |   3 | old
   1 |  30 | new
+  1 |  30 | old
+ 11 |  12 | old
+ 11 |  13 | new
+ 11 |  13 | new
  11 |  13 | old
  11 | 130 | new
-  1 |  30 | old
-  1 |   3 | new
  11 | 130 | old
- 11 |  13 | new
 (12 rows)
 
 create rule r3 as on delete to rules_src do notify rules_src_deletion;
diff --git a/src/test/regress/expected/zheap.out b/src/test/regress/expected/zheap.out
index afc544c..b1bfed1 100644
--- a/src/test/regress/expected/zheap.out
+++ b/src/test/regress/expected/zheap.out
@@ -528,23 +528,23 @@ DELETE FROM test_multi_insert WHERE id%2=0;
 VACUUM test_multi_insert;
 BEGIN;
 COPY test_multi_insert FROM STDIN;
-SELECT * FROM test_multi_insert;
+SELECT * FROM test_multi_insert ORDER BY 1;
  id 
 ----
   1
- 11
   3
- 12
   5
- 13
   7
- 14
   9
+ 11
+ 12
+ 13
+ 14
  15
 (10 rows)
 
 ROLLBACK;
-SELECT * FROM test_multi_insert;
+SELECT * FROM test_multi_insert ORDER BY 1;
  id 
 ----
   1
diff --git a/src/test/regress/sql/rules.sql b/src/test/regress/sql/rules.sql
index 629c3cf..d62659f 100644
--- a/src/test/regress/sql/rules.sql
+++ b/src/test/regress/sql/rules.sql
@@ -997,13 +997,16 @@ create rule r1 as on update to rules_src do also
   insert into rules_log values(old.*, 'old'), (new.*, 'new');
 update rules_src set f2 = f2 + 1;
 update rules_src set f2 = f2 * 10;
-select * from rules_src;
-select * from rules_log;
+select * from rules_src ORDER BY 1,2;
+select * from rules_log ORDER BY 1,2,3;
 create rule r2 as on update to rules_src do also
   values(old.*, 'old'), (new.*, 'new');
-update rules_src set f2 = f2 / 10;
-select * from rules_src;
-select * from rules_log;
+-- To make output consistancey, we will update one row at a time because in
+-- zheap, some time due to non in-place updates, rows order will be differnt.
+update rules_src set f2 = f2 / 10 WHERE f2 = 30;
+update rules_src set f2 = f2 / 10 WHERE f2 = 130;
+select * from rules_src ORDER BY 1,2;
+select * from rules_log ORDER BY 1,2,3;
 create rule r3 as on delete to rules_src do notify rules_src_deletion;
 \d+ rules_src
 
diff --git a/src/test/regress/sql/zheap.sql b/src/test/regress/sql/zheap.sql
index 2221e95..9df2b94 100644
--- a/src/test/regress/sql/zheap.sql
+++ b/src/test/regress/sql/zheap.sql
@@ -356,7 +356,7 @@ COPY test_multi_insert FROM STDIN;
 14
 15
 \.
-SELECT * FROM test_multi_insert;
+SELECT * FROM test_multi_insert ORDER BY 1;
 ROLLBACK;
-SELECT * FROM test_multi_insert;
+SELECT * FROM test_multi_insert ORDER BY 1;
 DROP TABLE test_multi_insert;
-- 
1.8.3.1

