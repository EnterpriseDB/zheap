From 14b52b362113f842823109f80a5a8d928ff7fff8 Mon Sep 17 00:00:00 2001
From: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date: Thu, 18 Jul 2019 13:39:25 +0530
Subject: [PATCH 03/18] zheap_on_undoprocessing_v1 MIME-Version: 1.0
 Content-Type: text/plain; charset=UTF-8 Content-Transfer-Encoding: 8bit
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

zheap-squash-2019-05-23
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Squashed commit of the following:

commit 7f489f12c6ca7f758bf4d0861520512a3a203bfc
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-24 00:13:40 +0530

    Fixed bug for multi-locker clearing bit

    In ZIsAnyMultiLockMemberRunning, we were checking that if there
    is any running transaction or not, if not, then we were clearing
    multi-locker bit.  But it is possible that transaction is aborted and
    undo actions still not applied, then we can't clear bit.
    So as suggested by Amit and Dilip, now we are applying actions for
    aborted transaction in ZIsAnyMultiLockMemberRunning.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit a68c8bf1046a56da08c88851f969afa27d4f22e9
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-22 14:40:07 +0530

    pgindent run

commit 64a473e111e8c66e45d3217f7d17f666e160373a
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-22 14:28:07 +0530

    Refactor undo prepare code for lock

    Separate out the undo record preparation code into different function.
    This allows the same function to be used both during DO and REDO
    operation.

    reviewed by Mahendra Singh Thalor and Amit Kapila

commit 466d106919d10df5f96979ca7266cd5dde170f61
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-05-22 13:10:50 +0530

    Refactor zheap_lock_tuple.

    Move the logic for lock wait in a separate function.  This makes code more
    readable.

    Patch by Amit Kapila, reviewed by Kuntal Ghosh

commit fede6ef8691a8a6f99ff8a39839dd4820e5d4e60
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-22 09:44:41 +0530

    Fixed bug in zheap_lock_updated_tuple for TPD page allocation

    In zheap_lock_updated_tuple, when we were calling PageReserveTransactionSlot
    to reserve slot.  There we were passing offset of current tuple.  If we were
    not able to reserve slot of zheap page then to add TPD page, we were adding
    those number of entries in offset map (+8 additionally) in TPD entry.
    Due to current tuple offset, in some cases, we were adding less number of
    offset map in TPD entry than zheap page max offset.  Whenever any tuple having
    greater (8 greater than, because we are adding 8 extra entry in map) offset than
    TPD allocated offset and if marked slot on tuple was last slot of page, and page
    have TPD, then we were checking that offset in TPD map but our offset was not
    in TPD so we were getting assert failure.
    To fix this, we should pass max number of zheap page offset.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 6e9c4a48dbf3eb0a53b7de0a11af0c33e178cf0a
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-20 19:20:39 +0530

    Run pgindent

commit ff0ce877cc4a25ac067761140e9b4c4ce28ade38
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-20 17:26:20 +0530

    Use SubTransactionId instead of TransactionId in zheap_delete_wait_helper
    and zheap_update_wait_helper for sub xid.

    Patch by Mahendra Singh Thalor, suggested by Amit Kapila

commit 6d295d4c28d69f315e8236594e9f300904aafc19
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-20 17:13:00 +0530

    Removed duplicate test case from pgbench test

    In commit 896b4690a81542dbfdd3d9, we added some test cases
    to increase code coverage, but some of them are duplicate,
    so removed.

    Patch by Neha Sharma, reviewed by Mahendra Singh Thalor

commit bd7cd693a8448c146c99ee69bc309907b8c256cd
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-20 11:05:01 +0530

    Fixed bug in zheap_update and zheap_insert to set page reinit flag

    In zheap_update/ zheap_insert, when we were inserting tuple into
    zheap page, then if page was having only 1 max tuple and item id
    was unused then we were setting reinit flag.  Due to reinit, in
    replay, we were getting inconsistent page because in master copy,
    we had xid and urec of vacuum in page slot that marked item id
    unused but in standby due to reinit we don't have vacuum info.
    To fix this, now at the time of setting a reinit flag, check if
    there is any non-empty slot other than current transaction slot.
    If so, then don't set the reinit flag.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 0c68a5f962a4047ab0868001dc5746194c49f496
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-05-20 10:39:42 +0530

    Fix order by issue in rowsecurity regression test

    Gunjan Kumar Reviewed by me

commit 896b4690a81542dbfdd3d96c29847572d9c101ef
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-15 22:37:10 +0530

    Added test case to increase code coverage of rewritezheap.c
    and zmultilocker.c files in pgbench test folder

    Patch by Neha Sharma and Gunjan Kumar, reviewed by me

commit 0a2151cd40669f6fe45be822773066bf63a9c5a1
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-05-14 18:17:02 +0530

    Refactor zheap_lock_tuple_guts

    Reviewed by Amit Kapila

commit b4c8b09719adaadc508629be06180ad4c52619c1
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-15 15:34:44 +0530

    Fixed undo buffer locking hang

    In UndoGetPrevRecordLen, we were not releasing lock on previous
    buffer in some conditions and were trying to lock lower number
    block after locking higher number block so fixed this.

    Patch by Mahendra Singh Thalor, reviewed by Dilip Kumar

commit 210c57109214b717b26a87c7728e21641b5ad07d
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-15 13:51:19 +0530

    Fix bug in ZHeapTupleFetch

    Introduced in commit b1286c5db5, we were not checking if transactionid
    is valid when marking slot as frozen.

    reviewed by Amit Kapila

commit d453931a78dcaea29929783d0f6e9361f2380eb6
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-15 11:16:25 +0530

    Spellcheck

commit a56a7bb378dd71744a733ab2425c7f1cfe8aa4e6
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-14 15:41:23 +0530

    Fixed a bug in rollback handling.

    In zheap_undo_actions, when we try to open relation, it is possible
    that relation already dropped by that time.  In such case, we were not
    able to open relation and we were throwing an error.   Now, the
    request is again registered in the error queue for processing which is
    not correct.  We must skip processing the undo actions in this case.
    Also, we need to abort the transaction in case of error and clean the
    error state.

    Patch by Kuntal Ghosh and me, reviewed by Amit Kapila

commit 735daf821a4e02cb805617d7f4412b008c671067
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-14 13:57:06 +0530

    Run pgindent in src/backend/access/zheap

commit 2e9466cb6ca08d2317441d2c8326b9e39db0ed40
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-14 13:46:28 +0530

    Fixed few warnings

commit 68120b3263d638c287c5a419ac41f1f8d692b106
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-14 11:46:22 +0530

    Refactor zheap_update

    Separate out the undo record preparation code into different function.
    This allows the same function to be used both during DO and REDO
    operation.

    Reviewed by Mithun CY

commit a2e0664e16b5d6e4cdb853425d9e19ddfcf34019
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-05-13 17:41:02 +0530

    Add order by caluse to some test cases

    In this commit, we've added order by clauses to a few test cases of
    zheap.sql and updatable_views.sql

commit 893d4840388e6a2c27fee7e211e8cc6168c2e9da
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-05-10 20:20:37 +0530

    Use common routine to lock the tuple.

    During update we lock the tuple when we momentarily release the page lock.
    However, to lock tuple we were using a code very similar to what we have in
    zheap_lock_tuple_guts.  This is probably done this way by seeing heap, but
    here we have somewhat more code, so it is better to use a common routine.

    While doing this refactoring, I have noticed that zheap_lock_tuple_guts
    accepts too many parameters which we should try to reduce, but that is a
    matter of separate commit.

    Suggested by Andres Freund, Patch by me, reviewed by Kuntal Ghosh

commit 164baef206ba2090c63d81da49ab06f6f3f1661b
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-05-10 14:28:43 +0530

    Fixups from undoprocessing patch

    We'd better include the RMGR ID when finding groups of undo records
    to pass to an undo callback, otherwise we could give them records they
    don't understand.

    When logical decoding encounters an undo action redo record, it should
    ignore it.

    Patch by Thomas Munro.

commit fdb0ff5d52142c0de5c442bf7a356d1be055dd97
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-09 15:58:57 +0530

    Removed rewind lock and rewinding of urec ptr.

    As suggested by Robert and Andres, now we will not rewind urec
    ptr so removing rewinding handling.  As per new design, we don't
    need rewind lock so removing rewind lock also in this.

    Patch by Amit Kapila and me, reviewed by Dilip Kumar and Amit
    Kapila

commit f71dfd5b2c90cd8bcd3ccecf03964662626e8c06
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-09 10:58:34 +0530

    Fixed a bug in zheap_lock_tuple

    In zheap_lock_tuple, a check to examine if tuple data is NULL when
    ZHeapTupleSatisfiesUpdate returns TM_updated was missing in commit
    007f31470dd384d0b.  Fixed it.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 335d27fcc326c0b30ea4b1598997e65752a71f7e
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-05-08 11:41:42 -0400

    Remove a few calls to ZHeapTupleGetTransXID.

    In these cases, it seems that the value we get must be the same one
    that was returned by ZHeapTupleSatisfiesUpdate, because both
    functions perform the same steps, and the buffer lock is not
    released in the meanwhile.

commit db8c0be4568320a0c6d9387e5bda540aae3a9ab5
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-05-08 11:00:23 -0400

    GetLockerTransInfo: Change output parameter to FullTransactionId.

commit 007f31470dd384d0b29b3e8a03744b0cc02c695d
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-05-07 12:04:37 -0400

    Move some logic common to all callers into ZHeapTupleSatisfiesUpdate.

commit 7cf4d9fac1e22fc43db4592af4b3441e2c6e7ba2
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-05-07 11:31:37 -0400

    zheap_update: Refactor to reduce code duplication.

    Moving the check_tup_satisfies_update label a bit earlier means that
    code which jumps to it doesn't have to separately handle the
    ItemIdIsDeleted case.

commit 0a1638a0eaedc0d1ff6dff0123d403f8fc333e32
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-05-07 11:03:57 -0400

    zheap_update: Tighten up code for setting key_intact and *lockmode.

commit dd9ef4776597cad197a446a6cda7ccdd913d9913
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-05-07 10:49:01 -0400

    zheap_update: Revise code that sets use_inplace_update.

    This seems clearer and takes less code.  It does mean that we invoke
    zheap_page_prune_opt before taking the subtransaction lock, but that
    seems like it should be OK.

commit ad78e8e1b979085b4e356d4ea0c8feadda762473
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-05-07 10:27:26 -0400

    zheap_update: Code movement.

    Let's do all of the changes to interesting_attrs in one place instead
    of dividing that logic up between two places, and let's also do it
    before acquiring the buffer lock.

    And a bunch of other things can be postponed until we know that the
    update is moving forward.

commit 0084ebf10284b5d10b486b19cb7865cdb5f90e11
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-07 19:55:29 +0530

    Make a seperate function for xlog lock insert

    This function can be used by both zheap_update and zheap_lock_tuple_guts

    reviewed by Amit Kapila

commit 0d79ac7c2ebb3bf4ed4907ab82bdef7ec4a9b324
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-07 14:01:18 +0530

    Fixed bug in UndoDiscard

    In UndoDiscard, we were not setting oldestXidHavingUndo correctly,
    so discarding was not proper.  Due to this, we were getting some
    assert failures for xid. Fixed this.

    Patch by Mahendra Singh Thalor, suggested and reviewed by Amit Kapila
    and Dilip Kumar

commit 52e159b0bb77c6a20cc478f7b6f3bdf2eec7a8c4
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-07 12:13:04 +0530

    Fixed bug in zheap_exec_pending_rollback

    In commit e44f3022d9faca, instead of checking the xid in every slot
    for abort, only the currect xid is checked thus trying to apply undo
    actions for all xid that was wrong. so fixed this.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit b5c8323abee7513e200c214b5ce71bed6d2e563e
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-03 13:28:04 +0530

    Refactor zheap_multi_insert

    Move WAL related code to a seperate function.

commit 36db7fc1cf014aa3a9f1ad0da83900ee9d264603
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-03 11:21:07 +0530

    Run pgindent on src/include/access

commit 8d428d89cdeeadd7d858bbdf4d6910bb3eddab32
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-03 11:19:30 +0530

    Update typedefs.list

    Add all the new structs added for undo worker and zheap.

commit 53c00ab55044cc0e0162523398dad54ffddd896a
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-03 10:38:21 +0530

    Run pgindent on src/backend/access/zheap

commit f22111b5560f093250981d24f5955220209d5bcc
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-03 10:37:11 +0530

    Update typedef.lists and run pgindent

commit cf911474da41ee43157989216092862bef3089f7
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-05-03 00:12:04 +0530

    Run pgindent

commit 6a9c39e5780b85c8075ab473203856e466dd8145
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-05-02 09:28:35 -0400

    Move a few variables to inner scopes.

commit 3de208afe0e5a0a83e6f00a286736b3f2414e44c
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-02 15:08:47 +0530

    To avoid deadlock in TPD page locking, we disallow using the
    freepage from FSM.

    In TPDAllocatePageAndAddEntry, we will not use page from FSM to avoid
    deadlock, so setting always_extand = true by default.

    Once we fix the locking order for TPD pages, we can change this flag.

    Patch by Mahendra Singh Thalor, suggested and reviewed by Amit Kapila

commit 4dcc6a4416d113bb6b8e4d22ab2aa37983195acd
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-05-02 10:43:38 +0530

    Fixed warnings for unused variables in GetLockerTransInfo

    In GetLockerTransInfo, cid and save_urec_ptr are setted but not
    used, so removed these variables to silence warnings.

    Patch by Mahendra Singh Thalor

commit ffd8d0ca35e8f70c6afb977ad237fb2a9d5aee2d
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-05-01 19:24:13 -0400

    Minor cleanup of GetLockerTransInfo.

    It doesn't need the whole ZHeapTuple, just the TID.  And several
    of its output parameters are completely unused.

commit 605d889dee48cb3cca9420ef3d271384957e631c
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-05-01 18:54:32 -0400

    Remove ZHeapPageGetCtid; use FetchTransInfoFromUndo instead.

    This is both less code and eliminates some possible duplicate
    undo fetches.

commit cb0d64b8b955bfbad7da399a0233d7a793514d64
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-29 15:26:32 -0400

    ZHeapTupleGetTransInfo: Remove fetch_cid argument.

    The only caller that uses this argument is ZHeapTupleSatisfiesUpdate.
    Open-code the logic there instead.

commit 7909491fbc3604426aff8177fb7d2bfb8e3ae730
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-30 17:05:35 -0400

    Move more logic into ZGetMultiLockMembersForCurrentXact.

    It is renamed to ZCurrentXactHasTupleLockMode.  The loop performed
    by every caller to check whether a high-enough lock mode is present
    is now moved into the function itself.  This not only takes less
    code but also permits us to stop early if we find that the lock
    mode is present.  It also saves allocating and deallocating memory
    unnecessarily.

commit 07293de5feacc9b7fbf60ffa9d6356b2cc41c1b2
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-29 14:43:23 -0400

    ZHeapTupleGetTransInfo: Adjust transaction-is-old test.

    Use 64-bit XID test instead of 32-bit XID test.

    Don't check UndoLogIsDiscarded.  If it is, then FetchTransInfoFromUndo
    will just find itself unable to locate the undo in question; the
    current code is testing essentially the same condition an extra
    time.

commit cf5adbcfbfe0e78dc2647b8b1ef09d6b418c5530
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-30 11:52:40 +0530

    Removed unused flag(rellock) from execute_undo_actions

    In commit 4f9eb6a92a3ec7620, I missed to remove rellock flag from
    execute_undo_actions, so fixed this.

    Patch by Mahednra Singh Thalor, reviewed by Amit Kapila

commit 6b185176d630d11bbf68cdf57777ef8382d79f38
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-30 11:24:39 +0530

    Fixed buffer leak warning for undo buffer

    In execute_undo_actions, we missed to release undo buffer in
    case of undo actions already executed.

    Patch by Mahendra Singh Thalor, reviewed by Dilip Kumar

commit 1c30f19226537ba186a0bd878b4b0ee4313b1556
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-04-29 11:58:24 +0530

    Fix rollback for twophase xacts

    For rollback of twophase xacts, if the execute_undo_actions is failed
    from backend, we should try to insert the same in error queue.

    Reported and reviewed by Amit Kapila.

commit e9ba01be6be326d6a6b0bbdc3f589821294775db
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-29 10:55:25 +0530

    Fixed xid unused warning in zheap_insert

    Warning is introduced by commit e44f3022d9faca53c122268821a86

    Patch by Mahendra Singh Thalor

commit 02b1a8a746ca8da6baa1416af57eb00968e77448
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-04-29 10:44:55 +0530

    Correct use of TransactionId in the reverted commit.

    The struct which uses FullTransactionId has been removed with revert so
    use an additional variable to store the TransactionId.

commit 3ed3d242ccfbdd1aca9ab586cf417604717a62a9
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-04-29 10:12:25 +0530

    Revert "Refactor zheap_update"

    This reverts commit 9049c73e9cbca4a0a90a6d6a45a2ed145ab34166.
    There were multiple problems with TPD during redo.

commit 5785dd46a3e82f7f03515d96d1712c4c2c4d75cf
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-04-27 11:23:59 +0530

    Fix a bug in undoworker

    When we remove an element from the binary heap, we basically swap that
    element with the last one.  So, when we're removing multiple elements
    from binary heap using a loop, once we remove an element from a
    location, we need to examine the same location again.

    Reported by Mahendra Singh Thalor

commit ef4dfe276efb4dc988a8be3f6f4467d9b1a2e086
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-26 11:02:20 -0400

    RefetchAndCheckTupleStatus's single_locker_xid is INOUT after all.

    I thought otherwise, but I was wrong.

    This probably needs a redesign of some kind, but for right now
    let's just unbreak what I broke.

commit e44f3022d9faca53c122268821a867149a75a7fd
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-26 09:56:46 -0400

    Convert many more functions to accept FullTransactionId.

    TPDPageGetSlotIfExists, TPDPageSetUndo, PageReserveTransactionSlot,
    MultiPageReserveTransSlot, PageGetTransactionSlotId, PageSetUNDO,
    and process_and_execute_undo_actions_page were all taking an XID
    and an epoch as separate arguments.  Pass a FullTransactionId
    instead.

commit 1e680c9f2ec060a9a7bc2d664df5893c6b98db41
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-04-26 13:23:00 +0530

    Use full_xid in undoworker and execute_undo_actions apis

    Reviewed by Amit Kapila

commit d7bd804c56671fa8e259029161220c5e899c13a0
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-04-26 12:24:14 +0530

    Get rid of GetEpochForXid from undodiscard API

    Reviewed by Amit Kapila

commit d09431928064a491e7becb6b6acb3dd199e9d6ab
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-04-26 14:08:45 +0530

    Remove redundant reference to epoch in comments.

commit 023876f45b992f371c4e2016da68fe32a55ae45f
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-04-26 13:50:00 +0530

    Improve the variable naming for TransInfo structure.

    Suggested by Andres Freund, Robert Haas

commit 603280af337653c749e83708e94f5e3ae7be3dbb
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-04-26 13:48:23 +0530

    Get rid of GetTPDBlockNumberFromHeapBuffer.

    In commit ce0105f370, we have introduced a new function GetTPDBlockAndOffset
    which can be used instead of GetTPDBlockNumberFromHeapBuffer.

    Amit Kapila and Mahendra Singh Thalor

commit ce0105f37006d470b10fc86cfccdb1134dad99e8
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-04-26 13:46:33 +0530

    Use common function GetTPDBlockAndOffset.

    There are a lot of places which were fetching TPDBlock and TPDItemOffset
    from last transaction slot, unify all those places into a single
    function.

    Suggested by Andres Freund, Patch by me, Reviewed by Mahendra Singh Thalor

commit 46190a491c3e230d499d9d98c014b7fe7c325e54
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-25 17:51:24 +0530

    Fixed TPD slot logging bug in zheap_update

    In zheap_update, if TPD flag is set, then we were writing
    xid in place of TPD slot.  So fixed this.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 9049c73e9cbca4a0a90a6d6a45a2ed145ab34166
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-04-25 17:37:42 +0530

    Refactor zheap_update

    Separate out the undo record preparation code into separate function.
    This allows the same function to be used both during DO and REDO
    operation.

commit 043301124c226b57f22be0e6d11a0e97e933f652
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-25 14:39:32 +0530

    Added test case for toast rollback in zheap.sql

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 77bc76acf0c81cb4c5c65ce685d936857a9c6604
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-25 14:25:39 +0530

    Fixed segmentation fault for rollback of toast table insertions.

    While applying undo actions for speculative insertions, we expect that
    there must be speculative token in undo record.  This is just to
    distinguish it from non-speculative insertions.  We were not inserting
    the token for toast table insertions, fix that.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 4f9eb6a92a3ec76209bfb8d9b5aec7965d14e985
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-25 14:20:28 +0530

    Fixed toast rollback related bug in zheap_undo_actions

    In zheap_undo_actions, we were locking the relation based on rellock
    flag.  We assume that if our current backend aborts and then in applying
    undo actions, we have all locks of this transaction but for toast relation
    we don't have lock because we acquires and release the lock on relation in
    ztoast_save_datum.  So we were getting assert failure of relation lock.

    As suggested by Robert and Andres, I removed rellock flag and now we
    are locking the relation unconditionally.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit a60eb69b056c2cb3e5eab39bfcbe0efdd03a0596
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-25 13:28:10 +0530

    Fixed wrong check in zheap_update

    In zheap_update, in place of slot, we were checking xid
    to set TPD info flag. so fixed this.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 11f72e491b33404e51130b1d353f4f3c68b70ddd
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-25 13:05:18 +0530

    Added ORDER BY to fix arrays.out regression failure

    Patch by Mahendra Singh Thalor, suggested by Amit Kapila

commit ff1de4957261b4d2a76605c43e09824f49fc320d
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-04-25 08:14:48 +0530

    Run pgindent on zheapam.c

    Introduced in refactor commit 6f35538f

commit de87396f671f2389f8ae3644c5ca75b4ce1cb6d2
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-04-24 16:35:41 +0530

    Remove spurious check.

    Pointed by Andres Freund.

commit 2ca383e954adf7e96f274e65ecc3fbd2a6729e28
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-04-24 13:52:11 +0530

    Remove genham.h.

    It make some sense before tableam, but not now.

    Pointed by Andres Freund and Robert Haas, patch by me.

commit 035d07a8e794bb873998ec95be9de7367a6dc389
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-23 15:32:37 -0400

    Remove ZHeapTupleGetCtid.

    It's easier to include the one extra line of code this function
    contains in the caller.

commit 58190ca30095959bc42d320b738aec25eab58b5c
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-23 15:17:49 -0400

    Have ZHeapPageGetNewCtid take ZHeapTupleTransInfo *zinfo.

    Previously, it took TransctionId *xid and CommandId *cid, but all
    callers are OK with doing it this way instead.  The only difference
    is that all of the zinfo fields will be updated instead of just
    zinfo.xid and zinfo.cid.

commit 20f03fb957f95516d83dfbc8a27d8bbccafcdf5b
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-23 15:06:28 -0400

    zheap_update, zheap_lock_updated_tuple: Use zinfo fields more.

commit 9388247cb2d9a76b3d38eaaa2210801036a31019
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-23 14:08:59 -0400

    Minor code cleanup in zheap_lock_tuple.

    Use zinfo fields instead of having separate variables tup_xid,
    tup_cid, and tup_trans_slot_id.  Instead of duplicating the code for
    handling deleted items, centralize it all in one place by moving the
    check_tup_satisfies_update label a bit earlier.

commit 5b95cb5be9207763f8bd063636f9f5aa88e0f2ac
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-23 13:25:09 -0400

    Factor a big chunk of tuple locking code out of zheap_update.

    This is very similar to what the last commit did for zheap_delete.
    The two new helper functions are quite similar.

commit 6f35538fb8d2c4bb294b1f9e654cd6ceeaf37f78
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-23 12:02:24 -0400

    Factor a big chunk of tuple locking code out of zheap_delete.

    To create a cleaner abstraction boundary between zheap_delete and
    the new function zheap_delete_wait_helper, move the label
    check_tup_satisfies_update a bit earlier.  This enables removal
    of a bit of duplicate code elsewhere.

commit dcab56fd2d8c2ea5d986564913b702edf32f860c
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-04-23 16:53:06 +0530

    Fix an issue in UndoDiscardOneLog

    While calculating xmin in DiscardWorkerMain, we ignore the vacuum and
    autovacuum xids. But, in zheap, a vacuum/autovacuum process can write
    undo records that needs to be discarded.  So, we can't ignore the
    autovacuum/vacuum process while calculating the xmin.  Else, we may
    consider an in-progress vacuum/autovacuum xid as aborted which is wrong.

    As of now, when a backend performs VACUUM, we forcefully clear
    the vacuum flag from MyPgXact in lazy_vacuum_zheap_rel.  Hence, the
    problem comes only with autovacuums.  We've to investigate the correct
    way to handle this situation. For now, I've made the check for
    registering a rollback request more strict.  It checks for the following
    conditions to decide whether a xid is aborted:
    1. xid didn't commit.
    2. xid is not in progress. (added in this commit)
    3. the corresponding undo record is not being rolled back.
    4. the corresponding database is still exists.

    Reported by Andres Freund. Investigated and Patch by me. Reviewed by Amit
    Kapila and Dilip Kumar.

commit 399e9c6a12ee27327cae7ad0e6f018d07a0603df
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-22 18:03:15 -0700

    Convert TransInfo.{xid, xid_epoch} to FullTransactionId.

    Part of the ongoing work to use FullTransactionId rather than tracking
    xid and epoch separately.

commit cf3678c41198133c2d51d420dcf89414c614d8e4
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-04-22 14:49:45 +0530

    Update copyright information

commit d90cee9afd873c5122c091ff56db5ee646ee933a
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-04-22 14:23:11 +0530

    Rewrite undo and discard worker implementation

    To improve the efficiency of the rollbacks, we create three queues and a
    hash table for the rollback requests.  A Xid based priority queue which will
    allow us to process the requests of older transactions and help us to move
    oldesdXidHavingUndo forward.  A size-based queue which will help us to
    perform the rollbacks of larger aborts in a timely fashion, so that we don't
    get stuck while processing them during discard of the logs.  An error queue
    to hold the requests for transactions that failed to apply its undo.  The
    rollback hash table is used to avoid duplicate undo requests by backends and
    discard worker.

    To process the request, we get the request from one of the queues, search
    it in hash table and mark it as in-progress and then remove from the
    respective queue.  After that, we perform the request and remove it from
    hash table.

    Undo launcher is responsible for launching the workers iff there is some
    work available in one of work queues and there are more workers available.
    The worker is launched to handle requests for a particular database.  Each
    undo worker then start reading from one of the queue the requests for that
    particular database.

    The discard worker is responsible for discarding the undo log of
    transactions that are committed and all-visible or are rolledback.  It also
    registers the request for aborted transactions in the work queues.  It
    iterates through all the active logs one-by-one and try to discard the
    transactions that are old enough to matter.

    Designed by: Andres Freund, Amit Kapila, Robert Haas, Thomas Munro
    Author: Amit Kapila, Kuntal Ghosh, and Dilip Kumar

commit 2cdb5260accd5a553590b1400dac6f124c339d16
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-04-19 16:31:48 +0530

    Give proper variable name in ZHeapWALInfo struct

    The terms tup_trans_slot_id and trans_slot_id were not intuative so use
    prior_trans_slot_id and new_trans_slot_id instead.

    suggested by Robert Haas

commit 350beb84aba15497f8d8c724268f5cc83781a37a
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-04-19 10:48:44 +0530

    Fix a bug in log_zheap_update

    During refactor in 7071df5c1c, the variable names were mixed up causing
    assertion failure.

    Report and fix by Robert Haas

commit 136215dce3d4e6952adbec5318b0d8e4895d6712
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-18 10:48:09 +0530

    Fixed truncation bug for non-index table

    In lazy_scan_zheap, we were using tupindex varibale to
    mark dead tuples to unused. In case of non-index table,
    we were not reseting this variable for every block but
    we were reseting num_dead_tuples so we were not marking
    dead tuples as unused hence we were not truncating. So
    fixed this bug.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila
    and Kuntal Ghosh, reported by Hitachi

commit 2f4475d2e6ae59c3963578bb873ca26e0c70e953
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-17 13:29:21 -0400

    ValidateTuplesXact: Fix bogus pfree.

    We should not free the tuple we got from the caller, but rather the
    one we got from ZHeapTupleFetch.

    The resulting use-after-free situation was discoverd by Mahendra
    Singh Thalor.

commit 7ec0cf75cc8da8468f646b74ef20925e9a211a01
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-17 12:59:55 -0400

    Consolidate and simplify code in ZHeapTupleFetch.

    Most of the logic in ZHeapTupleSatifies moves into ZHeapTupleFetch,
    with some modifications intended to make the logic work for deleted
    tuples.

    The role of ZHeapTupleSatisfies is reduced to determining whether a
    tuple satisfies a snapshot, just like the name of the function might
    suggest.

    ZHeapGetVisibleTuple is removed, since the code paths for deleted
    and non-deleted items have now been merged.  This has the side
    effect that, if using a dirty snapshot on a deleted item, we will
    now apply ZHeapSelectVersionDirty rather than ZHeapSelectVersionSelf.
    That seems like a good thing, but will change the behavior when
    TransactionIdIsCurrentTransactionId(xid) is false but
    TransactionIdIsInProgress(xid) is true.  Also, SNAPSHOT_ANY will
    now apply the appropriate set of rules rather than SnapshotSelf
    rules.

    I noticed that at some point during previous refactorings I inverted
    the logic for the SNAPSHOT_NON_VACUUMABLE case, so flip that back
    around.  It's surprising this doesn't break any tests.

    The new logic for SNAPSHOT_NON_VACUUMABLE won't work in the case of
    a tuple that's been deleted from the page, so Assert() that this
    doesn't happen.  The old code would have applied SNAPSHOT_SELF
    semantics, which doesn't seem like the right thing either.

commit 9fefd8edd04fc2a54b57a22e7b2838cc9cfbaa10
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-17 10:28:28 +0530

    Revert "Fixed truncation bug for non-index table"

    This reverts commit f2659747cb9524d26b0333bc5c8de4845f3bc35b.
    This commit introduced a bug, that causing regression failure.

    Reported by Andres Freund

commit 7cca248c181052d79f8d375bff69b576b605d06a
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-16 20:13:54 -0400

    Try to repair broken all_dead handling in zheap_search_buffer.

    Commit 8bf28cb629046c437f14d7ac1d4fc8b0381cedb1 accidentally
    broke this.  Repair by adjusting ZHeapTupleIsSurelyDead to work
    for both deleted and non-deleted items, and using it for that
    purpose in zheap_search_buffer.

    We should have a more efficient way of doing this, but that can
    wait for a later commit.

commit 254a34d06b7477c2a7d7f0e4f31cc23f20e5c53e
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-16 19:57:40 -0400

    Adapt ZHeapTupleGetTransInfo not to require a ZHeapTuple.

    It is more convenient to be able to call it with just a block and
    offset number.

commit 8bf28cb629046c437f14d7ac1d4fc8b0381cedb1
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-16 17:27:18 -0400

    Add new interface function ZHeapTupleFetch and use it everywhere.

    Previously, callers that were looked at non-deleted items used
    ZHeapTupleSatisfies, while those looking at deleted items used
    ZHeapGetVisibleTuple.  The new function ZHeapTupleFetch can handle
    both cases, which in some places permits considerable simplification
    on the calling side.  Currently, the new function just calls one or the
    other of ZHeapTupleSatisfies and ZHeapGetVisibleTuple, but it should
    be possible to combine more of the logic in the future.

    The new function offers the option either to return the tuple or
    just a true/false value.  A few callers now use this to avoid
    leaking the returned tuple.  It also offers the option to return
    the new CTID whether or not the tuple is deleted, where previously that
    was only conveniently available for non-deleted tuple.  Those
    operating on deleted tuples had to separately call
    ZHeapPageGetNewCtid; this function will now do that automatically
    where required, and in the future it should be possible to adjust
    things so that we get the same effect with less redundant work.

    The mysterious ValidateTuplesXact function now takes a relation as
    an additional argument so that it can call ZHeapTupleFetch with
    the right arguments.  There are other ways this could work, but
    this seems simplest.

    In various places, this converts the code to use zheap_gettuple
    rather than bespoke logic for constructing a stack-allocated
    ZHeapTupleData.  There might be a minor loss of efficiency there,
    but I think it's worth it for the improved code cleanliness.
    Further refactoring work will probably recapture any performance
    we're surrendering here.

commit b10523ff41c326a2f711860bc1ac416ea77ab310
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-16 14:08:11 -0700

    Fix possible stack-overflow during concurrent index creations.

    validate_index_zheapscan's in_index array was sized for heap, not
    zheap - the latter can have more tuples per page. Thus, depending on
    what's on the stack, modifications of in_index would end up trashing
    stack contents, including the return pointer.

    Found using asan.

    Also fix stray reference to MaxHeapTuplesPerPage instead of
    MaxZHeapTuplesPerPage in an error message.

    Bug reported by Mahendra Thalor.

commit a1a180232da6b06cd24f09b97ef26b81232d0725
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-16 10:23:44 -0400

    Simplify and fix zheapam_tuple_satisfies_snapshot.

    It's not OK for this function to stack-allocate the ZHeapTupleData,
    because ZHeapTupleSatisfies can free the input tuple.

    Using zhtup.t_len rather than tup->t_len as an argument to memcmp
    looks like a bug, too.

commit 310a779198f4bac50c9ce9664004d280fcf6698b
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-16 09:25:44 -0400

    Remove ZHeapPageGetCid.

    Use FetchTransInfoFromUndo instead.  It will overwrite zinfo.xid
    and zinfo.epoch_xid, but it should find the same XID that was
    already there; otherwise, the transaction slot point to some other
    transaction's undo chain.  It will also update zinfo.urec_ptr,
    but just to point to the record we actually found instead of the
    record where we started the search, so it should be OK.

    One perhaps-noteworthy difference is that FetchTransInfoFromUndo
    skips UNDO_XID_LOCK_ONLY and UNDO_XID_MULTI_LOCK_ONLY records,
    whereas ZHeapPageGetCid does not.  I *think* that should be a bug
    fix if it makes any difference at all, because the point of
    fetching the CID is to check visibility, and locking a tuple
    can't change anything about the visibility of that tuple.

commit 405cee10cb987edf256b1d9709ab5cdd6578dd84
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-16 18:27:18 +0530

    Clearing local FSM map after allocating new TPD page

    In TPDAllocatePageAndAddEntry, we missed to clear local FSM map.
    Additionally, changed one flag in RelationGetBufferForZTuple.  We
    were calling GetPageWithFreeSpace function with check_fsm_only = false,
    so as per Amit suggection I changed this flag as true in one case.

    Patch ny Mahendra Singh Thalor, reviewed by Amit Kapila

commit 54525ff6ef59157af506c20d08880c6b93f9dbcb
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-04-16 14:59:59 +0530

    Run pgindent on zheapam.c and zheap.h

commit ae7071df5c1c6ee8467c956436077ba984c1abf8
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-04-16 13:48:16 +0530

    Refactor WAL related code

    This adds a new struct which encapsulates all the parameters necessary
    to write a WAL. It also refactors the WAL related code in zheap_delete
    into a seperate function.

commit 0a024f43e90c7470ed47e2082b6da7352f394346
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-04-16 13:11:07 +0530

    Fix compilation error in test_undorecord

    Dilip Kumar Reported by Amit Kapila

commit da46a95caf1c32caf6a1dcbe7309230ee0faf157
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-12 16:12:33 -0700

    Fix contrib/btree_gist for zheap, by forcing the planner's hand.

    The test output otherwise differ - seemingly due to zheap's denser
    storage.

commit 8bb91b5e29310506a3ec53088c00edeae589dc8e
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-12 15:48:33 -0700

    Add alternative output for postgres_fdw when using zheap.

    The diff is mostly planner changes. There's also a tid related
    changes, which should probably be fixed in a more general manner. But
    they don't indicate bugs, and it's good to be able to actually use
    tests.

commit 580948baa9f1a6f6b3c27209e7a86da19d3707bf
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-15 21:27:44 -0400

    In ZHeapTupleTransInfo struct, make epoch_xid a FullTransactionId.

commit 71b41f06eac69ef5ff9a4678912f6823460b327f
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-15 13:11:38 -0400

    Remove ZHeapTupleSatisfiesVacuum.

    Revise API for ZHeapTupleSatisfiesOldestXmin so that it can be used
    instead.

commit e8684ab71c279d8f3ea57e219466ecf62f4d62e9
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-15 12:40:16 -0400

    Remove obsolete stuff.

    Maybe these things had a point at some point in time, but they are
    not needed now.

commit 9b10f8565ae14ea8d72ffedf5143a3785c20404f
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-15 12:30:36 -0400

    Make zheap not depend on HTSV_Result.

    Instead, always use the closely-related ZHTSV_Result.  This allows
    moving some more stuff out of genham.h and including it in fewer
    places.

commit 4b385c59172482bbd599bf62b174093e6738486b
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-15 12:04:17 -0400

    Some basic #include cleanup.

    Remove unnecessarily inclusions from genham.h.

    Don't include genham.h in access/tupmacs.h; it is unnecessary.

    Don't include zhtup.h (and thus, indirectly, genham.h) in
    tuptoaster.h.  This can easily be avoided by moving prototypes
    for ztuptoaster.c into zheapam.h.

commit cba6cdbc0224b2794205fa98a14005375a6e368c
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-15 10:49:03 -0400

    ZHeapTupleSatisfiesVacuum: Work like ZHeapTupleSatisfiesOldestXmin.

    Per Amit Kapila, it is the behavior of the latter which is
    correct.  The difference between the two functions was spotted
    by me during code review.

commit f2659747cb9524d26b0333bc5c8de4845f3bc35b
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-15 14:49:26 +0530

    Fixed truncation bug for non-index table

    In lazy_scan_zheap, we were using tupindex varibale to
    mark dead tuples to unused. In case of non-index table,
    we were not reseting this variable for every block but
    we were resting num_dead_tuples so we were not marking
    dead tuples as unused hence we were not truncating.
    So fixed this bug.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila,
    reported by Hitachi

commit 071d91de5e035ddc11f961aa2dc24c599d0187b8
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-12 15:42:11 -0700

    Adapt contrib regression tests to rebase.

    Most failures were because creating a partitioned table doesn't allow
    specifying the partition anymore.  One was a table created later, that
    didn't specify USING heap despite being heap dependant.

commit e901499be4e7fbd949c8635b1b864aa8743bd424
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-12 02:32:11 -0700

    Use ZHeapTupleHeaderGetNatts rather than heap version in slot_deform_ztuple.

commit 3d4760649ead8eb447c6ccbb865ab5013968641b
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-12 02:31:07 -0700

    Fix bug in zheap_tuple_attr_equals().

    Didn't detect nullness difference. Bit scary that only one recently
    added test catches this.

commit 2b71e07b411a401925b47ac0bcd67ae096082175
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-12 13:52:44 -0400

    Tighten up code in ZHeapTupleSatisfiesUpdate.

    Rather than having a bunch of separate call sites in this function
    that each call GetTupleFromUndo and/or ZHeapTupleGetSubXid, use some
    flags to indicate whether those operations are needed and have only
    one place where we actually make the function call.

    Also, use ZHeapTidOpFromInfomask for consistency with other places
    where I made similar adjustments.

    Also, don't bother catering to subxid == NULL, because no caller does
    that.

    This commit qualifies as a minor performance optimization and/or bug
    fix, because in the old code arrangement if had an in-place updated or
    ZHEAP_XID_LOCK_ONLY tuple, and then we went down the branch for
    TransactionIdIsCurrentTransactionId, and then GetTupleFromUndo
    returned false, we would not return.  Instead we'd fall through to the
    code intended to handle newly-inserted tuples, which would recheck
    TransactionIdIsCurrentTransactionId and then decide that the answer is
    HeapTupleInvisible.  That's probably the right answer, but not the
    right way to arrive at it.

commit dea193919a2d46a04bd0db601ccd99bcf62819ca
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-12 12:30:00 -0400

    Remove GetTupleFromUndoForAbortedXact.

    This code path is just fetching the latest committed version of the
    tuple when the most recent update is known to have aborted.  But
    GetTupleFromUndo can also tell us that.

    GetTupleFromUndoForAbortedXact was probably marginally more efficient
    than GetTupleFromUndo since it had various special-purpose
    optimizations.  But those seem less important than not having multiple
    copies of this code.  If they are important, perhaps we should add
    some of them to GetTupleFromUndo so that all callers can benefit from
    them.

    For example, once we hit an undo record for an update or delete for a
    committed XID, we should be able to just assume that the XID for any
    previous update or delete is also committed.  That's because you can't
    update or delete a tuple while another update or delete is in
    progress.  Figuring out how to optimize this kind of thing might be
    important for reducing CLOG pressure, or maybe it doesn't matter, but
    we shouldn't have multiple copies of the code some of which try to
    optimize this and others of which don't.

    Unfortunately, I was not able to figure out a way to hit this
    code, so add a ZBORKED comment saying it needs tests.

commit d2083956c30f16041d72e41a696183506c4ce5a8
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-12 10:41:55 -0400

    Restructure fetching of tuples from undo.

    GetTupleFromUndo now has the ability to determine whether a visible
    version of the tuple exists without actually fetching the tuple from
    the undo log; we do that only if the caller needs it.  Eventually,
    this can be used by ZHeapTupleSatisfies, some of whose callers do not
    need the returned tuple, but I haven't tried to make that work in this
    commit.

    The easiest way to implement this seemed to eliminate the last
    remaining caller of CopyTupleFromUndoRecord and pull up the logic for
    ZHeapTuple construction into GetTupleFromUndoRecord, so this commit
    also removes CopyTupleFromUndoRecord.  It preserves some of the
    commments in UpdateTupleHeaderFromUndoRecord which has assumed what
    remains of CopyTupleFromUndoRecord's original function.

    GetTupleFromUndo also now has the ability to test according to
    satisfies-update rules; previously, it could only test according to
    satisfies-MVCC and satisfies-self rules.  This eliminates the need for
    a separate copy of the logic in UndoTupleSatisfiesUpdate, so that has
    been removed in favor of having the callers invoke GetTupleFromUndo
    directly.  These callers benefit from GetTupleFromUndo's new ability
    to find out whether a visible version exists without necessarily
    fetching it.

commit 3f480815da46e2451ec79549c0070ee5b418946e
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-11 14:45:57 -0400

    Remove unused arguments.

    ZHeapTupleSatisfiesUpdate's should_free argument is always passed
    as false.  So remove it.

    UndoTupleSatisfiesUpdate's should_free argument is always passed
    as false, its in_place_updated_or_locked argument is ignored, and
    its prev_undo_xid argument is always passeed as InvalidTransactionId.
    Remove them all.

    In passing, remove UndoTupleSatisfiesUpdate's prev_trans_slot_id
    variable.  We set it equal to trans_slot and then never do
    anything with trans_slot again.

commit 21d8b00cef7fd684b823fa6666645cc99c7d1b8c
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-11 14:05:35 -0400

    Use ZHeapPageGetCid instead of ZHeapTupleGetCid.

    The latter does more work and has no advantages.

commit 955ebeb4e77ea531c286a126eb92e694f45c8596
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-11 13:28:31 -0400

    Tidy up initializations around GetTupleFromUndoRecord.

commit eb9013941d0ea7b52048cd017ce37496cb9aef3c
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-11 12:57:32 -0400

    Avoid unnecessarily copying whole tuple from undo record.

    Four of five preexisting callers of CopyTupleFromUndoRecord needed
    only the five-byte header rather than the entire tuple.

commit c06fe811dfd704a0091d5fa304cb146050e6a632
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-11 12:54:48 -0400

    ZHeapTupleGetSubXid: Pass OffsetNumber in lieu of ZHeapTuple.

    Nothing else from the tuple is needed here, so don't insist
    that the caller must have one.

commit 5e179ca4239cf370c60318a4882ac31148798629
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-11 11:11:00 -0400

    ValidateTuplesXact: Minor code cleanup.

commit e8b858e45152546aab1ff0e3c6ab8aaf63ab816c
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-11 10:30:44 -0400

    zheap_delete: Remove a few local variables.

    We can just use the ZHeapTupleTransInfo fields instead.

commit aee1620b6854a7ec692b381d181f1afa67ab2404
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-04-11 14:26:34 +0530

    Avoid extra lock buffer during bulk fetching the undo record

    Currently, BulkFetch of undo record during rollback, acquire and
    release the buffer lock for every undo record.  This patch holds the
    buffer lock untill we read all the records from this buffer.

    Dilip Kumar idea discussed with Amit Kapila

commit 94be2b40fdea3794ff84a92316b5d386b5b3b802
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-04-11 10:09:48 +0530

    Store undo record length at the end of the undo record.

    Instead of kepping the track of the previous undo record in the
    undo log meta and later updating same in the next undo record
    directly store the undo record length at the end of each undo
    record.  This will make code simpler and also for recovery we
    don't need to log the prevlen in WAL as we can directly read
    last 2 byte to read the record.

    Dilip Kumar Idea by Thomas Munro and Reviewed by Amit Kapila

commit ba5437230950149282658eac4aa22334e405c449
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-04-11 09:51:04 +0530

    Refactor zheap_page_execute_undo_action

    Dilip Kumar Suggested by Amit Kapila

commit 28c8e341c324960379804fb8587aad257c9520b0
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-10 12:01:39 +0530

    Fixed small bug in lazy_vacuum_zpage_with_undo

    In lazy_vacuum_zpage_with_undo, we were passing wrong
    argument to PageReserveTransactionSlot.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 64c85b545ebc2b6ee8c7a638baf63bdf88eea7a8
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-04-09 16:00:42 +0530

    Fix some regerssion test added ORDER BY

    Dilip Kumar reported by Robert Haas

commit 6088be05c30d572679fde2010fe06bf91c584b7e
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-04-09 09:32:00 +0530

    Prevent wrong WAL ordering of discard and Update TransInfo.

    Both the discard and the update TransInfo logic register WAL but the
    updaters only wait on the discard lock while updating the oldest_data.
    This sometimes cause the update WAL to be written before the discard
    WAL, causing error at REDO because it will expect the buffers
    to be registered for the data considered discarded during DO time.

    To fix this add a new lock discard_update_lock which will be used in
    shared mode by the updaters and in exclusive mode during the actual
    discard process.

    Patch by me, reviewed by Dilip Kumar

commit 831c604d3adf053bc8cd97f5bc467ee8a4ec5731
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-08 22:24:46 -0400

    Don't store ZHeapTupleData fields in update/delete undo records.

    Doing so is redundant, because the tuple length is already stored in
    uur_tuple.len, the TID is already stored in uur_block and uur_offset,
    and the table OID is already stored in uur_reloid.  Just get the
    information from there instead of storing it all again.

    Not only does this save on I/O, but it's also less code.

commit 92923fe901a42654337edd715108938e900d303b
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-04-08 16:34:46 +0530

    Bug fix in applying undo action

    When undo action is applied from the backend there is a small window
    where the discard worker can push the request to rollback hash table before
    the backend actually apply undo action.  Now, if backend apply the undo
    actions and rewinds the insert location then the worker might read undo
    records of the next transaction.  So for avoiding this backend need to
    remove the entry from the hash table if it presents.

    Dilip Kumar bug raised by Robert Haas

commit 85b8f24ebe167dd9e85e39d709b8031cecf489f1
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-04-05 15:15:00 +0530

    Bug fix in undo record bulk fetch

    During bulk fetch if we have already read the to_urecptr and after that
    the memory segment is full then we need not to call BulkFetch again,
    but due to this bug it will call the BulkFetch and it will start fetching
    from the previous urec pointer of the to_urecptr so it will never reach to
    end until it will find prevlen as 0.  So, it will fetch many unwanted or
    already discarded undo records which doen't belongs to this transaction.

    Dilip Kumar

commit b530ea04b98a4f03cf4b819992ea08be784e77c9
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-08 16:21:50 -0400

    Refactor CopyTupleFromUndoRecord a bit.

    Separate out, as far as I can easily to do so, the logic to figure
    out the transaction slot.

    Also, avoid duplicating the free_zhtup logic, and remove some
    comments that don't seem to make much sense.

commit 3c71d3cca040ea03745cbe9a70030150dec627eb
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-08 15:04:59 -0400

    Header comment cleanup for CopyTupleFromUndoRecord.

commit ff609111a5a5f26df6362e06ff107f3090b005c4
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-08 14:49:24 -0400

    Remove 'cid' argument from CopyTupleFromUndoRecord.

    It is unused.  It is also not really useful even in theory, because
    the caller already has the UnpackedUndoRecord.

commit 2ee61c0c4f189158337787763bc73dbf6154c73c
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-08 14:28:04 -0400

    Consolidate many copies of the logic to create a ZHeapTuple.

    Replace 10 copies of the logic with calls to a new helper function,
    zheap_gettuple.  Replace 2 other copies with calls to the existing
    function zheap_copytuple.

    We still have 5 different bits of code that know how to build a
    ZHeapTuple, but that's better than having 15.

commit ec4f75aa88d2e70ee5fe8f208ca58dfa456dc09a
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-12 01:49:49 -0700

    Refactor zheap_insert.

    Separate out the undo record preparation code into separate
    function. This allows the same function to be used both during DO
    and REDO operation.

commit bd52f599c88fc42585082024714ebe8538a65415
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-04-04 16:49:02 +0530

    Fix an assert

    Apparently can't use UndoRecPtrIsValid for an undo log.

commit b1286c5db5bb75308224c8aafcd17351c817b503
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-05 14:55:29 -0400

    ZHeapTupleSatisfies: Improve logic for deferring CID lookup.

    Instead of ZHeapTupleSatisfies guess at the correct value of
    fetch_cid, and then have ZHeapTupleGetTransInfo sometimes ignore
    it if it thinks that the caller guessed wrong, defer CID lookup
    to the point when we discover that we need it to make a
    visibility decision, and then go get it if we don't have it
    already.

    This doesn't quite get rid of the need for the fetch_cid
    parameter to ZHeapTupleGetTransInfo, because it's still used
    by ZHeapTupleSatisfiesUpdate.  But it at least gets rid of
    the need for the snapshot parameter, since ZHeapTupleSatsisfies
    was the only caller using that parameter, and now it doesn't.

commit dd15aa00a8321301f9963b9f53d3a3d168c58070
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-05 13:22:46 -0400

    Avoid unnecessary clearing of fields in ZHeapTupleGetTransInfo.

    If the slot is ZHTUP_SLOT_FROZEN, GetTransactionSlotInfo will have
    already set these fields to these values, so we don't need to
    do it again.

commit b615a9dc33311e9c009469d83c212ed5c853c22e
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-05 13:11:55 -0400

    In ZHeapTupleGetTransInfo, don't use ZHeapTupleGetCid.

    There's no advantage to using this for non-deleted tuple vs. just
    calling ZHeapPageGetCid.  In fact, it's strictly worse, because
    it will do GetTransactionSlotInfo all over again, which is not
    necessary.

commit a61b1addc28fce279e2db65dbdca283f83f37f49
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-05 13:04:48 -0400

    Teach FetchTransInfoFromUndo to work using block number + offset.

    This spares callers working with deleted tuples the pain of having
    to construct a fake ZHeapTuple just so FetchTransInfoFromUndo can
    take it apart again.

commit d43d12d4145d4fd10bf4ac02bd7117c19c7266df
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-05 11:22:59 -0400

    Move CID visibility checking to a separate function, ZHeapCheckCID.

    Moving this code out of ZHeapSelectVersionMVCC makes it easier to
    postpone fetching the CID until it's clear whether we actually need
    it.  In this commit, GetTupleFromUndo is optimized to work that way.
    ZHeapTupleSatisfies needs a similar optimization, but the current
    code structure makes that hard to implement, so I'm leaving that
    for a later commit.

    Another advantage of this change is that the same code can be shared
    with UndoTupleSatisfiesUpdate, which also needs CID visibility
    checks.

commit 5c98c94a2dea44c653cc0fb46a16bf712dc68b1b
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-05 10:16:43 -0400

    Don't pass cid to ZHeapSelectVersionSelf.

    It's not needed.

commit 27d4c8db7437ac3c80330249d38fbfca00a9e2cf
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-05 07:54:54 -0400

    Pass xid to GetTupleFromUndoRecord.

    Bug reported by Amit Kapila.

commit 158ce0e0bd75054a1f3ea91959dad83349910f45
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-04-05 09:09:30 +0530

    Fix Null pointer access.

    Commit 8b492281 introduced this while refactoring the code.

commit 4ac701ae4f67bdbece65aeee362e8b4af5575f20
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-04 23:35:02 -0400

    Introduce new helper function, GetTupleFromUndoRecord.

    Instead of having 3 copies of this code in this file, just have
    one.  While I'm at it, fix the oldestXidHavingUndo tests to use
    64-bit tests instead of 32-bit tests.

commit 091c4e4f9dcf5489a3bbd2ce285f2d56a51690e6
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-12 01:19:20 -0700

    Refactor ZHeapTupleSatisfies to reduce code duplication.

    The result of this is a bit clunky, because some of the more obscure
    snapshot types require significantly different handling, but it avoids
    a good bit of code duplication, because there are a bunch of common
    steps that are performed for multiple snapshot types.  With more work,
    this can probably be further streamlined.

commit 776ab7b30ef2cb825396b55bc9c07d93935b11ac
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-04 11:24:20 -0400

    Move 'nobuflock' handling into ZHeapTupleGetTransXID.

    None of the direct callers of ZHeapTupleGetTransInfo require
    nobuflock = true, so move that logic into the wrapper function,
    ZHeapTupleGetTransXID, which has a few callers that do pass
    nobuflock = true.

    This involves a small amount of duplicated work but it seems
    worth it to simplify ZHeapTupleGetTransInfo.  I suspect that
    ZHeapTupleGetTransXID is going to get refactored out of
    existence eventually anyway.

commit 1d31e466d3dd49816ebbb446d4e151be0c2740c2
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-04-04 17:31:36 +0530

    Remove unnecessary ReadBuffer call in zheap_getsysattr

    Though commit 14fdcc4b9 removed support for xmax, cmin, and cmax,
    the condition in zheap_getsysattr to read valid buffer was unaltered.
    This caused uncessary fetching of buffer when not required. Since only
    xmin requires a valid buffer, modify and shift the code to read the
    buffer to the appropriate switch case block.

commit ed1fdc596ee1fc1c8efcfc42a9b2063b39cc7d5a
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-04 07:32:18 -0400

    zheap_fetchinsertxid: Swap if/else blocks to save indentation.

commit e443641e896079784e501cb1f8da3337945d47f1
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-04 06:55:59 -0400

    zheap_fetchinsertxid: Make better use of ZHeapTupleTransInfo.

commit faafcd9cf397bff93a090a614630423c278a1361
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-04 15:41:06 +0530

    Fixed segmentation fault in CopyTupleFromUndoRecord

    In CopyTupleFromUndoRecord, if ztup is NULL, then also we were
    trying to access ztup.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 84a26cd5fcdad2048ad12a2bb4662813d7f48a23
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-04-04 14:05:01 +0530

    Fix bug in zheap_fetchinsertxid

    Transaction slot was not updated properly when undo tuple is stamped
    with different slot.

    Found by Robert Haas fixed by me.

commit fc5d4465d5805125a257f4e2891f1f66d3d694b1
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-03 14:22:39 -0400

    Stylistic improvements to FetchTransInfoFromUndo.

    Don't use goto.  Improve grammar in comments.  Add some
    information about why it's sometimes OK to pass InvalidTransactionId;
    details provided by Amit Kapila.

commit a05f25f5e3ee55c5e3246c467c76823a0dbcd5b7
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-03 20:27:10 +0530

    Fixed incorrect data type of trans_slot_id

    In xl_zheap_unused, data type of trans_slot_id was uint8 that was
    wrong because slot can be greater than 256.   If slot is greater than
    256, then also we were wal logging it as uint8.  Due to this, we
    were getting inconsistant page found.

    Patch by Mahendra Singh Thalor, reviewed by Dilip Kumar

commit 41f9cdd24043c2ab7fcbacaa659148d7bba38083
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-04-03 16:27:08 +0530

    Remove redundant check in GetTupleFromUndoForAbortedXact

    Reported by Robert Haas

commit d74988a2d7dcf13ac29ba856cc88a670bc62c34d
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-04-02 18:16:41 +0530

    Fix unaligned access of undo data

    Use memcpy to copy slot from undo data, as undo data might point
    inside the buffer which can cause unaligned access.

    Dilip Kumar reviewed by Amit kapila

commit 3a3750e0f3a713137fcd0347cee833a161190cb1
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-04-01 10:50:47 +0530

    Check tuple status correctly once buffer lock is reaquired

    While checking for tuple lock conflicts, we may release the buffer lock
    in some cases. Once the lock is acquired again, we should check whether
    the infomask on the tuple got changed or the tuple xid/locker xid got changed.
    If so, we've to go through SatisfiesUpdate path again.

    Patch by me. Reviewed by Amit Kapila.

commit 5ea40f0694edd992144eaac2195bd62d4724ada1
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-04-03 13:53:50 +0530

    Retain invalid xact flag while locking tuple

    Since we don't set the xact slot while locking a tuple, we should not
    modify the existing (if any) invalid xact flag from the tuple.

    Patch by me. Reviewed by Amit Kapila.

commit 0dc664fef2c27942f63d56b14105db129fd4c792
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-04-03 12:44:54 +0530

    Fix bugs in compute_new_xid_infomask

    1. When we update tuple which doesn't have any locker, we don't set the
    lockmode on the tuple.  But, when a locker comes later, we should consider
    the lockmode of the updater(no-key exclusive or exclusive) as well and set
    the strongest lock mode on the tuple.
    2. While locking the tuple keep old xact slot unmodified.

    Patch by me. Reviewed by Amit Kapila.

commit 882adb877d8b7ac1c3a9d1289e23edb64375da46
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-04-03 12:43:05 +0530

    Skip lockers while fetching xact info for a tuple

    We should skip lockers while fetching the visibility xact info for a
    tuple.  For lockers, we never store the xact slot on the tuple.  Lockers
    should only be fetched by ZGetMultiLockMembers for multilockers and
    GetLockerTransInfo for single lockers.

    Patch by me. Reviewed by Amit Kapila.

commit 4aa3c2fd7c777cf5b4c1dcaab1c32fe8e93c5351
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-04-02 17:05:09 +0530

    Fix xid_infomask_changed

    Similar two xmax_infomask_changed, it should compare the multilocker flag
    lock only flag and the different lock modes between two infomask.

    Patch by me. Reviewed by Amit Kapila.

commit e0ac6b882d9ad854042f730c69d09ce79636e459
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-03-26 12:54:27 +0530

    Fix small bug in zheap_lock_updated_tuple

    In zheap_lock_updated_tuple, we should use the refetched tuple to check
    the tuple's latest status.

    Patch by me. Reviewed by Amit Kapila.

commit 24128a68f364835e3eeb56c6c5acbf6a169f8a5d
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-03-19 16:35:42 +0530

    Fixed aborted xid case in compute_new_xid_infomask

    In compute_new_xid_infomask, if xid is aborted, then we were
    not doing anything, so changed condition to work same as
    committed id in case of aborted also.

    Patch by Kuntal Ghosh. Reviewed by Amit Kapila.

commit e58d85b333c1d8dee14eaed39c4a6a675c771aa8
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-04-03 11:55:06 +0530

    Modify zheap_tuple_attr_equals

    To prevent frequent calls to zheap_deform_tuple, modify
    zheap_tuple_attr_equals to handle a Bitmapset of attributes instead
    of a single attribute number. It will iterate over the given
    attribute list and return all the columns that are different between
    the two tuples under consideration. Also, add a new parameter
    att_count to zheap_deform_tuple which specifies the number of
    attributes to be deformed for the given tuple. Remove znocachegetattr,
    zfastgetattr and zheap_getattr that are no longer required.

commit 2773a730283f74671935b41c4ce96c331e171982
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-04-03 10:38:44 +0530

    Refactor zheap_delete.

    Separate out the undo record preparation code into separate function. This
    allows the same function to be used both during DO and REDO operation.

commit 10ee871369e3a9182e9ad65e33246d1ca503124f
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-02 16:54:18 -0400

    Add a new function ZHeapUpdateTransactionSlotInfo.

    This logic is duplicated in several places; let's not repeat the
    code.

commit db5fc49e9f175f1d5731f5ce5fd1ebf90a56471b
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-02 15:48:44 -0400

    Remove GetTupleFromUndoWithOffset and GetVisibleTupleIfAny.

    These functions duplicate GetTupleFromUndo almost exactly.  The major
    difference is that GetTupleFromUndo does everything in one function,
    while in the other case the exact same logic is split across two
    functions.  I'm not sure whether it's better in one function or two,
    but I am sure that it's better not to have two copies of the logic.

commit b5bdcb87598e1a6e26b71c1d15f0de9b70c9d226
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-02 14:32:16 -0400

    Don't bother avoid calls to GetTransactionSlotInfo in a few cases.

    It isn't necessary to first check whether the transaction slot is
    something other than ZHTUP_SLOT_FROZEN, because GetTransactionSlotInfo
    handles that case just fine, and quite efficiently.  So simplify
    the logic in a few places.

commit 5a7be5ec486011fe56b0ca39e8d6f986e356bc28
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-02 13:41:46 -0400

    Remove minor code duplication in ZHeapGetVisibleTuple.

commit 39ea23507a63a3495d6d5abcbda776c7e42d6d41
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-02 13:32:26 -0400

    Revise FetchTransInfoFromUndo interface.

    Since all callers now store the results into a ZHeapTupleTransInfo,
    just have the function do that itself.

    It looks more convenient to have callers pass the starting XID as
    an argument instead of assuming it's already stored in the
    ZHeapTupleTransInfo, so do it that way.

commit 36cf86b0e12bf1314f01588ddf8d4eda0f1b20ce
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-02 12:58:27 -0400

    More code cleanup around FetchTransInfoFromUndo.

    Every caller of FetchTransInfoFromUndo now calls it with all non-NULL
    arguments, so FetchTransInfoFromUndo no longer has to cater to the
    possibility of getting a NULL argument.

    Every caller also now stores the results into a ZHeapTupleTransInfo
    which ends up with a valid epoch_xid, xid, cid, and urec_ptr.

commit d4f30b0d84c673bce385dcdb8c861f7072a11eba
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-02 12:14:49 -0400

    Make ValidateTuplesXact smarter about ZHeapTupleTransInfo.

    Get rid of some redundant local variables.  Don't have two
    ZHeapTupleTransInfo variables that are both named zinfo.

commit 4c9909f2e17fd1962b7d0ca60644a34e2ed0e50a
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-02 11:55:34 -0400

    Fix compile break.

    Oops.

commit 65ad8d20a9dceafefb6b8876308c74e55d8365ca
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-02 11:50:16 -0400

    Use ZHeapTupleTransInfo in UndoTupleSatisfiesUpdate.

    Also improve epoch handling.

commit 9571d5654badf646030600c7cba829b38cd65f21
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-02 11:27:36 -0400

    Assorted code cleanup in zheapam_visibility.c.

    In FetchTransInfoFromUndo, xid cannot be NULL, because we dereference
    it unconditionally.  So there's no point in checking whether it's
    NULL later in the function, but let's Assert() that it isn't.

    In ZHeapPageGetNewCtid, make a bit more extensive use of
    ZHeapTupleTransInfo and clean up epoch handling.  Actually, setting
    the value of zinfo.epoch_xid here is useless, but it's also cheap, and
    we eventually need to move to using 64-bit XIDs in a lot more places,
    so this is a step in that direction.

    Also clean up epoch handling in ZHeapTupleGetTransInfo,
    GetVisibleTupleIfAny and ZHeapGetVisibleTuple.

commit ff1417000305d4925f1b7cedd35aa63f7c1c3474
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-02 09:15:14 -0400

    Convert ZHeapGetVisibleTuple to use ZHeapSelectVersion* functions.

    Per Amit Kapila, the TransactionIdIsCurrentTransactionId cases in
    this function cannot be hit, so this is actaully implementing the
    same rules that we use in other cases where we do visibility checks
    against the undo.  So use the same code here as we do there.

commit 92dc03480373d37922d72827f52a710978d6e1bb
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-01 22:37:54 -0400

    Use ZHeapTupleTransInfo in GetTupleFromUndo.

commit 60a612d6edc55cb74b3945e229b6a42c2dac5130
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-01 19:38:02 -0400

    Deduplicate calls to GetTransactionSlotInfo.

    In three different code paths, we had two calls to this function
    where, with a little bit of code movement, we could have had just one.

    Also, remove a useless cast of GetTransactionSlotInfo's result
    to void.

commit c2152480a2339ad0eb93359852291ffa8ece53a1
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-01 18:56:59 -0400

    Merge 'epoch' and 'xid' arguments to ZHeapPageGetCid.

commit a7c130055c5e3b9107c10e32d41db7518c158e9d
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-01 18:17:15 -0400

    Adjust FetchTransInfoFromUndo to treat epoch as uint32.

commit c6e6d608b7223cc1ec9870b72fdf8c2f1cc49a3c
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-01 16:31:15 -0400

    Replace MakeEpochXid macro.

    This macro only works if the epoch is passed as a uint64, but the
    normal type for an epoch is uint32, which led to code contortions
    in a number of places.  Replace this macro with an inline function,
    called FullTransactionIdFromEpochAndXid for Thomas Munro's recent
    work on the PostgreSQL master branch.

    Rip out most of the places where epochs are stored as uint64 rather
    than uint32, but leave FetchTransInfoFromUndo alone for the time
    being, since it needs more extensive surgery.

commit cadc7b3509f286a6321e74771c4112068ed5e214
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-01 14:12:25 -0400

    Remove trans_slot argument from ZHeapPageGetCid and ZHeapPageGetCtid.

    It is not used.

commit 7df51dc22d4c39b34e5284c28ea9ccc6148d12c1
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-01 13:12:07 -0400

    Change GetVisibleTupleIfAny to take a ZHeapTupleTransInfo.

    To make this fully valid, I had to add an additional call to
    GetEpochForXid, but that seems like it's probably not that
    expensive; or perhaps it's something we can clean up later.
    For now, it seems to be worth it for consistency.

commit 7bcb989fd230291df42fd0569bfaa149df954b1f
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-04-01 10:45:54 -0400

    Fix compile break without USE_PREFETCH.

    Since PrefetchBufferGuts is only called from within code that doesn't
    get compiled without USE_PREFETCH, it shouldn't get compiled at all
    when USE_PREFETCH is not specified.  Before, it was getting compiled
    with no contents, which is right for the calling functions but wrong
    for this one.

commit 2d76c2bd322946f31daa3fb1642c1d154b3ed9a6
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-04-01 17:12:10 +0530

    Batch wise undo apply

    This patch implements a better way of applying undo actions for an
    aborted transaction.  So instead of fetching undo records one by one
    like we do now we will read multiple undo records together which can
    fit in undo apply memory.  While fetching the undo record we will
    ensure that we don't release the first buffer of the undo record
    because there are high chances that we get the previous undo record
    in the same buffer.  We will still read the undo record following
    transaction's backward chain. However, we will issue prefetch for
    some of the block ahead of reading the undo record so that we can
    avoid I/O at the time of reading the undo record.  After we have
    collected enough number of undo records we sort them in their
    block order so that all the undo for a block are together and we
    also ensures their order is preserved.

    Dilip Kumar Reviewed by Amit Kapila

commit 6014e991cc635a6abb0718e7ef2c0e1542def3ab
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-01 16:32:06 +0530

    Updated README

    Removed heap_to_zheap related info.

    Suggested by Robert Haas, patch by Mahendra Singh Thalor

commit b12afeb56e8e3aae94f013b00b5e50756f5c43ca
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-04-01 16:18:08 +0530

    Remove reference to ztqual.c.

    The file ztqual.c has been renamed to zheapam_visibility.c, so removed
    it's reference from the code.

    Noted by Robert Haas.

commit bc049c57bd8c130483aa4b6a3acafa02def54c07
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-01 15:34:25 +0530

    Removed heap_to_zheap function

    Suggested by Robert Haas, patch by Mahendra Singh Thalor,
    reviewed by Amit Kapila

commit a2b2a331e6e4a605616ae7679ca928cc828b63ab
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-01 14:40:01 +0530

    Allow aborted transactions slot to be reused in more cases

    In case of non in-place in two different buffers, now we will pass
    old buffer in PageReserveTransactionSlot to release the lock of old
    buffer to apply undo actions of aborted slots for new buffer.
    If old buffer is valid in PageFreezeTransSlots, then we will release
    lock of old buffer and will take care at the caller of
    MultiPageReserveTransSlot.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 47caeb3fc22cea153207c2cff90095aa89dd82c3
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-04-01 14:17:50 +0530

    Avoid fetching transaction id unless required.

    Suggested by Robert Haas.

commit c58a1e4cab7906693381538ff743e3a30ad550c3
Author: Mahendra Singh Thalor <mahi6run@gmail.com>
Date:   2019-04-01 11:11:27 +0530

    Fixed warning of assert used variable

    In ValidateTuplesXact, xid variable is only used in assert.

    Patch by Mahendra Singh Thalor

commit 24356d84cc80a503bd8f097045b45e661dc3d1ca
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-29 17:24:13 -0400

    Refactor ZHeapTupleSatisfiesMVCC/ZHeapTupleSatisfiesSelf.

    As it turns out, the ZHeapSelectVersion function introduced in
    commit fb8cd5c33a0117730cdf3b1af76066a2a1480a19 implements precisely
    the same set of rules as ZHeapTupleSatisfiesMVCC in the case of an
    MVCC snapshot, and precisely the same set of rules as
    ZHeapTupleSatisfiesSelf for a non-MVCC snapshot.

    To avoid code duplication, this commit consolidates three sets of
    visibility rules into two.  Before this, we had one copy of the
    SnapshotMVCC rules, one copy of the SnapshotSelf rules, and a third
    set of rules that was a combination of the two.  Now the combined copy
    is gone, so we just have one copy of each set of rules.

    It is unclear why the places that now rely on ZHeapSelectVersionMVCC
    and ZHeapSelectVersionSelf -- and which before today had their own
    copies of these rules -- treat all non-MVCC snapshots in the same
    manner.  Add some comments encouraging further study of that
    question.

commit f953ddea23100efc7592037eda3c245d238e23a4
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-29 16:46:46 -0400

    Add and use new function ZHeapTidOpFromInfomask.

    This function figures out what kind of operation was last performed
    on a ZHeapTuple by examining the infomask.  Allows removal of a
    little bit of duplicated code.

commit 2385c627b1f6cf70408f616c17e35b6765ddeb97
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-29 16:10:25 -0400

    Adjust ZHeapTupleSatisfiesMVCC to rely less on fetch_cid.

    This increases the degree to which this code is similar to other code
    that does similar things.

commit 7bb8607bb1a64c5786e705055a82819fb6aa620d
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-29 13:53:35 -0400

    Factor duplicate code into new function ZHeapSelectVersion.

    The previous commit resulted in identical chunks of code in
    GetVisibleTupleIfAny and GetTupleFromUndo.

    Put that code in a new function and call it in both places,
    instead of duplicating the logic.

commit 725c888e335007ddc06e16df2cb3d3fa26aaa485
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-29 13:09:01 -0400

    Use ZVersionSelector in more places.

    This commit adjusts GetTupleFromUndo, GetVisibleTupleIfAny,
    UndoTupleSatisfiesUpdate, and ZHeapGetVisibleTuple to use
    ZVersionSelector.  This saves some code by itself, and also opens
    up further refactoring possibilities.

commit 8d2c2eb24c4c6d9169bda6061ac84b5961d8a1d0
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-29 12:49:32 -0400

    Revise GetTransactionSlotInfo to use ZHeapTupleTransInfo.

commit 16313bdae94cdd13f93d40dac67bb0a1feb244af
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-28 11:24:00 +0530

    Add pgbench tap tests for zheap

    These test increase the coverage of access/undo (ln: 70%, fn: 78.6%)
    and access/zheap (ln: 50%, fn: 65%)

    Patch by Neha Sharma

commit 99196d2f67b88c29620c9f89c27ae52f8ab3f0fa
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-27 14:50:03 -0400

    Refactor GetTupleFromUndo to not use 'goto'.

commit d2a50b89b57e90c7d32e91db96af2aeb6c2a0f5a
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-27 13:44:25 -0400

    Introduce ZVersionSelector to reduce code duplication.

    The ZHeapTupleSatisfies* functions in zheapam_visbility.c basically
    all do one of three things: return NULL, return the tuple passed
    to them, or hand the request off to GetTupleFromUndo().  Instead
    of repeating the GetTupleFromUndo() call in many places, set an
    enum variable to indicate which of those three things we're going
    to do, and then take the appropriate action at the end of the
    function based on the value of the enum.

    I think there's more that can be done here to further reduce
    code duplication and organize things more logically, but even
    doing this much helps a little.

commit 4011369f5b41aa5e4602aa9d5a3b8abadea8e016
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-27 09:10:31 -0400

    Return a struct from ZHeapTupleGetTransInfo.

    Large numbers of individual out parameters are difficult to
    maintain. For example, adding a new one requires updating many
    call sites; and renaming one risks inconsistencies between the
    parameter names and the variable names used in the caller.

    Use the same struct in ZHeapTupleSatisfiesUpdate.  Callers don't
    currently need all of the information contained in the structure,
    but since we are retrieving it anyway, there's no harm in
    returning the whole thing.

    The case of calling ZHeapTupleGetTransInfo solely to fetch the
    XID that last touched the tuple seems to be quite common, so
    provide a convenience function that does that and use it wherever
    it makes sense.

commit a447f2667c53f93ae6a4dce51f43a80d7a7d9b37
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-03-27 16:02:56 +0530

    Update README.md  add information about the test executed before
    pushing code.

commit 0cc7fb0ab64d7a759c53a19aceb77421694515c9
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-25 15:01:14 -0400

    Remove dead code.

commit c998699a7d17f3cb6bdb130cee1fe8f5b08727ba
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-03-25 16:01:16 +0530

    Remove dead code.

commit bb30241e7b3299028cc483f3947bafa7d9ac1757
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-22 15:02:30 -0400

    Rewrite tts_zheap_copy_heap_tuple.

    The old implementation was poor for reasons explained in the ZBORKED
    comment.

    Along the way, add a related assertion to
    tts_zheap_copy_minimal_tuple.

commit 4bfd066917147c6bb043abd8d93f8ec3e5e95cb6
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-22 10:13:53 -0400

    Remove dead code.

commit 29a58f1ea57a78279f5556765d4c9eb51147d8d2
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-22 09:00:12 -0400

    Code cleanup for ExecStoreZHeapTuple.

    No need to set slot->tts_nvalid = 0 here; tts_zheap_clear does it.
    Also make that function do zslot->off = 0 instead of doing it here,
    since presumably that should always happen when a slot is cleared.

commit 9bc6f37619b7f0336e55fb00ddfbd2db748208d7
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-22 08:51:48 -0400

    Remove obsolete reference to data_alignment GUC.

commit d222b3ca50338addd3a65ee5eca4f388a0fd0170
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-22 08:47:36 -0400

    Rename ExecStoreZTuple to ExecStoreZHeapTuple.

    Also, remove the used 'Buffer buffer' argument.  This makes things
    more consistent with ExecStoreHeapTuple.

commit d1f8994685389198f39c22f444d944ac9aa75e03
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-22 08:30:50 -0400

    Move TTSOpsZHeapTuple to top of file, rather than middle.

commit bca783c5fdbeda39e84ebec13873108cc97be479
Author: Robert Haas <rhaas@postgresql.org>
Date:   2019-03-22 08:18:28 -0400

    Assorted cleanup, mostly cosmetic, for ztuple.c.

    Improve comments.  Add ZBORKED comments in a few places where it
    seems work is needed.  Remove some dead code.  Move some
    explanation that seems like it actually belongs in zpage.c to that
    file and improve the wording.  A few minor formatting tweaks.

commit 980fc33c8b72b0be8d608a2360dcb5410f2ed7ac
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-03-20 16:32:56 +0530

    Improve some debug messages

commit 8692bf9f495993de151be7620954995216c2bdf6
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-14 15:12:04 +0530

    Fix a bug in zheap_xlog_update

    During undo refactoring in commit 1f12b8ca, uur_rmid was wrongly set
    for undorecord instead of newundorecord.

commit 575c9beeea0dea8c05b0a49d3264c6c7e2c8ba40
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-13 14:08:45 +0530

    Run pgindent on new zheap files created in src/include

commit 62b51f563941d7edf9e0ded76d2417d437295ab1
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-13 14:08:45 +0530

    Run pgindent on new zheap files created in src/include

commit 632c86400e9fdc6eea585831a752c8b91e572dcc
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-13 13:57:02 +0530

    Run pgindent on zheap code in src/include pg files

commit 47ee91f8b5753b94d756d998348f005fbccd5906
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-13 13:56:25 +0530

    Run pgindent on zheap code in src/backend pg files

commit be2d2ef1dade66e512abc81f8c07cd7cfe1c8179
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-13 09:55:46 +0530

    Fix some typos

commit 6b9ec1385a00a85b866bcc9426d8eb91aee0d096
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-03-13 09:32:21 +0530

    Always perform rollback actions after cleaning up current (sub)transaction.

    Currently, for error Rollbacks or when the Rollback requests are pushed to
    the background worker, we perform the undo actions in a new transaction or
    in parent transaction (it happens in parent transaction when we get an
    error in sub-transactions).  We want the behavior to be the same for all cases
    namely (a) an error, (b) rollback request executed by background worker or
    (c) user-initiated rollback (to savepoint).

    There are quite a few reasons to make the behavior consistent.  First one
    is that if we process the undo actions in the original transaction, then we
    might not get desired results for the scenario where we perform some
    actions (say inserts) on a table, then altered it's tablespace and then again
    performed few inserts.  We will be able to perform undo actions for the
    later inserts, but not the ones which were performed before Alter tablespace.
    The second case is that sometimes we hold some resources like buffer pins till
    the end of the transaction and when we try to perform rollback actions for
    operations where we have to forget some buffers (like drop relation files
    as part of rollback), it creates problems.  The third advantage is that we
    have fewer things to test.

    This commit fixes both of the above problems.

    One thing we have to be careful is that if we release locks before applying
    undo actions, then the parallel session can acquire the lock before us
    which can lead to deadlock and or possibly can start applying the actions by
    itself.  So we release locks only after applying undo actions.

    Amit Kapila, some review and testing by Dilip Kumar

commit c79eba02208fb0e271e00f596ce78b2ea3b76caf
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-13 09:12:02 +0530

    Update Copyright date in zheap files to 2019

commit a1fb84c982738b967941c47fc0df60b394c81423
Author: mahendra <mahi6run@gmail.com>
Date:   2019-03-13 09:04:03 +0530

    Fixed wrong check in zheap_exec_pending_rollback

    In zheap_exec_pending_rollback, if slot was last page slot and page
    haven't tpd, then we were not applying rollback that was wrong so
    fixed this.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 3799b772c278110c398bd128c23959492afd3a07
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-03-12 17:40:18 +0530

    undo code refactoring.

    Move zheap related code out from the undo directory.

    Dilip Kumar reviewed by Amit Kapila

commit 0340d327aaf098932b50dcbb81ee1a52c73c9c57
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-03-12 15:55:09 +0530

    Refactor and improve comments around zheap_insert functionality.

    In the passing, fix the case where we were WAL logging undo information
    during insert even when we don't insert any Undo.

    Amit Kapila, bug fixes by Dilip Kumar, some suggestions by Robert Haas.

commit 867592aed08635aec1fb1a814d86fe3dc2780074
Author: mahendra <mahi6run@gmail.com>
Date:   2019-03-12 08:50:05 +0530

    Fixed wrong check in zheap_lock_tuple_guts

    In zheap_lock_tuple_guts, if tuple has multilocker and LockForUpdate,
    then we should not set xlrec.flag as XLZ_LOCK_FOR_UPDATE.
    Due to this wrong check, we were getting "inconsistent page found"
    FATAL during replay.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila and
    Dilip Kumar

commit 5cbf9001dca7cb82e150fa68cb1072cd3446427a
Author: mahendra <mahi6run@gmail.com>
Date:   2019-03-11 10:57:05 +0530

    Fixed bug in RestoreXactFromUndoRecord

    In RestoreXactFromUndoRecord, we were not updating is_tpd_map_updated
    flag due to wrong check.  So we were not logging tpd map in rollback
    and this caused "inconsistent page found" during replay.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila and
    Dilip Kumar

commit fa59db5b7b1d0a2abee03ba7511f72b9e581c452
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-11 10:52:34 +0530

    Run pgindent and spellcheck on zheap files in src/include

commit 1ee9f7520cfa20d6b6c47abb9ce766da5950ab3a
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2019-03-07 20:49:50 -0800

    Fix regression caused by refactoring work db9903a

    For an invalid vmbuffer it's vm bit status should be read as
    cleared.

commit 8a0f160b0cd1a601c7898eeb1ce33c1f7b2881b0
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-08 09:10:43 +0530

    pgindent run on access/zheap folder

commit 0ff16a54e87c86e57f9d2afddf8184feb0a7fac6
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-08 08:44:41 +0530

    Run pgindent on zvacuumlazy.c

commit f3963d33d1c63741d3f458a907474d2956e45940
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-07 19:03:43 +0530

    Run pgindent on zmultilocker.c

commit 58d3ef7e22fef9764760030ca94ebdd5abf18dc8
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-07 18:52:58 +0530

    Run pgindent on zheapxlog.c

commit 4ea3fadd50033da58b29f3d8f7341c7fe8e30ee8
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-07 18:39:48 +0530

    Run pgindent on prunezheap

commit 7d9d2518f3ac52bfea83c99ad543fc56b70b254b
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-07 18:31:42 +0530

    Run pgindent on prunetpd.c

commit e5ecb698d5233055cd7e50f8c112b06377530933
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-07 18:22:53 +0530

    Run spellcheck and pgindent on zheapam.c

commit 0930d5d68416af3af2b8a38942b06775549b9300
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-07 16:56:50 +0530

    Bug fix in IndexBuildZHeapRangeScan

    The tuple was not freed during the scan and hence the memory
    was accumulating, causing an OOM error.

    This commit converts the tuple scan code in IndexBuildZHeapRangeScan
    to slot API and also sets the sholdFree flag in ExecStoreZTuple to
    true when scan type is not rs_pageatatime.

    patch by me, review by Kuntal Ghosh and Amit Kapila

commit 5cfa66507e12f996c25db8d346dc7b0c7e779a7b
Author: mahendra <mahi6run@gmail.com>
Date:   2019-03-07 15:59:46 +0530

    Fix assert of TPD slot

    In zheap_search_buffer, we were reading tuple from undo and trying
    to lock tid.
    To fetch the xmin (aka transaction that has inserted the tuple), we
    need to use the transaction slot of the tuple in the page instead of
    the tuple from undo, otherwise, it might traverse the wrong chain.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit caaf5b1d7ec76dc2bcf2c8c47b3d4306ecc2bbf3
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-07 15:52:13 +0530

    Run pgindent on zheapam_visibility.c

commit 17081eba08f6fdd091e063452935212d70ed981d
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-07 15:28:58 +0530

    Run pgindent for tpd.c

commit e51eabcf1ac6034fee757755dc55e44ad94ab932
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-03-05 00:19:42 +0530

    Fix xact for lock-for-update v1

    For lock-for-update undo records, we should restore the previous
    transaction slot during rollback. Also, while fetching transaction
    information for a tuple, we should not skip lock-for-update undo
    records.

    Patch by me. Reviewed by Amit Kapila.

commit a900ec437c05bdfcf8cc9ab27ac3adeeb87ded50
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-03-05 00:53:14 +0530

    Bugfix in ValidateTuplesXact

    In ValidateTuplesXact, when we fetch the xact info for a tuple, we
    should call ZHeapTupleGetTransInfo. Because, the tuple may have
    invalid xact flag in which case we need to change undo chain to
    fetch the correct xact info.

    Patch by me. Reviewed by Amit Kapila.

commit c24e3018da3d9260b360596fd0e713442249c304
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-03-05 14:17:06 +0530

    Fix small bug in FetchTransInfoFromUndo

    In FetchTransInfoFromUndo, we can't skip the undo for lock-for-update
    operation while fetching the xact info. The lock-for-update operation
    sets transaction slot on the tuple.

    Patch by me. Reviewed by Amit Kapila.

commit fad7983940f21f96caa2a359f357714f7f2611a5
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-03-07 11:13:21 +0530

    Rename ZHEAP_XACT_SLOT_MASK as ZHEAP_XACT_SLOT_SHIFT

    This macro is used to fetch tuple xact slot by shifting the infomask2.
    Hence, it should be named accordingly.

    Suggested by Robert Haas.

commit c3c0ffd0d5ec70f24ddcd0ab7a595619ce246739
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-11 23:10:46 -0700

    Run pgindent on zheapam_handler.c

commit 0331c1ac224dba9a863bb7441c6250af66c58858
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-07 10:21:15 +0530

    Run spellcheck in src/backend/access/zheap folder

commit a19bb8f70bee8129fedd6d51bae8ab4cbaad9101
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-03-07 09:57:04 +0530

    Correct a condition in ZHeapTupleGetTransInfo

    The check to ensure xid is valid when checking if xid is in the MVCC
    Snapshot was missing.

    Patch by me, reviewed by Kuntal Ghosh and Amit Kapila

commit bddb328d6c8eaa8958c8917b4f66332629afee4d
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-03-04 09:17:30 +0530

    Fix compute_new_xid_infomask

    If the tuple has multilocker and we're locking the tuple in
    LockForUpdate mode, we keep the tuple transaction slot as it is.
    If we set multilocker flag while locking the tuple, we keep the
    old transaction slot as it is.

commit a40773622950f1e6b01b3c10ab85241ce38eab43
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-03-05 00:45:07 +0530

    Fix zheap_exec_pending_rollback when TPD entry got pruned away

    If the TPD entry got pruned away, rollback must have been performed
    by some other backend or undo-woker. In that case, we don't have to
    perform undo actions.

commit edfa6c78372be9efed77ec9a34e906ec121ec406
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-03-05 09:09:36 +0530

    Small bug fix in FetchTransInfoFromUndo

commit 7ce458aa8ce19c2000b87148b4e1a39bdabe8685
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-03-07 09:22:19 +0530

    Improve comments in zheap_insert.

    In passing, add BufferIsValid check at one of the missing places.

commit 0d2bd917cc3e8446970944972d697d6c616360c2
Author: mahendra <mahi6run@gmail.com>
Date:   2019-02-28 23:20:27 +0530

    Fix unused function warning

    Patch by Mahendra Singh Thalor

commit 333ba3464701e292fac08af4e5d61b697f3609dc
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-02-28 15:49:40 +0530

    Add undo type definitions to pgindent/typedefs.list

    Dilip Kumar

commit 0dc8530a5f134eff5f7099bb81bffb2742652c9b
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-02-28 15:19:48 +0530

    Refactor undoaction.c file

    Dilip Kumar reviewed by Amit Kapila

commit f78fbe74f1510bf4a6d75a773f8ee8732123f2bd
Author: mahendra <mahi6run@gmail.com>
Date:   2019-02-27 12:05:19 +0530

    Fix "could not read block" error

    In ExtendTPDEntry, we are calling TPDPagePrune with can_free as
    false.  If TPDPagePrune make TPD page fully empty then we are not
    removing that page from meta list to avoid deadlock. And we are not
    extending our TPD entry in that page due to empty page.
    At vacuum time, we are removing only non-empty pages from meta list.
    But it is possible that empty TPD page yet not removed from meta list
    and we truncated that page.
    To allocate new TPD page, first we check that last used TPD page
    have enough space or not.  If that empty TPD page is the last used
    TPD page, then we can't read that page because page is already truncated
    but not removed from meta list.
    So fixed this problem by removing empty TPD page from meta list at
    vacuum time if yet not removed.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 6045aecd71b626ebc665c08fac19a431d64e1715
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-02-26 16:24:41 +0530

    Move the undo processing related API's to a new file zundo.c.

    This helps us to better segregate the undo processing related code in one
    file.

    Suggested by Robert Haas, patch by Amit Kapila

commit 22d589fb053d26631f81d35a8010a23f6472c70d
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-11 22:55:32 -0700

    pgindent zheapam.c and zheap.h.

commit 2e9be8512c957f452a68cfc6592eb518d80f3348
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-02-25 17:30:08 +0530

    Move more tuple related API's to ztuple.c.

commit 24810182cce9309347411e04a59fbae398207224
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-02-25 16:53:46 +0530

    Move the tuple manipulation related API's to a new file ztuple.c.

    This helps us to better segregate the tuple manipulation related code in
    one file.

    Suggested by Robert Haas, patch by Amit Kapila

commit eaee0308f5c3386688959659b416caf44b2d1247
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-02-25 15:26:25 +0530

    Move the scan related API's to a new file zscan.c.

    This helps us to better segregate the scan related code in one file.

    Suggested by Robert Haas, patch by Amit Kapila

commit 7d26a7536a8e5eaee50e247e3ad61c0f237ba3c7
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-02-25 15:04:58 +0530

    Remove spurious white-space added by commit 363e466304.

commit 83954fd2c10ed1b784a2bba8deb8d5752a34ad80
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-02-25 09:55:47 +0530

    Move the page related API's to a new file zpage.c.

    This helps us to better segregate the page related code in one file.  In
    the passing, moved zheap_mask function zheapamxlog.c.

    Suggested by Robert Haas, patch by Amit Kapila

commit 2da9f5bbae8dea8c090713b5ec834bece8b3c221
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-02-20 16:33:39 +0530

    Fix a bug while fetching xact info for a tuple

    When a tuple is marked with invalid xact flag, we should skip lockers
    while fetching the xact info from undo records.

    Patch by me. Reviewed by Amit Kapila.

commit 82b446940203cb1eced4cb7ac1258081160916cc
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-02-20 16:36:31 +0530

    Fix a bug in compute_new_xid_infomask

    When we compute infomask while updating a tuple, we should keep the
    strongest lock mode on the tuple.

commit bb42a7793b03ea83ca9aea849917be09aed58fe7
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2019-02-21 14:22:50 +0530

    pg_stats: Fix the dead tuple count

    Update counters were revised to store counts of both inplace and
    non-inplace updates in 122eef23ca but the dead tuple calculation
    was not adjusted to exclude inplace updates which do not generate
    dead tuples and this triggered vacuum frequently.

    This commit adds new counters for inplace updates and modifies the
    calculation of dead tuples to:
         dead tuples = updates - inplace updates + delete

    Reusing the hot_update counter does not work because calculation of
    dead tuples is done at transaction level and hot_update
    counter is a non-transactional table level counter.

    Patch by me, reviewed by Amit Kapila

commit c269390d0df50522dd7f26729f6ef5bec7ff7c9f
Author: mahendra <mahi6run@gmail.com>
Date:   2019-02-19 19:51:54 +0530

    Bug fix in ZHeapTupleHasSerializableConflictOut

    In ZHeapTupleHasSerializableConflictOut, if tuple is non in-place
    updated and slot is frozen and if tuple is live, then xid will be
    zero.  So that tuple will be all visible and there is no need to
    call XidIsConcurrent to check visibility.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit dc8a657806b932efed6dd33b57b86eaf898932d5
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-02-19 14:26:23 +0530

    Fix undo record test case compilation error.

    Dilip kumar Reported by Amit Kapila.

commit 329cece5d26cfad3679a577dabf93fbcca5404aa
Author: mahendra <mahi6run@gmail.com>
Date:   2019-02-18 17:55:22 +0530

    Fixed assert failure in zheap_lock_updated_tuple

    Dead tuple has length 0 so we can not copy tuple
    and we can not lock dead tuples so fixed this.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila,
    idea by Kuntal Ghosh

commit afbc7ef7dff93c4401c9b186cee6fa48ac452738
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-02-15 09:33:57 +0530

    Fix rs_numblocks in zheapgettup apis

commit 8da3dddb853b9dfa32358352830ee5425a87827f
Author: mahendra <mahi6run@gmail.com>
Date:   2019-02-14 15:24:54 +0530

    Fix compilation warning for unused varibale

    In MultiPageReserveTransSlot, we are using one varibale only in
    assert, so if we configure with assert disable option, we were
    getting warning. So this patch will fix.

    Patch by Mahendra Singh Thalor, reported by
    https://github.com/EnterpriseDB/zheap/commit/0d3d4894fce9d5e49663f412fa9028fc3f157ff0#commitcomment-32315321

commit 38e4b62c7aa850e8a3b21a44195b4b8a4f3de867
Author: mahendra <mahi6run@gmail.com>
Date:   2019-02-13 16:10:53 +0530

    Silence spurious compiler warning

    In UndoRecordUpdateTransInfo and InsertPreparedUndo, without
    initializing Page varibale, we were using so fix will silence
    the compiler.

    Patch by Mahendra Singh Thalor

commit bee1b3bd53bf997a8453a6b7ca9f4f912b496b9c
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-02-13 15:29:41 +0530

    Keep the meta page while truncating a zheap relation

    When we truncate a zheap relation, there is no point of truncating the
    meta page since we create the meta page immediately after that. We can
    just re-initialize the meta page after truncation.

commit dc59f55f2718c6f4884efc5fdc36e7a8a72e97fe
Author: mahendra <mahi6run@gmail.com>
Date:   2019-02-13 15:49:35 +0530

    Added optimization to reserve slot for non in-place update

    In MultiPageReserveTransSlot, if old buffer has TPD entry, then
    every time we were trying to lock buffer in lower block order.
    But if previous reserved slot for old buffer is non TPD slot and
    not last slot then we should not consider TPD buffer order because
    we will never lock old buffer TPD block.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 807fa4f4c9b01ae26ae70f99b302024e537e77e2
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-02-13 13:48:58 +0530

    Fix handling for partial undo record in case of BLK_NOTFOUND

    If undo record is spread in more than 1 pages and for the first
    page we get action as BLK_NOTFOUND then the inserting partial
    record in the next page was not handled properly.

    Dilip Kumar reviewed by Amit Kapila

commit 890bcfb425c523db935d255fb79562e31f29bc7a
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-02-13 11:54:53 +0530

    Bug fix in zheap prune

    After creating temp copy of page tuple are getting modified and
    because of this while copying tuple from temp copy we were getting
    older tuple.

    Dilip Kumar reviewed by Amit Kapila

commit 20731103dda36a79f6d7cfa3a5ba5b9424ba9d38
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-11 22:12:35 -0700

    Refactor the code to move block level vacuum files in common header.

    This allows us to move the vacuum related functionality common heap and
    zheap into a single file.

    Reported by Andres Freund.

commit 7f75f53306d286a644150788490195fd27c10e58
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-02-13 11:33:39 +0530

    Don't set TTS_FLAG_SLOW for zheap tuple

    In zheap, we don't use cached offsets. So, don't set the TTS_FLAG_SLOW
    flag in tuple slot.

commit 4d199de543c036bf46c3646fbefea192b10781ed
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-02-13 11:00:58 +0530

    Use topxact to decide which backend should wait for a speculative conflict

    When a speculative insertion conflict is detected among two in-progress
    transactions, one of the backends must back out first, and then wait,
    while the other one waits without backing out. It doesn't matter which one
    backs out, so we employ an arbitrary rule that the transaction
    with the higher top XID backs out.
    We've used top XID to make the api generic across different storage
    engines. For example, heap stores current xact as xmin and
    xmax unlike zheap which always use top xact.

    Reported by Andres Freund. Patch by me. Reviewed by Amit Kapila.

commit bcc5b4f76227cc717d57ce4542292eaa8cdf9614
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-02-13 09:15:40 +0530

    Rename ztqual.c to zheapam_visibility.c for compatability with heap.

commit a924dce17f4f4cd179e8729087316b2d3b9f6b63
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-11 21:48:15 -0700

    Move some functions from zheapam_handler.c to zheapam.c.

    The functions moved have core zheap specific stuff, so moved them to
    zheapam.c.

commit b1621e2f7e5f411323c061884833ef71eb05e29d
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-02-12 17:15:25 +0530

    Add comments in zheapam_relation_copy_data

    In zheapam_relation_copy_data, we use copy_zrelation_data for
    MAIN_FORKNUM and RelationCopyStorage for other forks. In this commit,
    we've added some comments to explain this behavior. This commit also
    removes some redundant checks for init forks in copy_zrelation_data.

commit 101047277c5ded94fcbf270c0045781a7cf0ab92
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-02-12 08:10:01 +0530

    Move zheap specific function from common header.

commit 8c610fc5af42a4a15e30229af260fe0f8fdfd5ab
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-02-11 17:48:00 +0530

    Compiler warning fix.

commit 199ff25587e25a584cc3555d921fd37eda64fd89
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2019-02-11 17:33:00 +0530

    Remove unnecessary includes from execTuples.c

commit 20fad7d3e10c27716a1a8cd6ba9cdf290d44624a
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-11 21:43:15 -0700

    Refactor code to remove zheap specific code from tuptable.h

    This is done to ensure that zheap specific API's shouldn't be exposed to
    the entire system.  This is a good abstraction as if anyone wants to use
    zheap specific API's, they should use via tableAM specific API.

commit cc79283550571688d04bbc22106777d38b2cfc14
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-11 21:28:33 -0700

    Fix the usage of specToken in speculative insertion.

    There is no advantage in using global variable when the value can be
    passed.

commit fb668612af4d127384d053c06b7f913b0e5cc460
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-02-06 09:21:05 +0530

    Fix a bug in compute_new_xid_infomask

    There can be a non-conflicting key share locker on the tuple and we want to
    update the tuple in no-key exclusive mode.  In that case, we should set the
    multilocker flag as well.

    Patch by me. Reviewed by Amit Kapila.

commit bc181e8f495c4e36c87545430ef94608c7b222f6
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-02-08 11:19:50 +0530

    Fix an assert in execute_undo_actions_page

    Patch by me. Reviewed by Amit Kapila.

commit be1706065e5c7beb685a1b89a51a5081fafc92b1
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-02-08 12:01:34 +0530

    Fix some bugs in copy_zrelation_data

    1. After performing undo actions on a zheap page, skip writing the
    corresponding the TPD buffer if it will be written in future.
    2. Remove PageIsVerified check since it's already done in ReadBuffer.

    Patch by me. Reviewed by Amit Kapila.

commit d28ae775ee3e93d08519b5322bfc3b353aa084f3
Author: mahendra <mahi6run@gmail.com>
Date:   2019-02-08 11:44:21 +0530

    Added check in TPDPageIsValid for TPD entry header verification

    In TPDPageIsValid, to avoid deadlock, sometime we were reading TPD
    entry header without taking lock on buffer. It is possible that
    other backend was extending other TPD entry and re-arranging all
    TPD entries.
    Due to re-arrangement, sometime we were getting wrong TPD entry
    so added check to read TPD entry only in lock.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 8c1d37d94ddbe82f9152f18aa28df3ac47e744d9
Author: mahendra <mahi6run@gmail.com>
Date:   2019-02-08 09:51:20 +0530

    Changed "Max TPD entry size" warning to Error

    Currently, we are not supporting multiple pages for TPD
    entry so it is better to report error instead warning
    for "Max TPD entry size".

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit a4fe58fe921656d71ab3c70dbd6717e894120e65
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-31 18:49:23 +0530

    Fix a bug in table sample scan

    In zheap_scan_sample_next_block, when a zheap relation doesn't contain
    any pages except the meta page, we should return from the function.

    Patch by me. Reviewed by Amit Kapila.

commit 9ec92841006335891c642a21e93e48cbfbad726e
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-11 21:21:28 -0700

    Fix Zorked comments by Andres.

    The fixes include changing Asserts, comments and confirming if the
    fixes done are correct.

commit 21069d0f627249143b7fc306c58937f0dda65599
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-02-06 14:09:46 +0530

    Merge review comment fix from undo worker and rollback patch

    Dilip Kumar reviewed by Amit Kapila

commit f8a0a1ee4f813410b64bbe6075c74b53dd1734e9
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-02-04 22:23:35 +0530

    Handling BLK_NOTFOUND for undo page

    During recovery if FPW is disabled then we might need to handle
    BLK_NOTFOUND for the undo pages.

    Dilip Kumar reviewed by Amit Kpila

commit 731afdcee613042ea5e5db56d71a91ec68d44a3a
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-31 18:34:58 +0530

    In TableSampleScan, dont use rs_cindex from scan state

    Patch by me. Reviewed by Amit Kapila.

commit 3f78d2bcf4a63e81f12ac473fab90ed5f3ad6231
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-31 19:08:03 +0530

    In ZHeapPageGetCtid, handle multilocker undo records

    When a tuple is updated, it can be locked in key share mode by a
    concurrent locker. If the locker reserves the same slot id as the
    updater's xid, the latest undo pointer in the slot will refer to
    the locker's undo record. In that case, we should fetch the prior undo
    record to get the updater's info.

    Patch by me. Reviewed by Amit Kapila.

commit 76f8bca8484905e31e035c1566394b2484e59b65
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2019-01-31 04:25:07 -0800

    Silence spurious compiler warning.

    Variables are initialized and used under specific condition, but the
    compiler is able not see it. The fix will silence the compiler.

    By Mithun reported by
    https://github.com/EnterpriseDB/zheap/commit/a219461eaf1bffb93fdc2e99c7657371ba1cb19a#commitcomment-32130495

commit 39efe19f3adf9a04b9ab29f7bad6ff64b01238a1
Author: mahendra <mahi6run@gmail.com>
Date:   2019-01-31 12:52:17 +0530

    Prevent deadlock in pruning of TPD page

    Patch by Mahendra Singh Thalor, idea, edited and reviewd by
    Amit Kapila.

commit 563e42f508e78c1811a8b8c3b71f53e6e80d2c36
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-30 17:02:29 +0530

    Fix a minor typo

commit 08523c92849b7b3a6fefe0bfaf302bdccc946769
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-30 16:57:46 +0530

    Add order by caluse to some test cases in zheap.sql

commit 2ddcc68c9fc7c70b3f5fac859652aa1715112f20
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-11 21:12:55 -0700

    Perform undo actions for SPI rollbacks

    For SPI rollbacks, we've to perform the undo actions. If the transaction
    state is in progress, we perform the undo action before aborting the
    transaction. Else, we save the undo record pointers so that it can be
    rolled back later.

    Patch by me. Reviewed by Amit Kapila and Dilip Kumar. Test case added by Neha
    Sharma.

commit b0a0c0236a9b4dc8c56e915e8b88c9275c101260
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-01-30 16:00:27 +0530

    Bug fix in zheapam_lock_tuple

    The function is returning HeapTupleSelfUpdated without setting
    hufd->cmax, so attached patch set valid tuple cid.

    Dilip Kumar reviewed by Amit Kapila

commit a2dce5a8e3c28a468708c179b9420ccad4708862
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-01-30 10:32:39 +0530

    Bug fix in execute undo action while setting TPD offset map slot

    While setting the tpd offset map slot during rollback we must
    ensure that the TPD entry exist otherwise mark the slot frozen.

    Dilip Kumar reviewed by Amit Kapila

commit 9462c0785b21ba601f32ee536f615739f7efd5f9
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-01-30 10:25:52 +0530

    Avoid fetching transaction information from undo in some cases

    We can avoid fetching the transaction information from the undo even
    if the the slot is reused by another transaction if the slot's current
    xid is all-visible, then the xid prior to it must be all visible.
    The other case where we can avoid it when the current xid is visible
    to the snapshot for similar reasoning.

    Dilip Kumar and Kuntal Ghosh reviewed by Amit Kapila

commit 22d308ecc4250b73fc1ab7958c005ca494eaee73
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-23 22:08:47 +0530

    Clean TPD location only if zheap buffer is ex-locked

    When a TPD entry is pruned away there is an oppertunity to clean the TPD
    location from the corresponding zheap buffer. But, in that case, we
    should hold an exclusive lock on the zheap buffer.

    Patch by me. Reviewed by Amit Kapila.

commit e2b4f51c967a3d1ddf41bf8c2f55a11013d9454c
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-23 16:04:38 +0530

    Refetch tuple after reacquiring buffer lock

    There are few places in zheap_lock_tuple and zheap_lock_updated_tuple
    where we release the buffer lock and reacquire the same. In that case we
    should refetch the tuple. Otherwise, the tuple won't contain the correct
    transaction slot or related transaction flags.

    Patch by me. Reviewed by Amit Kapila.

commit f5ded49e416ce58701d3be5debdfe5ba1717a702
Author: mahendra <mahi6run@gmail.com>
Date:   2019-01-23 15:22:50 +0530

    Fixed assert in ValidateTuplesXact

    In zheapam_lock_tuple, we missed to pass true to ValidateTuplesXact
    for nobuflock argument, so that without taking buffer lock, we were
    validating so fixed this by passing flag true so based on this flag
    inside ValidateTuplesXact, we will take lock.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila.

commit d7cfca1708ee2432847131f360e7f562d1ff2555
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-22 12:06:18 +0530

    Fix fetching tuple from page

    When we use memcpy to copy an attribute from the page to datum field, we
    should use fetch_att to set the other uninitialized bytes in datum
    field as zero.

    Discussed by Amit Kapila, Andres Freund, Dilip Kumar and myself
    Patch by me. Reviewed by Amit Kapila.

commit 2ce1e26d73b072716bc29551d7d0e1d91524ca1f
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-22 11:56:22 +0530

    Use top transaction id for creating speculative insertion lock tag

    For creative speculative lock tag, use top transaction id to make it generic
    across different storage engine. Since, zheap always use top transaction id while
    modifying the tuple, it'll be easier to fetch the same from the tuple. When
    encountering a conflict, we should use SubTransGetTopmostTransaction() to
    determine the xid on which we should wait.

    Discussed by Amit Kapila, Andres Freund, Dilip Kumar and myself.
    Patch by me. Reviewed by Amit Kapila.

commit b513bd480d6411f8f7ac1f451978ea2d7c6a6e7c
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-22 10:30:22 +0530

    Set TPD slot info correctly for LockForUpdate mode

    For lockers, we only set the slot on tuple when the lock mode is
    LockForUpdate and the tuple doesn't have multilocker flag. In that
    case, pass set_tpd_map_slot as true, flase otherwise.

    Patch by me. Reviewed by Amit Kapila.

commit 6724af83619636d4dbf5197adbd7838f3e4bd0d8
Author: mahendra <mahi6run@gmail.com>
Date:   2019-01-18 12:45:46 +0530

    Prevent deadlocks while acquiring lock on TPD page.

    To prevent deadlock risks, we always need to ensure that lower
    numbered TPD block is locked first. This is generally followed
    in all the places in code, but we missed to do it while acquiring
    lock on TPD page during non-in-place update.

    Patch by Mahendra Singh Thalor, reviewed and edited by Amit Kapila

commit 1bae93fbd5e1e2a45d89fbd48d15a6d9995eadb6
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-11 21:05:21 -0700

    Make changes in lazy_scan_zheap related to page initialization

    In an earlier commit 'Move page initialization from RelationAddExtraBlocks()
    to use', Andres has made some changes in lazy_scan_heap(). We should do
    the similar changes in lazy_scan_zheap().

    Patch by me. Reviewed by Amit Kapila.

commit ddca0ce25f3ad51077e4ebd801890c2aa1638592
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-16 11:20:14 +0530

    Fix a buffer locking issue in zheap_lock_updated_tuple

    In zheap_lock_updated_tuple, when we lock the tuple, we've to reserve
    one transaction slot in the page. During page reserve, if we've
    reaquired the lock, we've to check the tuple status again. In that case
    we should unlock the buffer before locking it again.

    Patch by me. Reviewed by Amit Kapila.

commit ad072514d388112fdf5524f1e300942d652c7d00
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-14 17:05:39 +0530

    Initialize t_self for deleted item pointers in zheap_lock_tuple

    When an item pointer is deleted, we return HeapTupleUpdated from
    zheap_lock_tuple. But, we should also initialize t_self so that can
    be used in zheapam_lock_tuple to decide whether the tuple is deleted.

    Patch by me. Reviewed by Amit Kapila.

commit 28f4a8ea8e5049431c350eec566b37cb2033e9f1
Author: mahendra <mahi6run@gmail.com>
Date:   2019-01-17 11:07:23 +0530

    Avoid deadlock among heap and TPD buffers

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 2979f5ffc33ae4eb5361523ce77ae53b20d7b193
Author: mahendra <mahi6run@gmail.com>
Date:   2019-01-17 09:50:25 +0530

    Fix crash in zheapam_scan_analyze_next_tuple in freeing tuple

    In zheapam_scan_analyze_next_tuple, if we fetch tuple from undo,
    then we have to free old tuple, but by mistake, we were not
    allocating memory for tuple and trying to free multiple times.
    So fixed crash by allocating new memory for tuple.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit 12e1df2690fe9c7b96dd8096c6cda9f1d58810b9
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-01-14 17:51:57 +0530

    Bug fix in undo apply worker

    Currently, undo launcher is acuiring a lock on database before launching
    undo worker and that creates deadlock if concurrently backend tries to
    drop the database.  Now, for handling this, launcher is just checking whether
    dbid is exist or not if it does not exist it will remove all undo actions
    for the db from the rollback hash table.

    Rafia Sabih reviewed by Dilip Kumar and Amit Kapila

commit 865139d97fc00f818deffccd6c7e3a50139ed793
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-13 23:04:37 +0530

    Fix a regression test for rowsecurity

commit 806075de47d9e3d77e7034600fe7a729da11b07f
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-13 22:19:34 +0530

    Fix an assert in zheap_update

commit 3d7b04cfc4d3bdebde9ddb68f29b3bbdee32d8c6
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-10 16:13:53 +0530

    Optimize zheap_update performance for write heavy but small workloads

    If we've reused a slot or allocated a slot in TPD page, we've some contention
    on the page. Hence, we perform non-inplace updates to other buffer to distribute
    the tuple across pages. But, we should have a hard limit for the optimization,
    else the number of blocks will be increasing.

commit 399e0d06176d57f55f75ed2ea2b56093d0f2bf36
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-11 16:40:49 +0530

    Fix tuple slot for LockForUpdate

    When we've to lock the tuple before updating it, we take LockForUpdate
    lock on the tuple. In that case, we also set the current transaction
    slot on the tuple. This avoids the requirement of marking the tuple with
    multilocker flag when previous updater/inserter is not all-visible. But
    when
    the tuple already has a multilocker flag, we should maintain the old
    transaction slot.
    In the above case, when the tuple has to be marked with multilocker
    flag, we should propagate the updaters information as well. Otherwise
    the tuple is marked with locked-only flag and current transaction slot
    is set. So, there is no need to propagate the updaters information.
    This patch also fixes the previous tuple xid that'll be stored in undo
    record for ZHEAP_UPDATE.

    Patch by Amit Kapila and Kuntal Ghosh

commit ad66c42839b716f9ff76b52c2d3a7518b656dd82
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-11 13:36:16 +0530

    Modified few regression test case files

    Modified select queries in .sql files with 'ORDER BY' to
    match heap and zheap output files and removed extra files.

commit 2f4d8749430cab7e89da2694bf626d6be80464e2
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-10 13:24:50 +0530

    Before computing infomask, clear multilocker flag if possible

    When we lock/update/delete a tuple, we've to calculate the new infomask
    from the old one. Before calculating the new infomask, we can clear the
    mutilocker flag from old infomask if no lockers are alive.

    Patch by me. Reviewed by Amit Kapila.

commit 822b7faf9d43e481f847046ae23fc52e11cea4c4
Author: mahendra <mahi6run@gmail.com>
Date:   2019-01-11 12:48:27 +0530

    Fix a assert failure during recovery

    The ItemIdSetUnusedExtended marks itemIds as UNUSED with transaction
    slot information. However, the ItemIdUnused is called later by the
    ZPageRepairFragmentation resetting this transaction slot information
    causing assert failure in recovery to get slot from TPD because in
    recovery, we are not setting slot for unused xlog.
    If unused_set flag is true, then we will not reset slot info so
    ignoring fetching slot info based on this flag. Because anyway if
    unused_set is set, then we will not re-evaluate.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit b90442e707f5fbca52c872bfcdb36b76300fc294
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2019-01-09 13:00:44 +0530

    In ZHeapTupleGetTransInfo, avoid checking tuple if itemid is deleted

    In ZHeapTupleGetTransInfo, if a tuple has multilocker flag, we've to
    fetch its transaction information in a different way. But, when the
    corresponding item id is marked as deleted, the tuple can't be marked
    with multilocker flag. Hence, we shouldn't access the tuple.

    Patch by me. Reviewed by Amit Kapila.

commit e7bd65ee787bf0a294aa6b42d2fa3e3e0514875b
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-01-09 18:08:54 +0530

    Review comment fix merge from undo interface patch on hackers

    Dilip Kumar Reviewed by Amit Kapila

commit b5840ad259f671909a3690476c8257a5f6ccf741
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-01-09 17:16:30 +0530

    Design change for handling multi-log transaction in undo.

    In current patch I have removed the concept of prevlogno in undo log meta.
    For addressing these issues related to multilog I have changed the
    design as below
    - Now, at 'DO' time we identify the log switch by identifying which
    log we are attached to before and after allocate. And, if the log is
    switched we write a WAL for the same and during recovery whenever
    this WAL is replayed we stored the undo record pointer of the
    transaction header (which is in the previous undo log) in
    UndoLogStateData and read it while allocating space the undo record
    and immediately reset it.

    - For handling the discard issue, along with updating the current
    transaction's start header in the previous undo log we also update the
    previous transaction's start header in the current log if we get
    assigned with the non-empty undo log.

    - For, identifying the previous undo record of the transaction during
    rollback (when undo log is switched), we store the transaction's last
    record's (in previous undo log) undo record pointer in the transaction
    header of the first undo record in the new undo log.

    Dilip Kumar reviewed by Amit Kapila

commit 33f626fedfc5ffb78f79224fe5688ae38998eb78
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-01-09 10:10:28 +0530

    Bug fix in the previous commit
    "Ignore vacuum transction id while calculating oldestxmin for discard"

    Add separate flag for ignoring autovacuum worker.

    Reported by Andres Freund patch by me

commit 578a42f323b1fa2d614e327cbc282e76bd4e6e35
Author: mahendra <mahi6run@gmail.com>
Date:   2019-01-08 17:36:49 +0530

    Avoid reusing aborted transaction slots in few cases.

    During non in-place updates, we can't reuse aborted transaction's
    slot for new block if it is smaller than old block.  This is because
    we want to preserve our rule "lock lower numbered block first.

    Patch by Mahendra Singh Thalor, based on idea by Amit Kapila who also
    reviewed this patch.

commit 87af310b6449c66f63c9cff83092d84b02d523d5
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2019-01-08 11:14:10 +0530

    Ignore vacuum transction id while calculating oldestxmin for discard

    Ignore vacuum transaction while computing the oldestxmin for discard,
    because we can discard undo for the vacuum transaction as soon as
    they are committed.  We don't need to hold it's undo for the visibility
    purpose.

    Dilip Kumar

commit ac7f7bdf30b24cdb0754abf7c490832600fdb514
Author: mahendra <mahi6run@gmail.com>
Date:   2019-01-07 11:05:56 +0530

    Removed redundant code from execute_undo_actions_page

    In execute_undo_actions_page, in UNDO_XID_LOCK_ONLY case, we added
    code to update TPD offset map, that was not needed as we never set
    the locker slot on the tuple.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit c10f69b15e97cff7b118613a3e4ee509664d2676
Author: mahendra <mahi6run@gmail.com>
Date:   2019-01-07 11:00:31 +0530

    Corrected assert condition in zheap_update in UNDO_XID_LOCK_ONLY
    case

    In zheap_update, in case of UNDO_XID_LOCK_ONLY, we were checking
    previous slot with tuple slot. It is possible that from undo
    fetched slot moved to TPD, so handle this condition, changed assert
    condition.

    Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

commit cb5d977a49d56ccfe6a35b49a32c68139cbcc2c8
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-11 20:34:50 -0700

    zheap: regression differerences

commit c95f51f722cb5d8f07e390372e914a7df886c337
Author: Andres Freund <andres@anarazel.de>
Date:   2018-12-10 17:31:46 -0800

    zheap: Also increment tuples_updates for inplace updates.

    That's more in line with HOT treatment, and avoids breaking newer
    tests in stats.sql.

    Author:
    Reviewed-By:
    Discussion: https://postgr.es/m/
    Backpatch:

commit 93426ca749aebbb04757ea548b0e573c399f51e0
Author: Andres Freund <andres@anarazel.de>
Date:   2019-04-11 19:56:32 -0700

    rebase-changes

    Author:
    Reviewed-By:
    Discussion: https://postgr.es/m/
    Backpatch:

commit 9b0289bc66c1a24ce11ccc714e7188f359ec3284
Author: mahendra <mahi6run@gmail.com>
Date:   2019-01-02 18:52:29 +0530

    Fixed incorrect assert condition in zheap_xlog_insert

    For zheap, in case of "SELECT INTO" statement, length of data will
    be equal to the zheap header size, but in heap, it will be always
    greater than heap header size, because in heap, we have one byte
    alignment in case of zero byte data length.
    So fixed assert condition for zheap to handle "SELECT INTO"
    statement at recovery time.

    Reported by Neha Sharma, Patch by Mahendra Singh Thalor, reviewed
    by Amit Kapila and Dilip

commit 493243515f77beae7d2768bbacdb949f68185a0f
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-12-26 15:38:04 +0530

    Fix conditions to check whether tpd entry exists in TPD page

    To check whether a TPD entry exists, we check whether the page is empty
    and it is indeed a TPD page. Apart from that, we should also check
    whether the item offset for the tpd entry exists in the page. If it
    exists, then only we can check whether the corresponding tpd entry
    matches the required block number.

    Patch by me. Reviewed by Amit Kapila.

commit 790d56d8d1eba4c6e91b88410f1b75ed992b053c
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2018-12-31 12:30:22 +0530

    Bug fix while executing undo action during update/lock/delete

    While executing the undo action we have released the buffer lock. So if the tuple infomask
    got changed while applying the undo action then we must reverify the tuple.

    Dilip Kumar reviewed by Amit Kapila

commit 828e897736d8afec50a4bfa2d63aeae0b35065ff
Author: mahendra <mahi6run@gmail.com>
Date:   2018-12-26 18:54:28 +0530

    Bugfix in execute_undo_actions when collecting undo records from
    multiple pages

    In execute_undo_actions, first we are collecting all undo records
    corresponding to one page and then we are executing undo action
    for that page.
    By mistake, we missed to update previous block number after
    collecting undo records of 1st page. So from 2nd page, we were
    collecting undo records one by one and executing undo action for
    that single record, that was costly. so fixed this.

    Patch by Mahendra Singh Thalor, reviewed by Kuntal Ghosh

commit 3cc81113909fae16f78a821db664bc823a258ec0
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-12-24 20:12:30 +0530

    In ExtendTPDEntry, set can_free as false in TPDPagePrune

    When we free a TPD page, we've to take lock on previous block. It's possible
    that we already have a lock on the same non-inplace update on other buffer).
    In that case, we'll wait on ourselves. Hence, we set can_free as false
    in ExtendTPDEntry.

commit e2dd732d4e565fd40b9c08410ad5ae2328fb4d89
Author: mahendra <mahi6run@gmail.com>
Date:   2018-12-24 18:22:21 +0530

    Added missing check in lock reacquired case

    In zheap_update, in non in-place update, when both new and old
    buffers are same, then in lock reacquired case, we can't release
    new buffer so added check to handle this case.

    Patch by Mahendra Singh Thalor, reviewed by Dilip Kumar

commit 16657db3919b300788b132012a36979f78cdc9e1
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2018-12-24 17:45:57 +0530

    Fix a crash during recovery.

    The ItemIdSetUnusedExtended marks itemIds as UNUSED with transaction
    slot information. However, the ItemIdUnused is called later by the
    ZPageRepairFragmentation resetting this transaction slot information
    causing 'inconsistent page found' error during wal consistency check.
    This bug is fixed by passing a bool argument ZPageRepairFragmentation
    and preventing re-evaluation of itemIds.

    patch by me, reviewed by Kuntal Ghosh

commit 45f1834f6312ff25eb34526c60b56ca142d351d0
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2018-12-23 13:38:41 +0530

    Merge review comments fix from undo_interface patch

    Dilip Kumar reviewed by Amit Kapila

commit c4c74972f8e3958863463eb5bda533fc32d081aa
Author: mahendra <mahi6run@gmail.com>
Date:   2018-12-21 18:31:29 +0530

    Fix TPD buffer locking order for non-in-place updates.

    For non-in-place updates, we were locking old and new buffers in
    increasing order of block numbers, but for corresponding TPD pages,
    we were not checking the locking order. To avoid deadlock, we
    should follow the rule "lock lower numbered block first".

    Patch by Mahendra Singh Thalor, reviewed by Kuntal Ghosh and Amit
    Kapila

commit 9ffaad892e6c461a85adbf714cb230522bc973fe
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-12-21 15:19:53 +0530

    Bugfix in speculative insertion in zheap

    When speculative insert fails, the itemId is marked dead. While applying
    undo action, we now consider if the item is dead and it is from speculative
    insert then need not to do anything.

    Reported by Neha, patch by me, reviewed by Amit Kapila

commit e271621655d6e5bec37de5c7a0e93e7a4f5a399e
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2018-12-18 15:45:57 +0530

    Undo action was not applied after rollback of truncate

    As of now handle it the same way as it was handled before changing
    relfilenode to reloid.  Later we might want to handle it differently
    after Thomas handle the simmilar issue in cleaning up the orphan files

    Mithun CY reviewed by Dilip Kumar

commit 7bf50d9d2bfb8daa1d6e8892e2515c928b277fcd
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-12-18 13:28:29 +0530

    Warning fix in zheap_multi_insert

    Reported by Thomas Munro, patch by me, reviewed by Kuntal Ghosh

commit e1200ad6ca62bf57a01a23068e7385377b1204ed
Author: mahendra <mahi6run@gmail.com>
Date:   2018-12-18 11:54:49 +0530

    After allocating a TPD page, update freespace with zero in FSM

    In TPDAllocatePageAndAddEntry, after allocating a TPD page, we
    sholud update freespace with zero in FSM, so that we can restrict
    other backends from getting the same page from FSM.

    Patch by Amit Kapila and Mahendra Singh Thalor.

commit e4d3f718991b673ca3f6b02f5562366f7bc67b6d
Author: mahendra <mahi6run@gmail.com>
Date:   2018-12-17 16:27:49 +0530

    Fix buffer lock in RelationGetBufferForZTuple

    Whenever we need two buffers for updating a tuple (non-inplace),
    we use the rule "lock lower numbered buffer first" to avoid
    deadlocks. But, in zheap this is not the sufficient condition.
    It's possible that the new buffer is a pruned TPD buffer and some
    other backend is trying to use it while holding lock on a zheap
    buffer with higher block number. To fix this, whenever we encounter
    a TPD buffer as a new buffer for updates and it has lower block
    number,we allocate a new block by extending the relation.

    Patch by Amit Kapila, tested by Mahendra Singh Thalor.

commit 5f4e025d6374d1ec039ca4e50811b75e0d57dd0a
Author: mahendra <mahi6run@gmail.com>
Date:   2018-12-17 10:51:53 +0530

    Fix: Copying undometa after advancing the insert location

    In UndoRecordAllocate, we were copying undometa after advancing the
    insert location, that was incorrect.

    Patch by Dilip Kumar and Mahendra Singh Thalor.

commit 2fe20b7f0f6e1d2d82979c8e0d73f475939702d9
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-12-17 10:44:26 +1300

    FPW support for undo logs.

    Register undo log buffers in WAL records, and set their LSNs.  This
    allows the FPW machinery to log full page images after checkpoints.
    Register zeroed out pages (ie most undo pages we allocate) as
    REGBUF_WILL_INIT, so that FPW is skipped most of the time (similar
    to the way we don't read newly allocated pages at DO time, see
    RM43486).

    Use a new function XLogReadForRedoBlock() to read blocks during
    recovery, since we don't have the block ID at that point but we
    know exactly which block number we need.

    RM43689, Thomas Munro, reviewed and debugged by Mahendra Thalor.

commit fb13bc8c2413294abdefad574a3af767a6ecb230
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-12-17 09:40:40 +1300

    Add XLOG_UNDO_APPLY_PROGRESS to desc/identify functions.

    Extracted from a larger patch by Mahendra Thalor.

commit 7c6a38c262b064e9d1fac2201e047222f80afae7
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2018-12-14 18:57:10 +0530

    Add simple VACUUM progress reporting for zheap

    Zheap has reduced the number of pass in vacuum from three to two.
    Hence the progress report also uses 2 phases of vacuuming viz
    vaccuming heap and vacuuming index before going to the clean up
    phase. The scanning heap phase is not used.

commit 56a9f85f6bc91573889a385c1e6a4910ad5ba0a6
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2018-12-07 17:43:56 +0530

    Fixing wrong option passed to execute undo action

    In FinishPreparedTransaction we are not holding the relation lock so pass
    the correct information to execute_undo_action so that it can acquire
    proper lock.

    Dilip Kumar

commit 309145fb8ab59c993e26855cf0bf51d37902773f (zheap/master)
Author: mahendra <mahi6run@gmail.com>
Date:   2018-12-10 11:14:44 +0530

    Fix WAL logging for tpd map update during Rollback

    We were not WAL logging tpd map update in few cases, fix that.

    By Mahendra Singh Thalor and Amit Kapila

commit deda887629ca8bba859c0fa2a2e459e2c922c2bd
Author: mahendra <mahi6run@gmail.com>
Date:   2018-12-10 10:45:04 +0530

    BugFix : Correcting block number read in tpd_xlog_free_page

    In tpd_xlog_free_page function, we were trying to read from
    block 3 the data written in block 2. Hence correcting the
    block number.

    Patch by me, reviewed by Amit Kapila

commit 79738e7038e267c2c685cc5a5221153269317eeb
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2018-12-07 10:54:33 +0530

    Revert "For slots marked as invalid xact, skip fetching undo for some cases"

    This reverts commit 796299af2ca14800f8d69560d33f89ac293c1d15.

commit 796299af2ca14800f8d69560d33f89ac293c1d15
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-12-05 17:27:18 +0530

    For slots marked as invalid xact, skip fetching undo for some cases

    For a slot marked as invalid xact, if the corresponding xid preceds
    oldest xid having undo or the corresponding undo record is already
    discarded, we can consider the slot as frozen.

    Patch by me. Investigated by Amit Kapila, Dilip Kumar and me.

commit e26c804789fdcf24fc588a734b2196a81a51eef4
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2018-12-05 13:09:06 +0530

    Merged review comment fixes from pg hackers patch

    Dilip Kumar and Amit Kapila

commit 1fee88b7ec5d9aed7e1c0429292906e30f457f0d
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-12-04 02:11:08 -0800

    Fix CLANG's warnings.

    By Mithun C Y, review by Amit Kaplia.

commit 5b48c0c175dabfaf34099f0cc7feefe0b2367a0c
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-12-04 01:35:40 -0800

    Fix thinkos, caught by CLANG compilers.

    By Mithun C Y and Review by Dilip Kumar.

commit a1e1859d6910f49bb6eec8d04113dbba78deee3a
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2018-12-03 14:54:38 +0530

    Improve comments and code for previous commit.

commit 132fefaf953e632e07ddc53f8e0198e655cf0896
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2018-12-02 16:35:02 +0530

    In ZGetMultiLockMembers we fetch the undo record without a buffer lock
    so it's possible that a transaction in the slot can rollback and rewind
    the undo record pointer.  To prevent that we acquire the rewind lock
    before rewinding the undo record pointer and the same lock will be
    acquire by ZGetMultiLockMembers lock in shared mode.  Other places
    where we fetch the undo record we don't need this lock as we are doing
    that under the buffer lock.  So remember to acquire the rewind lock in
    shared mode wherever we are fetching the undo record of non commited
    transaction without buffer lock.

    Mahendra Thalor Reviewed and modified by Dilip Kumar

commit c200352aa6917b8c3d4a0e771a1f19d6f4eec6d9
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-11-30 14:06:07 +0530

    Bugfix in TPD recovery

    Patch by me, reviewed by Dilip Kumar

commit fd9152fa3ecfe1d0d8e6d06571d91f082d0f4ee9
Author: Dilip Kumar <dilipkumar@localhost.localdomain>
Date:   2018-11-29 07:17:27 -0800

    Remove multilocker flags for the cases for unwanted cases

    Currently, we are setting multilocker flag whenever lock is acquired
    on the tuple which has some performance penalty.  As part of this patch
    we have avoided setting multilocker flag for the case when a updater is
    taking a lock through eval plan qual mechanishm.

    Amit Kapila and Dilip Kumar

commit 79882e67fe4572081fc65a0dc28c20a773ef0533
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-29 18:26:12 +0530

    Fix issue in TPD allocate entry

    While allocating an entry for TPD, we traverse all the tuples in the
    page and check for tuples the correspond to the last slot and update the
    corresponding offset map in TPD with the actual transaction slot.

commit 8a6d050f121d2e588defee48d4a3ad9e43ac6136
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-11-29 16:57:02 +0530

    Bugfix in recovery of TPD free page

    Patch by me, reviewed by Amit Kapila

commit 47b86637a3d1ae71102c1a7a7704aaf7e95feffc
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-28 14:10:10 +0530

    Fix issues in TPD

    1. If previous and next block number is invalid for a TPD page, then
    that is the only TPD page in the same relation. We should handle the
    case correctly in TPDFreePage.
    2. While allocating a new TPD page, we ask a new page from FSM. It's
    possible that FSM returns a zheap page on which the current backend already
    holds a lock in exclusive mode. Hence, try for a conditional lock. If it
    can't get the lock immediately, extend the relation and allocate a new
    TPD block.
    3. In TPDPageLock, if a TPD buffer is already pruned, we don't take a
    lock on the same. Here, we should take the opportunity to clear the TPD
    location from the corresponding zheap buffer.
    4. In lazy vacuum, we don't vacuum a TPD page. Instead, we try to prune
    the page. But, if it's already pruned, we should skip it.
    5. There are several places in the code where we lock a TPD page before
    entering critical section. For non-inplace updates on different buffers,
    it is possible that both old and new zheap buffer corresponding to the
    same TPD buffer. Hence, we should be careful that we don't try to lock
    the TPD page two times. Else, we'll be waiting on self.

    Patch by me. Reviewed by Amit Kapila.

commit 8c31fef78166e7df53470f43c6bd1d53d18341e7
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-28 14:31:09 +0530

    Skip using tuple if corresponding item is deleted

    If item id is marked as deleted, we can't check the tuple. Else, it'll
    lead to segmentation fault.

    Patch by me. Reviewed by Amit Kapila.

commit c66b03f50c074236882fb0370a87dad8df4a597c
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-11-27 09:10:44 +0530

    Fix windows build.

commit 35e2e1b5907d85ee02d74b728a23ab7865405e64
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-11-26 14:34:16 +0530

    Forget Local buffers

    For zheap, forget the local buffers whenever used.

    Patch by me, reviewed by Amit Kapila

commit 3a1f846c48cea443478478622c12b6df28fe15a6
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-11-25 10:12:13 +0530

    Fetch CID from undo only when required.

    If the current command doesn't need to modify any tuple and the snapshot
    used is not of any previous command, then it can see all the modifications
    made by current transactions till now.  So, we don't even attempt to fetch
    CID from undo in such cases.

    Patch by Amit Kapila, reviewed and verified by Dilip Kumar

commit e48be86489daf6bc78071d7fe7fe5e1eb5b2a705
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-11-23 07:58:01 -0800

    Bug Fix, correct an invalid Assert.

    slot_xid is uninitialized and Assert condition is invalid.

    Patch By Mahendra Thalor Review by Amit Kapila.

commit 12bf9650d247c64d96868ada87fcda07a2ff46b5
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-11-23 03:31:06 -0800

    Merge review comments fixed on community patch

    Dilip Kumar

commit d06ab949c8774f6989ffefc65a100b7208516a06
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-11-22 15:53:22 +0530

    Fix the modification of TPD map during rollback.

    If the previous transaction slot points to a TPD slot then we need to
    update the slot in the offset map of the TPD entry.  This is the case where
    during DO operation the previous updater belongs to a non-TPD slot whereas
    now the same slot has become a TPD slot.  In such cases, we need to update
    offset-map.

    Patch Mahendra Singh, reviewed by Amit Kapila

commit 9f1fd917e954b6b430b2575e84bd669166ee8cdf
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-11-21 22:09:16 -0800

    Make the expected file to be generated by a source file.

    Patch By Mahendra Thalor Review by Mithun C Y.

commit 3e255b05d87a65183adc8cac204529937c978e13
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2018-11-20 11:47:49 +0530

    Fix crash in pg_stat_* functions

    commit b04aeb0a05 added Assets to ensure that we hold some relevant
    lock during relation_open. This commit corrects the locks used in
    relation_open for the zheap pg_stat functions to avoid Assertion
    failure.

    Patch by me, reviewed by Dilip Kumar

commit 0e2f8eb102744121d7203213c87c124f75578665
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-11-19 13:07:25 +0530

    Reset undo buffers in case of abort

    In case of errors, when the transaction aborts, the undo buffers and
    the buffer index are now reset.

    Patch by me, reviewed by Dilip Kumar and Amit Kapila

commit 88f9e6e42d0c769158b283b378c4c0d19af91139
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-11-18 04:43:36 -0800

    Fix trailing space in previous commit

commit b925c7ab4df48f42951b9690216d9c9e78f25ba3
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-11-18 04:18:04 -0800

    Only try to lock the TPD page if the zheap page has the TPD slots in it.

    Path by Mahendra Thalor reviewed by Dilip Kumar

commit 257e8e7990e9d85a373a41d0dce17f7f56ed5c61
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-15 17:46:14 +0530

    Add expected file for multiple-row-versions isolation test

    In this test, we get a serialization failure due to in-place updates in
    zheap. But, this is an expected behavior.

    Discussions: https://postgr.es/m/CAGz5QCJzreUqJqHeXrbEs6xb0zCNKBHhOj6D9Tjd3btJTzydxg@mail.gmail.com

commit 1b44ba6c5154fa6eed3e56bfb97285a78aa58003
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-02 12:00:41 +0530

    Implement ALTER TABLE SET TABLESPACE for zheap

    To alter the tablespace for a zheap table, we copy the pages one-by-one
    to the new tablespace. Following is the algorithm to perform the same:

    For each zheap page,
        a. If it's a meta page, copy it as it is.
        b. If it's a TPD page, copy it as it is.
        c. If it's a zheap data page, apply pending aborts, copy the page
        and corresponding TPD page if we've rolled back any transaction from
        the TPD.

    Patch by me. Reviewed by Amit Kapila.

commit 2b5f6aa07e8d705f238bf8b1a308e6f761e05a98
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-14 11:35:00 +0530

    Create a wrapper function for fetching transaction slots for a page

    We've created a  wrapper function GetTransactionsSlotsForPage for
    fetching all transaction information for a zheap page and its
    corresponding TPD page.

    Patch by me. Reviewed by Amit Kapila.

commit 0931d56b34aaf5c9c2b665da751aec051aa7d90a
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-11-15 01:50:11 -0800

    Fix assert

    It must be in critical section only if it's not in recovery

commit 96ede480d229e874e204895856bcded0fb33f68b
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-11-15 01:41:43 -0800

    Remove relfilenode and tablespace id from the undo record and store reloid

    There was no reason why we stored relfilenode and tablespaceid in undo record,
    instead we could just store reloid.  Earlier, we might have kept it thinking
    that we will perform rollback without database connection but that's not the
    case now.  This will save the space as well as it will be useful when we need
    to transfer the undo records across the relfilenodes e.g ALTER TABLE SET TABLESPACE.

    Dilip Kumar reviewed by Amit Kapila

commit 842e9e36821e2ad1ce2f557631a2af8bb96f2d23
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-11-15 01:28:07 -0800

    Fix cosmetic review comments in undoinsert

    Dilip Kumar review by Amit Kapila

commit 01f981fdeddad6eff83f1a12c8751a373df56a1c
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-11-14 20:48:14 +0530

    Discard undo logs in single-user mode

    For zheap, discard the undo logs at commit time when in single user mode.

    Patch by me, reviewed by Dilip Kumar and Amit Kapila

commit 1bcef1bf35738b060e5c412428aac502245abe2b
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-11-14 17:03:47 +0530

    Bugfix for visibility map buffer

    In case the page is newly extended, the vmbuffer will not be valid.
    Hence avoid checking the status for it in zheap insert and update.

    Reported by Neha, patch by me, reviewed by Amit Kapila

commit 1b1cace0bb7195025ea5bd19848953f10fe5cd30
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-11-13 05:14:26 -0800

    Removed invalid assert in extend_undo_log

    It is possible that while we try to extend the undo log it's already
    extended by discard (recycle old undo log) so this situation is
    possible.

    Patch by Mahindra reviewed by Dilip Kumar and Amit Kapila

commit aa25f816c637f9123f67a4c7e1fa14f64c15d72c
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-11-11 19:35:32 -0800

    Fix compiler error

commit 48d8236385a8894f17e642bb182e6be01b5fcfb7
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-11-12 08:33:05 +0530

    Fix warning.

commit 0495698cb6e1e6d29ddb146332ddc61299c99aeb
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-11-10 16:15:45 +0530

    Prune entire TPD page at one-shot if possible.

    We have used tpd_latest_xid_epoch stored in page to prune the entire TPD page.
    Basically, if tpd_latest_xid_epoch precedes oldestXidhaving undo, then we
    can assume all the entries in the page can be pruned.

    Apart from that, I have changed the logic so that page is freed during
    pruning if all the entries are removed from the page. this will ensure that
    pages will be reclaimed whenever they are empty, not only during vacuum.

    In the passing, I have fixed another related issue which is after we get
    the new page from fsm, we need to ensure that it is a tpd page before
    using it.

    Patch by Amit Kapila, reviewed and verified by Dilip Kumar

commit 2c0af615df41867e26fd80900f0e38f032750752
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-09 15:22:26 +0530

    While computing infomask for updating a tuple, don't copy update flags

    When we compute infomask during updating a tuple, we don't have to copy
    update flags. We compute it later in zheap_update.

commit 48f1a2d2973ae25b33adfeac4129769fadfea134
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-09 13:27:35 +0530

    Small bugfix in UndoDiscardOneLog

    We can't compare log->meta.insert directly with the undo_ptr. We need to
    create a undo pointer first.

commit 0b374e91021b49795d2ec05243e3c9c24363d7d5
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-11-08 22:09:05 -0800

    Bugfix in TPDPageGetTransactionSlots to handle truncated pages.

    Block number starts from zero, when compared with the total number of
    blocks in relation, we need to adjust the block number accordingly.

    Fix by Mithun C Y, review by Amit Kapila.

commit 38e5a0cee902dae0c18961d91699ba254ea0fcb3
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-08 15:16:02 +0530

    In zheap_update, clear the in-place update flag for non-inplace updates

    Reported by Gunjan Kumar.

commit 05c36ee9f886c9feb274360d9b523ea0d9e4dac7
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-08 11:51:20 +0530

    Fix a testcase in expected file for trigger.sql regression test

commit f52a281728a425df027d4a201c09730c5a8f0c42
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-08 11:14:55 +0530

    While locking the tuple, set cid as FirstCommandId

     While locking the tuple, we set the command id as FirstCommandId since
     it doesn't modify the tuple, just updates the infomask.

commit 2595ad4d099abf21d59017f8cebfa416fe454d2d
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-07 15:07:49 +0530

    Fix a bug for projecting table oid

    There are certain places in the code where we form a heap tuple using
    ExecCopyTuple and store it in slot along with the zheap tuple. In that
    case, we don't copy the tableOid to heap tuple. Hence, for fetching
    tableOid, we should prefer a zheap tuple instead of a heap tuple.

commit a3d175ba1b4a089b74a9f68be4b035695d57d698
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-11-07 21:11:32 -0800

    Post push compilation error fix for 903ce21849

    By Mithun C Y

commit fdd2e03c972269b4a0fe95b13433ce55ac1f8bd7
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-11-06 02:11:35 -0800

    Bugfix in recovery of invalid_xact and freeze

    TPD page slot information was not set if BLK_NEED_REDO is false for
    the heap page.  Also, during recovery relation descriptor is used
    to take the pruning decision which is wrong because during recovery
    it should be done automatically by a seperate WAL.

    Dilip Kumar and Amit Kapila

commit 0fc2cb13d810d7979b51c2b6ea44fa4f9119f7a4
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-05 16:31:38 +0530

    Fix shared memory size for rollback hash table

    While creating shared memory segment for rollback hash table, we should
    set the size of the segment correctly.

    Patch by me. Investigated by Dilip Kumar and me.

commit 62c4099af465e7f739aa0f391724eb4efb02ba08
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-05 13:52:25 +0530

    Fix warnings in tpd.c

commit 9e203e16ffd03867bda789c33f0bdeece04df7a0
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-04 21:57:23 +0530

    Assign OID correctly while converting tuple

commit b8bcb9891a1fc24e1c02933ee84eba1a017af692
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-11-05 13:46:47 +0530

    Handling rollbacks in single user mode for zheap

    Never push rollback requests to worker when in single user mode.

    Patch by me, reviewed by Amit Kapila

commit a95fc28e9073d6e7815f3772e1255efe2967c847
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-11-05 11:03:54 +0530

    Add empty TPD pages to FSM.

    The empty TPD pages are added to FSM by vacuum which prune such pages as
    well. The empty pages from FSM can be used either by zheap or TPD when
    required. We need to ensure that when we access TPD pages, such a page can
    be pruned or truncated away by vacuum. After pruning the TPD page, it can
    be freed by removing it from the chain of TPD pages.

    As of now, only vacumm can add TPD pages into FSM, but we might want to
    improve it someday that backends can also do the same.

    Patch by me with help from Dilip Kumar who also tested and verified the
    patch.

commit 49a60ee0c3bbb844621bc8167f8e04ca0c032509
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-11-05 10:14:13 +0530

    Adding new output files for regress-suite

    Some system attributes are not supported for zheap tuples, hence,
    for combocid and transactions new .out files are added for zheap.

    Patch by me, reviewed by Kuntal Ghosh

commit 3d8d5f45b4b928fbcc9d1ff29c3f8fc822009a4f
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-11-05 08:09:29 +0530

    Fix valgrind error.

    Reported by Tomas Vondra, patch by me, verified by Mithun

commit 8e3a8679dfb0248699155eec8f07098df7d7f3ad
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-11-02 16:44:26 +0530

    Change case in one error message

    Pointed out by Kuntal Ghosh, patch by me.

commit 1bcb9489f3077ef03616ff19ff46b0e3a2980aa6
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-11-02 16:36:32 +0530

    Fix the errors reported by valgrind.

    In the passing, I have noticed the xidepoch was not assigned properly,
    so fixed that as well.

    Reported by Tomas Vondra, Patch by me, verified by Mithun C Y.

commit f69fa9edc361c374cb7ce8780b5e63b6412c9d08
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-11-02 16:26:04 +0530

    Bugfix in heap_truncate for zheap relations

    Initialize meta page for zheap relations only when the complete
    relation is truncated.

    Patch by Amit Kapila, tested by me

commit 704e3b777c385e319ded0b0fa317409fc41dc7a1
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-02 15:40:19 +0530

    Add expected file for rowsecurity regression test

    In rowsecurity test, there is a test case that uses table sample scan
    with bernoulli distribution. The output of tablesample scan partially
    depends on the block number of the relpage from which the tuples are
    fetched. For zheap, blocknumber 0 is meta page. Hence, tuples are stored
    from block 1. Hence, the output of table sample scan can be different.

commit 153ea5c17e65144382c8c68a22d46527f0f7de2d
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-11-01 08:09:35 -0700

    Release Undo buffer locks after wal replay of XLOG_UNDO_APPLY_PROGRESS

    By Mithun C Y And Mahendra Thalor.

commit 5fed5fe9eaa00c1196dc47d18b91c9e2bb336aab
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-01 15:33:47 +0530

    Add expected file for stats.sql regression test

    In zheap, we increase pgstat_info->trans->tuples_updated only for
    non-inplace updates, otherwise vacuum will be triggered for in-place
    updates as well. But for heap, we always increase tuples_updated since
    heap always creates a new version of the tuple during updates. Hence, we
    need to fix the output in expected file for zheap.

commit 987049f5b11351ee6b985ddc76e978e2d77fa403
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-01 14:52:39 +0530

    Add expected file for strings.sql regression test

    There is a test case in strings.sql that counts the number of pages for
    toast table. In zheap, toast tables are also created in zheap format
    which always includes a zheap meta page. We should count that in the
    expected file.

commit 3ef3b9b67ae27d9568ce9380c9f646bd894b8bd0
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-11-01 12:00:50 +0530

    Add storage_engine in reloptions regression test

commit 94777e98221cf49e42f9a7bddf5947072424e368
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-10-31 22:23:28 -0700

    Add alternative expected files for zheap regression.

    Order of zheap tuples in pages will be diffrent form heap. Hence
    zheap specific expected files are needed.

    By Mithun C Y

commit 7570b3bed887531f31dcc25ea602233c8d56ee6d
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-10-31 22:06:56 -0700

    Fix warning of hash seq scan leak and also removed unwanted assert
    from the zheap mask.

    Dilip Kumar Reviewed by Amit Kapila and Kuntal Ghosh

commit 14fdcc4b9eda81577d81ba3c7b040f86850e78eb
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-11-01 09:54:26 +0530

    System attributes for Zheap

    For zheap tuples, Xmin is given as the xid which last modified the
    tuple. The other system attributes Xmax, Cmin, and Cmax are not
    supported for zheap, for now.

    Patch by me, reviewed by Amit Kapila

commit 794b8f4df739d3565663f51ca7117dbe855980c2
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-11-01 09:11:31 +0530

    Update README.md.

commit 6ce786252d5ddaac6fdb07506f6cde3d66e093cd
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-10-31 19:11:40 +0530

    Updated readme to match latest status.

commit 8c780e8474aed4c38ae482d94683cba1be0e9a29
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-10-31 06:34:45 -0700

    Fix assert in RollbackFromHT

    Ideally number of entries should be <= ROLLBACK_HT_SIZE

commit 3017c86cdaba643d61f32eab351b63acfa381720
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-10-31 06:18:52 -0700

    Merge additional test in zheap expected file

commit 8bf58ba522c27429d0da0260a35abc5d519feece
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-10-31 05:58:00 -0700

    Fix defect in undo worker connection

    Take a database object lock before connecting to the database so that
    the database does not get dropped concurrently.

    Dilip Kumar Reviewed by Amit Kapila

commit 007af507d94b992f0a37caa10015d134a0782b07
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-31 14:35:02 +0530

    Skip aborting rewinded undo records

    Before discarding undo records, the undo discard worker checks whether it
    has to issue a rollback request for the corresponding aborted transaction.
    It's possible that the transaction got aborted by some other backend at
    the same time and the undo records got rewinded. Hence, the undo worker
    should recheck to detect whether the undo records got rewinded. In that
    case, there is no need to issue a rollback request.

    Reviewed by Amit Kapila

commit 28bae62a6745f223e99e1af27328ed6218752bb4
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-10-31 16:01:02 +0530

    Eliminate alignment padding whereever possible.

    We omit all alignment padding for pass-by-value types. Even in the current
    heap, we never point directly to such values, so the alignment padding
    doesn't help much; it lets us fetch the value using a single instruction,
    but that is all.  Pass-by-reference types will work as they do in the heap.
    Many pass-by-reference data types will be varlena data types (typlen = -1)
    with short varlena headers so no alignment padding will be introduced in that
    case anyway, but if we have varlenas with 4-byte headers or if we have
    fixed-length pass-by-reference types (e.g. interval, box) then we'll still end
    up with padding.  We can't directly access unaligned values; instead, we need to
    use memcpy.  We believe that the space savings will more than pay for the
    additional CPU costs.

    We don't need alignment padding between the tuple header and the tuple
    data as we always make a copy of the tuple to support in-place updates.
    Likewise, we ideally don't need any alignment padding between tuples.
    However, there are places in zheap code where we access tuple header
    directly from page (ex. zheap_delete, zheap_update, etc.) for which we
    them to be aligned at two-byte boundary).

    Amit Kapila and Kuntal Ghosh

commit 580dcc4fc69e57dac919d1ac1068f876505f6c17
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-10-31 14:59:31 +0530

    Fix for a compiler warning

    Reported by Neha Sharma

commit 7f2397b0b87a9941a34998ffc63990eab32f09f1
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-10-31 00:43:06 -0700

    Wal log page extension if it was not done previously.

    Patch by Amit Kapila, Review by Mithun C Y.

commit 9ffbe108474a898e76302bb834d040f288b78e67
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-30 13:17:34 +0530

    Fix bug in registering TPD buffers for WAL

    While creating a WAL record, if a concurrent checkpoint occurs, WAL
    insertion may fail. In that case, we need to prepare the WAL record
    again. At the same time, we should clear the registered TPD buffer
    array. Else, it'll not be registered in WAL in next try.

    Patch by me. Investigated by Amit Kapila, Dilip Kumar and me. Reviewed
    by Amit Kapila and Dilip Kumar.

commit b30e67a310db0bd75a44094c8acd9e87c1f5c51e
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-31 11:51:01 +0530

    Fix eval-plan-qual isolation test

    After rebasing the zheap branch with latest PG HEAD, there are some
    additional testcases in eval-plan-qual isolation test. Add those changes
    in regression out file targeted for zheap.

commit 799ca622b624f0b13916ea8ce4ea1afad51d5f1c
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-10-31 11:50:49 +0530

    Return error on trying to update a row moved to another partition.

    The approach used here is to set the ZHEAP_MOVED (ZHEAP_DELETED |
    ZHEAP_UPDATED) flag when the tuple is moved to different partition.
    All the cases that are handled in heap needs to be handled for zheap as
    well.

    Amit Kapila, based on earlier patch by Amit Khandekar which has used a
    different approach.

commit d9918b8ec386619a3cd2ac28d8f2ea8698aeec99
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-10-31 11:22:29 +0530

    Defect fix post rebase

commit 10492266c5789bbec1fdbfd13220dcacbea633c6
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-30 10:16:43 +0530

    TPD fix by Dilip RM43761

commit 7524cd8cf9f7a20bfb44aefe32f0085bec1ce385
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-10-30 18:36:32 +0530

    During recovery restore dbid from WAL

    Patch by Mahendra Thalor Reviewed by Dilip Kumar and Kuntal Ghosh

commit e73d2bf79db041177d35c9f3333e126318460f8c
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-10-30 17:57:00 +0530

    Bug fix after rebase

    Dilip Kumar and Kuntal Ghosh

commit 5340d395c5d63e56f0398fee816393a613e385fb
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-10-25 05:32:50 -0700

    Avoid page compaction if the tuple is marked updated, deleted or
    inplace updated by an open transaction.

    By Mithun C Y

commit ed9356efb9f5ad9622beef61ce75cfb9b8c5ea39
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-24 10:35:11 +0530

    Fix an isolation test case for zheap

    In zheap, when a transaction rolls back, it needs to perforfm undo
    actions on the modfied relation. For that, it needs a lock on that
    relation. If any concurrent transaction holds an exclusive lock on the
    relation, the rollback operation will wait untill the lock is available.

commit 5711aac11e6443d16e6b0aeb2219c9ce0ac6f3b7
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-10-23 21:24:07 +0530

    Fix compiler warning.

    Reported by Thomas Munro.

commit 407f6350335597bb2029109df3c0a4d090410a4f
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-10-23 14:12:58 +0530

    Move functions that can allocate memory or allow locking outside critical
    section.

    At few places in the code, TPDPageGetTransactionSlotInfo was being called
    from critical section which leads to assertion failure.  Lock the TPD page
    whereever required before entring critical section.

commit 390416aa17bc215e541c3cf83acd5e336bb6e350
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-23 12:13:23 +0530

    Bugfix in tpdxlog.c

commit a68d7ef43e07849bd75bd5e39634e3ab29efbe0b
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-23 12:11:07 +0530

    Fix a variable initialization

commit 09a0518389ccce88b381b3f44b4d88769feb7634
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-10-22 18:10:00 -0700

    Fix orderering issues in regression tests.

    With zheap we have inplace updates so order of tuples in zheap page
    will be different from heap.  Adding order by clause to test to get
    consistent results for both heap and zheap.

    By Mithun C Y

commit b5f1649f55aa366f239fe37dc2e06c9b2cecdf17
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-10-18 16:37:00 +0530

    Bug fix in zheap_lock_tuple

    Added a code-path in zheap_lock_tuple to check for the latest copy
    of the tuple in case it is modified by some aborted transaction.

    Issue reported by Neha Sharma, patch by me, and reviewed by Amit Kapila

commit f9a00ee12997bc0ac823ac4419b8aa3f7024aee6
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-18 11:06:04 +0530

    Add expected file for eval-plan-qual isolation test

    Include metapages in ctid for zheap tuples. Also, Updated a test case
    related to self join. Basically, when performing a self join if it needs
    to pass through EvalPlanQualFetch path, it's possible that both sides of
    the join see the same value due to in-place update. This behaviour is
    different from heap, but similar to other undo-based storage.

commit 804d6edc03cc8aa9b5bb0428bccda27a48c1c8fb
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-18 10:09:54 +0530

    Include meta page in isolation test results

    In vacuum-reltuples isolation test, include zheap metapage in relpages.

commit c0f90396dd27d28c27d0b59e682680289fcba669
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-10-17 18:28:05 +0530

    Bump the number of initial TPD entries.

    By mistake, commit 1400d8f84b has changed the number, it was added just for
    testing purpose, but it should have been removed before commit.

commit 14d67f52665110d64666e1addc255df15015dc6b
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-10-17 16:49:10 +0530

    Support inplace update of TPD entries.

    Whenever TPD entry needs to be extended, we call Call TPDPagePrune to
    ensure that it will create a space adjacent to current offset for the new
    (bigger) TPD entry, if possible. We use compactify_ztuples to ensure that
    space adjacent to existing entry can be created. For inplace update of TPD
    entry, we just replace the old entry with new entry at the same location
    similar to inplace updates of tuples. We also write WAL record this
    operation.

    Amit Kapila and Kuntal Ghosh, reviewed and verified by Dilip Kumar

commit 83c27f9fae800fb73eff68f1987136adaf7965ab
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-10-17 06:26:24 +0530

    Bugfixes in zheap update, delete, and lock

    - Modify the infomask only after writing the corresponding undo.
    - Always be in inside critical section when modifying tuple.
    - Check if the current member is the only locker with multilockers,
      then no need to lock tuple again.

    Issue reported by Neha Sharma. Patch by me, reviewed by Amit Kapila
    and Kuntal Ghosh

commit 69b6b791ffaa0d04cc10bc0603c8bbc39f58dfa8
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-10-15 14:31:43 +0530

    Improve test coverage of update.sql.

    Commit 521461cfd91b9b44f0ecc392b3470922e78246b0 had removed
    some redundant RETURNING clauses in some statements, in order to
    make the output consistent. This commit reverts back those changes
    and instead uses WITH clause over the update statements, so that
    we could use ORDER BY for consistent ordering . This helps retain
    the RETURNING clauses, which also makes sure we don't reduce the test
    coverage that we may have got for the update-partition-key feature.

    Patch by me; idea suggested and changes reviewed by Mithun Cy.

commit 0a261c3bae670e9b3748a9eeb82706a96a2b4f32
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-15 11:27:51 +0530

    Fix payload length in standby

commit dac8323bfc43f7c0dec9c02dd53ca761b3c098b8
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-15 10:15:32 +0530

    After fetching xid recheck for frozen xid

commit abdd14af03e32e9abfe7b7ed0c6bb88a0a6184af
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-15 09:53:14 +0530

    Clear TPD entry only in exclusive lock

    When we clear TPD entry from a TPD page, we should have a exclusive lock
    on the TPD buffer. Hence, perform a check for the same before clearing
    the entry.

commit 52b84f9fb21468080c8ea252336a1994f915ca8b
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-10-15 10:55:07 +0530

    Bug fix in recovery

    Multiple bug fix in recovery of the TPD and undo action WAL

    Dilip Kumar reviewed by Amit Kapila

commit 6ebf7d2e1f12fcd92bb5c7ebe11e83eda3824c32
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-10-15 10:51:17 +0530

    Bug fix in tpd

    If the tpd entry is pruned then we can directly use the last slot
    for the transaction and no need to try for extending the tpd entry

    Amit Kapila reviewed by Dilip Kumar

commit aa09e789b0b40f9593f97135c6c9af4c74464023
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-10 13:47:25 +0530

    Skip calling zheap_fetchinsertxid for non-serializable xacts

    For non-serializable xacts, we can skip calling zheap_fetchinsertxid to
    fetch the targetxmin that is passed to PredicateLockTid. A call to
    zheap_fetchinsertxid is costly since it has to fetch undorecords.

commit 2b2963b37cb1316de21ed65e8c859b76467616ca
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-10 11:07:35 +0530

    Fix compiler warnings

commit 0a82317f0378b35122df6bef1d473826f149c121
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-10-08 11:58:38 +0530

    Bugfix in undoworker commit.

    Shared memory size was not calculated for undo launcher
    and removing one unwanted hunk.

commit c77321a0364149c3831844f02082579a070d47f0
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-10-07 14:47:06 -0700

    Fix regression tests and output for row order changes.

    With the introduction of inplace updates in zheap, order of rows
    within a page has changed. This fix changes the queries whose output
    depend on stored row order. Those queries are rewritten to have an
    order by clause to get consistent result for both heap and zheap.

    By Mithun C Y

commit e5a37a151fc52b0bc10b2dd6af13af3b71136360
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-10-05 22:20:44 +0530

    Fix a concurrency issue with UPDATEs and triggers.

    In GetZTupleForTrigger(), after it calls zheap_lock_tuple(), a check
    for hufd.in_place_updated_or_locked was missing. So if there was a
    concurrent in-place update, it used to conclude that the tuple was
    deleted. Add the missing check.

    Patch by me, reviewed by Dilip Kumar.

commit f5c0d3dd3cbab42628d311fbb50614f1bce93ec1
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-10-05 22:01:36 +0530

    Regression test changes for update.sql

    update.sql had to undergo some modifications because the RETURNING
    clause was returning in different order. Also some UPDATE statements
    that updated multiple rows had to be modified such that they update
    only single row, because the erroring row was different in case of
    zheap. There were two erroring rows, and out of them whichever is the
    first in the update scan result got displayed in the error message.
    This test also has some more ORDER BY clauses.

commit bbd7a64c3495b77bf77406511afa4f1183a7fcc4
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-10-05 21:37:18 +0530

    Fix tuple handling with trigger functions and transition capture.

    In ExecUpdate(), for zheap tables, ExecARUpdateTriggers() was called
    only if resultRelInfo->ri_TrigDesc is true, which is incorrect. This
    function also needs to be called for transition capture even when
    trigdesc is false. Due to this, transition table rows were not getting
    generated.

    Furthermore, in ExecInsert(), for zheap tables, ExecARUpdateTriggers()
    was getting called using tuple when it should be called using ztuple.

    Fixed both these by making the newtuple parameter of
    ExecARUpdateTriggers() a void * type and renaming it to
    newtuple_abstract, so that we can pass tuple or ztuple according to
    the table storage. And then in ExecARUpdateTriggers(), do the
    conversion from zheap to heap if it's a zheap tuple.

    On similar lines, do changes for ExecARInsertTriggers(), where
    trigtuple is made trigtuple_abstract. Now that this function accepts
    an abstract tuple, fix another pending issue in copy.c : in CopyFrom()
    and CopyFromInsertBatch(), pass either zheap or heap tuples to
    ExecARInsertTriggers().

    Reviewed by Dilip Kumar and Amit Kapila.

commit 51da00138eeceda6ea57e59760e49b9d60518274
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-10-05 17:04:22 +0530

    This commit completes the work of adding the new lock type for
    sub-transactions in zheap that was started in commit
    13b72c94cc77f6471e46f6e9da29423994753240. This commit handles the cases
    of waiting on sub-transactions when using dirty snapshot, inserting
    index tuples in btree, and while checking for constraints violation.

    Patch by me, reviewed by Amit Kapila

commit 0cb8b6c800d4437c0e413c8bd2473181d843f1e3
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-10-05 02:22:45 -0700

    Fix condition for page pruning.

    In zheap_page_prune_guts condition for pruning was wrongly set. This patch
    fixes same. Along with it patch also fixes the code which made NULL pointer
    dereference.

    By Amit Kapila and Mithun C Y

commit 1662919e20b45e515849304f68e310b28939aae6
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-10-04 19:36:10 +0530

    Support Cluster/Vacuum Full in zheap.

    As of now we only rewrite LIVE tuples and we freeze them before storing in new
    heap.  This is not a good idea as we lose all the visibility information of
    tuples, but OTOH, the same can't be copied from the original tuple as that is
    maintained in undo and we don't have facility to modify undorecords.  We
    have some ideas how to do that and those are documented in rewritezheap.c.

    Patch by Amit Kapila with help from Mithun C Y who also reviewed the patch.

commit 62606342d267ad671d7084798ac9febd1230919c
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-04 11:22:11 +0530

    Fix compiler warnings

commit bfe41c9db8b397d9c230b36f5c7f6f7826b7fa64
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-04 10:49:57 +0530

    Fix assert for insertion of frozen tuple

    If we're freezing a tuple during insertion, we can use the HEAP_INSERT_SKIP_WAL
    optimization since we don't write undo for the same. Hence, adjust the
    assert in zheap_prepare_insert accordingly.

commit 8defd8aa1852f24ca81552efbf158d3abeda7662
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-03 19:07:57 +0530

    In zheap parallel scan, use SnapshotAny if required

commit 268ab31eebddb41e4f5c9bfb026b9e88f24d4416
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-03 19:06:48 +0530

    During in-place updates, update t_hoff correctly

commit 14dd056736a4cdf4949f798bf1386b80671ada85
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-03 19:01:57 +0530

    Initialize startblock for zheap scan

    Since zheap scan unconditionally uses scan->rs_startblock in zheap_getnext,
    we should initialize the same by default. Otherwise, valgrind barks
    loudly. This may also result in undefined behaviour in release mode.

commit bf1b20a81832f1c007690cda95088aef857bd34d
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-10-03 19:00:25 +0530

    Fix scan initialization for zheap tables

    Use zheap_beginscan_parallel in _bt_parallel_scan_and_sort for scanning
    zheap tables.

commit e090a7c5b3f82578d38860cf0e0244aee5e585e7
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-09-28 15:03:14 +0530

    undoworker for hadling the rollback

    This patch introduces two type of workers the discard-worker and
    the undo-launcher. The discard worker's main responsibility is
    to discard the older undo and the undo-launcher will process the
    rollback hash table and launch undo-worker one for each dbid.
    The undoworker will take the database connection and start
    processing all the request for that db.  Once the undo-action is
    applied than it will mark the transaction header in the undo as
    processed and remove the entry from the rollback hash table.

    Dilip Kumar Reviewed by Amit Kapila

commit 93ed5d44e3f9c62b78fa651d7a9082cfc57791f6
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-09-25 13:28:47 +0530

    Fix some TPD issues

    1. Introduced Asserts for ZHEAP_METAPAGE before calling ZheapInitPage.
    Metapage should not be initialized using this method.
    2. Introduced Asserts to identify zheap metapage after reading the same.
    3. Fixed tpd_desc.
    4. In TPDPageAddEntry, we shouldn't shuffle the item pointers.
    5. In TPDAllocatePageAndAddEntry, when new page is not added, we
    shouldn't over-write previous and next block number in tpd opaque space.
    6. Set LSN in page header for meta page.
    7. For PageSetUNDO while locking a tuple, send set_tpd_map_slot=false.
    8. Properly initilize fist and last tpd page in meta page.
    9. In zheap_xlog_update, send proper undo pointer in TPDSetUNDO.
    10. Fixed the storage of old tpd slot in xlrec.
    11. Fixed compactify_ztuple memory overrun issue.

    Patch by Dilip Kumar and me. Reviewed by Amit Kapila.

commit 8683fff396da98ad00ae3b853714b0788bff99b6
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-09-27 16:54:01 +0530

    Fix compiler warnings in xact.c

commit 3f86bb91ece478ab9ab562cc1972bb85d9f2a965
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-09-26 15:32:12 +0530

    Introducing sub-transactions lock type in zheap

    With this patch, the sub-transactions will have a new type
    of lock for them. Now, instead of waiting for top-level
    transaction lock, the tuples are free once the sub-transaction
    is committed. This way, we neither waste our transaction-slots
    by assigning transaction ids to sub-transaction, nor we suffer
    in performance by waiting on top-level transactions.

    Patch by Amit Kapila and me.

commit f0a2c8247aad9fe1569709599c5b267f473a6024
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-09-25 17:22:41 +0530

    Bugfix in inserting the undo record when previous transaction and
    the current transaction are in different undo logs.

    Earlier it was just comparing the block number to find whether
    we have already read the  buffer or not, but that's not
    enough when we are comparing block no. which are in two different
    undo logs.

    Dilip kumar Reported by Thomas and Reviewed by Amit Kapila

commit 4060bd90a3a47dfc9e5b396b3071c9c4d6bd0dcd
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-09-25 17:17:48 +0530

    Add comment for specific handling of geting CID for inserted
    tuple with lockers.

    Dilip Kumar Reviewed by Amit Kapila

commit e5eee5471d739b1abf084feed6635c5a526e43b4
Author: Dilip Kumar <dilip.kumar@enterprisedb.com>
Date:   2018-09-25 14:15:21 +0530

    Fix compilation error

commit 0fe57bf56a54fecf31d7b810c47853ba8e00925b
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-09-25 13:26:05 +0530

    Fix zheap_mask declaration

commit 61226ffd40ad0841d6c1cd4bbf792ec9e85349ba
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-09-20 11:44:55 +0530

    Dont call GetTransactionSlotInfo for all visible tuple

    For all visible tuple, the corresponding slot can be re-used or pruned.
    Hence, we shouldn't call GetTransactionSlotInfo to retrieve the
    transaction information for the same slot.

commit 20c3244baba9a72530fc4747da962190a15623f2
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-09-25 12:04:00 +0530

    Check WAL Consistency for TPD and zheap meta pages

commit 5f8604946763e6b537f8f68f382b5da62a7d5a86
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-09-24 06:24:18 -0700

    Test fix, Allow inplace updates if the row can fit on the same page.

    By Mithun C Y Review Amit Kapila.

commit 0b83a48a01eb57ffd8a247c8adbe3c85de1d8d98
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-09-24 18:46:55 +0530

    Allow inplace updates if the row can fit on the same page.

    Currently, we perform inplace updates only when the new row is smaller than
    old row or if the old row is the last row on page and it has space after
    it. However, there are more cases where we can perform inplace updates:
    (a) If there's no free space immediately following the tuple, but there is
    a space in the page to accomodate the entire tuple. (b) If there's no free
    space immediately following the tuple, but there is a space in page to
    accommodate the delta tuple (new_tuple_size - old_tuple_size).

    We allow pruning function to rearrange the page such that it can make space
    adjacent to the tuple being updated. This is only possible if the page has
    at least space to support equal to (newtupsize - oldtupsize). Otherwise,
    also we try to prune the dead/deleted tuples to see if the new tuple can be
    accommodated on same page and that will allow inplace updates.

    To perform pruning, we make the copy of the page. We don't scribble on
    that copy, rather it is only used during repair fragmentation to copy the
    tuples. So, we need to ensure that after making the copy, we operate on
    tuples, otherwise, the temporary copy will become useless. It is okay
    to scribble on itemid's or special space of page.  While rearranging the
    page tuples will be placed in itemid order. It will help in the speedup of
    future sequential scans. Note that we use the temporary copy of the page to
    copy the tuples as writing in itemid order will overwrite some tuples. We have
    also changed the patch such that REDO will perform repairfragmentation only if
    we it has been done during DO operation.

    Amit Kapila, Mithun C Y.

commit 85262536130fbf40afb96b4d7a64692d31171cc5
Author: edb <edb@Laptop220.pn.in>
Date:   2018-09-19 09:57:29 +0530

    Fix compiler warning in tpd.c

    Reported by Mithun

commit de73a4d3c89af83d08f3e2822f0ad07090d89f77
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-09-18 19:46:36 -0700

    Bugfix in vacuuming zheap table.

    The function count_nondeletable_pages is using vac_strategy variable
    defined for heap even when it is called for a zheap relation. This
    patch fixes it to use zheap's vac_strategy variable.

    Reported by Neha Sharma, fix by Mithun C Y, review by Amit Kapila.

commit 92fdaf6736bd975fcf6fba3486e2578781c16404
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-09-18 19:36:25 -0700

    Remove no longer needed fixme comments on visibility map.

    Reported by Amit Kapila.

commit 2509bd2e93e2cc16f4555cd2112895badc304471
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-09-18 19:35:15 -0700

    Bug fix in execute_undo_actions_page.

    ove ZheapInitPage after XLogInsert, as TPD related information in
    page are needed by some of the functions called before.

    By Mithun C Y and Amit Kapila.

commit c5817d6ade8c1ba423bb0d04f983a65e718138d0
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-09-18 08:10:04 +0530

    Support variable sized TPD entries.

    We extend the TPD entries when (a) while reserving a slot, we found that
    there aren't enough slots in TPD entry or offset-map doesn't have much
    space, (b) while getting the existing TPD entry we found that offset-map
    doesn't have enough space. If we find the space in the same TPD page, then
    we perform inplace update of the TPD entry, otherwise, a non-inplace-update
    is performed. In non-inplace-update, we mark the old entry as deleted and
    later during pruning, if we encounter any deleted entry, we directly prune
    it.

    Currently, the implementation of in-place updates is not complete, so we
    always perform non-in-place update.

    Patch by Amit Kapila, Dilip Kumar and Kuntal Ghosh.

commit f17c96014308f8f01385a82e41be8601073d147e
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-09-14 16:43:14 +0530

    In replay of freeze_xact, read TPD buffer before using it

commit 40ce6e610d138de1ebb2944ce619db9f53df61f1
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-09-14 12:39:18 +0530

    Fix a flag in xl_zheap_lock

    In xl_zheap_lock flags, we've skipped the second bit for no good reason.

    Reported by Dilip Kumar.

commit 58000e7691eda261ddc99566f24b03692bf2b19a
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-09-13 17:51:11 +0530

    Implement serializable isolation APIs for zheap

    For PredicateLockTid, ConflictIn and ConflictOut, we pass the tid to
    identify the tuple.

    For conflict out, we've introduced a function ZHeapTupleHasSerializableConflictOut
    that performs all zheap related work to figure out whether the reader
    conflicts out with any other writers. In ZHeapTupleHasSerializableConflictOut,
    we refetch the tuple and check the recent status of the tuple. Using
    that, we decide whether we conflicts out.

    We've a special handling for the tuple which is in-place updated or the
    latest transaction that modified that tuple got aborted. In that case,
    we check whether the latest committed transaction that modified that
    tuple is a concurrent transaction. Based on that, we take a decision
    whether we have any serialization conflict.

    Patch by me with help from Amit Kapila. Reviewed by Amit Kapila and
    Thomas Munro.

commit b401a9c4da9e9038a0a72e4c31f31ba87bd43dbb
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-07 19:49:32 +0530

    Make serializable code independent of storage

    This code aims to make PredicateLockTuple, CheckForSerializableConflictIn
    and CheckForSerializableConflictOut independent of storage tuple.
    PredicateLockTuple and CheckForSerializableConflictIn method can
    work with tid only. However, CheckForSerializableConflictOut requires
    the storage tuple to check latest visibility status of the tuple. Hence,
    I've separated the *SatisfiesVacuum and its usage towards conflict
    resolution in a separate storage specific function.
    I've also renamed PredicateLockTuple to PredicateLockTid.

    Patch by me. Reviewed by Amit Kapila and Thomas Munro.

commit 44d776147cdafc55ea3fe95569bb039352e580ac
Author: edb <kuntal.ghosh@enterprisedb.com>
Date:   2018-09-10 21:27:38 +0530

    Change behaviour of zheap_fetchinsertxid

    Earlier this function was returning xid which has inserted the tuple.
    But, the tuple can be inserted by multi_insert and inplace-update
    operations as well. Hence, we should handle that.

commit e5b821e0cfc905ea32e11a9619cf797de2342104
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-09-06 18:28:49 +0530

    Modifying the size of rs_visztuples in HeapScanDescData

    The size of rs_visztuples was kept to a fixed value which was causing
    the failure in regression suite when running with increased blocksize.
    Now, it is modified to the value of MaxZHeapTuplesPerPageAlign0.

    Patch by me, reviewed by Amit Kapila.

commit 0136ec40cb54df56f52af626df680ae5981e8fd3
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-09-06 17:07:53 +0530

    Bugfix in toast table updation

    Patch by me and reviewed by Amit Kapila

commit e12bb90c6751d60564535a7effc8e08994d61f3c
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-09-03 11:32:30 +0530

    Fix compilation warning in test_undorecord.c

    Reported By Amit Kapila.

commit c11609baa42bd0332bc90a97a2d27814a66346b9
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-09-03 15:43:14 +1200

    Reorder handling of ONCOMMIT_TEMP_DISCARD.

    The previous coding accidentally caused ONCOMMIT_NOOP to enter the
    new ONCOMMIT_TEMP_DISCARD case.

    Patch from Rafia.

commit 16a7bf70c67dae185d74e5cd988af8bb6d2bb4fd
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-09-02 05:02:57 +1200

    Fix test_undo undo_append_file() procedure.

commit 6f94ac34370ffd305bf702fa514136eab98e43f7
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-23 22:46:34 +1200

    Delete undo log files in dropped tablespaces in recovery.

    When a tablespace is dropped, we clear out any remaining undo log files.

commit c7e00a820e5daaa3c7a268cdae195a859c5476af
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-23 18:43:50 +1200

    Handle missing undo log segment files during WAL replay.

    In recovery, segment files may not be present because they will be deleted
    by later WAL records.  Following the example of regular relation files, we'll
    supply empty files.

    Previously, I created unexpectedly missing files during startup, which
    didn't work correctly if we crashed after dropping a tablespace (I couldn't
    create the files in the tablespace directory if it has already been
    deleted).  This new approach does what other PostgreSQL code does, and
    creates a new tablespace directory as required (expecting it to be deleted
    by a later WAL record).

    Thomas Munro

commit 3bbf152f4d330e582e950a45790d0e375d93bc5c
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-08-26 14:11:59 +0530

    Fix thinko in assert.

commit 1e9d17cc2406683b014f872ce873c845adafe3af
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-08-26 14:10:21 +0530

    Fix discrepancy between ZHeapTupleSatisfiesUpdate and

    HeapTupleSatisfiesUpdate also for the non-inplace update, it was trying to
    fetch the cid from the prev_undoptr but in case of non-inplace update it will
    not find the previous version of the undo so get the cid while copying the
    tuple.

    Dilip Kumar, Amit Kapila  Review and tested by Ashutosh Sharm

commit 4cc08c3ee0c31346af8c8a02a45a7bb759c3ed68
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-10 22:24:22 +0530

    Refetch tuple after reserving slots in the page

    When we reserve a slot in the page, we sometimes freeze some tuple in
    the same page. Hence, we should re-fetch the tuple to update the slot
    information.

    Patch by me. Reviewed by Amit Kapila.

commit 056a37b464058d6c386b6337ad65589f15c1a9b3
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-10 16:49:11 +0530

    An optimization for temp tables

    For temp relations, we don't have to check all the slots since
    no other backend can access the same relation. If a slot is available,
    we return it from here. Else, we freeze the slot in PageFreezeTransSlots.

    Note that for temp tables, oldestXidWithEpochHavingUndo is not relevant as
    the undo for them can be discarded on commit.  Hence, comparing xid
    with oldestXidWithEpochHavingUndo during visibility checks can lead to
    incorrect behavior.  To avoid that, we mark the tuple as frozen for any
    previous transaction id.  In that way, we don't have to compare the previous
    xid of tuple with oldestXidWithEpochHavingUndo.

    Patch by me. Reviewed by Amit Kapila.

commit 10c225fbd9a3aa8239efaf8cf6d00e8b7e9d589d
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-10 13:50:15 +0530

    GUC to enable/disable undo launcher

    We've introduced a new GUC variable called disable_undo_launcher
    to enable/disable the undo launcher process. If true, the postmaster
    won't register the undo launcher. By default, it's set to false.
    This is a postmaster option. Changing the value requires a restart.

    Patch by me. Reviewed by Amit Kapila.

commit e613fa25d714ddba99f2b3675894f3d0d141df4f
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-08-23 16:40:35 +0530

    Undorecord cleanup.

    Created two files undorecord.c and undoinsert.c where undorecord.c
    mainly deals with how to insert and read the undo record and the
    undoinsert.c provides external interfaces to prepare,insert and
    fetch undo and deals with buffers management required for undo record.

    Dilip Kumar Review by Amit Kapila

commit dccab1c216d8677bb6ad716e13adc08da44f79a9
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-08-23 10:39:53 +0530

    bug fix in pg_control_checkpoint

    Reported by Andres

commit 6d3f5716cb4257e8226212fbe002f05cc0d60145
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-17 18:54:13 +0530

    Fix issue in vmbuffer wal replay

    While logging visibility map changes for zheap, we don't register
    the zheap buffer. That's intentional since we don't set any hint bits
    in zheap buffer for tracking visibility. But, we've to store the block
    number in WAL so that we can track the block number for setting the
    corresponding visibility map bit while replaying the WAL for the same.

commit 9fc32f608a0900f8ed051cc010e72a40abe318ac
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-20 14:39:05 +0530

    Fix prevxid for insert/multiinsert WAL replay

    We should set the prev xid as frozen during WAL replay of insert and
    multiinsert.

commit 9fcccee5d272c437a898171a4a97317ba1430ee0
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-20 16:25:02 +0530

    Fix slot index in undo_xlog_reset_xid

commit 0047fe43fe0fa5a10833d7f864d81b6a2e4ac4ed
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-17 17:59:59 +0530

    In zheap_update, fix WAL record for lock tuple

    This is leftover of commit 9b1f493a6335d07024. In zheap_update, we also
    lock the tuple. Hence, we need to fix the transaction slot related issue
    that was fixed as part of the above-mentioned commit.

commit e5f5c83c3120ac90c0a8501a584935a0ceb782f4
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-16 16:13:10 +0530

    Lock undo buffer while preparing an undorecord

    Currently, we're locking the undo buffers in InsertPreparedUndo. This
    is called under critical section. If we encounter any error while
    taking the lock under critical section, it'll lead to server crash. We
    can easily avoid this situation by taking the lock in PrepareUndoInsert.

commit 25593d3c8351df93c9d5d57ec5b88ba94f10df7a
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-08-21 11:37:09 +0530

    Bugfix in temp table rollbacks

    If rollback_oversize is set to zero then rollbacks of temp tables
    were pushed to RollbackHT. This is corrected to perform the
    rollbacks by the backend itself.

    Reported by Neha Sharma, patch reviewed by Amit Kapila

commit 420810a9cc500cdc539d34e8e4e49296337453e8
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-08-20 12:00:03 +0530

    Bugfixes in UserAbortTransactionBlock

    - If rollback request could not be pushed, then backend executes
    the undo actions.
    - Corrected arguments for PushRollbackRequest.

    Reported by Dilip Kumar.

commit 771f43b086060f2b1bba25a857693886aa0ef4e9
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-08-19 19:21:41 -0700

    Bug fix, In lazy_cleanup_index and lazy_vacuum_index we shall use
    vac_strategy passed to it by either zheap or heap relation.

    By Mithun C Y, reviewed by Amit Kapila.

commit bd0b43b93ed204749347d3c885ee258942cc8221
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-08-17 15:55:22 +0530

    Bugfix for speculative insert in toast table

    Reported by Kuntal Ghosh, reviewed by Amit Kapila

commit cb36f7e7e848cfb11a5062684451788a41f048f9
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-08-17 15:53:50 +0530

    Bugfix in ZMultilockers

    Found as part of a bug reported by Neha, reviewed by Amit Kapila

commit 22e1c1c33e1e5ed129de8fbfa539d943ae42c844
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-16 13:46:54 +0530

    For insert/multi-insert, set previous xid as frozen

    When we modify a tuple, we set the previous xid for this tuple as frozen
    if its previous modifier xid is older than the discarded xid. For insert/
    multi-insert, we don't have any previous modifier. Hence, we can set it
    as frozen unconditionally.

commit 9668bfac227acb13c87dcdf8a54e440aab768e07
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-08-16 09:32:43 +0530

    Indentation fix.

    Reported by Andres.

commit 45e405946ff54b5461fdeb7f2a4826c7a87a890a
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-14 17:14:23 +0530

    Use ZHeapTupleHasInvalidXact wrapper consistently

commit 043603d58f4dfc4bd8b1f7ddaa4f2c73e5713f24
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-14 17:12:46 +0530

    Update regression tests file in pageinspect

commit 4d0a2ebf9e8bc40f44430174d9990b26b473405c
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-14 16:19:35 +0530

    Bugfix in zheap_update for non-inplace updates

    For non-inplace, we should always mark the tuple as locker-only
    if we're propagating the key-share lock to the new tuple.

    Reported by Rafia Sabih. Reviewed by Amit Kapila. Patch by me.

commit 1b8c7eba990341809096a245937c48e2fdb875d2
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-14 14:49:36 +0530

    Fix bug in regression tests for pageinspect

    The previous commit of pageinspect forgot to attach the zheap.sql
    and zheap.out file required for regression tests.

commit 02d983e5a5b4a6e2b76b59023668a98457465060
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-08-14 13:43:31 +0530

    Propagate lockers information.

    We were not propagating the lockers information when the tuple has
    multi-lockers bit set.  Fix it.

    Reported by Ashutosh Sharma, Patch by Amit Kapila.

commit b16f0fec8868482773d5a7bc37ec9369dcfaa476
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-14 10:52:08 +0530

    In bitmap scan, don't keep the pin on the buffer

    For bitmap scan, we always use pagemode to scan the tuple. Hence, there
    is no need to keep the lock on the tuple.

commit 191d6f03c143097d63e17e057935a30f3a4db6bc
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-08-13 15:25:56 +0530

    Bug fixes

    - fixes for incorrect retieval of TPD buffer
    - fixes for incorrect size calculation of undo-header at recovery time
    - fix for accessing an uninitialised variable in TPDPageGetTransactionSlots
    - fixed one space issue in zheapamxlog.c

    Came across these while working on an issue reported by Neha Sharma.
    Reviewed by Dilip Kumar

commit 5fcf8c59430fe4ae105d544d9f406c1e7e3e3959
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-08-10 17:34:05 +0530

    Bug fix in undo action

    When previous version of the tuple has the TPD slot that time
    we need to pass a flag to the function so that it can set the
    tpd slot in the offset map.  Mistakenly that option was always
    passed as 0.

    Dilip Kumar Reviwed by Kuntal Ghosh

commit ef717922bb7f357a772e2f274766e1d1049beb37
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-08-10 15:27:29 +0530

    Fix Typo

    Reported by Andres.

commit f68d2c8862ee2f0981ccbc767c1435cca647b804
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-08-10 09:35:12 +0530

    Allow in-place updates for some expression indexes.

    This is a zheap port of commit c203d6cf81b4d :
    "Allow HOT updates for some expression indexes."

    Since we can do HOT udpates for such expressions, allow in-place
    updates for the same expressions.

    Add a new regression test zheap_func_index.sql derived from the
    existing test func_index.sql. The new test uses
    pg_stat_get_xact_tuples_inplace_updated().

    Amit Khandekar, reviewed by Amit Kapila.

commit c5e306aa3afc6b8ac2975be699772c76734d0ff0
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-08-10 09:24:10 +0530

    Add a pg_stat function for inplace updates in a transaction.

    There was already a pg_stat_get_tuples_inplace_updated() function for
    getting in-place updates in a session. But the _xact_ version was
    missing.

    Amit Khandekar, reviewed by Amit Kapila.

commit 24c5086eb332d3e0549238f25641887c9c9d03fb
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-06-25 20:22:29 +0530

    Add pageinspect functions to analyze zheap page and zheap tuples

    It adds two functions zheap_page_items to inspect the tuples in
    the page. It also adds another function zheap_page_slots to inspect
    the transaction slots in the special space. If the page contains
    TPD slot, then zheap_page_slots doesn't show the same since it
    doesn't contain any transaction information.
    TPD slot information can be shown in future once the structure of
    TPD page is stabilized.

    Patch by me, reviewed by Ashutosh Sharma

commit a8442adccf916a5de5c79f4c8a155cc6d4fe9919
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-08 17:28:47 +0530

    Initialize some local tuples in zheap scan APIs

    It also fixes a bug in zheapgetpage. We should not copy the tuple
    for deleted item pointers.

commit abb680be862a99fc23b3abfa28f159b545eba5e6
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-09 14:22:37 +0530

    Fix some compiler warnings

commit 11b199c7d779a2beb6ba9217303d4b73359665c2
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-08-09 11:39:09 +0530

    Allow freezing and reusing of the TPD slots

    Currently, for zheap pages we allow to freeze slots of the
    the all visible xids and also allow to reuse the slot of the
    committed xids.

    This patch is implementing the same for the TPD slots. The mechanism
    of the freezing and reusing the tpd slots are same as for the
    zheap page slots.

    Dilip Kumar reviewed by Amit Kapila

commit 67ca8248109f52c10f06347ac82ab20693547b7f
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-08-09 12:04:50 +0530

    Remove unnecessary changes related to zheap from RelationGetBufferForTuple.

    Now, that we have a corresponding separate function for zheap, we can remove
    the zheap related changes from the function RelationGetBufferForTuple.

commit e18858cffcbf964d7cf3aab7a087673bd492652b
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-08-09 11:22:40 +0530

    Bug fix in execution undo action

    Set the proper slot on the TPD offset map while replaying undo actions
    if the prior version of the tuple is pointing to the TPD slot.  Prior
    to this we are simply overwriting the older tuple version but the slot
    is not updated in the TPD offset map.

    Dilip Kumar review by Amit Kapila

commit db2d9ae8a2c609e2535932b1bbcc9bb9181ca7b8
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-08-08 22:10:29 -0700

    Post push fix for 2c9d6d9216ad28be2 which by mistake resued
    a flag value.

    By Mithun C Y

commit 2c9d6d9216ad28be25b5e4d60c07f5fb2db6096b
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-08-08 21:49:15 -0700

    Bug fix, move calls of visibilitymap_pin or visibilitymap_status
    outside the critical section at execute_undo_actions_page.

commit 7b799efee32450a93b5200774d3550893d4049e0
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-07 10:44:00 +0530

    Handle whether a tuple is self-locked before modifying it

    While deleting/updating a tuple, we should check whether the tuple
    is already locked in desirable lockmode by the current transaction.
    We've missed this check in zheap_delete/zheap_update when the tuple
    is marked with multilocker flag.

    Patch by me and Dilip Kumar. Reported by Thomas Munro.

commit b51357225493b0436bedece52075de58334d3abd
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-07 14:14:24 +0530

    Fix a bug while fetching a pruned tuple from all-visible page

    In zheapgetpage, when a pruned tuple is fetched from an all-visible
    page, we return NULL (and we should return NULL). But, in page-scan mode,
    we increase rs_ntuples by mistake.

commit 2b9bb36f1a7bdcf1e2792e31d943fad3bbc9fa8b
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-08-07 08:54:58 +0530

    Fix various bugs in TPD with multi-lockers
    - Locker is setting wrong slot in TPD offset map
    - Locker is not calculating proper TPD slot for members.

    Dilip Kumar Reviewed by Amit Kpila

commit 3967b9019e051842c2947aa0333c4938facdb636
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-08-06 16:02:02 +0530

    A minor bug fix in TPD code, missing break statement in switch case

    Reported by Andres.

commit 7949de7ff8bd4cd9d99f5cd81ad1211af5a55c7e
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-08-05 05:58:36 -0700

    Support visibility map for zheap.

    With the support of visibility map for zheap relation, vacuum task
    and Index Only scan can skip looking into all visible pages. Also,
    on page flag PD_ALL_VISIBLE is no more in use for zheap.

    Index Only scan for zheap is enabled with this patch.

    By Amit Kapila, Mithun C Y

    Review by Amit Kapila.

commit 585226697f91c61926361ad565a10f7a78144ad5
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-08-03 12:44:03 +0530

    Pass the right priorXMax to ValidateTuplesXact()

    In zheap_get_latest_tid(), ZHeapTupleGetTransInfo() was getting called
    with 'resulttup'. But because 'resulttup' is returned from
    ZHeapTupleSatisfiesVisibility(), it can be a tuple generated from an
    undo record. And if we use ZHeapTupleGetTransInfo() to get the xid
    that modified resulttup, it returns the xid that created the original
    tuple instead of the xid that modified the tuple. This results in
    the wrong xid being passed as priorXMax to ValidateTuplesXact(), which
    in turn leads to assertion failures.

    So move the ZHeapTupleGetTransInfo() call before
    ZHeapTupleSatisfiesVisibility() call, so that we could use 'tp' rather
    than resulttup. 'tp' gets freed by ZHeapTupleSatisfiesVisibility(), so
    we could not use tp after ZHeapTupleSatisfiesVisibility() call.

    Added a new isolation test.

commit 7ad7a9aedaf883e02caf5b172374344faa4507b8
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-02 19:44:07 +0530

    Fix some compiler warnings

commit db8af0bf6388182415d0cbcde55882a1bf8de84c
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-02 14:18:00 +0530

    Report the scan location for zheap meta page

    During scan, we report our scan position for synchronization
    purposes. We do this before checking for end of scan so that the
    final state of the position hint is back at the start of the
    rel. But, if we skip metapage, the scan location may point to a
    block at the end of the relation.

    Patch by me, reviewed by Amit Kapila

commit caf343183b8940670f9f953014f6815883f9f66c
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-08-02 14:14:50 +0530

    For parallel scan, find and set the scan's startblock

    Probably, we've missed this change during earlier rebase.

commit ec6c8b936c6de6af49816e29dd04ebc363aad5e6
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-07-26 16:43:44 +1200

    Fix silly bug in undolog_xlog_discard().

    When an XLOG_UNDOLOG_DISCARD record is replayed, we need to tell the
    checkpointer to forget about any files that we are about to unlink.
    I was using the wrong variable, so if a single XLOG_UNDOLOG_DISCARD
    record caused segment files 1, 2, 3 to be unlinked, I was telling it
    to forget about fsyncing 3, 3, 3.  Then it would eventually try to
    fsync 1 and 2 and try to raise an error.  Repair that.

    Additionally, in the error path resulting from the above bug, I was
    also calling FilePathName() on a File that I had failed to open.  That
    causes an assertion failure.  Repair that too.

    Thomas Munro, reported by Neha Sharma, RM43571

commit 9d8be03646a5775000e1008badcabf0a5ff828bc
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-07-26 17:56:27 +1200

    The startup process shouldn't attach to undo logs.

    When replaying XLOG_UNDOLOG_META records, the startup process was
    recording that it was attached to the referenced undo log.  That
    caused corruption of the freelists when it tried to detach on exit.
    During recovery we shouldn't attach at all; instead we use the
    xid->undo log mapping.

    Thomas Munro, RM43614

commit adaaac4518c68b378ec2c60a2a8b29353de6b190
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-08-01 11:52:41 +0530

    Toast table support for zheap

    Now, toast tables for zheap tables are created of zheap type. This imporves the
    performance in terms of memory by reducing the bloat in toast tables. With zheap
    type toast tables, as soon as a transaction deletes a tuple and commits, the space
    can be utilised for the next insertion. Since, toast tables are larger in size
    compared to ordinary tables and their updation is handled by insertion + deletion,
    zheap storage is likely to benefit significantly.

    Reviwed by Amit Khandekar and Amit Kapila.

commit b2509b38661f97c1e1308a5b043a1f34d4d9ebeb
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-08-01 11:46:12 +0530

    Bugfix in GetLockerTransInfo

    The initialization of trans_slots was missing.

commit b455083f2a902df76ba43e38fb16260fd26fb4f0
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-31 16:21:47 +0530

    In zheap, we cannot ignore trans status of backends executing vacuum

    For zheap, since vacuum process also reserves transaction slot in page,
    other backend can't ignore this while calculating OldestXmin/RecentXmin.

commit df3e6a10a3ba9c5fe81dd80fc1bfd105b7b42478
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-31 16:15:23 +0530

    During vacuum, reserve sufficient offsets in tpd page

    In lazy_vacuum_zpage_with_undo, we should allocate sufficient space
    in tpd page to store the highest unused offset from zheap page.  Since,
    we've to reserve space before determining the unused offsets, we reserve
    space for maximum used offset in the zheap page.

commit 58e36c8929684198c40bb326cfb455e719b7a11d
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-07-31 14:51:17 +0530

    Support pruning in TPD pages.

    The basic idea is process all the TPD entries in the page and remove
    the old entries which are all-visible. We attempt pruning when there
    is no space in the existing TPD page. Also, while accessing TPD entry,
    we can consider the entry as pruned, if we find that the
    ItemIdIsUnused or the block number in TPD entry is different from the
    heap block number for which we are accessing the TPD entry.

    Amit Kapila with help from Dilip Kumar.

commit 1c37ab83d083241d8738444980ca5510e8e5deb0
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-07-31 14:23:08 +0530

    Store Itemids in TPD page.

    Earlier heappage always point directly to the actual offset of TPD
    entry in a TPD page.  This won't work after pruning as even if the
    particular page's TPD entry is not pruned, we might not be able to
    directly access the TPD entry as offset might have moved. Now, we can
    reach our TPD entry if we can traverse all the TPD entries and TPD
    entry has block number in it, but that is quite inefficient.  To
    overcome this problem, it is better to store Itemids in the TPD page.

    Amit Kapila, reviewed and verified by Dilip Kumar

commit ed01319cc1d9541b3293b051d3d91eb35b7c448d
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-07-31 18:43:17 +1200

    Improve smgr README.

    Wordsmithing.

    Thomas Munro

commit 99f54c695641304061847f6124f04fc9f82a5317
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-07-31 18:33:22 +1200

    Add missing case to undolog_identify().

commit 9a956e391937f685fd3284620c0c6796362cfdf0
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-07-31 18:30:04 +1200

    Add basic undo log storage tests.

    Exercise basic undo log storage code under make check-world.

    Thomas Munro

commit 576f60e34994d4e5777c3e1e17c9987199c46a1f
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-07-27 17:55:32 +0530

    Discard temp table undo logs for zheap

    At the commit of a transaction, backend discards temp table undo
    logs.

    Reviewed by Dilip Kumar and Amit Kapila

commit c61887386927699c1f40c8ad2da0bb49948d38eb
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-27 17:21:48 +0530

    In zheap_update, fix condition for reserving slots.

commit 142f2a014312c668eddc20d9a43d5c81baa48675
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-27 12:37:02 +0530

    An optimization to improve COPY FREEZE in zheap

    In COPY FREEZE, when we insert a tuple, we always mark it as frozen.
    Hence, there is a possible performance optimization for the same scenario:
    1. We can skip inserting undo records for the tuples to be inserted.
    2. There is no need to reserve a transaction slot.

    Here is the implementation details:
    1. Set skip_undo = true if HEAP_INSERT_FROZEN is mentioned.
    2. If skip_undo is true, we don't have to reserve a transaction slot in
    the page. Also, we skip preparing and inserting undo records for the
    to-be-inserted tuples.
    3. For recovery, a new WAL flag XLZ_INSERT_IS_FROZEN is introduced. It's
    true if HEAP_INSERT_FROZEN is mentioned. During WAL replay, we skip preparing
    and inserting undo records if XLZ_INSERT_IS_FROZEN is set in WAL records.

    Patch by me. Reviewed by Amit Kapila.

commit 3dd753713bfdedebd5d38cdd709d61f4cf97b60e
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-06-22 12:46:15 +0530

    Cosmetic changes in zheap_multi_insert and zheap_xlog_multi_insert

    This commit removes the usage of undo record information at other
    places in the same function. This makes the coding easy when we
    intend to skip undo insertions.

    Patch by me. Reviewed by Amit Kapila.

commit bf8288d70bad7da53ea6ab3457ac234ca08ff4f9
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-27 16:29:44 +0530

    In ZHeapGetVisibleTuple, fetch transaction slot correctly

    When we call GetTransactionSlotInfo to fetch the transaction info
    from undo, we should pass TPDSlot=false since we fetch the slot
    from the item pointer. Item pointer never stores TPD slots.

    Reported by Neha Sharma. Patch by Mithun CY. Reviewed by Amit Kapila.

commit 0f4f8ad4b402ab3163c78691c70ebcf38cc54384
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-27 12:15:32 +0530

    In ZHeapGetVisibleTuple, handle non-mvcc snapshots

    Reported by Neha Sharma. Patch by me. Reviewed by Amit Kapila.

commit 8d395035cc9a711b6761006b5b2433aa4077ea12
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-27 11:12:05 +0530

    Fix some compiler warnings

commit 2a932c0c1580a699740b5628562f014381dd48c5
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-25 16:50:58 +0530

    Handle locked-only tuple in ZHeapTupleSatisfiesOldestXmin

    In ZHeapTupleSatisfiesOldestXmin, we can't take any decision if the
    tuple is marked as locked-only. It's possible that inserted transaction
    took a lock on the tuple. Later, if it rolled back, we should return
    HEAPTUPLE_DEAD, or if it's still in progress, we should return
    HEAPTUPLE_INSERT_IN_PROGRESS. Similarly, if the inserted transaction
    got committed, we should return HEAPTUPLE_LIVE. The subsequent checks
    in the function already takes care of all these possible scenarios,
    so we don't need any extra checks for locked-only tuple.

commit bca6d63cdc78fd8e8d5804b0296b2d1c436af7d5
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-07-26 17:52:14 +0530

    Fix bug in prepared transaction.  StartPrepare is only copying
    the first member of the array instead of copying whole array.

    Dilip Kumar Reviewed by Amit Kapila

commit 199b463c81cb253b4bb77645629dc9b621ab865c
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-07-26 17:51:43 +0530

    fix the regression test for the zheap.

commit 85b792b7a12c91e59abe0189e79587fd516ea1c2
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-07-26 17:49:08 +0530

    Create an auxiliary resource owner for the undoworker because now
    we need to have valid resource owner for accessing the buffer.

    Dilip Kumar Reviewed by Amit Kapila

commit f41d0055f5129b99530f1fc0f612b21627e816b2
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-25 12:09:10 +0530

    Handle single in-progress locker in ZHeapTupleSatisfiesUpdate

    For single in-progress locker, ZHeapTupleSatisfiesUpdate returns
    locker's xid and transaction slot along with latest modifier/inserter's
    xid and transaction slot. We also send the single locker's trans info
    and latest modifier/inserter's to compute_new_xid_infomask.

    Kuntal Ghosh and Amit Kapila

commit afe785f273dfbb393c0026677e00c32296e7406e
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-07-25 09:06:26 +0530

    Rollbacks of zheap temp tables

    We diligently take care to never push the rollback requests to
    undo worker for temp tables and the backend itself performs the
    required undo actions.

    Reviewed by Dilip Kumar and Amit Kapila

commit 9282d623ae17a9ff3f15e5e8e000150a8aee6011
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-07-23 18:41:22 +0530

    Undo actions is not executed in many cases when failure occurs during
    commit/abort path.  This commit fixes the same.

    Dilip Kumar Reviewed by Amit Kapila

commit 3ac8b197c0f12f91f0f8f93426e818f902036c1e
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-07-23 17:02:02 +0530

    Bug fix in PushRollbackHT

    In PushRollbackHT, if the start_urec_ptr is not given then
    get it from the log, as done in execute_undo_actions.

    Reported by Neha Sharma.

commit 5c599edf74c44a02332ed50ee939bf974bde6fef
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-19 16:43:19 +0530

    Remove unnecessary GetTransactionSlotInfo() call

commit e68f8d97ecbdf730fdd910b0e683542684c6c9d8
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-07-19 08:34:50 +0530

    Fix Rollback of multilockers.

    Uptill now, on rollback, we never change the slot of tuple if the
    multilockers flag is set on the tuple.  This is because we can't find
    the next highest locker (there could be multiple lockers with same
    lock level) even by traversing undo chains.  To overcome this problem,
    we come up with a new design where we ensure that the tuple always
    point to the transaction slot of latest inserter/updater.  For example,
    say after a committed insert/update, a new request arrives to lock the
    tuple in key share mode, we will keep the inserter's/updater's slot on
    the tuple and set the multi-locker and key-share bit.  If the
    inserter/updater is already known to be having a frozen slot (visible
    to every one), we will set the key-share locker bit and the tuple will
    indicate a frozen slot.  Similarly, for a new updater, if the tuple has
    a single locker, then the undo will have a frozen tuple and for multi-lockers,
    the undo of updater will have previous inserter/updater slot; in both cases
    the new tuple will point to the updaters slot.  Now, the rollback of a single
    locker will set the frozen slot on tuple and the rollback of multi-locker
    won't change slot information on tuple.  We don't want to keep the slot of
    locker on the tuple as after rollback, we will lose track of last
    updater/inserter.

    Amit Kapila, Kuntal Ghosh and Dilip Kumar

commit 143adfee5ad287dedc744e06eaae0c0ed390005e
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-16 17:14:54 +0530

    Small fix in GetTupleFromUndoForAbortedXact

commit dd2f4010834f885af0c2baffa16bc4f6cfeb0664
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-10 23:16:25 +0530

    Implement ZHeapTupleSatisfiesVacuum for pruning/vacuum

    For pruning/vacuum, we can skip the tuples inserted/modified by an
    aborted transaction. It'll be handled by future pruning/vacuum calls
    once the pending rollback is applied on the tuple. This optimization
    allows to avoid fetching prior version of the tuple from undo.

    Patch by me. Reviewed by Amit Kapila.

commit d5d9f72eca46bc01efea01f3236f1a3d279459d7
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-16 16:45:29 +0530

    Handle aborted xact in ZHeapTupleSatisfiesOldestXmin

    If the latest transaction for the tuple aborted, we fetch a prior committed
    version of the tuple and return it along with prior comitted xid and status
    as HEAPTUPLE_LIVE.
    If the latest transaction for the tuple aborted and it also inserted
    the tuple, we return the aborted transaction id and status as
    HEAPTUPLE_DEAD. In this case, the caller *should* never mark the
    corresponding item id as dead. Because, when undo action for the same
    will be performed, we need the item pointer.

    Patch by Amit Kapila and me. Reviewed by Amit Kapila.

commit 3cc15be2061d294fe2762da471c321394bf06ebb
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-13 13:26:43 +0530

    In zheap, don't support the optimization for HEAP_INSERT_SKIP_WAL

    If we skip writing/using WAL, we must force the relation down to disk
    (using heap_sync) before it's safe to commit the transaction. This
    requires writing out any dirty buffers of that relation and then doing
    a forced fsync. For zheap, we've to fsync the corresponding undo buffers
    as well. It is difficult to keep track of dirty undo buffers and fsync
    them at end of the operation in some function similar to heap_sync.

    This commit skips copy_relation_data and copy_heap_data. We need to
    revisit the same once we implement ALTER TABLE.. SET TABLESPACE and
    CREATE CLUSTER/VACUUM FULL feature for zheap.

    Reviewed by Dilip Kumar and Amit Kapila

commit d261daaee572c0d6ea953948428a93eec95eee79
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-07-10 15:45:05 +0530

    Modified output file for triggers.sql for zheap

    When storage_engine = zheap, the behavior for one test case
    is different than heap. The difference in behavior is because
    of inplace updates in zheap and non inplace updates in heap.
    This changed behavior is acceptable for zheap, hence, adding a
    new output file for zheap.

    Reported by Neha

commit 1ca9a92cde64fcc798c5a0a5e7dbc0b8aae7454f
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-09 11:58:50 +0530

    Bug fix in UndoRecordAllocateMulti

    Reported by Neha, reviewed by Amit Kapila and Dilip Kumar

commit 2eb1df348fe34bd4d68b0892a5e63d6d8a9ddb47
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-07-09 11:57:45 +0530

    In recovery, transaction id should be sent in UndoSetPrepareSize

    Reported by Neha, reviewed by Amit Kapila and Dilip Kumar

commit c4b6cc166f11fbc22147e4f5567791ac9bbc572e
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-07-05 17:39:50 +0530

    Handling when a transaction span across undo logs and avoid single
    WAL logged operation to span across multiple log.

    The first part of the patch handle a case, when a single WAL logged
    operation which needs multiple undo records (e.g non-inplace update,
    multi-insert) we avoid it to go in multiple logs.  For that we first
    allocate all the undo required for the operation in one allocate call.

    And the second part handle the discarding and rollback when a transaction
    span across undo logs.

    Path by Dilip Kumar Reviewed by Amit Kapila.

commit 7ed998fd1d369ce8012cd69bed7b020a367c9294
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-07-03 12:14:47 +0530

    Handle changed relfilenode while executing undo actions.

    While an undo worker executes undo actions for a relation, the same
    relation can be truncated. In that case, RelidByRelfilenode() when
    called using the relfilenode saved in the undo record returns invalid
    relation oid. Use this behaviour to figure out that the relation is
    truncated, and abort the undo actions.

    Because this was not handled earlier, the algorithm in
    execute_undo_actions() failed to identify when exactly the undo
    records switch to new pages, and kept on fetching records, without
    releasing them, thus leaving behind those many records and their
    buffers unreleased. This eventually leads to "no unpinned buffers
    available" error in the server log. This was reproducible easily when
    truncate is run immediately after interrupting a long insert, and with
    shared_buffers set to minimum value.

    Amit Khandekar, reviewed by Amit Kapila.
    Reported by Neha Sharma.

commit a96820d722ca0244c8bd9a9749f18e5b2604c45d
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-06-28 09:42:58 +0530

    Prevent usage of uninitialized tuple during tuple routing.

    TransitionCaptureState.tcs_original_insert_tuple is of type HeapTuple,
    and it was assigned a tuple variable which remains unitinitialized in
    case of zheap table. Fix it so that the zheap tuple is converted to
    heap tuple and then assigned to tcs_original_insert_tuple. Fixed this
    in both ExecPrepareTupleRouting() and CopyFrom(). Due to this issue,
    trigger.sql regression test used to crash on some environments.

    Amit Khandekar, reviewed by Kuntal Ghosh.

commit 304dfa7af0547db1f22d72b30b42baa92647b136
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-06-27 20:49:04 -0700

    Fix compilation warning

commit 89c80035015098c563c104e31406dd23d483fc0f
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-06-13 16:49:04 +0530

    Change minimum transaction slots per zheap page to one

    We distinguish a zheap page from a TPD page by comparing the special
    page size. TPD pages always have 1 slot in its special space. Hence,
    we've to set minimum slot as two in zheap pages.

    Tested on Windows by Ashutosh Sharma

commit 1265603a63e90def6a1738f5cca962a13d59e43d
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-06-25 08:08:51 +0530

    Free payload data only when it is allocated.

commit 045032bdedff74d583bd54c68a1560f63b7cb967
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-06-21 06:24:13 -0700

    Isolation test for tpd patch.

    Patch by Rafia Sabih Reviewed by Dilip Kumar

commit 6bbe1f3fde618cf35f64da2726f1100963ba5576
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-06-21 06:14:12 -0700

    Post TPD commit fix.  After Rereserve the slot,  trans_slot is not
    set back to the new slot.  Ideally we should get the same slot but
    if our slot moved to TPD than it can be old_slo +1.  Also, removed
    the invalid Assert and converted to if condition.

    Patch by Dilip Kumar Reviewed by Amit Kapila

commit 3d3697e196c2f44eceaa07b77d00bc9d90ff0c19
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-06-21 16:32:10 +0530

    Support TPD which allows transaction slots to be extended beyond page
    boundary.

    TPD is nothing but temporary data page consisting of extended
    transaction slots from heap pages.  There are two primary reasons for
    having TPD (a) In the heap page, we have fixed number of transaction
    slots which can lead to deadlock, (b) To support cases where a large
    number of transactions acquire SHARE or KEY SHARE locks on a single page.

    The TPD overflow pages will be stored in the zheap itself, interleaved
    with regular pages.  We have a meta page in zheap from which all overflow
    pages are tracked.

    TPD Entry acts like an extension of the transaction slot array in heap
    page.  Tuple headers normally point to the transaction slot responsible
    for the last modification, but since there aren't enough bits available
    to do this in the case where a TPD is used, an offset -> slot mapping is
    stored in the TPD entry itself.  This array can be used to get the slot
    for tuples in heap page, but for undo tuples we can't use it because we
    can't track multiple slots that have updated the same tuple.  So for
    undo records, we record the TPD transaction slot number along with the undo
    record.

    This commit provides basic support of TPD entries where a fixed number
    of entries per page can be allocated in extended pages.  There is more
    to do in order to complete the support of TPD.  The remaining work
    consisits of
    1. Reuse transaction slots in TPD entry.
    2. Allocate bigger TPD entries once the initially configured slots or
    offsets are exhausted.
    3. TPD page pruning and once the page is clean, we can add it to the
    FSM.
    4. Find the free TPD page from FSM.
    5. Chain of TPD entries when the single TPD entry can't fit on a page.

    Amit Kapila with the help of Dilip Kumar and Rafia Sabih

commit 15536e74ed38ba970f30684850ad013d2174d6e8
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-06-20 04:31:51 -0700

    Move Assert to right place.

    By Mithun C Y review By Dilip Kumar

commit 9724bc889e4a99309e74912c739416c4345cd5d1
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-06-19 22:24:35 -0700

    Release restriction on page compactification.

    Previously a30d278e8d we did not allow compactification of page
    if it ever have deleted uncommitted tuple in it. This is not
    necessary and hence removing same.

    By Mithun C Y, review by Amit Kapila.

commit a07a3976029c6322cc3e3f954eae0cd606e776b2
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-06-18 05:29:17 -0700

    Fix bugs related to concurrency in zheap update

    While updating the tuple we might need to release the buffer lock and
    reaquire same. During that period where we do not hold buffer lock
    a concurrent process might have moved the tuple to undo and/or pruned
    the page. So whenever we reacquire the buffer lock check if
    itemid is deleted and readjust the position of tuple in page buffer.

    Patch by Mithun C Y and Amit Kapila.

commit 2448790b692e8f6581cce59b4d08abc977dbd20b
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-06-12 11:13:34 +0530

    In PrepareUndoInsert, don't call SubTransGetTopmostTransaction

    In PrepareUndoInsert, we always send the top transaction id. Hence,
    there is no need to fetch the parent xid for a transaction.

commit 4abb8ba5305ef04f7164be58f4c0c94b11ab793c
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-06-14 05:00:13 -0700

    LogUndoMetaData was called inside XLogBeginInsert, And,
    LogUndoMetaData iteself call XLogBeginInsert for inserting the
    meta WAL.

    Patch by Dilip Kumar

commit 7c44b88155a14186ca91ca010cf84d5f7be5fd93
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-06-14 04:54:20 -0700

    Conditions for rollback request push to worker was not consistant
    it should only be pushed for the top transaction.  Also, when there
    is an error in top transaction, then we will not have xid for the
    top transaction. So we have removed the xid based key for rollback
    hashtable.

    Path by Rafia Sabih Review by Amit Kapila tested by me.

commit 2797c4bc90ad986804b698a4eaa39991ffcf2094
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-06-14 15:37:44 +0530

    Implement stats for in-place updates

    Reuse the existing hot-update stat variable for in-place updates
    instead of introducing a new variable as that will increase the size
    of stats structure.  It appears ugly to overload the unrelated
    variable, but it is better to discuss in community before introducing
    a new variable.

    Beena Emerson, reviewed by Mithun C Y and me

commit 0b8ef5ea24a55c23d54821fa4bc3667319e84801
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-06-08 17:12:59 +0530

    Use high 4-bits of xl_info to store undoaction WAL operation type

commit 80e9fe40e186dac8ffbd4b9bf2479cb1fca4f770
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-06-11 13:04:33 +0530

    Pass '/c:' option with findstr command on Windows.

    Commit 3e9f07a8fe22 uses findstr command to remove the lines having
    "Options: storage_engine='zheap'" pattern from the results/*.out
    files on Windows platform but, it doesn't pass the correct option to
    findstr to ensure that only the lines having the given pattern gets
    removed form the results/*.out file.

    Ashutosh Sharma, Reported by Amit Kapila.

commit a600e4e055877dbb9071f40f215a8f8bb8662d79
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-06-08 17:00:07 +0530

    Buffer leak fix in zheap_insert

commit 303634f18969c53dc31b6668668232f327d7bed6
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-06-07 23:08:42 -0700

    During rollback we rewind the insert location, Now if the insert
    location is used by some other transaction then its updating its
    own next pointer with its own insert location resulting in cycle
    and due to that undo worker is stuck in this cycle.

    Patch by Dilip Kumar Review by Amit Kapila and Kuntal Ghosh

commit 6fe4dfdda5db82e0e24eeaefa4cdc63a3277be49
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-06-07 23:06:34 -0700

    ZHeapPageGetCid currently comparing with RecentGlobalXmin to
    identify the old undo, ideally it should compare with oldest
    xid having undo. Due to this it fetching many extra undo hence
    the performance of is low.

    Fix by Dilip Kumar review by Amit Kapila

commit 363c7aa95eeb35f57908ed7c777817cfa38a0f1d
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-06-04 22:09:13 +0530

    While performing undo, ignore out of range block numbers

    If a table is truncated just berfore performing undo actions on the same,
    it's possible to encounter out of range block numbers. In that case,
    we can safely ignore those block since we don't have to perform rollback
    on the same.

commit 7cd5b08da9380552376a69456ca11c6f97ce1a1c
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-06-07 17:32:52 +0530

    Store the information about lockmode in undorecord and initialize
    the flags variable in xl_zheap_lock to zero.

    Commit 0763c68645e9 introduced the support for different tuple
    locking modes and added the necessary changes in
    zheap_lock_tuple_guts() to store lockmode information in undo record
    but, missed to do the similar changes in zheap_update() due to which
    the undo record pointers for non-inplace updates were not the same in
    master and standby nodes thereby, resulting in an assertion failure.

    Additionally, commit f45251a37fe2 introduced flags variable in
    xl_zheap_lock to store transaction slot related information and did
    the necessary changes for it in zheap_lock_tuple_guts() but, missed
    to do the same in zheap_update().

    Ashutosh Sharma, reported by Neha Sharma, reviewed by Dilip Kumar.

commit 643bf383e77acb5eca372380267d01ed01d3a545
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-05-31 03:17:44 -0700

    Correct style issues in macro definition.

    By Mithun C Y comments by Robert Haas.

commit aaf09cb0491869b5d6e84e4cc68cfe28418ef6ad
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-30 15:37:24 +0530

    In zheap insert option, HEAP_INSERT_FROZEN should be used

    In zheap_insert/multi_insert, we can use HEAP_INSERT_FROZEN flag
    similar to heap to indicate the inserted tuple should be frozen
    after insertion.

commit 409cf3957bee5894cacc603670587476171277fe
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-05-30 01:42:43 -0700

    Applying pending undo action before modifying the page.

    Currently, if a transaction wants to update a tuple and we
    find that the other modifier is aborted and undo actions is
    not yet applied we simply modify the page, which will create
    an unpredictable behaviour as the execute undo action may
    rollback the changes made by our transaction.
    This commit first apply the pending undo action only for that
    page and then perform the changes.

    Patch by Dilip Kumar and Amit Kapila Reviewed by Amit Kapila
    Tested by Kuntal Ghosh

commit 736ff4cb26355992800792dc64954e55694a82fb
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-05-30 01:41:06 -0700

    Bugfix in condition check while applying the undo action.

    Earlier it was not collect when two undo pointer was in different logs.

    Patch by Dilip Kumar Reviewed By Amit Kapila

commit c708efefa812ffe54d94841b3c54c906b263a3da
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-30 12:00:01 +0530

    In zheap_update, don't propagate lockers when no lockers are present

    When no lockers are present, we should not propagate any locker
    related information to the newly inserted tuple.

    Patch by Dilip Kumar, reviewed by Amit Kapila and me.

commit 640c67490b76c096405fe38253ae222439707ba5
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-05-25 13:20:53 +0530

    Correct the insert and discard pointer of the undo log segment file
    when resetting the undo logs.

    Report by Neha Sharma, Initial Analysis by Ashutosh Sharma, Patch
    by Thomas Munro.

commit dc28828a8aa5a54fd8a5aced67c4a69cad84faf7
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-24 14:39:34 +0530

    Allow DML commands that create zheap tables to use parallel query

    This commit applies the required changes for zheap corrsponding to
    the commit e9baa5e9fa147e00a2466.

    Reviewed by Amit Kapila

commit be186ca7f02be4c8d88632bc9fff37d2a7680267
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-05-25 15:30:31 +1200

    Fix corruption of oldest_data.

    After commit 9ebe7511 it could be left pointing to space before log->discard,
    and we'd later try to read from there and possibly see a bunch of zeroes.

    Thomas Munro, RM43553, reviewed by Rafia Sabih

commit ba2406238eb93e400ac223a3d8e78097984072c6
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-05-25 08:31:46 +0530

    Fix the freespace recording by vacuum

    The freespace was not being updated till we have some deleted/dead
    tuples in the page.

    Report and initial analysis by Ashutosh Sharma, patch by me

commit ab0049c4bb174c332052b187ce60b3f01466bb18
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-24 11:11:40 +0530

    Revert last commit 853849138bf05bcac85

    We're already releasing the lock in function IsPrevTxnUndoDiscarded.
    Although, we could've released the lock in the same function where
    it was taken, but let it be as it is for now.

commit d7e1b3f1c30456b25fbbaa22ffa6bb9791f60a6e
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-23 16:38:33 +0530

    In PrepareUndoRecordUpdateTransInfo, release discard lock before leaving page

commit e329d580a973fcb41dc37b6283fc0db67e8262f3
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-21 12:28:12 +0530

    In execute_undo_actions, release undo records before exiting

    When undo record is discarded, we return from execute_undo_actions
    immediately. But, we should release the undo records and corresponding
    undo buffers collected earlier in the same function for rollback purpose.

commit 9dcdb6468df34f45b2975e5c4cac69a05ed27ac2
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-05-22 23:14:02 -0700

    Revert the restriction on page pruning.

    Revert code which disallowed pruning if there exist any open
    transaction on the page.

    Patch By Mithun C Y

commit 7023615ca40a2041e79863f56c2c1fa6b7c58cda
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-05-23 09:42:55 +0530

    Pass nobuflock=false to ZHeapTupleGetTransInfo().

    In zheap_get_latest_tid(), ZHeapTupleGetTransInfo() was called with
    nobuflock=true, which is wrong because the buffer is already locked.

    Discovered by Kuntal Ghosh, patch by Amit Khandekar.

commit ad0dd279a096e5f9763f44799dfc78c18c4bbd26
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-05-23 09:12:09 +0530

    Avoid using tuple freed by a visibility function.

    In zheap_get_latest_tid(), the tuple that is passed to
    ZHeapTupleSatisfiesVisibility() was being used subsequently, ignoring
    the fact that the visibility function frees the passed-in tuple.

    Rather than the passed-in tuple, use the tuple returned by the
    visibility function in the subsequent code. While at it, make sure
    that the returned tuple is also freed if it is different than the
    passed-in tuple.

    Discovered by Neha Sharma while testing TidScan implementation for
    zheap.

    Amit Khandekar, reviewed by Kuntal Ghosh.

commit e47016cdfba942a07cc3c9fb98d698e22251cb77
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-05-22 09:38:16 +0530

    Fix an issue with copying overlapping memory areas.

    For adjusting zheap tuple location, the tuple header was getting
    corrupted because memcpy() was used to copy, and the old and new tuple
    header areas may sometimes overlap, which memcpy does not handle. This
    was discovered when trigger.sql regression test used to crash on some
    environments.

    So use memmove() instead of memcpy(). memmove() is meant to handle
    this scenario of overlapping areas by first copying the data from
    source location into a temporary location.

    Amit Khandekar, reviewed by Dilip Kumar.

commit ec2d2d7b51bd843b88c2668d548fb90da60fcc67
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-17 10:33:47 +0530

    Fetch correct cid for undo tuples

    In ZHeapTupleGetCid, we should fetch the correct cid from undo.

    Patch by me, reviewed by Amit Kapila

commit ef42a733e045b5624308ce37f4d745b0b9e7d221
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-21 13:09:17 +0530

    Fix compiler warnings

commit 804476bd9929532a83fd0b30ddacfa00b68c5028
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-23 14:38:34 +1200

    Add a smgrsync() implementation for undofile.c.

    Teach the checkpointer to go through an sgmr API call to mark a (RelFileNode,
    forknum, segment) as in need of flushing to disk at the next call to
    smgrsync().  Previously it called RememberFsyncRequest() in md.c directly,
    but undofile.c needs to be able to participate in this scheme too.  So, add a
    new function smgrrequestsync(), and have it forward to mdrequestsync() or
    undofile_requestsync() as appropriate.

    For now, there is a LOG message when undo segment files are fsync'd, like the
    existing create/recycle/unlink messages.  These will be removed in future.

    This contains a small amount of code that is copied from md.c, but the fsync
    queue machinery is being redesigned so this can be rebased later to use a
    common fsync queue.  See commitfest entry 18/1639 (work independent of zheap).

    Thomas Munro, RM43460, reviewed by Amit Kapila

commit 74c0db38b6469fd92bfca32b41ecbadafd99ed40
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-05-15 01:22:41 +1200

    Free up undo log DSM segments and trim pg_undo file size.

    To prevent the pg_undo file from getting gradually larger and the number of
    undo log DSM segments from gradually increasing in a long running system,
    update the lowest non-discarded undo log number at each checkpoint so that we
    can free up resources.

    In passing, change UNDO_LOG_STATUS_DROPPED to UNDO_LOG_STATUS_DISCARDED, a
    name that better describes the state.

    Thomas Munro, RM43532, reviewed by Amit Kapila

commit 9b18132fe9ad889e0aaecb2d2019e3bcf9433018
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-24 16:45:58 +1200

    Recycle memory used in recovery for the xid->undo log map.

    At each checkpoint, free up memory used to hold information about which
    undo log old xids are attached to.  Also rename associated variables and
    functions to make things clearer.

    Thomas Munro, RM43532, reviewed by Amit Kapila

commit 8cb810f82a694d794429f0b8e28328baf6334bc5
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-05-17 15:06:51 +0530

    Bug fix in discard mechanism

    When undo actions were applied by backend and the undo record pointer
    is rewound, discard the corresponding undo logs and skip performing
    undo actions.

    Reported by Neha Sharma, reviewed by Dilip Kumar and Amit Kapila

commit 56762bc994dfa14e79c29f13231bd0f6e99e0782
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-15 17:16:55 +0530

    Fix compiler warnings

commit e40d26a76fb67a3b2f1cf144a2e76c8301be6a4b
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-05-15 05:12:47 +1200

    Improve smgr.c and undofile.c modularity.

    Add a void pointer called "private_data" to SmgrRelationData where undofile.c
    can put its state, instead of the previous horrible hack where it was using
    relm->md_seg_fds.  md.c should really use the new member too, but that'll be a
    patch for another day.

    Thomas Munro

commit bc419ace343682505687cbb39f402d4e90cf228a
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-05-15 17:04:31 +1200

    Remove obsolete comment from undolog.c.

commit 62e17972070c1b994f2ae63abe07f951f59bdbc3
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-05-15 13:40:29 +1200

    Update copyright date to 2018.

    For all undolog-related files.

commit b591268e289fba15aeb9f1160d7c164e241c6a11
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-05-09 18:44:56 +1200

    Add some user-facing documentation about undo logs.

    This commit documents the pg_stat_undo_logs view and the layout of files on
    disk.  More wordsmithing will be needed.

    Thomas Munro

commit 350dadc12b77a4efccafbb5f11663c07370bfd01
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-05-09 19:16:24 +1200

    Undo log README tweaks.

    Author: Thomas Munro

commit 22560511be9b6d49034573736feb0c7a830e1a3a
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-16 16:15:54 +1200

    Skip unnecessary reads of newly allocated undo log pages.

    Whenever we're inserting new undo data that happens to fall at the start of a
    page, we know that there can be no pre-existing data on the page.  Therefore
    we can ask bufmgr.c to zero it out instead of reading it from the storage
    manager.

    To facilitate this, create a new BufferReadMode RBM_ZERO, just like
    RBM_ZERO_AND_LOCK except without the content lock.  undorecord.c expects to
    acquire the content lock a bit later.  Since each backend has sole write
    access to write to the undo log, it's not necessary for bufmgr.c to acquire
    the lock for us.

    Thomas Munro, RM43486, reviewed by Amit Kapila

commit b88edc54636b2649101106ad08b95c16fbfc1d7f
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-05-14 21:46:38 -0700

    Move previous transaction's undo updation inside critical section

    Update the previous transaction's undo record inside
    InsertPreparedUndo after we have actually inserted the undo record.

    Patch by Mithun C Y Review by Dilip Kumar.

commit 87075c70ffaeea5c570340df7aa144823d94a510
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-05-14 21:35:47 -0700

    Get deleted rows from zheap_fetch.

    In zheap_fetch if ItemId is set as deleted we need to
    fetch the old version of rows from undo.

    Patch by Mithun C Y Review by Kuntal Ghosh

commit 229aaef467f263bf779cab93c2bf05011a03f335
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-05-14 18:18:30 +0530

    Fix an issue in parallel btree index build.

    Commit 9da0cc35284b added support for parallel btree index build.
    While imitating those changes for zheap in IndexBuildZHeapRangeScan()
    with commit a33e61f999f03, some changes got missed, due to which
    an already-unregistered snapshot is tried to be freed again.
    Added the missing changes.

    Reviewed by Mithun Cy and Amit Kapila.

commit 43d9001c390852fae721b9351a8404f3e063b0d5
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-07 16:10:29 +0530

    During ROLLBACK, set frozen/invalid xact flag correctly

    Reviewed by Amit Kapila

commit e18393d52f04e6c5ade7529581b521d2f7387bdf
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-14 12:05:48 +0530

    In UndoLogAllocate, set is_first_rec to false by default

commit db7d7ee6110a47b420d2be2dc88381e39a099f9c
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-05-13 09:29:14 +0530

    Update README.md to reflect the current status of zheap.

commit 19235c3d03f0505f91b5056871c79a70e79430c4
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-08 12:26:35 +0530

    Add new expected .out files for zheap to compensate the failures
    only happening due to inplace updates.

commit 4396609900c4bd5efdd7ecebc8d3966411304786
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-05-08 11:41:45 +0530

    Fetch the tuple from undo for aborted transactions when checking
    the visibility for dirty snapshot

    Reviewed by Kuntal Ghosh

commit 27814264865d23ab8cfae46cdbe9202117ae7c6c
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-05-07 13:18:29 +0530

    Thinko fixed for execute_undo_actions caller

commit d8a3a11957e1e4647da0782308ca89b5ac931b1b
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-05-07 13:11:26 +0530

    Fixed a thinko in RollbackFromHT

    Reported by Dilip Kumar

commit 35a9231220d0866847cd7bd3729c5d231b10e3b5
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-05-04 15:45:25 +1200

    Document the undo log IO wait events.

    Add the new undo log wait events to monitoring.sgml.

    Thomas Munro

commit 7dc8a6862586586b48eadfe708044e679f86f153
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-05-04 15:06:23 +1200

    Report read/write/sync wait events for undo checkpoints.

    Like other file IO, let's make these show up in pg_stat_activity.

    Thomas Munro, RM43509, based on feedback from Amit Kapila

commit ff7193ad4d4472014344e0983ce90adce9be3229
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-23 23:19:49 +1200

    CRC verification for pg_undo checkpoint files.

    Add CRC32C checksums to the per-checkpoint files stored under pg_undo.

    Thomas Munro, RM43509, reviewed by Amit Kapila

commit 5ec98770f1e4a1b6fc515447a7d01e1139a8eb27
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-05-01 17:48:01 +1200

    Fix compiler error in test_undo.c on Windows.

    Per CI build report.

commit e8ee49180be2391e87a0858d6c2b09eca5fbd716
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-05-03 18:55:15 +0530

    Avoid calling PageGetUNDO

    We need to avoid calling PageGetUndo as it re-access the transaction
    slots the second time.  We can already get it via PageReserveTransactionSlot.
    This is okay till now, but with TPD, we need to again access the TPD page
    which will be costly.

    Patch by me, reviewed and edited by Dilip Kumar

commit 83986b54c2b6445517502d1750f5523ed2690bba
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-03 14:23:22 +0530

    Small fix in CopyTupleFromUndoRecord

    We should free the memory for zheap tuple only after allocating memory
    for the copied undo tuple.

commit c8ce97a9d55c0c3a3f537a389513ce10de1b6c0e
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-03 11:51:11 +0530

    Remove unnecessary undo type from CopyTupleFromUndoRecord

    Reported and reviewed by Amit Kapila

commit a2a88babb3e190f526cdb3fae496c41fc9c1d2f2
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-05-03 12:45:30 +0530

    Fix WAL replay of XLOG_ZHEAP_UNUSED

    We forgot to call PageSetUNDO during wal replay of XLOG_ZHEAP_UNUSED.

    Patch by me, verified by Mithun C Y

commit 9b1f493a6335d0702479bc56506dc34287b46b35
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-05-02 16:54:50 +0530

    WAL replay for lock tuple was not using correct transaction slot to
    update the transaction information

    This commit fixes the issue by logging and using the correct
    transaction slot during replay of lock tuple.

    Patch by me, reviewed by Dilip Kumar

commit 6a74940a505bd5e302cc9ac7b3adbb3625c560a8
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-05-01 23:19:24 -0700

    Bug fix in undo record start header update during recovery

    Patch by Dilip Kumar Reviewed by Rafia Sabih

commit a5c5e1706570f379eb8bf6a12a9226af60912016
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-05-02 13:42:36 +0530

    Handle non-exixtent/empty files in pg_regress

    Commit 3e9f07a8fe222b0e9 excluded storage_engine option from result
    files using grep/findstr command. But, these commands returns
    non-zero values in case of non-existent/empty files. Hence, we've to
    skip the checks for the same.

commit fd4c197eca2a0846d08727361073cbc1f82d7cbf
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-05-01 22:51:15 -0700

    Fix tuple lock wal replay

    lock mode was not stored in lock tuple WAL and also not stored in undo
    during replay.  This commit fixes the same.

    Patch by Dilip Kumar Reviewed by Amit Kapila

commit 3775d97153d1cd63bc98d561816e9662cd03eb53
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-04-30 17:14:08 +0530

    Fix copy undo payload

    Reported by Amit Kapila

commit 02a89f973c2be94019d695fb0d917494db319473
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-05-01 21:45:18 -0700

    Bug fix in update wal replay.

    Patch by Dilip Kumar Reviewed by Amit Kapila

commit c5f63f27f73618b994bd561057d3f4e9c0da15ff
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-05-01 12:42:26 +0530

    The check to ensure whether undo is discarded was missing at few
    places.

    This patch fixes two such occurrences.

    Patch by me, reported and reviewed by Rafia Sabih

commit f336c7a16c72e0048f897f85b1e38b24adc8ff8e
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-04-30 11:15:40 +0530

    Add new expected .out files for zheap to compensate the failures
    only happening due to inplace updates.

commit 1a8e463d48e1bbf5ea9abb1e07b1512a097fb963
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-04-30 10:49:06 +0530

    Additional flag in execute_undo_actions for relation lock

    Callers of execute_undo_actions now provide a flag based on if they
    a lock on the relation. If the caller have relation lock already
    then no need to lock again in execute_undo_actions.

    This is required particularly in cases when rollbacking the prepared
    transactions or rollback to savepoints. In such cases the transaction
    have already held the relation locks and we need not take another.

    Reviewed by Dilip Kumar

commit 5f229e04af2f187fc757e8f59ba8c075e56cf46c
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-04-27 04:21:42 -0700

    While vacuuming a large zheap table, update upper-level FSM data every so often.
    for detail refer commit 851a26e26637aac60d6e974acbadb31748b12f86 of PG.

    Patch by Dilip Kumar Reviewed by Amit kapila

commit 90dbf29c4b815ea3b51c8736f412a67d59d5f4f1
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-27 21:49:59 +1200

    Log the same undo segment messages in REDO and in DO.

    During DO we currently output LOG messages when undo segment files are
    recycled etc.  Output the same messages in recovery.  All of these
    messages will later be removed, but it's helpful for testing to show
    them for now.

    Thomas Munro

commit 292856c5c73f80f9089441a9079ce76ab17b9764
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-04-27 12:53:10 +0530

    Add new expected .out files for zheap to compensate the failures
    only happening due to inplace updates.

    Patch by Ashutosh Sharma, suggested by Amit Kapila, reviewed by
    Kuntal Ghosh.

commit 0925b489735ab6ba01c3c57a85175947ec04a373
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-04-27 12:51:00 +0530

    Allow pg_regress module to exclude storage_engine option printed
    when viewing the definition of zheap table using \d command.
    Additionally, also add a new reloption_1.out file to compensate
    for the diffs generated due to storage_engine option in reltopions
    field of pg_class table.

    Patch by Ashutosh Sharma, reviewed by Kuntal Ghosh.

commit c13e3a64be6fe571f48c1abc8a837c063594ce1d
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-04-18 18:17:16 +0530

    Implement Foreign Key Constraint for zheap

    For zheap, when we call the triggers we convert a zheap tuple to heap
    tuple. But, we don't store any transaction related information on the
    heap tuple. Hence, I've to make the following two
    assumptions/considerations for the foreign key implementation in
    zheap:

    1. RI_FKey_fk_upd_check_required: In this function, we check if the
    original row was inserted by our own transaction, we must fire the
    trigger whether or not the keys are equal. For zheap, since we don't
    have the transaction related information, we always fire the trigger.
    So, even if the keys are equal, we cannot skip the trigger for zheap.

    2. validateForeignKeyConstraint: During ALTER TABLE..ADD CONSTRAINT
    FOREIGN KEY, this function is called to validate whether we can add
    the foreign key constraint. First, it tries to fire a LEFT JOIN query
    to test the validity. If the user doesn't have proper access rights to
    pktable/fktable, we scan the table in pagescanmode and fire trigger
    for each tuple. Before firing the trigger, it takes buffer lock to
    check whether it can skip the trigger. For zheap, we don't retain the
    pin on the buffer. Hence, we've to read the buffer again before
    locking the same.

    Patch by me, Reviewed and tested by Ashutosh Sharma

commit 4113663bfa26941ef3b5eec9589e70dfe3643e96
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-04-27 11:34:49 +0530

    Update t_infomask2 field of old tuple correctly during inplace
    updates.

    Patch by Amit Kapila, reviewed by Ashutosh Sharma

commit 06fb3f80e349e0a329606702cd94cd2bdc740946
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-04-25 23:56:02 -0700

    Mark all_dead if ItemId is already dead.

    By Mithun C Y review by Ashutosh Sharma

commit 60731dbac9433dc640d3412504423e15260b1ed6
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-04-25 23:52:55 -0700

    Fix rebase issue

    Prototype change of GetOldestXmin was not updated while rebasing to
    postgres main branch. Above patch corrects same.

commit 7e10f40e60dcd2704ba98781ae98d658b3dcbb5a
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-25 15:07:34 +1200

    Track undo logs' is_first_rec correctly in recovery.

    Previously we could get confused about whether an undo record is the first
    in a transaction during recovery.  Use XLOG_UNDOLOG_ATTACH to set the flag,
    since that is always emitted before the first zheap WAL record for each
    transaction.

    If a checkpoint happens to come between that and the first zheap operation,
    it doesn't matter because then an XLOG_UNDOLOG_META will be inserted and that
    will restore the is_first_rec flag, assuming it was also tracked correctly
    during DO (that's a separate investigation).

    Thomas Munro, RM43459, reviewed by Dilip Kumar

commit 3a82f2f014ac86b7587bc85f12a5df6fc4bb1514
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-25 21:10:30 +1200

    Make src/test/modules/test_undo compile.

    After many recent changes it wasn't building.  Repair.  It isn't useful
    for testing at the moment, because if you add test content to undo logs it
    causes the undo worker to crash.  I need to figure out a way to prevent that
    from happening and then convert this into a useful set of tests of undo log
    machinery.  Watch this space.

    Thomas Munro

commit 0bf11c41400b26ec50a2edd4fb70777268993d56
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-03-26 09:59:39 +1300

    Change undo log segment size to 1MB.

    The previous size was 4MB.  That size wasn't chosen with much thought, and it
    creates a fairly large disk footprint for systems with many concurrent
    backends.  Let's try the smaller and nice, round number of 1MB and see how
    frequently we finish up doing filesystem operations.  Early testing with
    pgbench on powerful machines seem acceptable, since the undo worker is very
    easily able to recycle segments fast enough so that foreground processes never
    have to create a new one.

    Thomas Munro

commit 5b7fbed0c316ec15cdf8fc566a503e5428946dd7
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-03-09 16:18:12 +1300

    Add a README file describing the undo log storage subsystem.

    Add src/backend/access/undo/README, and update src/backend/storage/smgr/README
    to describe the new storage manager.

    Thomas Munro

commit 2b620d2e8b3bc0708106e122d42464f417406071
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-03-20 05:19:45 +1300

    Make temporary undo logs use backend-local buffers.

    For now temporary undo data is not discarded, except at startup when it's all
    discarded at once.  This will be addressed in later commits.

    Thomas Munro, RM43422

commit 1f176882f95411b5a4fd18740687143fd4cd2c0e
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-23 14:30:14 +1200

    Basic tablespace and persistence support for undo (take II).

    You can now be attached to a separate undo log for each persistence level
    (permanent, unlogged, temporary).  Undo logs can now be created in tablespaces
    other than pg_default by setting the new GUC "undo_tablespaces".

    Temporary undo logs are not yet backend-local; a separate commit will add
    that.  A separate commit will also fix some details of crash recovery.

    Thomas Munro, RM43422, reviewed by Rafia Sabih, Dilip Kumar, Amit Kapila

commit 25eb200b1aa3d05cb1d8365946fc03c3ca1c96fc
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-23 13:01:51 +1200

    Introduce XLOG_UNDOLOG_META WAL records.

    During checkpoints, undo log meta-data is captured at an arbitrary time after
    the redo point is chosen.  In the case of an online checkpoint, this means
    that we might capture incorrect meta-data.  Correct that by inserting an
    XLOG_UNDOLOG_META record before the first WAL record that writes to each undo
    log after a checkpoint.

    Dilip Kumar, RM43459, reviewed by Thomas Munro

commit 47c7e3b5199d561953f693e18c2f85dae7b56264
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-23 12:32:00 +1200

    Remove code for consistent pg_undo checkpoint files.

    Instead of trying to make pg_undo files consistent, we have decided to allow
    them to contain data from any arbitrary time after the redo point.  A
    follow-up commit will introduce new WAL records that will be emitted to
    correct them.

    This is not a complete revert of commit d8a02edf as there were some
    refactorings and small fixes that seem worth keeping.

    Thomas Munro, RM43459

commit b43da384a36b13679f5f0ec12aa72e218656d0d1
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-04-24 07:09:41 -0700

    Fix the assert.  In recovery we can not ensure that we are attached
    to the undo log from which we are allocating.

commit f306a1c5c10e63eb38c790be504e154413372a90
Author: Mithun CY <mithun.cy@gmail.com>
Date:   2018-04-24 06:35:27 -0700

    Force page init on Insert rollback

    In zheap_xlog_insert we see insert of first and only tuple on the
    page we re-initialize the page. Force page init on insert or multi
    insert rollabck so wal consistency check of page on standby still
    satisfy. This overrides previous commit 15179e57b124

    Patch by me and review by Kuntal Ghosh.

commit ffc5ea7e8577d3cce4b5e44fda55a4f7df6bed75
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-04-13 14:13:44 +0530

    Fix ZHeapPageGetCtid for deleted tuples

commit d8107861935ad0e202aeb14ad116722af5d22af5
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-04-24 18:26:23 +0530

    Handle deleted item pointers for no-key-exclusive mode

    Reported by Amit Kapila

commit 156e25415049a1d9a940bf709abc5fd5f550ee7e
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-04-20 15:15:59 +0530

    Fix assert in zheap lock,update and delete tuple

    For deleted item id, we don't retrieve the tuple. Hence, we should
    check for the same.

commit af6f63e740cd904f234475bf530a9290b982b38b
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-04-24 03:35:42 -0700

    make zheap changes in slot_getsysattr function.  This function is
    now called by execCurrentOf.

commit 8b6041f28b8e2554da439da7701500bb2af2c712
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-23 11:11:57 +1200

    Fix warnings in non-assertion build.

    Clang complained about uninitialized variables when there was no assertion.

commit 2b96b1be41fad5aa00e8d8b8db63aada925f7581
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-04-20 19:17:48 +0530

    Fix a bug in ALTER DOMAIN .. ADD CONSTRAINT

    The previous commit doesn't use beginscan correctly for heap/zheap
    relation.

commit 7cb019bbcec083052f8436f4489fe6e2957b223a
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2018-04-20 16:11:19 +0530

    Correct the behaviour of ALTER DOMAIN .. ADD CONSTRAINT in zheap

    Add zheap support in functions validateDomainConstraint and
    AlterDomainNotNull which will check if any tuple violates the
    newly added constraint.

    Reviewed by Kuntal Ghosh

commit dbcfe95943c7f5ddd5fbcb3b84daa62a32c3abf9
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2018-04-20 14:22:16 +0530

    Allow foreign tables to be added as partitions of zheap table

    Since foreign tables do not support the storage_engine option, exempt
    them from the checks where we check if the partitions have the same
    storage_engine option as their ancestors.

commit 439869f9fc77a8e6121a74fc433eef7d822951b8
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-04-20 00:38:59 +0530

    Add isolation expected file of vacuum-reltuples test for zheap

    In zheap, we don't have to take cleanup lock for vaccuming the
    relation. Hence, the vacuum command won't skip the buffer even
    when another backend holds a pin on the same.

commit d50ed5e003d5104171540e3bcb45335bc941cd4a
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-04-18 13:00:28 -0700

    Force Refragmentation on Insert rollback

    In zheap_xlog_insert we see insert of first and only tuple on the
    page we re-initialize the page. Force pruning on insert or multi
    insert so wal consistency check of page on standby still satisfy.

    Patch by me and review ny Kuntal Ghosh.

commit 240b960b6cf36a5611aa13b7f67e6cebedd15b63
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-04-18 14:26:43 +0530

    Introducing a queue for passing rollback requests to undo worker

    To increase the efficiency of rollback mechanism in zheap,
    we now have a rollback queue. Now, any rollback request that
    exceeds the threshold -- rollback_overflow_size, is added to
    this queue. Whenever undo worker is idle it checks if rollback
    queue has some entries and executes the required undo actions,
    if any. The rollbacks required for 'rollbacks to savepoint' are
    not added to this queue, rather the backend itself executes the
    required undo actions for them.

    The rollback queue is implemented as a shared hash table.

    Reviewd by Beena Emerson and Amit Kapila

commit fee9b99b1ccf3dca9a822d4e41e6a3a801598eb1
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-04-17 03:37:04 -0700

    Block VACUUM FULL on zheap table, which got unblocked by commit
    0d27be592d82a44158d

    Reported by Thomas Munro and Kuntal Ghosh.

commit 49743ef26167946e60292aa3251b6bbdfdacd015
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-04-16 17:26:56 +1200

    Fix uninitialized variable.

    Per compiler warning from clang.

commit 31cd2baf750596b961c9838a61078f3c9f3eb70f
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-04-13 05:12:13 -0700

    Fix for warnings introduced by commit 0d27be592d82a44158d

    Reported by Kuntal Ghosh.

commit 274b0cb5c7ad77da7f4f98db23619a30571f6ac0
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-04-12 12:53:26 +0530

    Declare get_old_lock_mode as static inline

    Otherwise clang complains about the inline function declaration.
    Reported by Thomas Munro, reviewed by Amit Kapila

commit ee296fd6b96d8294dba9437f30353797e756d6da
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-04-12 10:07:15 +0530

    Two pass vacuum

    We need vacuum in zheap for non-delete marked indexes, however, we can
    use undo to reduce three-pass to two-pass vacuum.  When a row is
    deleted, the vacuum will directly mark the line pointer as unused,
    writing an undo record as it does, and then mark the corresponding
    index entries as dead.  If vacuum fails midway through the undo can
    ensure that changes to the heap page are rolled back.  If the vacuum
    goes on to commit, we don't need to revisit the heap page after index
    cleanup.

    We must be careful about  TID reuse: we will only allow a TID to be
    reused when the transaction that has marked it as unused has
    committed. At that point, we can be assured that all the index
    entries corresponding to dead tuples will be marked as dead.

    Currently, due to lack of visibility map for zheap, we scan all the
    pages during vacuum.  A future patch which will introduce visibility
    map in zheap will remove that limitation.

    Patch by me, Mithun has fixed few bugs and added implementation for
    Rollback action, also he has done basic verification of the patch

commit 4f3a0106661ab1f52be6a4b1c1de37216c710535
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-04-11 16:51:11 +0530

    Support different tuple locking modes

    The basic idea is that we maintain each lockers information in undo
    and the strongest lockers information on the tuple. If there is more
    than one locker, then we set multi_locker bit on tuple. Now, if the
    multi_locker bit is set and the new locker conflicts with the
    strongest locker, then we traverse all the undo chains in the page and
    wait for all the conflicting lockers to finish. As we have to wait for
    all the lockers by releasing the lock on the buffer and then reacquire
    the buffer lock after waiting for all the transactions is finished, in
    the meantime, a new locker (say key share) can take a lock on the
    tuple and we won't be able to detect it unless we do something
    special.  Now, one might think that as before waiting for multiple
    lockers we have acquired a heavyweight lock on tuple by using
    heap_acquire_tuplock, no other transaction can acquire xid-based lock
    (something like key share), but that is not true, as that is allowed for
    both heap as well as for zheap (till now).

    Now, the heap can detect such a case because it always creates a new
    multixact whenever a new locker is added to the existing set of
    lockers and it puts the newly create multixact id in xmax of tuple, so
    in above case after reacquiring the buffer lock we can just check if
    the xmax has changed and if so, then we redo the *TupleSatisfies check
    and again wait for new lockers.

    For zheap, after reacquiring the buffer lock, check again if there is
    any new locker on the tuple and to find this we need to again traverse
    the undo chains. Although this doesn't sound the best design, it is
    not clear whether it can really create the problem. If we want we can
    optimize by checking whether LSN of the page is changed, then only go
    for chasing all the undo chains, sure that won't work for unlogged
    tables, but still it is a good optimization. Another thing is that
    this approach is quite simple, so we inclined to go with this
    approach.

    We clear the multi_locker bit lazily like when we are already
    traversing all the undo chains to verify if there is any new locker on
    the tuple after taking the buffer lock.

    The visibility routines don't need any special handling as we are
    already storing the strongest locker information on a tuple which can
    help us get the transaction information of updater which is what is
    required to check visibility of tuple.

    Patch by me with help from Kuntal Ghosh and Dilip Kumar, reviewed and
    tested by Kuntal Ghosh

commit 5bf3a603cd575ec188e42b1e0b7b0978f0fc54ed
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-04-11 16:12:12 +0530

    Retrieve the transaction slot of modified tuple

    This is required for the upcoming tuple locking patch.

    Patch by me, reviewed by Dilip Kumar

commit f2922167ffb0134854ca1fceea7b80d1a657cc23
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-04-05 11:03:14 +0530

    Fix the incorrect update of infomask for inplace updates

    Ensure to copy everything from new tuple in infomask apart from
    visibility flags.

    Patch by me, reported by Kuntal and reviewed by Ashutosh Sharma

commit 1dc99668b499b30a6fb7146e7c6156178143ced7
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-04-04 00:30:38 -0700

    If full_page_writes is enabled, and the buffer image is not included in
    the WAL then we can rely on the tuple in the page to regenerate the undo
    tuple during recovery as the tuple state must be same as now, otherwise,
    we need to store it explicitly. But, in current code it is not stored
    externally even if the page image in included in the WAL.

    Introduced new API XLogInsertExtended. Unlike XLogInsert, this function will
    not retry for WAL insert if the page image inclusion decision got changed
    instead it will return immediately. Also, it will not calculate the latest
    value of the RedoRecPtr like XLogInsert does, instead it will take as input
    from caller so that if the caller has decided to not to include the tuple
    info (because page image is not present in the WAL) it can start over again
    (if including page image decision got changed during WAL insertion). And
    for the zheap wherever we need to include tuple info for generating the undo
    record, we will call this new function instead of XLogInsert.

    Patch by Dilip Kumar. Review and modified by Ashutosh Sharma and Amit Kapila

commit 9b3f81dd68751cd8fc61a588e07c0299c52b1e7b
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-04-03 01:44:20 -0700

    Remove undo for INVALID_XACT_SLOT

    Previously we needed this undo to identify the exact xid which
    was there in the slot before reusing it.  And, that was stored
    as uur_prevxid of the undo record.  Now, we are already including
    uur_xid (transaction id which has inserted undo record) so we can
    find the actual slot xid just by traversing the undo chain.

    This will reduce the complexity of the code.  And, this will also
    remove the limitation that one transaction is writing the undo in
    other slots. So, by removing this limitation we can rewind the insert
    location during rollback from the backend.

    Patch by Dilip Kumar Review and Defect fixes by Amit Kapila

commit a354f4e7ad32176b57a47251fb8ac2366d0bff3c
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-04-03 13:44:33 +0530

    Include undolog.h in undorecord.h to fix compilation error on MSVC.

    Ashutosh Sharma

commit 44f5d0336add411302e9de94329ac7cc8808508c
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-03-20 00:26:36 +1300

    Fix uur_next corruption by replacing global variables with UndoLogControl.

    Previously we could corrupt our uur_next chain when the undo log you're
    attached to changes.  This broke some later commits.

    Get last_xact_start and prevlen in UndoLogControl instead of maintaining a
    local copy.  They can be read directly from shmem without locking (but not
    written) by the backend that is currently attached.

    prev_txid remains as a global variable, and it needs to be cleared whenever
    the undo log changes.  Perhaps it could be stored in UndoLogControl too, but
    that leads to some circularities.

    Thomas Munro, RM43421, reviewed by Rafia Sabih

commit a0536401ad8f228ea7bffa08ccbb9f69d62fb4d1
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-03-12 15:29:05 +1300

    Remove UndoDiscard and move its state into UndoLogControl.

    Previously, a per-undo log object "UndoDiscard" was used to track the progress
    of the undo worker machinery.  It was in a shared memory array of fixed size,
    which isn't going to work.  Move that state into the UndoLogControl object for
    each undo log.

    Since this change requires undodiscard.c to have direct access to
    UndoLogControl objects and to iterate over them, create new functions
    UndoLogNext(), UndoLogGet() with extern linkage to do that.  A better
    interface is probably needed -- to review later when we work out the type of
    access that multi-process undo worker infrastructure will need.

    Register the LWLock tranches.

    Thomas Munro, RM43420, reviewed by Dilip Kumar and Amit Kapila

commit 709a41dc526b9eecda1d4891f758b3d268af2650
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-03-08 16:01:03 +1300

    Move UndoLogControl struct into header to prepare for wider use.

    A later commit will make use of it from other translation units so let's not
    define it in undolog.c.  This requires hiding the definition when included
    from FRONTEND code.  Perhaps this should have a new header of its own or some
    other reorganization, but for now let's just do it conditionally.

    Thomas Munro, RM43420

commit 8b74af923855cd72e1fca40b8822d546fc07a1ab
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-03-22 11:07:35 +0530

    For calculating latest removable xid, don't use raw xid from page

    This commit also modifies ZHeapTupleGetTransInfo to work with
    deleted item pointers when we've buffer lock on the page.

    Reviewed by Amit Kapila

commit 38345d269e4bb4908b9e48cb3a4a955d2579a0cf
Author: Amit Khandekar <amit.khandekar@enterprisedb.com>
Date:   2018-03-26 12:23:43 +0530

    Support Tid Scan for tables with zheap storage.

    Use zheap equivalent of heap_fetch() to fetch the next tid.

    To support WHERE CURRENT OF, have a zheap-equivalent of
    heap_get_latest_tid() function. This function in turns uses
    the zheap visibility function. For following the ctid chain
    for non-in-place-updated tuples, have the MVCC visibility function
    pass back the ctid of the new tuple.

    Although zheap_get_latest_tid() accepts a snapshot, it may not work
    with snapshots other than MVCC snapshot, because the corresponding
    visibility functions for those snapshots are not modified to return
    the new tuple ctid. This would be done in later commits, since it is
    not necessary for Tid Scan.

    Furthermore, the callers of heap_get_latest_tid()
    (e.g. currtid_byreloid) should be modified to call
    zheap_get_latest_tid() for zheap tables. This also would be done
    in later commits.

    Patch by Amit Khandekar, reviewed by Amit Kapila and Kuntal Ghosh.

commit ec068b0903c8dc9788b06e0405f6d4c94ba24dcc
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-03-25 22:14:13 -0700

    Handling the rollback if error in commit path

    During the commit if there is error occure before updating the
    status in the clog then we need to track the undo pointers and
    apply the undo actions.

    Patch by Dilip Kumar review by Amit Khandekar.

commit 37994ff7060acc5317ccfd8c48c2ef440e4a3504
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-03-23 13:55:50 +0530

    Fix README.md for better readability

commit 698f1fb1bb35f423891c7ae64b4f6f7f1f1f2074
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-03-21 16:22:49 +0530

    Make transaction slots per zheap page as compile-time parameter

    One can specify the same using --with-trans_slots_per_page=<VALUE> while
    configuring postgres installer. Allowed values are 1,2,4,8,16,31. By default,
    it is assigned to 4 slots per page.
    The changes required for Windows have been done by Ashutosh Sharma.

    Patch by me, reviewed by Amit Kapila and Ashutosh Sharma

commit acbc6636929b21c6df12e4c69964a2c4035652c6
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-03-23 12:33:34 +0530

    Bugfix in btree and hash delete items

    Sizes of xl_btree_delete and xl_hash_vacuum_one_page were not properly
    calculated.

commit a8bae1f3400d9e98e46268040521f517d556efe9
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-03-23 12:02:35 +0530

    Handling rollbacks in prepared transactions

    Reviewed by Dilip Kumar and Amit Kapila

commit 2fa48d89c290f309fa92b719d1070b5f329f4daa
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-03-23 10:58:40 +0530

    For speculative insertion, store a dummy speculative token in the
    REDO function (zheap_xlog_insert()) so that, the size of undorecord
    in DO and REDO function matches with each other.

    Ashutosh Sharma, Reported by Neha Sharma.

commit 574f673a1cf6d494b2ef0817962aee93bb0659a1
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-03-22 10:51:23 +0530

    Fix for warnings introduced by commit 70f35f756834028c

    Reported by Amit Kapila

commit 89cb28898369622578be42f7a131c024b7bb5f05
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-03-19 18:13:52 +0530

    Skip unnecessary palloc for deleted item pointers

    Reviewed by Amit Kapila

commit 4765f6669408f9e13e3cebd1c33a668d718b5b98
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-03-20 16:19:00 +0530

    Bug fixes in rollback

    1. Check for running transactions using top transaction instead of
    current transaction state in XactPerfromUndoActionsIfPending

    2. Insert start undo record if we rewound the previous start undo
    record pointer while rollbacking the subtransaction containing the
    start undo record of the transaction.

    Issues reported by Neha Sharma, reviewed by Dilip Kumar, Amit Kapila

commit 1830381aa7c44d0ba24fb1fc6fc94cab87165705
Author: dilip kumar <dilip.kumar@enterprisedb.com>
Date:   2018-03-19 23:44:10 -0700

    Removed unwanted function "SetUndoPageLSNs"

commit 6a2b8d3f80829987908005941de9c9583577430e
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-03-19 16:36:54 +0530

    Place the if-check used to decide whether the last tuple in a page
    can be inplace updated or not outside the check to know if a page
    needs to be pruned, otherwise, even if the tuple to be updated is
    a last tuple in a page, it won't go for inplace updated if the
    page pruning is not required.

    Ashutosh Sharma, Reported by Neha Sharma, Reviewed by Mithun CY.

commit 6953e07fcf5bd914c31beb6adcc756ea34974940
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-03-16 14:28:39 +0530

    Fix zheap_xlog_multi_insert to release the buffer properly

    In zheap_xlog_multi_insert, we should unlock and release the buffer
    even after restoring the block from backup image.

    Issue reported by Tushar Ahuja

commit 350f34b92fcac83aa9447cb8b7685f1f5e3655e4
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-03-15 22:09:38 -0700

    Bugfix advance latest RemovedXid only if tuple is dead.

    By Mithun C Y, Review Dilip Kumar

commit e63e2365e1ccc78424032fafa8c3a5a012955c1e
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-03-08 11:50:50 +1300

    Fix incorrect worker name displayed if undo launcher/worker dies.

    Previously bgw_type was uninitialized, causing at least some systems to show
    a value that confusingly just happened to be "logical replication launcher" to
    be displayed by the postmaster in error messages.

commit 5541c5927873c34aecbf5bc82b7610fc8b035e94
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-03-14 14:17:48 +0530

    Fix UndoFetchRecord for fetching UNDO_MULTI_INSERT

    For UNDO_MULTI_INSERT undorecords, we've to check whether our offset
    number falls in the offset range stored in the payload of undorecord.
    We've added a callback function in UndoFetchRecord to check whether
    an undorecord satisfies any blocknumber, offset number and xid.

    Reviewed by Amit Kapila

commit 986cfc9f789e51fa796b2afdb8ee093c740172a3
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-03-13 22:12:30 -0700

    Bug Fix in CopyTupleFromUndoRecord

    For certain undo record type we will not have tuple data associated
    with them. For Copying such tuple we need an input tuple. Above patch
    Asserts and address those issues.

    Patch By Mithun C Y Review By Amit Kapila

commit 28078c9b70d8d6d7a9af9f5f5789b3a739af0ca9
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-03-07 16:03:23 +0530

    In zheap_prepare_insert, reset visibility bits in infomask/infomask2

    Dilip Kumar and Kuntal Ghosh, reviewed by Amit Kapila

commit 1cd9b192209084bcea39c8603a1de54e8481e5ee
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-03-08 14:26:14 +0530

    Enable WAL consistency check for zheap

    We've added zheap_mask function to mask unimportant fields in
    zheap page before consistency check.

    Patch by me, reviewed by Mithun CY

commit d1d0d9de831695f218f6390f0fea742ddce98b46
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-03-07 13:17:25 +0530

    Fix compiler warnings

commit ac3838b9ab274d2e18e7f4ec19b02ece442d043b
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-03-06 17:30:13 +0530

    Support Insert .. On Conflict

    The design is similar to current heap such that we use the
    speculative token to detect conflicts.  We store the speculative token
    in undo instead of in the tuple header (CTID) simply because zheaps
    tuple header doesnt have CTID. Additionally, we set a bit in tuple
    header to indicate speculative insertion.  ZheapTupleSatisfiesDirty
    routine checks this bit and fetches a speculative token from undo.

    Amit Kapila and Ashutosh Sharma

commit 96eeccc2d9c095fcea050e3c797b9934c9d1cfcc
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-03-06 12:31:21 +0530

    Fix MinZHeapTupleSize definition

commit 7ba6c3c85e913faa02cb7507093abf648d05a3b2
Author: dilip <dilip@localhost.localdomain>
Date:   2018-03-02 01:17:23 -0800

    Commit (db9d0b2988c829b8e0599ebf087a10b98cb9690d) calculated the
    latest_urec_ptr in case of SUB_INPROGRESS but it should have done that
    for SUB_ABORT case.

    Pointed out by Rafia Sabih

commit 89cb2efebb0b039786a1ffde7b48ff16b2ece128
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-03-01 13:47:14 +0530

    Bug fix in zheap_xlog_multi_insert

    This fixes a type casting error. It also fixes the condition for changing
    the offset range.

commit 0eb31eb589c1430eecf430a9c04f988b98914d8e
Author: dilip <dilip@localhost.localdomain>
Date:   2018-03-01 05:55:22 -0800

    Bugfix in rollback

    Latest_urec_ptr is not calculated before executing undo actions,
    fixed the same.

    Patch by me, Reviewed by Amit Kapila.

commit 8043baef73e74311eb399305e99e12bb8e86f868
Author: akapila16 <amit.kapila@enterprisedb.com>
Date:   2018-03-01 17:26:52 +0530

    Create README.md

    This document is to help users understand how to use zheap and open issues.

    Amit Kapila, reviewed by Robert Haas

commit 82320f78eec7eb44584d00728ed84e6a89d5d55b
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-03-01 17:12:41 +0530

    Remove memory leak in various zheap related functions.

    Ashutosh Sharma, reviewed by Amit Kapila.

commit 0618b93ac8f431de813f23d5c8a7b68812ef729c
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-03-01 17:02:12 +0530

    Initialize the new zheap page allocated during update operation on
    zheap tables correctly in zheap_xlog_update().

    Ashutosh Sharma, reviewed by Amit Kapila, reported by Tushar Ahuja.

commit 729d4cb6b09c98a5ecc57a670f55b468ab598d45
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-03-01 16:34:44 +0530

    Design of zheap

    This readme covers overall design of zheap.  This is to help
    developers and or users to understand the zheap.  Later, we might
    split this into multiple README's.

    Amit Kapila, Robert Haas and Dilip Kumar

commit 17ae6f76fb85a1036111eb62f6bf0a2375531306
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-02-28 11:27:23 +0530

    Fix memory leak in zheap_multi_insert wal replay

    Reported by Ashutosh Sharma

commit 0d03216692b1d38b646126fd6300de1e619bc2db
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-02-27 16:30:11 +0530

    Allow zheap_lock_tuple() to release lock on a zheap page if the
    tuple may be updated but the desired lock on a tuple is already
    acquired.

    Patch by me, as per the suggestions from Amit Kapila.

commit 37911c71c174dd3b95befe2d5f7b44d3dc421f62
Author: dilip <dilip@localhost.localdomain>
Date:   2018-02-25 20:58:02 -0800

    Currently, on standby, we don't have DiscardUndoInfo like we have on the
    master side. So, on master before accessing any undo buffer we hold lock
    on DiscardUndoInfo in shared mode and undoworker hold that lock in exclusive
    mode. But on standby side we discard undo directly by WAL. So even though we
    check that undo is not discarded, but by the time we try to access the buffer
    undo may get discarded by the wal.

    Patch fixes the problem by checking the standby recovery conflict with other
    snapshot.

    Patch by Dilip Kumar, Reviewed by Ashutosh Sharma and Amit Kapila

commit c6457f72c4e7695680118902f4c662bedba3a965
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-02-21 01:34:42 -0800

    Remove unrelated code of previous commit

    In commit 5ba1e2f4c605f63a6deca278f39c9bfa05afb239 we have committed
    some unrelated code this patch removes same.

    By Mithun C Y

commit c04a4c83e19f0e9e10cb6aab0ab12ff8a241880f
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-02-19 21:18:29 +0530

    Fix zheap insert options for COPY

    Patch by me with help from Dilip Kumar

commit 17aaf8247ae3ef5763f5a164528f5c9f38dbe345
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-02-20 16:37:37 +0530

    Remove redundant header inclusions.

commit 82681700ad5bd7b976438138d1c970eb6c55720a
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-02-20 02:26:27 -0800

    Check ItemIdIsDeleted on reacquire of BufferLocks

    In some cases after reacquiring the BufferLocks ItemId's might have
    been pruned so check if it is deleted before accessing ItemId's.

    Mithun C Y, reviewed by Amit Kapila

commit cf4614bf7a7b294eae264d4123d76584d66f0384
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-02-16 05:06:28 -0800

    Bugfix in ItemId status check.

    We have used tuple header flag
    ZHEAP_INVALID_XACT_SLOT instead of itemId flag
    ITEMID_XACT_INVALID while checking its status
    this caused undefined behavior. And, fixed a
    condition in zheap_search_buffer.

    Patch By Mithun C Y reviewed by Amit Kapila

commit 418c2e1ac7c46497b3d994bb3db5ea6850d66c50
Author: dilip <dilip@localhost.localdomain>
Date:   2018-02-16 02:12:37 -0800

    bugfix in FetchTransInfoFromUndo

    The actual condition to break the while was if undo type is
    UNDO_INVALID_XACT_SLOT and undo_xid is input xid. This was
    broken in some of the previous commit.

    Patch by me reviewed by Amit Kapila

commit 051a7a2a3849a1140627de7414f79a868a292c38
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2018-02-16 14:59:51 +0530

    Provide zheap support in check_default_allows_bounds

    For a zheap partitioned tables, check if the default partition has rows that
    meet the constraints of the new partition.

    Beena Emerson, reviewed by Rafia Sabih and Amit Kapila

commit a9c5724aca95877300414606bec648e8f512e045
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-02-13 16:02:37 +0530

    To add the storage_engine option in conf.sample file.

commit d61ff363ce28733fb518ccfa5fe9d32f71b7994d
Author: dilip <dilip@localhost.localdomain>
Date:   2018-02-12 15:29:33 +0530

    wal log oldestxid having undo

    Currently oldestxid having undo is not durable and value is also
    not sent to standby.  As part of this patch this value is included
    in checkpoint record so after server restart also value will be
    valid.

    Patch by Dilip Kumar Reviewed by Kuntal Ghosh and Amit Kapila

commit 16fa749cf1c025efb744f1ebd246690a541fe0ac
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-02-12 02:02:57 -0800

    Set page prunable on Insert undo, inplace update
    with reduced lengths.

    Patch by Mithun C Y Reviewed by Amit Kapila.

commit 50f9fb43a3c302cf4fc206227786fba26ce72167
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-02-09 23:52:42 +1300

    Create missing undo log segments during recovery.

    During recovery, we might discover that the segment files that existed at the
    time of the checkpoint don't exist, because they'll be deleted by later WAL
    traffic.  We'll create zero-filled files to avoid errors, and trust that the
    contents of the files will never be needed, because later WAL records discard
    them.

commit bc2ed1a1cefcb56749b3de382c6d6056e7837bd4
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-02-09 23:10:22 +1300

    Make undolog meta-data checkpoints consistent.

    The earlier prototype code captured undo log meta-data at an arbitrary point
    in time somewhere after the redo point.  That worked only for clean shutdowns,
    at which point it was consistent and correct.  To do the job properly, this
    commit keeps track of two copied of each undo log's meta-data in memory: the
    current meta-data, and a snapshot as of the last checkpoint.  In order to
    maintain the checkpoint snapshot, every operation that modifies an undo log's
    meta-data must check if we are now on the other side of a redo point.  Since
    the shared memory access and lock contention would be expensive, we only
    actually do that while a checkpoint is in in progress, from a moment just
    before the redo point is chosen up until we discover that we are now on the
    other side of a redo point, which should ideally mean that it happens only
    once.

    RM43038, Thomas Munro

commit df81f34c6d62ec7601314d5561b8bf1be1596f53
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-02-08 23:37:10 -0800

    Fix crashes in page access after page pruning .

    Issue is in many places while fetching or updating
    tuple we failed to check if tuple has been
    eleted/updated and pruned after we have released the
    Buffer lock. This caused invalid access of pruned
    tuples from the page. Now we now check if itemid is
    deleted before accessing the tuple data in page.

commit b26c26c7e0651cbf4cd5fbfe865ee2226b776ee0
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-02-09 10:29:42 +1300

    Fix an ordering bug when discarding undo buffers.

    We need to forget about undo buffers before we remove or recycle undo segment
    files, since otherwise a concurrent backend might try to write a buffer in
    order to evict it and discover that the file is gone.

    We also need need the same logic during recovery, so let's refactor that code
    into a function called from both UndoLogDiscard() and undolog_xlog_discard().

    Thomas Munro, based on report from Neha Sharma and diagnosis by Kuntal Ghosh

commit 25c38e52afb9d4252117fcb4bc575173b43f7492
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-02-08 17:57:44 +0530

    Validate CHECK constraints on zheap relations.

    Ashutosh Sharma, reviewed by Dilip Kumar and Amit Kapila.

commit 1ef3bcd30c337456386ccfbafff1a913f111782a
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-02-08 17:47:55 +0530

    Implement Table Rewrite performed during execution of ALTER
    TABLE command in zheap.

    Ashutosh Sharma, reviewed by Dilip Kumar and Amit Kapila.

commit 652911807ff33f35a7c297fdde709fbfc30f43be
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-02-08 17:44:50 +0530

    Bugfixes in zheap_to_heap and heap_to_zheap APIs

    Allow zheap_to_heap and heap_to_zheap to allocate the values and
    nulls array based on the number of attributes specified in tuple
    descriptor rather than tuple header.

    Ashutosh Sharma, reviewed by Dilip Kumar and Amit Kapila.

commit fc6d0379c922e8c7cf797ec7c7247eb845c6ddb4
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-02-08 17:43:55 +0530

    Restrict clustering of zheap tables

    Ashutosh Sharma, reviewed by Dilip Kumar and Amit Kapila

commit fe470e36e6ef990861d210cde6fc659657554ac3
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-02-07 21:56:43 +1300

    Don't try to use DSM segments for undo logs in single-user mode.

    Thomas Munro, per bug report from Kuntal Ghosh

commit 5f10daf1c6a1a91b4311f0a578fb9f86eb1fd5cf
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-02-06 14:13:29 +0530

    Avoid stack overflow in visibility routines

    Till now, we were traversing the undo chain in a recursive way which
    could easily lead to stack overflow for very large transactions.
    Traverse the undo chains in a non-recursive way.

    Amit Kapila, reviewed by Dilip Kumar

commit 2b3c4b122d756e4645c69709ed069eb754705a07
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-02-05 18:28:47 +0530

    Implementation of 'For Update and For Share' tuple lock modes

    This requires tuple to be locked in Exclusive or Shared mode and it
    will conflict update, delete and other modes of locks.  Currently,
    multiple lockers for shared mode are not supported, that can be done
    as a separate patch.

    For other types of lock modes, user will get error "unsupported lock
    mode".

    Amit Kapila and Kuntal Ghosh

commit 57a987ada64779896e4c5653d7e65a628f51233c
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-02-05 03:28:56 -0800

    Bug fix in bitmap scan of zheap

    Consider zheap pages when calculating MAX_TUPLES_PER_PAGE

    Patch by Mithun C Y Review by Amit Kapila

commit 35c926be66fb6d991335e93ded5ae59e1919bf2b
Author: dilip <dilip@localhost.localdomain>
Date:   2018-02-02 13:37:59 +0530

    Warning fix

commit 1d455e7504fd2a662c0624f36a42f1b303afdb20
Author: dilip <dilip@localhost.localdomain>
Date:   2018-02-02 11:14:50 +0530

    Minor check fix while recovery from worker

    Reviewed by Rafia Sabih

commit 167901ea80db5e86c64e68630ac5c1082acf464b
Author: dilip <dilip@localhost.localdomain>
Date:   2018-02-02 09:56:44 +0530

    Bugfix in wal recovery

    Flag, is_first_rec is not reset after allocating the first undolog
    for the transaction and it was considering transaction header for
    subsequent allocation for the transaction.

    Patch by Dilip Kumar Reviewed by Amit Kapila.

commit 1ddec06687a1c662d898c865d0a51fe85587040e
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-02-01 17:53:05 +0530

    Fix for Xmax value of unmodified zheap tuples

    Now, output InvalidTransactionId as the value of xmax for the
    zheap tuples which are unmodified. Previously, it was set to
    FrozenTransactionId which was incoherent with the behaviour of heap.

    Reported and reviewed by Ashutosh Sharma

commit d8c3e25148045a50a0f0a767cf803dad588e42d1
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-01-31 18:11:18 +0530

    Bug fix for undo actions

    If backend tries to apply undo actions for a record which is
    already discarded by undo worker, then exit quietly.

    Reported by Neha Sharma

commit 13ecdf57369df7a70087ce1a814fd5586dc420cb
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-29 15:18:32 +0530

    During recovery, set correct urecptr for non-inplace updates

commit 7f8c4546c7456a233b7317a08d730c797e23032f
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2018-01-26 15:18:35 +1300

    Fix recovery of undo logs after a standby crash.

    A standby should never delete undo log meta data files that are referenced by
    its own control file, or it would fail to start up.

    RM43132, analysis and patch by Ashutosh Sharma, tweaked by me

commit 83159870bccd343672cb228580ec5f3c779c6b34
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-01-25 18:55:09 +0530

    Recovery of zheap relations when rollbacks are pending

    Now, the undo actions are performed at the time of restart
    for all those transactions that were in progress at the time
    of system crash or the last time when system was up. This
    ensures proper recovery of transactions involving zheap relations.

    A caveat to note here is that undo worker is initialised with the
    connection to default database 'postgres'.

    Reviewed by Dilip Kumar and Amit Kapila

commit c308be7d90a8a8ffb068203303cf0c1c99ff4fb2
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-25 11:00:10 +0530

    Fix definition of SizeOfZHeapMultiInsert

    Reported by Amit Kapila

commit 34619026014c203f2bd9a2d151ffae2778140ea4
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-24 17:43:10 +0530

    Allow ANALYZE on zheap table using VACUUM ANALYZE command

    Also, we forward the warning to LOG to avoid regression
    failure of some test cases.

commit d5454ef8d5e0556a1fceff48dcf13d55ecc8cffa
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-24 13:47:56 +0530

    Assign table oid while constructing heap tuple from zheap tuple

commit 81e55b488c707be50437484d21a1e92b553b291d
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-01-24 12:39:39 +0530

    Move zheap_insert's buffer modifications inside critical section

    Previously, it was not done because we thought we need to add the
    tuple in page before forming the undo record as undo record requires
    blockid and offset which we can only get after adding the tuple.
    However, on closer inspection, actually, we only need blockid which we
    can get from the buffer.

    Patch by me, reviewed by Rafia Sabih

commit 9351f042a09197bcae827889e3b78ddea2e7b68d
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-02 12:07:15 +0530

    Concurrent index creation on zheap tables

    Add the ability to create indexes 'concurrently' on zheap relations,
    that is, without blocking concurrent writes to the table.
    Patch by me, Reviewed and tested by Ashutosh Sharma, Amit Kapila

commit 4780ba565205c638a890f053908157d128ea2470
Author: Beena Emerson <memissemerson@gmail.com>
Date:   2018-01-23 14:44:20 +0530

    Support storage_engine option for partitioned relations

    Allow partitioned table to have the storage_engine option and throw error when
    user tries to create a partition with storage_engine different from the parent.

    Reviewed by Rafia Sabih, Ashutosh Sharma

commit dec2957cbddadefda7b49fbf9c3a0d920d01a08b
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-01-23 12:28:41 +0530

    Bug fix for GiST indexes on ZHeap relations.

commit 9444dc2d14dc3f11d4a79156577475afe6e3f393
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-23 12:00:34 +0530

    Fix warning in nodeSamplescan

    Reported by Amit Kapila

commit bc3ff0e94567b0e85de7830113e84468fa003ed8
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-01-23 11:11:13 +0530

    Add comments to elaborate why we always use Top Transaction Id in
    zheap.

commit a1b34455e7e1ca3b48373c192c25773e84b33b95
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-01-22 02:46:07 -0800

    Bug fix in space reuse

    Fix Null pointer access.
    Patch by Mithun C Y reported by Ashutosh Sharma.

commit 34be2349dca4d238ec3fe99fbe4bbc299ca0c615
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-22 12:28:25 +0530

    Fix definition of SizeOfZHeapMultiInsert

    Reported by Amit Kapila

commit 0257c1a99b1c1958d6c1ed535d219ab7ad4e73f6
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-01-19 15:55:49 +0530

    Add zheap relevant functions in DefineQueryRewrite

    Reviewed by Ashutosh Sharma

commit 38cef475cb6c6b74765be07b2e1f419661c002f6
Author: dilip <dilip@localhost.localdomain>
Date:   2018-01-19 13:18:40 +0530

    Bug fix in space reuse

    Item is getting acceseed without checking whether its deleted or
    not.

    Patch by Dilip Kumar reviewed by Mithun C.Y.

commit ce9e110fb857e050aea92c5f1affbf7b7246d6b1
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2018-01-19 11:54:19 +0530

    Bugfix in zheap_update().

    pfree memory allocated for payload bytes during non-inplace update
    in zheap_update().

    Ashutosh Sharma, With some help from Dilip and Kuntal.

commit 079443ce69d8425b42bbd217579753f6ce8d8ee6
Author: dilip <dilip@localhost.localdomain>
Date:   2018-01-17 13:59:30 +0530

    Perform undo action in case of error.

    If there is some error while executing some sql statement, the patch
    take care of applying the undo actions required for rolling back the
    work done.

    Patch by Dilip Kumar Reviewed by Rafia Sabih and Amit Kapila

commit 9229daa6df42bc3eb60de0b4ef0728ea3a67a011
Author: dilip <dilip@localhost.localdomain>
Date:   2018-01-18 11:08:17 +0530

    Block TidScan for the zheap

    Currently, tidscan is not implemented for zheap so give error.

commit 878ea5ed9c76ce7481a86d636728cc3e7b8e288a
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-17 15:47:05 +0530

    Bugfix in IndexBuildZHeapRangeScan

    We should avoid freeing zheap tuple from the slot in
    IndexBuildZHeapRangeScan when pageatatime scan mode is used for
    scanning the underlying relation.

    Reported by Ashutosh Sharma

commit 4ce7628b00bec6b0058ec9aeb4eade82075fd0b5
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-01-17 17:19:29 +0530

    Extend the support of exclusion constraints to zheap relations

    Reviewed by Ashutosh Sharma

commit a842d28fcb9de980a290268d8c557e1749bb232b
Author: dilip <dilip@localhost.localdomain>
Date:   2018-01-17 13:58:37 +0530

    Bug fix in rewind

    If we are under a subtransaction then just reuse one
    slot, because during the rollback of the subtransaction we will rewind the
    undo insert location and the undo written for invalidating the slot will be
    overwritten. So, it is better to invalidate only one slot which our
    transaction is going to use.

    Patch by Dilip Kumar reviewed by Amit Kapila

commit e5e03186920b5a79025956258b17fe87b3d50699
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-11 17:48:06 +0530

    Fix mask value used in ZHeapTupleHeaderGetNatts

    ZHeapTupleHeaderGetNatts should use ZHEAP_NATTS_MASK to fetch number
    of attributes from t_infomask2.

commit 4c6d4c685f52b0a7d998097734d11b5387ee05c3
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-11 11:49:25 +0530

    Implement TableSampleScan for zheap

    Reviewed by Mithun CY

commit 68bee6f61f146ef71630d3809482a1944ef40ddd
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-01-10 03:26:41 -0800

    Fix cursor fetch backward scan for zheap

    Reviewed by Kuntal Ghosh

commit ed720bd223e3ce9842681ccacd4de84b052c619c
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-01-10 03:01:21 -0800

    get rid of KeyTest in zheap scan

    zheap do not support catalog tables hence
    no need of keytest as it is in heap. So
    adding asserts to acknowledge same.

    Reviewed by Kuntal Ghosh

commit cb19200ec6837fa2fb1aef37ad045db5661c892e
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-10 15:31:23 +0530

    Fix brin summarize for zheap

    Reported by Mithun CY

commit 9d6ee4a45df4911854ac32d205eeaab648ce4fb0
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-10 11:01:34 +0530

    Implement bulk insert strategy for zheap_insert

    Reported by Ashutosh Sharma

commit 8253166c9f8100e6ce75049004787215f5befe37
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-08 17:43:42 +0530

    Fix sysattributes fetching for the ZHeap

    Make sysattributes fetching work with 64-bit transaction ids.

commit e9a4184a96df7f96b53f1a849cdb75cae6b4ee2a
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-09 17:27:39 +0530

    Handl COPY FROM for non-multi-insert mode

commit 78d680eb0deef07ead5b93c70168284a73ea30ec
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-09 16:11:59 +0530

    For triggers, tuple table slot shouldn't try to free memory itself

commit 250fef496972efec042ec83a490d377b1621f4a1
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2018-01-08 14:00:45 +0530

    Support Epoch in Zheap pages

    The idea is to make the change related to 64-bit transaction ids only
    for the zheap pages whereas heap pages still operate with 32-bit
    transaction ids. We will need wraparound and freeze vacuums for
    metadata (system tables) stored in heap, but not for data stored in
    zheap tables. The way to make 64-bit transaction ids in zheap is to
    store epoch along with transaction id in each transaction slot (which
    will make each transaction slot as 16 bytes (4 bytes transaction id,
    4 bytes epoch, 8 bytes undo pointer)). Now, if we somehow ensure that
    there is no undo for any transaction whose age is 2-billion years old
    (wraparound limit), then we can easily make out the visibility using
    current epoch and oldest_xid_having_undo. The way to achieve it is to
    stop the system if it reaches such a situation. We piggybacked on the
    existing wraparound machinery to raise different warning messages once
    the system reaches that stage. If the epoch+xid in the page is lesser
    than oldestXidWithEpochHavingUndo then it is all visible, otherwise,
    the transaction will belong to current epoch and all the current rules
    of current transaction system will work.

    The reason for relying on 2-billion transaction age limit is that
    current system (Transaction related functions like TransactionIdPrecedes)
    relies on that and we don't want to change it.

    We won't need any vacuum for freezing the transaction ids or wraparound
    vacuums for zheap pages after this commit.

    Amit Kapila, with some contribution by Dilip Kumar, reviewed and
    verified by Kuntal Ghosh and Dilip Kumar.

commit 0cc6dbc97f9320a21cad0d7deb86a9867b51e97f
Author: dilip <dilip@localhost.localdomain>
Date:   2018-01-08 11:19:01 +0530

    Bugfix in rollback to savepoint

    When rollback (partial or complete) is done from the backend then
    rewind the insert location of the undo log.

commit 455bb1d00b8258f0e76b88cbae9705e308c8900a
Author: dilip <dilip@localhost.localdomain>
Date:   2018-01-08 10:22:20 +0530

    Bugfix in parallel query

    Added function for parallel begin scan on the
    zheap table.

    Path by me, reported by Mithun C.Y reviewed by Amit Kapila

commit e9d75ef1410647ef223ebf52528d8010ede6f118
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-12-29 12:11:00 +0530

    Implement ANALYZE on zheap tables

    Reviewed by Amit Kapila

commit a74fac0c485211a102ffe4208a9549f0f5f5de52
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2018-01-04 19:16:00 -0800

    Bug fix for zheap page pruning

    When pruning we should ignore deleted itemid's as there
    is no tuple space assosiated with them.
    Also if tuple is non-inplace updated then consider the
    previous space assiated with them for pruning.

commit 3d4a58d41d19cb296633801169c31eeb7caf4c23
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2018-01-04 17:51:48 +0530

    Bug fixes for storage_engine option

    Ignore the storage_engine option for views or
    partitioned relations.

    Avoid adding storage_engine option multiple times
    when it's given in conf file as well as in CREATE
    statements.

    Reported by Ashutosh Sharma
    Reviewed by Amit Kapila and Ashutosh Sharma

commit 34dfda185019a93abdb77894558e37df9cd2b9b1
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2018-01-02 14:02:53 +0530

    Implement SatisfiesNonVacuumable for zheap

    Patch by me, Reviewed by Amit Kapila

commit 63e4455ec4009eae16fc2d4bbcc8c14767f0c5dd
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-12-22 13:57:59 +0530

    Remove redundant function definition added by commit 8aeb255f.

commit fb16b15dd108f1769587a5f81d57ac5e9a9478ab
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-12-22 13:51:13 +0530

    Support space reuse within a page

    Allow reuse of space for transactions that deletes or non-in-place
    updates the tuples or updates the tuples to shorter tuples. It has
    the capability to reclaim the space for deleted tuples as soon as
    the transaction that has performed the operation is committed. There
    is some difference between the way space is reclaimed for
    transactions that are committed and all-visible vs. the transactions
    that are committed but still not all-visible. In the former case, we
    can just indicate in line pointer that the corresponding item is dead
    whereas for later we need the capability to fetch the prior version of
    tuple for transactions to which delete is not visible. As of now, we
    have copied the transaction slot information in line pointer so that we
    can easily reach prior version of tuple.

    We try to prune the page for non-in-place updates when there is
    insufficient space on the page.  The other times where we can try to
    prune the page could be while Inserting if there is insufficient space
    on a page or when buffer is being evicted or read, but we can do that
    as a separate patch.

    Mithun C Y and Amit Kapila.

commit a1bce7facfd467c804ccab660f9befb3df8eae1f
Author: dilip <dilip@localhost.localdomain>
Date:   2017-12-22 10:55:30 +0530

    Avoid using UndoDiscardInfo if it is not initialized

    If UndoDiscardInfo is not yet initialized, use UndoLogIsDiscarded to
    check whether an undo record is discarded. It also initialize UndoDiscardInfo
    for the same log.

    Reported by Mithun. patch by me

commit 4baf44c765524baf9833308af1d3807987f6889e
Author: dilip <dilip@localhost.localdomain>
Date:   2017-12-18 17:47:48 +0530

    Fix warnings in zheap code

    Reported by Thomas Munro

commit 92c2b94de69c49504f3b7d79d676b364870ff279
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2017-12-12 14:53:54 +0530

    Buf fix for prevlen of the first record of the log

    Reviewed by Dilip Kumar

commit 6616d18f3080f2d80b21c891d2376ffe58b51614
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-12-08 18:23:09 +0530

    Restrict transition table creation for zheap

commit 97119d13a22de3759574c30ebc442cf7e00e3a49
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-12-08 16:55:25 +0530

    Fix defect in applying undo action in case of abort

commit c8287a5eaac5bc934645e4cc9b51da12d8f3f71e
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-12-08 18:25:57 +0530

    Fix dirtysnapshot behaviour for inserted tuples by aborted transactions

    Reviewed by Amit Kapila

commit 1369b1c6dc27d7eeac63791725f9e010ee09e495
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-12-07 17:50:30 +0530

    Restrict foreign key triggers on zheap tables

commit 1c1befcf0e8a08ff1f5cdd49110a0f4a0140afbc
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-12-07 17:49:51 +0530

    Restrict INSERT ON CONFLICT on zheap tables

commit e135508ebd7292042d8d12b820198025e569b9b8
Author: dilip <dilip@localhost.localdomain>
Date:   2017-12-07 17:40:47 +0530

    Fix issue is PageFreezeSlot

    Memory was freed without checking NULL, fixed the same

    Reported By Kuntal Gosh

commit 1ba3aebd1b0d1789c99ba816237b487f950e40ff
Author: dilip <dilip@localhost.localdomain>
Date:   2017-12-07 16:07:34 +0530

    Fix issue in regression test

    Avoid executing undo action when transaction is not in progress

    Reported by Kuntal Ghosh

commit 787fa1ff9697dcf872546812ad606a7e41950287
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-12-06 15:46:37 +0530

    During recovery of inplace-update, fix old tuple header

    Reviewed by Amit Kapila

commit 2eec4974f8da5a7db17524250fd466fbe8995dc7
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-12-06 15:43:52 +0530

    Update tuple length during inplace-update

    During inplace-update, the tuple should be updated to the new tuple.

    Reviewed by Amit Kapila

commit 03014036363d2c494ee80f95d64f5abd5bdae48a
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-12-06 15:26:15 +0530

    Store block number before preparing the undo record

    In undorecord, we should store block number before preparing the
    undo record. Otherwise, expected size of the undo record won't
    consider the size for including block info.

    Reviewed by Amit Kapila

commit e7fb026e79d9b724edc54d1b78d2725651d77757
Author: dilip <dilip@localhost.localdomain>
Date:   2017-12-07 11:19:04 +0530

    Fix defect in applying undo action in case of abort

    Reviewed by Kuntal Ghosh

commit c646ff19e7fdaddba0b8757ce14e8ab0e824329b
Author: dilip <dilip@localhost.localdomain>
Date:   2017-12-06 10:35:03 +0530

    Fix Typo

    Reported by Rafia

commit dac6bdc623bd7b8502dd6642f784024a50abfb1d
Author: dilip <dilip@localhost.localdomain>
Date:   2017-12-05 18:55:41 +0530

    Fix warnings

commit 59eb32500326cfb4db8b1336d4ab9d97aa6741f4
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-12-05 18:22:01 +0530

    Rewind the undo pointer after applying undo actions

    After applying all the undo actions for a page, we clear the
    transaction slot on a page if the undo chain for block is complete,
    otherwise rewind the undo pointer to the last record for that block
    that precedes the last undo record for which action is replayed.

    This will help us in knowing whether the undo action is already
    replayed during recovery.

    Patch by Amit Kapila, reviewed by Dilip Kumar

commit 43c6e1c541a4e9d6cc310c1e4b46e514ddfc9f98
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-12-05 14:30:26 +0530

    UndoDiscardInfo should be updated in exclusive lock on the mutex

    Reviewed by Dilip Kumar

commit 41c6d9d337e2b09448ff324991c639793e61889e
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-12-05 14:28:00 +0530

    UndoGetOneRecord should be called under shared lock on UndoDiscardInfo

    Reviewed by Dilip Kumar

commit 49b755159affcc0f0e23f3591ddc46d2a9a1e7fc
Author: dilip <dilip@localhost.localdomain>
Date:   2017-12-01 15:27:16 +0530

    Remove genarating the subtransaction id in zheap

    Currently in heap we need to maintain the subxac id so that
    we can identify the changes done within suxact and properly
    identify the visible tuple if subxact status is not same as
    main transaction. But, in zheap we have undo and with help
    of that we can immediately revert the effect of the subxact
    and we never need to track the status of the subxact.

    This will also help in maintaining the limited slot inside the
    zheap page.  Because if we assign a separate xid to subxact then
    we may need to provide extra slot for each subxact.

    Patch by Dilip Kumar reviewed by Amit Kapila

commit c0c59ddea242f191eaeb55ddb2598ec31e77b96a
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-12-04 17:50:36 +0530

    During slot-reuse replay, use physical tuple if not included in wal record

    If tuple is not included in wal record, access the physical tuple
    to fetch the corresponding slot number for the same tuple.
    Reported by me, patch by Dilip Kumar.

commit a83904b8bb7e5aa81e8906d2daefed70afdacd80
Author: Mithun CY <mithuncy@localhost.localdomain>
Date:   2017-12-04 20:48:01 -0800

    Zheap tuples are locally allocated hence set
    tts_shouldFree as true.

    Reviewed by kuntal

commit 5d561693d232b766ed618f48498b9a667cc1ac56
Author: dilip <dilip@localhost.localdomain>
Date:   2017-12-04 17:36:45 +0530

    Fix issue in prevlen

    Return without releasing the lock
    Reported by Kuntal Ghosh

commit b5071ac66cf206801b0de4f0cc9de4390bb59cf8
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-12-04 14:34:27 +0530

    Avoid using UndoDiscardInfo just after undoshem initialization

    If UndoDiscardInfo is not yet initialized, use UndoLogIsDiscarded to
    check whether an undo record is discarded. It also initialize UndoDiscardInfo
    for the same log.

    Reported by Neha Sharma, patch by me, reviewed by Dilip Kumar

commit f916f158f39676de2ab755118924518e3c6f45b1
Author: dilip <dilip@localhost.localdomain>
Date:   2017-11-28 09:16:00 +0530

    Make prevlen crash safe

    Currently transaction previous recrod's length is not crash safe
    but there is possibility that transaction can be spread across
    checkpoints, in such case while preparing the first undo record
    we do need to have the length of the previous record which was
    inserted before checkpoint. For fixing the same we are maintaining
    this value in undo meta and wal logging this along with other
    undo meta.

    As part of this patch also removed one unused structure member
    in undo meta.

    Patch by Dilip Kumar Reviewed by Amit Kapila

commit f20d78fe0d048ba600162e0f5d794399e0dbee13
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-11-22 16:27:25 +0530

    Write WAL for zheap_multi_insert

    Reviewed by Dilip Kumar, Amit Kapila

commit ed0f47495ef7de6c0e0e8940b6ac630704b0bf77
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-11-22 16:08:25 +0530

    Set uur_type for multi_insert at begining

    Reviewed by Amit Kapila, Dilip Kumar

commit e13cb875476963959cea79edd114fa8d701909e0
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-11-14 14:49:30 +0530

    Fix assertion failure in zheap_delete

    Reported by Neha Sharma

commit ee06e282b6bb1c64d6c0820fb2c690778af71f71
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-11-21 20:32:49 +0530

    Derive latestRemovedXid for hash deletes by reading zheap pages

    Reviewed by Amit Kapila

commit bf78457e2e7706338d00f60fbe487b315b626ff5
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-11-13 21:02:12 +0530

    Derive latestRemovedXid for btree deletes by reading zheap pages

    Reviewed by Amit Kapila

commit 53b6d509674a0aa1b59c00306bdec63c9cad3110
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-11-22 10:26:35 +0530

    Implement exclusion constraints for zheap

    Patch by Ashutosh Sharma. Reviewed by Kuntal Ghosh, Amit Kapila.

commit a4f00f80ba4745c45be7d747bdd7d4a6363a78f7
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-11-22 09:33:47 +0530

    Implement SnapshotSelf for zheap

    Returns the visible version of tuple (including effects of previous
    commands in current transaction) if any, NULL otherwise.  This will
    be required for features like exclusion constraints to work with
    zheap.

    Ashutosh Sharma and Amit Kapila

commit a1f49ef37d8bbfd19741bc76b0c749000c9d281d
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2017-11-21 12:13:44 +0530

    Bug fix in rollbacks in zheap

    The patch fixes the case where ending undo record pointer
    is not provided. This is particularly required in rollback
    to savepoint type of scenarios.

    RM 42958, reviewed by Amit Kapila.

commit 64ecef026b765bba8262b3acce21b3c308e2b02a
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-11-21 08:54:58 +0530

    Implement the API to advance the latest xid that has removed the
    tuple.

    This will be required by the future patches to implement free space
    management and xlog for indexes like btree and hash.

commit b6d4a835ee52a6c0eec1e2e29c0dc84f866ab42a
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-11-20 17:43:12 +0530

    Implementation of undo actions for zheap operations

    Implemented undo actions for delete, update, lock tuple, multi-insert
    operations.

    Patch by Amit Kapila, reviewed by Rafia Sabih

commit 6828caf8f4d53788756079e0059a0d117e92afe3
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-11-20 17:27:37 +0530

    Infrastructure to execute undo actions at page-level

    Starting from the last undo record of a transaction read the undo
    records in a backward direction till first undo record of a
    transaction and accumulate the actions per page.  As soon as the
    action is for a different page, we execute the accumulated actions
    of previous page.

    We are logging the complete page for undo actions, so we don't need
    to record the data for individual operations.  We can optimize it by
    recording the data for individual operations, but again if there are
    multiple operations, then it might be better to log the complete
    page.

    Patch by Amit Kapila, reviewed by Rafia and Dilip

commit c00df8c30bd5baa1eb1ea14f89747ee5ea7d7fe0
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-11-20 09:56:20 +0530

    Write WAL for zheap_lock_tuple

    Patch by Ashutosh Sharma and Kuntal Ghosh. Reviewed by Amit Kapila.

commit c00823a0787680eb8c0f02b8d998c6cf3bad39b1
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2017-11-17 15:59:40 +0530

    Bug fix for rollback inserts

    The page header size was not included in the calculation of
    prevlen for undo records when record starts from a new page.
    The patch fixes the issue.

commit b7bda571bb9c01fe2cb9355f9fd498cb6aa06078
Author: dilip <dilip@localhost.localdomain>
Date:   2017-11-16 18:10:42 +0530

    Write WAL for invalidating the transaction slot

    The important consideration for logging invalidating slot operation is
    that we need to identify the tuples pointing to these slots and also the
    transaction id in the slot while performing redo operation for undo log.
    So, we are conditionally (when full page writes are off) writing tuple
    offsets and slot xid in WAL as well.  In case full page writes are
    on, we can rely on the tuples and slots from page.

    Path by Dilip Kumar, Reviewed by Kuntal Ghosh and Amit Kapila

commit 9c9a8f88ad2b8fea8a319e0d9aad40924e1f5684
Author: dilip <dilip@localhost.localdomain>
Date:   2017-11-16 18:09:18 +0530

    Write WAL for slot Freeze operation

    Write the information of the slots which got frozen and during recovery
    we can generate the information of the tuple which are pointing to these
    slot and mark them frozen same as we are doing in DO operation.

    Path by Dilip Kumar, Reviewed by Kuntal Ghosh and Amit Kapila

commit f1be5834b52f5023522af5ce862f9c2c40d7048e
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-11-15 17:17:17 +0530

    Store old version of tuple in WAL for delete

    Patch by me, reported and reviewed by Ashutosh Sharma

commit e1a47f763d17e4bc33af7ae64fa234f7fefbed96
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2017-11-14 13:26:53 +0530

    Support for SELECT INTO statements for zheap

    This enables the creation of tables in zheap format
    through SELECT INTO statements.

    Reviewed by Amit Kapila.

commit e1afa7d5eacde17d322dadb659f1d4c78d628cdb
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2017-11-14 11:56:43 +0530

    GUC for storage_engine

    Now, we have a GUC -- storage_engine to specify the storage_engine option,
    which can be modified before server start. Currently, we have two options
    for this GUC, viz. heap and zheap, with it's default value being heap.
    Note that once this GUC is set to zheap, relations are created in
    zheap format, irrespective of whether with (storage_engine ='zheap')
    is specified in CREATE TABLE statement or not.

    Reviewed by Amit Kapila.

commit 2587d533e90aa99701d3125f2dc0ac00c9a54029
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-11-13 14:11:58 +0530

    Use better way to set item pointer.

    Suggested by Kuntal Ghosh.

commit 2c3e87e4e9efdef30663c93ee606c12de10c78de
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-11-13 13:09:03 +0530

    WAL log update operation in zheap

    The important consideration for logging update operation is that we
    need to generate entire old tuple while performing redo operation for
    undo log.  So, we are conditionally (when full page writes are off)
    writing complete tuple in WAL as well.  In case full page writes are
    on, we can rely on the tuple from page. For the new tuple, we are
    writing just the diff tuple as we are doing for heap.

    Patch by me, reviewed by Kuntal Ghosh.

commit a6eb456784db76b444121ef171d635e4c4a01e13
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-11-13 08:56:41 +0530

    Fix type of undo record in zheap_multi_insert

commit d1859b51bd51ac39d8915f40df7ff679c3df0461
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-11-10 18:31:54 +0530

    Fix the calculation of previous undo record length

    When the undo record crosses page boundary, we need to consider
    pageheader length which was being ignored.  Fix the same.

commit 4159a0175ce16bd5684314b63a23c0cf9fc8733e
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-11-09 22:27:44 +1300

    Show unattached undo logs as null xid and pid in pg_stat_undo_logs.

commit fce53d149e2b6e67e40eb33b92517cd58673cd4b
Author: dilip <dilip@localhost.localdomain>
Date:   2017-11-08 17:13:31 +0530

    Enhance zheap_lock_tuple

    Handled the case when same tuple is locked multiple time by
    the same transaction.

    Patch by me, reviewed by Ashutosh Sharma and Amit Kapila.

commit 91cd6e14fa9e2a2a9a4bb929750951ed7cfa68ef
Author: dilip <dilip@localhost.localdomain>
Date:   2017-11-08 17:03:49 +0530

    Bug fix in trigger for zheap

    Currently we are always getting the older as well as newer version
    of tuple from the zheap. But, in case of inplace update both are
    having same tid and will fetch the tuple.  Patch will fix the bug
    by getting the older version of the tuple from the undolog.

    Patch by me, reviewed by Ashutosh Sharma and Amit Kapila.

commit 0ef921f6fc46aa6a3fd20eac9d199a3e173c1fc1
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-11-06 16:00:43 +0530

    Restrict ExecLockRows on zheap relations

    As of now, we don't support FOR SHARE/FOR UPDATE on zheap tables.
    So, throw appropriate error for the same.

    Reviewed by Dilip Kumar

commit 3e73bc3ccd71c28c962749dcda4e54bc8f245022
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-11-08 11:18:50 +0530

    WAL log delete operation in zheap

    The important consideration for logging delete operation is that we
    need to generate entire tuple while performing redo operation for undo
    log.  So, we are conditionally (when full page writes are off) writing
    complete tuple in WAL as well.  In case full page writes are on, we
    can rely on the tuple from page.

    Patch by me, reviewed by Ashutosh Sharma.

commit eaf3708c605930073dcb0d64caad1c9dd13efb01
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-11-07 15:42:10 +0530

    Fix assert in bitgetzpage

commit 01104c4a5af83cff71704bb399172e9c050929c0
Author: dilip <dilip@localhost.localdomain>
Date:   2017-10-27 13:58:08 +0530

    Support sysattributes fetching for the ZHeap

    Properly fetch the xmin,xmax,cmin and cmax from the undo.

    Patch by Rafia some defect fixed by me reviewed by me and Amit.

commit 50f4297716c242fee4cb8e34c2903ccef297983f
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-10-25 18:11:37 +0530

    Undo Action and Replay for Insert Operation

    The undo insert action is to mark the corresponding item as dead if
    relation has any index and unused otherwise.  The need to item as
    dead is that we can't completely clear the item till the
    corresponding index is marked as dead.  Currently undo actions are
    replayed on Rollback or Rollback to savepoint.  Ideally the action
    should be replayed on error as well, but we will deal with it in
    a separate patch.

    Amit Kapila, reviewed and tested by Rafia Sabih

commit a461ec04e06d1675d635904caa3d993370c7ef0f
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-10-25 17:44:57 +0530

    Update prevlen in undo record header with the length of previous
    record.  This is required to traverse the undo chains from last undo
    record to first.

    Dilip Kumar.

commit 66c00153e2de48f9b8ab5c8d2454f87cb2efea6d
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-10-23 17:57:39 +0530

    Bug fix in UndoLogAdvance

    During recovery, MyUndoLogState is uninitialized. Hence, It can't be
    used to fetch undo control pointer while replaying undo records.

    Reviewed by Amit Kapila, Dilip Kumar

commit 08870389179383469196b243b6b5662bc8d41cb6
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-10-18 14:21:19 +0530

    Restrict alterting non-empty zheap tables

    During ALTER command, sometimes we scan and rewrite a table.
    For zheap, we've to implement the same in ATRewriteTable. For now,
    just throw an appropriate error.

    Reviewed by Amit Kapila

commit 1207f60fb21542e8b6675335848d373e6aafed3d
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-10-18 15:04:01 +0530

    ALTER should restrict partitioning/inheritance to same storage_engine

commit d43e896ba1e66d0a8246bbb3df58c4f38010fcbd
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2017-10-17 17:07:05 +0530

    Hibernate undo-worker when the system is inactive

    The undo-worker hibernates for minimum of 100ms and maximum of 10s,
    based on the time the system remained idle.

    RM42373, reviewed by Mithun Cy

commit 9c612f44ad2204510ab13a620a003460889c41db
Author: dilip <dilip@localhost.localdomain>
Date:   2017-10-17 16:42:38 +0530

    Bug fix in multi-insert

    uur_xid is not set properly in multi-insert that was making undo-discard
    operate based on invalid xid and was causing segmentation fault.

    Reported by Ashutosh, fixed by me Reviewed by Kuntal

commit 0023cc82949adc74fdb18c7825cf7e5d1988da49
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-10-04 15:20:38 +0530

    Restrict partitioning/inheritance to same storage_engine

    The descendant/partitioned table inherits the same storage
    engine as its ancestors. User should not specify any storage_engine
    for the descendant/partitioned table. Also, this commit doesn't
    include any sanity checks for the scenarios where heap table
    inherits zheap table and vice versa.

    Reviewed by Amit Kapila, Rafia Sabih

commit 99623dfb48a055ae2b43db76d9e87747915fec09
Author: Rafia Sabih <rafia.sabih@enterprisedb.com>
Date:   2017-10-17 10:39:51 +0530

    Avoid iteration over all the backends in UndoDiscard

    Instead of iterating over all the backends, now iterate only
    the active logs to determine the next log for undoDiscard.

    RM42373, reviewed by Dilip Kumar

commit 8f40d7b7802c1904f4c845c744f62a366d2f9a8a
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-10-17 13:58:11 +1300

    Fix undolog wordsize thinkos that broke 32 bit builds.

commit 927c309586f38da7c737594c3beef65f7c51e5cc
Author: dilip <dilip@localhost.localdomain>
Date:   2017-10-16 21:11:17 +0530

    Bug fix in update transaction start record

    In recovery start transaction info was not updated properly, it was
    fetching prev_xact_start from local variable which in fine during
    normal run, but InRecovery there is only one process so we can not
    depend upon the local variable instead we should always fetch that
    from log meta data.

commit ea6bf762f2a6f5673e8978118edfee99767b844f
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-10-12 05:53:59 +1300

    Implement UndoLogNextActiveLog().

    Provide a simple way to iterate through the set of active undo log numbers.
    This interface might need some refinement to support UndoPersistence
    levels in future.

    RM42373, Rafia Sabih

commit 712f332b5ac98b22110929ae2136e4b0c38dffab
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-10-11 14:47:58 +0530

    Don't discard undo if a transaction rolls back

commit 1c2daa5b5a47856a227ad66c7cc08e761e147871
Author: dilip <dilip@localhost.localdomain>
Date:   2017-10-11 09:48:37 +0530

    bug fix in Synchronizing undo update with undo discard

    update undo record is just checking whether undo is discarded
    or not, instead it should acquire the discard lock and read the
    undo under the lock. Fixed the same.

commit 8f17025103fc2c344f56b05770550e50e79b5bb3
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-10-05 16:48:57 +0530

    Wrong undorecord expected size for first record of a undolog

    When we attach a new undo log, a new transaction is definitely started.
    Hence, we should set is_first_rec flag in undo meta and calculate the
    undorecord expected size.

    Reviewed by Dilip Kumar

commit 23be6c5939487c691e77c03daffbdb04dff9afb4
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-10-04 11:36:04 +0530

    Fix some compiler warnings

commit 21c53521b5a1e98ba21a83ec0e8abd5fc97fa866
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2017-09-28 15:11:33 +0530

    Add missing null terminator to the dest string after memcpy().

    memcpy() does copy the specified bytes of string from memory area
    src to memory area dest, but, doesn't add null terminator to the
    dest string. This patch handles to same in FindLatestUndoCheckpointFile().

    Patch by me, reported by Amit Kapila.

commit cee1d83ad2888cfe451ec6bf7c31c31ae79b694b
Author: dilip <dilip@localhost.localdomain>
Date:   2017-09-28 14:16:05 +0530

    Fixed pending issues for WAL recovery

    Fixed the recovery for the subtransaction and properly update
    the start transaction header record.

commit 4df8c94e347ee6291f9310840164125e3c57a5fe
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-09-28 09:25:43 +0530

    WAL log Insert operation in zheap

    We need to ensure that we log enough information that during recovery,
    we can construct the unpackedundo record and then insert it in same
    way as we insert for the DO operation.  Note, that we don't write full
    page image for undo logs as those are written serially and we always
    apply all the WAL records for undo log unlike for zheap pages where
    we don't apply it, if the LSN on a page is greater than the LSN of WAL
    record.  This is to avoid problems like if the page header is written
    after last checkpoint, but the other part is not then the LSN in page
    header will be latest but not all the data.

    Patch by me, reviewed by Dilip Kumar.

commit 604100e9ff28172ef1c4372745fafd5501e03a98
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2017-09-27 16:45:24 +0530

    Throw an error message if index-only scan is performed for zheap
    tables.

    Patch by me, per suggestions from Amit Kapila.

commit 91630e7f7129b76fe46f29637f4117fca7ef3963
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2017-09-26 16:30:52 +0530

    Make the macro 'RelationStorageIsZHeap' (used to determine if the
    relation storage format is zheap or not) more robust.

    Patch by me, quickly reviewed by Dilip.

commit 31a1c21f3e38e1935a8e8d9061ea307273ead50c
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2017-09-26 10:34:17 +0530

    Add macro 'UndoCheckPointFilenamePrecedes' to find the oldest undo
    checkpoint file in pg_undo directory.

    RM42357, Patch by me, as per the suggestions from Thomas Munro.

commit fb101c53f1c750c6ca37b049694db50118637b61
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2017-09-26 10:29:28 +0530

    pg_upgrade: Rename undo checkpoint file after pg_resetwal.

    During pg_upgrade, pg_resetwal module is invoked which resets all WAL
    related information in the Controlfile including the last checkpoint
    LSN and then a server process is started. But, as the undo checkpoint
    filename is based on last checkpoint LSN, the server startup process
    fails as it is unable to find the undo checkpoint file corresponding
    to the last checkpoint lsn as mentioned in the Controlfile.

    This patch fixes that issue and also copies the undo data and checkpoint
    files from old to new cluster during pg_upgrade.

    TODO: Currently, this patch just adds the logic to copy undo data files
    from default location i.e 'base/undo' which means if undo data files are
    present in non-default location it won't work. In future, when the support
    for storing undo data files in the non-default location is added, that
    needs to be handled in pg_upgrade as well.

    RM42357, Patch by me, reviewed by Thomas Munro.

commit c95f0fda591c3d1e1b3e520570c8e616d4fb42ea
Author: dilip <dilip@localhost.localdomain>
Date:   2017-09-25 11:51:06 +0530

    Added trigger supports for zheap

    Currently zheap is not supporting the triggers because all
    trigger mechanism is dependent on HeapTuple, this patch
    provide a conversion between heap and zheap tuple and also
    a api to fetch tuple from zheap for trigger.

commit 13b7d1735e5444fca61368df9ab515267eadf4be
Author: dilip <dilip@localhost.localdomain>
Date:   2017-09-22 15:00:13 +0530

    Bugfix in undo discard

    If log is not attached to any session it will have invalid
    transaction id.  In such case just discard till the current
    insert location.

commit ef93ec6350767d863b30cd8a11e632a1442a22af
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-21 16:50:30 +0530

    Fix update of zheap columns with null

    For in-place updates, we should copy non-visibility flags of
    infomask in the updated tuple.

    Reviewed by Amit Kapila

commit 19c54fb49faecbde387be5ed6bde2bc94cbf67bf
Author: dilip <dilip@localhost.localdomain>
Date:   2017-09-22 09:49:29 +0530

    Bugfix in undo discard mechanishm

    Prior to this undo was not discarded properly for the last transaction
    in the undolog hence oldestxidhavingundo was also not getting updated
    properly.

commit 5e45ce2025a7024937763e71dcde007941057c3f
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2017-09-21 20:03:44 +0530

    Replace unwanted Assert statement in ZHeapTupleSatisfiesDirty
    with if-check.

    Patch by me, reviewed by Amit Kapila, reported by Neha Sharma.

commit 943e365fc06f42c264b9c39d78d9a8a94b3754b6
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-09-21 15:00:10 +0530

    Use oldexXidHavingUndo to determine if the record is visible

    Previously we were using RecentGlobalXmin to determine if the record
    is all visible, that is okay till we have rollbacks.  Use the more
    appropriate xid i.e oldexXidHavingUndo to determine if record is all
    visible.

    Patch by me, reviewed by Dilip and Kuntal.

commit 6715131fd875709a5b4d89808117b2e17bb7cc32
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-09-21 14:02:57 +0530

    Code refactoring to eliminate duplicate code.

    We were using the similar code to fetch transaction information from
    undo records in multiple places.  Expose a new function to fetch that
    information and use it in all places.

    Patch by Amit Kapila, reviewed and tested by Dilip and Kuntal.

commit a69d8bb6cc49b4bfb3ef0ad8321508007f7e7d66
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2017-09-20 16:18:19 +0530

    Allow INSERT/UPDATE/DELETE RETURNING to work with zheap relations.

    Patch by me, reviewed by Amit Kapila, reported by Tushar Ahuja.

commit 9c886fcb2e34d1ec073ce260a032c5fe3a484695
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-19 18:53:55 +0530

    Implement Bitmap Scan for zheap

    Reviewed by Amit Kapila

commit 113966f8755edabf26ce62eb54798a5bdb419911
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-19 23:44:47 +0530

    Implement COPY-TO for zheap relations

    Reviewed by Amit Kapila

commit 414f84fd6026b0e282c10b9fe01f40898d5a22a4
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-20 00:12:16 +0530

    Index Scan for spgist,gist,hash

    Reviewed by Amit Kapila

commit 95e893242410969de851bdf746b54b69292134ec
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-20 13:57:24 +0530

    Skip vacuum for zheap relations

    Tell autovacuum worker to skip zheap relations for vacuum. Also,
    throw appropriate error if one intends to vacuum zheap relations
    with VACUUM command.

    Reviewed by Amit Kapila, Dilip Kumar

commit e33f25249fc55d24c919d345b233a12b27e00db2
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-18 16:24:18 +0530

    Handle MinimalTuple for ztuple

    Reviewed by Amit Kapila, Ashutosh Sharma

commit f0d0850e99b3303a913a3f06998e120f052b0440
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-19 22:33:23 +0530

    Fix Oid crash in ExecInsert

commit aa0eefadeee806f7691cbe2374a942e771ca8d30
Author: dilip <dilip@localhost.localdomain>
Date:   2017-09-19 12:14:37 +0530

    zheap mvcc routine was not set properly in RestoreSnapshot
    which was causing problem in parallel query.  This commit
    fixes the issue

commit e43b9eeeb33b7cce358e4a1bede6623151bb4101
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2017-09-18 22:06:22 +0530

    Correct the XLOG record type used in UndoLogSetLastXactStartPoint().

    RM42384, Ashutosh Sharma, reviewed by Dilip Kumar and reported by
    Mithun CY.

commit 2edda475a0c19b293d61f657c02a4b38221765f5
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-09-18 14:49:31 +0530

    Retrieve CTID from undo record when requested.

    Reported by Neha Sharma.

commit f34620869854458a3a671c2112b38109fc240af2
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-15 12:11:23 +0530

    Move BulkInsertStateData def to genham.h

commit 7b30e2d13b1ef23d19ba0d1c521e901d50be21ec
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-14 14:41:27 +0530

    Fix comment style in zheap_multi_insert

commit 91094f3776e5aa18b71fb0360d5e754b128998ae
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-14 13:51:35 +0530

    Implement COPY FROM command for zheap relations

    Reviewed by Amit Kapila, tested by Ashutosh Sharma

commit e7de2741292bfce5ddb7c69c102010f1dc81e2ed
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-07-21 12:00:38 +0530

    Add options in zheap_prepare_insert like heap_prepare_insert.

    Reviewed by Amit Kapila

commit 1d9f79cf415be06824f8893c5e6cdb58bdde3f18
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-13 13:40:44 +0530

    Fix warnings in zheapgettup_pagemode

commit fba570c012c02b96bb3817e33763f03dde1248a1
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-12 15:37:26 +0530

    Isolation tests for non-inplace updates

    Reviewed by Amit Kapila

commit 51fb8188e05d92a973ee14a057c956fec2caab93
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-12 15:42:22 +0530

    Regression tests for non-inplace updates

    Reviewed by Amit Kapila

commit 039efbc45bb68a11db71ed0137d619af07951b54
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-09-11 17:40:21 +0530

    Fix usage of tuple in visibility API.

    ZHeapTupleSatisfiesVisibility API doesn't guarantee that the tuple
    passed won't be freed, so we can't reuse it.

commit ff452720310a3a8cbb27ff85625a5276110f9de2
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-09-11 17:26:27 +0530

    Support non-inplace-updates

    Allow tuples to be updated such that a newer version of tuple will be
    stored separately if any index column is updated or length of new
    tuple is greater than old tuple.

    For undo generation, we always generate two undo records one for the
    deletion of old tuple and another for addition of new tuple.  We need
    separate undo record for new tuple because during visibility checks we
    sometimes need commandid and that is always stored in undo record.  To
    reach new tuple from old tuple, we need ctid which is stored in old tuples
    undo record.

    Patch by me, review and test by Dilip Kumar and Kuntal Ghosh.

commit 918aea9d904dd4f2ea82c8e4b0aefd7006cedce8
Author: dilip <dilip@localhost.localdomain>
Date:   2017-09-11 16:44:26 +0530

    Support multi-prepare for undo record

    This will support preparing multiple undo record and all of
    them can be inserted with one call of InsertPreparedUndo.

    Reviewed by Amit Kapila.

commit 4df6058209a1028f328b5976315b9373d8385afc
Author: dilip <dilip@localhost.localdomain>
Date:   2017-09-07 10:57:14 +0530

    Fix compilation warning

commit 3d9616d314008d2c34942d50d81d40558a771eda
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-06 18:19:48 +0530

    CREATE INDEX on non-empty zheap relations

    This extends the implementation for index creation on zheap
    relations to non-empty relations as well.
    Patch by me, reviewed by Amit Kapila

commit 295f464ede2c243c7872cd3bc48b4d022b4cf9d8
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-09-06 15:15:30 +0530

    Implement and ZHeapTupleSatisfiesAny and
    ZHeapTupleSatisfiesOldestXmin

    Both these API's are required by upcoming patch to create index.
    These API's implement functionality similar to the heap API's
    HeapTupleSatisfiesAny and HeapTupleSatisfiesVacuum, but for zheap
    tuples.

commit a1bbc57456a2c0985aad6ca14042ff8690275b9b
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-09-01 17:07:30 +0530

    storage_engine can not be modified after table creation

    storage_engine can be set during CREATE TABLE. But, it can't be
    set/reset using ALTER TABLE later.

    Patch by me, reviewed by Mithun CY

commit 01e757ed5ff8e86fdece673c2dcee9d737628c5f
Author: dilip <dilip@localhost.localdomain>
Date:   2017-09-04 16:59:52 +0530

    RM42314: Fixes one part of the problem

    Implements better way to know whether the undo record
    is discarded or not instead of adding the TRY_CATCH as
    done in current code.

commit fc5e48996af7ea9398aed4adfce093ba7bba3c53
Author: mithun <mithun@localhost.localdomain>
Date:   2017-09-04 11:58:16 +0530

    RM41618: Asynchronous Undo Management - Undo BgWorker Part.

    Improved the log messages.

commit 7231d04084c1d305c374c91c8ac9328186ae90e2
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-09-01 15:30:39 +0530

    Fix typo in error message

commit b9746b046d25e8db6c36cd28bd49e72f650e3552
Author: mithun <mithun@localhost.localdomain>
Date:   2017-09-01 11:39:53 +0530

    RM41618: Asynchronous Undo Management - Undo BgWorker Part.

    registered a SITERM handler for undoworker.
    Review by Kuntal.

commit fec2d893806c3b163d4c96e6c2864361ad2eccae
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2017-08-31 17:15:20 +0530

    Implement PRIMARY KEY for zheap relations.

    This patch allows PRIMARY KEY to be created on zheap relations.
    For now, all it does is, throw an error message, if user tries
    to add a NULL or duplicate value on primary-key column (i.e. when
    primary key constraint is violated) but it doesn't protect it
    from getting inserted into a zheap table as currently ROLLBACK is
    not implemented in zheap. Therefore, if users tries to violate a
    primary key constraint on zheap table, it will result into a data
    corruption.

    RM42103, Ashutosh Sharma, reviewed by Kuntal Ghosh and Amit Kapila.
    Few adjustments done by Amit Kapila.

commit 5b704a091e300d12f18e0bba4d6e2083fd652d0b
Author: mithun <mithun@localhost.localdomain>
Date:   2017-08-30 08:25:40 +0530

    RM41618: Asynchronous Undo Management - Undo BgWorker Part.

    One undoworker's launcher process which calls a loop to
    periodically examine and discard undos of transactions
    which are visible to all.

    This is a very basic form of undoworker which can be used
    by undo subsystem for discarding undos. This code will
    later evolve into a more complex undoworker subsystem.

commit 1c16e16158d83850c20602acce9b6ab5e8833b7c
Author: dilip <dilip@localhost.localdomain>
Date:   2017-08-29 18:20:28 +0530

    Discard Interfaces for undo worker

    Provide an interface to discard all the undo which are inserted by the
    transaction id which is smaller than input xid.  This will also calculate
    the oldestXidHavingUndo.

    Reviewed by Amit Kapila

commit 5e7384fc7d2684ca0714147a0a1c60fdeed8d7fd
Author: dilip <dilip@localhost.localdomain>
Date:   2017-08-29 18:19:07 +0530

    Inserting a transaction header in the undo record.

    Insert a transaction header in the first undo record by the transaction. This
    header will contains the undo record ptr of the next transactions first undo
    log.  This will be used by discard apis to process a undolog transaction by
    transaction.

    Reviewed by Amit Kapila

commit 72ca11a0fe330abd69958c361ecf8fde2369802f
Author: dilip <dilip@localhost.localdomain>
Date:   2017-08-29 17:58:11 +0530

    Protection against accessing the discarded undo.

    This is a dirty way to handle the problem, we may need to find some
    better way for the same.

    Reviewed by Amit Kapila

commit 35c917a1e21c1c17c7de0d026c0820ac4086c0a2
Author: mithun <mithun@localhost.localdomain>
Date:   2017-08-29 16:16:55 +0530

    RM42266: Support no movement scans for zheap.

    It seems the NoMovementScanDirection is a dead code for
    heap itself. So got rid of related code in zheap and added
    an Assert(false) to indicate same.

commit 38a4d0037a5636e08e00a4e3a352a4b1ded8ba61
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-08-29 15:27:29 +0530

    Make PageSetUNDO less chatty

commit 44c19cc1a6db1c8bd6a4d21b17d1549c059c77d1
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-08-28 23:00:23 +1200

    Fix build problem on Windows.

    On Windows we have a macro wrapping open() that always needs three arguments.
    Per complaint from Amit Kapila.

commit 1302ec61e5bb482789db809c344b3fed5a9d6dae
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-08-28 15:57:26 +0530

    Change ValidateTuplesXact so that it always get the fresh copy of
    tuple.

    If the tuple is updated such that its transaction slot has been changed,
    then we will never be able to get the correct tuple from undo. To avoid
    that we get the latest tuple from page rather than relying on it's
    in-memory copy.

    Amit Kapila and Dilip Kumar

commit 531f8bf739266d5d0e40512a983cc5b757689810
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-08-28 15:11:39 +0530

    Add comments in code to explain the usage of commandid while
    traversing undo chain.

commit bd9d5215d2deff90615d8108cbdad07d8d4894df
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-08-28 14:46:32 +0530

    Improve comments in code.

commit 91416a25cd2f950a7de078d7661f18e411962c15
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-08-28 14:43:11 +0530

    Always write complete tuple in undo of delete.

    This will ensure that we can reuse the space of deleted tuples as soon
    as the transaction commits.

commit e63edb162c3a18acc7dc10e9510b24b53d2ddfda
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-08-28 14:23:54 +0530

    Fixed few warnings.

commit ed04b0bc3a955f0abfe712626c13dd3734a3676c
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2017-08-25 13:18:05 +0530

    Remove isolation test for REPEATABLE READ mode and rename mvcc.spec
    file with zheap prefix.

    Commit 0fd69d86 unintentionally added isolation test for REPEATABLE
    READ mode. But unfortunately, zheap is currently just restricted to
    READ COMMITTED mode. Hence, this commit removes the test added for
    REPEATABLE READ mode and it also renames the test file with zheap
    prefix.

    Patch by Kuntal Ghosh, reviewed by me.

commit 953868285ef6d57c83a246603d5e3b615b837b3a
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-08-24 21:17:31 +0530

    Allow transaction slots to be reused after transaction is finished.

    To reuse the slot, it needs to ensure that (a) the xid is committed
    and all-visible (b) if the xid is committed, then write an undo
    records for all the tuples that belong to that slot.  The undo record
    will cover the transaction information of committed transaction. The
    basic idea is that after reuse of slot, if someone still needs to find
    the information of prior transaction that has modified the tuple, the
    same can be retrieved from undo.

    We can reuse the slot even after the transaction has aborted, but for
    that we need to have Rollback facility which is currently not
    implemented, so we can't reuse slots of aborted transactions.

    Amit Kapila and Dilip Kumar.

commit 13de424924220e65ec7348687210e3752ad0fd50
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-08-22 17:13:52 +0530

    Fix crash in EvalPlanQualStart during isolation check

    We can't use es_result_relation_info in EvalPlanQualStart to decide
    the type of the underlying relation. Instead, We can use es_range_table.

    Reported by Amit Kapila.

commit 10c6bff9873d3ce203eb0368ee262a67d6f43d79
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-08-11 15:54:28 +0530

    Deform zheap tuples for aggregate nodes

    Aggregate nodes don't recognize zheap tuples. To fix this,
    we deform a zheap tuple in ExecCopySlotTuple and form a heap
    tuple from the same.

commit 61d3d5e7178203d3070a11872bcdc64d365fce16
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-08-21 17:25:12 +0530

    Fix type of urec_fork in UndoRecordRelationDetails

commit 3d390e874b93b8f265520d2381cd5227f6f8f60c
Author: ashu <ashutosh.sharma@enterprisedb.com>
Date:   2017-08-18 16:26:43 +0530

    Add some isolation tests to validate MVCC model with zheap.

    Thomas Munro and Ashutosh Sharma (The original patch here was
    by Thomas Munro and it was for heap storage, but I ported
    it to zheap.)

commit 89466c9b213f939809de73ae21e8ec939cec1925
Author: dilip <dilip@localhost.localdomain>
Date:   2017-08-07 14:35:11 +0530

    Mark buffer dirty after inserting the undo record in undo buffer.

    Reported by Thomes and Amit.

commit 8fec492113e3f03eeea42063b23b530b689bfd8e
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-08-05 21:10:32 +1200

    Correct comment.

commit e5818f2fd0b55cab123926db0afc52e832d44dd6
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-08-05 21:08:17 +1200

    Define a macro UndoRecPtrFormat for use in printf-style functions.

commit 5eedbd8378b0b32cee25ff882a78082a273ac9a6
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-08-04 16:53:50 +1200

    Git rid of last_size tracking from undo storage layer.

    This problem belongs higher up.

commit 93d94231ef7ff2b30a2c8ae5d795ca9129a0f00d
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-08-04 16:47:41 +1200

    Report all UndoRecPtr values as hex in pg_stat_undo_logs.

    Previously raw offsets were shown.  Let's not confuse ourselves with more
    than one representation.

commit 1bc609f9f3943c70e94a3cd409c32c536871f309
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-08-04 16:47:14 +1200

    Raise error if you try to access non-existent undo segment.

commit 799820348f683ff7b4120fdd3356ea75e98b757f
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-08-04 16:34:31 +1200

    Make test_undo module more cromulent.

    Also change type used for space allocation size_t rather than anything smaller
    so that we can test insertion of large amounts of data at once.

commit def8e64b77cb8e50ac12768f930ee6dbc3785a38
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-07-26 17:21:29 +0530

    Update the transaction id in undorecord header

    Separately store the latest transaction id that has changed the tuple
    in the undo record header to ensure that we don't try to process the
    tuple in undo chain that is already discarded. As of now, we are
    using RecentGlobalXmin to prevent it, but up-coming patches that have
    Discard undo mechanism will replace it with oldest_xid_that_has_undo.

commit 5126ec94af589fb56cfcad9f014f6a8c20b16fff
Author: dilip <dilip@localhost.localdomain>
Date:   2017-07-26 15:30:05 +0530

    Adding xid in undo header

    Xid will be used by zheap to traverse the undo chain. It
    will not traverse the chain once it get the undo which has
    the xid smaller than OldestXidHavingUndo

commit 7f994a6806858bcc2069004fa16f50d37263dd51
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-07-26 15:06:49 +0530

    Support EvalPlanQual mechanism for zheap

    To support evalplanqual mechanism we need to support locking a tuple
    (as of now only now only in LockTupleExclusive mode) to ensure that
    nobody else can update it once the tuple is qualified by this
    mechanism. We also need dirty snapshots to fetch the tuple by tupleid.
    We also need to update ExecScanFetch APIs so that it can recognise
    zheaptuples. We also need to adjust other visibility routines so that
    they can understand locked tuples, similarly we need to adjust
    zheap_update and zheap_delete to account for locked tuples.

    Patch by me, reviewed and tested by Dilip.

commit a4ac11945ae4201bc1c45ddd4ea676841f281cd3
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-07-25 05:16:51 +1200

    Improve loop.  Nobody likes degenerate for loops.

commit 4980d572117fc14583af00006e741eedc269a7b3
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-07-25 05:13:52 +1200

    Fix UndoLogDiscard().

    Commit d12ea1cec176c3793cb53b6133d413418c338f62 changed the way that the
    offset part of an UndoRecPtr maps to a block number from header exclusive
    to header inclusive, but I failed to change UndoLogDiscard().
    Thanks to Dilip Kumar for diagnosis & fix.

commit fbd05d66d941cb5410c8cc4b3c0bfe1fa4b9f3a6
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-07-17 14:49:36 +0530

    Implement Index Scan using btree on zheap relations

    This doesn't include the implementation required for fetching
    multiple versions of a tuple in case of a non-MVCC snapshot.

commit 5d9386b049a6dc61286c4140457ee1d728938fa6
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-07-18 10:43:19 +0530

    Implement insertion of zheap tuples in btree index

    It doesn't include the implementation for handling updates on
    key column.

commit f849ed2274727a5c04988fcace73361f79b0346f
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-07-17 14:18:16 +0530

    Implement CREATE INDEX on zheap relations USING BTREE.

    This allows creation of btree index on *empty* zheap relations.

commit 0bab411eeb75256cbcb6e58cf99b493d59158ce3
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-07-14 10:12:17 +0530

    Define and use InvalidUndoRecPtr.

commit 64433f17dd08fa2db21af689ff673abf16d863ff
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-07-11 17:04:22 +0530

    Fix an assert failure in PrepareUndoInsert

commit 80878d1097ae747de6b257e8be911c16fd57196b
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-07-04 12:32:00 +0530

    Fix 'storage_engine' reloption to support case-insensitive inputs

commit 9d4097fad8db35add630b7da9b98b3d0e95dcfbe
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-06-30 23:56:14 +1200

    Change the way that undolog.c accounts for page headers.

    Previously, the offset component of UndoRecPtr was a counter of usable bytes
    within the undo log.  Now it's straight physical offset into the undo log.
    This means that it's now possible to have a (corrupt) UndoRecPtr that points
    at header data, which is nonsensical, but it makes a lot of things simpler.
    Now segment filenames, insert, discard, end offsets and UndoRecPtr values are
    all based on the same scale: number of raw bytes from the start of the undo
    log, regardless of whether those are header or data bytes.

    Previously, UndoLogAllocate advanced the insert pointer by the exact number
    of bytes requested in the 'size' argument.  That was unusable because it
    required the caller to allocate header space this way too, and do a bunch of
    math that required knowing where the insert point already was.  Now 'size'
    means usable bytes; header bytes are automatically accounted for.

    Based on a complaint from Dilip.  Let's try it this way and see if it makes
    more sense.

commit 717961ad5ae25a6cfad73f7843e718a36b0f889b
Author: dilip <dilip@localhost.localdomain>
Date:   2017-06-30 10:29:32 +0530

    Fix defect in undo record API

    In the earlier version there was an assumption that
    at least undorecor header will fit into the buffer,
    but actually that was not true undo record header
    can also split across 2 buffers, the same has been
    fixed.

commit c3cd40c69a91cee5d71fb04432393e49b8b62302
Author: dilip <dilip@localhost.localdomain>
Date:   2017-06-29 16:26:48 +0530

    Fix compilation warning in undolog.c

commit a56bc2ce68de378fd73f31e48a127f0620c8fc48
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-06-29 16:13:38 +0530

    Store command id in undo records.

    Till now, there was a primitive implementation of command id.  We were
    storing the command id in transaction slots, but that won't work for
    tuples stored in undo records.  Now, store the command id in undo
    record and fetch it from undo records during visibility checks.

commit abef75d8885d21857afbc9d4487628807e913cb4
Author: dilip <dilip@localhost.localdomain>
Date:   2017-06-29 15:44:44 +0530

    Support for command ID in undorecord header

commit 779cb3080bf4e4862cd008aa902b55029f545f4e
Author: dilip <dilip@localhost.localdomain>
Date:   2017-06-27 10:09:24 +0530

    Bug fix in undo buffer list: Reset the undo buffer list

commit 99f1adcf642e102df9f87f4763ca299ff0a57733
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-06-23 20:45:43 +0530

    Support reuse of transaction slots

    Currently the zheap page has four transaction slots which means that
    there can't be more than four active transactions operating on a page.
    After four transactions the system will start waiting, this commit
    will allow to reuse the transaction slots.  The transaction slot can
    reuse if the transaction is committed and all-visible or if it is
    aborted then the undo has been applied.  As of now, we don't have
    rollback support so we just rely on the first check to reuse the slot.

commit 3d850d24e8aa04087ca55ebf9319e6b56ec5ec63
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-06-23 20:32:51 +0530

    Support Zheap in-place update and delete operations

    This allows zheap tuples to be updated in-place and marked as deleted.
    This also supports visibility checking for snapshots and traversing
    the undo chains for non-visible tuples.  As of this commit, the
    support for snapshot visibility with respect to command id is not
    complete and can give wrong answers.  The future commit will support
    the same.

commit 9fe80770ed32020cac9487f93cdf542cd070c4fa
Author: dilip <dilip@localhost.localdomain>
Date:   2017-06-23 16:53:26 +0530

    Fix warning in undolog and undorecord

commit 3075d2186e45ca0fe14add50d1a8bdf82de7e85f
Author: dilip <dilip@localhost.localdomain>
Date:   2017-06-23 16:48:07 +0530

    Undo API for inserting and fetching the undo records from undo storage

    Undo API is an interface on top of the undo log storage which provides
    a way to insert and fetch records from undo logs. The API internally
    manages the buffers and performs encoding and decoding the undo records.

commit 21d2703d218f05c28638e1ec98559d357e4b94f8
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-06-22 10:27:23 +1200

    Changed interface of UndoLogDiscard based on feedback.

    Previously it took old pointer and size.  Now it just takes the new pointer.
    In other words you call it with the address of the oldest byte you would
    like to keep.

    Also updated various comments, changed the pg_stat_undo_logs view a bit
    and fixed the rules.out to reflect that.

commit 10ccdce79fed7a4dd42321198c8f8a1e9bd26dda
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-06-21 13:59:31 +1200

    Implemented UndoLogDiscard and related things.

    Now able to discard and recycle segment files on master and standby.
    Assorted other changes: using an LWLock per undo log, instead of a SpinLock.
    Using base/undo rather than base/9 to hold undo segment files.  Renamed
    segment files as logno.offset, so that they also tell you the UndoRecPtr
    of the first byte in the segment.  Got rid of the separate tracking of
    'mvcc' and 'rollback' discard pointers; I don't think that's my job, instead
    there is just a single 'discard' pointer.  Renamed 'capacity' to 'end'.

    There is plenty more work to be done here...

commit 502d0afd95e3b7a6bb089be6efed35ed24cec96e
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-06-19 15:45:41 +1200

    Fix double lock release bug in ForgetBuffer

    Don't try to release the partition lock twice if we failed to find the
    buffer.

commit 32ca66260db1675f7fce94e59dbc55d9057bdfdd
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-06-01 17:07:43 +1200

    Early prototype code for undo log storage.

    Includes a backport of 767bc028e5f001351feb498acef9a87c123093d6 because
    we need to be able to create pinned DSM segments without creating a bogus
    ResourceOwner first.

commit 80bb5103f41d28052c8cd11f5393de6eaf1522cd
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-06-06 21:47:46 +0530

    Fix return type for zheap_insert

commit 51f5293a475d6e2175f4e5d87978308e3d7b0a60
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-06-04 19:36:14 +0530

    Fix NULL pointer access in RelationStorageIsZHeap

commit 7c4f86a14b93151c9281a7cab3408b9d040fee88
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-06-02 16:16:23 +0530

    Change UNDO Insert tuple contents.

    As per current understanding, we don't need to store any information
    about in undo insert as the command id (cid) is also stored in
    transaction slot.

commit 31142f2fcde9e84baf531feb4187505dbaf2259d
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-06-02 16:12:42 +0530

    Few defines for zheap tuple

    Define infomask flags required for zheap tuples. One of these flags is
    required for the already committed code in commit
    a3bb8c3411d1a17fb190b5757bf181d38900800a.

commit feea62deb7528b7525090e6623cfc2482c6d20e0
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-06-02 15:40:44 +0530

    Implement getsysattribute function for zheap.

    This is required for upcomimng zheap delete operation patch.
    Attributes related to transaction information won't give correct
    information for all cases.  I have added Fixme in code which needs
    to be fixed at later time when we need to use those attributes.

commit 7d7bb25644ad0a3fd234e6185d21151e7a7e8af0
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-06-02 07:22:28 +0530

    Initialize Zheap page with appropriate special space size.

commit 7598316c1645db0e8d7eee55c45a529d5d426544
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-06-01 18:13:11 +0530

    Add a 'storage_engine' reloption.

    The code that decides which storage should be used for a relation.
    Allowed values are 'heap' and 'zheap'. The default value for this
    options is 'heap'. Also, it adds a macro 'RelationStorageIsZHeap(relation)'
    which can be used to decide whether a relation uses zheap or not.

    Patch by me, reviewed by Mithun C Y

commit 2d8452096418348c6f406b595cc75903fde38b61
Author: Kuntal Ghosh <kuntal.ghosh@enterprisedb.com>
Date:   2017-05-31 12:00:05 +0530

    Support query quals for ZHeap

    It implements the qualification check of column names for a ZHeap tuple.

commit a0ae8ceb08757b0cdce77780c87267b6dbc7de1f
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-05-30 16:31:54 +0530

    ZHeap Tuple visibility checks

    Implements the basic zheap tuple visibility skeleton wherein we can
    verify if the inserted tuple is visible to our command. The basic idea
    used is to have few transaction slots (as of now four, needs some
    testing to determine the exact number) in special space of zheap page.
    Each write operation on page first needs to reserve transaction slot
    in the page and update the same in tuple header and then proceed with
    the actual operation. We need to reserve two bits in tuple header to
    remember the information of transaction slot. There is a need of
    additional bit to indicate no tranasction slot in which case tuple
    will be all-visible.  This usage of additional bit will be implemented
    as a separate commit.  As of now, each transaction slot contains xid,
    cid and undo_rec_ptr which helps us to determine tuple visibility. We
    might not need cid in transaction slot as that can be retrieved from
    undo, however keeping it in page saves us from fetching undo record
    pointer in many cases and due to alignment, it doesn't cost us much
    space wise.

commit 74983024bedce424427bec359f8f0c0f0615a774
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-05-17 10:59:55 +0530

    Handle cases for data_alignment = 4.

    Currently for four-byte alignment, we align everything to four-byte
    boundary which is not what we want for typalign 'c' or 's'.  So align the
    given offset as per attalign for char and short alignment and at four-byte
    boundary for other values of attalign.

    Patch by me, reported by Robert Haas.

commit a802bb024f8041c0122419729c86611f592a262e
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-05-11 12:12:49 +0530

    Support basic seqscan operation for ZHeap.

    Make HeapScanDesc aware of ZHeapTuple, this is required to scan. We
    could create a separate ZHeapScanDesc, but at this stage, I don't see
    the need of same. I have written Zheap scan API's like zheap_getnext,
    zheap_beginscan, etc. As for inserts, it doesn't seem advisable to add
    a lot of if..else checks in heap scan API's to support Zheap tuple
    format. Apart from tuple format, we can't directly use heap visibility
    routines (fetching transaction info from tuple will be different),
    although I have yet to implement the same. Also, we might want to copy
    the zheap tuple before releasing buffer lock as zheap tuples can be
    updated in-place.

    Note that with this patch only select * from <table_name> can work, to
    make where clause work, we need to change few other *get_attr api's so
    that they can understand zheaptuple format.

commit ffbc3b0a84451e365457e7a1d1d31a15cd1366cd
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-05-02 08:41:19 +0530

    Set Tag needs to use zheap tuple when zheap is enabled.

commit 63ba474f0d69a4123129ffa4849548e9d53a0146
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-05-02 08:22:29 +0530

    Mark data_alignment_zheap as PGDLLIMPORT.

    This is so that extensions can use it.

commit 058618921b6f6319eb4f86909058a5a274fcabd0
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-05-02 08:17:16 +0530

    Remove spurious whitespace.

commit 171bfaeeca96c2186ba45e5f9930df2cf7eeb5ee
Author: amitkapila <amitkapila@localhost.localdomain>
Date:   2017-05-02 07:54:16 +0530

    Add missing Makefile in zheap directory.

    Commit 53643b6589a6b963b8621e3173d505383d510bb5 forgot to add Makefile
    for zheap directory.

commit e70c0c4404021ece54e8bdcb9ce2ec6d3c2d87eb
Author: amitkapila <amitkapila@localhost.localdomain>
Date:   2017-04-28 15:38:56 +0530

    Change max heap tuples per page.

    With shorter tuple headers, the maximum number of tuples that can fit
    on a page have significantly increased.  So changed the calculation in
    API's required for insert operation.  I have choosen to expose new
    API's as doing checks for type of heap in such lower level API's
    doesn't seem sensible.

    For now, I have added new page level api's in zheapam.c.  I think
    later we might want to split them into a separate file.

commit 22449b025419c176ed74464ee26bbcc46125a63e
Author: amitkapila <amitkapila@localhost.localdomain>
Date:   2017-04-28 14:56:44 +0530

    Support unaligned inserts in zheap.

    A new guc data_alignment has been introduced to decide the alignment
    of tuple data.  The data_alignment value 0 indicates no alignment,
    value 4 indicates align everything at 4 byte boundary and any other
    value indicates align as per typalign of the attribute.  The main
    objective of this commit is test the size of data with different
    alignments.

    Based on test results we might want to retain one type of alignment
    and remove this GUC and associated code.

commit eaf9f4b054e9d8e7bfd2fc86bf7c7f4e51a04e20
Author: amitkapila <amitkapila@localhost.localdomain>
Date:   2017-04-28 12:24:29 +0530

    Support Zheap Insert Operation.

    The main idea of this patch is to support a short tuple header (3
    bytes instead of 24 bytes). As of this patch, I have kept tuple
    header aligned to 8-bytes and tuple data alignment works as for main
    heap. This doesn't include support for toast inserts or speculative
    inserts (Insert .. On Conflict). Also, we don't support selects. As
    of now, the support for undo record is dummy which means records are
    formed, but not stored. Similarly for WAL, there is support of XLOG
    record insertion, but replay is not done as that also needs some support
    from undo. I have added a guc enable_zheap to perform zheap inserts
    which needs to be changed to reloption or something else, but it serves
    the purpose as of now.

commit ba5b2b31bbd9d8053be2416fb0cad0fda64df053
Author: Robert Haas <rhaas@postgresql.org>
Date:   2017-03-05 10:18:45 +0530

    Throw-away test code for UndoRecordInsert.

commit daadef317fa3b8453115ac24c351faed5f277ffd
Author: Robert Haas <rhaas@postgresql.org>
Date:   2017-03-05 08:07:52 +0530

    Implement UndoRecordExpectedSize and InsertUndoRecord.

commit fe886f35e8b257c6a24fa3729df26432dfb52881
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-02-24 11:42:16 +0530

    update comment to reflect function name changed in
    commit 29f4db6d7a158c75fc152351f874b8d4e6af63a0.

commit 0c79dde27afa0d432ed53ad7c353204560500611
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-02-23 16:19:10 +0530

    Added bootstrap interface; tidied

commit b05429f48e3e7104e84428a81884055569e1006d
Author: Thomas Munro <thomas.munro@enterprisedb.com>
Date:   2017-02-23 14:57:08 +0530

    An early draft of undolog.h.

commit cc1c4927fbc236559c6831ab583f1600c96a543d
Author: Robert Haas <rhaas@postgresql.org>
Date:   2017-02-23 14:41:05 +0530

    Rename DropBuffer to ForgetBuffer, change API a bit, implement.

    Also, implement ForgetLocalBuffer.

commit 954bf571a3e332e5d0dd16f6ec2eb4c11d7962cf
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-02-23 14:02:03 +0530

    Expose the DropBuffer API.

    We don't need a new header file just to expose one API.
    So move the API to bufmgr.h and remove the undobuf.h.

commit 28ca1b57f1d509657d6c77eaf07fd0af395e2e5b
Author: Amit Kapila <amit.kapila@enterprisedb.com>
Date:   2017-02-23 12:04:24 +0530

    draft header files for undoworker, undoloop and undobuf.

rebase merge issue fixes

zheap code adjusted as per new undo interfaces

Dilip Kumar

zheap: Add tests verifying vacuum/vacuum full/cluster dont create xid horizons.

Added IsTPDPage macro to check page is TPD.

Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

Bug fix - Undo launcher exiting with exit code 1

Terminate signal not handled in UndoLauncherMain, added signal handling
for terminate signal to exit cleanly.

Vigneshwaran C reviewed by Dilip Kumar

Fix random order issue in trigger.sql

Gunjan Kumar review by me

Fixed bug "inconsistent page found" for redo zheap_xlog_confirm.

This failure was coming in isolation test(insert-conflict-specconflict).
We were not calculating correct size of xl_zheap_confirm structre so we
were logging wrong trans_slot.  Due to wrong trans_slot, we were currepting
item id in redo of zheap_xlog_confirm for abort.  So fixed this and changed
trans_slot data type from uint8 to uint16.

Patch by Mahendra Singh Thalor, revewed by Dilip Kumar,
reported by Beena Emerson.

Refactor zheap_undo_actions

Move WAL related code to a seperate function.

reviewed by Mahendra Singh Thalor

Fixed a bug in zheap_update for TM_Updated

In zheap_update, from commit 007f31470dd384d0b, ItemIdIsDeleted
check is moved into ZHeapTupleSatisfiesUpdate so there we are
setting tuple data as null.  And then in ZHeapDetermineModifiedColumns,
we are trying to access tuple data so we were getting segment fault in
zheap_deform_tuple.  Fixed this.

Patch by Mahendra Singh Thalor, Reported by Andres Freund, reviewed by
Dilip Kumar and Amit Kapila.

Fixed a bug in RelationGetBufferForZTuple to avoid using of TPD page for new buffer and mark empty TPD page as new page from TPDFreePage.

In RelationGetBufferForZTuple, when we don't get any page from FSM,
then we try with last block of relation.  We were checking that this
is an empty TPD page or not, if empty, then we were using it as zheap
page.  But it is possible that this empty page is still in meta list
(ExtendTPDEntry can make TPD page as empty but will not remove from
meta list.)
So in this case, page might be in meta list and might be last used
TPD page.  So whenever we were needed new TPD for any page, then we
were trying to access zheap page as TPD page so we were getting
locking hang as our last used TPD page was now zheap page also.  So
fixed this bug by not using any TPD page for zheap page in this case
and we will mark TPD page as new from TPDFreePage so that we will
not get any TPD page from FSM.

Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

Added isolation test case for commit 3bacab225c6c88b78e4

When we were trying to update a tuple and concurrently tuple is
deleted and item id is marked as deleted, then we were getting
segment fault in ZHeapDetermineModifiedColumns because tuple data
is setted to null in ZHeapTupleSatisfiesUpdate for deleted item id.
So added test case for this failure.

Patch by Mahendar Singh Thalor, reviewed by Amit Kapila

Converted epoch and xid to fxid in TPDPageSetTransactionSlotInfo, PageSetTransactionSlotInfo and TPD page opaque.

Patch by Mahendra Singh Thalor, reviewed by Amit Kapila

Refactor zheap_multi_insert

Move undo related code to a separate function.  Also, added few test
cases related to multi-insert.

Patch by Beena Emerson with some minor modifications by me in the test
cases.

Fix random regression failure in constraints

Added where clause to prevent random failure message which occurs due
to non-inplace update optimization.

Patch by Vigneshwaran C, reviewed by Dilip Kumar.
---
 README.md                                          |   68 +
 configure                                          |   48 +
 configure.in                                       |   23 +
 contrib/btree_gist/expected/enum.out               |   14 +-
 contrib/btree_gist/sql/enum.sql                    |    2 +
 contrib/pageinspect/Makefile                       |    6 +-
 contrib/pageinspect/expected/btree.out             |   14 +-
 contrib/pageinspect/expected/hash.out              |   15 +-
 contrib/pageinspect/expected/page.out              |    6 +-
 contrib/pageinspect/expected/zheap.out             |   64 +
 contrib/pageinspect/pageinspect--1.7--1.8.sql      |   39 +
 contrib/pageinspect/pageinspect.control            |    2 +-
 contrib/pageinspect/sql/btree.sql                  |   12 +-
 contrib/pageinspect/sql/hash.sql                   |   14 +-
 contrib/pageinspect/sql/page.sql                   |    6 +-
 contrib/pageinspect/sql/zheap.sql                  |   38 +
 contrib/pageinspect/zheapfuncs.c                   |  431 +
 contrib/pg_visibility/expected/pg_visibility.out   |    6 +-
 contrib/pg_visibility/sql/pg_visibility.sql        |    6 +-
 contrib/pgstattuple/expected/pgstattuple.out       |    4 +-
 contrib/pgstattuple/sql/pgstattuple.sql            |    4 +-
 contrib/postgres_fdw/expected/postgres_fdw_1.out   | 8600 +++++++++++++++++++
 contrib/test_decoding/Makefile                     |    3 +
 doc/src/sgml/config.sgml                           |   35 +
 doc/src/sgml/func.sgml                             |    5 +
 doc/src/sgml/monitoring.sgml                       |  107 +-
 doc/src/sgml/storage.sgml                          |   56 +
 src/backend/access/Makefile                        |    2 +-
 src/backend/access/common/heaptuple.c              |    8 -
 src/backend/access/common/tupconvert.c             |    1 +
 src/backend/access/heap/heapam.c                   |   50 +-
 src/backend/access/heap/heapam_handler.c           |    3 +-
 src/backend/access/heap/heapam_visibility.c        |   72 +
 src/backend/access/heap/hio.c                      |    8 +-
 src/backend/access/heap/tuptoaster.c               |   20 +-
 src/backend/access/heap/vacuumlazy.c               |  569 +-
 src/backend/access/heap/visibilitymap.c            |   44 +-
 src/backend/access/index/genam.c                   |   12 +
 src/backend/access/index/indexam.c                 |    2 +-
 src/backend/access/nbtree/nbtinsert.c              |   20 +-
 src/backend/access/rmgrdesc/Makefile               |    2 +-
 src/backend/access/rmgrdesc/tpddesc.c              |   73 +
 src/backend/access/rmgrdesc/zheapamdesc.c          |  237 +
 src/backend/access/table/Makefile                  |    2 +-
 src/backend/access/table/vacuumblk.c               |  559 ++
 src/backend/access/transam/rmgr.c                  |    3 +
 src/backend/access/transam/twophase.c              |   84 +
 src/backend/access/transam/varsup.c                |   88 +-
 src/backend/access/transam/xact.c                  |  110 +-
 src/backend/access/transam/xlog.c                  |   32 +-
 src/backend/access/transam/xloginsert.c            |   68 +-
 src/backend/access/undo/undoworker.c               |   12 +-
 src/backend/access/zheap/Makefile                  |   20 +
 src/backend/access/zheap/README                    |  591 ++
 src/backend/access/zheap/prunetpd.c                |  512 ++
 src/backend/access/zheap/prunezheap.c              |  958 +++
 src/backend/access/zheap/rewritezheap.c            |  374 +
 src/backend/access/zheap/tpd.c                     | 3269 ++++++++
 src/backend/access/zheap/tpdxlog.c                 |  522 ++
 src/backend/access/zheap/zheapam.c                 | 8806 ++++++++++++++++++++
 src/backend/access/zheap/zheapam_handler.c         | 2163 +++++
 src/backend/access/zheap/zheapam_visibility.c      | 1927 +++++
 src/backend/access/zheap/zheapamxlog.c             | 2194 +++++
 src/backend/access/zheap/zhio.c                    |  456 +
 src/backend/access/zheap/zmultilocker.c            |  780 ++
 src/backend/access/zheap/zpage.c                   |  596 ++
 src/backend/access/zheap/zscan.c                   | 1543 ++++
 src/backend/access/zheap/ztuple.c                  | 1008 +++
 src/backend/access/zheap/ztuptoaster.c             |  980 +++
 src/backend/access/zheap/zundo.c                   | 1397 ++++
 src/backend/access/zheap/zvacuumlazy.c             | 1555 ++++
 src/backend/catalog/storage.c                      |    2 +
 src/backend/commands/tablecmds.c                   |    1 +
 src/backend/commands/tablespace.c                  |   22 +
 src/backend/commands/vacuum.c                      |   11 +
 src/backend/executor/execIndexing.c                |   23 +-
 src/backend/executor/execTuples.c                  |    6 +-
 src/backend/executor/nodeModifyTable.c             |   32 +-
 src/backend/lib/binaryheap.c                       |  116 +-
 src/backend/lib/stringinfo.c                       |   32 +
 src/backend/nodes/tidbitmap.c                      |    3 +-
 src/backend/optimizer/util/plancat.c               |    4 -
 src/backend/postmaster/pgstat.c                    |   58 +-
 src/backend/postmaster/postmaster.c                |    2 +
 src/backend/replication/logical/decode.c           |   16 +
 src/backend/storage/lmgr/lmgr.c                    |  148 +
 src/backend/storage/lmgr/lock.c                    |   36 +
 src/backend/storage/lmgr/predicate.c               |   93 +-
 src/backend/storage/page/bufpage.c                 |   18 +-
 src/backend/storage/smgr/README                    |   23 +-
 src/backend/storage/smgr/smgr.c                    |    1 +
 src/backend/tcop/utility.c                         |    2 +-
 src/backend/utils/adt/lockfuncs.c                  |    2 +
 src/backend/utils/adt/pgstatfuncs.c                |   61 +-
 src/backend/utils/error/elog.c                     |    2 -
 src/backend/utils/init/postinit.c                  |   28 +-
 src/backend/utils/misc/guc.c                       |   21 +
 src/backend/utils/misc/pg_controldata.c            |   11 +-
 src/backend/utils/misc/postgresql.conf.sample      |    6 +
 src/bin/pg_controldata/pg_controldata.c            |    4 +
 src/bin/pg_resetwal/pg_resetwal.c                  |   83 +
 src/bin/pg_upgrade/pg_upgrade.c                    |    9 +
 src/bin/pg_waldump/rmgrdesc.c                      |    2 +
 src/bin/pgbench/t/001_pgbench_with_server.pl       |   66 +
 src/include/access/genam.h                         |    1 +
 src/include/access/hash_xlog.h                     |    9 +-
 src/include/access/heapam.h                        |    3 +
 src/include/access/htup_details.h                  |    1 +
 src/include/access/relscan.h                       |    9 +
 src/include/access/rewritezheap.h                  |   32 +
 src/include/access/rmgrlist.h                      |    4 +
 src/include/access/tableam.h                       |   22 +
 src/include/access/tpd.h                           |  148 +
 src/include/access/tpd_xlog.h                      |   81 +
 src/include/access/transam.h                       |   11 +
 src/include/access/tuptoaster.h                    |   11 +
 src/include/access/undorecord.h                    |   15 +
 src/include/access/vacuumblk.h                     |   32 +
 src/include/access/visibilitymap.h                 |    2 +
 src/include/access/xact.h                          |   12 +
 src/include/access/xlog.h                          |    1 +
 src/include/access/xloginsert.h                    |    2 +
 src/include/access/xlogreader.h                    |    1 +
 src/include/access/xlogrecord.h                    |    1 +
 src/include/access/xlogutils.h                     |   16 +-
 src/include/access/zheap.h                         |  355 +
 src/include/access/zheapam_xlog.h                  |  366 +
 src/include/access/zheapscan.h                     |   74 +
 src/include/access/zhio.h                          |   26 +
 src/include/access/zhtup.h                         |  331 +
 src/include/access/zmultilocker.h                  |   90 +
 src/include/catalog/pg_am.dat                      |    4 +
 src/include/catalog/pg_control.h                   |   12 +
 src/include/catalog/pg_proc.dat                    |   19 +-
 src/include/commands/vacuum.h                      |   37 +
 src/include/executor/tuptable.h                    |    1 -
 src/include/lib/stringinfo.h                       |    8 +
 src/include/miscadmin.h                            |    3 +
 src/include/nodes/lockoptions.h                    |    9 +
 src/include/pg_config.h.in                         |    4 +
 src/include/pgstat.h                               |   14 +-
 src/include/postgres.h                             |    7 +
 src/include/storage/bufpage.h                      |   34 +
 src/include/storage/itemid.h                       |  126 +
 src/include/storage/lmgr.h                         |   12 +
 src/include/storage/lock.h                         |   45 +
 src/include/storage/predicate.h                    |    9 +-
 src/include/storage/proc.h                         |    8 +
 src/include/storage/smgr.h                         |    1 +
 src/include/utils/elog.h                           |    4 +
 src/include/utils/rel.h                            |   13 +
 src/include/utils/snapshot.h                       |    7 +
 src/include/utils/ztqual.h                         |   78 +
 src/pl/plperl/expected/plperl_transaction.out      |   18 +-
 src/pl/plperl/expected/plperl_trigger.out          |   10 +-
 src/pl/plperl/sql/plperl_transaction.sql           |   16 +-
 src/pl/plperl/sql/plperl_trigger.sql               |    8 +-
 src/pl/plpython/expected/plpython_transaction.out  |   18 +-
 src/pl/plpython/sql/plpython_transaction.sql       |   16 +-
 src/pl/tcl/expected/pltcl_transaction.out          |   10 +-
 src/pl/tcl/expected/pltcl_trigger.out              |   24 +-
 src/pl/tcl/sql/pltcl_transaction.sql               |   10 +-
 src/pl/tcl/sql/pltcl_trigger.sql                   |   18 +-
 src/test/isolation/expected/alter-table-3_1.out    |  697 ++
 src/test/isolation/expected/deleted_item_id.out    |   10 +
 src/test/isolation/expected/eval-plan-qual.out     |   32 +-
 src/test/isolation/expected/eval-plan-qual_1.out   |  285 +
 src/test/isolation/expected/inherit-temp.out       |   64 +-
 .../isolation/expected/multiple-row-versions_1.out |   25 +
 .../isolation/expected/tpd_offset_map_updation.out |   20 +
 src/test/isolation/expected/vacuum-reltuples_1.out |   59 +
 src/test/isolation/expected/zheap_mvcc.out         |  164 +
 .../expected/zheap_non-inplace-update.out          |   73 +
 src/test/isolation/expected/zheap_tidscan.out      |   16 +
 src/test/isolation/expected/zheap_tpd.out          |  128 +
 src/test/isolation/isolation_schedule              |    6 +
 src/test/isolation/specs/deleted_item_id.spec      |   28 +
 src/test/isolation/specs/eval-plan-qual.spec       |    4 +-
 src/test/isolation/specs/inherit-temp.spec         |    8 +-
 .../isolation/specs/tpd_offset_map_updation.spec   |   38 +
 src/test/isolation/specs/vacuum-reltuples.spec     |    3 +
 src/test/isolation/specs/zheap_mvcc.spec           |   45 +
 .../isolation/specs/zheap_non-inplace-update.spec  |   40 +
 src/test/isolation/specs/zheap_tidscan.spec        |   26 +
 src/test/isolation/specs/zheap_tpd.spec            |   63 +
 src/test/modules/Makefile                          |    1 +
 .../modules/test_alter_tablespace_zheap/Makefile   |   24 +
 .../modules/test_alter_tablespace_zheap/atz.conf   |    6 +
 .../expected/.gitignore                            |    1 +
 .../input/alter_tablespace_zheap.source            |   31 +
 .../output/alter_tablespace_zheap.source           |   47 +
 .../test_alter_tablespace_zheap/sql/.gitignore     |    2 +
 src/test/regress/expected/arrays.out               |   30 +-
 src/test/regress/expected/box.out                  |    1 +
 src/test/regress/expected/case.out                 |   18 +-
 src/test/regress/expected/combocid_1.out           |  117 +
 src/test/regress/expected/copy2_1.out              |  616 ++
 src/test/regress/expected/create_am.out            |   11 +-
 src/test/regress/expected/float4.out               |    4 +-
 src/test/regress/expected/float4_1.out             |  259 +
 src/test/regress/expected/float8.out               |    4 +-
 src/test/regress/expected/float8_1.out             |  586 ++
 src/test/regress/expected/foreign_key.out          |   92 +-
 src/test/regress/expected/fsm_1.out                |   73 +
 src/test/regress/expected/generated.out            |    4 +-
 src/test/regress/expected/identity.out             |   10 +-
 src/test/regress/expected/indirect_toast.out       |   80 +-
 src/test/regress/expected/inherit.out              |    8 +-
 src/test/regress/expected/insert_conflict.out      |   28 +-
 .../regress/expected/partition_aggregate_1.out     | 1507 ++++
 src/test/regress/expected/partition_join_1.out     | 2005 +++++
 src/test/regress/expected/plpgsql.out              |   12 +-
 src/test/regress/expected/plpgsql_1.out            | 5766 +++++++++++++
 src/test/regress/expected/portals.out              |   42 +-
 src/test/regress/expected/reloptions.out           |    5 +-
 src/test/regress/expected/returning_1.out          |  357 +
 src/test/regress/expected/rowsecurity.out          | 1185 ++-
 src/test/regress/expected/rowsecurity_1.out        | 4461 ++++++++++
 src/test/regress/expected/rules.out                |   32 +-
 src/test/regress/expected/rules_1.out              | 3309 ++++++++
 src/test/regress/expected/select_parallel_1.out    | 1163 +++
 src/test/regress/expected/select_views_1.out       | 1552 ++++
 src/test/regress/expected/stats_1.out              |  231 +
 src/test/regress/expected/strings_1.out            | 1823 ++++
 src/test/regress/expected/tablesample_1.out        |  336 +
 src/test/regress/expected/tidscan_1.out            |  268 +
 src/test/regress/expected/transactions.out         |    8 +-
 src/test/regress/expected/transactions_1.out       |  944 +++
 src/test/regress/expected/triggers.out             |   53 +-
 src/test/regress/expected/triggers_1.out           | 2834 +++++++
 src/test/regress/expected/updatable_views.out      |   30 +-
 src/test/regress/expected/updatable_views_1.out    | 3015 +++++++
 src/test/regress/expected/update.out               |   56 +-
 src/test/regress/expected/update_1.out             |  928 +++
 src/test/regress/expected/vacuum.out               |    6 +-
 src/test/regress/expected/with_1.out               | 2291 +++++
 src/test/regress/expected/zheap.out                |  557 ++
 src/test/regress/input/constraints.source          |    6 +-
 src/test/regress/input/misc.source                 |    4 +-
 src/test/regress/output/constraints.source         |   14 +-
 src/test/regress/output/misc.source                |   24 +-
 src/test/regress/parallel_schedule                 |    3 +
 src/test/regress/serial_schedule                   |    1 +
 src/test/regress/sql/arrays.sql                    |   18 +-
 src/test/regress/sql/box.sql                       |    1 +
 src/test/regress/sql/case.sql                      |    6 +-
 src/test/regress/sql/float4.sql                    |    2 +-
 src/test/regress/sql/float8.sql                    |    2 +-
 src/test/regress/sql/foreign_key.sql               |   38 +-
 src/test/regress/sql/generated.sql                 |    2 +-
 src/test/regress/sql/identity.sql                  |    4 +-
 src/test/regress/sql/indirect_toast.sql            |   36 +-
 src/test/regress/sql/inherit.sql                   |    8 +-
 src/test/regress/sql/insert_conflict.sql           |   10 +-
 src/test/regress/sql/plpgsql.sql                   |    6 +-
 src/test/regress/sql/portals.sql                   |   42 +-
 src/test/regress/sql/reloptions.sql                |    6 +-
 src/test/regress/sql/rowsecurity.sql               |  230 +-
 src/test/regress/sql/rules.sql                     |   20 +-
 src/test/regress/sql/transactions.sql              |    8 +-
 src/test/regress/sql/triggers.sql                  |   25 +-
 src/test/regress/sql/updatable_views.sql           |   14 +-
 src/test/regress/sql/update.sql                    |   38 +-
 src/test/regress/sql/vacuum.sql                    |    6 +-
 src/test/regress/sql/zheap.sql                     |  362 +
 src/tools/msvc/Mkvcbuild.pm                        |    3 +-
 src/tools/msvc/Solution.pm                         |    7 +
 src/tools/msvc/config_default.pl                   |    1 +
 src/tools/pgindent/typedefs.list                   |   78 +
 269 files changed, 82382 insertions(+), 1869 deletions(-)
 create mode 100644 README.md
 create mode 100644 contrib/pageinspect/expected/zheap.out
 create mode 100644 contrib/pageinspect/pageinspect--1.7--1.8.sql
 create mode 100644 contrib/pageinspect/sql/zheap.sql
 create mode 100644 contrib/pageinspect/zheapfuncs.c
 create mode 100644 contrib/postgres_fdw/expected/postgres_fdw_1.out
 create mode 100644 src/backend/access/rmgrdesc/tpddesc.c
 create mode 100644 src/backend/access/rmgrdesc/zheapamdesc.c
 create mode 100644 src/backend/access/table/vacuumblk.c
 create mode 100644 src/backend/access/zheap/Makefile
 create mode 100644 src/backend/access/zheap/README
 create mode 100644 src/backend/access/zheap/prunetpd.c
 create mode 100644 src/backend/access/zheap/prunezheap.c
 create mode 100644 src/backend/access/zheap/rewritezheap.c
 create mode 100644 src/backend/access/zheap/tpd.c
 create mode 100644 src/backend/access/zheap/tpdxlog.c
 create mode 100644 src/backend/access/zheap/zheapam.c
 create mode 100644 src/backend/access/zheap/zheapam_handler.c
 create mode 100644 src/backend/access/zheap/zheapam_visibility.c
 create mode 100644 src/backend/access/zheap/zheapamxlog.c
 create mode 100644 src/backend/access/zheap/zhio.c
 create mode 100644 src/backend/access/zheap/zmultilocker.c
 create mode 100644 src/backend/access/zheap/zpage.c
 create mode 100644 src/backend/access/zheap/zscan.c
 create mode 100644 src/backend/access/zheap/ztuple.c
 create mode 100644 src/backend/access/zheap/ztuptoaster.c
 create mode 100644 src/backend/access/zheap/zundo.c
 create mode 100644 src/backend/access/zheap/zvacuumlazy.c
 create mode 100644 src/include/access/rewritezheap.h
 create mode 100644 src/include/access/tpd.h
 create mode 100644 src/include/access/tpd_xlog.h
 create mode 100644 src/include/access/vacuumblk.h
 create mode 100644 src/include/access/zheap.h
 create mode 100644 src/include/access/zheapam_xlog.h
 create mode 100644 src/include/access/zheapscan.h
 create mode 100644 src/include/access/zhio.h
 create mode 100644 src/include/access/zhtup.h
 create mode 100644 src/include/access/zmultilocker.h
 create mode 100644 src/include/utils/ztqual.h
 create mode 100644 src/test/isolation/expected/alter-table-3_1.out
 create mode 100644 src/test/isolation/expected/deleted_item_id.out
 create mode 100644 src/test/isolation/expected/eval-plan-qual_1.out
 create mode 100644 src/test/isolation/expected/multiple-row-versions_1.out
 create mode 100644 src/test/isolation/expected/tpd_offset_map_updation.out
 create mode 100644 src/test/isolation/expected/vacuum-reltuples_1.out
 create mode 100644 src/test/isolation/expected/zheap_mvcc.out
 create mode 100644 src/test/isolation/expected/zheap_non-inplace-update.out
 create mode 100644 src/test/isolation/expected/zheap_tidscan.out
 create mode 100644 src/test/isolation/expected/zheap_tpd.out
 create mode 100644 src/test/isolation/specs/deleted_item_id.spec
 create mode 100644 src/test/isolation/specs/tpd_offset_map_updation.spec
 create mode 100644 src/test/isolation/specs/zheap_mvcc.spec
 create mode 100644 src/test/isolation/specs/zheap_non-inplace-update.spec
 create mode 100644 src/test/isolation/specs/zheap_tidscan.spec
 create mode 100644 src/test/isolation/specs/zheap_tpd.spec
 create mode 100644 src/test/modules/test_alter_tablespace_zheap/Makefile
 create mode 100644 src/test/modules/test_alter_tablespace_zheap/atz.conf
 create mode 100644 src/test/modules/test_alter_tablespace_zheap/expected/.gitignore
 create mode 100644 src/test/modules/test_alter_tablespace_zheap/input/alter_tablespace_zheap.source
 create mode 100644 src/test/modules/test_alter_tablespace_zheap/output/alter_tablespace_zheap.source
 create mode 100644 src/test/modules/test_alter_tablespace_zheap/sql/.gitignore
 create mode 100644 src/test/regress/expected/combocid_1.out
 create mode 100644 src/test/regress/expected/copy2_1.out
 create mode 100644 src/test/regress/expected/float4_1.out
 create mode 100644 src/test/regress/expected/float8_1.out
 create mode 100644 src/test/regress/expected/fsm_1.out
 create mode 100644 src/test/regress/expected/partition_aggregate_1.out
 create mode 100644 src/test/regress/expected/partition_join_1.out
 create mode 100644 src/test/regress/expected/plpgsql_1.out
 create mode 100644 src/test/regress/expected/returning_1.out
 create mode 100644 src/test/regress/expected/rowsecurity_1.out
 create mode 100644 src/test/regress/expected/rules_1.out
 create mode 100644 src/test/regress/expected/select_parallel_1.out
 create mode 100644 src/test/regress/expected/select_views_1.out
 create mode 100644 src/test/regress/expected/stats_1.out
 create mode 100644 src/test/regress/expected/strings_1.out
 create mode 100644 src/test/regress/expected/tablesample_1.out
 create mode 100644 src/test/regress/expected/tidscan_1.out
 create mode 100644 src/test/regress/expected/transactions_1.out
 create mode 100644 src/test/regress/expected/triggers_1.out
 create mode 100644 src/test/regress/expected/updatable_views_1.out
 create mode 100644 src/test/regress/expected/update_1.out
 create mode 100644 src/test/regress/expected/with_1.out
 create mode 100644 src/test/regress/expected/zheap.out
 create mode 100644 src/test/regress/sql/zheap.sql

diff --git a/README.md b/README.md
new file mode 100644
index 0000000..619b883
--- /dev/null
+++ b/README.md
@@ -0,0 +1,68 @@
+The purpose of this document is to let users know how they can use zheap (a new
+storage format for PostgreSQL) and the work that is still pending.  This new
+storage format provides a better control over bloat, reduces the tuple size
+and reduces the write amplification. The detail design of zheap is present in
+zheap design document (src/backend/access/zheap/README).
+
+How do I use zheap?
+===================
+
+We have provided a storage engine option which you can set when creating a table.
+For example:
+
+create table t_zheap(c1 int, c2 varchar) USING zheap;
+
+Index creation for zheap tables doesn't need any special syntax.
+
+You can also set the GUC parameter default_table_access_method.  The
+default value is heap", but you can set it to zheap.  If you do,
+all subsequently-created tables will use zheap.
+
+These interfaces will probably change once the storage format API work is
+integrated into PostgreSQL.  Well adjust this code to use whatever interfaces
+are agreed by the PostgreSQL community.
+
+Each zheap page has fixed set of transaction slots each of which contains the
+transaction information (transaction id and epoch) and the latest undo record
+pointer for that transaction.  By default, we have four transaction slots per
+page, but this can be changed by setting --with-trans_slots_per_zheap_page=value
+while configuring zheap.
+
+What doesnt work yet?
+======================
+- Logical decoding
+- Snapshot too old - We might want to implement this after first version is
+committed as this will work differently for zheap.
+- Alter Table <table_name> Set Tablesapce <tbs_name> - For this feature to work
+correctly in zheap, while copying pages, we need to ensure that pending aborts
+gets applied before copying the page.
+
+Tools
+- pg_undo_dump similar to pg_wal_dump:  We would like to develop this utility
+as it can be used to view undo record contents and can help us debug problems
+related to undo chains.
+- We also want to develop tools like pgstattuple, pgrowlocks that
+allow us to inspect the contents of database pages at a low level.
+- wal consistency checker: This will be used to check for bugs in the WAL redo
+routines.  Currently, it is quite similar to what we have in current heap, but
+we want to extend it to check the consistency of undo pages similar to how it
+checks for data and index pages.
+
+Open Issues
+===========
+- Currently, the TPD pages are not added to FSM even if they can be completely
+reused.
+- Single user mode: This needs some investigation as to what exactly is required.
+I think we need to ensure that undo gets applied without the need to invoke undo
+worker.
+
+The other pending code related items are tracked on zheap wiki page:
+https://wiki.postgresql.org/wiki/Zheap
+
+Test run before pushing code
+============================
+- make check-world
+- make installcheck and isolation test (with default_table_access_method = 'zheap')
+- make installcheck with hot standby (with wal_consistency_checking=all)
+
+You can find overall design of zheap in the README: src/backend/access/zheap/README
diff --git a/configure b/configure
index 7a6bfc2..23f2b82 100755
--- a/configure
+++ b/configure
@@ -836,6 +836,7 @@ enable_tap_tests
 with_blocksize
 with_segsize
 with_wal_blocksize
+with_trans_slots_per_zheap_page
 with_CC
 with_llvm
 enable_depend
@@ -1542,6 +1543,8 @@ Optional Packages:
   --with-segsize=SEGSIZE  set table segment size in GB [1]
   --with-wal-blocksize=BLOCKSIZE
                           set WAL block size in kB [8]
+  --with-trans_slots_per_zheap_page=SLOTS
+                          set transaction slots per zheap page [4]
   --with-CC=CMD           set compiler (deprecated)
   --with-llvm             build with LLVM based JIT support
   --with-icu              build with ICU support
@@ -3780,6 +3783,51 @@ _ACEOF
 
 
 #
+# transaction slots per zheap page
+#
+{ $as_echo "$as_me:${as_lineno-$LINENO}: checking for transaction slots per zheap page" >&5
+$as_echo_n "checking for transaction slots per zheap page... " >&6; }
+
+
+
+# Check whether --with-trans_slots_per_zheap_page was given.
+if test "${with_trans_slots_per_zheap_page+set}" = set; then :
+  withval=$with_trans_slots_per_zheap_page;
+  case $withval in
+    yes)
+      as_fn_error $? "argument required for --with-trans_slots_per_zheap_page option" "$LINENO" 5
+      ;;
+    no)
+      as_fn_error $? "argument required for --with-trans_slots_per_zheap_page option" "$LINENO" 5
+      ;;
+    *)
+      trans_slots_per_page=$withval
+      ;;
+  esac
+
+else
+  trans_slots_per_page=4
+fi
+
+
+case ${trans_slots_per_page} in
+  2) ZHEAP_PAGE_TRANS_SLOTS=2;;
+  4) ZHEAP_PAGE_TRANS_SLOTS=4;;
+  8) ZHEAP_PAGE_TRANS_SLOTS=8;;
+ 16) ZHEAP_PAGE_TRANS_SLOTS=16;;
+ 31) ZHEAP_PAGE_TRANS_SLOTS=31;;
+  *) as_fn_error $? "Invalid transaction slots per zheap page. Allowed values are 2,4,8,16,31." "$LINENO" 5
+esac
+{ $as_echo "$as_me:${as_lineno-$LINENO}: result: ${trans_slots_per_page}" >&5
+$as_echo "${trans_slots_per_page}" >&6; }
+
+
+cat >>confdefs.h <<_ACEOF
+#define ZHEAP_PAGE_TRANS_SLOTS ${ZHEAP_PAGE_TRANS_SLOTS}
+_ACEOF
+
+
+#
 # C compiler
 #
 
diff --git a/configure.in b/configure.in
index dde3eec..3a7908f 100644
--- a/configure.in
+++ b/configure.in
@@ -337,6 +337,29 @@ AC_DEFINE_UNQUOTED([XLOG_BLCKSZ], ${XLOG_BLCKSZ}, [
 ])
 
 #
+# transaction slots per zheap page
+#
+AC_MSG_CHECKING([for transaction slots per zheap page])
+PGAC_ARG_REQ(with, trans_slots_per_zheap_page, [SLOTS], [set transaction slots per zheap page [4]],
+             [trans_slots_per_page=$withval],
+             [trans_slots_per_page=4])
+case ${trans_slots_per_page} in
+  2) ZHEAP_PAGE_TRANS_SLOTS=2;;
+  4) ZHEAP_PAGE_TRANS_SLOTS=4;;
+  8) ZHEAP_PAGE_TRANS_SLOTS=8;;
+ 16) ZHEAP_PAGE_TRANS_SLOTS=16;;
+ 31) ZHEAP_PAGE_TRANS_SLOTS=31;;
+  *) AC_MSG_ERROR([Invalid transaction slots per zheap page. Allowed values are 2,4,8,16,31.])
+esac
+AC_MSG_RESULT([${trans_slots_per_page}])
+
+AC_DEFINE_UNQUOTED([ZHEAP_PAGE_TRANS_SLOTS], ${ZHEAP_PAGE_TRANS_SLOTS}, [
+ transaction slots per zheap page. By default, it is set to 4.
+
+ Changing ZHEAP_PAGE_TRANS_SLOTS requires an initdb.
+])
+
+#
 # C compiler
 #
 
diff --git a/contrib/btree_gist/expected/enum.out b/contrib/btree_gist/expected/enum.out
index c4b769d..7453605 100644
--- a/contrib/btree_gist/expected/enum.out
+++ b/contrib/btree_gist/expected/enum.out
@@ -48,6 +48,8 @@ SELECT count(*) FROM enumtmp WHERE a >  'g'::rainbow;
 
 CREATE INDEX enumidx ON enumtmp USING gist ( a );
 SET enable_seqscan=off;
+SET enable_bitmapscan=off;
+SET enable_indexonlyscan=off;
 SELECT count(*) FROM enumtmp WHERE a <  'g'::rainbow;
  count 
 -------
@@ -80,12 +82,10 @@ SELECT count(*) FROM enumtmp WHERE a >  'g'::rainbow;
 
 EXPLAIN (COSTS OFF)
 SELECT count(*) FROM enumtmp WHERE a >= 'g'::rainbow;
-                  QUERY PLAN                   
------------------------------------------------
+                QUERY PLAN                 
+-------------------------------------------
  Aggregate
-   ->  Bitmap Heap Scan on enumtmp
-         Recheck Cond: (a >= 'g'::rainbow)
-         ->  Bitmap Index Scan on enumidx
-               Index Cond: (a >= 'g'::rainbow)
-(5 rows)
+   ->  Index Scan using enumidx on enumtmp
+         Index Cond: (a >= 'g'::rainbow)
+(3 rows)
 
diff --git a/contrib/btree_gist/sql/enum.sql b/contrib/btree_gist/sql/enum.sql
index 476211e..9a7176a 100644
--- a/contrib/btree_gist/sql/enum.sql
+++ b/contrib/btree_gist/sql/enum.sql
@@ -23,6 +23,8 @@ SELECT count(*) FROM enumtmp WHERE a >  'g'::rainbow;
 CREATE INDEX enumidx ON enumtmp USING gist ( a );
 
 SET enable_seqscan=off;
+SET enable_bitmapscan=off;
+SET enable_indexonlyscan=off;
 
 SELECT count(*) FROM enumtmp WHERE a <  'g'::rainbow;
 
diff --git a/contrib/pageinspect/Makefile b/contrib/pageinspect/Makefile
index e5a581f..18fca39 100644
--- a/contrib/pageinspect/Makefile
+++ b/contrib/pageinspect/Makefile
@@ -2,17 +2,17 @@
 
 MODULE_big	= pageinspect
 OBJS		= rawpage.o heapfuncs.o btreefuncs.o fsmfuncs.o \
-		  brinfuncs.o ginfuncs.o hashfuncs.o $(WIN32RES)
+		  brinfuncs.o ginfuncs.o hashfuncs.o zheapfuncs.o $(WIN32RES)
 
 EXTENSION = pageinspect
-DATA =  pageinspect--1.6--1.7.sql \
+DATA =  pageinspect--1.7--1.8.sql pageinspect--1.6--1.7.sql \
 	pageinspect--1.5.sql pageinspect--1.5--1.6.sql \
 	pageinspect--1.4--1.5.sql pageinspect--1.3--1.4.sql \
 	pageinspect--1.2--1.3.sql pageinspect--1.1--1.2.sql \
 	pageinspect--1.0--1.1.sql pageinspect--unpackaged--1.0.sql
 PGFILEDESC = "pageinspect - functions to inspect contents of database pages"
 
-REGRESS = page btree brin gin hash
+REGRESS = page btree brin gin hash zheap
 
 ifdef USE_PGXS
 PG_CONFIG = pg_config
diff --git a/contrib/pageinspect/expected/btree.out b/contrib/pageinspect/expected/btree.out
index 07c2dcd..2d58263 100644
--- a/contrib/pageinspect/expected/btree.out
+++ b/contrib/pageinspect/expected/btree.out
@@ -31,30 +31,28 @@ btpo_flags    | 3
 
 SELECT * FROM bt_page_stats('test1_a_idx', 2);
 ERROR:  block number out of range
-SELECT * FROM bt_page_items('test1_a_idx', 0);
+SELECT itemoffset, itemlen, nulls, vars, data FROM bt_page_items('test1_a_idx', 0);
 ERROR:  block 0 is a meta page
-SELECT * FROM bt_page_items('test1_a_idx', 1);
+SELECT itemoffset, itemlen, nulls, vars, data FROM bt_page_items('test1_a_idx', 1);
 -[ RECORD 1 ]-----------------------
 itemoffset | 1
-ctid       | (0,1)
 itemlen    | 16
 nulls      | f
 vars       | f
 data       | 01 00 00 00 00 00 00 01
 
-SELECT * FROM bt_page_items('test1_a_idx', 2);
+SELECT itemoffset, itemlen, nulls, vars, data FROM bt_page_items('test1_a_idx', 2);
 ERROR:  block number out of range
-SELECT * FROM bt_page_items(get_raw_page('test1_a_idx', 0));
+SELECT itemoffset, itemlen, nulls, vars, data FROM bt_page_items(get_raw_page('test1_a_idx', 0));
 ERROR:  block is a meta page
-SELECT * FROM bt_page_items(get_raw_page('test1_a_idx', 1));
+SELECT itemoffset, itemlen, nulls, vars, data FROM bt_page_items(get_raw_page('test1_a_idx', 1));
 -[ RECORD 1 ]-----------------------
 itemoffset | 1
-ctid       | (0,1)
 itemlen    | 16
 nulls      | f
 vars       | f
 data       | 01 00 00 00 00 00 00 01
 
-SELECT * FROM bt_page_items(get_raw_page('test1_a_idx', 2));
+SELECT itemoffset, itemlen, nulls, vars, data FROM bt_page_items(get_raw_page('test1_a_idx', 2));
 ERROR:  block number 2 is out of range for relation "test1_a_idx"
 DROP TABLE test1;
diff --git a/contrib/pageinspect/expected/hash.out b/contrib/pageinspect/expected/hash.out
index 75d7bcf..0d42a23 100644
--- a/contrib/pageinspect/expected/hash.out
+++ b/contrib/pageinspect/expected/hash.out
@@ -1,4 +1,4 @@
-CREATE TABLE test_hash (a int, b text);
+CREATE TABLE test_hash (a int, b text) USING heap;
 INSERT INTO test_hash VALUES (1, 'one');
 CREATE INDEX test_hash_a_idx ON test_hash USING hash (a);
 \x
@@ -140,23 +140,22 @@ SELECT live_items, dead_items, page_size, hasho_prevblkno, hasho_nextblkno,
 hasho_bucket, hasho_flag, hasho_page_id FROM
 hash_page_stats(get_raw_page('test_hash_a_idx', 5));
 ERROR:  page is not a hash bucket or overflow page
-SELECT * FROM hash_page_items(get_raw_page('test_hash_a_idx', 0));
+SELECT itemoffset, data FROM hash_page_items(get_raw_page('test_hash_a_idx', 0));
 ERROR:  page is not a hash bucket or overflow page
-SELECT * FROM hash_page_items(get_raw_page('test_hash_a_idx', 1));
+SELECT itemoffset, data FROM hash_page_items(get_raw_page('test_hash_a_idx', 1));
 (0 rows)
 
-SELECT * FROM hash_page_items(get_raw_page('test_hash_a_idx', 2));
+SELECT itemoffset, data FROM hash_page_items(get_raw_page('test_hash_a_idx', 2));
 (0 rows)
 
-SELECT * FROM hash_page_items(get_raw_page('test_hash_a_idx', 3));
+SELECT itemoffset, data FROM hash_page_items(get_raw_page('test_hash_a_idx', 3));
 -[ RECORD 1 ]----------
 itemoffset | 1
-ctid       | (0,1)
 data       | 2389907270
 
-SELECT * FROM hash_page_items(get_raw_page('test_hash_a_idx', 4));
+SELECT itemoffset, data FROM hash_page_items(get_raw_page('test_hash_a_idx', 4));
 (0 rows)
 
-SELECT * FROM hash_page_items(get_raw_page('test_hash_a_idx', 5));
+SELECT itemoffset, data FROM hash_page_items(get_raw_page('test_hash_a_idx', 5));
 ERROR:  page is not a hash bucket or overflow page
 DROP TABLE test_hash;
diff --git a/contrib/pageinspect/expected/page.out b/contrib/pageinspect/expected/page.out
index 3fcd9fb..a4e48d3 100644
--- a/contrib/pageinspect/expected/page.out
+++ b/contrib/pageinspect/expected/page.out
@@ -1,5 +1,5 @@
 CREATE EXTENSION pageinspect;
-CREATE TABLE test1 (a int, b int);
+CREATE TABLE test1 (a int, b int) USING heap;
 INSERT INTO test1 VALUES (16777217, 131584);
 VACUUM test1;  -- set up FSM
 -- The page contents can vary, so just test that it can be read
@@ -92,12 +92,12 @@ ERROR:  cannot get raw page from partitioned table "test_partitioned"
 select get_raw_page('test_partitioned_index', 0); -- error about partitioned index
 ERROR:  cannot get raw page from partitioned index "test_partitioned_index"
 -- a regular table which is a member of a partition set should work though
-create table test_part1 partition of test_partitioned for values from ( 1 ) to (100);
+create table test_part1 partition of test_partitioned for values from ( 1 ) to (100) USING heap;
 select get_raw_page('test_part1', 0); -- get farther and error about empty table
 ERROR:  block number 0 is out of range for relation "test_part1"
 drop table test_partitioned;
 -- check null bitmap alignment for table whose number of attributes is multiple of 8
-create table test8 (f1 int, f2 int, f3 int, f4 int, f5 int, f6 int, f7 int, f8 int);
+create table test8 (f1 int, f2 int, f3 int, f4 int, f5 int, f6 int, f7 int, f8 int) USING heap;
 insert into test8(f1, f8) values (x'7f00007f'::int, 0);
 select t_bits, t_data from heap_page_items(get_raw_page('test8', 0));
   t_bits  |       t_data       
diff --git a/contrib/pageinspect/expected/zheap.out b/contrib/pageinspect/expected/zheap.out
new file mode 100644
index 0000000..095e988
--- /dev/null
+++ b/contrib/pageinspect/expected/zheap.out
@@ -0,0 +1,64 @@
+CREATE TABLE test_zheap (a int, b int) USING zheap;
+INSERT INTO test_zheap VALUES (16777217, 131584);
+-- The page contents can vary, so just test that it can be read
+-- successfully, but don't keep the output.
+SELECT pagesize, version FROM page_header(get_raw_page('test_zheap', 1));
+ pagesize | version 
+----------+---------
+     8192 |       4
+(1 row)
+
+SELECT page_checksum(get_raw_page('test_zheap', 1), 1) IS NOT NULL AS silly_checksum_test;
+ silly_checksum_test 
+---------------------
+ t
+(1 row)
+
+DROP TABLE test_zheap;
+-- check that using any of these functions with a partitioned table would fail
+create table test_partitioned (a int) partition by range (a);
+select get_raw_page('test_partitioned', 1); -- error about partitioned table
+ERROR:  cannot get raw page from partitioned table "test_partitioned"
+-- a regular table which is a member of a partition set should work though
+create table test_part1 partition of test_partitioned for values from ( 1 ) to (100) USING zheap;
+select get_raw_page('test_part1', 1); -- get farther and error about empty table
+ERROR:  block number 1 is out of range for relation "test_part1"
+drop table test_partitioned;
+-- The tuple contents can vary, so we perform some basic testing of zheap_page_items.
+-- We perform all the tuple modifications in a single transaction so that t_slot
+-- doesn't change if we change trancsation slots in page during compile time.
+-- Because of the same reason, we cannot check for all possibile output for
+-- t_infomask_info (for example: slot-reused, multilock, l-nokey-ex etc).
+create table test_zheap (a int, b text) USING zheap WITH (autovacuum_enabled=false);
+begin;
+insert into test_zheap (a) select generate_series(1,6);
+update test_zheap set a=10 where a=2;
+update test_zheap set b='abcd' where a=3;
+delete from test_zheap where a=4;
+select * from test_zheap where a=5 for share;
+ a | b 
+---+---
+ 5 | 
+(1 row)
+
+select * from test_zheap where a=6 for update;
+ a | b 
+---+---
+ 6 | 
+(1 row)
+
+commit;
+select  lp,lp_flags,t_slot,t_infomask2,t_infomask,t_hoff,t_bits,
+		t_infomask_info from zheap_page_items(get_raw_page('test_zheap', 1));
+ lp | lp_flags | t_slot | t_infomask2 | t_infomask | t_hoff |  t_bits  | t_infomask_info 
+----+----------+--------+-------------+------------+--------+----------+-----------------
+  1 |        1 |      1 |        2050 |          1 |      6 | 10000000 | 
+  2 |        1 |      1 |        2050 |         33 |      6 | 10000000 | {in-updated}
+  3 |        1 |      1 |        2050 |         65 |      6 | 10000000 | {updated}
+  4 |        1 |      1 |        2050 |       1041 |      6 | 10000000 | {deleted,l-ex}
+  5 |        1 |      1 |        2050 |        897 |      6 | 10000000 | {l-share}
+  6 |        1 |      1 |        2050 |       1153 |      6 | 10000000 | {l-ex}
+  7 |        1 |      1 |        2050 |          2 |      5 |          | 
+(7 rows)
+
+drop table test_zheap;
diff --git a/contrib/pageinspect/pageinspect--1.7--1.8.sql b/contrib/pageinspect/pageinspect--1.7--1.8.sql
new file mode 100644
index 0000000..b538af7
--- /dev/null
+++ b/contrib/pageinspect/pageinspect--1.7--1.8.sql
@@ -0,0 +1,39 @@
+/* contrib/pageinspect/pageinspect--1.7--1.8.sql */
+
+-- complain if script is sourced in psql, rather than via ALTER EXTENSION
+\echo Use "ALTER EXTENSION pageinspect UPDATE TO '1.8'" to load this file. \quit
+
+--
+-- zheap functions
+--
+
+--
+-- zheap_page_items()
+--
+CREATE FUNCTION zheap_page_items(IN page bytea,
+    OUT lp smallint,
+    OUT lp_off smallint,
+    OUT lp_flags smallint,
+    OUT lp_len smallint,
+    OUT t_slot smallint,
+    OUT t_infomask2 integer,
+    OUT t_infomask integer,
+    OUT t_hoff smallint,
+    OUT t_bits text,
+    OUT t_data bytea,
+    OUT t_infomask_info text[])
+RETURNS SETOF record
+AS 'MODULE_PATHNAME', 'zheap_page_items'
+LANGUAGE C STRICT PARALLEL SAFE;
+
+--
+-- zheap_page_slots()
+--
+CREATE FUNCTION zheap_page_slots(IN page bytea,
+    OUT slot_id smallint,
+    OUT epoch int4,
+    OUT xid int4,
+    OUT undoptr int8)
+RETURNS SETOF record
+AS 'MODULE_PATHNAME', 'zheap_page_slots'
+LANGUAGE C STRICT PARALLEL SAFE;
diff --git a/contrib/pageinspect/pageinspect.control b/contrib/pageinspect/pageinspect.control
index dcfc61f..f8cdf52 100644
--- a/contrib/pageinspect/pageinspect.control
+++ b/contrib/pageinspect/pageinspect.control
@@ -1,5 +1,5 @@
 # pageinspect extension
 comment = 'inspect the contents of database pages at a low level'
-default_version = '1.7'
+default_version = '1.8'
 module_pathname = '$libdir/pageinspect'
 relocatable = true
diff --git a/contrib/pageinspect/sql/btree.sql b/contrib/pageinspect/sql/btree.sql
index 8eac64c..d1e1e3f 100644
--- a/contrib/pageinspect/sql/btree.sql
+++ b/contrib/pageinspect/sql/btree.sql
@@ -10,12 +10,12 @@ SELECT * FROM bt_page_stats('test1_a_idx', 0);
 SELECT * FROM bt_page_stats('test1_a_idx', 1);
 SELECT * FROM bt_page_stats('test1_a_idx', 2);
 
-SELECT * FROM bt_page_items('test1_a_idx', 0);
-SELECT * FROM bt_page_items('test1_a_idx', 1);
-SELECT * FROM bt_page_items('test1_a_idx', 2);
+SELECT itemoffset, itemlen, nulls, vars, data FROM bt_page_items('test1_a_idx', 0);
+SELECT itemoffset, itemlen, nulls, vars, data FROM bt_page_items('test1_a_idx', 1);
+SELECT itemoffset, itemlen, nulls, vars, data FROM bt_page_items('test1_a_idx', 2);
 
-SELECT * FROM bt_page_items(get_raw_page('test1_a_idx', 0));
-SELECT * FROM bt_page_items(get_raw_page('test1_a_idx', 1));
-SELECT * FROM bt_page_items(get_raw_page('test1_a_idx', 2));
+SELECT itemoffset, itemlen, nulls, vars, data FROM bt_page_items(get_raw_page('test1_a_idx', 0));
+SELECT itemoffset, itemlen, nulls, vars, data FROM bt_page_items(get_raw_page('test1_a_idx', 1));
+SELECT itemoffset, itemlen, nulls, vars, data FROM bt_page_items(get_raw_page('test1_a_idx', 2));
 
 DROP TABLE test1;
diff --git a/contrib/pageinspect/sql/hash.sql b/contrib/pageinspect/sql/hash.sql
index 87ee549..e27c78a 100644
--- a/contrib/pageinspect/sql/hash.sql
+++ b/contrib/pageinspect/sql/hash.sql
@@ -1,4 +1,4 @@
-CREATE TABLE test_hash (a int, b text);
+CREATE TABLE test_hash (a int, b text) USING heap;
 INSERT INTO test_hash VALUES (1, 'one');
 CREATE INDEX test_hash_a_idx ON test_hash USING hash (a);
 
@@ -69,12 +69,12 @@ SELECT live_items, dead_items, page_size, hasho_prevblkno, hasho_nextblkno,
 hasho_bucket, hasho_flag, hasho_page_id FROM
 hash_page_stats(get_raw_page('test_hash_a_idx', 5));
 
-SELECT * FROM hash_page_items(get_raw_page('test_hash_a_idx', 0));
-SELECT * FROM hash_page_items(get_raw_page('test_hash_a_idx', 1));
-SELECT * FROM hash_page_items(get_raw_page('test_hash_a_idx', 2));
-SELECT * FROM hash_page_items(get_raw_page('test_hash_a_idx', 3));
-SELECT * FROM hash_page_items(get_raw_page('test_hash_a_idx', 4));
-SELECT * FROM hash_page_items(get_raw_page('test_hash_a_idx', 5));
+SELECT itemoffset, data FROM hash_page_items(get_raw_page('test_hash_a_idx', 0));
+SELECT itemoffset, data FROM hash_page_items(get_raw_page('test_hash_a_idx', 1));
+SELECT itemoffset, data FROM hash_page_items(get_raw_page('test_hash_a_idx', 2));
+SELECT itemoffset, data FROM hash_page_items(get_raw_page('test_hash_a_idx', 3));
+SELECT itemoffset, data FROM hash_page_items(get_raw_page('test_hash_a_idx', 4));
+SELECT itemoffset, data FROM hash_page_items(get_raw_page('test_hash_a_idx', 5));
 
 
 DROP TABLE test_hash;
diff --git a/contrib/pageinspect/sql/page.sql b/contrib/pageinspect/sql/page.sql
index 8ac9991..4ab4245 100644
--- a/contrib/pageinspect/sql/page.sql
+++ b/contrib/pageinspect/sql/page.sql
@@ -1,6 +1,6 @@
 CREATE EXTENSION pageinspect;
 
-CREATE TABLE test1 (a int, b int);
+CREATE TABLE test1 (a int, b int) USING heap;
 INSERT INTO test1 VALUES (16777217, 131584);
 
 VACUUM test1;  -- set up FSM
@@ -41,12 +41,12 @@ select get_raw_page('test_partitioned', 0); -- error about partitioned table
 select get_raw_page('test_partitioned_index', 0); -- error about partitioned index
 
 -- a regular table which is a member of a partition set should work though
-create table test_part1 partition of test_partitioned for values from ( 1 ) to (100);
+create table test_part1 partition of test_partitioned for values from ( 1 ) to (100) USING heap;
 select get_raw_page('test_part1', 0); -- get farther and error about empty table
 drop table test_partitioned;
 
 -- check null bitmap alignment for table whose number of attributes is multiple of 8
-create table test8 (f1 int, f2 int, f3 int, f4 int, f5 int, f6 int, f7 int, f8 int);
+create table test8 (f1 int, f2 int, f3 int, f4 int, f5 int, f6 int, f7 int, f8 int) USING heap;
 insert into test8(f1, f8) values (x'7f00007f'::int, 0);
 select t_bits, t_data from heap_page_items(get_raw_page('test8', 0));
 select tuple_data_split('test8'::regclass, t_data, t_infomask, t_infomask2, t_bits)
diff --git a/contrib/pageinspect/sql/zheap.sql b/contrib/pageinspect/sql/zheap.sql
new file mode 100644
index 0000000..0aa3a8c
--- /dev/null
+++ b/contrib/pageinspect/sql/zheap.sql
@@ -0,0 +1,38 @@
+CREATE TABLE test_zheap (a int, b int) USING zheap;
+INSERT INTO test_zheap VALUES (16777217, 131584);
+
+-- The page contents can vary, so just test that it can be read
+-- successfully, but don't keep the output.
+
+SELECT pagesize, version FROM page_header(get_raw_page('test_zheap', 1));
+
+SELECT page_checksum(get_raw_page('test_zheap', 1), 1) IS NOT NULL AS silly_checksum_test;
+
+DROP TABLE test_zheap;
+
+-- check that using any of these functions with a partitioned table would fail
+create table test_partitioned (a int) partition by range (a);
+select get_raw_page('test_partitioned', 1); -- error about partitioned table
+
+-- a regular table which is a member of a partition set should work though
+create table test_part1 partition of test_partitioned for values from ( 1 ) to (100) USING zheap;
+select get_raw_page('test_part1', 1); -- get farther and error about empty table
+drop table test_partitioned;
+
+-- The tuple contents can vary, so we perform some basic testing of zheap_page_items.
+-- We perform all the tuple modifications in a single transaction so that t_slot
+-- doesn't change if we change trancsation slots in page during compile time.
+-- Because of the same reason, we cannot check for all possibile output for
+-- t_infomask_info (for example: slot-reused, multilock, l-nokey-ex etc).
+create table test_zheap (a int, b text) USING zheap WITH (autovacuum_enabled=false);
+begin;
+insert into test_zheap (a) select generate_series(1,6);
+update test_zheap set a=10 where a=2;
+update test_zheap set b='abcd' where a=3;
+delete from test_zheap where a=4;
+select * from test_zheap where a=5 for share;
+select * from test_zheap where a=6 for update;
+commit;
+select  lp,lp_flags,t_slot,t_infomask2,t_infomask,t_hoff,t_bits,
+		t_infomask_info from zheap_page_items(get_raw_page('test_zheap', 1));
+drop table test_zheap;
diff --git a/contrib/pageinspect/zheapfuncs.c b/contrib/pageinspect/zheapfuncs.c
new file mode 100644
index 0000000..d85240a
--- /dev/null
+++ b/contrib/pageinspect/zheapfuncs.c
@@ -0,0 +1,431 @@
+/*-------------------------------------------------------------------------
+ *
+ * zheapfuncs.c
+ *	  Functions to investigate zheap pages
+ *
+ * We check the input to these functions for corrupt pointers etc. that
+ * might cause crashes, but at the same time we try to print out as much
+ * information as possible, even if it's nonsense. That's because if a
+ * page is corrupt, we don't know why and how exactly it is corrupt, so we
+ * let the user judge it.
+ *
+ * These functions are restricted to superusers for the fear of introducing
+ * security holes if the input checking isn't as water-tight as it should be.
+ * You'd need to be superuser to obtain a raw page image anyway, so
+ * there's hardly any use case for using these without superuser-rights
+ * anyway.
+ *
+ * Copyright (c) 2007-2019, PostgreSQL Global Development Group
+ *
+ * IDENTIFICATION
+ *	  contrib/pageinspect/zheapfuncs.c
+ *
+ *-------------------------------------------------------------------------
+ */
+
+#include "postgres.h"
+
+#include "pageinspect.h"
+
+#include "access/htup_details.h"
+#include "access/zheap.h"
+#include "funcapi.h"
+#include "catalog/pg_type.h"
+#include "miscadmin.h"
+#include "utils/array.h"
+#include "utils/builtins.h"
+#include "utils/rel.h"
+
+static void decode_infomask(ZHeapTupleHeader ztuphdr, Datum *values, bool *nulls);
+
+/*
+ * bits_to_text
+ *
+ * Converts a bits8-array of 'len' bits to a human-readable
+ * c-string representation.
+ */
+static char *
+bits_to_text(bits8 *bits, int len)
+{
+	int			i;
+	char	   *str;
+
+	str = palloc(len + 1);
+
+	for (i = 0; i < len; i++)
+		str[i] = (bits[(i / 8)] & (1 << (i % 8))) ? '1' : '0';
+
+	str[i] = '\0';
+
+	return str;
+}
+
+/*
+ * decode_infomask
+ *
+ * Converts tuple infomask into an array describing the flags marked in
+ * tuple infomask.
+ */
+static void
+decode_infomask(ZHeapTupleHeader ztuphdr, Datum *values, bool *nulls)
+{
+	ArrayBuildState *raw_attrs;
+
+	raw_attrs = initArrayResult(TEXTOID, CurrentMemoryContext, false);
+	if (ZHeapTupleHasMultiLockers(ztuphdr->t_infomask) ||
+		IsZHeapTupleModified(ztuphdr->t_infomask) ||
+		ZHeapTupleHasInvalidXact(ztuphdr->t_infomask))
+	{
+		if (ZHeapTupleHasInvalidXact(ztuphdr->t_infomask))
+		{
+			raw_attrs = accumArrayResult(raw_attrs, CStringGetTextDatum("slot-reused"),
+										 false, TEXTOID, CurrentMemoryContext);
+		}
+		if (ZHeapTupleHasMultiLockers(ztuphdr->t_infomask))
+		{
+			raw_attrs = accumArrayResult(raw_attrs, CStringGetTextDatum("multilock"),
+										 false, TEXTOID, CurrentMemoryContext);
+		}
+		if (ztuphdr->t_infomask & ZHEAP_DELETED)
+		{
+			raw_attrs = accumArrayResult(raw_attrs, CStringGetTextDatum("deleted"),
+										 false, TEXTOID, CurrentMemoryContext);
+		}
+		if (ztuphdr->t_infomask & ZHEAP_UPDATED)
+		{
+			raw_attrs = accumArrayResult(raw_attrs, CStringGetTextDatum("updated"),
+										 false, TEXTOID, CurrentMemoryContext);
+		}
+		if (ztuphdr->t_infomask & ZHEAP_INPLACE_UPDATED)
+		{
+			raw_attrs = accumArrayResult(raw_attrs, CStringGetTextDatum("in-updated"),
+										 false, TEXTOID, CurrentMemoryContext);
+		}
+		if ((ztuphdr->t_infomask & ZHEAP_XID_SHR_LOCK) == ZHEAP_XID_SHR_LOCK)
+		{
+			raw_attrs = accumArrayResult(raw_attrs, CStringGetTextDatum("l-share"),
+										 false, TEXTOID, CurrentMemoryContext);
+		}
+		else if (ztuphdr->t_infomask & ZHEAP_XID_NOKEY_EXCL_LOCK)
+		{
+			raw_attrs = accumArrayResult(raw_attrs, CStringGetTextDatum("l-nokey-ex"),
+										 false, TEXTOID, CurrentMemoryContext);
+		}
+		else if (ztuphdr->t_infomask & ZHEAP_XID_KEYSHR_LOCK)
+		{
+			raw_attrs = accumArrayResult(raw_attrs, CStringGetTextDatum("l-keyshare"),
+										 false, TEXTOID, CurrentMemoryContext);
+		}
+		if (ztuphdr->t_infomask & ZHEAP_XID_EXCL_LOCK)
+		{
+			raw_attrs = accumArrayResult(raw_attrs, CStringGetTextDatum("l-ex"),
+										 false, TEXTOID, CurrentMemoryContext);
+		}
+		*values = makeArrayResult(raw_attrs, CurrentMemoryContext);
+	}
+	else
+		*nulls = true;
+}
+
+/*
+ * zheap_page_items
+ *
+ * Allows inspection of line pointers and tuple headers of a zheap page.
+ */
+PG_FUNCTION_INFO_V1(zheap_page_items);
+
+typedef struct zheap_page_items_state
+{
+	TupleDesc	tupd;
+	Page		page;
+	uint16		offset;
+} zheap_page_items_state;
+
+Datum
+zheap_page_items(PG_FUNCTION_ARGS)
+{
+	bytea	   *raw_page = PG_GETARG_BYTEA_P(0);
+	zheap_page_items_state *inter_call_data = NULL;
+	FuncCallContext *fctx;
+	int			raw_page_size;
+
+	if (!superuser())
+		ereport(ERROR,
+				(errcode(ERRCODE_INSUFFICIENT_PRIVILEGE),
+				 (errmsg("must be superuser to use raw page functions"))));
+
+	raw_page_size = VARSIZE(raw_page) - VARHDRSZ;
+
+	if (SRF_IS_FIRSTCALL())
+	{
+		TupleDesc	tupdesc;
+		MemoryContext mctx;
+		int			num_trans_slots;
+
+		if (raw_page_size < SizeOfPageHeaderData)
+			ereport(ERROR,
+					(errcode(ERRCODE_INVALID_PARAMETER_VALUE),
+					 errmsg("input page too small (%d bytes)", raw_page_size)));
+
+		fctx = SRF_FIRSTCALL_INIT();
+		mctx = MemoryContextSwitchTo(fctx->multi_call_memory_ctx);
+
+		inter_call_data = palloc(sizeof(zheap_page_items_state));
+
+		/* Build a tuple descriptor for our result type */
+		if (get_call_result_type(fcinfo, NULL, &tupdesc) != TYPEFUNC_COMPOSITE)
+			elog(ERROR, "return type must be a row type");
+
+		inter_call_data->tupd = tupdesc;
+
+		inter_call_data->offset = FirstOffsetNumber;
+		inter_call_data->page = VARDATA(raw_page);
+
+		fctx->max_calls = PageGetMaxOffsetNumber(inter_call_data->page);
+		fctx->user_fctx = inter_call_data;
+
+		/*
+		 * We cannot check whether this is a zheap page or not. But, we can
+		 * check whether pd_special is set correctly so that it contains the
+		 * expected number of transaction slots in the special space.
+		 */
+		num_trans_slots = (raw_page_size - ((PageHeader)
+											(inter_call_data->page))->pd_special)
+			/ sizeof(ZHeapPageOpaqueData);
+
+		if (num_trans_slots != ZHEAP_PAGE_TRANS_SLOTS)
+			elog(ERROR, "zheap page contains unexpected number of transaction"
+				 "slots: %d, expecting %d", num_trans_slots, ZHEAP_PAGE_TRANS_SLOTS);
+
+		MemoryContextSwitchTo(mctx);
+	}
+
+	fctx = SRF_PERCALL_SETUP();
+	inter_call_data = fctx->user_fctx;
+
+	if (fctx->call_cntr < fctx->max_calls)
+	{
+		Page		page = inter_call_data->page;
+		HeapTuple	resultTuple;
+		Datum		result;
+		ItemId		id;
+		Datum		values[11];
+		bool		nulls[11];
+		uint16		lp_offset;
+		uint16		lp_flags;
+		uint16		lp_len;
+
+		memset(nulls, 0, sizeof(nulls));
+
+		/* Extract information from the line pointer */
+
+		id = PageGetItemId(page, inter_call_data->offset);
+
+		lp_offset = ItemIdGetOffset(id);
+		lp_flags = ItemIdGetFlags(id);
+		lp_len = ItemIdGetLength(id);
+
+		values[0] = UInt16GetDatum(inter_call_data->offset);
+		values[1] = UInt16GetDatum(lp_offset);
+		values[2] = UInt16GetDatum(lp_flags);
+		values[3] = UInt16GetDatum(lp_len);
+
+		/*
+		 * We do just enough validity checking to make sure we don't reference
+		 * data outside the page passed to us. The page could be corrupt in
+		 * many other ways, but at least we won't crash.
+		 */
+		if (ItemIdHasStorage(id) &&
+			lp_len >= MinZHeapTupleSize &&
+			lp_offset + lp_len <= raw_page_size)
+		{
+			ZHeapTupleHeader ztuphdr;
+			bytea	   *tuple_data_bytea;
+			int			tuple_data_len;
+
+			/* Extract information from the tuple header */
+			ztuphdr = (ZHeapTupleHeader) PageGetItem(page, id);
+
+			values[4] = UInt16GetDatum(ZHeapTupleHeaderGetXactSlot(ztuphdr));
+
+			values[5] = UInt32GetDatum(ztuphdr->t_infomask2);
+			values[6] = UInt32GetDatum(ztuphdr->t_infomask);
+			values[7] = UInt8GetDatum(ztuphdr->t_hoff);
+
+			/*
+			 * We already checked that the item is completely within the raw
+			 * page passed to us, with the length given in the line pointer.
+			 * Let's check that t_hoff doesn't point over lp_len, before using
+			 * it to access t_bits and oid.
+			 */
+			if (ztuphdr->t_hoff >= SizeofZHeapTupleHeader &&
+				ztuphdr->t_hoff <= lp_len)
+			{
+				if (ztuphdr->t_infomask & ZHEAP_HASNULL)
+				{
+					int			bits_len;
+
+					bits_len =
+						BITMAPLEN(ZHeapTupleHeaderGetNatts(ztuphdr)) * BITS_PER_BYTE;
+					values[8] = CStringGetTextDatum(
+													bits_to_text(ztuphdr->t_bits, bits_len));
+				}
+				else
+					nulls[8] = true;
+
+			}
+			else
+			{
+				nulls[8] = true;
+			}
+
+			/* Copy raw tuple data into bytea attribute */
+			tuple_data_len = lp_len - ztuphdr->t_hoff;
+			tuple_data_bytea = (bytea *) palloc(tuple_data_len + VARHDRSZ);
+			SET_VARSIZE(tuple_data_bytea, tuple_data_len + VARHDRSZ);
+			memcpy(VARDATA(tuple_data_bytea), (char *) ztuphdr + ztuphdr->t_hoff,
+				   tuple_data_len);
+			values[9] = PointerGetDatum(tuple_data_bytea);
+
+			decode_infomask(ztuphdr, &values[10], &nulls[10]);
+		}
+		else
+		{
+			/*
+			 * The line pointer is not used, or it's invalid. Set the rest of
+			 * the fields to NULL
+			 */
+			int			i;
+
+			for (i = 4; i <= 11; i++)
+				nulls[i] = true;
+		}
+
+		/* Build and return the result tuple. */
+		resultTuple = heap_form_tuple(inter_call_data->tupd, values, nulls);
+		result = HeapTupleGetDatum(resultTuple);
+
+		inter_call_data->offset++;
+
+		SRF_RETURN_NEXT(fctx, result);
+	}
+	else
+		SRF_RETURN_DONE(fctx);
+}
+
+/*
+ * zheap_page_slots
+ *
+ * Allows inspection of transaction slots of a zheap page.
+ */
+PG_FUNCTION_INFO_V1(zheap_page_slots);
+
+typedef struct zheap_page_slots_state
+{
+	TupleDesc	tupd;
+	Page		page;
+	uint16		slot_id;
+} zheap_page_slots_state;
+
+Datum
+zheap_page_slots(PG_FUNCTION_ARGS)
+{
+	bytea	   *raw_page = PG_GETARG_BYTEA_P(0);
+	zheap_page_slots_state *inter_call_data = NULL;
+	FuncCallContext *fctx;
+	int			raw_page_size;
+
+	if (!superuser())
+		ereport(ERROR,
+				(errcode(ERRCODE_INSUFFICIENT_PRIVILEGE),
+				 (errmsg("must be superuser to use raw page functions"))));
+
+	raw_page_size = VARSIZE(raw_page) - VARHDRSZ;
+
+	if (SRF_IS_FIRSTCALL())
+	{
+		TupleDesc	tupdesc;
+		MemoryContext mctx;
+		int			num_trans_slots;
+
+		if (raw_page_size < SizeOfPageHeaderData)
+			ereport(ERROR,
+					(errcode(ERRCODE_INVALID_PARAMETER_VALUE),
+					 errmsg("input page too small (%d bytes)", raw_page_size)));
+
+		fctx = SRF_FIRSTCALL_INIT();
+		mctx = MemoryContextSwitchTo(fctx->multi_call_memory_ctx);
+
+		inter_call_data = palloc(sizeof(zheap_page_slots_state));
+
+		/* Build a tuple descriptor for our result type */
+		if (get_call_result_type(fcinfo, NULL, &tupdesc) != TYPEFUNC_COMPOSITE)
+			elog(ERROR, "return type must be a row type");
+
+		inter_call_data->tupd = tupdesc;
+
+		inter_call_data->slot_id = 0;
+		inter_call_data->page = VARDATA(raw_page);
+
+		fctx->user_fctx = inter_call_data;
+
+		/*
+		 * We cannot check whether this is a zheap page or not. But, we can
+		 * check whether pd_special is set correctly so that it contains the
+		 * expected number of transaction slots in the special space.
+		 */
+		num_trans_slots = (raw_page_size - ((PageHeader)
+											(inter_call_data->page))->pd_special)
+			/ sizeof(ZHeapPageOpaqueData);
+
+		if (num_trans_slots != ZHEAP_PAGE_TRANS_SLOTS)
+			elog(ERROR, "zheap page contains unexpected number of transaction"
+				 "slots: %d, expecting %d", num_trans_slots, ZHEAP_PAGE_TRANS_SLOTS);
+
+		/*
+		 * If the page has tpd slot, last slot is used as tpd slot. In that
+		 * case, it will not have any informations about transaction.
+		 */
+		if (ZHeapPageHasTPDSlot((PageHeader) inter_call_data->page))
+			num_trans_slots--;
+		fctx->max_calls = num_trans_slots;
+
+		MemoryContextSwitchTo(mctx);
+	}
+
+	fctx = SRF_PERCALL_SETUP();
+	inter_call_data = fctx->user_fctx;
+
+	if (fctx->call_cntr < fctx->max_calls)
+	{
+		Page		page = inter_call_data->page;
+		HeapTuple	resultTuple;
+		Datum		result;
+		Datum		values[4];
+		bool		nulls[4];
+		ZHeapPageOpaque opaque;
+		TransInfo	transinfo;
+
+		memset(nulls, 0, sizeof(nulls));
+
+		opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+		transinfo = opaque->transinfo[inter_call_data->slot_id];
+
+		/* Fetch transaction and undo information from slot */
+		values[0] = UInt16GetDatum(inter_call_data->slot_id + 1);
+		/* FIXME: should probably be represented as a single value? */
+		values[1] = UInt32GetDatum(EpochFromFullTransactionId(transinfo.fxid));
+		values[2] = UInt32GetDatum(XidFromFullTransactionId(transinfo.fxid));
+		values[3] = UInt64GetDatum(transinfo.urec_ptr);
+
+		/* Build and return the result tuple. */
+		resultTuple = heap_form_tuple(inter_call_data->tupd, values, nulls);
+		result = HeapTupleGetDatum(resultTuple);
+
+		inter_call_data->slot_id++;
+
+		SRF_RETURN_NEXT(fctx, result);
+	}
+	else
+		SRF_RETURN_DONE(fctx);
+}
diff --git a/contrib/pg_visibility/expected/pg_visibility.out b/contrib/pg_visibility/expected/pg_visibility.out
index f0dcb89..d8905a5 100644
--- a/contrib/pg_visibility/expected/pg_visibility.out
+++ b/contrib/pg_visibility/expected/pg_visibility.out
@@ -15,7 +15,7 @@ select pg_check_frozen('test_partitioned');
 ERROR:  "test_partitioned" is not a table, materialized view, or TOAST table
 select pg_truncate_visibility_map('test_partitioned');
 ERROR:  "test_partitioned" is not a table, materialized view, or TOAST table
-create table test_partition partition of test_partitioned for values in (1);
+create table test_partition partition of test_partitioned for values in (1) using heap;
 create index test_index on test_partition (a);
 -- indexes do not, so these all fail
 select pg_visibility('test_index', 0);
@@ -67,7 +67,7 @@ ERROR:  "test_foreign_table" is not a table, materialized view, or TOAST table
 select pg_truncate_visibility_map('test_foreign_table');
 ERROR:  "test_foreign_table" is not a table, materialized view, or TOAST table
 -- check some of the allowed relkinds
-create table regular_table (a int);
+create table regular_table (a int) using heap;
 insert into regular_table values (1), (2);
 vacuum regular_table;
 select count(*) > 0 from pg_visibility('regular_table');
@@ -83,7 +83,7 @@ select count(*) > 0 from pg_visibility('regular_table');
  f
 (1 row)
 
-create materialized view matview_visibility_test as select * from regular_table;
+create materialized view matview_visibility_test using heap as select * from regular_table;
 vacuum matview_visibility_test;
 select count(*) > 0 from pg_visibility('matview_visibility_test');
  ?column? 
diff --git a/contrib/pg_visibility/sql/pg_visibility.sql b/contrib/pg_visibility/sql/pg_visibility.sql
index c2a7f1d..24605b8 100644
--- a/contrib/pg_visibility/sql/pg_visibility.sql
+++ b/contrib/pg_visibility/sql/pg_visibility.sql
@@ -13,7 +13,7 @@ select pg_visibility_map_summary('test_partitioned');
 select pg_check_frozen('test_partitioned');
 select pg_truncate_visibility_map('test_partitioned');
 
-create table test_partition partition of test_partitioned for values in (1);
+create table test_partition partition of test_partitioned for values in (1) using heap;
 create index test_index on test_partition (a);
 -- indexes do not, so these all fail
 select pg_visibility('test_index', 0);
@@ -49,14 +49,14 @@ select pg_check_frozen('test_foreign_table');
 select pg_truncate_visibility_map('test_foreign_table');
 
 -- check some of the allowed relkinds
-create table regular_table (a int);
+create table regular_table (a int) using heap;
 insert into regular_table values (1), (2);
 vacuum regular_table;
 select count(*) > 0 from pg_visibility('regular_table');
 truncate regular_table;
 select count(*) > 0 from pg_visibility('regular_table');
 
-create materialized view matview_visibility_test as select * from regular_table;
+create materialized view matview_visibility_test using heap as select * from regular_table;
 vacuum matview_visibility_test;
 select count(*) > 0 from pg_visibility('matview_visibility_test');
 insert into regular_table values (1), (2);
diff --git a/contrib/pgstattuple/expected/pgstattuple.out b/contrib/pgstattuple/expected/pgstattuple.out
index 9920dbf..f6d0568 100644
--- a/contrib/pgstattuple/expected/pgstattuple.out
+++ b/contrib/pgstattuple/expected/pgstattuple.out
@@ -4,7 +4,7 @@ CREATE EXTENSION pgstattuple;
 -- the pgstattuple functions, but the results for empty tables and
 -- indexes should be that.
 --
-create table test (a int primary key, b int[]);
+create table test (a int primary key, b int[]) using heap;
 select * from pgstattuple('test');
  table_len | tuple_count | tuple_len | tuple_percent | dead_tuple_count | dead_tuple_len | dead_tuple_percent | free_space | free_percent 
 -----------+-------------+-----------+---------------+------------------+----------------+--------------------+------------+--------------
@@ -199,7 +199,7 @@ ERROR:  relation "test_foreign_table" is not a GIN index
 select pgstathashindex('test_foreign_table');
 ERROR:  "test_foreign_table" is not an index
 -- a partition of a partitioned table should work though
-create table test_partition partition of test_partitioned for values from (1) to (100);
+create table test_partition partition of test_partitioned for values from (1) to (100) using heap;
 select pgstattuple('test_partition');
      pgstattuple     
 ---------------------
diff --git a/contrib/pgstattuple/sql/pgstattuple.sql b/contrib/pgstattuple/sql/pgstattuple.sql
index cfa5403..9061f71 100644
--- a/contrib/pgstattuple/sql/pgstattuple.sql
+++ b/contrib/pgstattuple/sql/pgstattuple.sql
@@ -6,7 +6,7 @@ CREATE EXTENSION pgstattuple;
 -- indexes should be that.
 --
 
-create table test (a int primary key, b int[]);
+create table test (a int primary key, b int[]) using heap;
 
 select * from pgstattuple('test');
 select * from pgstattuple('test'::text);
@@ -95,7 +95,7 @@ select pgstatginindex('test_foreign_table');
 select pgstathashindex('test_foreign_table');
 
 -- a partition of a partitioned table should work though
-create table test_partition partition of test_partitioned for values from (1) to (100);
+create table test_partition partition of test_partitioned for values from (1) to (100) using heap;
 select pgstattuple('test_partition');
 select pgstattuple_approx('test_partition');
 select pg_relpages('test_partition');
diff --git a/contrib/postgres_fdw/expected/postgres_fdw_1.out b/contrib/postgres_fdw/expected/postgres_fdw_1.out
new file mode 100644
index 0000000..d816bd1
--- /dev/null
+++ b/contrib/postgres_fdw/expected/postgres_fdw_1.out
@@ -0,0 +1,8600 @@
+-- ===================================================================
+-- create FDW objects
+-- ===================================================================
+CREATE EXTENSION postgres_fdw;
+CREATE SERVER testserver1 FOREIGN DATA WRAPPER postgres_fdw;
+DO $d$
+    BEGIN
+        EXECUTE $$CREATE SERVER loopback FOREIGN DATA WRAPPER postgres_fdw
+            OPTIONS (dbname '$$||current_database()||$$',
+                     port '$$||current_setting('port')||$$'
+            )$$;
+        EXECUTE $$CREATE SERVER loopback2 FOREIGN DATA WRAPPER postgres_fdw
+            OPTIONS (dbname '$$||current_database()||$$',
+                     port '$$||current_setting('port')||$$'
+            )$$;
+    END;
+$d$;
+CREATE USER MAPPING FOR public SERVER testserver1
+	OPTIONS (user 'value', password 'value');
+CREATE USER MAPPING FOR CURRENT_USER SERVER loopback;
+CREATE USER MAPPING FOR CURRENT_USER SERVER loopback2;
+-- ===================================================================
+-- create objects used through FDW loopback server
+-- ===================================================================
+CREATE TYPE user_enum AS ENUM ('foo', 'bar', 'buz');
+CREATE SCHEMA "S 1";
+CREATE TABLE "S 1"."T 1" (
+	"C 1" int NOT NULL,
+	c2 int NOT NULL,
+	c3 text,
+	c4 timestamptz,
+	c5 timestamp,
+	c6 varchar(10),
+	c7 char(10),
+	c8 user_enum,
+	CONSTRAINT t1_pkey PRIMARY KEY ("C 1")
+);
+CREATE TABLE "S 1"."T 2" (
+	c1 int NOT NULL,
+	c2 text,
+	CONSTRAINT t2_pkey PRIMARY KEY (c1)
+);
+CREATE TABLE "S 1"."T 3" (
+	c1 int NOT NULL,
+	c2 int NOT NULL,
+	c3 text,
+	CONSTRAINT t3_pkey PRIMARY KEY (c1)
+);
+CREATE TABLE "S 1"."T 4" (
+	c1 int NOT NULL,
+	c2 int NOT NULL,
+	c3 text,
+	CONSTRAINT t4_pkey PRIMARY KEY (c1)
+);
+-- Disable autovacuum for these tables to avoid unexpected effects of that
+ALTER TABLE "S 1"."T 1" SET (autovacuum_enabled = 'false');
+ALTER TABLE "S 1"."T 2" SET (autovacuum_enabled = 'false');
+ALTER TABLE "S 1"."T 3" SET (autovacuum_enabled = 'false');
+ALTER TABLE "S 1"."T 4" SET (autovacuum_enabled = 'false');
+INSERT INTO "S 1"."T 1"
+	SELECT id,
+	       id % 10,
+	       to_char(id, 'FM00000'),
+	       '1970-01-01'::timestamptz + ((id % 100) || ' days')::interval,
+	       '1970-01-01'::timestamp + ((id % 100) || ' days')::interval,
+	       id % 10,
+	       id % 10,
+	       'foo'::user_enum
+	FROM generate_series(1, 1000) id;
+INSERT INTO "S 1"."T 2"
+	SELECT id,
+	       'AAA' || to_char(id, 'FM000')
+	FROM generate_series(1, 100) id;
+INSERT INTO "S 1"."T 3"
+	SELECT id,
+	       id + 1,
+	       'AAA' || to_char(id, 'FM000')
+	FROM generate_series(1, 100) id;
+DELETE FROM "S 1"."T 3" WHERE c1 % 2 != 0;	-- delete for outer join tests
+INSERT INTO "S 1"."T 4"
+	SELECT id,
+	       id + 1,
+	       'AAA' || to_char(id, 'FM000')
+	FROM generate_series(1, 100) id;
+DELETE FROM "S 1"."T 4" WHERE c1 % 3 != 0;	-- delete for outer join tests
+ANALYZE "S 1"."T 1";
+ANALYZE "S 1"."T 2";
+ANALYZE "S 1"."T 3";
+ANALYZE "S 1"."T 4";
+-- ===================================================================
+-- create foreign tables
+-- ===================================================================
+CREATE FOREIGN TABLE ft1 (
+	c0 int,
+	c1 int NOT NULL,
+	c2 int NOT NULL,
+	c3 text,
+	c4 timestamptz,
+	c5 timestamp,
+	c6 varchar(10),
+	c7 char(10) default 'ft1',
+	c8 user_enum
+) SERVER loopback;
+ALTER FOREIGN TABLE ft1 DROP COLUMN c0;
+CREATE FOREIGN TABLE ft2 (
+	c1 int NOT NULL,
+	c2 int NOT NULL,
+	cx int,
+	c3 text,
+	c4 timestamptz,
+	c5 timestamp,
+	c6 varchar(10),
+	c7 char(10) default 'ft2',
+	c8 user_enum
+) SERVER loopback;
+ALTER FOREIGN TABLE ft2 DROP COLUMN cx;
+CREATE FOREIGN TABLE ft4 (
+	c1 int NOT NULL,
+	c2 int NOT NULL,
+	c3 text
+) SERVER loopback OPTIONS (schema_name 'S 1', table_name 'T 3');
+CREATE FOREIGN TABLE ft5 (
+	c1 int NOT NULL,
+	c2 int NOT NULL,
+	c3 text
+) SERVER loopback OPTIONS (schema_name 'S 1', table_name 'T 4');
+CREATE FOREIGN TABLE ft6 (
+	c1 int NOT NULL,
+	c2 int NOT NULL,
+	c3 text
+) SERVER loopback2 OPTIONS (schema_name 'S 1', table_name 'T 4');
+-- ===================================================================
+-- tests for validator
+-- ===================================================================
+-- requiressl, krbsrvname and gsslib are omitted because they depend on
+-- configure options
+ALTER SERVER testserver1 OPTIONS (
+	use_remote_estimate 'false',
+	updatable 'true',
+	fdw_startup_cost '123.456',
+	fdw_tuple_cost '0.123',
+	service 'value',
+	connect_timeout 'value',
+	dbname 'value',
+	host 'value',
+	hostaddr 'value',
+	port 'value',
+	--client_encoding 'value',
+	application_name 'value',
+	--fallback_application_name 'value',
+	keepalives 'value',
+	keepalives_idle 'value',
+	keepalives_interval 'value',
+	tcp_user_timeout 'value',
+	-- requiressl 'value',
+	sslcompression 'value',
+	sslmode 'value',
+	sslcert 'value',
+	sslkey 'value',
+	sslrootcert 'value',
+	sslcrl 'value'
+	--requirepeer 'value',
+	-- krbsrvname 'value',
+	-- gsslib 'value',
+	--replication 'value'
+);
+-- Error, invalid list syntax
+ALTER SERVER testserver1 OPTIONS (ADD extensions 'foo; bar');
+ERROR:  parameter "extensions" must be a list of extension names
+-- OK but gets a warning
+ALTER SERVER testserver1 OPTIONS (ADD extensions 'foo, bar');
+WARNING:  extension "foo" is not installed
+WARNING:  extension "bar" is not installed
+ALTER SERVER testserver1 OPTIONS (DROP extensions);
+ALTER USER MAPPING FOR public SERVER testserver1
+	OPTIONS (DROP user, DROP password);
+ALTER FOREIGN TABLE ft1 OPTIONS (schema_name 'S 1', table_name 'T 1');
+ALTER FOREIGN TABLE ft2 OPTIONS (schema_name 'S 1', table_name 'T 1');
+ALTER FOREIGN TABLE ft1 ALTER COLUMN c1 OPTIONS (column_name 'C 1');
+ALTER FOREIGN TABLE ft2 ALTER COLUMN c1 OPTIONS (column_name 'C 1');
+\det+
+                              List of foreign tables
+ Schema | Table |  Server   |              FDW options              | Description 
+--------+-------+-----------+---------------------------------------+-------------
+ public | ft1   | loopback  | (schema_name 'S 1', table_name 'T 1') | 
+ public | ft2   | loopback  | (schema_name 'S 1', table_name 'T 1') | 
+ public | ft4   | loopback  | (schema_name 'S 1', table_name 'T 3') | 
+ public | ft5   | loopback  | (schema_name 'S 1', table_name 'T 4') | 
+ public | ft6   | loopback2 | (schema_name 'S 1', table_name 'T 4') | 
+(5 rows)
+
+-- Test that alteration of server options causes reconnection
+-- Remote's errors might be non-English, so hide them to ensure stable results
+\set VERBOSITY terse
+SELECT c3, c4 FROM ft1 ORDER BY c3, c1 LIMIT 1;  -- should work
+  c3   |              c4              
+-------+------------------------------
+ 00001 | Fri Jan 02 00:00:00 1970 PST
+(1 row)
+
+ALTER SERVER loopback OPTIONS (SET dbname 'no such database');
+SELECT c3, c4 FROM ft1 ORDER BY c3, c1 LIMIT 1;  -- should fail
+ERROR:  could not connect to server "loopback"
+DO $d$
+    BEGIN
+        EXECUTE $$ALTER SERVER loopback
+            OPTIONS (SET dbname '$$||current_database()||$$')$$;
+    END;
+$d$;
+SELECT c3, c4 FROM ft1 ORDER BY c3, c1 LIMIT 1;  -- should work again
+  c3   |              c4              
+-------+------------------------------
+ 00001 | Fri Jan 02 00:00:00 1970 PST
+(1 row)
+
+-- Test that alteration of user mapping options causes reconnection
+ALTER USER MAPPING FOR CURRENT_USER SERVER loopback
+  OPTIONS (ADD user 'no such user');
+SELECT c3, c4 FROM ft1 ORDER BY c3, c1 LIMIT 1;  -- should fail
+ERROR:  could not connect to server "loopback"
+ALTER USER MAPPING FOR CURRENT_USER SERVER loopback
+  OPTIONS (DROP user);
+SELECT c3, c4 FROM ft1 ORDER BY c3, c1 LIMIT 1;  -- should work again
+  c3   |              c4              
+-------+------------------------------
+ 00001 | Fri Jan 02 00:00:00 1970 PST
+(1 row)
+
+\set VERBOSITY default
+-- Now we should be able to run ANALYZE.
+-- To exercise multiple code paths, we use local stats on ft1
+-- and remote-estimate mode on ft2.
+ANALYZE ft1;
+ALTER FOREIGN TABLE ft2 OPTIONS (use_remote_estimate 'true');
+-- ===================================================================
+-- simple queries
+-- ===================================================================
+-- single table without alias
+EXPLAIN (COSTS OFF) SELECT * FROM ft1 ORDER BY c3, c1 OFFSET 100 LIMIT 10;
+     QUERY PLAN      
+---------------------
+ Foreign Scan on ft1
+(1 row)
+
+SELECT * FROM ft1 ORDER BY c3, c1 OFFSET 100 LIMIT 10;
+ c1  | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+-----+----+-------+------------------------------+--------------------------+----+------------+-----
+ 101 |  1 | 00101 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+ 102 |  2 | 00102 | Sat Jan 03 00:00:00 1970 PST | Sat Jan 03 00:00:00 1970 | 2  | 2          | foo
+ 103 |  3 | 00103 | Sun Jan 04 00:00:00 1970 PST | Sun Jan 04 00:00:00 1970 | 3  | 3          | foo
+ 104 |  4 | 00104 | Mon Jan 05 00:00:00 1970 PST | Mon Jan 05 00:00:00 1970 | 4  | 4          | foo
+ 105 |  5 | 00105 | Tue Jan 06 00:00:00 1970 PST | Tue Jan 06 00:00:00 1970 | 5  | 5          | foo
+ 106 |  6 | 00106 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+ 107 |  7 | 00107 | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+ 108 |  8 | 00108 | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+ 109 |  9 | 00109 | Sat Jan 10 00:00:00 1970 PST | Sat Jan 10 00:00:00 1970 | 9  | 9          | foo
+ 110 |  0 | 00110 | Sun Jan 11 00:00:00 1970 PST | Sun Jan 11 00:00:00 1970 | 0  | 0          | foo
+(10 rows)
+
+-- single table with alias - also test that tableoid sort is not pushed to remote side
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 ORDER BY t1.c3, t1.c1, t1.tableoid OFFSET 100 LIMIT 10;
+                                     QUERY PLAN                                      
+-------------------------------------------------------------------------------------
+ Limit
+   Output: c1, c2, c3, c4, c5, c6, c7, c8, tableoid
+   ->  Sort
+         Output: c1, c2, c3, c4, c5, c6, c7, c8, tableoid
+         Sort Key: t1.c3, t1.c1, t1.tableoid
+         ->  Foreign Scan on public.ft1 t1
+               Output: c1, c2, c3, c4, c5, c6, c7, c8, tableoid
+               Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1"
+(8 rows)
+
+SELECT * FROM ft1 t1 ORDER BY t1.c3, t1.c1, t1.tableoid OFFSET 100 LIMIT 10;
+ c1  | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+-----+----+-------+------------------------------+--------------------------+----+------------+-----
+ 101 |  1 | 00101 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+ 102 |  2 | 00102 | Sat Jan 03 00:00:00 1970 PST | Sat Jan 03 00:00:00 1970 | 2  | 2          | foo
+ 103 |  3 | 00103 | Sun Jan 04 00:00:00 1970 PST | Sun Jan 04 00:00:00 1970 | 3  | 3          | foo
+ 104 |  4 | 00104 | Mon Jan 05 00:00:00 1970 PST | Mon Jan 05 00:00:00 1970 | 4  | 4          | foo
+ 105 |  5 | 00105 | Tue Jan 06 00:00:00 1970 PST | Tue Jan 06 00:00:00 1970 | 5  | 5          | foo
+ 106 |  6 | 00106 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+ 107 |  7 | 00107 | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+ 108 |  8 | 00108 | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+ 109 |  9 | 00109 | Sat Jan 10 00:00:00 1970 PST | Sat Jan 10 00:00:00 1970 | 9  | 9          | foo
+ 110 |  0 | 00110 | Sun Jan 11 00:00:00 1970 PST | Sun Jan 11 00:00:00 1970 | 0  | 0          | foo
+(10 rows)
+
+-- whole-row reference
+EXPLAIN (VERBOSE, COSTS OFF) SELECT t1 FROM ft1 t1 ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10;
+                                                                          QUERY PLAN                                                                          
+--------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: t1.*, c3, c1
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" ORDER BY c3 ASC NULLS LAST, "C 1" ASC NULLS LAST LIMIT 10::bigint OFFSET 100::bigint
+(3 rows)
+
+SELECT t1 FROM ft1 t1 ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10;
+                                             t1                                             
+--------------------------------------------------------------------------------------------
+ (101,1,00101,"Fri Jan 02 00:00:00 1970 PST","Fri Jan 02 00:00:00 1970",1,"1         ",foo)
+ (102,2,00102,"Sat Jan 03 00:00:00 1970 PST","Sat Jan 03 00:00:00 1970",2,"2         ",foo)
+ (103,3,00103,"Sun Jan 04 00:00:00 1970 PST","Sun Jan 04 00:00:00 1970",3,"3         ",foo)
+ (104,4,00104,"Mon Jan 05 00:00:00 1970 PST","Mon Jan 05 00:00:00 1970",4,"4         ",foo)
+ (105,5,00105,"Tue Jan 06 00:00:00 1970 PST","Tue Jan 06 00:00:00 1970",5,"5         ",foo)
+ (106,6,00106,"Wed Jan 07 00:00:00 1970 PST","Wed Jan 07 00:00:00 1970",6,"6         ",foo)
+ (107,7,00107,"Thu Jan 08 00:00:00 1970 PST","Thu Jan 08 00:00:00 1970",7,"7         ",foo)
+ (108,8,00108,"Fri Jan 09 00:00:00 1970 PST","Fri Jan 09 00:00:00 1970",8,"8         ",foo)
+ (109,9,00109,"Sat Jan 10 00:00:00 1970 PST","Sat Jan 10 00:00:00 1970",9,"9         ",foo)
+ (110,0,00110,"Sun Jan 11 00:00:00 1970 PST","Sun Jan 11 00:00:00 1970",0,"0         ",foo)
+(10 rows)
+
+-- empty result
+SELECT * FROM ft1 WHERE false;
+ c1 | c2 | c3 | c4 | c5 | c6 | c7 | c8 
+----+----+----+----+----+----+----+----
+(0 rows)
+
+-- with WHERE clause
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE t1.c1 = 101 AND t1.c6 = '1' AND t1.c7 >= '1';
+                                                                   QUERY PLAN                                                                   
+------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE ((c7 >= '1'::bpchar)) AND (("C 1" = 101)) AND ((c6 = '1'::text))
+(3 rows)
+
+SELECT * FROM ft1 t1 WHERE t1.c1 = 101 AND t1.c6 = '1' AND t1.c7 >= '1';
+ c1  | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+-----+----+-------+------------------------------+--------------------------+----+------------+-----
+ 101 |  1 | 00101 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+(1 row)
+
+-- with FOR UPDATE/SHARE
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE c1 = 101 FOR UPDATE;
+                                                QUERY PLAN                                                
+----------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8, t1.*
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 101)) FOR UPDATE
+(3 rows)
+
+SELECT * FROM ft1 t1 WHERE c1 = 101 FOR UPDATE;
+ c1  | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+-----+----+-------+------------------------------+--------------------------+----+------------+-----
+ 101 |  1 | 00101 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+(1 row)
+
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE c1 = 102 FOR SHARE;
+                                               QUERY PLAN                                                
+---------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8, t1.*
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 102)) FOR SHARE
+(3 rows)
+
+SELECT * FROM ft1 t1 WHERE c1 = 102 FOR SHARE;
+ c1  | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+-----+----+-------+------------------------------+--------------------------+----+------------+-----
+ 102 |  2 | 00102 | Sat Jan 03 00:00:00 1970 PST | Sat Jan 03 00:00:00 1970 | 2  | 2          | foo
+(1 row)
+
+-- aggregate
+SELECT COUNT(*) FROM ft1 t1;
+ count 
+-------
+  1000
+(1 row)
+
+-- subquery
+SELECT * FROM ft1 t1 WHERE t1.c3 IN (SELECT c3 FROM ft2 t2 WHERE c1 <= 10) ORDER BY c1;
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+  1 |  1 | 00001 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+  2 |  2 | 00002 | Sat Jan 03 00:00:00 1970 PST | Sat Jan 03 00:00:00 1970 | 2  | 2          | foo
+  3 |  3 | 00003 | Sun Jan 04 00:00:00 1970 PST | Sun Jan 04 00:00:00 1970 | 3  | 3          | foo
+  4 |  4 | 00004 | Mon Jan 05 00:00:00 1970 PST | Mon Jan 05 00:00:00 1970 | 4  | 4          | foo
+  5 |  5 | 00005 | Tue Jan 06 00:00:00 1970 PST | Tue Jan 06 00:00:00 1970 | 5  | 5          | foo
+  6 |  6 | 00006 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+  7 |  7 | 00007 | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+  8 |  8 | 00008 | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+  9 |  9 | 00009 | Sat Jan 10 00:00:00 1970 PST | Sat Jan 10 00:00:00 1970 | 9  | 9          | foo
+ 10 |  0 | 00010 | Sun Jan 11 00:00:00 1970 PST | Sun Jan 11 00:00:00 1970 | 0  | 0          | foo
+(10 rows)
+
+-- subquery+MAX
+SELECT * FROM ft1 t1 WHERE t1.c3 = (SELECT MAX(c3) FROM ft2 t2) ORDER BY c1;
+  c1  | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+------+----+-------+------------------------------+--------------------------+----+------------+-----
+ 1000 |  0 | 01000 | Thu Jan 01 00:00:00 1970 PST | Thu Jan 01 00:00:00 1970 | 0  | 0          | foo
+(1 row)
+
+-- used in CTE
+WITH t1 AS (SELECT * FROM ft1 WHERE c1 <= 10) SELECT t2.c1, t2.c2, t2.c3, t2.c4 FROM t1, ft2 t2 WHERE t1.c1 = t2.c1 ORDER BY t1.c1;
+ c1 | c2 |  c3   |              c4              
+----+----+-------+------------------------------
+  1 |  1 | 00001 | Fri Jan 02 00:00:00 1970 PST
+  2 |  2 | 00002 | Sat Jan 03 00:00:00 1970 PST
+  3 |  3 | 00003 | Sun Jan 04 00:00:00 1970 PST
+  4 |  4 | 00004 | Mon Jan 05 00:00:00 1970 PST
+  5 |  5 | 00005 | Tue Jan 06 00:00:00 1970 PST
+  6 |  6 | 00006 | Wed Jan 07 00:00:00 1970 PST
+  7 |  7 | 00007 | Thu Jan 08 00:00:00 1970 PST
+  8 |  8 | 00008 | Fri Jan 09 00:00:00 1970 PST
+  9 |  9 | 00009 | Sat Jan 10 00:00:00 1970 PST
+ 10 |  0 | 00010 | Sun Jan 11 00:00:00 1970 PST
+(10 rows)
+
+-- fixed values
+SELECT 'fixed', NULL FROM ft1 t1 WHERE c1 = 1;
+ ?column? | ?column? 
+----------+----------
+ fixed    | 
+(1 row)
+
+-- Test forcing the remote server to produce sorted data for a merge join.
+SET enable_hashjoin TO false;
+SET enable_nestloop TO false;
+-- inner join; expressions in the clauses appear in the equivalence class list
+EXPLAIN (VERBOSE, COSTS OFF)
+	SELECT t1.c1, t2."C 1" FROM ft2 t1 JOIN "S 1"."T 1" t2 ON (t1.c1 = t2."C 1") OFFSET 100 LIMIT 10;
+                                      QUERY PLAN                                       
+---------------------------------------------------------------------------------------
+ Limit
+   Output: t1.c1, t2."C 1"
+   ->  Merge Join
+         Output: t1.c1, t2."C 1"
+         Inner Unique: true
+         Merge Cond: (t1.c1 = t2."C 1")
+         ->  Foreign Scan on public.ft2 t1
+               Output: t1.c1
+               Remote SQL: SELECT "C 1" FROM "S 1"."T 1" ORDER BY "C 1" ASC NULLS LAST
+         ->  Index Only Scan using t1_pkey on "S 1"."T 1" t2
+               Output: t2."C 1"
+(11 rows)
+
+SELECT t1.c1, t2."C 1" FROM ft2 t1 JOIN "S 1"."T 1" t2 ON (t1.c1 = t2."C 1") OFFSET 100 LIMIT 10;
+ c1  | C 1 
+-----+-----
+ 101 | 101
+ 102 | 102
+ 103 | 103
+ 104 | 104
+ 105 | 105
+ 106 | 106
+ 107 | 107
+ 108 | 108
+ 109 | 109
+ 110 | 110
+(10 rows)
+
+-- outer join; expressions in the clauses do not appear in equivalence class
+-- list but no output change as compared to the previous query
+EXPLAIN (VERBOSE, COSTS OFF)
+	SELECT t1.c1, t2."C 1" FROM ft2 t1 LEFT JOIN "S 1"."T 1" t2 ON (t1.c1 = t2."C 1") OFFSET 100 LIMIT 10;
+                                      QUERY PLAN                                       
+---------------------------------------------------------------------------------------
+ Limit
+   Output: t1.c1, t2."C 1"
+   ->  Merge Left Join
+         Output: t1.c1, t2."C 1"
+         Inner Unique: true
+         Merge Cond: (t1.c1 = t2."C 1")
+         ->  Foreign Scan on public.ft2 t1
+               Output: t1.c1
+               Remote SQL: SELECT "C 1" FROM "S 1"."T 1" ORDER BY "C 1" ASC NULLS LAST
+         ->  Index Only Scan using t1_pkey on "S 1"."T 1" t2
+               Output: t2."C 1"
+(11 rows)
+
+SELECT t1.c1, t2."C 1" FROM ft2 t1 LEFT JOIN "S 1"."T 1" t2 ON (t1.c1 = t2."C 1") OFFSET 100 LIMIT 10;
+ c1  | C 1 
+-----+-----
+ 101 | 101
+ 102 | 102
+ 103 | 103
+ 104 | 104
+ 105 | 105
+ 106 | 106
+ 107 | 107
+ 108 | 108
+ 109 | 109
+ 110 | 110
+(10 rows)
+
+-- A join between local table and foreign join. ORDER BY clause is added to the
+-- foreign join so that the local table can be joined using merge join strategy.
+EXPLAIN (VERBOSE, COSTS OFF)
+	SELECT t1."C 1" FROM "S 1"."T 1" t1 left join ft1 t2 join ft2 t3 on (t2.c1 = t3.c1) on (t3.c1 = t1."C 1") OFFSET 100 LIMIT 10;
+                                                                       QUERY PLAN                                                                        
+---------------------------------------------------------------------------------------------------------------------------------------------------------
+ Limit
+   Output: t1."C 1"
+   ->  Merge Right Join
+         Output: t1."C 1"
+         Inner Unique: true
+         Merge Cond: (t3.c1 = t1."C 1")
+         ->  Foreign Scan
+               Output: t3.c1
+               Relations: (public.ft1 t2) INNER JOIN (public.ft2 t3)
+               Remote SQL: SELECT r3."C 1" FROM ("S 1"."T 1" r2 INNER JOIN "S 1"."T 1" r3 ON (((r2."C 1" = r3."C 1")))) ORDER BY r2."C 1" ASC NULLS LAST
+         ->  Index Only Scan using t1_pkey on "S 1"."T 1" t1
+               Output: t1."C 1"
+(12 rows)
+
+SELECT t1."C 1" FROM "S 1"."T 1" t1 left join ft1 t2 join ft2 t3 on (t2.c1 = t3.c1) on (t3.c1 = t1."C 1") OFFSET 100 LIMIT 10;
+ C 1 
+-----
+ 101
+ 102
+ 103
+ 104
+ 105
+ 106
+ 107
+ 108
+ 109
+ 110
+(10 rows)
+
+-- Test similar to above, except that the full join prevents any equivalence
+-- classes from being merged. This produces single relation equivalence classes
+-- included in join restrictions.
+EXPLAIN (VERBOSE, COSTS OFF)
+	SELECT t1."C 1", t2.c1, t3.c1 FROM "S 1"."T 1" t1 left join ft1 t2 full join ft2 t3 on (t2.c1 = t3.c1) on (t3.c1 = t1."C 1") OFFSET 100 LIMIT 10;
+                                                                            QUERY PLAN                                                                            
+------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Limit
+   Output: t1."C 1", t2.c1, t3.c1
+   ->  Merge Right Join
+         Output: t1."C 1", t2.c1, t3.c1
+         Inner Unique: true
+         Merge Cond: (t3.c1 = t1."C 1")
+         ->  Foreign Scan
+               Output: t3.c1, t2.c1
+               Relations: (public.ft2 t3) LEFT JOIN (public.ft1 t2)
+               Remote SQL: SELECT r3."C 1", r2."C 1" FROM ("S 1"."T 1" r3 LEFT JOIN "S 1"."T 1" r2 ON (((r2."C 1" = r3."C 1")))) ORDER BY r3."C 1" ASC NULLS LAST
+         ->  Index Only Scan using t1_pkey on "S 1"."T 1" t1
+               Output: t1."C 1"
+(12 rows)
+
+SELECT t1."C 1", t2.c1, t3.c1 FROM "S 1"."T 1" t1 left join ft1 t2 full join ft2 t3 on (t2.c1 = t3.c1) on (t3.c1 = t1."C 1") OFFSET 100 LIMIT 10;
+ C 1 | c1  | c1  
+-----+-----+-----
+ 101 | 101 | 101
+ 102 | 102 | 102
+ 103 | 103 | 103
+ 104 | 104 | 104
+ 105 | 105 | 105
+ 106 | 106 | 106
+ 107 | 107 | 107
+ 108 | 108 | 108
+ 109 | 109 | 109
+ 110 | 110 | 110
+(10 rows)
+
+-- Test similar to above with all full outer joins
+EXPLAIN (VERBOSE, COSTS OFF)
+	SELECT t1."C 1", t2.c1, t3.c1 FROM "S 1"."T 1" t1 full join ft1 t2 full join ft2 t3 on (t2.c1 = t3.c1) on (t3.c1 = t1."C 1") OFFSET 100 LIMIT 10;
+                                                                            QUERY PLAN                                                                            
+------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Limit
+   Output: t1."C 1", t2.c1, t3.c1
+   ->  Merge Full Join
+         Output: t1."C 1", t2.c1, t3.c1
+         Inner Unique: true
+         Merge Cond: (t3.c1 = t1."C 1")
+         ->  Foreign Scan
+               Output: t2.c1, t3.c1
+               Relations: (public.ft1 t2) FULL JOIN (public.ft2 t3)
+               Remote SQL: SELECT r2."C 1", r3."C 1" FROM ("S 1"."T 1" r2 FULL JOIN "S 1"."T 1" r3 ON (((r2."C 1" = r3."C 1")))) ORDER BY r3."C 1" ASC NULLS LAST
+         ->  Index Only Scan using t1_pkey on "S 1"."T 1" t1
+               Output: t1."C 1"
+(12 rows)
+
+SELECT t1."C 1", t2.c1, t3.c1 FROM "S 1"."T 1" t1 full join ft1 t2 full join ft2 t3 on (t2.c1 = t3.c1) on (t3.c1 = t1."C 1") OFFSET 100 LIMIT 10;
+ C 1 | c1  | c1  
+-----+-----+-----
+ 101 | 101 | 101
+ 102 | 102 | 102
+ 103 | 103 | 103
+ 104 | 104 | 104
+ 105 | 105 | 105
+ 106 | 106 | 106
+ 107 | 107 | 107
+ 108 | 108 | 108
+ 109 | 109 | 109
+ 110 | 110 | 110
+(10 rows)
+
+RESET enable_hashjoin;
+RESET enable_nestloop;
+-- ===================================================================
+-- WHERE with remotely-executable conditions
+-- ===================================================================
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE t1.c1 = 1;         -- Var, OpExpr(b), Const
+                                         QUERY PLAN                                          
+---------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 1))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE t1.c1 = 100 AND t1.c2 = 0; -- BoolExpr
+                                                  QUERY PLAN                                                  
+--------------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 100)) AND ((c2 = 0))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE c1 IS NULL;        -- NullTest
+                                           QUERY PLAN                                            
+-------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" IS NULL))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE c1 IS NOT NULL;    -- NullTest
+                                             QUERY PLAN                                              
+-----------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" IS NOT NULL))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE round(abs(c1), 0) = 1; -- FuncExpr
+                                                     QUERY PLAN                                                      
+---------------------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE ((round(abs("C 1"), 0) = 1::numeric))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE c1 = -c1;          -- OpExpr(l)
+                                             QUERY PLAN                                              
+-----------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = (- "C 1")))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE 1 = c1!;           -- OpExpr(r)
+                                                QUERY PLAN                                                
+----------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE ((1::numeric = ("C 1" !)))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE (c1 IS NOT NULL) IS DISTINCT FROM (c1 IS NOT NULL); -- DistinctExpr
+                                                                 QUERY PLAN                                                                 
+--------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE ((("C 1" IS NOT NULL) IS DISTINCT FROM ("C 1" IS NOT NULL)))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE c1 = ANY(ARRAY[c2, 1, c1 + 0]); -- ScalarArrayOpExpr
+                                                        QUERY PLAN                                                         
+---------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = ANY (ARRAY[c2, 1, ("C 1" + 0)])))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE c1 = (ARRAY[c1,c2,3])[1]; -- ArrayRef
+                                                      QUERY PLAN                                                      
+----------------------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = ((ARRAY["C 1", c2, 3])[1])))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE c6 = E'foo''s\\bar';  -- check special chars
+                                                 QUERY PLAN                                                  
+-------------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE ((c6 = E'foo''s\\bar'::text))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 t1 WHERE c8 = 'foo';  -- can't be sent to remote
+                               QUERY PLAN                                
+-------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Filter: (t1.c8 = 'foo'::user_enum)
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1"
+(4 rows)
+
+-- parameterized remote path for foreign table
+EXPLAIN (VERBOSE, COSTS OFF)
+  SELECT * FROM "S 1"."T 1" a, ft2 b WHERE a."C 1" = 47 AND b.c1 = a.c2;
+                                                 QUERY PLAN                                                  
+-------------------------------------------------------------------------------------------------------------
+ Nested Loop
+   Output: a."C 1", a.c2, a.c3, a.c4, a.c5, a.c6, a.c7, a.c8, b.c1, b.c2, b.c3, b.c4, b.c5, b.c6, b.c7, b.c8
+   ->  Index Scan using t1_pkey on "S 1"."T 1" a
+         Output: a."C 1", a.c2, a.c3, a.c4, a.c5, a.c6, a.c7, a.c8
+         Index Cond: (a."C 1" = 47)
+   ->  Foreign Scan on public.ft2 b
+         Output: b.c1, b.c2, b.c3, b.c4, b.c5, b.c6, b.c7, b.c8
+         Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (($1::integer = "C 1"))
+(8 rows)
+
+SELECT * FROM ft2 a, ft2 b WHERE a.c1 = 47 AND b.c1 = a.c2;
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  | c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----+----+----+-------+------------------------------+--------------------------+----+------------+-----
+ 47 |  7 | 00047 | Tue Feb 17 00:00:00 1970 PST | Tue Feb 17 00:00:00 1970 | 7  | 7          | foo |  7 |  7 | 00007 | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+(1 row)
+
+-- check both safe and unsafe join conditions
+EXPLAIN (VERBOSE, COSTS OFF)
+  SELECT * FROM ft2 a, ft2 b
+  WHERE a.c2 = 6 AND b.c1 = a.c1 AND a.c8 = 'foo' AND b.c7 = upper(a.c7);
+                                                 QUERY PLAN                                                  
+-------------------------------------------------------------------------------------------------------------
+ Nested Loop
+   Output: a.c1, a.c2, a.c3, a.c4, a.c5, a.c6, a.c7, a.c8, b.c1, b.c2, b.c3, b.c4, b.c5, b.c6, b.c7, b.c8
+   ->  Foreign Scan on public.ft2 a
+         Output: a.c1, a.c2, a.c3, a.c4, a.c5, a.c6, a.c7, a.c8
+         Filter: (a.c8 = 'foo'::user_enum)
+         Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE ((c2 = 6))
+   ->  Foreign Scan on public.ft2 b
+         Output: b.c1, b.c2, b.c3, b.c4, b.c5, b.c6, b.c7, b.c8
+         Filter: (upper((a.c7)::text) = (b.c7)::text)
+         Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (($1::integer = "C 1"))
+(10 rows)
+
+SELECT * FROM ft2 a, ft2 b
+WHERE a.c2 = 6 AND b.c1 = a.c1 AND a.c8 = 'foo' AND b.c7 = upper(a.c7);
+ c1  | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  | c1  | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+-----+----+-------+------------------------------+--------------------------+----+------------+-----+-----+----+-------+------------------------------+--------------------------+----+------------+-----
+   6 |  6 | 00006 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo |   6 |  6 | 00006 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+  16 |  6 | 00016 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo |  16 |  6 | 00016 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo
+  26 |  6 | 00026 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo |  26 |  6 | 00026 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo
+  36 |  6 | 00036 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo |  36 |  6 | 00036 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo
+  46 |  6 | 00046 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo |  46 |  6 | 00046 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo
+  56 |  6 | 00056 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo |  56 |  6 | 00056 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo
+  66 |  6 | 00066 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo |  66 |  6 | 00066 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo
+  76 |  6 | 00076 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo |  76 |  6 | 00076 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo
+  86 |  6 | 00086 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo |  86 |  6 | 00086 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo
+  96 |  6 | 00096 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo |  96 |  6 | 00096 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo
+ 106 |  6 | 00106 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo | 106 |  6 | 00106 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+ 116 |  6 | 00116 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo | 116 |  6 | 00116 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo
+ 126 |  6 | 00126 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo | 126 |  6 | 00126 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo
+ 136 |  6 | 00136 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo | 136 |  6 | 00136 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo
+ 146 |  6 | 00146 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo | 146 |  6 | 00146 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo
+ 156 |  6 | 00156 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo | 156 |  6 | 00156 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo
+ 166 |  6 | 00166 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo | 166 |  6 | 00166 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo
+ 176 |  6 | 00176 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo | 176 |  6 | 00176 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo
+ 186 |  6 | 00186 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo | 186 |  6 | 00186 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo
+ 196 |  6 | 00196 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo | 196 |  6 | 00196 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo
+ 206 |  6 | 00206 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo | 206 |  6 | 00206 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+ 216 |  6 | 00216 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo | 216 |  6 | 00216 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo
+ 226 |  6 | 00226 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo | 226 |  6 | 00226 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo
+ 236 |  6 | 00236 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo | 236 |  6 | 00236 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo
+ 246 |  6 | 00246 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo | 246 |  6 | 00246 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo
+ 256 |  6 | 00256 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo | 256 |  6 | 00256 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo
+ 266 |  6 | 00266 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo | 266 |  6 | 00266 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo
+ 276 |  6 | 00276 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo | 276 |  6 | 00276 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo
+ 286 |  6 | 00286 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo | 286 |  6 | 00286 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo
+ 296 |  6 | 00296 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo | 296 |  6 | 00296 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo
+ 306 |  6 | 00306 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo | 306 |  6 | 00306 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+ 316 |  6 | 00316 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo | 316 |  6 | 00316 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo
+ 326 |  6 | 00326 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo | 326 |  6 | 00326 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo
+ 336 |  6 | 00336 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo | 336 |  6 | 00336 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo
+ 346 |  6 | 00346 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo | 346 |  6 | 00346 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo
+ 356 |  6 | 00356 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo | 356 |  6 | 00356 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo
+ 366 |  6 | 00366 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo | 366 |  6 | 00366 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo
+ 376 |  6 | 00376 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo | 376 |  6 | 00376 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo
+ 386 |  6 | 00386 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo | 386 |  6 | 00386 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo
+ 396 |  6 | 00396 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo | 396 |  6 | 00396 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo
+ 406 |  6 | 00406 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo | 406 |  6 | 00406 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+ 416 |  6 | 00416 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo | 416 |  6 | 00416 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo
+ 426 |  6 | 00426 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo | 426 |  6 | 00426 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo
+ 436 |  6 | 00436 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo | 436 |  6 | 00436 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo
+ 446 |  6 | 00446 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo | 446 |  6 | 00446 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo
+ 456 |  6 | 00456 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo | 456 |  6 | 00456 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo
+ 466 |  6 | 00466 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo | 466 |  6 | 00466 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo
+ 476 |  6 | 00476 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo | 476 |  6 | 00476 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo
+ 486 |  6 | 00486 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo | 486 |  6 | 00486 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo
+ 496 |  6 | 00496 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo | 496 |  6 | 00496 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo
+ 506 |  6 | 00506 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo | 506 |  6 | 00506 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+ 516 |  6 | 00516 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo | 516 |  6 | 00516 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo
+ 526 |  6 | 00526 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo | 526 |  6 | 00526 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo
+ 536 |  6 | 00536 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo | 536 |  6 | 00536 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo
+ 546 |  6 | 00546 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo | 546 |  6 | 00546 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo
+ 556 |  6 | 00556 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo | 556 |  6 | 00556 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo
+ 566 |  6 | 00566 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo | 566 |  6 | 00566 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo
+ 576 |  6 | 00576 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo | 576 |  6 | 00576 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo
+ 586 |  6 | 00586 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo | 586 |  6 | 00586 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo
+ 596 |  6 | 00596 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo | 596 |  6 | 00596 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo
+ 606 |  6 | 00606 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo | 606 |  6 | 00606 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+ 616 |  6 | 00616 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo | 616 |  6 | 00616 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo
+ 626 |  6 | 00626 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo | 626 |  6 | 00626 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo
+ 636 |  6 | 00636 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo | 636 |  6 | 00636 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo
+ 646 |  6 | 00646 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo | 646 |  6 | 00646 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo
+ 656 |  6 | 00656 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo | 656 |  6 | 00656 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo
+ 666 |  6 | 00666 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo | 666 |  6 | 00666 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo
+ 676 |  6 | 00676 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo | 676 |  6 | 00676 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo
+ 686 |  6 | 00686 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo | 686 |  6 | 00686 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo
+ 696 |  6 | 00696 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo | 696 |  6 | 00696 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo
+ 706 |  6 | 00706 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo | 706 |  6 | 00706 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+ 716 |  6 | 00716 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo | 716 |  6 | 00716 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo
+ 726 |  6 | 00726 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo | 726 |  6 | 00726 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo
+ 736 |  6 | 00736 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo | 736 |  6 | 00736 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo
+ 746 |  6 | 00746 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo | 746 |  6 | 00746 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo
+ 756 |  6 | 00756 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo | 756 |  6 | 00756 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo
+ 766 |  6 | 00766 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo | 766 |  6 | 00766 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo
+ 776 |  6 | 00776 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo | 776 |  6 | 00776 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo
+ 786 |  6 | 00786 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo | 786 |  6 | 00786 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo
+ 796 |  6 | 00796 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo | 796 |  6 | 00796 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo
+ 806 |  6 | 00806 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo | 806 |  6 | 00806 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+ 816 |  6 | 00816 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo | 816 |  6 | 00816 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo
+ 826 |  6 | 00826 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo | 826 |  6 | 00826 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo
+ 836 |  6 | 00836 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo | 836 |  6 | 00836 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo
+ 846 |  6 | 00846 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo | 846 |  6 | 00846 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo
+ 856 |  6 | 00856 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo | 856 |  6 | 00856 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo
+ 866 |  6 | 00866 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo | 866 |  6 | 00866 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo
+ 876 |  6 | 00876 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo | 876 |  6 | 00876 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo
+ 886 |  6 | 00886 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo | 886 |  6 | 00886 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo
+ 896 |  6 | 00896 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo | 896 |  6 | 00896 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo
+ 906 |  6 | 00906 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo | 906 |  6 | 00906 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+ 916 |  6 | 00916 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo | 916 |  6 | 00916 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo
+ 926 |  6 | 00926 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo | 926 |  6 | 00926 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo
+ 936 |  6 | 00936 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo | 936 |  6 | 00936 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo
+ 946 |  6 | 00946 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo | 946 |  6 | 00946 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo
+ 956 |  6 | 00956 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo | 956 |  6 | 00956 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo
+ 966 |  6 | 00966 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo | 966 |  6 | 00966 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo
+ 976 |  6 | 00976 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo | 976 |  6 | 00976 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo
+ 986 |  6 | 00986 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo | 986 |  6 | 00986 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo
+ 996 |  6 | 00996 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo | 996 |  6 | 00996 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo
+(100 rows)
+
+-- bug before 9.3.5 due to sloppy handling of remote-estimate parameters
+SELECT * FROM ft1 WHERE c1 = ANY (ARRAY(SELECT c1 FROM ft2 WHERE c1 < 5));
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+  1 |  1 | 00001 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+  2 |  2 | 00002 | Sat Jan 03 00:00:00 1970 PST | Sat Jan 03 00:00:00 1970 | 2  | 2          | foo
+  3 |  3 | 00003 | Sun Jan 04 00:00:00 1970 PST | Sun Jan 04 00:00:00 1970 | 3  | 3          | foo
+  4 |  4 | 00004 | Mon Jan 05 00:00:00 1970 PST | Mon Jan 05 00:00:00 1970 | 4  | 4          | foo
+(4 rows)
+
+SELECT * FROM ft2 WHERE c1 = ANY (ARRAY(SELECT c1 FROM ft1 WHERE c1 < 5));
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+  1 |  1 | 00001 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+  2 |  2 | 00002 | Sat Jan 03 00:00:00 1970 PST | Sat Jan 03 00:00:00 1970 | 2  | 2          | foo
+  3 |  3 | 00003 | Sun Jan 04 00:00:00 1970 PST | Sun Jan 04 00:00:00 1970 | 3  | 3          | foo
+  4 |  4 | 00004 | Mon Jan 05 00:00:00 1970 PST | Mon Jan 05 00:00:00 1970 | 4  | 4          | foo
+(4 rows)
+
+-- we should not push order by clause with volatile expressions or unsafe
+-- collations
+EXPLAIN (VERBOSE, COSTS OFF)
+	SELECT * FROM ft2 ORDER BY ft2.c1, random();
+                                  QUERY PLAN                                   
+-------------------------------------------------------------------------------
+ Sort
+   Output: c1, c2, c3, c4, c5, c6, c7, c8, (random())
+   Sort Key: ft2.c1, (random())
+   ->  Foreign Scan on public.ft2
+         Output: c1, c2, c3, c4, c5, c6, c7, c8, random()
+         Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1"
+(6 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+	SELECT * FROM ft2 ORDER BY ft2.c1, ft2.c3 collate "C";
+                                  QUERY PLAN                                   
+-------------------------------------------------------------------------------
+ Sort
+   Output: c1, c2, c3, c4, c5, c6, c7, c8, ((c3)::text)
+   Sort Key: ft2.c1, ft2.c3 COLLATE "C"
+   ->  Foreign Scan on public.ft2
+         Output: c1, c2, c3, c4, c5, c6, c7, c8, c3
+         Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1"
+(6 rows)
+
+-- user-defined operator/function
+CREATE FUNCTION postgres_fdw_abs(int) RETURNS int AS $$
+BEGIN
+RETURN abs($1);
+END
+$$ LANGUAGE plpgsql IMMUTABLE;
+CREATE OPERATOR === (
+    LEFTARG = int,
+    RIGHTARG = int,
+    PROCEDURE = int4eq,
+    COMMUTATOR = ===
+);
+-- built-in operators and functions can be shipped for remote execution
+EXPLAIN (VERBOSE, COSTS OFF)
+  SELECT count(c3) FROM ft1 t1 WHERE t1.c1 = abs(t1.c2);
+                                QUERY PLAN                                 
+---------------------------------------------------------------------------
+ Foreign Scan
+   Output: (count(c3))
+   Relations: Aggregate on (public.ft1 t1)
+   Remote SQL: SELECT count(c3) FROM "S 1"."T 1" WHERE (("C 1" = abs(c2)))
+(4 rows)
+
+SELECT count(c3) FROM ft1 t1 WHERE t1.c1 = abs(t1.c2);
+ count 
+-------
+     9
+(1 row)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+  SELECT count(c3) FROM ft1 t1 WHERE t1.c1 = t1.c2;
+                              QUERY PLAN                              
+----------------------------------------------------------------------
+ Foreign Scan
+   Output: (count(c3))
+   Relations: Aggregate on (public.ft1 t1)
+   Remote SQL: SELECT count(c3) FROM "S 1"."T 1" WHERE (("C 1" = c2))
+(4 rows)
+
+SELECT count(c3) FROM ft1 t1 WHERE t1.c1 = t1.c2;
+ count 
+-------
+     9
+(1 row)
+
+-- by default, user-defined ones cannot
+EXPLAIN (VERBOSE, COSTS OFF)
+  SELECT count(c3) FROM ft1 t1 WHERE t1.c1 = postgres_fdw_abs(t1.c2);
+                        QUERY PLAN                         
+-----------------------------------------------------------
+ Aggregate
+   Output: count(c3)
+   ->  Foreign Scan on public.ft1 t1
+         Output: c3
+         Filter: (t1.c1 = postgres_fdw_abs(t1.c2))
+         Remote SQL: SELECT "C 1", c2, c3 FROM "S 1"."T 1"
+(6 rows)
+
+SELECT count(c3) FROM ft1 t1 WHERE t1.c1 = postgres_fdw_abs(t1.c2);
+ count 
+-------
+     9
+(1 row)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+  SELECT count(c3) FROM ft1 t1 WHERE t1.c1 === t1.c2;
+                        QUERY PLAN                         
+-----------------------------------------------------------
+ Aggregate
+   Output: count(c3)
+   ->  Foreign Scan on public.ft1 t1
+         Output: c3
+         Filter: (t1.c1 === t1.c2)
+         Remote SQL: SELECT "C 1", c2, c3 FROM "S 1"."T 1"
+(6 rows)
+
+SELECT count(c3) FROM ft1 t1 WHERE t1.c1 === t1.c2;
+ count 
+-------
+     9
+(1 row)
+
+-- ORDER BY can be shipped, though
+EXPLAIN (VERBOSE, COSTS OFF)
+  SELECT * FROM ft1 t1 WHERE t1.c1 === t1.c2 order by t1.c2 limit 1;
+                                                QUERY PLAN                                                
+----------------------------------------------------------------------------------------------------------
+ Limit
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   ->  Foreign Scan on public.ft1 t1
+         Output: c1, c2, c3, c4, c5, c6, c7, c8
+         Filter: (t1.c1 === t1.c2)
+         Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" ORDER BY c2 ASC NULLS LAST
+(6 rows)
+
+SELECT * FROM ft1 t1 WHERE t1.c1 === t1.c2 order by t1.c2 limit 1;
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+  1 |  1 | 00001 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+(1 row)
+
+-- but let's put them in an extension ...
+ALTER EXTENSION postgres_fdw ADD FUNCTION postgres_fdw_abs(int);
+ALTER EXTENSION postgres_fdw ADD OPERATOR === (int, int);
+ALTER SERVER loopback OPTIONS (ADD extensions 'postgres_fdw');
+-- ... now they can be shipped
+EXPLAIN (VERBOSE, COSTS OFF)
+  SELECT count(c3) FROM ft1 t1 WHERE t1.c1 = postgres_fdw_abs(t1.c2);
+                                          QUERY PLAN                                           
+-----------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (count(c3))
+   Relations: Aggregate on (public.ft1 t1)
+   Remote SQL: SELECT count(c3) FROM "S 1"."T 1" WHERE (("C 1" = public.postgres_fdw_abs(c2)))
+(4 rows)
+
+SELECT count(c3) FROM ft1 t1 WHERE t1.c1 = postgres_fdw_abs(t1.c2);
+ count 
+-------
+     9
+(1 row)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+  SELECT count(c3) FROM ft1 t1 WHERE t1.c1 === t1.c2;
+                                       QUERY PLAN                                        
+-----------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (count(c3))
+   Relations: Aggregate on (public.ft1 t1)
+   Remote SQL: SELECT count(c3) FROM "S 1"."T 1" WHERE (("C 1" OPERATOR(public.===) c2))
+(4 rows)
+
+SELECT count(c3) FROM ft1 t1 WHERE t1.c1 === t1.c2;
+ count 
+-------
+     9
+(1 row)
+
+-- and both ORDER BY and LIMIT can be shipped
+EXPLAIN (VERBOSE, COSTS OFF)
+  SELECT * FROM ft1 t1 WHERE t1.c1 === t1.c2 order by t1.c2 limit 1;
+                                                                         QUERY PLAN                                                                         
+------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" OPERATOR(public.===) c2)) ORDER BY c2 ASC NULLS LAST LIMIT 1::bigint
+(3 rows)
+
+SELECT * FROM ft1 t1 WHERE t1.c1 === t1.c2 order by t1.c2 limit 1;
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+  1 |  1 | 00001 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+(1 row)
+
+-- ===================================================================
+-- JOIN queries
+-- ===================================================================
+-- Analyze ft4 and ft5 so that we have better statistics. These tables do not
+-- have use_remote_estimate set.
+ANALYZE ft4;
+ANALYZE ft5;
+-- join two tables
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10;
+                                                                                                       QUERY PLAN                                                                                                       
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c1, t1.c3
+   Relations: (public.ft1 t1) INNER JOIN (public.ft2 t2)
+   Remote SQL: SELECT r1."C 1", r2."C 1", r1.c3 FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")))) ORDER BY r1.c3 ASC NULLS LAST, r1."C 1" ASC NULLS LAST LIMIT 10::bigint OFFSET 100::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10;
+ c1  | c1  
+-----+-----
+ 101 | 101
+ 102 | 102
+ 103 | 103
+ 104 | 104
+ 105 | 105
+ 106 | 106
+ 107 | 107
+ 108 | 108
+ 109 | 109
+ 110 | 110
+(10 rows)
+
+-- join three tables
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2, t3.c3 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) JOIN ft4 t3 ON (t3.c1 = t1.c1) ORDER BY t1.c3, t1.c1 OFFSET 10 LIMIT 10;
+                                                                                                                                   QUERY PLAN                                                                                                                                    
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c2, t3.c3, t1.c3
+   Relations: ((public.ft1 t1) INNER JOIN (public.ft2 t2)) INNER JOIN (public.ft4 t3)
+   Remote SQL: SELECT r1."C 1", r2.c2, r4.c3, r1.c3 FROM (("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")))) INNER JOIN "S 1"."T 3" r4 ON (((r1."C 1" = r4.c1)))) ORDER BY r1.c3 ASC NULLS LAST, r1."C 1" ASC NULLS LAST LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c2, t3.c3 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) JOIN ft4 t3 ON (t3.c1 = t1.c1) ORDER BY t1.c3, t1.c1 OFFSET 10 LIMIT 10;
+ c1 | c2 |   c3   
+----+----+--------
+ 22 |  2 | AAA022
+ 24 |  4 | AAA024
+ 26 |  6 | AAA026
+ 28 |  8 | AAA028
+ 30 |  0 | AAA030
+ 32 |  2 | AAA032
+ 34 |  4 | AAA034
+ 36 |  6 | AAA036
+ 38 |  8 | AAA038
+ 40 |  0 | AAA040
+(10 rows)
+
+-- left outer join
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft4 t1 LEFT JOIN ft5 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 10 LIMIT 10;
+                                                                                           QUERY PLAN                                                                                           
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c1
+   Relations: (public.ft4 t1) LEFT JOIN (public.ft5 t2)
+   Remote SQL: SELECT r1.c1, r2.c1 FROM ("S 1"."T 3" r1 LEFT JOIN "S 1"."T 4" r2 ON (((r1.c1 = r2.c1)))) ORDER BY r1.c1 ASC NULLS LAST, r2.c1 ASC NULLS LAST LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c1 FROM ft4 t1 LEFT JOIN ft5 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 10 LIMIT 10;
+ c1 | c1 
+----+----
+ 22 |   
+ 24 | 24
+ 26 |   
+ 28 |   
+ 30 | 30
+ 32 |   
+ 34 |   
+ 36 | 36
+ 38 |   
+ 40 |   
+(10 rows)
+
+-- left outer join three tables
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 LEFT JOIN ft2 t2 ON (t1.c1 = t2.c1) LEFT JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+                                                                                                   QUERY PLAN                                                                                                    
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c2, t3.c3
+   Relations: ((public.ft2 t1) LEFT JOIN (public.ft2 t2)) LEFT JOIN (public.ft4 t3)
+   Remote SQL: SELECT r1."C 1", r2.c2, r4.c3 FROM (("S 1"."T 1" r1 LEFT JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")))) LEFT JOIN "S 1"."T 3" r4 ON (((r2."C 1" = r4.c1)))) LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 LEFT JOIN ft2 t2 ON (t1.c1 = t2.c1) LEFT JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+ c1 | c2 |   c3   
+----+----+--------
+ 11 |  1 | 
+ 12 |  2 | AAA012
+ 13 |  3 | 
+ 14 |  4 | AAA014
+ 15 |  5 | 
+ 16 |  6 | AAA016
+ 17 |  7 | 
+ 18 |  8 | AAA018
+ 19 |  9 | 
+ 20 |  0 | AAA020
+(10 rows)
+
+-- left outer join + placement of clauses.
+-- clauses within the nullable side are not pulled up, but top level clause on
+-- non-nullable side is pushed into non-nullable side
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t1.c2, t2.c1, t2.c2 FROM ft4 t1 LEFT JOIN (SELECT * FROM ft5 WHERE c1 < 10) t2 ON (t1.c1 = t2.c1) WHERE t1.c1 < 10;
+                                                                          QUERY PLAN                                                                           
+---------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t1.c2, ft5.c1, ft5.c2
+   Relations: (public.ft4 t1) LEFT JOIN (public.ft5)
+   Remote SQL: SELECT r1.c1, r1.c2, r4.c1, r4.c2 FROM ("S 1"."T 3" r1 LEFT JOIN "S 1"."T 4" r4 ON (((r1.c1 = r4.c1)) AND ((r4.c1 < 10)))) WHERE ((r1.c1 < 10))
+(4 rows)
+
+SELECT t1.c1, t1.c2, t2.c1, t2.c2 FROM ft4 t1 LEFT JOIN (SELECT * FROM ft5 WHERE c1 < 10) t2 ON (t1.c1 = t2.c1) WHERE t1.c1 < 10;
+ c1 | c2 | c1 | c2 
+----+----+----+----
+  2 |  3 |    |   
+  4 |  5 |    |   
+  6 |  7 |  6 |  7
+  8 |  9 |    |   
+(4 rows)
+
+-- clauses within the nullable side are not pulled up, but the top level clause
+-- on nullable side is not pushed down into nullable side
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t1.c2, t2.c1, t2.c2 FROM ft4 t1 LEFT JOIN (SELECT * FROM ft5 WHERE c1 < 10) t2 ON (t1.c1 = t2.c1)
+			WHERE (t2.c1 < 10 OR t2.c1 IS NULL) AND t1.c1 < 10;
+                                                                                              QUERY PLAN                                                                                               
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t1.c2, ft5.c1, ft5.c2
+   Relations: (public.ft4 t1) LEFT JOIN (public.ft5)
+   Remote SQL: SELECT r1.c1, r1.c2, r4.c1, r4.c2 FROM ("S 1"."T 3" r1 LEFT JOIN "S 1"."T 4" r4 ON (((r1.c1 = r4.c1)) AND ((r4.c1 < 10)))) WHERE (((r4.c1 < 10) OR (r4.c1 IS NULL))) AND ((r1.c1 < 10))
+(4 rows)
+
+SELECT t1.c1, t1.c2, t2.c1, t2.c2 FROM ft4 t1 LEFT JOIN (SELECT * FROM ft5 WHERE c1 < 10) t2 ON (t1.c1 = t2.c1)
+			WHERE (t2.c1 < 10 OR t2.c1 IS NULL) AND t1.c1 < 10;
+ c1 | c2 | c1 | c2 
+----+----+----+----
+  2 |  3 |    |   
+  4 |  5 |    |   
+  6 |  7 |  6 |  7
+  8 |  9 |    |   
+(4 rows)
+
+-- right outer join
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft5 t1 RIGHT JOIN ft4 t2 ON (t1.c1 = t2.c1) ORDER BY t2.c1, t1.c1 OFFSET 10 LIMIT 10;
+                                                                                           QUERY PLAN                                                                                           
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c1
+   Relations: (public.ft4 t2) LEFT JOIN (public.ft5 t1)
+   Remote SQL: SELECT r1.c1, r2.c1 FROM ("S 1"."T 3" r2 LEFT JOIN "S 1"."T 4" r1 ON (((r1.c1 = r2.c1)))) ORDER BY r2.c1 ASC NULLS LAST, r1.c1 ASC NULLS LAST LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c1 FROM ft5 t1 RIGHT JOIN ft4 t2 ON (t1.c1 = t2.c1) ORDER BY t2.c1, t1.c1 OFFSET 10 LIMIT 10;
+ c1 | c1 
+----+----
+    | 22
+ 24 | 24
+    | 26
+    | 28
+ 30 | 30
+    | 32
+    | 34
+ 36 | 36
+    | 38
+    | 40
+(10 rows)
+
+-- right outer join three tables
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 RIGHT JOIN ft2 t2 ON (t1.c1 = t2.c1) RIGHT JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+                                                                                                   QUERY PLAN                                                                                                    
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c2, t3.c3
+   Relations: ((public.ft4 t3) LEFT JOIN (public.ft2 t2)) LEFT JOIN (public.ft2 t1)
+   Remote SQL: SELECT r1."C 1", r2.c2, r4.c3 FROM (("S 1"."T 3" r4 LEFT JOIN "S 1"."T 1" r2 ON (((r2."C 1" = r4.c1)))) LEFT JOIN "S 1"."T 1" r1 ON (((r1."C 1" = r2."C 1")))) LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 RIGHT JOIN ft2 t2 ON (t1.c1 = t2.c1) RIGHT JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+ c1 | c2 |   c3   
+----+----+--------
+ 22 |  2 | AAA022
+ 24 |  4 | AAA024
+ 26 |  6 | AAA026
+ 28 |  8 | AAA028
+ 30 |  0 | AAA030
+ 32 |  2 | AAA032
+ 34 |  4 | AAA034
+ 36 |  6 | AAA036
+ 38 |  8 | AAA038
+ 40 |  0 | AAA040
+(10 rows)
+
+-- full outer join
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft4 t1 FULL JOIN ft5 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 45 LIMIT 10;
+                                                                                           QUERY PLAN                                                                                           
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c1
+   Relations: (public.ft4 t1) FULL JOIN (public.ft5 t2)
+   Remote SQL: SELECT r1.c1, r2.c1 FROM ("S 1"."T 3" r1 FULL JOIN "S 1"."T 4" r2 ON (((r1.c1 = r2.c1)))) ORDER BY r1.c1 ASC NULLS LAST, r2.c1 ASC NULLS LAST LIMIT 10::bigint OFFSET 45::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c1 FROM ft4 t1 FULL JOIN ft5 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 45 LIMIT 10;
+ c1  | c1 
+-----+----
+  92 |   
+  94 |   
+  96 | 96
+  98 |   
+ 100 |   
+     |  3
+     |  9
+     | 15
+     | 21
+     | 27
+(10 rows)
+
+-- full outer join with restrictions on the joining relations
+-- a. the joining relations are both base relations
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM (SELECT c1 FROM ft4 WHERE c1 between 50 and 60) t1 FULL JOIN (SELECT c1 FROM ft5 WHERE c1 between 50 and 60) t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1;
+                                                                                                                                  QUERY PLAN                                                                                                                                   
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: ft4.c1, ft5.c1
+   Relations: (public.ft4) FULL JOIN (public.ft5)
+   Remote SQL: SELECT s4.c1, s5.c1 FROM ((SELECT c1 FROM "S 1"."T 3" WHERE ((c1 >= 50)) AND ((c1 <= 60))) s4(c1) FULL JOIN (SELECT c1 FROM "S 1"."T 4" WHERE ((c1 >= 50)) AND ((c1 <= 60))) s5(c1) ON (((s4.c1 = s5.c1)))) ORDER BY s4.c1 ASC NULLS LAST, s5.c1 ASC NULLS LAST
+(4 rows)
+
+SELECT t1.c1, t2.c1 FROM (SELECT c1 FROM ft4 WHERE c1 between 50 and 60) t1 FULL JOIN (SELECT c1 FROM ft5 WHERE c1 between 50 and 60) t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1;
+ c1 | c1 
+----+----
+ 50 |   
+ 52 |   
+ 54 | 54
+ 56 |   
+ 58 |   
+ 60 | 60
+    | 51
+    | 57
+(8 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT 1 FROM (SELECT c1 FROM ft4 WHERE c1 between 50 and 60) t1 FULL JOIN (SELECT c1 FROM ft5 WHERE c1 between 50 and 60) t2 ON (TRUE) OFFSET 10 LIMIT 10;
+                                                                                                             QUERY PLAN                                                                                                              
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: 1
+   Relations: (public.ft4) FULL JOIN (public.ft5)
+   Remote SQL: SELECT NULL FROM ((SELECT NULL FROM "S 1"."T 3" WHERE ((c1 >= 50)) AND ((c1 <= 60))) s4 FULL JOIN (SELECT NULL FROM "S 1"."T 4" WHERE ((c1 >= 50)) AND ((c1 <= 60))) s5 ON (TRUE)) LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT 1 FROM (SELECT c1 FROM ft4 WHERE c1 between 50 and 60) t1 FULL JOIN (SELECT c1 FROM ft5 WHERE c1 between 50 and 60) t2 ON (TRUE) OFFSET 10 LIMIT 10;
+ ?column? 
+----------
+        1
+        1
+        1
+        1
+        1
+        1
+        1
+        1
+        1
+        1
+(10 rows)
+
+-- b. one of the joining relations is a base relation and the other is a join
+-- relation
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, ss.a, ss.b FROM (SELECT c1 FROM ft4 WHERE c1 between 50 and 60) t1 FULL JOIN (SELECT t2.c1, t3.c1 FROM ft4 t2 LEFT JOIN ft5 t3 ON (t2.c1 = t3.c1) WHERE (t2.c1 between 50 and 60)) ss(a, b) ON (t1.c1 = ss.a) ORDER BY t1.c1, ss.a, ss.b;
+                                                                                                                                                   QUERY PLAN                                                                                                                                                    
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Sort
+   Output: ft4.c1, t2.c1, t3.c1
+   Sort Key: ft4.c1, t2.c1, t3.c1
+   ->  Foreign Scan
+         Output: ft4.c1, t2.c1, t3.c1
+         Relations: (public.ft4) FULL JOIN ((public.ft4 t2) LEFT JOIN (public.ft5 t3))
+         Remote SQL: SELECT s4.c1, s8.c1, s8.c2 FROM ((SELECT c1 FROM "S 1"."T 3" WHERE ((c1 >= 50)) AND ((c1 <= 60))) s4(c1) FULL JOIN (SELECT r5.c1, r6.c1 FROM ("S 1"."T 3" r5 LEFT JOIN "S 1"."T 4" r6 ON (((r5.c1 = r6.c1)))) WHERE ((r5.c1 >= 50)) AND ((r5.c1 <= 60))) s8(c1, c2) ON (((s4.c1 = s8.c1))))
+(7 rows)
+
+SELECT t1.c1, ss.a, ss.b FROM (SELECT c1 FROM ft4 WHERE c1 between 50 and 60) t1 FULL JOIN (SELECT t2.c1, t3.c1 FROM ft4 t2 LEFT JOIN ft5 t3 ON (t2.c1 = t3.c1) WHERE (t2.c1 between 50 and 60)) ss(a, b) ON (t1.c1 = ss.a) ORDER BY t1.c1, ss.a, ss.b;
+ c1 | a  | b  
+----+----+----
+ 50 | 50 |   
+ 52 | 52 |   
+ 54 | 54 | 54
+ 56 | 56 |   
+ 58 | 58 |   
+ 60 | 60 | 60
+(6 rows)
+
+-- c. test deparsing the remote query as nested subqueries
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, ss.a, ss.b FROM (SELECT c1 FROM ft4 WHERE c1 between 50 and 60) t1 FULL JOIN (SELECT t2.c1, t3.c1 FROM (SELECT c1 FROM ft4 WHERE c1 between 50 and 60) t2 FULL JOIN (SELECT c1 FROM ft5 WHERE c1 between 50 and 60) t3 ON (t2.c1 = t3.c1) WHERE t2.c1 IS NULL OR t2.c1 IS NOT NULL) ss(a, b) ON (t1.c1 = ss.a) ORDER BY t1.c1, ss.a, ss.b;
+                                                                                                                                                                                                                  QUERY PLAN                                                                                                                                                                                                                  
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Sort
+   Output: ft4.c1, ft4_1.c1, ft5.c1
+   Sort Key: ft4.c1, ft4_1.c1, ft5.c1
+   ->  Foreign Scan
+         Output: ft4.c1, ft4_1.c1, ft5.c1
+         Relations: (public.ft4) FULL JOIN ((public.ft4) FULL JOIN (public.ft5))
+         Remote SQL: SELECT s4.c1, s10.c1, s10.c2 FROM ((SELECT c1 FROM "S 1"."T 3" WHERE ((c1 >= 50)) AND ((c1 <= 60))) s4(c1) FULL JOIN (SELECT s8.c1, s9.c1 FROM ((SELECT c1 FROM "S 1"."T 3" WHERE ((c1 >= 50)) AND ((c1 <= 60))) s8(c1) FULL JOIN (SELECT c1 FROM "S 1"."T 4" WHERE ((c1 >= 50)) AND ((c1 <= 60))) s9(c1) ON (((s8.c1 = s9.c1)))) WHERE (((s8.c1 IS NULL) OR (s8.c1 IS NOT NULL)))) s10(c1, c2) ON (((s4.c1 = s10.c1))))
+(7 rows)
+
+SELECT t1.c1, ss.a, ss.b FROM (SELECT c1 FROM ft4 WHERE c1 between 50 and 60) t1 FULL JOIN (SELECT t2.c1, t3.c1 FROM (SELECT c1 FROM ft4 WHERE c1 between 50 and 60) t2 FULL JOIN (SELECT c1 FROM ft5 WHERE c1 between 50 and 60) t3 ON (t2.c1 = t3.c1) WHERE t2.c1 IS NULL OR t2.c1 IS NOT NULL) ss(a, b) ON (t1.c1 = ss.a) ORDER BY t1.c1, ss.a, ss.b;
+ c1 | a  | b  
+----+----+----
+ 50 | 50 |   
+ 52 | 52 |   
+ 54 | 54 | 54
+ 56 | 56 |   
+ 58 | 58 |   
+ 60 | 60 | 60
+    |    | 51
+    |    | 57
+(8 rows)
+
+-- d. test deparsing rowmarked relations as subqueries
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, ss.a, ss.b FROM (SELECT c1 FROM "S 1"."T 3" WHERE c1 = 50) t1 INNER JOIN (SELECT t2.c1, t3.c1 FROM (SELECT c1 FROM ft4 WHERE c1 between 50 and 60) t2 FULL JOIN (SELECT c1 FROM ft5 WHERE c1 between 50 and 60) t3 ON (t2.c1 = t3.c1) WHERE t2.c1 IS NULL OR t2.c1 IS NOT NULL) ss(a, b) ON (TRUE) ORDER BY t1.c1, ss.a, ss.b FOR UPDATE OF t1;
+                                                                                                                                                                                             QUERY PLAN                                                                                                                                                                                             
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ LockRows
+   Output: "T 3".c1, ft4.c1, ft5.c1, "T 3".ctid, ft4.*, ft5.*
+   ->  Nested Loop
+         Output: "T 3".c1, ft4.c1, ft5.c1, "T 3".ctid, ft4.*, ft5.*
+         ->  Foreign Scan
+               Output: ft4.c1, ft4.*, ft5.c1, ft5.*
+               Relations: (public.ft4) FULL JOIN (public.ft5)
+               Remote SQL: SELECT s8.c1, s8.c2, s9.c1, s9.c2 FROM ((SELECT c1, ROW(c1, c2, c3) FROM "S 1"."T 3" WHERE ((c1 >= 50)) AND ((c1 <= 60))) s8(c1, c2) FULL JOIN (SELECT c1, ROW(c1, c2, c3) FROM "S 1"."T 4" WHERE ((c1 >= 50)) AND ((c1 <= 60))) s9(c1, c2) ON (((s8.c1 = s9.c1)))) WHERE (((s8.c1 IS NULL) OR (s8.c1 IS NOT NULL))) ORDER BY s8.c1 ASC NULLS LAST, s9.c1 ASC NULLS LAST
+               ->  Sort
+                     Output: ft4.c1, ft4.*, ft5.c1, ft5.*
+                     Sort Key: ft4.c1, ft5.c1
+                     ->  Hash Full Join
+                           Output: ft4.c1, ft4.*, ft5.c1, ft5.*
+                           Hash Cond: (ft4.c1 = ft5.c1)
+                           Filter: ((ft4.c1 IS NULL) OR (ft4.c1 IS NOT NULL))
+                           ->  Foreign Scan on public.ft4
+                                 Output: ft4.c1, ft4.*
+                                 Remote SQL: SELECT c1, c2, c3 FROM "S 1"."T 3" WHERE ((c1 >= 50)) AND ((c1 <= 60))
+                           ->  Hash
+                                 Output: ft5.c1, ft5.*
+                                 ->  Foreign Scan on public.ft5
+                                       Output: ft5.c1, ft5.*
+                                       Remote SQL: SELECT c1, c2, c3 FROM "S 1"."T 4" WHERE ((c1 >= 50)) AND ((c1 <= 60))
+         ->  Materialize
+               Output: "T 3".c1, "T 3".ctid
+               ->  Seq Scan on "S 1"."T 3"
+                     Output: "T 3".c1, "T 3".ctid
+                     Filter: ("T 3".c1 = 50)
+(28 rows)
+
+SELECT t1.c1, ss.a, ss.b FROM (SELECT c1 FROM "S 1"."T 3" WHERE c1 = 50) t1 INNER JOIN (SELECT t2.c1, t3.c1 FROM (SELECT c1 FROM ft4 WHERE c1 between 50 and 60) t2 FULL JOIN (SELECT c1 FROM ft5 WHERE c1 between 50 and 60) t3 ON (t2.c1 = t3.c1) WHERE t2.c1 IS NULL OR t2.c1 IS NOT NULL) ss(a, b) ON (TRUE) ORDER BY t1.c1, ss.a, ss.b FOR UPDATE OF t1;
+ c1 | a  | b  
+----+----+----
+ 50 | 50 |   
+ 50 | 52 |   
+ 50 | 54 | 54
+ 50 | 56 |   
+ 50 | 58 |   
+ 50 | 60 | 60
+ 50 |    | 51
+ 50 |    | 57
+(8 rows)
+
+-- full outer join + inner join
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1, t3.c1 FROM ft4 t1 INNER JOIN ft5 t2 ON (t1.c1 = t2.c1 + 1 and t1.c1 between 50 and 60) FULL JOIN ft4 t3 ON (t2.c1 = t3.c1) ORDER BY t1.c1, t2.c1, t3.c1 LIMIT 10;
+                                                                                                                                                 QUERY PLAN                                                                                                                                                 
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c1, t3.c1
+   Relations: ((public.ft4 t1) INNER JOIN (public.ft5 t2)) FULL JOIN (public.ft4 t3)
+   Remote SQL: SELECT r1.c1, r2.c1, r4.c1 FROM (("S 1"."T 3" r1 INNER JOIN "S 1"."T 4" r2 ON (((r1.c1 = (r2.c1 + 1))) AND ((r1.c1 >= 50)) AND ((r1.c1 <= 60)))) FULL JOIN "S 1"."T 3" r4 ON (((r2.c1 = r4.c1)))) ORDER BY r1.c1 ASC NULLS LAST, r2.c1 ASC NULLS LAST, r4.c1 ASC NULLS LAST LIMIT 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c1, t3.c1 FROM ft4 t1 INNER JOIN ft5 t2 ON (t1.c1 = t2.c1 + 1 and t1.c1 between 50 and 60) FULL JOIN ft4 t3 ON (t2.c1 = t3.c1) ORDER BY t1.c1, t2.c1, t3.c1 LIMIT 10;
+ c1 | c1 | c1 
+----+----+----
+ 52 | 51 |   
+ 58 | 57 |   
+    |    |  2
+    |    |  4
+    |    |  6
+    |    |  8
+    |    | 10
+    |    | 12
+    |    | 14
+    |    | 16
+(10 rows)
+
+-- full outer join three tables
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 FULL JOIN ft2 t2 ON (t1.c1 = t2.c1) FULL JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+                                                                                                   QUERY PLAN                                                                                                    
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c2, t3.c3
+   Relations: ((public.ft2 t1) FULL JOIN (public.ft2 t2)) FULL JOIN (public.ft4 t3)
+   Remote SQL: SELECT r1."C 1", r2.c2, r4.c3 FROM (("S 1"."T 1" r1 FULL JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")))) FULL JOIN "S 1"."T 3" r4 ON (((r2."C 1" = r4.c1)))) LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 FULL JOIN ft2 t2 ON (t1.c1 = t2.c1) FULL JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+ c1 | c2 |   c3   
+----+----+--------
+ 11 |  1 | 
+ 12 |  2 | AAA012
+ 13 |  3 | 
+ 14 |  4 | AAA014
+ 15 |  5 | 
+ 16 |  6 | AAA016
+ 17 |  7 | 
+ 18 |  8 | AAA018
+ 19 |  9 | 
+ 20 |  0 | AAA020
+(10 rows)
+
+-- full outer join + right outer join
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 FULL JOIN ft2 t2 ON (t1.c1 = t2.c1) RIGHT JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+                                                                                                   QUERY PLAN                                                                                                    
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c2, t3.c3
+   Relations: ((public.ft4 t3) LEFT JOIN (public.ft2 t2)) LEFT JOIN (public.ft2 t1)
+   Remote SQL: SELECT r1."C 1", r2.c2, r4.c3 FROM (("S 1"."T 3" r4 LEFT JOIN "S 1"."T 1" r2 ON (((r2."C 1" = r4.c1)))) LEFT JOIN "S 1"."T 1" r1 ON (((r1."C 1" = r2."C 1")))) LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 FULL JOIN ft2 t2 ON (t1.c1 = t2.c1) RIGHT JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+ c1 | c2 |   c3   
+----+----+--------
+ 22 |  2 | AAA022
+ 24 |  4 | AAA024
+ 26 |  6 | AAA026
+ 28 |  8 | AAA028
+ 30 |  0 | AAA030
+ 32 |  2 | AAA032
+ 34 |  4 | AAA034
+ 36 |  6 | AAA036
+ 38 |  8 | AAA038
+ 40 |  0 | AAA040
+(10 rows)
+
+-- right outer join + full outer join
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 RIGHT JOIN ft2 t2 ON (t1.c1 = t2.c1) FULL JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+                                                                                                   QUERY PLAN                                                                                                    
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c2, t3.c3
+   Relations: ((public.ft2 t2) LEFT JOIN (public.ft2 t1)) FULL JOIN (public.ft4 t3)
+   Remote SQL: SELECT r1."C 1", r2.c2, r4.c3 FROM (("S 1"."T 1" r2 LEFT JOIN "S 1"."T 1" r1 ON (((r1."C 1" = r2."C 1")))) FULL JOIN "S 1"."T 3" r4 ON (((r2."C 1" = r4.c1)))) LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 RIGHT JOIN ft2 t2 ON (t1.c1 = t2.c1) FULL JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+ c1 | c2 |   c3   
+----+----+--------
+ 11 |  1 | 
+ 12 |  2 | AAA012
+ 13 |  3 | 
+ 14 |  4 | AAA014
+ 15 |  5 | 
+ 16 |  6 | AAA016
+ 17 |  7 | 
+ 18 |  8 | AAA018
+ 19 |  9 | 
+ 20 |  0 | AAA020
+(10 rows)
+
+-- full outer join + left outer join
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 FULL JOIN ft2 t2 ON (t1.c1 = t2.c1) LEFT JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+                                                                                                   QUERY PLAN                                                                                                    
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c2, t3.c3
+   Relations: ((public.ft2 t1) FULL JOIN (public.ft2 t2)) LEFT JOIN (public.ft4 t3)
+   Remote SQL: SELECT r1."C 1", r2.c2, r4.c3 FROM (("S 1"."T 1" r1 FULL JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")))) LEFT JOIN "S 1"."T 3" r4 ON (((r2."C 1" = r4.c1)))) LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 FULL JOIN ft2 t2 ON (t1.c1 = t2.c1) LEFT JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+ c1 | c2 |   c3   
+----+----+--------
+ 11 |  1 | 
+ 12 |  2 | AAA012
+ 13 |  3 | 
+ 14 |  4 | AAA014
+ 15 |  5 | 
+ 16 |  6 | AAA016
+ 17 |  7 | 
+ 18 |  8 | AAA018
+ 19 |  9 | 
+ 20 |  0 | AAA020
+(10 rows)
+
+-- left outer join + full outer join
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 LEFT JOIN ft2 t2 ON (t1.c1 = t2.c1) FULL JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+                                                                                                   QUERY PLAN                                                                                                    
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c2, t3.c3
+   Relations: ((public.ft2 t1) LEFT JOIN (public.ft2 t2)) FULL JOIN (public.ft4 t3)
+   Remote SQL: SELECT r1."C 1", r2.c2, r4.c3 FROM (("S 1"."T 1" r1 LEFT JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")))) FULL JOIN "S 1"."T 3" r4 ON (((r2."C 1" = r4.c1)))) LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 LEFT JOIN ft2 t2 ON (t1.c1 = t2.c1) FULL JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+ c1 | c2 |   c3   
+----+----+--------
+ 11 |  1 | 
+ 12 |  2 | AAA012
+ 13 |  3 | 
+ 14 |  4 | AAA014
+ 15 |  5 | 
+ 16 |  6 | AAA016
+ 17 |  7 | 
+ 18 |  8 | AAA018
+ 19 |  9 | 
+ 20 |  0 | AAA020
+(10 rows)
+
+-- right outer join + left outer join
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 RIGHT JOIN ft2 t2 ON (t1.c1 = t2.c1) LEFT JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+                                                                                                   QUERY PLAN                                                                                                    
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c2, t3.c3
+   Relations: ((public.ft2 t2) LEFT JOIN (public.ft2 t1)) LEFT JOIN (public.ft4 t3)
+   Remote SQL: SELECT r1."C 1", r2.c2, r4.c3 FROM (("S 1"."T 1" r2 LEFT JOIN "S 1"."T 1" r1 ON (((r1."C 1" = r2."C 1")))) LEFT JOIN "S 1"."T 3" r4 ON (((r2."C 1" = r4.c1)))) LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 RIGHT JOIN ft2 t2 ON (t1.c1 = t2.c1) LEFT JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+ c1 | c2 |   c3   
+----+----+--------
+ 11 |  1 | 
+ 12 |  2 | AAA012
+ 13 |  3 | 
+ 14 |  4 | AAA014
+ 15 |  5 | 
+ 16 |  6 | AAA016
+ 17 |  7 | 
+ 18 |  8 | AAA018
+ 19 |  9 | 
+ 20 |  0 | AAA020
+(10 rows)
+
+-- left outer join + right outer join
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 LEFT JOIN ft2 t2 ON (t1.c1 = t2.c1) RIGHT JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+                                                                                                    QUERY PLAN                                                                                                    
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c2, t3.c3
+   Relations: (public.ft4 t3) LEFT JOIN ((public.ft2 t1) INNER JOIN (public.ft2 t2))
+   Remote SQL: SELECT r1."C 1", r2.c2, r4.c3 FROM ("S 1"."T 3" r4 LEFT JOIN ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")))) ON (((r2."C 1" = r4.c1)))) LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c2, t3.c3 FROM ft2 t1 LEFT JOIN ft2 t2 ON (t1.c1 = t2.c1) RIGHT JOIN ft4 t3 ON (t2.c1 = t3.c1) OFFSET 10 LIMIT 10;
+ c1 | c2 |   c3   
+----+----+--------
+ 22 |  2 | AAA022
+ 24 |  4 | AAA024
+ 26 |  6 | AAA026
+ 28 |  8 | AAA028
+ 30 |  0 | AAA030
+ 32 |  2 | AAA032
+ 34 |  4 | AAA034
+ 36 |  6 | AAA036
+ 38 |  8 | AAA038
+ 40 |  0 | AAA040
+(10 rows)
+
+-- full outer join + WHERE clause, only matched rows
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft4 t1 FULL JOIN ft5 t2 ON (t1.c1 = t2.c1) WHERE (t1.c1 = t2.c1 OR t1.c1 IS NULL) ORDER BY t1.c1, t2.c1 OFFSET 10 LIMIT 10;
+                                                                            QUERY PLAN                                                                            
+------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Limit
+   Output: t1.c1, t2.c1
+   ->  Sort
+         Output: t1.c1, t2.c1
+         Sort Key: t1.c1, t2.c1
+         ->  Foreign Scan
+               Output: t1.c1, t2.c1
+               Relations: (public.ft4 t1) FULL JOIN (public.ft5 t2)
+               Remote SQL: SELECT r1.c1, r2.c1 FROM ("S 1"."T 3" r1 FULL JOIN "S 1"."T 4" r2 ON (((r1.c1 = r2.c1)))) WHERE (((r1.c1 = r2.c1) OR (r1.c1 IS NULL)))
+(9 rows)
+
+SELECT t1.c1, t2.c1 FROM ft4 t1 FULL JOIN ft5 t2 ON (t1.c1 = t2.c1) WHERE (t1.c1 = t2.c1 OR t1.c1 IS NULL) ORDER BY t1.c1, t2.c1 OFFSET 10 LIMIT 10;
+ c1 | c1 
+----+----
+ 66 | 66
+ 72 | 72
+ 78 | 78
+ 84 | 84
+ 90 | 90
+ 96 | 96
+    |  3
+    |  9
+    | 15
+    | 21
+(10 rows)
+
+-- full outer join + WHERE clause with shippable extensions set
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2, t1.c3 FROM ft1 t1 FULL JOIN ft2 t2 ON (t1.c1 = t2.c1) WHERE postgres_fdw_abs(t1.c1) > 0 OFFSET 10 LIMIT 10;
+                                                                                                 QUERY PLAN                                                                                                 
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c2, t1.c3
+   Relations: (public.ft1 t1) FULL JOIN (public.ft2 t2)
+   Remote SQL: SELECT r1."C 1", r2.c2, r1.c3 FROM ("S 1"."T 1" r1 FULL JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")))) WHERE ((public.postgres_fdw_abs(r1."C 1") > 0)) LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+ALTER SERVER loopback OPTIONS (DROP extensions);
+-- full outer join + WHERE clause with shippable extensions not set
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2, t1.c3 FROM ft1 t1 FULL JOIN ft2 t2 ON (t1.c1 = t2.c1) WHERE postgres_fdw_abs(t1.c1) > 0 OFFSET 10 LIMIT 10;
+                                                          QUERY PLAN                                                           
+-------------------------------------------------------------------------------------------------------------------------------
+ Limit
+   Output: t1.c1, t2.c2, t1.c3
+   ->  Foreign Scan
+         Output: t1.c1, t2.c2, t1.c3
+         Filter: (postgres_fdw_abs(t1.c1) > 0)
+         Relations: (public.ft1 t1) FULL JOIN (public.ft2 t2)
+         Remote SQL: SELECT r1."C 1", r2.c2, r1.c3 FROM ("S 1"."T 1" r1 FULL JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1"))))
+(7 rows)
+
+ALTER SERVER loopback OPTIONS (ADD extensions 'postgres_fdw');
+-- join two tables with FOR UPDATE clause
+-- tests whole-row reference for row marks
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10 FOR UPDATE OF t1;
+                                                                                                                                                                                                                           QUERY PLAN                                                                                                                                                                                                                            
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c1, t1.c3, t1.*, t2.*
+   Relations: (public.ft1 t1) INNER JOIN (public.ft2 t2)
+   Remote SQL: SELECT r1."C 1", r2."C 1", r1.c3, CASE WHEN (r1.*)::text IS NOT NULL THEN ROW(r1."C 1", r1.c2, r1.c3, r1.c4, r1.c5, r1.c6, r1.c7, r1.c8) END, CASE WHEN (r2.*)::text IS NOT NULL THEN ROW(r2."C 1", r2.c2, r2.c3, r2.c4, r2.c5, r2.c6, r2.c7, r2.c8) END FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")))) ORDER BY r1.c3 ASC NULLS LAST, r1."C 1" ASC NULLS LAST LIMIT 10::bigint OFFSET 100::bigint FOR UPDATE OF r1
+(4 rows)
+
+SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10 FOR UPDATE OF t1;
+ c1  | c1  
+-----+-----
+ 101 | 101
+ 102 | 102
+ 103 | 103
+ 104 | 104
+ 105 | 105
+ 106 | 106
+ 107 | 107
+ 108 | 108
+ 109 | 109
+ 110 | 110
+(10 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10 FOR UPDATE;
+                                                                                                                                                                                                                                    QUERY PLAN                                                                                                                                                                                                                                    
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c1, t1.c3, t1.*, t2.*
+   Relations: (public.ft1 t1) INNER JOIN (public.ft2 t2)
+   Remote SQL: SELECT r1."C 1", r2."C 1", r1.c3, CASE WHEN (r1.*)::text IS NOT NULL THEN ROW(r1."C 1", r1.c2, r1.c3, r1.c4, r1.c5, r1.c6, r1.c7, r1.c8) END, CASE WHEN (r2.*)::text IS NOT NULL THEN ROW(r2."C 1", r2.c2, r2.c3, r2.c4, r2.c5, r2.c6, r2.c7, r2.c8) END FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")))) ORDER BY r1.c3 ASC NULLS LAST, r1."C 1" ASC NULLS LAST LIMIT 10::bigint OFFSET 100::bigint FOR UPDATE OF r1 FOR UPDATE OF r2
+(4 rows)
+
+SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10 FOR UPDATE;
+ c1  | c1  
+-----+-----
+ 101 | 101
+ 102 | 102
+ 103 | 103
+ 104 | 104
+ 105 | 105
+ 106 | 106
+ 107 | 107
+ 108 | 108
+ 109 | 109
+ 110 | 110
+(10 rows)
+
+-- join two tables with FOR SHARE clause
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10 FOR SHARE OF t1;
+                                                                                                                                                                                                                           QUERY PLAN                                                                                                                                                                                                                           
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c1, t1.c3, t1.*, t2.*
+   Relations: (public.ft1 t1) INNER JOIN (public.ft2 t2)
+   Remote SQL: SELECT r1."C 1", r2."C 1", r1.c3, CASE WHEN (r1.*)::text IS NOT NULL THEN ROW(r1."C 1", r1.c2, r1.c3, r1.c4, r1.c5, r1.c6, r1.c7, r1.c8) END, CASE WHEN (r2.*)::text IS NOT NULL THEN ROW(r2."C 1", r2.c2, r2.c3, r2.c4, r2.c5, r2.c6, r2.c7, r2.c8) END FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")))) ORDER BY r1.c3 ASC NULLS LAST, r1."C 1" ASC NULLS LAST LIMIT 10::bigint OFFSET 100::bigint FOR SHARE OF r1
+(4 rows)
+
+SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10 FOR SHARE OF t1;
+ c1  | c1  
+-----+-----
+ 101 | 101
+ 102 | 102
+ 103 | 103
+ 104 | 104
+ 105 | 105
+ 106 | 106
+ 107 | 107
+ 108 | 108
+ 109 | 109
+ 110 | 110
+(10 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10 FOR SHARE;
+                                                                                                                                                                                                                                   QUERY PLAN                                                                                                                                                                                                                                   
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c1, t1.c3, t1.*, t2.*
+   Relations: (public.ft1 t1) INNER JOIN (public.ft2 t2)
+   Remote SQL: SELECT r1."C 1", r2."C 1", r1.c3, CASE WHEN (r1.*)::text IS NOT NULL THEN ROW(r1."C 1", r1.c2, r1.c3, r1.c4, r1.c5, r1.c6, r1.c7, r1.c8) END, CASE WHEN (r2.*)::text IS NOT NULL THEN ROW(r2."C 1", r2.c2, r2.c3, r2.c4, r2.c5, r2.c6, r2.c7, r2.c8) END FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")))) ORDER BY r1.c3 ASC NULLS LAST, r1."C 1" ASC NULLS LAST LIMIT 10::bigint OFFSET 100::bigint FOR SHARE OF r1 FOR SHARE OF r2
+(4 rows)
+
+SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10 FOR SHARE;
+ c1  | c1  
+-----+-----
+ 101 | 101
+ 102 | 102
+ 103 | 103
+ 104 | 104
+ 105 | 105
+ 106 | 106
+ 107 | 107
+ 108 | 108
+ 109 | 109
+ 110 | 110
+(10 rows)
+
+-- join in CTE
+EXPLAIN (VERBOSE, COSTS OFF)
+WITH t (c1_1, c1_3, c2_1) AS MATERIALIZED (SELECT t1.c1, t1.c3, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1)) SELECT c1_1, c2_1 FROM t ORDER BY c1_3, c1_1 OFFSET 100 LIMIT 10;
+                                                             QUERY PLAN                                                              
+-------------------------------------------------------------------------------------------------------------------------------------
+ Limit
+   Output: t.c1_1, t.c2_1, t.c1_3
+   CTE t
+     ->  Foreign Scan
+           Output: t1.c1, t1.c3, t2.c1
+           Relations: (public.ft1 t1) INNER JOIN (public.ft2 t2)
+           Remote SQL: SELECT r1."C 1", r1.c3, r2."C 1" FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1"))))
+   ->  Sort
+         Output: t.c1_1, t.c2_1, t.c1_3
+         Sort Key: t.c1_3, t.c1_1
+         ->  CTE Scan on t
+               Output: t.c1_1, t.c2_1, t.c1_3
+(12 rows)
+
+WITH t (c1_1, c1_3, c2_1) AS MATERIALIZED (SELECT t1.c1, t1.c3, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1)) SELECT c1_1, c2_1 FROM t ORDER BY c1_3, c1_1 OFFSET 100 LIMIT 10;
+ c1_1 | c2_1 
+------+------
+  101 |  101
+  102 |  102
+  103 |  103
+  104 |  104
+  105 |  105
+  106 |  106
+  107 |  107
+  108 |  108
+  109 |  109
+  110 |  110
+(10 rows)
+
+-- ctid with whole-row reference
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.ctid, t1, t2, t1.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10;
+                                                                                                                                                                                                                  QUERY PLAN                                                                                                                                                                                                                   
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.ctid, t1.*, t2.*, t1.c1, t1.c3
+   Relations: (public.ft1 t1) INNER JOIN (public.ft2 t2)
+   Remote SQL: SELECT r1.ctid, CASE WHEN (r1.*)::text IS NOT NULL THEN ROW(r1."C 1", r1.c2, r1.c3, r1.c4, r1.c5, r1.c6, r1.c7, r1.c8) END, CASE WHEN (r2.*)::text IS NOT NULL THEN ROW(r2."C 1", r2.c2, r2.c3, r2.c4, r2.c5, r2.c6, r2.c7, r2.c8) END, r1."C 1", r1.c3 FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")))) ORDER BY r1.c3 ASC NULLS LAST, r1."C 1" ASC NULLS LAST LIMIT 10::bigint OFFSET 100::bigint
+(4 rows)
+
+-- SEMI JOIN, not pushed down
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1 FROM ft1 t1 WHERE EXISTS (SELECT 1 FROM ft2 t2 WHERE t1.c1 = t2.c1) ORDER BY t1.c1 OFFSET 100 LIMIT 10;
+                                      QUERY PLAN                                       
+---------------------------------------------------------------------------------------
+ Limit
+   Output: t1.c1
+   ->  Merge Semi Join
+         Output: t1.c1
+         Merge Cond: (t1.c1 = t2.c1)
+         ->  Foreign Scan on public.ft1 t1
+               Output: t1.c1
+               Remote SQL: SELECT "C 1" FROM "S 1"."T 1" ORDER BY "C 1" ASC NULLS LAST
+         ->  Foreign Scan on public.ft2 t2
+               Output: t2.c1
+               Remote SQL: SELECT "C 1" FROM "S 1"."T 1" ORDER BY "C 1" ASC NULLS LAST
+(11 rows)
+
+SELECT t1.c1 FROM ft1 t1 WHERE EXISTS (SELECT 1 FROM ft2 t2 WHERE t1.c1 = t2.c1) ORDER BY t1.c1 OFFSET 100 LIMIT 10;
+ c1  
+-----
+ 101
+ 102
+ 103
+ 104
+ 105
+ 106
+ 107
+ 108
+ 109
+ 110
+(10 rows)
+
+-- ANTI JOIN, not pushed down
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1 FROM ft1 t1 WHERE NOT EXISTS (SELECT 1 FROM ft2 t2 WHERE t1.c1 = t2.c2) ORDER BY t1.c1 OFFSET 100 LIMIT 10;
+                                      QUERY PLAN                                       
+---------------------------------------------------------------------------------------
+ Limit
+   Output: t1.c1
+   ->  Merge Anti Join
+         Output: t1.c1
+         Merge Cond: (t1.c1 = t2.c2)
+         ->  Foreign Scan on public.ft1 t1
+               Output: t1.c1
+               Remote SQL: SELECT "C 1" FROM "S 1"."T 1" ORDER BY "C 1" ASC NULLS LAST
+         ->  Foreign Scan on public.ft2 t2
+               Output: t2.c2
+               Remote SQL: SELECT c2 FROM "S 1"."T 1" ORDER BY c2 ASC NULLS LAST
+(11 rows)
+
+SELECT t1.c1 FROM ft1 t1 WHERE NOT EXISTS (SELECT 1 FROM ft2 t2 WHERE t1.c1 = t2.c2) ORDER BY t1.c1 OFFSET 100 LIMIT 10;
+ c1  
+-----
+ 110
+ 111
+ 112
+ 113
+ 114
+ 115
+ 116
+ 117
+ 118
+ 119
+(10 rows)
+
+-- CROSS JOIN can be pushed down
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft1 t1 CROSS JOIN ft2 t2 ORDER BY t1.c1, t2.c1 OFFSET 100 LIMIT 10;
+                                                                                           QUERY PLAN                                                                                            
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c1, t2.c1
+   Relations: (public.ft1 t1) INNER JOIN (public.ft2 t2)
+   Remote SQL: SELECT r1."C 1", r2."C 1" FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (TRUE)) ORDER BY r1."C 1" ASC NULLS LAST, r2."C 1" ASC NULLS LAST LIMIT 10::bigint OFFSET 100::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c1 FROM ft1 t1 CROSS JOIN ft2 t2 ORDER BY t1.c1, t2.c1 OFFSET 100 LIMIT 10;
+ c1 | c1  
+----+-----
+  1 | 101
+  1 | 102
+  1 | 103
+  1 | 104
+  1 | 105
+  1 | 106
+  1 | 107
+  1 | 108
+  1 | 109
+  1 | 110
+(10 rows)
+
+-- different server, not pushed down. No result expected.
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft5 t1 JOIN ft6 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 100 LIMIT 10;
+                                      QUERY PLAN                                       
+---------------------------------------------------------------------------------------
+ Limit
+   Output: t1.c1, t2.c1
+   ->  Merge Join
+         Output: t1.c1, t2.c1
+         Merge Cond: (t2.c1 = t1.c1)
+         ->  Foreign Scan on public.ft6 t2
+               Output: t2.c1, t2.c2, t2.c3
+               Remote SQL: SELECT c1 FROM "S 1"."T 4" ORDER BY c1 ASC NULLS LAST
+         ->  Materialize
+               Output: t1.c1, t1.c2, t1.c3
+               ->  Foreign Scan on public.ft5 t1
+                     Output: t1.c1, t1.c2, t1.c3
+                     Remote SQL: SELECT c1 FROM "S 1"."T 4" ORDER BY c1 ASC NULLS LAST
+(13 rows)
+
+SELECT t1.c1, t2.c1 FROM ft5 t1 JOIN ft6 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 100 LIMIT 10;
+ c1 | c1 
+----+----
+(0 rows)
+
+-- unsafe join conditions (c8 has a UDT), not pushed down. Practically a CROSS
+-- JOIN since c8 in both tables has same value.
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft1 t1 LEFT JOIN ft2 t2 ON (t1.c8 = t2.c8) ORDER BY t1.c1, t2.c1 OFFSET 100 LIMIT 10;
+                               QUERY PLAN                                
+-------------------------------------------------------------------------
+ Limit
+   Output: t1.c1, t2.c1
+   ->  Sort
+         Output: t1.c1, t2.c1
+         Sort Key: t1.c1, t2.c1
+         ->  Merge Left Join
+               Output: t1.c1, t2.c1
+               Merge Cond: (t1.c8 = t2.c8)
+               ->  Sort
+                     Output: t1.c1, t1.c8
+                     Sort Key: t1.c8
+                     ->  Foreign Scan on public.ft1 t1
+                           Output: t1.c1, t1.c8
+                           Remote SQL: SELECT "C 1", c8 FROM "S 1"."T 1"
+               ->  Sort
+                     Output: t2.c1, t2.c8
+                     Sort Key: t2.c8
+                     ->  Foreign Scan on public.ft2 t2
+                           Output: t2.c1, t2.c8
+                           Remote SQL: SELECT "C 1", c8 FROM "S 1"."T 1"
+(20 rows)
+
+SELECT t1.c1, t2.c1 FROM ft1 t1 LEFT JOIN ft2 t2 ON (t1.c8 = t2.c8) ORDER BY t1.c1, t2.c1 OFFSET 100 LIMIT 10;
+ c1 | c1  
+----+-----
+  1 | 101
+  1 | 102
+  1 | 103
+  1 | 104
+  1 | 105
+  1 | 106
+  1 | 107
+  1 | 108
+  1 | 109
+  1 | 110
+(10 rows)
+
+-- unsafe conditions on one side (c8 has a UDT), not pushed down.
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft1 t1 LEFT JOIN ft2 t2 ON (t1.c1 = t2.c1) WHERE t1.c8 = 'foo' ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10;
+                                 QUERY PLAN                                  
+-----------------------------------------------------------------------------
+ Limit
+   Output: t1.c1, t2.c1, t1.c3
+   ->  Sort
+         Output: t1.c1, t2.c1, t1.c3
+         Sort Key: t1.c3, t1.c1
+         ->  Hash Right Join
+               Output: t1.c1, t2.c1, t1.c3
+               Hash Cond: (t2.c1 = t1.c1)
+               ->  Foreign Scan on public.ft2 t2
+                     Output: t2.c1
+                     Remote SQL: SELECT "C 1" FROM "S 1"."T 1"
+               ->  Hash
+                     Output: t1.c1, t1.c3
+                     ->  Foreign Scan on public.ft1 t1
+                           Output: t1.c1, t1.c3
+                           Filter: (t1.c8 = 'foo'::user_enum)
+                           Remote SQL: SELECT "C 1", c3, c8 FROM "S 1"."T 1"
+(17 rows)
+
+SELECT t1.c1, t2.c1 FROM ft1 t1 LEFT JOIN ft2 t2 ON (t1.c1 = t2.c1) WHERE t1.c8 = 'foo' ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10;
+ c1  | c1  
+-----+-----
+ 101 | 101
+ 102 | 102
+ 103 | 103
+ 104 | 104
+ 105 | 105
+ 106 | 106
+ 107 | 107
+ 108 | 108
+ 109 | 109
+ 110 | 110
+(10 rows)
+
+-- join where unsafe to pushdown condition in WHERE clause has a column not
+-- in the SELECT clause. In this test unsafe clause needs to have column
+-- references from both joining sides so that the clause is not pushed down
+-- into one of the joining sides.
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) WHERE t1.c8 = t2.c8 ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10;
+                                                                      QUERY PLAN                                                                       
+-------------------------------------------------------------------------------------------------------------------------------------------------------
+ Limit
+   Output: t1.c1, t2.c1, t1.c3
+   ->  Sort
+         Output: t1.c1, t2.c1, t1.c3
+         Sort Key: t1.c3, t1.c1
+         ->  Foreign Scan
+               Output: t1.c1, t2.c1, t1.c3
+               Filter: (t1.c8 = t2.c8)
+               Relations: (public.ft1 t1) INNER JOIN (public.ft2 t2)
+               Remote SQL: SELECT r1."C 1", r2."C 1", r1.c3, r1.c8, r2.c8 FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1"))))
+(10 rows)
+
+SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) WHERE t1.c8 = t2.c8 ORDER BY t1.c3, t1.c1 OFFSET 100 LIMIT 10;
+ c1  | c1  
+-----+-----
+ 101 | 101
+ 102 | 102
+ 103 | 103
+ 104 | 104
+ 105 | 105
+ 106 | 106
+ 107 | 107
+ 108 | 108
+ 109 | 109
+ 110 | 110
+(10 rows)
+
+-- Aggregate after UNION, for testing setrefs
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1c1, avg(t1c1 + t2c1) FROM (SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) UNION SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1)) AS t (t1c1, t2c1) GROUP BY t1c1 ORDER BY t1c1 OFFSET 100 LIMIT 10;
+                                                                     QUERY PLAN                                                                     
+----------------------------------------------------------------------------------------------------------------------------------------------------
+ Limit
+   Output: t1.c1, (avg((t1.c1 + t2.c1)))
+   ->  Sort
+         Output: t1.c1, (avg((t1.c1 + t2.c1)))
+         Sort Key: t1.c1
+         ->  HashAggregate
+               Output: t1.c1, avg((t1.c1 + t2.c1))
+               Group Key: t1.c1
+               ->  HashAggregate
+                     Output: t1.c1, t2.c1
+                     Group Key: t1.c1, t2.c1
+                     ->  Append
+                           ->  Foreign Scan
+                                 Output: t1.c1, t2.c1
+                                 Relations: (public.ft1 t1) INNER JOIN (public.ft2 t2)
+                                 Remote SQL: SELECT r1."C 1", r2."C 1" FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1"))))
+                           ->  Foreign Scan
+                                 Output: t1_1.c1, t2_1.c1
+                                 Relations: (public.ft1 t1) INNER JOIN (public.ft2 t2)
+                                 Remote SQL: SELECT r1."C 1", r2."C 1" FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1"))))
+(20 rows)
+
+SELECT t1c1, avg(t1c1 + t2c1) FROM (SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1) UNION SELECT t1.c1, t2.c1 FROM ft1 t1 JOIN ft2 t2 ON (t1.c1 = t2.c1)) AS t (t1c1, t2c1) GROUP BY t1c1 ORDER BY t1c1 OFFSET 100 LIMIT 10;
+ t1c1 |         avg          
+------+----------------------
+  101 | 202.0000000000000000
+  102 | 204.0000000000000000
+  103 | 206.0000000000000000
+  104 | 208.0000000000000000
+  105 | 210.0000000000000000
+  106 | 212.0000000000000000
+  107 | 214.0000000000000000
+  108 | 216.0000000000000000
+  109 | 218.0000000000000000
+  110 | 220.0000000000000000
+(10 rows)
+
+-- join with lateral reference
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1."C 1" FROM "S 1"."T 1" t1, LATERAL (SELECT DISTINCT t2.c1, t3.c1 FROM ft1 t2, ft2 t3 WHERE t2.c1 = t3.c1 AND t2.c2 = t1.c2) q ORDER BY t1."C 1" OFFSET 10 LIMIT 10;
+                                                                             QUERY PLAN                                                                             
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Limit
+   Output: t1."C 1"
+   ->  Nested Loop
+         Output: t1."C 1"
+         ->  Index Scan using t1_pkey on "S 1"."T 1" t1
+               Output: t1."C 1", t1.c2, t1.c3, t1.c4, t1.c5, t1.c6, t1.c7, t1.c8
+         ->  HashAggregate
+               Output: t2.c1, t3.c1
+               Group Key: t2.c1, t3.c1
+               ->  Foreign Scan
+                     Output: t2.c1, t3.c1
+                     Relations: (public.ft1 t2) INNER JOIN (public.ft2 t3)
+                     Remote SQL: SELECT r1."C 1", r2."C 1" FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")) AND ((r1.c2 = $1::integer))))
+(13 rows)
+
+SELECT t1."C 1" FROM "S 1"."T 1" t1, LATERAL (SELECT DISTINCT t2.c1, t3.c1 FROM ft1 t2, ft2 t3 WHERE t2.c1 = t3.c1 AND t2.c2 = t1.c2) q ORDER BY t1."C 1" OFFSET 10 LIMIT 10;
+ C 1 
+-----
+   1
+   1
+   1
+   1
+   1
+   1
+   1
+   1
+   1
+   1
+(10 rows)
+
+-- non-Var items in targetlist of the nullable rel of a join preventing
+-- push-down in some cases
+-- unable to push {ft1, ft2}
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT q.a, ft2.c1 FROM (SELECT 13 FROM ft1 WHERE c1 = 13) q(a) RIGHT JOIN ft2 ON (q.a = ft2.c1) WHERE ft2.c1 BETWEEN 10 AND 15;
+                                                        QUERY PLAN                                                         
+---------------------------------------------------------------------------------------------------------------------------
+ Nested Loop Left Join
+   Output: (13), ft2.c1
+   Join Filter: (13 = ft2.c1)
+   ->  Foreign Scan on public.ft2
+         Output: ft2.c1
+         Remote SQL: SELECT "C 1" FROM "S 1"."T 1" WHERE (("C 1" >= 10)) AND (("C 1" <= 15)) ORDER BY "C 1" ASC NULLS LAST
+   ->  Materialize
+         Output: (13)
+         ->  Foreign Scan on public.ft1
+               Output: 13
+               Remote SQL: SELECT NULL FROM "S 1"."T 1" WHERE (("C 1" = 13))
+(11 rows)
+
+SELECT q.a, ft2.c1 FROM (SELECT 13 FROM ft1 WHERE c1 = 13) q(a) RIGHT JOIN ft2 ON (q.a = ft2.c1) WHERE ft2.c1 BETWEEN 10 AND 15;
+ a  | c1 
+----+----
+    | 10
+    | 11
+    | 12
+ 13 | 13
+    | 14
+    | 15
+(6 rows)
+
+-- ok to push {ft1, ft2} but not {ft1, ft2, ft4}
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT ft4.c1, q.* FROM ft4 LEFT JOIN (SELECT 13, ft1.c1, ft2.c1 FROM ft1 RIGHT JOIN ft2 ON (ft1.c1 = ft2.c1) WHERE ft1.c1 = 12) q(a, b, c) ON (ft4.c1 = q.b) WHERE ft4.c1 BETWEEN 10 AND 15;
+                                                                                    QUERY PLAN                                                                                     
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Nested Loop Left Join
+   Output: ft4.c1, (13), ft1.c1, ft2.c1
+   Join Filter: (ft4.c1 = ft1.c1)
+   ->  Foreign Scan on public.ft4
+         Output: ft4.c1, ft4.c2, ft4.c3
+         Remote SQL: SELECT c1 FROM "S 1"."T 3" WHERE ((c1 >= 10)) AND ((c1 <= 15))
+   ->  Materialize
+         Output: ft1.c1, ft2.c1, (13)
+         ->  Foreign Scan
+               Output: ft1.c1, ft2.c1, 13
+               Relations: (public.ft1) INNER JOIN (public.ft2)
+               Remote SQL: SELECT r4."C 1", r5."C 1" FROM ("S 1"."T 1" r4 INNER JOIN "S 1"."T 1" r5 ON (((r5."C 1" = 12)) AND ((r4."C 1" = 12)))) ORDER BY r4."C 1" ASC NULLS LAST
+(12 rows)
+
+SELECT ft4.c1, q.* FROM ft4 LEFT JOIN (SELECT 13, ft1.c1, ft2.c1 FROM ft1 RIGHT JOIN ft2 ON (ft1.c1 = ft2.c1) WHERE ft1.c1 = 12) q(a, b, c) ON (ft4.c1 = q.b) WHERE ft4.c1 BETWEEN 10 AND 15;
+ c1 | a  | b  | c  
+----+----+----+----
+ 10 |    |    |   
+ 12 | 13 | 12 | 12
+ 14 |    |    |   
+(3 rows)
+
+-- join with nullable side with some columns with null values
+UPDATE ft5 SET c3 = null where c1 % 9 = 0;
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT ft5, ft5.c1, ft5.c2, ft5.c3, ft4.c1, ft4.c2 FROM ft5 left join ft4 on ft5.c1 = ft4.c1 WHERE ft4.c1 BETWEEN 10 and 30 ORDER BY ft5.c1, ft4.c1;
+                                                                                                                    QUERY PLAN                                                                                                                     
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Sort
+   Output: ft5.*, ft5.c1, ft5.c2, ft5.c3, ft4.c1, ft4.c2
+   Sort Key: ft5.c1
+   ->  Foreign Scan
+         Output: ft5.*, ft5.c1, ft5.c2, ft5.c3, ft4.c1, ft4.c2
+         Relations: (public.ft5) INNER JOIN (public.ft4)
+         Remote SQL: SELECT CASE WHEN (r1.*)::text IS NOT NULL THEN ROW(r1.c1, r1.c2, r1.c3) END, r1.c1, r1.c2, r1.c3, r2.c1, r2.c2 FROM ("S 1"."T 4" r1 INNER JOIN "S 1"."T 3" r2 ON (((r1.c1 = r2.c1)) AND ((r2.c1 >= 10)) AND ((r2.c1 <= 30))))
+(7 rows)
+
+SELECT ft5, ft5.c1, ft5.c2, ft5.c3, ft4.c1, ft4.c2 FROM ft5 left join ft4 on ft5.c1 = ft4.c1 WHERE ft4.c1 BETWEEN 10 and 30 ORDER BY ft5.c1, ft4.c1;
+      ft5       | c1 | c2 |   c3   | c1 | c2 
+----------------+----+----+--------+----+----
+ (12,13,AAA012) | 12 | 13 | AAA012 | 12 | 13
+ (18,19,)       | 18 | 19 |        | 18 | 19
+ (24,25,AAA024) | 24 | 25 | AAA024 | 24 | 25
+ (30,31,AAA030) | 30 | 31 | AAA030 | 30 | 31
+(4 rows)
+
+-- multi-way join involving multiple merge joins
+-- (this case used to have EPQ-related planning problems)
+CREATE TABLE local_tbl (c1 int NOT NULL, c2 int NOT NULL, c3 text, CONSTRAINT local_tbl_pkey PRIMARY KEY (c1));
+INSERT INTO local_tbl SELECT id, id % 10, to_char(id, 'FM0000') FROM generate_series(1, 1000) id;
+ANALYZE local_tbl;
+SET enable_nestloop TO false;
+SET enable_hashjoin TO false;
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT * FROM ft1, ft2, ft4, ft5, local_tbl WHERE ft1.c1 = ft2.c1 AND ft1.c2 = ft4.c1
+    AND ft1.c2 = ft5.c1 AND ft1.c2 = local_tbl.c1 AND ft1.c1 < 100 AND ft2.c1 < 100 FOR UPDATE;
+                                                                                                                                                                                                                                                                                                                                                                                                                                               QUERY PLAN                                                                                                                                                                                                                                                                                                                                                                                                                                               
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ LockRows
+   Output: ft1.c1, ft1.c2, ft1.c3, ft1.c4, ft1.c5, ft1.c6, ft1.c7, ft1.c8, ft2.c1, ft2.c2, ft2.c3, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft4.c1, ft4.c2, ft4.c3, ft5.c1, ft5.c2, ft5.c3, local_tbl.c1, local_tbl.c2, local_tbl.c3, ft1.*, ft2.*, ft4.*, ft5.*, local_tbl.ctid
+   ->  Merge Join
+         Output: ft1.c1, ft1.c2, ft1.c3, ft1.c4, ft1.c5, ft1.c6, ft1.c7, ft1.c8, ft2.c1, ft2.c2, ft2.c3, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft4.c1, ft4.c2, ft4.c3, ft5.c1, ft5.c2, ft5.c3, local_tbl.c1, local_tbl.c2, local_tbl.c3, ft1.*, ft2.*, ft4.*, ft5.*, local_tbl.ctid
+         Inner Unique: true
+         Merge Cond: (ft1.c2 = local_tbl.c1)
+         ->  Foreign Scan
+               Output: ft1.c1, ft1.c2, ft1.c3, ft1.c4, ft1.c5, ft1.c6, ft1.c7, ft1.c8, ft1.*, ft2.c1, ft2.c2, ft2.c3, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft2.*, ft4.c1, ft4.c2, ft4.c3, ft4.*, ft5.c1, ft5.c2, ft5.c3, ft5.*
+               Relations: (((public.ft1) INNER JOIN (public.ft2)) INNER JOIN (public.ft4)) INNER JOIN (public.ft5)
+               Remote SQL: SELECT r1."C 1", r1.c2, r1.c3, r1.c4, r1.c5, r1.c6, r1.c7, r1.c8, CASE WHEN (r1.*)::text IS NOT NULL THEN ROW(r1."C 1", r1.c2, r1.c3, r1.c4, r1.c5, r1.c6, r1.c7, r1.c8) END, r2."C 1", r2.c2, r2.c3, r2.c4, r2.c5, r2.c6, r2.c7, r2.c8, CASE WHEN (r2.*)::text IS NOT NULL THEN ROW(r2."C 1", r2.c2, r2.c3, r2.c4, r2.c5, r2.c6, r2.c7, r2.c8) END, r3.c1, r3.c2, r3.c3, CASE WHEN (r3.*)::text IS NOT NULL THEN ROW(r3.c1, r3.c2, r3.c3) END, r4.c1, r4.c2, r4.c3, CASE WHEN (r4.*)::text IS NOT NULL THEN ROW(r4.c1, r4.c2, r4.c3) END FROM ((("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1")) AND ((r2."C 1" < 100)) AND ((r1."C 1" < 100)))) INNER JOIN "S 1"."T 3" r3 ON (((r1.c2 = r3.c1)))) INNER JOIN "S 1"."T 4" r4 ON (((r1.c2 = r4.c1)))) ORDER BY r1.c2 ASC NULLS LAST FOR UPDATE OF r1 FOR UPDATE OF r2 FOR UPDATE OF r3 FOR UPDATE OF r4
+               ->  Merge Join
+                     Output: ft1.c1, ft1.c2, ft1.c3, ft1.c4, ft1.c5, ft1.c6, ft1.c7, ft1.c8, ft1.*, ft2.c1, ft2.c2, ft2.c3, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft2.*, ft4.c1, ft4.c2, ft4.c3, ft4.*, ft5.c1, ft5.c2, ft5.c3, ft5.*
+                     Merge Cond: (ft1.c2 = ft5.c1)
+                     ->  Merge Join
+                           Output: ft1.c1, ft1.c2, ft1.c3, ft1.c4, ft1.c5, ft1.c6, ft1.c7, ft1.c8, ft1.*, ft2.c1, ft2.c2, ft2.c3, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft2.*, ft4.c1, ft4.c2, ft4.c3, ft4.*
+                           Merge Cond: (ft1.c2 = ft4.c1)
+                           ->  Sort
+                                 Output: ft1.c1, ft1.c2, ft1.c3, ft1.c4, ft1.c5, ft1.c6, ft1.c7, ft1.c8, ft1.*, ft2.c1, ft2.c2, ft2.c3, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft2.*
+                                 Sort Key: ft1.c2
+                                 ->  Merge Join
+                                       Output: ft1.c1, ft1.c2, ft1.c3, ft1.c4, ft1.c5, ft1.c6, ft1.c7, ft1.c8, ft1.*, ft2.c1, ft2.c2, ft2.c3, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft2.*
+                                       Merge Cond: (ft1.c1 = ft2.c1)
+                                       ->  Sort
+                                             Output: ft1.c1, ft1.c2, ft1.c3, ft1.c4, ft1.c5, ft1.c6, ft1.c7, ft1.c8, ft1.*
+                                             Sort Key: ft1.c1
+                                             ->  Foreign Scan on public.ft1
+                                                   Output: ft1.c1, ft1.c2, ft1.c3, ft1.c4, ft1.c5, ft1.c6, ft1.c7, ft1.c8, ft1.*
+                                                   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" < 100)) FOR UPDATE
+                                       ->  Materialize
+                                             Output: ft2.c1, ft2.c2, ft2.c3, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft2.*
+                                             ->  Foreign Scan on public.ft2
+                                                   Output: ft2.c1, ft2.c2, ft2.c3, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft2.*
+                                                   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" < 100)) ORDER BY "C 1" ASC NULLS LAST FOR UPDATE
+                           ->  Sort
+                                 Output: ft4.c1, ft4.c2, ft4.c3, ft4.*
+                                 Sort Key: ft4.c1
+                                 ->  Foreign Scan on public.ft4
+                                       Output: ft4.c1, ft4.c2, ft4.c3, ft4.*
+                                       Remote SQL: SELECT c1, c2, c3 FROM "S 1"."T 3" FOR UPDATE
+                     ->  Sort
+                           Output: ft5.c1, ft5.c2, ft5.c3, ft5.*
+                           Sort Key: ft5.c1
+                           ->  Foreign Scan on public.ft5
+                                 Output: ft5.c1, ft5.c2, ft5.c3, ft5.*
+                                 Remote SQL: SELECT c1, c2, c3 FROM "S 1"."T 4" FOR UPDATE
+         ->  Index Scan using local_tbl_pkey on public.local_tbl
+               Output: local_tbl.c1, local_tbl.c2, local_tbl.c3, local_tbl.ctid
+(47 rows)
+
+SELECT * FROM ft1, ft2, ft4, ft5, local_tbl WHERE ft1.c1 = ft2.c1 AND ft1.c2 = ft4.c1
+    AND ft1.c2 = ft5.c1 AND ft1.c2 = local_tbl.c1 AND ft1.c1 < 100 AND ft2.c1 < 100 FOR UPDATE;
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  | c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  | c1 | c2 |   c3   | c1 | c2 |   c3   | c1 | c2 |  c3  
+----+----+-------+------------------------------+--------------------------+----+------------+-----+----+----+-------+------------------------------+--------------------------+----+------------+-----+----+----+--------+----+----+--------+----+----+------
+  6 |  6 | 00006 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo |  6 |  6 | 00006 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo |  6 |  7 | AAA006 |  6 |  7 | AAA006 |  6 |  6 | 0006
+ 16 |  6 | 00016 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo | 16 |  6 | 00016 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo |  6 |  7 | AAA006 |  6 |  7 | AAA006 |  6 |  6 | 0006
+ 26 |  6 | 00026 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo | 26 |  6 | 00026 | Tue Jan 27 00:00:00 1970 PST | Tue Jan 27 00:00:00 1970 | 6  | 6          | foo |  6 |  7 | AAA006 |  6 |  7 | AAA006 |  6 |  6 | 0006
+ 36 |  6 | 00036 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo | 36 |  6 | 00036 | Fri Feb 06 00:00:00 1970 PST | Fri Feb 06 00:00:00 1970 | 6  | 6          | foo |  6 |  7 | AAA006 |  6 |  7 | AAA006 |  6 |  6 | 0006
+ 46 |  6 | 00046 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo | 46 |  6 | 00046 | Mon Feb 16 00:00:00 1970 PST | Mon Feb 16 00:00:00 1970 | 6  | 6          | foo |  6 |  7 | AAA006 |  6 |  7 | AAA006 |  6 |  6 | 0006
+ 56 |  6 | 00056 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo | 56 |  6 | 00056 | Thu Feb 26 00:00:00 1970 PST | Thu Feb 26 00:00:00 1970 | 6  | 6          | foo |  6 |  7 | AAA006 |  6 |  7 | AAA006 |  6 |  6 | 0006
+ 66 |  6 | 00066 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo | 66 |  6 | 00066 | Sun Mar 08 00:00:00 1970 PST | Sun Mar 08 00:00:00 1970 | 6  | 6          | foo |  6 |  7 | AAA006 |  6 |  7 | AAA006 |  6 |  6 | 0006
+ 76 |  6 | 00076 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo | 76 |  6 | 00076 | Wed Mar 18 00:00:00 1970 PST | Wed Mar 18 00:00:00 1970 | 6  | 6          | foo |  6 |  7 | AAA006 |  6 |  7 | AAA006 |  6 |  6 | 0006
+ 86 |  6 | 00086 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo | 86 |  6 | 00086 | Sat Mar 28 00:00:00 1970 PST | Sat Mar 28 00:00:00 1970 | 6  | 6          | foo |  6 |  7 | AAA006 |  6 |  7 | AAA006 |  6 |  6 | 0006
+ 96 |  6 | 00096 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo | 96 |  6 | 00096 | Tue Apr 07 00:00:00 1970 PST | Tue Apr 07 00:00:00 1970 | 6  | 6          | foo |  6 |  7 | AAA006 |  6 |  7 | AAA006 |  6 |  6 | 0006
+(10 rows)
+
+RESET enable_nestloop;
+RESET enable_hashjoin;
+DROP TABLE local_tbl;
+-- check join pushdown in situations where multiple userids are involved
+CREATE ROLE regress_view_owner SUPERUSER;
+CREATE USER MAPPING FOR regress_view_owner SERVER loopback;
+GRANT SELECT ON ft4 TO regress_view_owner;
+GRANT SELECT ON ft5 TO regress_view_owner;
+CREATE VIEW v4 AS SELECT * FROM ft4;
+CREATE VIEW v5 AS SELECT * FROM ft5;
+ALTER VIEW v5 OWNER TO regress_view_owner;
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2 FROM v4 t1 LEFT JOIN v5 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 10 LIMIT 10;  -- can't be pushed down, different view owners
+                              QUERY PLAN                              
+----------------------------------------------------------------------
+ Limit
+   Output: ft4.c1, ft5.c2, ft5.c1
+   ->  Sort
+         Output: ft4.c1, ft5.c2, ft5.c1
+         Sort Key: ft4.c1, ft5.c1
+         ->  Hash Left Join
+               Output: ft4.c1, ft5.c2, ft5.c1
+               Hash Cond: (ft4.c1 = ft5.c1)
+               ->  Foreign Scan on public.ft4
+                     Output: ft4.c1, ft4.c2, ft4.c3
+                     Remote SQL: SELECT c1 FROM "S 1"."T 3"
+               ->  Hash
+                     Output: ft5.c2, ft5.c1
+                     ->  Foreign Scan on public.ft5
+                           Output: ft5.c2, ft5.c1
+                           Remote SQL: SELECT c1, c2 FROM "S 1"."T 4"
+(16 rows)
+
+SELECT t1.c1, t2.c2 FROM v4 t1 LEFT JOIN v5 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 10 LIMIT 10;
+ c1 | c2 
+----+----
+ 22 |   
+ 24 | 25
+ 26 |   
+ 28 |   
+ 30 | 31
+ 32 |   
+ 34 |   
+ 36 | 37
+ 38 |   
+ 40 |   
+(10 rows)
+
+ALTER VIEW v4 OWNER TO regress_view_owner;
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2 FROM v4 t1 LEFT JOIN v5 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 10 LIMIT 10;  -- can be pushed down
+                                                                                              QUERY PLAN                                                                                               
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: ft4.c1, ft5.c2, ft5.c1
+   Relations: (public.ft4) LEFT JOIN (public.ft5)
+   Remote SQL: SELECT r6.c1, r9.c2, r9.c1 FROM ("S 1"."T 3" r6 LEFT JOIN "S 1"."T 4" r9 ON (((r6.c1 = r9.c1)))) ORDER BY r6.c1 ASC NULLS LAST, r9.c1 ASC NULLS LAST LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c2 FROM v4 t1 LEFT JOIN v5 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 10 LIMIT 10;
+ c1 | c2 
+----+----
+ 22 |   
+ 24 | 25
+ 26 |   
+ 28 |   
+ 30 | 31
+ 32 |   
+ 34 |   
+ 36 | 37
+ 38 |   
+ 40 |   
+(10 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2 FROM v4 t1 LEFT JOIN ft5 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 10 LIMIT 10;  -- can't be pushed down, view owner not current user
+                              QUERY PLAN                              
+----------------------------------------------------------------------
+ Limit
+   Output: ft4.c1, t2.c2, t2.c1
+   ->  Sort
+         Output: ft4.c1, t2.c2, t2.c1
+         Sort Key: ft4.c1, t2.c1
+         ->  Hash Left Join
+               Output: ft4.c1, t2.c2, t2.c1
+               Hash Cond: (ft4.c1 = t2.c1)
+               ->  Foreign Scan on public.ft4
+                     Output: ft4.c1, ft4.c2, ft4.c3
+                     Remote SQL: SELECT c1 FROM "S 1"."T 3"
+               ->  Hash
+                     Output: t2.c2, t2.c1
+                     ->  Foreign Scan on public.ft5 t2
+                           Output: t2.c2, t2.c1
+                           Remote SQL: SELECT c1, c2 FROM "S 1"."T 4"
+(16 rows)
+
+SELECT t1.c1, t2.c2 FROM v4 t1 LEFT JOIN ft5 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 10 LIMIT 10;
+ c1 | c2 
+----+----
+ 22 |   
+ 24 | 25
+ 26 |   
+ 28 |   
+ 30 | 31
+ 32 |   
+ 34 |   
+ 36 | 37
+ 38 |   
+ 40 |   
+(10 rows)
+
+ALTER VIEW v4 OWNER TO CURRENT_USER;
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.c1, t2.c2 FROM v4 t1 LEFT JOIN ft5 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 10 LIMIT 10;  -- can be pushed down
+                                                                                              QUERY PLAN                                                                                               
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: ft4.c1, t2.c2, t2.c1
+   Relations: (public.ft4) LEFT JOIN (public.ft5 t2)
+   Remote SQL: SELECT r6.c1, r2.c2, r2.c1 FROM ("S 1"."T 3" r6 LEFT JOIN "S 1"."T 4" r2 ON (((r6.c1 = r2.c1)))) ORDER BY r6.c1 ASC NULLS LAST, r2.c1 ASC NULLS LAST LIMIT 10::bigint OFFSET 10::bigint
+(4 rows)
+
+SELECT t1.c1, t2.c2 FROM v4 t1 LEFT JOIN ft5 t2 ON (t1.c1 = t2.c1) ORDER BY t1.c1, t2.c1 OFFSET 10 LIMIT 10;
+ c1 | c2 
+----+----
+ 22 |   
+ 24 | 25
+ 26 |   
+ 28 |   
+ 30 | 31
+ 32 |   
+ 34 |   
+ 36 | 37
+ 38 |   
+ 40 |   
+(10 rows)
+
+ALTER VIEW v4 OWNER TO regress_view_owner;
+-- cleanup
+DROP OWNED BY regress_view_owner;
+DROP ROLE regress_view_owner;
+-- ===================================================================
+-- Aggregate and grouping queries
+-- ===================================================================
+-- Simple aggregates
+explain (verbose, costs off)
+select count(c6), sum(c1), avg(c1), min(c2), max(c1), stddev(c2), sum(c1) * (random() <= 1)::int as sum2 from ft1 where c2 < 5 group by c2 order by 1, 2;
+                                                                                              QUERY PLAN                                                                                               
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (count(c6)), (sum(c1)), (avg(c1)), (min(c2)), (max(c1)), (stddev(c2)), ((sum(c1)) * ((random() <= '1'::double precision))::integer), c2
+   Relations: Aggregate on (public.ft1)
+   Remote SQL: SELECT count(c6), sum("C 1"), avg("C 1"), min(c2), max("C 1"), stddev(c2), c2 FROM "S 1"."T 1" WHERE ((c2 < 5)) GROUP BY 7 ORDER BY count(c6) ASC NULLS LAST, sum("C 1") ASC NULLS LAST
+(4 rows)
+
+select count(c6), sum(c1), avg(c1), min(c2), max(c1), stddev(c2), sum(c1) * (random() <= 1)::int as sum2 from ft1 where c2 < 5 group by c2 order by 1, 2;
+ count |  sum  |         avg          | min | max  | stddev | sum2  
+-------+-------+----------------------+-----+------+--------+-------
+   100 | 49600 | 496.0000000000000000 |   1 |  991 |      0 | 49600
+   100 | 49700 | 497.0000000000000000 |   2 |  992 |      0 | 49700
+   100 | 49800 | 498.0000000000000000 |   3 |  993 |      0 | 49800
+   100 | 49900 | 499.0000000000000000 |   4 |  994 |      0 | 49900
+   100 | 50500 | 505.0000000000000000 |   0 | 1000 |      0 | 50500
+(5 rows)
+
+explain (verbose, costs off)
+select count(c6), sum(c1), avg(c1), min(c2), max(c1), stddev(c2), sum(c1) * (random() <= 1)::int as sum2 from ft1 where c2 < 5 group by c2 order by 1, 2 limit 1;
+                                                                                                      QUERY PLAN                                                                                                       
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (count(c6)), (sum(c1)), (avg(c1)), (min(c2)), (max(c1)), (stddev(c2)), ((sum(c1)) * ((random() <= '1'::double precision))::integer), c2
+   Relations: Aggregate on (public.ft1)
+   Remote SQL: SELECT count(c6), sum("C 1"), avg("C 1"), min(c2), max("C 1"), stddev(c2), c2 FROM "S 1"."T 1" WHERE ((c2 < 5)) GROUP BY 7 ORDER BY count(c6) ASC NULLS LAST, sum("C 1") ASC NULLS LAST LIMIT 1::bigint
+(4 rows)
+
+select count(c6), sum(c1), avg(c1), min(c2), max(c1), stddev(c2), sum(c1) * (random() <= 1)::int as sum2 from ft1 where c2 < 5 group by c2 order by 1, 2 limit 1;
+ count |  sum  |         avg          | min | max | stddev | sum2  
+-------+-------+----------------------+-----+-----+--------+-------
+   100 | 49600 | 496.0000000000000000 |   1 | 991 |      0 | 49600
+(1 row)
+
+-- Aggregate is not pushed down as aggregation contains random()
+explain (verbose, costs off)
+select sum(c1 * (random() <= 1)::int) as sum, avg(c1) from ft1;
+                                  QUERY PLAN                                   
+-------------------------------------------------------------------------------
+ Aggregate
+   Output: sum((c1 * ((random() <= '1'::double precision))::integer)), avg(c1)
+   ->  Foreign Scan on public.ft1
+         Output: c1
+         Remote SQL: SELECT "C 1" FROM "S 1"."T 1"
+(5 rows)
+
+-- Aggregate over join query
+explain (verbose, costs off)
+select count(*), sum(t1.c1), avg(t2.c1) from ft1 t1 inner join ft1 t2 on (t1.c2 = t2.c2) where t1.c2 = 6;
+                                                                    QUERY PLAN                                                                    
+--------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (count(*)), (sum(t1.c1)), (avg(t2.c1))
+   Relations: Aggregate on ((public.ft1 t1) INNER JOIN (public.ft1 t2))
+   Remote SQL: SELECT count(*), sum(r1."C 1"), avg(r2."C 1") FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r2.c2 = 6)) AND ((r1.c2 = 6))))
+(4 rows)
+
+select count(*), sum(t1.c1), avg(t2.c1) from ft1 t1 inner join ft1 t2 on (t1.c2 = t2.c2) where t1.c2 = 6;
+ count |   sum   |         avg          
+-------+---------+----------------------
+ 10000 | 5010000 | 501.0000000000000000
+(1 row)
+
+-- Not pushed down due to local conditions present in underneath input rel
+explain (verbose, costs off)
+select sum(t1.c1), count(t2.c1) from ft1 t1 inner join ft2 t2 on (t1.c1 = t2.c1) where ((t1.c1 * t2.c1)/(t1.c1 * t2.c1)) * random() <= 1;
+                                                         QUERY PLAN                                                         
+----------------------------------------------------------------------------------------------------------------------------
+ Aggregate
+   Output: sum(t1.c1), count(t2.c1)
+   ->  Foreign Scan
+         Output: t1.c1, t2.c1
+         Filter: (((((t1.c1 * t2.c1) / (t1.c1 * t2.c1)))::double precision * random()) <= '1'::double precision)
+         Relations: (public.ft1 t1) INNER JOIN (public.ft2 t2)
+         Remote SQL: SELECT r1."C 1", r2."C 1" FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r1."C 1" = r2."C 1"))))
+(7 rows)
+
+-- GROUP BY clause having expressions
+explain (verbose, costs off)
+select c2/2, sum(c2) * (c2/2) from ft1 group by c2/2 order by c2/2;
+                                                    QUERY PLAN                                                    
+------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: ((c2 / 2)), ((sum(c2) * (c2 / 2)))
+   Relations: Aggregate on (public.ft1)
+   Remote SQL: SELECT (c2 / 2), (sum(c2) * (c2 / 2)) FROM "S 1"."T 1" GROUP BY 1 ORDER BY (c2 / 2) ASC NULLS LAST
+(4 rows)
+
+select c2/2, sum(c2) * (c2/2) from ft1 group by c2/2 order by c2/2;
+ ?column? | ?column? 
+----------+----------
+        0 |        0
+        1 |      500
+        2 |     1800
+        3 |     3900
+        4 |     6800
+(5 rows)
+
+-- Aggregates in subquery are pushed down.
+explain (verbose, costs off)
+select count(x.a), sum(x.a) from (select c2 a, sum(c1) b from ft1 group by c2, sqrt(c1) order by 1, 2) x;
+                                                                 QUERY PLAN                                                                  
+---------------------------------------------------------------------------------------------------------------------------------------------
+ Aggregate
+   Output: count(ft1.c2), sum(ft1.c2)
+   ->  Foreign Scan
+         Output: ft1.c2, (sum(ft1.c1)), (sqrt((ft1.c1)::double precision))
+         Relations: Aggregate on (public.ft1)
+         Remote SQL: SELECT c2, sum("C 1"), sqrt("C 1") FROM "S 1"."T 1" GROUP BY 1, 3 ORDER BY c2 ASC NULLS LAST, sum("C 1") ASC NULLS LAST
+(6 rows)
+
+select count(x.a), sum(x.a) from (select c2 a, sum(c1) b from ft1 group by c2, sqrt(c1) order by 1, 2) x;
+ count | sum  
+-------+------
+  1000 | 4500
+(1 row)
+
+-- Aggregate is still pushed down by taking unshippable expression out
+explain (verbose, costs off)
+select c2 * (random() <= 1)::int as sum1, sum(c1) * c2 as sum2 from ft1 group by c2 order by 1, 2;
+                                            QUERY PLAN                                             
+---------------------------------------------------------------------------------------------------
+ Sort
+   Output: ((c2 * ((random() <= '1'::double precision))::integer)), ((sum(c1) * c2)), c2
+   Sort Key: ((ft1.c2 * ((random() <= '1'::double precision))::integer)), ((sum(ft1.c1) * ft1.c2))
+   ->  Foreign Scan
+         Output: (c2 * ((random() <= '1'::double precision))::integer), ((sum(c1) * c2)), c2
+         Relations: Aggregate on (public.ft1)
+         Remote SQL: SELECT (sum("C 1") * c2), c2 FROM "S 1"."T 1" GROUP BY 2
+(7 rows)
+
+select c2 * (random() <= 1)::int as sum1, sum(c1) * c2 as sum2 from ft1 group by c2 order by 1, 2;
+ sum1 |  sum2  
+------+--------
+    0 |      0
+    1 |  49600
+    2 |  99400
+    3 | 149400
+    4 | 199600
+    5 | 250000
+    6 | 300600
+    7 | 351400
+    8 | 402400
+    9 | 453600
+(10 rows)
+
+-- Aggregate with unshippable GROUP BY clause are not pushed
+explain (verbose, costs off)
+select c2 * (random() <= 1)::int as c2 from ft2 group by c2 * (random() <= 1)::int order by 1;
+                                  QUERY PLAN                                  
+------------------------------------------------------------------------------
+ Sort
+   Output: ((c2 * ((random() <= '1'::double precision))::integer))
+   Sort Key: ((ft2.c2 * ((random() <= '1'::double precision))::integer))
+   ->  HashAggregate
+         Output: ((c2 * ((random() <= '1'::double precision))::integer))
+         Group Key: (ft2.c2 * ((random() <= '1'::double precision))::integer)
+         ->  Foreign Scan on public.ft2
+               Output: (c2 * ((random() <= '1'::double precision))::integer)
+               Remote SQL: SELECT c2 FROM "S 1"."T 1"
+(9 rows)
+
+-- GROUP BY clause in various forms, cardinal, alias and constant expression
+explain (verbose, costs off)
+select count(c2) w, c2 x, 5 y, 7.0 z from ft1 group by 2, y, 9.0::int order by 2;
+                                                 QUERY PLAN                                                 
+------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (count(c2)), c2, 5, 7.0, 9
+   Relations: Aggregate on (public.ft1)
+   Remote SQL: SELECT count(c2), c2, 5, 7.0, 9 FROM "S 1"."T 1" GROUP BY 2, 3, 5 ORDER BY c2 ASC NULLS LAST
+(4 rows)
+
+select count(c2) w, c2 x, 5 y, 7.0 z from ft1 group by 2, y, 9.0::int order by 2;
+  w  | x | y |  z  
+-----+---+---+-----
+ 100 | 0 | 5 | 7.0
+ 100 | 1 | 5 | 7.0
+ 100 | 2 | 5 | 7.0
+ 100 | 3 | 5 | 7.0
+ 100 | 4 | 5 | 7.0
+ 100 | 5 | 5 | 7.0
+ 100 | 6 | 5 | 7.0
+ 100 | 7 | 5 | 7.0
+ 100 | 8 | 5 | 7.0
+ 100 | 9 | 5 | 7.0
+(10 rows)
+
+-- GROUP BY clause referring to same column multiple times
+-- Also, ORDER BY contains an aggregate function
+explain (verbose, costs off)
+select c2, c2 from ft1 where c2 > 6 group by 1, 2 order by sum(c1);
+                                                         QUERY PLAN                                                         
+----------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: c2, c2, (sum(c1))
+   Relations: Aggregate on (public.ft1)
+   Remote SQL: SELECT c2, c2, sum("C 1") FROM "S 1"."T 1" WHERE ((c2 > 6)) GROUP BY 1, 2 ORDER BY sum("C 1") ASC NULLS LAST
+(4 rows)
+
+select c2, c2 from ft1 where c2 > 6 group by 1, 2 order by sum(c1);
+ c2 | c2 
+----+----
+  7 |  7
+  8 |  8
+  9 |  9
+(3 rows)
+
+-- Testing HAVING clause shippability
+explain (verbose, costs off)
+select c2, sum(c1) from ft2 group by c2 having avg(c1) < 500 and sum(c1) < 49800 order by c2;
+                                                                         QUERY PLAN                                                                         
+------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: c2, (sum(c1))
+   Relations: Aggregate on (public.ft2)
+   Remote SQL: SELECT c2, sum("C 1") FROM "S 1"."T 1" GROUP BY 1 HAVING ((avg("C 1") < 500::numeric)) AND ((sum("C 1") < 49800)) ORDER BY c2 ASC NULLS LAST
+(4 rows)
+
+select c2, sum(c1) from ft2 group by c2 having avg(c1) < 500 and sum(c1) < 49800 order by c2;
+ c2 |  sum  
+----+-------
+  1 | 49600
+  2 | 49700
+(2 rows)
+
+-- Unshippable HAVING clause will be evaluated locally, and other qual in HAVING clause is pushed down
+explain (verbose, costs off)
+select count(*) from (select c5, count(c1) from ft1 group by c5, sqrt(c2) having (avg(c1) / avg(c1)) * random() <= 1 and avg(c1) < 500) x;
+                                                              QUERY PLAN                                                               
+---------------------------------------------------------------------------------------------------------------------------------------
+ Aggregate
+   Output: count(*)
+   ->  Foreign Scan
+         Output: ft1.c5, NULL::bigint, (sqrt((ft1.c2)::double precision))
+         Filter: (((((avg(ft1.c1)) / (avg(ft1.c1))))::double precision * random()) <= '1'::double precision)
+         Relations: Aggregate on (public.ft1)
+         Remote SQL: SELECT c5, NULL::bigint, sqrt(c2), avg("C 1") FROM "S 1"."T 1" GROUP BY 1, 3 HAVING ((avg("C 1") < 500::numeric))
+(7 rows)
+
+select count(*) from (select c5, count(c1) from ft1 group by c5, sqrt(c2) having (avg(c1) / avg(c1)) * random() <= 1 and avg(c1) < 500) x;
+ count 
+-------
+    49
+(1 row)
+
+-- Aggregate in HAVING clause is not pushable, and thus aggregation is not pushed down
+explain (verbose, costs off)
+select sum(c1) from ft1 group by c2 having avg(c1 * (random() <= 1)::int) > 100 order by 1;
+                                            QUERY PLAN                                             
+---------------------------------------------------------------------------------------------------
+ Sort
+   Output: (sum(c1)), c2
+   Sort Key: (sum(ft1.c1))
+   ->  HashAggregate
+         Output: sum(c1), c2
+         Group Key: ft1.c2
+         Filter: (avg((ft1.c1 * ((random() <= '1'::double precision))::integer)) > '100'::numeric)
+         ->  Foreign Scan on public.ft1
+               Output: c1, c2
+               Remote SQL: SELECT "C 1", c2 FROM "S 1"."T 1"
+(10 rows)
+
+-- Testing ORDER BY, DISTINCT, FILTER, Ordered-sets and VARIADIC within aggregates
+-- ORDER BY within aggregate, same column used to order
+explain (verbose, costs off)
+select array_agg(c1 order by c1) from ft1 where c1 < 100 group by c2 order by 1;
+                                                                                            QUERY PLAN                                                                                            
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (array_agg(c1 ORDER BY c1)), c2
+   Relations: Aggregate on (public.ft1)
+   Remote SQL: SELECT array_agg("C 1" ORDER BY "C 1" ASC NULLS LAST), c2 FROM "S 1"."T 1" WHERE (("C 1" < 100)) GROUP BY 2 ORDER BY array_agg("C 1" ORDER BY "C 1" ASC NULLS LAST) ASC NULLS LAST
+(4 rows)
+
+select array_agg(c1 order by c1) from ft1 where c1 < 100 group by c2 order by 1;
+           array_agg            
+--------------------------------
+ {1,11,21,31,41,51,61,71,81,91}
+ {2,12,22,32,42,52,62,72,82,92}
+ {3,13,23,33,43,53,63,73,83,93}
+ {4,14,24,34,44,54,64,74,84,94}
+ {5,15,25,35,45,55,65,75,85,95}
+ {6,16,26,36,46,56,66,76,86,96}
+ {7,17,27,37,47,57,67,77,87,97}
+ {8,18,28,38,48,58,68,78,88,98}
+ {9,19,29,39,49,59,69,79,89,99}
+ {10,20,30,40,50,60,70,80,90}
+(10 rows)
+
+-- ORDER BY within aggregate, different column used to order also using DESC
+explain (verbose, costs off)
+select array_agg(c5 order by c1 desc) from ft2 where c2 = 6 and c1 < 50;
+                                                       QUERY PLAN                                                        
+-------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (array_agg(c5 ORDER BY c1 DESC))
+   Relations: Aggregate on (public.ft2)
+   Remote SQL: SELECT array_agg(c5 ORDER BY "C 1" DESC NULLS FIRST) FROM "S 1"."T 1" WHERE (("C 1" < 50)) AND ((c2 = 6))
+(4 rows)
+
+select array_agg(c5 order by c1 desc) from ft2 where c2 = 6 and c1 < 50;
+                                                                array_agg                                                                 
+------------------------------------------------------------------------------------------------------------------------------------------
+ {"Mon Feb 16 00:00:00 1970","Fri Feb 06 00:00:00 1970","Tue Jan 27 00:00:00 1970","Sat Jan 17 00:00:00 1970","Wed Jan 07 00:00:00 1970"}
+(1 row)
+
+-- DISTINCT within aggregate
+explain (verbose, costs off)
+select array_agg(distinct (t1.c1)%5) from ft4 t1 full join ft5 t2 on (t1.c1 = t2.c1) where t1.c1 < 20 or (t1.c1 is null and t2.c1 < 5) group by (t2.c1)%3 order by 1;
+                                                                                                                               QUERY PLAN                                                                                                                               
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (array_agg(DISTINCT (t1.c1 % 5))), ((t2.c1 % 3))
+   Relations: Aggregate on ((public.ft4 t1) FULL JOIN (public.ft5 t2))
+   Remote SQL: SELECT array_agg(DISTINCT (r1.c1 % 5)), (r2.c1 % 3) FROM ("S 1"."T 3" r1 FULL JOIN "S 1"."T 4" r2 ON (((r1.c1 = r2.c1)))) WHERE (((r1.c1 < 20) OR ((r1.c1 IS NULL) AND (r2.c1 < 5)))) GROUP BY 2 ORDER BY array_agg(DISTINCT (r1.c1 % 5)) ASC NULLS LAST
+(4 rows)
+
+select array_agg(distinct (t1.c1)%5) from ft4 t1 full join ft5 t2 on (t1.c1 = t2.c1) where t1.c1 < 20 or (t1.c1 is null and t2.c1 < 5) group by (t2.c1)%3 order by 1;
+  array_agg   
+--------------
+ {0,1,2,3,4}
+ {1,2,3,NULL}
+(2 rows)
+
+-- DISTINCT combined with ORDER BY within aggregate
+explain (verbose, costs off)
+select array_agg(distinct (t1.c1)%5 order by (t1.c1)%5) from ft4 t1 full join ft5 t2 on (t1.c1 = t2.c1) where t1.c1 < 20 or (t1.c1 is null and t2.c1 < 5) group by (t2.c1)%3 order by 1;
+                                                                                                                                                                     QUERY PLAN                                                                                                                                                                     
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (array_agg(DISTINCT (t1.c1 % 5) ORDER BY (t1.c1 % 5))), ((t2.c1 % 3))
+   Relations: Aggregate on ((public.ft4 t1) FULL JOIN (public.ft5 t2))
+   Remote SQL: SELECT array_agg(DISTINCT (r1.c1 % 5) ORDER BY ((r1.c1 % 5)) ASC NULLS LAST), (r2.c1 % 3) FROM ("S 1"."T 3" r1 FULL JOIN "S 1"."T 4" r2 ON (((r1.c1 = r2.c1)))) WHERE (((r1.c1 < 20) OR ((r1.c1 IS NULL) AND (r2.c1 < 5)))) GROUP BY 2 ORDER BY array_agg(DISTINCT (r1.c1 % 5) ORDER BY ((r1.c1 % 5)) ASC NULLS LAST) ASC NULLS LAST
+(4 rows)
+
+select array_agg(distinct (t1.c1)%5 order by (t1.c1)%5) from ft4 t1 full join ft5 t2 on (t1.c1 = t2.c1) where t1.c1 < 20 or (t1.c1 is null and t2.c1 < 5) group by (t2.c1)%3 order by 1;
+  array_agg   
+--------------
+ {0,1,2,3,4}
+ {1,2,3,NULL}
+(2 rows)
+
+explain (verbose, costs off)
+select array_agg(distinct (t1.c1)%5 order by (t1.c1)%5 desc nulls last) from ft4 t1 full join ft5 t2 on (t1.c1 = t2.c1) where t1.c1 < 20 or (t1.c1 is null and t2.c1 < 5) group by (t2.c1)%3 order by 1;
+                                                                                                                                                                      QUERY PLAN                                                                                                                                                                      
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (array_agg(DISTINCT (t1.c1 % 5) ORDER BY (t1.c1 % 5) DESC NULLS LAST)), ((t2.c1 % 3))
+   Relations: Aggregate on ((public.ft4 t1) FULL JOIN (public.ft5 t2))
+   Remote SQL: SELECT array_agg(DISTINCT (r1.c1 % 5) ORDER BY ((r1.c1 % 5)) DESC NULLS LAST), (r2.c1 % 3) FROM ("S 1"."T 3" r1 FULL JOIN "S 1"."T 4" r2 ON (((r1.c1 = r2.c1)))) WHERE (((r1.c1 < 20) OR ((r1.c1 IS NULL) AND (r2.c1 < 5)))) GROUP BY 2 ORDER BY array_agg(DISTINCT (r1.c1 % 5) ORDER BY ((r1.c1 % 5)) DESC NULLS LAST) ASC NULLS LAST
+(4 rows)
+
+select array_agg(distinct (t1.c1)%5 order by (t1.c1)%5 desc nulls last) from ft4 t1 full join ft5 t2 on (t1.c1 = t2.c1) where t1.c1 < 20 or (t1.c1 is null and t2.c1 < 5) group by (t2.c1)%3 order by 1;
+  array_agg   
+--------------
+ {3,2,1,NULL}
+ {4,3,2,1,0}
+(2 rows)
+
+-- FILTER within aggregate
+explain (verbose, costs off)
+select sum(c1) filter (where c1 < 100 and c2 > 5) from ft1 group by c2 order by 1 nulls last;
+                                                                                         QUERY PLAN                                                                                         
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (sum(c1) FILTER (WHERE ((c1 < 100) AND (c2 > 5)))), c2
+   Relations: Aggregate on (public.ft1)
+   Remote SQL: SELECT sum("C 1") FILTER (WHERE (("C 1" < 100) AND (c2 > 5))), c2 FROM "S 1"."T 1" GROUP BY 2 ORDER BY sum("C 1") FILTER (WHERE (("C 1" < 100) AND (c2 > 5))) ASC NULLS LAST
+(4 rows)
+
+select sum(c1) filter (where c1 < 100 and c2 > 5) from ft1 group by c2 order by 1 nulls last;
+ sum 
+-----
+ 510
+ 520
+ 530
+ 540
+    
+    
+    
+    
+    
+    
+(10 rows)
+
+-- DISTINCT, ORDER BY and FILTER within aggregate
+explain (verbose, costs off)
+select sum(c1%3), sum(distinct c1%3 order by c1%3) filter (where c1%3 < 2), c2 from ft1 where c2 = 6 group by c2;
+                                                                                        QUERY PLAN                                                                                        
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (sum((c1 % 3))), (sum(DISTINCT (c1 % 3) ORDER BY (c1 % 3)) FILTER (WHERE ((c1 % 3) < 2))), c2
+   Relations: Aggregate on (public.ft1)
+   Remote SQL: SELECT sum(("C 1" % 3)), sum(DISTINCT ("C 1" % 3) ORDER BY (("C 1" % 3)) ASC NULLS LAST) FILTER (WHERE (("C 1" % 3) < 2)), c2 FROM "S 1"."T 1" WHERE ((c2 = 6)) GROUP BY 3
+(4 rows)
+
+select sum(c1%3), sum(distinct c1%3 order by c1%3) filter (where c1%3 < 2), c2 from ft1 where c2 = 6 group by c2;
+ sum | sum | c2 
+-----+-----+----
+  99 |   1 |  6
+(1 row)
+
+-- Outer query is aggregation query
+explain (verbose, costs off)
+select distinct (select count(*) filter (where t2.c2 = 6 and t2.c1 < 10) from ft1 t1 where t1.c1 = 6) from ft2 t2 where t2.c2 % 6 = 0 order by 1;
+                                                          QUERY PLAN                                                          
+------------------------------------------------------------------------------------------------------------------------------
+ Unique
+   Output: ((SubPlan 1))
+   ->  Sort
+         Output: ((SubPlan 1))
+         Sort Key: ((SubPlan 1))
+         ->  Foreign Scan
+               Output: (SubPlan 1)
+               Relations: Aggregate on (public.ft2 t2)
+               Remote SQL: SELECT count(*) FILTER (WHERE ((c2 = 6) AND ("C 1" < 10))) FROM "S 1"."T 1" WHERE (((c2 % 6) = 0))
+               SubPlan 1
+                 ->  Foreign Scan on public.ft1 t1
+                       Output: (count(*) FILTER (WHERE ((t2.c2 = 6) AND (t2.c1 < 10))))
+                       Remote SQL: SELECT NULL FROM "S 1"."T 1" WHERE (("C 1" = 6))
+(13 rows)
+
+select distinct (select count(*) filter (where t2.c2 = 6 and t2.c1 < 10) from ft1 t1 where t1.c1 = 6) from ft2 t2 where t2.c2 % 6 = 0 order by 1;
+ count 
+-------
+     1
+(1 row)
+
+-- Inner query is aggregation query
+explain (verbose, costs off)
+select distinct (select count(t1.c1) filter (where t2.c2 = 6 and t2.c1 < 10) from ft1 t1 where t1.c1 = 6) from ft2 t2 where t2.c2 % 6 = 0 order by 1;
+                                                                      QUERY PLAN                                                                      
+------------------------------------------------------------------------------------------------------------------------------------------------------
+ Unique
+   Output: ((SubPlan 1))
+   ->  Sort
+         Output: ((SubPlan 1))
+         Sort Key: ((SubPlan 1))
+         ->  Foreign Scan on public.ft2 t2
+               Output: (SubPlan 1)
+               Remote SQL: SELECT "C 1", c2 FROM "S 1"."T 1" WHERE (((c2 % 6) = 0))
+               SubPlan 1
+                 ->  Foreign Scan
+                       Output: (count(t1.c1) FILTER (WHERE ((t2.c2 = 6) AND (t2.c1 < 10))))
+                       Relations: Aggregate on (public.ft1 t1)
+                       Remote SQL: SELECT count("C 1") FILTER (WHERE (($1::integer = 6) AND ($2::integer < 10))) FROM "S 1"."T 1" WHERE (("C 1" = 6))
+(13 rows)
+
+select distinct (select count(t1.c1) filter (where t2.c2 = 6 and t2.c1 < 10) from ft1 t1 where t1.c1 = 6) from ft2 t2 where t2.c2 % 6 = 0 order by 1;
+ count 
+-------
+     0
+     1
+(2 rows)
+
+-- Aggregate not pushed down as FILTER condition is not pushable
+explain (verbose, costs off)
+select sum(c1) filter (where (c1 / c1) * random() <= 1) from ft1 group by c2 order by 1;
+                                                       QUERY PLAN                                                       
+------------------------------------------------------------------------------------------------------------------------
+ Sort
+   Output: (sum(c1) FILTER (WHERE ((((c1 / c1))::double precision * random()) <= '1'::double precision))), c2
+   Sort Key: (sum(ft1.c1) FILTER (WHERE ((((ft1.c1 / ft1.c1))::double precision * random()) <= '1'::double precision)))
+   ->  HashAggregate
+         Output: sum(c1) FILTER (WHERE ((((c1 / c1))::double precision * random()) <= '1'::double precision)), c2
+         Group Key: ft1.c2
+         ->  Foreign Scan on public.ft1
+               Output: c1, c2
+               Remote SQL: SELECT "C 1", c2 FROM "S 1"."T 1"
+(9 rows)
+
+explain (verbose, costs off)
+select sum(c2) filter (where c2 in (select c2 from ft1 where c2 < 5)) from ft1;
+                            QUERY PLAN                             
+-------------------------------------------------------------------
+ Aggregate
+   Output: sum(ft1.c2) FILTER (WHERE (hashed SubPlan 1))
+   ->  Foreign Scan on public.ft1
+         Output: ft1.c2
+         Remote SQL: SELECT c2 FROM "S 1"."T 1"
+   SubPlan 1
+     ->  Foreign Scan on public.ft1 ft1_1
+           Output: ft1_1.c2
+           Remote SQL: SELECT c2 FROM "S 1"."T 1" WHERE ((c2 < 5))
+(9 rows)
+
+-- Ordered-sets within aggregate
+explain (verbose, costs off)
+select c2, rank('10'::varchar) within group (order by c6), percentile_cont(c2/10::numeric) within group (order by c1) from ft1 where c2 < 10 group by c2 having percentile_cont(c2/10::numeric) within group (order by c1) < 500 order by c2;
+                                                                                                                                                                           QUERY PLAN                                                                                                                                                                           
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Sort
+   Output: c2, (rank('10'::character varying) WITHIN GROUP (ORDER BY c6)), (percentile_cont((((c2)::numeric / '10'::numeric))::double precision) WITHIN GROUP (ORDER BY ((c1)::double precision)))
+   Sort Key: ft1.c2
+   ->  Foreign Scan
+         Output: c2, (rank('10'::character varying) WITHIN GROUP (ORDER BY c6)), (percentile_cont((((c2)::numeric / '10'::numeric))::double precision) WITHIN GROUP (ORDER BY ((c1)::double precision)))
+         Relations: Aggregate on (public.ft1)
+         Remote SQL: SELECT c2, rank('10'::character varying) WITHIN GROUP (ORDER BY c6 ASC NULLS LAST), percentile_cont((c2 / 10::numeric)) WITHIN GROUP (ORDER BY ("C 1") ASC NULLS LAST) FROM "S 1"."T 1" WHERE ((c2 < 10)) GROUP BY 1 HAVING ((percentile_cont((c2 / 10::numeric)) WITHIN GROUP (ORDER BY ("C 1") ASC NULLS LAST) < 500::double precision))
+(7 rows)
+
+select c2, rank('10'::varchar) within group (order by c6), percentile_cont(c2/10::numeric) within group (order by c1) from ft1 where c2 < 10 group by c2 having percentile_cont(c2/10::numeric) within group (order by c1) < 500 order by c2;
+ c2 | rank | percentile_cont 
+----+------+-----------------
+  0 |  101 |              10
+  1 |  101 |             100
+  2 |    1 |             200
+  3 |    1 |             300
+  4 |    1 |             400
+(5 rows)
+
+-- Using multiple arguments within aggregates
+explain (verbose, costs off)
+select c1, rank(c1, c2) within group (order by c1, c2) from ft1 group by c1, c2 having c1 = 6 order by 1;
+                                                                             QUERY PLAN                                                                             
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: c1, (rank(c1, c2) WITHIN GROUP (ORDER BY c1, c2)), c2
+   Relations: Aggregate on (public.ft1)
+   Remote SQL: SELECT "C 1", rank("C 1", c2) WITHIN GROUP (ORDER BY "C 1" ASC NULLS LAST, c2 ASC NULLS LAST), c2 FROM "S 1"."T 1" WHERE (("C 1" = 6)) GROUP BY 1, 3
+(4 rows)
+
+select c1, rank(c1, c2) within group (order by c1, c2) from ft1 group by c1, c2 having c1 = 6 order by 1;
+ c1 | rank 
+----+------
+  6 |    1
+(1 row)
+
+-- User defined function for user defined aggregate, VARIADIC
+create function least_accum(anyelement, variadic anyarray)
+returns anyelement language sql as
+  'select least($1, min($2[i])) from generate_subscripts($2,1) g(i)';
+create aggregate least_agg(variadic items anyarray) (
+  stype = anyelement, sfunc = least_accum
+);
+-- Disable hash aggregation for plan stability.
+set enable_hashagg to false;
+-- Not pushed down due to user defined aggregate
+explain (verbose, costs off)
+select c2, least_agg(c1) from ft1 group by c2 order by c2;
+                                    QUERY PLAN                                    
+----------------------------------------------------------------------------------
+ GroupAggregate
+   Output: c2, least_agg(VARIADIC ARRAY[c1])
+   Group Key: ft1.c2
+   ->  Foreign Scan on public.ft1
+         Output: c2, c1
+         Remote SQL: SELECT "C 1", c2 FROM "S 1"."T 1" ORDER BY c2 ASC NULLS LAST
+(6 rows)
+
+-- Add function and aggregate into extension
+alter extension postgres_fdw add function least_accum(anyelement, variadic anyarray);
+alter extension postgres_fdw add aggregate least_agg(variadic items anyarray);
+alter server loopback options (set extensions 'postgres_fdw');
+-- Now aggregate will be pushed.  Aggregate will display VARIADIC argument.
+explain (verbose, costs off)
+select c2, least_agg(c1) from ft1 where c2 < 100 group by c2 order by c2;
+                                                      QUERY PLAN                                                       
+-----------------------------------------------------------------------------------------------------------------------
+ Sort
+   Output: c2, (least_agg(VARIADIC ARRAY[c1]))
+   Sort Key: ft1.c2
+   ->  Foreign Scan
+         Output: c2, (least_agg(VARIADIC ARRAY[c1]))
+         Relations: Aggregate on (public.ft1)
+         Remote SQL: SELECT c2, public.least_agg(VARIADIC ARRAY["C 1"]) FROM "S 1"."T 1" WHERE ((c2 < 100)) GROUP BY 1
+(7 rows)
+
+select c2, least_agg(c1) from ft1 where c2 < 100 group by c2 order by c2;
+ c2 | least_agg 
+----+-----------
+  0 |        10
+  1 |         1
+  2 |         2
+  3 |         3
+  4 |         4
+  5 |         5
+  6 |         6
+  7 |         7
+  8 |         8
+  9 |         9
+(10 rows)
+
+-- Remove function and aggregate from extension
+alter extension postgres_fdw drop function least_accum(anyelement, variadic anyarray);
+alter extension postgres_fdw drop aggregate least_agg(variadic items anyarray);
+alter server loopback options (set extensions 'postgres_fdw');
+-- Not pushed down as we have dropped objects from extension.
+explain (verbose, costs off)
+select c2, least_agg(c1) from ft1 group by c2 order by c2;
+                                    QUERY PLAN                                    
+----------------------------------------------------------------------------------
+ GroupAggregate
+   Output: c2, least_agg(VARIADIC ARRAY[c1])
+   Group Key: ft1.c2
+   ->  Foreign Scan on public.ft1
+         Output: c2, c1
+         Remote SQL: SELECT "C 1", c2 FROM "S 1"."T 1" ORDER BY c2 ASC NULLS LAST
+(6 rows)
+
+-- Cleanup
+reset enable_hashagg;
+drop aggregate least_agg(variadic items anyarray);
+drop function least_accum(anyelement, variadic anyarray);
+-- Testing USING OPERATOR() in ORDER BY within aggregate.
+-- For this, we need user defined operators along with operator family and
+-- operator class.  Create those and then add them in extension.  Note that
+-- user defined objects are considered unshippable unless they are part of
+-- the extension.
+create operator public.<^ (
+ leftarg = int4,
+ rightarg = int4,
+ procedure = int4eq
+);
+create operator public.=^ (
+ leftarg = int4,
+ rightarg = int4,
+ procedure = int4lt
+);
+create operator public.>^ (
+ leftarg = int4,
+ rightarg = int4,
+ procedure = int4gt
+);
+create operator family my_op_family using btree;
+create function my_op_cmp(a int, b int) returns int as
+  $$begin return btint4cmp(a, b); end $$ language plpgsql;
+create operator class my_op_class for type int using btree family my_op_family as
+ operator 1 public.<^,
+ operator 3 public.=^,
+ operator 5 public.>^,
+ function 1 my_op_cmp(int, int);
+-- This will not be pushed as user defined sort operator is not part of the
+-- extension yet.
+explain (verbose, costs off)
+select array_agg(c1 order by c1 using operator(public.<^)) from ft2 where c2 = 6 and c1 < 100 group by c2;
+                                         QUERY PLAN                                         
+--------------------------------------------------------------------------------------------
+ GroupAggregate
+   Output: array_agg(c1 ORDER BY c1 USING <^ NULLS LAST), c2
+   Group Key: ft2.c2
+   ->  Foreign Scan on public.ft2
+         Output: c1, c2
+         Remote SQL: SELECT "C 1", c2 FROM "S 1"."T 1" WHERE (("C 1" < 100)) AND ((c2 = 6))
+(6 rows)
+
+-- Update local stats on ft2
+ANALYZE ft2;
+-- Add into extension
+alter extension postgres_fdw add operator class my_op_class using btree;
+alter extension postgres_fdw add function my_op_cmp(a int, b int);
+alter extension postgres_fdw add operator family my_op_family using btree;
+alter extension postgres_fdw add operator public.<^(int, int);
+alter extension postgres_fdw add operator public.=^(int, int);
+alter extension postgres_fdw add operator public.>^(int, int);
+alter server loopback options (set extensions 'postgres_fdw');
+-- Now this will be pushed as sort operator is part of the extension.
+explain (verbose, costs off)
+select array_agg(c1 order by c1 using operator(public.<^)) from ft2 where c2 = 6 and c1 < 100 group by c2;
+                                                                           QUERY PLAN                                                                           
+----------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (array_agg(c1 ORDER BY c1 USING <^ NULLS LAST)), c2
+   Relations: Aggregate on (public.ft2)
+   Remote SQL: SELECT array_agg("C 1" ORDER BY "C 1" USING OPERATOR(public.<^) NULLS LAST), c2 FROM "S 1"."T 1" WHERE (("C 1" < 100)) AND ((c2 = 6)) GROUP BY 2
+(4 rows)
+
+select array_agg(c1 order by c1 using operator(public.<^)) from ft2 where c2 = 6 and c1 < 100 group by c2;
+           array_agg            
+--------------------------------
+ {6,16,26,36,46,56,66,76,86,96}
+(1 row)
+
+-- Remove from extension
+alter extension postgres_fdw drop operator class my_op_class using btree;
+alter extension postgres_fdw drop function my_op_cmp(a int, b int);
+alter extension postgres_fdw drop operator family my_op_family using btree;
+alter extension postgres_fdw drop operator public.<^(int, int);
+alter extension postgres_fdw drop operator public.=^(int, int);
+alter extension postgres_fdw drop operator public.>^(int, int);
+alter server loopback options (set extensions 'postgres_fdw');
+-- This will not be pushed as sort operator is now removed from the extension.
+explain (verbose, costs off)
+select array_agg(c1 order by c1 using operator(public.<^)) from ft2 where c2 = 6 and c1 < 100 group by c2;
+                                         QUERY PLAN                                         
+--------------------------------------------------------------------------------------------
+ GroupAggregate
+   Output: array_agg(c1 ORDER BY c1 USING <^ NULLS LAST), c2
+   Group Key: ft2.c2
+   ->  Foreign Scan on public.ft2
+         Output: c1, c2
+         Remote SQL: SELECT "C 1", c2 FROM "S 1"."T 1" WHERE (("C 1" < 100)) AND ((c2 = 6))
+(6 rows)
+
+-- Cleanup
+drop operator class my_op_class using btree;
+drop function my_op_cmp(a int, b int);
+drop operator family my_op_family using btree;
+drop operator public.>^(int, int);
+drop operator public.=^(int, int);
+drop operator public.<^(int, int);
+-- Input relation to aggregate push down hook is not safe to pushdown and thus
+-- the aggregate cannot be pushed down to foreign server.
+explain (verbose, costs off)
+select count(t1.c3) from ft2 t1 left join ft2 t2 on (t1.c1 = random() * t2.c2);
+                                        QUERY PLAN                                         
+-------------------------------------------------------------------------------------------
+ Aggregate
+   Output: count(t1.c3)
+   ->  Nested Loop Left Join
+         Output: t1.c3
+         Join Filter: ((t1.c1)::double precision = (random() * (t2.c2)::double precision))
+         ->  Foreign Scan on public.ft2 t1
+               Output: t1.c3, t1.c1
+               Remote SQL: SELECT "C 1", c3 FROM "S 1"."T 1"
+         ->  Materialize
+               Output: t2.c2
+               ->  Foreign Scan on public.ft2 t2
+                     Output: t2.c2
+                     Remote SQL: SELECT c2 FROM "S 1"."T 1"
+(13 rows)
+
+-- Subquery in FROM clause having aggregate
+explain (verbose, costs off)
+select count(*), x.b from ft1, (select c2 a, sum(c1) b from ft1 group by c2) x where ft1.c2 = x.a group by x.b order by 1, 2;
+                                          QUERY PLAN                                           
+-----------------------------------------------------------------------------------------------
+ Sort
+   Output: (count(*)), x.b
+   Sort Key: (count(*)), x.b
+   ->  HashAggregate
+         Output: count(*), x.b
+         Group Key: x.b
+         ->  Hash Join
+               Output: x.b
+               Inner Unique: true
+               Hash Cond: (ft1.c2 = x.a)
+               ->  Foreign Scan on public.ft1
+                     Output: ft1.c2
+                     Remote SQL: SELECT c2 FROM "S 1"."T 1"
+               ->  Hash
+                     Output: x.b, x.a
+                     ->  Subquery Scan on x
+                           Output: x.b, x.a
+                           ->  Foreign Scan
+                                 Output: ft1_1.c2, (sum(ft1_1.c1))
+                                 Relations: Aggregate on (public.ft1)
+                                 Remote SQL: SELECT c2, sum("C 1") FROM "S 1"."T 1" GROUP BY 1
+(21 rows)
+
+select count(*), x.b from ft1, (select c2 a, sum(c1) b from ft1 group by c2) x where ft1.c2 = x.a group by x.b order by 1, 2;
+ count |   b   
+-------+-------
+   100 | 49600
+   100 | 49700
+   100 | 49800
+   100 | 49900
+   100 | 50000
+   100 | 50100
+   100 | 50200
+   100 | 50300
+   100 | 50400
+   100 | 50500
+(10 rows)
+
+-- FULL join with IS NULL check in HAVING
+explain (verbose, costs off)
+select avg(t1.c1), sum(t2.c1) from ft4 t1 full join ft5 t2 on (t1.c1 = t2.c1) group by t2.c1 having (avg(t1.c1) is null and sum(t2.c1) < 10) or sum(t2.c1) is null order by 1 nulls last, 2;
+                                                                                                                                    QUERY PLAN                                                                                                                                     
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (avg(t1.c1)), (sum(t2.c1)), t2.c1
+   Relations: Aggregate on ((public.ft4 t1) FULL JOIN (public.ft5 t2))
+   Remote SQL: SELECT avg(r1.c1), sum(r2.c1), r2.c1 FROM ("S 1"."T 3" r1 FULL JOIN "S 1"."T 4" r2 ON (((r1.c1 = r2.c1)))) GROUP BY 3 HAVING ((((avg(r1.c1) IS NULL) AND (sum(r2.c1) < 10)) OR (sum(r2.c1) IS NULL))) ORDER BY avg(r1.c1) ASC NULLS LAST, sum(r2.c1) ASC NULLS LAST
+(4 rows)
+
+select avg(t1.c1), sum(t2.c1) from ft4 t1 full join ft5 t2 on (t1.c1 = t2.c1) group by t2.c1 having (avg(t1.c1) is null and sum(t2.c1) < 10) or sum(t2.c1) is null order by 1 nulls last, 2;
+         avg         | sum 
+---------------------+-----
+ 51.0000000000000000 |    
+                     |   3
+                     |   9
+(3 rows)
+
+-- Aggregate over FULL join needing to deparse the joining relations as
+-- subqueries.
+explain (verbose, costs off)
+select count(*), sum(t1.c1), avg(t2.c1) from (select c1 from ft4 where c1 between 50 and 60) t1 full join (select c1 from ft5 where c1 between 50 and 60) t2 on (t1.c1 = t2.c1);
+                                                                                                                  QUERY PLAN                                                                                                                   
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (count(*)), (sum(ft4.c1)), (avg(ft5.c1))
+   Relations: Aggregate on ((public.ft4) FULL JOIN (public.ft5))
+   Remote SQL: SELECT count(*), sum(s4.c1), avg(s5.c1) FROM ((SELECT c1 FROM "S 1"."T 3" WHERE ((c1 >= 50)) AND ((c1 <= 60))) s4(c1) FULL JOIN (SELECT c1 FROM "S 1"."T 4" WHERE ((c1 >= 50)) AND ((c1 <= 60))) s5(c1) ON (((s4.c1 = s5.c1))))
+(4 rows)
+
+select count(*), sum(t1.c1), avg(t2.c1) from (select c1 from ft4 where c1 between 50 and 60) t1 full join (select c1 from ft5 where c1 between 50 and 60) t2 on (t1.c1 = t2.c1);
+ count | sum |         avg         
+-------+-----+---------------------
+     8 | 330 | 55.5000000000000000
+(1 row)
+
+-- ORDER BY expression is part of the target list but not pushed down to
+-- foreign server.
+explain (verbose, costs off)
+select sum(c2) * (random() <= 1)::int as sum from ft1 order by 1;
+                                   QUERY PLAN                                   
+--------------------------------------------------------------------------------
+ Sort
+   Output: (((sum(c2)) * ((random() <= '1'::double precision))::integer))
+   Sort Key: (((sum(ft1.c2)) * ((random() <= '1'::double precision))::integer))
+   ->  Foreign Scan
+         Output: ((sum(c2)) * ((random() <= '1'::double precision))::integer)
+         Relations: Aggregate on (public.ft1)
+         Remote SQL: SELECT sum(c2) FROM "S 1"."T 1"
+(7 rows)
+
+select sum(c2) * (random() <= 1)::int as sum from ft1 order by 1;
+ sum  
+------
+ 4500
+(1 row)
+
+-- LATERAL join, with parameterization
+set enable_hashagg to false;
+explain (verbose, costs off)
+select c2, sum from "S 1"."T 1" t1, lateral (select sum(t2.c1 + t1."C 1") sum from ft2 t2 group by t2.c1) qry where t1.c2 * 2 = qry.sum and t1.c2 < 3 and t1."C 1" < 100 order by 1;
+                                              QUERY PLAN                                              
+------------------------------------------------------------------------------------------------------
+ Sort
+   Output: t1.c2, qry.sum
+   Sort Key: t1.c2
+   ->  Nested Loop
+         Output: t1.c2, qry.sum
+         ->  Index Scan using t1_pkey on "S 1"."T 1" t1
+               Output: t1."C 1", t1.c2, t1.c3, t1.c4, t1.c5, t1.c6, t1.c7, t1.c8
+               Index Cond: (t1."C 1" < 100)
+               Filter: (t1.c2 < 3)
+         ->  Subquery Scan on qry
+               Output: qry.sum, t2.c1
+               Filter: ((t1.c2 * 2) = qry.sum)
+               ->  Foreign Scan
+                     Output: (sum((t2.c1 + t1."C 1"))), t2.c1
+                     Relations: Aggregate on (public.ft2 t2)
+                     Remote SQL: SELECT sum(("C 1" + $1::integer)), "C 1" FROM "S 1"."T 1" GROUP BY 2
+(16 rows)
+
+select c2, sum from "S 1"."T 1" t1, lateral (select sum(t2.c1 + t1."C 1") sum from ft2 t2 group by t2.c1) qry where t1.c2 * 2 = qry.sum and t1.c2 < 3 and t1."C 1" < 100 order by 1;
+ c2 | sum 
+----+-----
+  1 |   2
+  2 |   4
+(2 rows)
+
+reset enable_hashagg;
+-- bug #15613: bad plan for foreign table scan with lateral reference
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT ref_0.c2, subq_1.*
+FROM
+    "S 1"."T 1" AS ref_0,
+    LATERAL (
+        SELECT ref_0."C 1" c1, subq_0.*
+        FROM (SELECT ref_0.c2, ref_1.c3
+              FROM ft1 AS ref_1) AS subq_0
+             RIGHT JOIN ft2 AS ref_3 ON (subq_0.c3 = ref_3.c3)
+    ) AS subq_1
+WHERE ref_0."C 1" < 10 AND subq_1.c3 = '00001'
+ORDER BY ref_0."C 1";
+                                               QUERY PLAN                                                
+---------------------------------------------------------------------------------------------------------
+ Nested Loop
+   Output: ref_0.c2, ref_0."C 1", (ref_0.c2), ref_1.c3, ref_0."C 1"
+   ->  Nested Loop
+         Output: ref_0.c2, ref_0."C 1", ref_1.c3, (ref_0.c2)
+         ->  Index Scan using t1_pkey on "S 1"."T 1" ref_0
+               Output: ref_0."C 1", ref_0.c2, ref_0.c3, ref_0.c4, ref_0.c5, ref_0.c6, ref_0.c7, ref_0.c8
+               Index Cond: (ref_0."C 1" < 10)
+         ->  Foreign Scan on public.ft1 ref_1
+               Output: ref_1.c3, ref_0.c2
+               Remote SQL: SELECT c3 FROM "S 1"."T 1" WHERE ((c3 = '00001'::text))
+   ->  Materialize
+         Output: ref_3.c3
+         ->  Foreign Scan on public.ft2 ref_3
+               Output: ref_3.c3
+               Remote SQL: SELECT c3 FROM "S 1"."T 1" WHERE ((c3 = '00001'::text))
+(15 rows)
+
+SELECT ref_0.c2, subq_1.*
+FROM
+    "S 1"."T 1" AS ref_0,
+    LATERAL (
+        SELECT ref_0."C 1" c1, subq_0.*
+        FROM (SELECT ref_0.c2, ref_1.c3
+              FROM ft1 AS ref_1) AS subq_0
+             RIGHT JOIN ft2 AS ref_3 ON (subq_0.c3 = ref_3.c3)
+    ) AS subq_1
+WHERE ref_0."C 1" < 10 AND subq_1.c3 = '00001'
+ORDER BY ref_0."C 1";
+ c2 | c1 | c2 |  c3   
+----+----+----+-------
+  1 |  1 |  1 | 00001
+  2 |  2 |  2 | 00001
+  3 |  3 |  3 | 00001
+  4 |  4 |  4 | 00001
+  5 |  5 |  5 | 00001
+  6 |  6 |  6 | 00001
+  7 |  7 |  7 | 00001
+  8 |  8 |  8 | 00001
+  9 |  9 |  9 | 00001
+(9 rows)
+
+-- Check with placeHolderVars
+explain (verbose, costs off)
+select sum(q.a), count(q.b) from ft4 left join (select 13, avg(ft1.c1), sum(ft2.c1) from ft1 right join ft2 on (ft1.c1 = ft2.c1)) q(a, b, c) on (ft4.c1 <= q.b);
+                                                                        QUERY PLAN                                                                        
+----------------------------------------------------------------------------------------------------------------------------------------------------------
+ Aggregate
+   Output: sum(q.a), count(q.b)
+   ->  Nested Loop Left Join
+         Output: q.a, q.b
+         Inner Unique: true
+         Join Filter: ((ft4.c1)::numeric <= q.b)
+         ->  Foreign Scan on public.ft4
+               Output: ft4.c1, ft4.c2, ft4.c3
+               Remote SQL: SELECT c1 FROM "S 1"."T 3"
+         ->  Materialize
+               Output: q.a, q.b
+               ->  Subquery Scan on q
+                     Output: q.a, q.b
+                     ->  Foreign Scan
+                           Output: 13, (avg(ft1.c1)), NULL::bigint
+                           Relations: Aggregate on ((public.ft2) LEFT JOIN (public.ft1))
+                           Remote SQL: SELECT 13, avg(r1."C 1"), NULL::bigint FROM ("S 1"."T 1" r2 LEFT JOIN "S 1"."T 1" r1 ON (((r1."C 1" = r2."C 1"))))
+(17 rows)
+
+select sum(q.a), count(q.b) from ft4 left join (select 13, avg(ft1.c1), sum(ft2.c1) from ft1 right join ft2 on (ft1.c1 = ft2.c1)) q(a, b, c) on (ft4.c1 <= q.b);
+ sum | count 
+-----+-------
+ 650 |    50
+(1 row)
+
+-- Not supported cases
+-- Grouping sets
+explain (verbose, costs off)
+select c2, sum(c1) from ft1 where c2 < 3 group by rollup(c2) order by 1 nulls last;
+                                  QUERY PLAN                                  
+------------------------------------------------------------------------------
+ Sort
+   Output: c2, (sum(c1))
+   Sort Key: ft1.c2
+   ->  MixedAggregate
+         Output: c2, sum(c1)
+         Hash Key: ft1.c2
+         Group Key: ()
+         ->  Foreign Scan on public.ft1
+               Output: c2, c1
+               Remote SQL: SELECT "C 1", c2 FROM "S 1"."T 1" WHERE ((c2 < 3))
+(10 rows)
+
+select c2, sum(c1) from ft1 where c2 < 3 group by rollup(c2) order by 1 nulls last;
+ c2 |  sum   
+----+--------
+  0 |  50500
+  1 |  49600
+  2 |  49700
+    | 149800
+(4 rows)
+
+explain (verbose, costs off)
+select c2, sum(c1) from ft1 where c2 < 3 group by cube(c2) order by 1 nulls last;
+                                  QUERY PLAN                                  
+------------------------------------------------------------------------------
+ Sort
+   Output: c2, (sum(c1))
+   Sort Key: ft1.c2
+   ->  MixedAggregate
+         Output: c2, sum(c1)
+         Hash Key: ft1.c2
+         Group Key: ()
+         ->  Foreign Scan on public.ft1
+               Output: c2, c1
+               Remote SQL: SELECT "C 1", c2 FROM "S 1"."T 1" WHERE ((c2 < 3))
+(10 rows)
+
+select c2, sum(c1) from ft1 where c2 < 3 group by cube(c2) order by 1 nulls last;
+ c2 |  sum   
+----+--------
+  0 |  50500
+  1 |  49600
+  2 |  49700
+    | 149800
+(4 rows)
+
+explain (verbose, costs off)
+select c2, c6, sum(c1) from ft1 where c2 < 3 group by grouping sets(c2, c6) order by 1 nulls last, 2 nulls last;
+                                    QUERY PLAN                                    
+----------------------------------------------------------------------------------
+ Sort
+   Output: c2, c6, (sum(c1))
+   Sort Key: ft1.c2, ft1.c6
+   ->  HashAggregate
+         Output: c2, c6, sum(c1)
+         Hash Key: ft1.c2
+         Hash Key: ft1.c6
+         ->  Foreign Scan on public.ft1
+               Output: c2, c6, c1
+               Remote SQL: SELECT "C 1", c2, c6 FROM "S 1"."T 1" WHERE ((c2 < 3))
+(10 rows)
+
+select c2, c6, sum(c1) from ft1 where c2 < 3 group by grouping sets(c2, c6) order by 1 nulls last, 2 nulls last;
+ c2 | c6 |  sum  
+----+----+-------
+  0 |    | 50500
+  1 |    | 49600
+  2 |    | 49700
+    | 0  | 50500
+    | 1  | 49600
+    | 2  | 49700
+(6 rows)
+
+explain (verbose, costs off)
+select c2, sum(c1), grouping(c2) from ft1 where c2 < 3 group by c2 order by 1 nulls last;
+                                  QUERY PLAN                                  
+------------------------------------------------------------------------------
+ Sort
+   Output: c2, (sum(c1)), (GROUPING(c2))
+   Sort Key: ft1.c2
+   ->  HashAggregate
+         Output: c2, sum(c1), GROUPING(c2)
+         Group Key: ft1.c2
+         ->  Foreign Scan on public.ft1
+               Output: c2, c1
+               Remote SQL: SELECT "C 1", c2 FROM "S 1"."T 1" WHERE ((c2 < 3))
+(9 rows)
+
+select c2, sum(c1), grouping(c2) from ft1 where c2 < 3 group by c2 order by 1 nulls last;
+ c2 |  sum  | grouping 
+----+-------+----------
+  0 | 50500 |        0
+  1 | 49600 |        0
+  2 | 49700 |        0
+(3 rows)
+
+-- DISTINCT itself is not pushed down, whereas underneath aggregate is pushed
+explain (verbose, costs off)
+select distinct sum(c1)/1000 s from ft2 where c2 < 6 group by c2 order by 1;
+                                              QUERY PLAN                                               
+-------------------------------------------------------------------------------------------------------
+ Unique
+   Output: ((sum(c1) / 1000)), c2
+   ->  Sort
+         Output: ((sum(c1) / 1000)), c2
+         Sort Key: ((sum(ft2.c1) / 1000))
+         ->  Foreign Scan
+               Output: ((sum(c1) / 1000)), c2
+               Relations: Aggregate on (public.ft2)
+               Remote SQL: SELECT (sum("C 1") / 1000), c2 FROM "S 1"."T 1" WHERE ((c2 < 6)) GROUP BY 2
+(9 rows)
+
+select distinct sum(c1)/1000 s from ft2 where c2 < 6 group by c2 order by 1;
+ s  
+----
+ 49
+ 50
+(2 rows)
+
+-- WindowAgg
+explain (verbose, costs off)
+select c2, sum(c2), count(c2) over (partition by c2%2) from ft2 where c2 < 10 group by c2 order by 1;
+                                                 QUERY PLAN                                                 
+------------------------------------------------------------------------------------------------------------
+ Sort
+   Output: c2, (sum(c2)), (count(c2) OVER (?)), ((c2 % 2))
+   Sort Key: ft2.c2
+   ->  WindowAgg
+         Output: c2, (sum(c2)), count(c2) OVER (?), ((c2 % 2))
+         ->  Sort
+               Output: c2, ((c2 % 2)), (sum(c2))
+               Sort Key: ((ft2.c2 % 2))
+               ->  Foreign Scan
+                     Output: c2, ((c2 % 2)), (sum(c2))
+                     Relations: Aggregate on (public.ft2)
+                     Remote SQL: SELECT c2, (c2 % 2), sum(c2) FROM "S 1"."T 1" WHERE ((c2 < 10)) GROUP BY 1
+(12 rows)
+
+select c2, sum(c2), count(c2) over (partition by c2%2) from ft2 where c2 < 10 group by c2 order by 1;
+ c2 | sum | count 
+----+-----+-------
+  0 |   0 |     5
+  1 | 100 |     5
+  2 | 200 |     5
+  3 | 300 |     5
+  4 | 400 |     5
+  5 | 500 |     5
+  6 | 600 |     5
+  7 | 700 |     5
+  8 | 800 |     5
+  9 | 900 |     5
+(10 rows)
+
+explain (verbose, costs off)
+select c2, array_agg(c2) over (partition by c2%2 order by c2 desc) from ft1 where c2 < 10 group by c2 order by 1;
+                                            QUERY PLAN                                             
+---------------------------------------------------------------------------------------------------
+ Sort
+   Output: c2, (array_agg(c2) OVER (?)), ((c2 % 2))
+   Sort Key: ft1.c2
+   ->  WindowAgg
+         Output: c2, array_agg(c2) OVER (?), ((c2 % 2))
+         ->  Sort
+               Output: c2, ((c2 % 2))
+               Sort Key: ((ft1.c2 % 2)), ft1.c2 DESC
+               ->  Foreign Scan
+                     Output: c2, ((c2 % 2))
+                     Relations: Aggregate on (public.ft1)
+                     Remote SQL: SELECT c2, (c2 % 2) FROM "S 1"."T 1" WHERE ((c2 < 10)) GROUP BY 1
+(12 rows)
+
+select c2, array_agg(c2) over (partition by c2%2 order by c2 desc) from ft1 where c2 < 10 group by c2 order by 1;
+ c2 |  array_agg  
+----+-------------
+  0 | {8,6,4,2,0}
+  1 | {9,7,5,3,1}
+  2 | {8,6,4,2}
+  3 | {9,7,5,3}
+  4 | {8,6,4}
+  5 | {9,7,5}
+  6 | {8,6}
+  7 | {9,7}
+  8 | {8}
+  9 | {9}
+(10 rows)
+
+explain (verbose, costs off)
+select c2, array_agg(c2) over (partition by c2%2 order by c2 range between current row and unbounded following) from ft1 where c2 < 10 group by c2 order by 1;
+                                            QUERY PLAN                                             
+---------------------------------------------------------------------------------------------------
+ Sort
+   Output: c2, (array_agg(c2) OVER (?)), ((c2 % 2))
+   Sort Key: ft1.c2
+   ->  WindowAgg
+         Output: c2, array_agg(c2) OVER (?), ((c2 % 2))
+         ->  Sort
+               Output: c2, ((c2 % 2))
+               Sort Key: ((ft1.c2 % 2)), ft1.c2
+               ->  Foreign Scan
+                     Output: c2, ((c2 % 2))
+                     Relations: Aggregate on (public.ft1)
+                     Remote SQL: SELECT c2, (c2 % 2) FROM "S 1"."T 1" WHERE ((c2 < 10)) GROUP BY 1
+(12 rows)
+
+select c2, array_agg(c2) over (partition by c2%2 order by c2 range between current row and unbounded following) from ft1 where c2 < 10 group by c2 order by 1;
+ c2 |  array_agg  
+----+-------------
+  0 | {0,2,4,6,8}
+  1 | {1,3,5,7,9}
+  2 | {2,4,6,8}
+  3 | {3,5,7,9}
+  4 | {4,6,8}
+  5 | {5,7,9}
+  6 | {6,8}
+  7 | {7,9}
+  8 | {8}
+  9 | {9}
+(10 rows)
+
+-- ===================================================================
+-- parameterized queries
+-- ===================================================================
+-- simple join
+PREPARE st1(int, int) AS SELECT t1.c3, t2.c3 FROM ft1 t1, ft2 t2 WHERE t1.c1 = $1 AND t2.c1 = $2;
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st1(1, 2);
+                                                          QUERY PLAN                                                          
+------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.c3, t2.c3
+   Relations: (public.ft1 t1) INNER JOIN (public.ft2 t2)
+   Remote SQL: SELECT r1.c3, r2.c3 FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 1" r2 ON (((r2."C 1" = 2)) AND ((r1."C 1" = 1))))
+(4 rows)
+
+EXECUTE st1(1, 1);
+  c3   |  c3   
+-------+-------
+ 00001 | 00001
+(1 row)
+
+EXECUTE st1(101, 101);
+  c3   |  c3   
+-------+-------
+ 00101 | 00101
+(1 row)
+
+-- subquery using stable function (can't be sent to remote)
+PREPARE st2(int) AS SELECT * FROM ft1 t1 WHERE t1.c1 < $2 AND t1.c3 IN (SELECT c3 FROM ft2 t2 WHERE c1 > $1 AND date(c4) = '1970-01-17'::date) ORDER BY c1;
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st2(10, 20);
+                                                QUERY PLAN                                                
+----------------------------------------------------------------------------------------------------------
+ Sort
+   Output: t1.c1, t1.c2, t1.c3, t1.c4, t1.c5, t1.c6, t1.c7, t1.c8
+   Sort Key: t1.c1
+   ->  Nested Loop Semi Join
+         Output: t1.c1, t1.c2, t1.c3, t1.c4, t1.c5, t1.c6, t1.c7, t1.c8
+         Join Filter: (t1.c3 = t2.c3)
+         ->  Foreign Scan on public.ft1 t1
+               Output: t1.c1, t1.c2, t1.c3, t1.c4, t1.c5, t1.c6, t1.c7, t1.c8
+               Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" < 20))
+         ->  Materialize
+               Output: t2.c3
+               ->  Foreign Scan on public.ft2 t2
+                     Output: t2.c3
+                     Filter: (date(t2.c4) = '01-17-1970'::date)
+                     Remote SQL: SELECT c3, c4 FROM "S 1"."T 1" WHERE (("C 1" > 10))
+(15 rows)
+
+EXECUTE st2(10, 20);
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+ 16 |  6 | 00016 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo
+(1 row)
+
+EXECUTE st2(101, 121);
+ c1  | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+-----+----+-------+------------------------------+--------------------------+----+------------+-----
+ 116 |  6 | 00116 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo
+(1 row)
+
+-- subquery using immutable function (can be sent to remote)
+PREPARE st3(int) AS SELECT * FROM ft1 t1 WHERE t1.c1 < $2 AND t1.c3 IN (SELECT c3 FROM ft2 t2 WHERE c1 > $1 AND date(c5) = '1970-01-17'::date) ORDER BY c1;
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st3(10, 20);
+                                                      QUERY PLAN                                                       
+-----------------------------------------------------------------------------------------------------------------------
+ Sort
+   Output: t1.c1, t1.c2, t1.c3, t1.c4, t1.c5, t1.c6, t1.c7, t1.c8
+   Sort Key: t1.c1
+   ->  Nested Loop Semi Join
+         Output: t1.c1, t1.c2, t1.c3, t1.c4, t1.c5, t1.c6, t1.c7, t1.c8
+         Join Filter: (t1.c3 = t2.c3)
+         ->  Foreign Scan on public.ft1 t1
+               Output: t1.c1, t1.c2, t1.c3, t1.c4, t1.c5, t1.c6, t1.c7, t1.c8
+               Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" < 20))
+         ->  Materialize
+               Output: t2.c3
+               ->  Foreign Scan on public.ft2 t2
+                     Output: t2.c3
+                     Remote SQL: SELECT c3 FROM "S 1"."T 1" WHERE (("C 1" > 10)) AND ((date(c5) = '1970-01-17'::date))
+(14 rows)
+
+EXECUTE st3(10, 20);
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+ 16 |  6 | 00016 | Sat Jan 17 00:00:00 1970 PST | Sat Jan 17 00:00:00 1970 | 6  | 6          | foo
+(1 row)
+
+EXECUTE st3(20, 30);
+ c1 | c2 | c3 | c4 | c5 | c6 | c7 | c8 
+----+----+----+----+----+----+----+----
+(0 rows)
+
+-- custom plan should be chosen initially
+PREPARE st4(int) AS SELECT * FROM ft1 t1 WHERE t1.c1 = $1;
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st4(1);
+                                         QUERY PLAN                                          
+---------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 1))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st4(1);
+                                         QUERY PLAN                                          
+---------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 1))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st4(1);
+                                         QUERY PLAN                                          
+---------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 1))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st4(1);
+                                         QUERY PLAN                                          
+---------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 1))
+(3 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st4(1);
+                                         QUERY PLAN                                          
+---------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 1))
+(3 rows)
+
+-- once we try it enough times, should switch to generic plan
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st4(1);
+                                              QUERY PLAN                                               
+-------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = $1::integer))
+(3 rows)
+
+-- value of $1 should not be sent to remote
+PREPARE st5(user_enum,int) AS SELECT * FROM ft1 t1 WHERE c8 = $1 and c1 = $2;
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st5('foo', 1);
+                                         QUERY PLAN                                          
+---------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Filter: (t1.c8 = 'foo'::user_enum)
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 1))
+(4 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st5('foo', 1);
+                                         QUERY PLAN                                          
+---------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Filter: (t1.c8 = 'foo'::user_enum)
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 1))
+(4 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st5('foo', 1);
+                                         QUERY PLAN                                          
+---------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Filter: (t1.c8 = 'foo'::user_enum)
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 1))
+(4 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st5('foo', 1);
+                                         QUERY PLAN                                          
+---------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Filter: (t1.c8 = 'foo'::user_enum)
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 1))
+(4 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st5('foo', 1);
+                                         QUERY PLAN                                          
+---------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Filter: (t1.c8 = 'foo'::user_enum)
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = 1))
+(4 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st5('foo', 1);
+                                              QUERY PLAN                                               
+-------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Filter: (t1.c8 = $1)
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = $1::integer))
+(4 rows)
+
+EXECUTE st5('foo', 1);
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+  1 |  1 | 00001 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+(1 row)
+
+-- altering FDW options requires replanning
+PREPARE st6 AS SELECT * FROM ft1 t1 WHERE t1.c1 = t1.c2;
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st6;
+                                          QUERY PLAN                                          
+----------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (("C 1" = c2))
+(3 rows)
+
+PREPARE st7 AS INSERT INTO ft1 (c1,c2,c3) VALUES (1001,101,'foo');
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st7;
+                                                                                           QUERY PLAN                                                                                            
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Insert on public.ft1
+   Remote SQL: INSERT INTO "S 1"."T 1"("C 1", c2, c3, c4, c5, c6, c7, c8) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
+   ->  Result
+         Output: NULL::integer, 1001, 101, 'foo'::text, NULL::timestamp with time zone, NULL::timestamp without time zone, NULL::character varying, 'ft1       '::character(10), NULL::user_enum
+(4 rows)
+
+ALTER TABLE "S 1"."T 1" RENAME TO "T 0";
+ALTER FOREIGN TABLE ft1 OPTIONS (SET table_name 'T 0');
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st6;
+                                          QUERY PLAN                                          
+----------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 0" WHERE (("C 1" = c2))
+(3 rows)
+
+EXECUTE st6;
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+  1 |  1 | 00001 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+  2 |  2 | 00002 | Sat Jan 03 00:00:00 1970 PST | Sat Jan 03 00:00:00 1970 | 2  | 2          | foo
+  3 |  3 | 00003 | Sun Jan 04 00:00:00 1970 PST | Sun Jan 04 00:00:00 1970 | 3  | 3          | foo
+  4 |  4 | 00004 | Mon Jan 05 00:00:00 1970 PST | Mon Jan 05 00:00:00 1970 | 4  | 4          | foo
+  5 |  5 | 00005 | Tue Jan 06 00:00:00 1970 PST | Tue Jan 06 00:00:00 1970 | 5  | 5          | foo
+  6 |  6 | 00006 | Wed Jan 07 00:00:00 1970 PST | Wed Jan 07 00:00:00 1970 | 6  | 6          | foo
+  7 |  7 | 00007 | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+  8 |  8 | 00008 | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+  9 |  9 | 00009 | Sat Jan 10 00:00:00 1970 PST | Sat Jan 10 00:00:00 1970 | 9  | 9          | foo
+(9 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st7;
+                                                                                           QUERY PLAN                                                                                            
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Insert on public.ft1
+   Remote SQL: INSERT INTO "S 1"."T 0"("C 1", c2, c3, c4, c5, c6, c7, c8) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
+   ->  Result
+         Output: NULL::integer, 1001, 101, 'foo'::text, NULL::timestamp with time zone, NULL::timestamp without time zone, NULL::character varying, 'ft1       '::character(10), NULL::user_enum
+(4 rows)
+
+ALTER TABLE "S 1"."T 0" RENAME TO "T 1";
+ALTER FOREIGN TABLE ft1 OPTIONS (SET table_name 'T 1');
+PREPARE st8 AS SELECT count(c3) FROM ft1 t1 WHERE t1.c1 === t1.c2;
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st8;
+                                       QUERY PLAN                                        
+-----------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: (count(c3))
+   Relations: Aggregate on (public.ft1 t1)
+   Remote SQL: SELECT count(c3) FROM "S 1"."T 1" WHERE (("C 1" OPERATOR(public.===) c2))
+(4 rows)
+
+ALTER SERVER loopback OPTIONS (DROP extensions);
+EXPLAIN (VERBOSE, COSTS OFF) EXECUTE st8;
+                        QUERY PLAN                         
+-----------------------------------------------------------
+ Aggregate
+   Output: count(c3)
+   ->  Foreign Scan on public.ft1 t1
+         Output: c3
+         Filter: (t1.c1 === t1.c2)
+         Remote SQL: SELECT "C 1", c2, c3 FROM "S 1"."T 1"
+(6 rows)
+
+EXECUTE st8;
+ count 
+-------
+     9
+(1 row)
+
+ALTER SERVER loopback OPTIONS (ADD extensions 'postgres_fdw');
+-- cleanup
+DEALLOCATE st1;
+DEALLOCATE st2;
+DEALLOCATE st3;
+DEALLOCATE st4;
+DEALLOCATE st5;
+DEALLOCATE st6;
+DEALLOCATE st7;
+DEALLOCATE st8;
+-- System columns, except ctid and oid, should not be sent to remote
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT * FROM ft1 t1 WHERE t1.tableoid = 'pg_class'::regclass LIMIT 1;
+                                  QUERY PLAN                                   
+-------------------------------------------------------------------------------
+ Limit
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   ->  Foreign Scan on public.ft1 t1
+         Output: c1, c2, c3, c4, c5, c6, c7, c8
+         Filter: (t1.tableoid = '1259'::oid)
+         Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1"
+(6 rows)
+
+SELECT * FROM ft1 t1 WHERE t1.tableoid = 'ft1'::regclass LIMIT 1;
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+  1 |  1 | 00001 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+(1 row)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT tableoid::regclass, * FROM ft1 t1 LIMIT 1;
+                                       QUERY PLAN                                        
+-----------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: (tableoid)::regclass, c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" LIMIT 1::bigint
+(3 rows)
+
+SELECT tableoid::regclass, * FROM ft1 t1 LIMIT 1;
+ tableoid | c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----------+----+----+-------+------------------------------+--------------------------+----+------------+-----
+ ft1      |  1 |  1 | 00001 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+(1 row)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT * FROM ft1 t1 WHERE t1.ctid = '(0,2)';
+                                              QUERY PLAN                                               
+-------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE ((ctid = '(0,2)'::tid))
+(3 rows)
+
+SELECT * FROM ft1 t1 WHERE t1.ctid = '(0,2)';
+ c1 | c2 | c3 | c4 | c5 | c6 | c7 | c8 
+----+----+----+----+----+----+----+----
+(0 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT ctid, * FROM ft1 t1 LIMIT 1;
+                                          QUERY PLAN                                           
+-----------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1 t1
+   Output: ctid, c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8, ctid FROM "S 1"."T 1" LIMIT 1::bigint
+(3 rows)
+
+SELECT ctid, * FROM ft1 t1 LIMIT 1;
+ ctid  | c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+-------+----+----+-------+------------------------------+--------------------------+----+------------+-----
+ (1,1) |  1 |  1 | 00001 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+(1 row)
+
+-- ===================================================================
+-- used in PL/pgSQL function
+-- ===================================================================
+CREATE OR REPLACE FUNCTION f_test(p_c1 int) RETURNS int AS $$
+DECLARE
+	v_c1 int;
+BEGIN
+    SELECT c1 INTO v_c1 FROM ft1 WHERE c1 = p_c1 LIMIT 1;
+    PERFORM c1 FROM ft1 WHERE c1 = p_c1 AND p_c1 = v_c1 LIMIT 1;
+    RETURN v_c1;
+END;
+$$ LANGUAGE plpgsql;
+SELECT f_test(100);
+ f_test 
+--------
+    100
+(1 row)
+
+DROP FUNCTION f_test(int);
+-- ===================================================================
+-- conversion error
+-- ===================================================================
+ALTER FOREIGN TABLE ft1 ALTER COLUMN c8 TYPE int;
+SELECT * FROM ft1 WHERE c1 = 1;  -- ERROR
+ERROR:  invalid input syntax for type integer: "foo"
+CONTEXT:  column "c8" of foreign table "ft1"
+SELECT  ft1.c1,  ft2.c2, ft1.c8 FROM ft1, ft2 WHERE ft1.c1 = ft2.c1 AND ft1.c1 = 1; -- ERROR
+ERROR:  invalid input syntax for type integer: "foo"
+CONTEXT:  column "c8" of foreign table "ft1"
+SELECT  ft1.c1,  ft2.c2, ft1 FROM ft1, ft2 WHERE ft1.c1 = ft2.c1 AND ft1.c1 = 1; -- ERROR
+ERROR:  invalid input syntax for type integer: "foo"
+CONTEXT:  whole-row reference to foreign table "ft1"
+SELECT sum(c2), array_agg(c8) FROM ft1 GROUP BY c8; -- ERROR
+ERROR:  invalid input syntax for type integer: "foo"
+CONTEXT:  processing expression at position 2 in select list
+ALTER FOREIGN TABLE ft1 ALTER COLUMN c8 TYPE user_enum;
+-- ===================================================================
+-- subtransaction
+--  + local/remote error doesn't break cursor
+-- ===================================================================
+BEGIN;
+DECLARE c CURSOR FOR SELECT * FROM ft1 ORDER BY c1;
+FETCH c;
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+  1 |  1 | 00001 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+(1 row)
+
+SAVEPOINT s;
+ERROR OUT;          -- ERROR
+ERROR:  syntax error at or near "ERROR"
+LINE 1: ERROR OUT;
+        ^
+ROLLBACK TO s;
+FETCH c;
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+  2 |  2 | 00002 | Sat Jan 03 00:00:00 1970 PST | Sat Jan 03 00:00:00 1970 | 2  | 2          | foo
+(1 row)
+
+SAVEPOINT s;
+SELECT * FROM ft1 WHERE 1 / (c1 - 1) > 0;  -- ERROR
+ERROR:  division by zero
+CONTEXT:  remote SQL command: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" WHERE (((1 / ("C 1" - 1)) > 0))
+ROLLBACK TO s;
+FETCH c;
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+  3 |  3 | 00003 | Sun Jan 04 00:00:00 1970 PST | Sun Jan 04 00:00:00 1970 | 3  | 3          | foo
+(1 row)
+
+SELECT * FROM ft1 ORDER BY c1 LIMIT 1;
+ c1 | c2 |  c3   |              c4              |            c5            | c6 |     c7     | c8  
+----+----+-------+------------------------------+--------------------------+----+------------+-----
+  1 |  1 | 00001 | Fri Jan 02 00:00:00 1970 PST | Fri Jan 02 00:00:00 1970 | 1  | 1          | foo
+(1 row)
+
+COMMIT;
+-- ===================================================================
+-- test handling of collations
+-- ===================================================================
+create table loct3 (f1 text collate "C" unique, f2 text, f3 varchar(10) unique);
+create foreign table ft3 (f1 text collate "C", f2 text, f3 varchar(10))
+  server loopback options (table_name 'loct3', use_remote_estimate 'true');
+-- can be sent to remote
+explain (verbose, costs off) select * from ft3 where f1 = 'foo';
+                                  QUERY PLAN                                  
+------------------------------------------------------------------------------
+ Foreign Scan on public.ft3
+   Output: f1, f2, f3
+   Remote SQL: SELECT f1, f2, f3 FROM public.loct3 WHERE ((f1 = 'foo'::text))
+(3 rows)
+
+explain (verbose, costs off) select * from ft3 where f1 COLLATE "C" = 'foo';
+                                  QUERY PLAN                                  
+------------------------------------------------------------------------------
+ Foreign Scan on public.ft3
+   Output: f1, f2, f3
+   Remote SQL: SELECT f1, f2, f3 FROM public.loct3 WHERE ((f1 = 'foo'::text))
+(3 rows)
+
+explain (verbose, costs off) select * from ft3 where f2 = 'foo';
+                                  QUERY PLAN                                  
+------------------------------------------------------------------------------
+ Foreign Scan on public.ft3
+   Output: f1, f2, f3
+   Remote SQL: SELECT f1, f2, f3 FROM public.loct3 WHERE ((f2 = 'foo'::text))
+(3 rows)
+
+explain (verbose, costs off) select * from ft3 where f3 = 'foo';
+                                  QUERY PLAN                                  
+------------------------------------------------------------------------------
+ Foreign Scan on public.ft3
+   Output: f1, f2, f3
+   Remote SQL: SELECT f1, f2, f3 FROM public.loct3 WHERE ((f3 = 'foo'::text))
+(3 rows)
+
+explain (verbose, costs off) select * from ft3 f, loct3 l
+  where f.f3 = l.f3 and l.f1 = 'foo';
+                                            QUERY PLAN                                            
+--------------------------------------------------------------------------------------------------
+ Nested Loop
+   Output: f.f1, f.f2, f.f3, l.f1, l.f2, l.f3
+   ->  Index Scan using loct3_f1_key on public.loct3 l
+         Output: l.f1, l.f2, l.f3
+         Index Cond: (l.f1 = 'foo'::text)
+   ->  Foreign Scan on public.ft3 f
+         Output: f.f1, f.f2, f.f3
+         Remote SQL: SELECT f1, f2, f3 FROM public.loct3 WHERE (($1::character varying(10) = f3))
+(8 rows)
+
+-- can't be sent to remote
+explain (verbose, costs off) select * from ft3 where f1 COLLATE "POSIX" = 'foo';
+                    QUERY PLAN                     
+---------------------------------------------------
+ Foreign Scan on public.ft3
+   Output: f1, f2, f3
+   Filter: ((ft3.f1)::text = 'foo'::text)
+   Remote SQL: SELECT f1, f2, f3 FROM public.loct3
+(4 rows)
+
+explain (verbose, costs off) select * from ft3 where f1 = 'foo' COLLATE "C";
+                    QUERY PLAN                     
+---------------------------------------------------
+ Foreign Scan on public.ft3
+   Output: f1, f2, f3
+   Filter: (ft3.f1 = 'foo'::text COLLATE "C")
+   Remote SQL: SELECT f1, f2, f3 FROM public.loct3
+(4 rows)
+
+explain (verbose, costs off) select * from ft3 where f2 COLLATE "C" = 'foo';
+                    QUERY PLAN                     
+---------------------------------------------------
+ Foreign Scan on public.ft3
+   Output: f1, f2, f3
+   Filter: ((ft3.f2)::text = 'foo'::text)
+   Remote SQL: SELECT f1, f2, f3 FROM public.loct3
+(4 rows)
+
+explain (verbose, costs off) select * from ft3 where f2 = 'foo' COLLATE "C";
+                    QUERY PLAN                     
+---------------------------------------------------
+ Foreign Scan on public.ft3
+   Output: f1, f2, f3
+   Filter: (ft3.f2 = 'foo'::text COLLATE "C")
+   Remote SQL: SELECT f1, f2, f3 FROM public.loct3
+(4 rows)
+
+explain (verbose, costs off) select * from ft3 f, loct3 l
+  where f.f3 = l.f3 COLLATE "POSIX" and l.f1 = 'foo';
+                         QUERY PLAN                          
+-------------------------------------------------------------
+ Hash Join
+   Output: f.f1, f.f2, f.f3, l.f1, l.f2, l.f3
+   Inner Unique: true
+   Hash Cond: ((f.f3)::text = (l.f3)::text)
+   ->  Foreign Scan on public.ft3 f
+         Output: f.f1, f.f2, f.f3
+         Remote SQL: SELECT f1, f2, f3 FROM public.loct3
+   ->  Hash
+         Output: l.f1, l.f2, l.f3
+         ->  Index Scan using loct3_f1_key on public.loct3 l
+               Output: l.f1, l.f2, l.f3
+               Index Cond: (l.f1 = 'foo'::text)
+(12 rows)
+
+-- ===================================================================
+-- test writable foreign table stuff
+-- ===================================================================
+EXPLAIN (verbose, costs off)
+INSERT INTO ft2 (c1,c2,c3) SELECT c1+1000,c2+100, c3 || c3 FROM ft2 LIMIT 20;
+                                                                                                                    QUERY PLAN                                                                                                                    
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Insert on public.ft2
+   Remote SQL: INSERT INTO "S 1"."T 1"("C 1", c2, c3, c4, c5, c6, c7, c8) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
+   ->  Subquery Scan on "*SELECT*"
+         Output: "*SELECT*"."?column?", "*SELECT*"."?column?_1", NULL::integer, "*SELECT*"."?column?_2", NULL::timestamp with time zone, NULL::timestamp without time zone, NULL::character varying, 'ft2       '::character(10), NULL::user_enum
+         ->  Foreign Scan on public.ft2 ft2_1
+               Output: (ft2_1.c1 + 1000), (ft2_1.c2 + 100), (ft2_1.c3 || ft2_1.c3)
+               Remote SQL: SELECT "C 1", c2, c3 FROM "S 1"."T 1" LIMIT 20::bigint
+(7 rows)
+
+INSERT INTO ft2 (c1,c2,c3) SELECT c1+1000,c2+100, c3 || c3 FROM ft2 LIMIT 20;
+INSERT INTO ft2 (c1,c2,c3)
+  VALUES (1101,201,'aaa'), (1102,202,'bbb'), (1103,203,'ccc') RETURNING *;
+  c1  | c2  | c3  | c4 | c5 | c6 |     c7     | c8 
+------+-----+-----+----+----+----+------------+----
+ 1101 | 201 | aaa |    |    |    | ft2        | 
+ 1102 | 202 | bbb |    |    |    | ft2        | 
+ 1103 | 203 | ccc |    |    |    | ft2        | 
+(3 rows)
+
+INSERT INTO ft2 (c1,c2,c3) VALUES (1104,204,'ddd'), (1105,205,'eee');
+EXPLAIN (verbose, costs off)
+UPDATE ft2 SET c2 = c2 + 300, c3 = c3 || '_update3' WHERE c1 % 10 = 3;              -- can be pushed down
+                                                      QUERY PLAN                                                      
+----------------------------------------------------------------------------------------------------------------------
+ Update on public.ft2
+   ->  Foreign Update on public.ft2
+         Remote SQL: UPDATE "S 1"."T 1" SET c2 = (c2 + 300), c3 = (c3 || '_update3'::text) WHERE ((("C 1" % 10) = 3))
+(3 rows)
+
+UPDATE ft2 SET c2 = c2 + 300, c3 = c3 || '_update3' WHERE c1 % 10 = 3;
+EXPLAIN (verbose, costs off)
+UPDATE ft2 SET c2 = c2 + 400, c3 = c3 || '_update7' WHERE c1 % 10 = 7 RETURNING *;  -- can be pushed down
+                                                                            QUERY PLAN                                                                            
+------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Update on public.ft2
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   ->  Foreign Update on public.ft2
+         Remote SQL: UPDATE "S 1"."T 1" SET c2 = (c2 + 400), c3 = (c3 || '_update7'::text) WHERE ((("C 1" % 10) = 7)) RETURNING "C 1", c2, c3, c4, c5, c6, c7, c8
+(4 rows)
+
+UPDATE ft2 SET c2 = c2 + 400, c3 = c3 || '_update7' WHERE c1 % 10 = 7 RETURNING *;
+  c1  | c2  |         c3         |              c4              |            c5            | c6 |     c7     | c8  
+------+-----+--------------------+------------------------------+--------------------------+----+------------+-----
+    7 | 407 | 00007_update7      | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+   17 | 407 | 00017_update7      | Sun Jan 18 00:00:00 1970 PST | Sun Jan 18 00:00:00 1970 | 7  | 7          | foo
+   27 | 407 | 00027_update7      | Wed Jan 28 00:00:00 1970 PST | Wed Jan 28 00:00:00 1970 | 7  | 7          | foo
+   37 | 407 | 00037_update7      | Sat Feb 07 00:00:00 1970 PST | Sat Feb 07 00:00:00 1970 | 7  | 7          | foo
+   47 | 407 | 00047_update7      | Tue Feb 17 00:00:00 1970 PST | Tue Feb 17 00:00:00 1970 | 7  | 7          | foo
+   57 | 407 | 00057_update7      | Fri Feb 27 00:00:00 1970 PST | Fri Feb 27 00:00:00 1970 | 7  | 7          | foo
+   67 | 407 | 00067_update7      | Mon Mar 09 00:00:00 1970 PST | Mon Mar 09 00:00:00 1970 | 7  | 7          | foo
+   77 | 407 | 00077_update7      | Thu Mar 19 00:00:00 1970 PST | Thu Mar 19 00:00:00 1970 | 7  | 7          | foo
+   87 | 407 | 00087_update7      | Sun Mar 29 00:00:00 1970 PST | Sun Mar 29 00:00:00 1970 | 7  | 7          | foo
+   97 | 407 | 00097_update7      | Wed Apr 08 00:00:00 1970 PST | Wed Apr 08 00:00:00 1970 | 7  | 7          | foo
+  107 | 407 | 00107_update7      | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+  117 | 407 | 00117_update7      | Sun Jan 18 00:00:00 1970 PST | Sun Jan 18 00:00:00 1970 | 7  | 7          | foo
+  127 | 407 | 00127_update7      | Wed Jan 28 00:00:00 1970 PST | Wed Jan 28 00:00:00 1970 | 7  | 7          | foo
+  137 | 407 | 00137_update7      | Sat Feb 07 00:00:00 1970 PST | Sat Feb 07 00:00:00 1970 | 7  | 7          | foo
+  147 | 407 | 00147_update7      | Tue Feb 17 00:00:00 1970 PST | Tue Feb 17 00:00:00 1970 | 7  | 7          | foo
+  157 | 407 | 00157_update7      | Fri Feb 27 00:00:00 1970 PST | Fri Feb 27 00:00:00 1970 | 7  | 7          | foo
+  167 | 407 | 00167_update7      | Mon Mar 09 00:00:00 1970 PST | Mon Mar 09 00:00:00 1970 | 7  | 7          | foo
+  177 | 407 | 00177_update7      | Thu Mar 19 00:00:00 1970 PST | Thu Mar 19 00:00:00 1970 | 7  | 7          | foo
+  187 | 407 | 00187_update7      | Sun Mar 29 00:00:00 1970 PST | Sun Mar 29 00:00:00 1970 | 7  | 7          | foo
+  197 | 407 | 00197_update7      | Wed Apr 08 00:00:00 1970 PST | Wed Apr 08 00:00:00 1970 | 7  | 7          | foo
+  207 | 407 | 00207_update7      | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+  217 | 407 | 00217_update7      | Sun Jan 18 00:00:00 1970 PST | Sun Jan 18 00:00:00 1970 | 7  | 7          | foo
+  227 | 407 | 00227_update7      | Wed Jan 28 00:00:00 1970 PST | Wed Jan 28 00:00:00 1970 | 7  | 7          | foo
+  237 | 407 | 00237_update7      | Sat Feb 07 00:00:00 1970 PST | Sat Feb 07 00:00:00 1970 | 7  | 7          | foo
+  247 | 407 | 00247_update7      | Tue Feb 17 00:00:00 1970 PST | Tue Feb 17 00:00:00 1970 | 7  | 7          | foo
+  257 | 407 | 00257_update7      | Fri Feb 27 00:00:00 1970 PST | Fri Feb 27 00:00:00 1970 | 7  | 7          | foo
+  267 | 407 | 00267_update7      | Mon Mar 09 00:00:00 1970 PST | Mon Mar 09 00:00:00 1970 | 7  | 7          | foo
+  277 | 407 | 00277_update7      | Thu Mar 19 00:00:00 1970 PST | Thu Mar 19 00:00:00 1970 | 7  | 7          | foo
+  287 | 407 | 00287_update7      | Sun Mar 29 00:00:00 1970 PST | Sun Mar 29 00:00:00 1970 | 7  | 7          | foo
+  297 | 407 | 00297_update7      | Wed Apr 08 00:00:00 1970 PST | Wed Apr 08 00:00:00 1970 | 7  | 7          | foo
+  307 | 407 | 00307_update7      | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+  317 | 407 | 00317_update7      | Sun Jan 18 00:00:00 1970 PST | Sun Jan 18 00:00:00 1970 | 7  | 7          | foo
+  327 | 407 | 00327_update7      | Wed Jan 28 00:00:00 1970 PST | Wed Jan 28 00:00:00 1970 | 7  | 7          | foo
+  337 | 407 | 00337_update7      | Sat Feb 07 00:00:00 1970 PST | Sat Feb 07 00:00:00 1970 | 7  | 7          | foo
+  347 | 407 | 00347_update7      | Tue Feb 17 00:00:00 1970 PST | Tue Feb 17 00:00:00 1970 | 7  | 7          | foo
+  357 | 407 | 00357_update7      | Fri Feb 27 00:00:00 1970 PST | Fri Feb 27 00:00:00 1970 | 7  | 7          | foo
+  367 | 407 | 00367_update7      | Mon Mar 09 00:00:00 1970 PST | Mon Mar 09 00:00:00 1970 | 7  | 7          | foo
+  377 | 407 | 00377_update7      | Thu Mar 19 00:00:00 1970 PST | Thu Mar 19 00:00:00 1970 | 7  | 7          | foo
+  387 | 407 | 00387_update7      | Sun Mar 29 00:00:00 1970 PST | Sun Mar 29 00:00:00 1970 | 7  | 7          | foo
+  397 | 407 | 00397_update7      | Wed Apr 08 00:00:00 1970 PST | Wed Apr 08 00:00:00 1970 | 7  | 7          | foo
+  407 | 407 | 00407_update7      | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+  417 | 407 | 00417_update7      | Sun Jan 18 00:00:00 1970 PST | Sun Jan 18 00:00:00 1970 | 7  | 7          | foo
+  427 | 407 | 00427_update7      | Wed Jan 28 00:00:00 1970 PST | Wed Jan 28 00:00:00 1970 | 7  | 7          | foo
+  437 | 407 | 00437_update7      | Sat Feb 07 00:00:00 1970 PST | Sat Feb 07 00:00:00 1970 | 7  | 7          | foo
+  447 | 407 | 00447_update7      | Tue Feb 17 00:00:00 1970 PST | Tue Feb 17 00:00:00 1970 | 7  | 7          | foo
+  457 | 407 | 00457_update7      | Fri Feb 27 00:00:00 1970 PST | Fri Feb 27 00:00:00 1970 | 7  | 7          | foo
+  467 | 407 | 00467_update7      | Mon Mar 09 00:00:00 1970 PST | Mon Mar 09 00:00:00 1970 | 7  | 7          | foo
+  477 | 407 | 00477_update7      | Thu Mar 19 00:00:00 1970 PST | Thu Mar 19 00:00:00 1970 | 7  | 7          | foo
+  487 | 407 | 00487_update7      | Sun Mar 29 00:00:00 1970 PST | Sun Mar 29 00:00:00 1970 | 7  | 7          | foo
+  497 | 407 | 00497_update7      | Wed Apr 08 00:00:00 1970 PST | Wed Apr 08 00:00:00 1970 | 7  | 7          | foo
+  507 | 407 | 00507_update7      | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+  517 | 407 | 00517_update7      | Sun Jan 18 00:00:00 1970 PST | Sun Jan 18 00:00:00 1970 | 7  | 7          | foo
+  527 | 407 | 00527_update7      | Wed Jan 28 00:00:00 1970 PST | Wed Jan 28 00:00:00 1970 | 7  | 7          | foo
+  537 | 407 | 00537_update7      | Sat Feb 07 00:00:00 1970 PST | Sat Feb 07 00:00:00 1970 | 7  | 7          | foo
+  547 | 407 | 00547_update7      | Tue Feb 17 00:00:00 1970 PST | Tue Feb 17 00:00:00 1970 | 7  | 7          | foo
+  557 | 407 | 00557_update7      | Fri Feb 27 00:00:00 1970 PST | Fri Feb 27 00:00:00 1970 | 7  | 7          | foo
+  567 | 407 | 00567_update7      | Mon Mar 09 00:00:00 1970 PST | Mon Mar 09 00:00:00 1970 | 7  | 7          | foo
+  577 | 407 | 00577_update7      | Thu Mar 19 00:00:00 1970 PST | Thu Mar 19 00:00:00 1970 | 7  | 7          | foo
+  587 | 407 | 00587_update7      | Sun Mar 29 00:00:00 1970 PST | Sun Mar 29 00:00:00 1970 | 7  | 7          | foo
+  597 | 407 | 00597_update7      | Wed Apr 08 00:00:00 1970 PST | Wed Apr 08 00:00:00 1970 | 7  | 7          | foo
+  607 | 407 | 00607_update7      | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+  617 | 407 | 00617_update7      | Sun Jan 18 00:00:00 1970 PST | Sun Jan 18 00:00:00 1970 | 7  | 7          | foo
+  627 | 407 | 00627_update7      | Wed Jan 28 00:00:00 1970 PST | Wed Jan 28 00:00:00 1970 | 7  | 7          | foo
+  637 | 407 | 00637_update7      | Sat Feb 07 00:00:00 1970 PST | Sat Feb 07 00:00:00 1970 | 7  | 7          | foo
+  647 | 407 | 00647_update7      | Tue Feb 17 00:00:00 1970 PST | Tue Feb 17 00:00:00 1970 | 7  | 7          | foo
+  657 | 407 | 00657_update7      | Fri Feb 27 00:00:00 1970 PST | Fri Feb 27 00:00:00 1970 | 7  | 7          | foo
+  667 | 407 | 00667_update7      | Mon Mar 09 00:00:00 1970 PST | Mon Mar 09 00:00:00 1970 | 7  | 7          | foo
+  677 | 407 | 00677_update7      | Thu Mar 19 00:00:00 1970 PST | Thu Mar 19 00:00:00 1970 | 7  | 7          | foo
+  687 | 407 | 00687_update7      | Sun Mar 29 00:00:00 1970 PST | Sun Mar 29 00:00:00 1970 | 7  | 7          | foo
+  697 | 407 | 00697_update7      | Wed Apr 08 00:00:00 1970 PST | Wed Apr 08 00:00:00 1970 | 7  | 7          | foo
+  707 | 407 | 00707_update7      | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+  717 | 407 | 00717_update7      | Sun Jan 18 00:00:00 1970 PST | Sun Jan 18 00:00:00 1970 | 7  | 7          | foo
+  727 | 407 | 00727_update7      | Wed Jan 28 00:00:00 1970 PST | Wed Jan 28 00:00:00 1970 | 7  | 7          | foo
+  737 | 407 | 00737_update7      | Sat Feb 07 00:00:00 1970 PST | Sat Feb 07 00:00:00 1970 | 7  | 7          | foo
+  747 | 407 | 00747_update7      | Tue Feb 17 00:00:00 1970 PST | Tue Feb 17 00:00:00 1970 | 7  | 7          | foo
+  757 | 407 | 00757_update7      | Fri Feb 27 00:00:00 1970 PST | Fri Feb 27 00:00:00 1970 | 7  | 7          | foo
+  767 | 407 | 00767_update7      | Mon Mar 09 00:00:00 1970 PST | Mon Mar 09 00:00:00 1970 | 7  | 7          | foo
+  777 | 407 | 00777_update7      | Thu Mar 19 00:00:00 1970 PST | Thu Mar 19 00:00:00 1970 | 7  | 7          | foo
+  787 | 407 | 00787_update7      | Sun Mar 29 00:00:00 1970 PST | Sun Mar 29 00:00:00 1970 | 7  | 7          | foo
+  797 | 407 | 00797_update7      | Wed Apr 08 00:00:00 1970 PST | Wed Apr 08 00:00:00 1970 | 7  | 7          | foo
+  807 | 407 | 00807_update7      | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+  817 | 407 | 00817_update7      | Sun Jan 18 00:00:00 1970 PST | Sun Jan 18 00:00:00 1970 | 7  | 7          | foo
+  827 | 407 | 00827_update7      | Wed Jan 28 00:00:00 1970 PST | Wed Jan 28 00:00:00 1970 | 7  | 7          | foo
+  837 | 407 | 00837_update7      | Sat Feb 07 00:00:00 1970 PST | Sat Feb 07 00:00:00 1970 | 7  | 7          | foo
+  847 | 407 | 00847_update7      | Tue Feb 17 00:00:00 1970 PST | Tue Feb 17 00:00:00 1970 | 7  | 7          | foo
+  857 | 407 | 00857_update7      | Fri Feb 27 00:00:00 1970 PST | Fri Feb 27 00:00:00 1970 | 7  | 7          | foo
+  867 | 407 | 00867_update7      | Mon Mar 09 00:00:00 1970 PST | Mon Mar 09 00:00:00 1970 | 7  | 7          | foo
+  877 | 407 | 00877_update7      | Thu Mar 19 00:00:00 1970 PST | Thu Mar 19 00:00:00 1970 | 7  | 7          | foo
+  887 | 407 | 00887_update7      | Sun Mar 29 00:00:00 1970 PST | Sun Mar 29 00:00:00 1970 | 7  | 7          | foo
+  897 | 407 | 00897_update7      | Wed Apr 08 00:00:00 1970 PST | Wed Apr 08 00:00:00 1970 | 7  | 7          | foo
+  907 | 407 | 00907_update7      | Thu Jan 08 00:00:00 1970 PST | Thu Jan 08 00:00:00 1970 | 7  | 7          | foo
+  917 | 407 | 00917_update7      | Sun Jan 18 00:00:00 1970 PST | Sun Jan 18 00:00:00 1970 | 7  | 7          | foo
+  927 | 407 | 00927_update7      | Wed Jan 28 00:00:00 1970 PST | Wed Jan 28 00:00:00 1970 | 7  | 7          | foo
+  937 | 407 | 00937_update7      | Sat Feb 07 00:00:00 1970 PST | Sat Feb 07 00:00:00 1970 | 7  | 7          | foo
+  947 | 407 | 00947_update7      | Tue Feb 17 00:00:00 1970 PST | Tue Feb 17 00:00:00 1970 | 7  | 7          | foo
+  957 | 407 | 00957_update7      | Fri Feb 27 00:00:00 1970 PST | Fri Feb 27 00:00:00 1970 | 7  | 7          | foo
+  967 | 407 | 00967_update7      | Mon Mar 09 00:00:00 1970 PST | Mon Mar 09 00:00:00 1970 | 7  | 7          | foo
+  977 | 407 | 00977_update7      | Thu Mar 19 00:00:00 1970 PST | Thu Mar 19 00:00:00 1970 | 7  | 7          | foo
+  987 | 407 | 00987_update7      | Sun Mar 29 00:00:00 1970 PST | Sun Mar 29 00:00:00 1970 | 7  | 7          | foo
+  997 | 407 | 00997_update7      | Wed Apr 08 00:00:00 1970 PST | Wed Apr 08 00:00:00 1970 | 7  | 7          | foo
+ 1007 | 507 | 0000700007_update7 |                              |                          |    | ft2        | 
+ 1017 | 507 | 0001700017_update7 |                              |                          |    | ft2        | 
+(102 rows)
+
+EXPLAIN (verbose, costs off)
+UPDATE ft2 SET c2 = ft2.c2 + 500, c3 = ft2.c3 || '_update9', c7 = DEFAULT
+  FROM ft1 WHERE ft1.c1 = ft2.c2 AND ft1.c1 % 10 = 9;                               -- can be pushed down
+                                                                                                   QUERY PLAN                                                                                                    
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Update on public.ft2
+   ->  Foreign Update
+         Remote SQL: UPDATE "S 1"."T 1" r1 SET c2 = (r1.c2 + 500), c3 = (r1.c3 || '_update9'::text), c7 = 'ft2       '::character(10) FROM "S 1"."T 1" r2 WHERE ((r1.c2 = r2."C 1")) AND (((r2."C 1" % 10) = 9))
+(3 rows)
+
+UPDATE ft2 SET c2 = ft2.c2 + 500, c3 = ft2.c3 || '_update9', c7 = DEFAULT
+  FROM ft1 WHERE ft1.c1 = ft2.c2 AND ft1.c1 % 10 = 9;
+EXPLAIN (verbose, costs off)
+  DELETE FROM ft2 WHERE c1 % 10 = 5 RETURNING c1, c4;                               -- can be pushed down
+                                         QUERY PLAN                                         
+--------------------------------------------------------------------------------------------
+ Delete on public.ft2
+   Output: c1, c4
+   ->  Foreign Delete on public.ft2
+         Remote SQL: DELETE FROM "S 1"."T 1" WHERE ((("C 1" % 10) = 5)) RETURNING "C 1", c4
+(4 rows)
+
+DELETE FROM ft2 WHERE c1 % 10 = 5 RETURNING c1, c4;
+  c1  |              c4              
+------+------------------------------
+    5 | Tue Jan 06 00:00:00 1970 PST
+   15 | Fri Jan 16 00:00:00 1970 PST
+   25 | Mon Jan 26 00:00:00 1970 PST
+   35 | Thu Feb 05 00:00:00 1970 PST
+   45 | Sun Feb 15 00:00:00 1970 PST
+   55 | Wed Feb 25 00:00:00 1970 PST
+   65 | Sat Mar 07 00:00:00 1970 PST
+   75 | Tue Mar 17 00:00:00 1970 PST
+   85 | Fri Mar 27 00:00:00 1970 PST
+   95 | Mon Apr 06 00:00:00 1970 PST
+  105 | Tue Jan 06 00:00:00 1970 PST
+  115 | Fri Jan 16 00:00:00 1970 PST
+  125 | Mon Jan 26 00:00:00 1970 PST
+  135 | Thu Feb 05 00:00:00 1970 PST
+  145 | Sun Feb 15 00:00:00 1970 PST
+  155 | Wed Feb 25 00:00:00 1970 PST
+  165 | Sat Mar 07 00:00:00 1970 PST
+  175 | Tue Mar 17 00:00:00 1970 PST
+  185 | Fri Mar 27 00:00:00 1970 PST
+  195 | Mon Apr 06 00:00:00 1970 PST
+  205 | Tue Jan 06 00:00:00 1970 PST
+  215 | Fri Jan 16 00:00:00 1970 PST
+  225 | Mon Jan 26 00:00:00 1970 PST
+  235 | Thu Feb 05 00:00:00 1970 PST
+  245 | Sun Feb 15 00:00:00 1970 PST
+  255 | Wed Feb 25 00:00:00 1970 PST
+  265 | Sat Mar 07 00:00:00 1970 PST
+  275 | Tue Mar 17 00:00:00 1970 PST
+  285 | Fri Mar 27 00:00:00 1970 PST
+  295 | Mon Apr 06 00:00:00 1970 PST
+  305 | Tue Jan 06 00:00:00 1970 PST
+  315 | Fri Jan 16 00:00:00 1970 PST
+  325 | Mon Jan 26 00:00:00 1970 PST
+  335 | Thu Feb 05 00:00:00 1970 PST
+  345 | Sun Feb 15 00:00:00 1970 PST
+  355 | Wed Feb 25 00:00:00 1970 PST
+  365 | Sat Mar 07 00:00:00 1970 PST
+  375 | Tue Mar 17 00:00:00 1970 PST
+  385 | Fri Mar 27 00:00:00 1970 PST
+  395 | Mon Apr 06 00:00:00 1970 PST
+  405 | Tue Jan 06 00:00:00 1970 PST
+  415 | Fri Jan 16 00:00:00 1970 PST
+  425 | Mon Jan 26 00:00:00 1970 PST
+  435 | Thu Feb 05 00:00:00 1970 PST
+  445 | Sun Feb 15 00:00:00 1970 PST
+  455 | Wed Feb 25 00:00:00 1970 PST
+  465 | Sat Mar 07 00:00:00 1970 PST
+  475 | Tue Mar 17 00:00:00 1970 PST
+  485 | Fri Mar 27 00:00:00 1970 PST
+  495 | Mon Apr 06 00:00:00 1970 PST
+  505 | Tue Jan 06 00:00:00 1970 PST
+  515 | Fri Jan 16 00:00:00 1970 PST
+  525 | Mon Jan 26 00:00:00 1970 PST
+  535 | Thu Feb 05 00:00:00 1970 PST
+  545 | Sun Feb 15 00:00:00 1970 PST
+  555 | Wed Feb 25 00:00:00 1970 PST
+  565 | Sat Mar 07 00:00:00 1970 PST
+  575 | Tue Mar 17 00:00:00 1970 PST
+  585 | Fri Mar 27 00:00:00 1970 PST
+  595 | Mon Apr 06 00:00:00 1970 PST
+  605 | Tue Jan 06 00:00:00 1970 PST
+  615 | Fri Jan 16 00:00:00 1970 PST
+  625 | Mon Jan 26 00:00:00 1970 PST
+  635 | Thu Feb 05 00:00:00 1970 PST
+  645 | Sun Feb 15 00:00:00 1970 PST
+  655 | Wed Feb 25 00:00:00 1970 PST
+  665 | Sat Mar 07 00:00:00 1970 PST
+  675 | Tue Mar 17 00:00:00 1970 PST
+  685 | Fri Mar 27 00:00:00 1970 PST
+  695 | Mon Apr 06 00:00:00 1970 PST
+  705 | Tue Jan 06 00:00:00 1970 PST
+  715 | Fri Jan 16 00:00:00 1970 PST
+  725 | Mon Jan 26 00:00:00 1970 PST
+  735 | Thu Feb 05 00:00:00 1970 PST
+  745 | Sun Feb 15 00:00:00 1970 PST
+  755 | Wed Feb 25 00:00:00 1970 PST
+  765 | Sat Mar 07 00:00:00 1970 PST
+  775 | Tue Mar 17 00:00:00 1970 PST
+  785 | Fri Mar 27 00:00:00 1970 PST
+  795 | Mon Apr 06 00:00:00 1970 PST
+  805 | Tue Jan 06 00:00:00 1970 PST
+  815 | Fri Jan 16 00:00:00 1970 PST
+  825 | Mon Jan 26 00:00:00 1970 PST
+  835 | Thu Feb 05 00:00:00 1970 PST
+  845 | Sun Feb 15 00:00:00 1970 PST
+  855 | Wed Feb 25 00:00:00 1970 PST
+  865 | Sat Mar 07 00:00:00 1970 PST
+  875 | Tue Mar 17 00:00:00 1970 PST
+  885 | Fri Mar 27 00:00:00 1970 PST
+  895 | Mon Apr 06 00:00:00 1970 PST
+  905 | Tue Jan 06 00:00:00 1970 PST
+  915 | Fri Jan 16 00:00:00 1970 PST
+  925 | Mon Jan 26 00:00:00 1970 PST
+  935 | Thu Feb 05 00:00:00 1970 PST
+  945 | Sun Feb 15 00:00:00 1970 PST
+  955 | Wed Feb 25 00:00:00 1970 PST
+  965 | Sat Mar 07 00:00:00 1970 PST
+  975 | Tue Mar 17 00:00:00 1970 PST
+  985 | Fri Mar 27 00:00:00 1970 PST
+  995 | Mon Apr 06 00:00:00 1970 PST
+ 1005 | 
+ 1015 | 
+ 1105 | 
+(103 rows)
+
+EXPLAIN (verbose, costs off)
+DELETE FROM ft2 USING ft1 WHERE ft1.c1 = ft2.c2 AND ft1.c1 % 10 = 2;                -- can be pushed down
+                                                         QUERY PLAN                                                         
+----------------------------------------------------------------------------------------------------------------------------
+ Delete on public.ft2
+   ->  Foreign Delete
+         Remote SQL: DELETE FROM "S 1"."T 1" r1 USING "S 1"."T 1" r2 WHERE ((r1.c2 = r2."C 1")) AND (((r2."C 1" % 10) = 2))
+(3 rows)
+
+DELETE FROM ft2 USING ft1 WHERE ft1.c1 = ft2.c2 AND ft1.c1 % 10 = 2;
+SELECT c1,c2,c3,c4 FROM ft2 ORDER BY c1;
+  c1  | c2  |         c3         |              c4              
+------+-----+--------------------+------------------------------
+    1 |   1 | 00001              | Fri Jan 02 00:00:00 1970 PST
+    3 | 303 | 00003_update3      | Sun Jan 04 00:00:00 1970 PST
+    4 |   4 | 00004              | Mon Jan 05 00:00:00 1970 PST
+    6 |   6 | 00006              | Wed Jan 07 00:00:00 1970 PST
+    7 | 407 | 00007_update7      | Thu Jan 08 00:00:00 1970 PST
+    8 |   8 | 00008              | Fri Jan 09 00:00:00 1970 PST
+    9 | 509 | 00009_update9      | Sat Jan 10 00:00:00 1970 PST
+   10 |   0 | 00010              | Sun Jan 11 00:00:00 1970 PST
+   11 |   1 | 00011              | Mon Jan 12 00:00:00 1970 PST
+   13 | 303 | 00013_update3      | Wed Jan 14 00:00:00 1970 PST
+   14 |   4 | 00014              | Thu Jan 15 00:00:00 1970 PST
+   16 |   6 | 00016              | Sat Jan 17 00:00:00 1970 PST
+   17 | 407 | 00017_update7      | Sun Jan 18 00:00:00 1970 PST
+   18 |   8 | 00018              | Mon Jan 19 00:00:00 1970 PST
+   19 | 509 | 00019_update9      | Tue Jan 20 00:00:00 1970 PST
+   20 |   0 | 00020              | Wed Jan 21 00:00:00 1970 PST
+   21 |   1 | 00021              | Thu Jan 22 00:00:00 1970 PST
+   23 | 303 | 00023_update3      | Sat Jan 24 00:00:00 1970 PST
+   24 |   4 | 00024              | Sun Jan 25 00:00:00 1970 PST
+   26 |   6 | 00026              | Tue Jan 27 00:00:00 1970 PST
+   27 | 407 | 00027_update7      | Wed Jan 28 00:00:00 1970 PST
+   28 |   8 | 00028              | Thu Jan 29 00:00:00 1970 PST
+   29 | 509 | 00029_update9      | Fri Jan 30 00:00:00 1970 PST
+   30 |   0 | 00030              | Sat Jan 31 00:00:00 1970 PST
+   31 |   1 | 00031              | Sun Feb 01 00:00:00 1970 PST
+   33 | 303 | 00033_update3      | Tue Feb 03 00:00:00 1970 PST
+   34 |   4 | 00034              | Wed Feb 04 00:00:00 1970 PST
+   36 |   6 | 00036              | Fri Feb 06 00:00:00 1970 PST
+   37 | 407 | 00037_update7      | Sat Feb 07 00:00:00 1970 PST
+   38 |   8 | 00038              | Sun Feb 08 00:00:00 1970 PST
+   39 | 509 | 00039_update9      | Mon Feb 09 00:00:00 1970 PST
+   40 |   0 | 00040              | Tue Feb 10 00:00:00 1970 PST
+   41 |   1 | 00041              | Wed Feb 11 00:00:00 1970 PST
+   43 | 303 | 00043_update3      | Fri Feb 13 00:00:00 1970 PST
+   44 |   4 | 00044              | Sat Feb 14 00:00:00 1970 PST
+   46 |   6 | 00046              | Mon Feb 16 00:00:00 1970 PST
+   47 | 407 | 00047_update7      | Tue Feb 17 00:00:00 1970 PST
+   48 |   8 | 00048              | Wed Feb 18 00:00:00 1970 PST
+   49 | 509 | 00049_update9      | Thu Feb 19 00:00:00 1970 PST
+   50 |   0 | 00050              | Fri Feb 20 00:00:00 1970 PST
+   51 |   1 | 00051              | Sat Feb 21 00:00:00 1970 PST
+   53 | 303 | 00053_update3      | Mon Feb 23 00:00:00 1970 PST
+   54 |   4 | 00054              | Tue Feb 24 00:00:00 1970 PST
+   56 |   6 | 00056              | Thu Feb 26 00:00:00 1970 PST
+   57 | 407 | 00057_update7      | Fri Feb 27 00:00:00 1970 PST
+   58 |   8 | 00058              | Sat Feb 28 00:00:00 1970 PST
+   59 | 509 | 00059_update9      | Sun Mar 01 00:00:00 1970 PST
+   60 |   0 | 00060              | Mon Mar 02 00:00:00 1970 PST
+   61 |   1 | 00061              | Tue Mar 03 00:00:00 1970 PST
+   63 | 303 | 00063_update3      | Thu Mar 05 00:00:00 1970 PST
+   64 |   4 | 00064              | Fri Mar 06 00:00:00 1970 PST
+   66 |   6 | 00066              | Sun Mar 08 00:00:00 1970 PST
+   67 | 407 | 00067_update7      | Mon Mar 09 00:00:00 1970 PST
+   68 |   8 | 00068              | Tue Mar 10 00:00:00 1970 PST
+   69 | 509 | 00069_update9      | Wed Mar 11 00:00:00 1970 PST
+   70 |   0 | 00070              | Thu Mar 12 00:00:00 1970 PST
+   71 |   1 | 00071              | Fri Mar 13 00:00:00 1970 PST
+   73 | 303 | 00073_update3      | Sun Mar 15 00:00:00 1970 PST
+   74 |   4 | 00074              | Mon Mar 16 00:00:00 1970 PST
+   76 |   6 | 00076              | Wed Mar 18 00:00:00 1970 PST
+   77 | 407 | 00077_update7      | Thu Mar 19 00:00:00 1970 PST
+   78 |   8 | 00078              | Fri Mar 20 00:00:00 1970 PST
+   79 | 509 | 00079_update9      | Sat Mar 21 00:00:00 1970 PST
+   80 |   0 | 00080              | Sun Mar 22 00:00:00 1970 PST
+   81 |   1 | 00081              | Mon Mar 23 00:00:00 1970 PST
+   83 | 303 | 00083_update3      | Wed Mar 25 00:00:00 1970 PST
+   84 |   4 | 00084              | Thu Mar 26 00:00:00 1970 PST
+   86 |   6 | 00086              | Sat Mar 28 00:00:00 1970 PST
+   87 | 407 | 00087_update7      | Sun Mar 29 00:00:00 1970 PST
+   88 |   8 | 00088              | Mon Mar 30 00:00:00 1970 PST
+   89 | 509 | 00089_update9      | Tue Mar 31 00:00:00 1970 PST
+   90 |   0 | 00090              | Wed Apr 01 00:00:00 1970 PST
+   91 |   1 | 00091              | Thu Apr 02 00:00:00 1970 PST
+   93 | 303 | 00093_update3      | Sat Apr 04 00:00:00 1970 PST
+   94 |   4 | 00094              | Sun Apr 05 00:00:00 1970 PST
+   96 |   6 | 00096              | Tue Apr 07 00:00:00 1970 PST
+   97 | 407 | 00097_update7      | Wed Apr 08 00:00:00 1970 PST
+   98 |   8 | 00098              | Thu Apr 09 00:00:00 1970 PST
+   99 | 509 | 00099_update9      | Fri Apr 10 00:00:00 1970 PST
+  100 |   0 | 00100              | Thu Jan 01 00:00:00 1970 PST
+  101 |   1 | 00101              | Fri Jan 02 00:00:00 1970 PST
+  103 | 303 | 00103_update3      | Sun Jan 04 00:00:00 1970 PST
+  104 |   4 | 00104              | Mon Jan 05 00:00:00 1970 PST
+  106 |   6 | 00106              | Wed Jan 07 00:00:00 1970 PST
+  107 | 407 | 00107_update7      | Thu Jan 08 00:00:00 1970 PST
+  108 |   8 | 00108              | Fri Jan 09 00:00:00 1970 PST
+  109 | 509 | 00109_update9      | Sat Jan 10 00:00:00 1970 PST
+  110 |   0 | 00110              | Sun Jan 11 00:00:00 1970 PST
+  111 |   1 | 00111              | Mon Jan 12 00:00:00 1970 PST
+  113 | 303 | 00113_update3      | Wed Jan 14 00:00:00 1970 PST
+  114 |   4 | 00114              | Thu Jan 15 00:00:00 1970 PST
+  116 |   6 | 00116              | Sat Jan 17 00:00:00 1970 PST
+  117 | 407 | 00117_update7      | Sun Jan 18 00:00:00 1970 PST
+  118 |   8 | 00118              | Mon Jan 19 00:00:00 1970 PST
+  119 | 509 | 00119_update9      | Tue Jan 20 00:00:00 1970 PST
+  120 |   0 | 00120              | Wed Jan 21 00:00:00 1970 PST
+  121 |   1 | 00121              | Thu Jan 22 00:00:00 1970 PST
+  123 | 303 | 00123_update3      | Sat Jan 24 00:00:00 1970 PST
+  124 |   4 | 00124              | Sun Jan 25 00:00:00 1970 PST
+  126 |   6 | 00126              | Tue Jan 27 00:00:00 1970 PST
+  127 | 407 | 00127_update7      | Wed Jan 28 00:00:00 1970 PST
+  128 |   8 | 00128              | Thu Jan 29 00:00:00 1970 PST
+  129 | 509 | 00129_update9      | Fri Jan 30 00:00:00 1970 PST
+  130 |   0 | 00130              | Sat Jan 31 00:00:00 1970 PST
+  131 |   1 | 00131              | Sun Feb 01 00:00:00 1970 PST
+  133 | 303 | 00133_update3      | Tue Feb 03 00:00:00 1970 PST
+  134 |   4 | 00134              | Wed Feb 04 00:00:00 1970 PST
+  136 |   6 | 00136              | Fri Feb 06 00:00:00 1970 PST
+  137 | 407 | 00137_update7      | Sat Feb 07 00:00:00 1970 PST
+  138 |   8 | 00138              | Sun Feb 08 00:00:00 1970 PST
+  139 | 509 | 00139_update9      | Mon Feb 09 00:00:00 1970 PST
+  140 |   0 | 00140              | Tue Feb 10 00:00:00 1970 PST
+  141 |   1 | 00141              | Wed Feb 11 00:00:00 1970 PST
+  143 | 303 | 00143_update3      | Fri Feb 13 00:00:00 1970 PST
+  144 |   4 | 00144              | Sat Feb 14 00:00:00 1970 PST
+  146 |   6 | 00146              | Mon Feb 16 00:00:00 1970 PST
+  147 | 407 | 00147_update7      | Tue Feb 17 00:00:00 1970 PST
+  148 |   8 | 00148              | Wed Feb 18 00:00:00 1970 PST
+  149 | 509 | 00149_update9      | Thu Feb 19 00:00:00 1970 PST
+  150 |   0 | 00150              | Fri Feb 20 00:00:00 1970 PST
+  151 |   1 | 00151              | Sat Feb 21 00:00:00 1970 PST
+  153 | 303 | 00153_update3      | Mon Feb 23 00:00:00 1970 PST
+  154 |   4 | 00154              | Tue Feb 24 00:00:00 1970 PST
+  156 |   6 | 00156              | Thu Feb 26 00:00:00 1970 PST
+  157 | 407 | 00157_update7      | Fri Feb 27 00:00:00 1970 PST
+  158 |   8 | 00158              | Sat Feb 28 00:00:00 1970 PST
+  159 | 509 | 00159_update9      | Sun Mar 01 00:00:00 1970 PST
+  160 |   0 | 00160              | Mon Mar 02 00:00:00 1970 PST
+  161 |   1 | 00161              | Tue Mar 03 00:00:00 1970 PST
+  163 | 303 | 00163_update3      | Thu Mar 05 00:00:00 1970 PST
+  164 |   4 | 00164              | Fri Mar 06 00:00:00 1970 PST
+  166 |   6 | 00166              | Sun Mar 08 00:00:00 1970 PST
+  167 | 407 | 00167_update7      | Mon Mar 09 00:00:00 1970 PST
+  168 |   8 | 00168              | Tue Mar 10 00:00:00 1970 PST
+  169 | 509 | 00169_update9      | Wed Mar 11 00:00:00 1970 PST
+  170 |   0 | 00170              | Thu Mar 12 00:00:00 1970 PST
+  171 |   1 | 00171              | Fri Mar 13 00:00:00 1970 PST
+  173 | 303 | 00173_update3      | Sun Mar 15 00:00:00 1970 PST
+  174 |   4 | 00174              | Mon Mar 16 00:00:00 1970 PST
+  176 |   6 | 00176              | Wed Mar 18 00:00:00 1970 PST
+  177 | 407 | 00177_update7      | Thu Mar 19 00:00:00 1970 PST
+  178 |   8 | 00178              | Fri Mar 20 00:00:00 1970 PST
+  179 | 509 | 00179_update9      | Sat Mar 21 00:00:00 1970 PST
+  180 |   0 | 00180              | Sun Mar 22 00:00:00 1970 PST
+  181 |   1 | 00181              | Mon Mar 23 00:00:00 1970 PST
+  183 | 303 | 00183_update3      | Wed Mar 25 00:00:00 1970 PST
+  184 |   4 | 00184              | Thu Mar 26 00:00:00 1970 PST
+  186 |   6 | 00186              | Sat Mar 28 00:00:00 1970 PST
+  187 | 407 | 00187_update7      | Sun Mar 29 00:00:00 1970 PST
+  188 |   8 | 00188              | Mon Mar 30 00:00:00 1970 PST
+  189 | 509 | 00189_update9      | Tue Mar 31 00:00:00 1970 PST
+  190 |   0 | 00190              | Wed Apr 01 00:00:00 1970 PST
+  191 |   1 | 00191              | Thu Apr 02 00:00:00 1970 PST
+  193 | 303 | 00193_update3      | Sat Apr 04 00:00:00 1970 PST
+  194 |   4 | 00194              | Sun Apr 05 00:00:00 1970 PST
+  196 |   6 | 00196              | Tue Apr 07 00:00:00 1970 PST
+  197 | 407 | 00197_update7      | Wed Apr 08 00:00:00 1970 PST
+  198 |   8 | 00198              | Thu Apr 09 00:00:00 1970 PST
+  199 | 509 | 00199_update9      | Fri Apr 10 00:00:00 1970 PST
+  200 |   0 | 00200              | Thu Jan 01 00:00:00 1970 PST
+  201 |   1 | 00201              | Fri Jan 02 00:00:00 1970 PST
+  203 | 303 | 00203_update3      | Sun Jan 04 00:00:00 1970 PST
+  204 |   4 | 00204              | Mon Jan 05 00:00:00 1970 PST
+  206 |   6 | 00206              | Wed Jan 07 00:00:00 1970 PST
+  207 | 407 | 00207_update7      | Thu Jan 08 00:00:00 1970 PST
+  208 |   8 | 00208              | Fri Jan 09 00:00:00 1970 PST
+  209 | 509 | 00209_update9      | Sat Jan 10 00:00:00 1970 PST
+  210 |   0 | 00210              | Sun Jan 11 00:00:00 1970 PST
+  211 |   1 | 00211              | Mon Jan 12 00:00:00 1970 PST
+  213 | 303 | 00213_update3      | Wed Jan 14 00:00:00 1970 PST
+  214 |   4 | 00214              | Thu Jan 15 00:00:00 1970 PST
+  216 |   6 | 00216              | Sat Jan 17 00:00:00 1970 PST
+  217 | 407 | 00217_update7      | Sun Jan 18 00:00:00 1970 PST
+  218 |   8 | 00218              | Mon Jan 19 00:00:00 1970 PST
+  219 | 509 | 00219_update9      | Tue Jan 20 00:00:00 1970 PST
+  220 |   0 | 00220              | Wed Jan 21 00:00:00 1970 PST
+  221 |   1 | 00221              | Thu Jan 22 00:00:00 1970 PST
+  223 | 303 | 00223_update3      | Sat Jan 24 00:00:00 1970 PST
+  224 |   4 | 00224              | Sun Jan 25 00:00:00 1970 PST
+  226 |   6 | 00226              | Tue Jan 27 00:00:00 1970 PST
+  227 | 407 | 00227_update7      | Wed Jan 28 00:00:00 1970 PST
+  228 |   8 | 00228              | Thu Jan 29 00:00:00 1970 PST
+  229 | 509 | 00229_update9      | Fri Jan 30 00:00:00 1970 PST
+  230 |   0 | 00230              | Sat Jan 31 00:00:00 1970 PST
+  231 |   1 | 00231              | Sun Feb 01 00:00:00 1970 PST
+  233 | 303 | 00233_update3      | Tue Feb 03 00:00:00 1970 PST
+  234 |   4 | 00234              | Wed Feb 04 00:00:00 1970 PST
+  236 |   6 | 00236              | Fri Feb 06 00:00:00 1970 PST
+  237 | 407 | 00237_update7      | Sat Feb 07 00:00:00 1970 PST
+  238 |   8 | 00238              | Sun Feb 08 00:00:00 1970 PST
+  239 | 509 | 00239_update9      | Mon Feb 09 00:00:00 1970 PST
+  240 |   0 | 00240              | Tue Feb 10 00:00:00 1970 PST
+  241 |   1 | 00241              | Wed Feb 11 00:00:00 1970 PST
+  243 | 303 | 00243_update3      | Fri Feb 13 00:00:00 1970 PST
+  244 |   4 | 00244              | Sat Feb 14 00:00:00 1970 PST
+  246 |   6 | 00246              | Mon Feb 16 00:00:00 1970 PST
+  247 | 407 | 00247_update7      | Tue Feb 17 00:00:00 1970 PST
+  248 |   8 | 00248              | Wed Feb 18 00:00:00 1970 PST
+  249 | 509 | 00249_update9      | Thu Feb 19 00:00:00 1970 PST
+  250 |   0 | 00250              | Fri Feb 20 00:00:00 1970 PST
+  251 |   1 | 00251              | Sat Feb 21 00:00:00 1970 PST
+  253 | 303 | 00253_update3      | Mon Feb 23 00:00:00 1970 PST
+  254 |   4 | 00254              | Tue Feb 24 00:00:00 1970 PST
+  256 |   6 | 00256              | Thu Feb 26 00:00:00 1970 PST
+  257 | 407 | 00257_update7      | Fri Feb 27 00:00:00 1970 PST
+  258 |   8 | 00258              | Sat Feb 28 00:00:00 1970 PST
+  259 | 509 | 00259_update9      | Sun Mar 01 00:00:00 1970 PST
+  260 |   0 | 00260              | Mon Mar 02 00:00:00 1970 PST
+  261 |   1 | 00261              | Tue Mar 03 00:00:00 1970 PST
+  263 | 303 | 00263_update3      | Thu Mar 05 00:00:00 1970 PST
+  264 |   4 | 00264              | Fri Mar 06 00:00:00 1970 PST
+  266 |   6 | 00266              | Sun Mar 08 00:00:00 1970 PST
+  267 | 407 | 00267_update7      | Mon Mar 09 00:00:00 1970 PST
+  268 |   8 | 00268              | Tue Mar 10 00:00:00 1970 PST
+  269 | 509 | 00269_update9      | Wed Mar 11 00:00:00 1970 PST
+  270 |   0 | 00270              | Thu Mar 12 00:00:00 1970 PST
+  271 |   1 | 00271              | Fri Mar 13 00:00:00 1970 PST
+  273 | 303 | 00273_update3      | Sun Mar 15 00:00:00 1970 PST
+  274 |   4 | 00274              | Mon Mar 16 00:00:00 1970 PST
+  276 |   6 | 00276              | Wed Mar 18 00:00:00 1970 PST
+  277 | 407 | 00277_update7      | Thu Mar 19 00:00:00 1970 PST
+  278 |   8 | 00278              | Fri Mar 20 00:00:00 1970 PST
+  279 | 509 | 00279_update9      | Sat Mar 21 00:00:00 1970 PST
+  280 |   0 | 00280              | Sun Mar 22 00:00:00 1970 PST
+  281 |   1 | 00281              | Mon Mar 23 00:00:00 1970 PST
+  283 | 303 | 00283_update3      | Wed Mar 25 00:00:00 1970 PST
+  284 |   4 | 00284              | Thu Mar 26 00:00:00 1970 PST
+  286 |   6 | 00286              | Sat Mar 28 00:00:00 1970 PST
+  287 | 407 | 00287_update7      | Sun Mar 29 00:00:00 1970 PST
+  288 |   8 | 00288              | Mon Mar 30 00:00:00 1970 PST
+  289 | 509 | 00289_update9      | Tue Mar 31 00:00:00 1970 PST
+  290 |   0 | 00290              | Wed Apr 01 00:00:00 1970 PST
+  291 |   1 | 00291              | Thu Apr 02 00:00:00 1970 PST
+  293 | 303 | 00293_update3      | Sat Apr 04 00:00:00 1970 PST
+  294 |   4 | 00294              | Sun Apr 05 00:00:00 1970 PST
+  296 |   6 | 00296              | Tue Apr 07 00:00:00 1970 PST
+  297 | 407 | 00297_update7      | Wed Apr 08 00:00:00 1970 PST
+  298 |   8 | 00298              | Thu Apr 09 00:00:00 1970 PST
+  299 | 509 | 00299_update9      | Fri Apr 10 00:00:00 1970 PST
+  300 |   0 | 00300              | Thu Jan 01 00:00:00 1970 PST
+  301 |   1 | 00301              | Fri Jan 02 00:00:00 1970 PST
+  303 | 303 | 00303_update3      | Sun Jan 04 00:00:00 1970 PST
+  304 |   4 | 00304              | Mon Jan 05 00:00:00 1970 PST
+  306 |   6 | 00306              | Wed Jan 07 00:00:00 1970 PST
+  307 | 407 | 00307_update7      | Thu Jan 08 00:00:00 1970 PST
+  308 |   8 | 00308              | Fri Jan 09 00:00:00 1970 PST
+  309 | 509 | 00309_update9      | Sat Jan 10 00:00:00 1970 PST
+  310 |   0 | 00310              | Sun Jan 11 00:00:00 1970 PST
+  311 |   1 | 00311              | Mon Jan 12 00:00:00 1970 PST
+  313 | 303 | 00313_update3      | Wed Jan 14 00:00:00 1970 PST
+  314 |   4 | 00314              | Thu Jan 15 00:00:00 1970 PST
+  316 |   6 | 00316              | Sat Jan 17 00:00:00 1970 PST
+  317 | 407 | 00317_update7      | Sun Jan 18 00:00:00 1970 PST
+  318 |   8 | 00318              | Mon Jan 19 00:00:00 1970 PST
+  319 | 509 | 00319_update9      | Tue Jan 20 00:00:00 1970 PST
+  320 |   0 | 00320              | Wed Jan 21 00:00:00 1970 PST
+  321 |   1 | 00321              | Thu Jan 22 00:00:00 1970 PST
+  323 | 303 | 00323_update3      | Sat Jan 24 00:00:00 1970 PST
+  324 |   4 | 00324              | Sun Jan 25 00:00:00 1970 PST
+  326 |   6 | 00326              | Tue Jan 27 00:00:00 1970 PST
+  327 | 407 | 00327_update7      | Wed Jan 28 00:00:00 1970 PST
+  328 |   8 | 00328              | Thu Jan 29 00:00:00 1970 PST
+  329 | 509 | 00329_update9      | Fri Jan 30 00:00:00 1970 PST
+  330 |   0 | 00330              | Sat Jan 31 00:00:00 1970 PST
+  331 |   1 | 00331              | Sun Feb 01 00:00:00 1970 PST
+  333 | 303 | 00333_update3      | Tue Feb 03 00:00:00 1970 PST
+  334 |   4 | 00334              | Wed Feb 04 00:00:00 1970 PST
+  336 |   6 | 00336              | Fri Feb 06 00:00:00 1970 PST
+  337 | 407 | 00337_update7      | Sat Feb 07 00:00:00 1970 PST
+  338 |   8 | 00338              | Sun Feb 08 00:00:00 1970 PST
+  339 | 509 | 00339_update9      | Mon Feb 09 00:00:00 1970 PST
+  340 |   0 | 00340              | Tue Feb 10 00:00:00 1970 PST
+  341 |   1 | 00341              | Wed Feb 11 00:00:00 1970 PST
+  343 | 303 | 00343_update3      | Fri Feb 13 00:00:00 1970 PST
+  344 |   4 | 00344              | Sat Feb 14 00:00:00 1970 PST
+  346 |   6 | 00346              | Mon Feb 16 00:00:00 1970 PST
+  347 | 407 | 00347_update7      | Tue Feb 17 00:00:00 1970 PST
+  348 |   8 | 00348              | Wed Feb 18 00:00:00 1970 PST
+  349 | 509 | 00349_update9      | Thu Feb 19 00:00:00 1970 PST
+  350 |   0 | 00350              | Fri Feb 20 00:00:00 1970 PST
+  351 |   1 | 00351              | Sat Feb 21 00:00:00 1970 PST
+  353 | 303 | 00353_update3      | Mon Feb 23 00:00:00 1970 PST
+  354 |   4 | 00354              | Tue Feb 24 00:00:00 1970 PST
+  356 |   6 | 00356              | Thu Feb 26 00:00:00 1970 PST
+  357 | 407 | 00357_update7      | Fri Feb 27 00:00:00 1970 PST
+  358 |   8 | 00358              | Sat Feb 28 00:00:00 1970 PST
+  359 | 509 | 00359_update9      | Sun Mar 01 00:00:00 1970 PST
+  360 |   0 | 00360              | Mon Mar 02 00:00:00 1970 PST
+  361 |   1 | 00361              | Tue Mar 03 00:00:00 1970 PST
+  363 | 303 | 00363_update3      | Thu Mar 05 00:00:00 1970 PST
+  364 |   4 | 00364              | Fri Mar 06 00:00:00 1970 PST
+  366 |   6 | 00366              | Sun Mar 08 00:00:00 1970 PST
+  367 | 407 | 00367_update7      | Mon Mar 09 00:00:00 1970 PST
+  368 |   8 | 00368              | Tue Mar 10 00:00:00 1970 PST
+  369 | 509 | 00369_update9      | Wed Mar 11 00:00:00 1970 PST
+  370 |   0 | 00370              | Thu Mar 12 00:00:00 1970 PST
+  371 |   1 | 00371              | Fri Mar 13 00:00:00 1970 PST
+  373 | 303 | 00373_update3      | Sun Mar 15 00:00:00 1970 PST
+  374 |   4 | 00374              | Mon Mar 16 00:00:00 1970 PST
+  376 |   6 | 00376              | Wed Mar 18 00:00:00 1970 PST
+  377 | 407 | 00377_update7      | Thu Mar 19 00:00:00 1970 PST
+  378 |   8 | 00378              | Fri Mar 20 00:00:00 1970 PST
+  379 | 509 | 00379_update9      | Sat Mar 21 00:00:00 1970 PST
+  380 |   0 | 00380              | Sun Mar 22 00:00:00 1970 PST
+  381 |   1 | 00381              | Mon Mar 23 00:00:00 1970 PST
+  383 | 303 | 00383_update3      | Wed Mar 25 00:00:00 1970 PST
+  384 |   4 | 00384              | Thu Mar 26 00:00:00 1970 PST
+  386 |   6 | 00386              | Sat Mar 28 00:00:00 1970 PST
+  387 | 407 | 00387_update7      | Sun Mar 29 00:00:00 1970 PST
+  388 |   8 | 00388              | Mon Mar 30 00:00:00 1970 PST
+  389 | 509 | 00389_update9      | Tue Mar 31 00:00:00 1970 PST
+  390 |   0 | 00390              | Wed Apr 01 00:00:00 1970 PST
+  391 |   1 | 00391              | Thu Apr 02 00:00:00 1970 PST
+  393 | 303 | 00393_update3      | Sat Apr 04 00:00:00 1970 PST
+  394 |   4 | 00394              | Sun Apr 05 00:00:00 1970 PST
+  396 |   6 | 00396              | Tue Apr 07 00:00:00 1970 PST
+  397 | 407 | 00397_update7      | Wed Apr 08 00:00:00 1970 PST
+  398 |   8 | 00398              | Thu Apr 09 00:00:00 1970 PST
+  399 | 509 | 00399_update9      | Fri Apr 10 00:00:00 1970 PST
+  400 |   0 | 00400              | Thu Jan 01 00:00:00 1970 PST
+  401 |   1 | 00401              | Fri Jan 02 00:00:00 1970 PST
+  403 | 303 | 00403_update3      | Sun Jan 04 00:00:00 1970 PST
+  404 |   4 | 00404              | Mon Jan 05 00:00:00 1970 PST
+  406 |   6 | 00406              | Wed Jan 07 00:00:00 1970 PST
+  407 | 407 | 00407_update7      | Thu Jan 08 00:00:00 1970 PST
+  408 |   8 | 00408              | Fri Jan 09 00:00:00 1970 PST
+  409 | 509 | 00409_update9      | Sat Jan 10 00:00:00 1970 PST
+  410 |   0 | 00410              | Sun Jan 11 00:00:00 1970 PST
+  411 |   1 | 00411              | Mon Jan 12 00:00:00 1970 PST
+  413 | 303 | 00413_update3      | Wed Jan 14 00:00:00 1970 PST
+  414 |   4 | 00414              | Thu Jan 15 00:00:00 1970 PST
+  416 |   6 | 00416              | Sat Jan 17 00:00:00 1970 PST
+  417 | 407 | 00417_update7      | Sun Jan 18 00:00:00 1970 PST
+  418 |   8 | 00418              | Mon Jan 19 00:00:00 1970 PST
+  419 | 509 | 00419_update9      | Tue Jan 20 00:00:00 1970 PST
+  420 |   0 | 00420              | Wed Jan 21 00:00:00 1970 PST
+  421 |   1 | 00421              | Thu Jan 22 00:00:00 1970 PST
+  423 | 303 | 00423_update3      | Sat Jan 24 00:00:00 1970 PST
+  424 |   4 | 00424              | Sun Jan 25 00:00:00 1970 PST
+  426 |   6 | 00426              | Tue Jan 27 00:00:00 1970 PST
+  427 | 407 | 00427_update7      | Wed Jan 28 00:00:00 1970 PST
+  428 |   8 | 00428              | Thu Jan 29 00:00:00 1970 PST
+  429 | 509 | 00429_update9      | Fri Jan 30 00:00:00 1970 PST
+  430 |   0 | 00430              | Sat Jan 31 00:00:00 1970 PST
+  431 |   1 | 00431              | Sun Feb 01 00:00:00 1970 PST
+  433 | 303 | 00433_update3      | Tue Feb 03 00:00:00 1970 PST
+  434 |   4 | 00434              | Wed Feb 04 00:00:00 1970 PST
+  436 |   6 | 00436              | Fri Feb 06 00:00:00 1970 PST
+  437 | 407 | 00437_update7      | Sat Feb 07 00:00:00 1970 PST
+  438 |   8 | 00438              | Sun Feb 08 00:00:00 1970 PST
+  439 | 509 | 00439_update9      | Mon Feb 09 00:00:00 1970 PST
+  440 |   0 | 00440              | Tue Feb 10 00:00:00 1970 PST
+  441 |   1 | 00441              | Wed Feb 11 00:00:00 1970 PST
+  443 | 303 | 00443_update3      | Fri Feb 13 00:00:00 1970 PST
+  444 |   4 | 00444              | Sat Feb 14 00:00:00 1970 PST
+  446 |   6 | 00446              | Mon Feb 16 00:00:00 1970 PST
+  447 | 407 | 00447_update7      | Tue Feb 17 00:00:00 1970 PST
+  448 |   8 | 00448              | Wed Feb 18 00:00:00 1970 PST
+  449 | 509 | 00449_update9      | Thu Feb 19 00:00:00 1970 PST
+  450 |   0 | 00450              | Fri Feb 20 00:00:00 1970 PST
+  451 |   1 | 00451              | Sat Feb 21 00:00:00 1970 PST
+  453 | 303 | 00453_update3      | Mon Feb 23 00:00:00 1970 PST
+  454 |   4 | 00454              | Tue Feb 24 00:00:00 1970 PST
+  456 |   6 | 00456              | Thu Feb 26 00:00:00 1970 PST
+  457 | 407 | 00457_update7      | Fri Feb 27 00:00:00 1970 PST
+  458 |   8 | 00458              | Sat Feb 28 00:00:00 1970 PST
+  459 | 509 | 00459_update9      | Sun Mar 01 00:00:00 1970 PST
+  460 |   0 | 00460              | Mon Mar 02 00:00:00 1970 PST
+  461 |   1 | 00461              | Tue Mar 03 00:00:00 1970 PST
+  463 | 303 | 00463_update3      | Thu Mar 05 00:00:00 1970 PST
+  464 |   4 | 00464              | Fri Mar 06 00:00:00 1970 PST
+  466 |   6 | 00466              | Sun Mar 08 00:00:00 1970 PST
+  467 | 407 | 00467_update7      | Mon Mar 09 00:00:00 1970 PST
+  468 |   8 | 00468              | Tue Mar 10 00:00:00 1970 PST
+  469 | 509 | 00469_update9      | Wed Mar 11 00:00:00 1970 PST
+  470 |   0 | 00470              | Thu Mar 12 00:00:00 1970 PST
+  471 |   1 | 00471              | Fri Mar 13 00:00:00 1970 PST
+  473 | 303 | 00473_update3      | Sun Mar 15 00:00:00 1970 PST
+  474 |   4 | 00474              | Mon Mar 16 00:00:00 1970 PST
+  476 |   6 | 00476              | Wed Mar 18 00:00:00 1970 PST
+  477 | 407 | 00477_update7      | Thu Mar 19 00:00:00 1970 PST
+  478 |   8 | 00478              | Fri Mar 20 00:00:00 1970 PST
+  479 | 509 | 00479_update9      | Sat Mar 21 00:00:00 1970 PST
+  480 |   0 | 00480              | Sun Mar 22 00:00:00 1970 PST
+  481 |   1 | 00481              | Mon Mar 23 00:00:00 1970 PST
+  483 | 303 | 00483_update3      | Wed Mar 25 00:00:00 1970 PST
+  484 |   4 | 00484              | Thu Mar 26 00:00:00 1970 PST
+  486 |   6 | 00486              | Sat Mar 28 00:00:00 1970 PST
+  487 | 407 | 00487_update7      | Sun Mar 29 00:00:00 1970 PST
+  488 |   8 | 00488              | Mon Mar 30 00:00:00 1970 PST
+  489 | 509 | 00489_update9      | Tue Mar 31 00:00:00 1970 PST
+  490 |   0 | 00490              | Wed Apr 01 00:00:00 1970 PST
+  491 |   1 | 00491              | Thu Apr 02 00:00:00 1970 PST
+  493 | 303 | 00493_update3      | Sat Apr 04 00:00:00 1970 PST
+  494 |   4 | 00494              | Sun Apr 05 00:00:00 1970 PST
+  496 |   6 | 00496              | Tue Apr 07 00:00:00 1970 PST
+  497 | 407 | 00497_update7      | Wed Apr 08 00:00:00 1970 PST
+  498 |   8 | 00498              | Thu Apr 09 00:00:00 1970 PST
+  499 | 509 | 00499_update9      | Fri Apr 10 00:00:00 1970 PST
+  500 |   0 | 00500              | Thu Jan 01 00:00:00 1970 PST
+  501 |   1 | 00501              | Fri Jan 02 00:00:00 1970 PST
+  503 | 303 | 00503_update3      | Sun Jan 04 00:00:00 1970 PST
+  504 |   4 | 00504              | Mon Jan 05 00:00:00 1970 PST
+  506 |   6 | 00506              | Wed Jan 07 00:00:00 1970 PST
+  507 | 407 | 00507_update7      | Thu Jan 08 00:00:00 1970 PST
+  508 |   8 | 00508              | Fri Jan 09 00:00:00 1970 PST
+  509 | 509 | 00509_update9      | Sat Jan 10 00:00:00 1970 PST
+  510 |   0 | 00510              | Sun Jan 11 00:00:00 1970 PST
+  511 |   1 | 00511              | Mon Jan 12 00:00:00 1970 PST
+  513 | 303 | 00513_update3      | Wed Jan 14 00:00:00 1970 PST
+  514 |   4 | 00514              | Thu Jan 15 00:00:00 1970 PST
+  516 |   6 | 00516              | Sat Jan 17 00:00:00 1970 PST
+  517 | 407 | 00517_update7      | Sun Jan 18 00:00:00 1970 PST
+  518 |   8 | 00518              | Mon Jan 19 00:00:00 1970 PST
+  519 | 509 | 00519_update9      | Tue Jan 20 00:00:00 1970 PST
+  520 |   0 | 00520              | Wed Jan 21 00:00:00 1970 PST
+  521 |   1 | 00521              | Thu Jan 22 00:00:00 1970 PST
+  523 | 303 | 00523_update3      | Sat Jan 24 00:00:00 1970 PST
+  524 |   4 | 00524              | Sun Jan 25 00:00:00 1970 PST
+  526 |   6 | 00526              | Tue Jan 27 00:00:00 1970 PST
+  527 | 407 | 00527_update7      | Wed Jan 28 00:00:00 1970 PST
+  528 |   8 | 00528              | Thu Jan 29 00:00:00 1970 PST
+  529 | 509 | 00529_update9      | Fri Jan 30 00:00:00 1970 PST
+  530 |   0 | 00530              | Sat Jan 31 00:00:00 1970 PST
+  531 |   1 | 00531              | Sun Feb 01 00:00:00 1970 PST
+  533 | 303 | 00533_update3      | Tue Feb 03 00:00:00 1970 PST
+  534 |   4 | 00534              | Wed Feb 04 00:00:00 1970 PST
+  536 |   6 | 00536              | Fri Feb 06 00:00:00 1970 PST
+  537 | 407 | 00537_update7      | Sat Feb 07 00:00:00 1970 PST
+  538 |   8 | 00538              | Sun Feb 08 00:00:00 1970 PST
+  539 | 509 | 00539_update9      | Mon Feb 09 00:00:00 1970 PST
+  540 |   0 | 00540              | Tue Feb 10 00:00:00 1970 PST
+  541 |   1 | 00541              | Wed Feb 11 00:00:00 1970 PST
+  543 | 303 | 00543_update3      | Fri Feb 13 00:00:00 1970 PST
+  544 |   4 | 00544              | Sat Feb 14 00:00:00 1970 PST
+  546 |   6 | 00546              | Mon Feb 16 00:00:00 1970 PST
+  547 | 407 | 00547_update7      | Tue Feb 17 00:00:00 1970 PST
+  548 |   8 | 00548              | Wed Feb 18 00:00:00 1970 PST
+  549 | 509 | 00549_update9      | Thu Feb 19 00:00:00 1970 PST
+  550 |   0 | 00550              | Fri Feb 20 00:00:00 1970 PST
+  551 |   1 | 00551              | Sat Feb 21 00:00:00 1970 PST
+  553 | 303 | 00553_update3      | Mon Feb 23 00:00:00 1970 PST
+  554 |   4 | 00554              | Tue Feb 24 00:00:00 1970 PST
+  556 |   6 | 00556              | Thu Feb 26 00:00:00 1970 PST
+  557 | 407 | 00557_update7      | Fri Feb 27 00:00:00 1970 PST
+  558 |   8 | 00558              | Sat Feb 28 00:00:00 1970 PST
+  559 | 509 | 00559_update9      | Sun Mar 01 00:00:00 1970 PST
+  560 |   0 | 00560              | Mon Mar 02 00:00:00 1970 PST
+  561 |   1 | 00561              | Tue Mar 03 00:00:00 1970 PST
+  563 | 303 | 00563_update3      | Thu Mar 05 00:00:00 1970 PST
+  564 |   4 | 00564              | Fri Mar 06 00:00:00 1970 PST
+  566 |   6 | 00566              | Sun Mar 08 00:00:00 1970 PST
+  567 | 407 | 00567_update7      | Mon Mar 09 00:00:00 1970 PST
+  568 |   8 | 00568              | Tue Mar 10 00:00:00 1970 PST
+  569 | 509 | 00569_update9      | Wed Mar 11 00:00:00 1970 PST
+  570 |   0 | 00570              | Thu Mar 12 00:00:00 1970 PST
+  571 |   1 | 00571              | Fri Mar 13 00:00:00 1970 PST
+  573 | 303 | 00573_update3      | Sun Mar 15 00:00:00 1970 PST
+  574 |   4 | 00574              | Mon Mar 16 00:00:00 1970 PST
+  576 |   6 | 00576              | Wed Mar 18 00:00:00 1970 PST
+  577 | 407 | 00577_update7      | Thu Mar 19 00:00:00 1970 PST
+  578 |   8 | 00578              | Fri Mar 20 00:00:00 1970 PST
+  579 | 509 | 00579_update9      | Sat Mar 21 00:00:00 1970 PST
+  580 |   0 | 00580              | Sun Mar 22 00:00:00 1970 PST
+  581 |   1 | 00581              | Mon Mar 23 00:00:00 1970 PST
+  583 | 303 | 00583_update3      | Wed Mar 25 00:00:00 1970 PST
+  584 |   4 | 00584              | Thu Mar 26 00:00:00 1970 PST
+  586 |   6 | 00586              | Sat Mar 28 00:00:00 1970 PST
+  587 | 407 | 00587_update7      | Sun Mar 29 00:00:00 1970 PST
+  588 |   8 | 00588              | Mon Mar 30 00:00:00 1970 PST
+  589 | 509 | 00589_update9      | Tue Mar 31 00:00:00 1970 PST
+  590 |   0 | 00590              | Wed Apr 01 00:00:00 1970 PST
+  591 |   1 | 00591              | Thu Apr 02 00:00:00 1970 PST
+  593 | 303 | 00593_update3      | Sat Apr 04 00:00:00 1970 PST
+  594 |   4 | 00594              | Sun Apr 05 00:00:00 1970 PST
+  596 |   6 | 00596              | Tue Apr 07 00:00:00 1970 PST
+  597 | 407 | 00597_update7      | Wed Apr 08 00:00:00 1970 PST
+  598 |   8 | 00598              | Thu Apr 09 00:00:00 1970 PST
+  599 | 509 | 00599_update9      | Fri Apr 10 00:00:00 1970 PST
+  600 |   0 | 00600              | Thu Jan 01 00:00:00 1970 PST
+  601 |   1 | 00601              | Fri Jan 02 00:00:00 1970 PST
+  603 | 303 | 00603_update3      | Sun Jan 04 00:00:00 1970 PST
+  604 |   4 | 00604              | Mon Jan 05 00:00:00 1970 PST
+  606 |   6 | 00606              | Wed Jan 07 00:00:00 1970 PST
+  607 | 407 | 00607_update7      | Thu Jan 08 00:00:00 1970 PST
+  608 |   8 | 00608              | Fri Jan 09 00:00:00 1970 PST
+  609 | 509 | 00609_update9      | Sat Jan 10 00:00:00 1970 PST
+  610 |   0 | 00610              | Sun Jan 11 00:00:00 1970 PST
+  611 |   1 | 00611              | Mon Jan 12 00:00:00 1970 PST
+  613 | 303 | 00613_update3      | Wed Jan 14 00:00:00 1970 PST
+  614 |   4 | 00614              | Thu Jan 15 00:00:00 1970 PST
+  616 |   6 | 00616              | Sat Jan 17 00:00:00 1970 PST
+  617 | 407 | 00617_update7      | Sun Jan 18 00:00:00 1970 PST
+  618 |   8 | 00618              | Mon Jan 19 00:00:00 1970 PST
+  619 | 509 | 00619_update9      | Tue Jan 20 00:00:00 1970 PST
+  620 |   0 | 00620              | Wed Jan 21 00:00:00 1970 PST
+  621 |   1 | 00621              | Thu Jan 22 00:00:00 1970 PST
+  623 | 303 | 00623_update3      | Sat Jan 24 00:00:00 1970 PST
+  624 |   4 | 00624              | Sun Jan 25 00:00:00 1970 PST
+  626 |   6 | 00626              | Tue Jan 27 00:00:00 1970 PST
+  627 | 407 | 00627_update7      | Wed Jan 28 00:00:00 1970 PST
+  628 |   8 | 00628              | Thu Jan 29 00:00:00 1970 PST
+  629 | 509 | 00629_update9      | Fri Jan 30 00:00:00 1970 PST
+  630 |   0 | 00630              | Sat Jan 31 00:00:00 1970 PST
+  631 |   1 | 00631              | Sun Feb 01 00:00:00 1970 PST
+  633 | 303 | 00633_update3      | Tue Feb 03 00:00:00 1970 PST
+  634 |   4 | 00634              | Wed Feb 04 00:00:00 1970 PST
+  636 |   6 | 00636              | Fri Feb 06 00:00:00 1970 PST
+  637 | 407 | 00637_update7      | Sat Feb 07 00:00:00 1970 PST
+  638 |   8 | 00638              | Sun Feb 08 00:00:00 1970 PST
+  639 | 509 | 00639_update9      | Mon Feb 09 00:00:00 1970 PST
+  640 |   0 | 00640              | Tue Feb 10 00:00:00 1970 PST
+  641 |   1 | 00641              | Wed Feb 11 00:00:00 1970 PST
+  643 | 303 | 00643_update3      | Fri Feb 13 00:00:00 1970 PST
+  644 |   4 | 00644              | Sat Feb 14 00:00:00 1970 PST
+  646 |   6 | 00646              | Mon Feb 16 00:00:00 1970 PST
+  647 | 407 | 00647_update7      | Tue Feb 17 00:00:00 1970 PST
+  648 |   8 | 00648              | Wed Feb 18 00:00:00 1970 PST
+  649 | 509 | 00649_update9      | Thu Feb 19 00:00:00 1970 PST
+  650 |   0 | 00650              | Fri Feb 20 00:00:00 1970 PST
+  651 |   1 | 00651              | Sat Feb 21 00:00:00 1970 PST
+  653 | 303 | 00653_update3      | Mon Feb 23 00:00:00 1970 PST
+  654 |   4 | 00654              | Tue Feb 24 00:00:00 1970 PST
+  656 |   6 | 00656              | Thu Feb 26 00:00:00 1970 PST
+  657 | 407 | 00657_update7      | Fri Feb 27 00:00:00 1970 PST
+  658 |   8 | 00658              | Sat Feb 28 00:00:00 1970 PST
+  659 | 509 | 00659_update9      | Sun Mar 01 00:00:00 1970 PST
+  660 |   0 | 00660              | Mon Mar 02 00:00:00 1970 PST
+  661 |   1 | 00661              | Tue Mar 03 00:00:00 1970 PST
+  663 | 303 | 00663_update3      | Thu Mar 05 00:00:00 1970 PST
+  664 |   4 | 00664              | Fri Mar 06 00:00:00 1970 PST
+  666 |   6 | 00666              | Sun Mar 08 00:00:00 1970 PST
+  667 | 407 | 00667_update7      | Mon Mar 09 00:00:00 1970 PST
+  668 |   8 | 00668              | Tue Mar 10 00:00:00 1970 PST
+  669 | 509 | 00669_update9      | Wed Mar 11 00:00:00 1970 PST
+  670 |   0 | 00670              | Thu Mar 12 00:00:00 1970 PST
+  671 |   1 | 00671              | Fri Mar 13 00:00:00 1970 PST
+  673 | 303 | 00673_update3      | Sun Mar 15 00:00:00 1970 PST
+  674 |   4 | 00674              | Mon Mar 16 00:00:00 1970 PST
+  676 |   6 | 00676              | Wed Mar 18 00:00:00 1970 PST
+  677 | 407 | 00677_update7      | Thu Mar 19 00:00:00 1970 PST
+  678 |   8 | 00678              | Fri Mar 20 00:00:00 1970 PST
+  679 | 509 | 00679_update9      | Sat Mar 21 00:00:00 1970 PST
+  680 |   0 | 00680              | Sun Mar 22 00:00:00 1970 PST
+  681 |   1 | 00681              | Mon Mar 23 00:00:00 1970 PST
+  683 | 303 | 00683_update3      | Wed Mar 25 00:00:00 1970 PST
+  684 |   4 | 00684              | Thu Mar 26 00:00:00 1970 PST
+  686 |   6 | 00686              | Sat Mar 28 00:00:00 1970 PST
+  687 | 407 | 00687_update7      | Sun Mar 29 00:00:00 1970 PST
+  688 |   8 | 00688              | Mon Mar 30 00:00:00 1970 PST
+  689 | 509 | 00689_update9      | Tue Mar 31 00:00:00 1970 PST
+  690 |   0 | 00690              | Wed Apr 01 00:00:00 1970 PST
+  691 |   1 | 00691              | Thu Apr 02 00:00:00 1970 PST
+  693 | 303 | 00693_update3      | Sat Apr 04 00:00:00 1970 PST
+  694 |   4 | 00694              | Sun Apr 05 00:00:00 1970 PST
+  696 |   6 | 00696              | Tue Apr 07 00:00:00 1970 PST
+  697 | 407 | 00697_update7      | Wed Apr 08 00:00:00 1970 PST
+  698 |   8 | 00698              | Thu Apr 09 00:00:00 1970 PST
+  699 | 509 | 00699_update9      | Fri Apr 10 00:00:00 1970 PST
+  700 |   0 | 00700              | Thu Jan 01 00:00:00 1970 PST
+  701 |   1 | 00701              | Fri Jan 02 00:00:00 1970 PST
+  703 | 303 | 00703_update3      | Sun Jan 04 00:00:00 1970 PST
+  704 |   4 | 00704              | Mon Jan 05 00:00:00 1970 PST
+  706 |   6 | 00706              | Wed Jan 07 00:00:00 1970 PST
+  707 | 407 | 00707_update7      | Thu Jan 08 00:00:00 1970 PST
+  708 |   8 | 00708              | Fri Jan 09 00:00:00 1970 PST
+  709 | 509 | 00709_update9      | Sat Jan 10 00:00:00 1970 PST
+  710 |   0 | 00710              | Sun Jan 11 00:00:00 1970 PST
+  711 |   1 | 00711              | Mon Jan 12 00:00:00 1970 PST
+  713 | 303 | 00713_update3      | Wed Jan 14 00:00:00 1970 PST
+  714 |   4 | 00714              | Thu Jan 15 00:00:00 1970 PST
+  716 |   6 | 00716              | Sat Jan 17 00:00:00 1970 PST
+  717 | 407 | 00717_update7      | Sun Jan 18 00:00:00 1970 PST
+  718 |   8 | 00718              | Mon Jan 19 00:00:00 1970 PST
+  719 | 509 | 00719_update9      | Tue Jan 20 00:00:00 1970 PST
+  720 |   0 | 00720              | Wed Jan 21 00:00:00 1970 PST
+  721 |   1 | 00721              | Thu Jan 22 00:00:00 1970 PST
+  723 | 303 | 00723_update3      | Sat Jan 24 00:00:00 1970 PST
+  724 |   4 | 00724              | Sun Jan 25 00:00:00 1970 PST
+  726 |   6 | 00726              | Tue Jan 27 00:00:00 1970 PST
+  727 | 407 | 00727_update7      | Wed Jan 28 00:00:00 1970 PST
+  728 |   8 | 00728              | Thu Jan 29 00:00:00 1970 PST
+  729 | 509 | 00729_update9      | Fri Jan 30 00:00:00 1970 PST
+  730 |   0 | 00730              | Sat Jan 31 00:00:00 1970 PST
+  731 |   1 | 00731              | Sun Feb 01 00:00:00 1970 PST
+  733 | 303 | 00733_update3      | Tue Feb 03 00:00:00 1970 PST
+  734 |   4 | 00734              | Wed Feb 04 00:00:00 1970 PST
+  736 |   6 | 00736              | Fri Feb 06 00:00:00 1970 PST
+  737 | 407 | 00737_update7      | Sat Feb 07 00:00:00 1970 PST
+  738 |   8 | 00738              | Sun Feb 08 00:00:00 1970 PST
+  739 | 509 | 00739_update9      | Mon Feb 09 00:00:00 1970 PST
+  740 |   0 | 00740              | Tue Feb 10 00:00:00 1970 PST
+  741 |   1 | 00741              | Wed Feb 11 00:00:00 1970 PST
+  743 | 303 | 00743_update3      | Fri Feb 13 00:00:00 1970 PST
+  744 |   4 | 00744              | Sat Feb 14 00:00:00 1970 PST
+  746 |   6 | 00746              | Mon Feb 16 00:00:00 1970 PST
+  747 | 407 | 00747_update7      | Tue Feb 17 00:00:00 1970 PST
+  748 |   8 | 00748              | Wed Feb 18 00:00:00 1970 PST
+  749 | 509 | 00749_update9      | Thu Feb 19 00:00:00 1970 PST
+  750 |   0 | 00750              | Fri Feb 20 00:00:00 1970 PST
+  751 |   1 | 00751              | Sat Feb 21 00:00:00 1970 PST
+  753 | 303 | 00753_update3      | Mon Feb 23 00:00:00 1970 PST
+  754 |   4 | 00754              | Tue Feb 24 00:00:00 1970 PST
+  756 |   6 | 00756              | Thu Feb 26 00:00:00 1970 PST
+  757 | 407 | 00757_update7      | Fri Feb 27 00:00:00 1970 PST
+  758 |   8 | 00758              | Sat Feb 28 00:00:00 1970 PST
+  759 | 509 | 00759_update9      | Sun Mar 01 00:00:00 1970 PST
+  760 |   0 | 00760              | Mon Mar 02 00:00:00 1970 PST
+  761 |   1 | 00761              | Tue Mar 03 00:00:00 1970 PST
+  763 | 303 | 00763_update3      | Thu Mar 05 00:00:00 1970 PST
+  764 |   4 | 00764              | Fri Mar 06 00:00:00 1970 PST
+  766 |   6 | 00766              | Sun Mar 08 00:00:00 1970 PST
+  767 | 407 | 00767_update7      | Mon Mar 09 00:00:00 1970 PST
+  768 |   8 | 00768              | Tue Mar 10 00:00:00 1970 PST
+  769 | 509 | 00769_update9      | Wed Mar 11 00:00:00 1970 PST
+  770 |   0 | 00770              | Thu Mar 12 00:00:00 1970 PST
+  771 |   1 | 00771              | Fri Mar 13 00:00:00 1970 PST
+  773 | 303 | 00773_update3      | Sun Mar 15 00:00:00 1970 PST
+  774 |   4 | 00774              | Mon Mar 16 00:00:00 1970 PST
+  776 |   6 | 00776              | Wed Mar 18 00:00:00 1970 PST
+  777 | 407 | 00777_update7      | Thu Mar 19 00:00:00 1970 PST
+  778 |   8 | 00778              | Fri Mar 20 00:00:00 1970 PST
+  779 | 509 | 00779_update9      | Sat Mar 21 00:00:00 1970 PST
+  780 |   0 | 00780              | Sun Mar 22 00:00:00 1970 PST
+  781 |   1 | 00781              | Mon Mar 23 00:00:00 1970 PST
+  783 | 303 | 00783_update3      | Wed Mar 25 00:00:00 1970 PST
+  784 |   4 | 00784              | Thu Mar 26 00:00:00 1970 PST
+  786 |   6 | 00786              | Sat Mar 28 00:00:00 1970 PST
+  787 | 407 | 00787_update7      | Sun Mar 29 00:00:00 1970 PST
+  788 |   8 | 00788              | Mon Mar 30 00:00:00 1970 PST
+  789 | 509 | 00789_update9      | Tue Mar 31 00:00:00 1970 PST
+  790 |   0 | 00790              | Wed Apr 01 00:00:00 1970 PST
+  791 |   1 | 00791              | Thu Apr 02 00:00:00 1970 PST
+  793 | 303 | 00793_update3      | Sat Apr 04 00:00:00 1970 PST
+  794 |   4 | 00794              | Sun Apr 05 00:00:00 1970 PST
+  796 |   6 | 00796              | Tue Apr 07 00:00:00 1970 PST
+  797 | 407 | 00797_update7      | Wed Apr 08 00:00:00 1970 PST
+  798 |   8 | 00798              | Thu Apr 09 00:00:00 1970 PST
+  799 | 509 | 00799_update9      | Fri Apr 10 00:00:00 1970 PST
+  800 |   0 | 00800              | Thu Jan 01 00:00:00 1970 PST
+  801 |   1 | 00801              | Fri Jan 02 00:00:00 1970 PST
+  803 | 303 | 00803_update3      | Sun Jan 04 00:00:00 1970 PST
+  804 |   4 | 00804              | Mon Jan 05 00:00:00 1970 PST
+  806 |   6 | 00806              | Wed Jan 07 00:00:00 1970 PST
+  807 | 407 | 00807_update7      | Thu Jan 08 00:00:00 1970 PST
+  808 |   8 | 00808              | Fri Jan 09 00:00:00 1970 PST
+  809 | 509 | 00809_update9      | Sat Jan 10 00:00:00 1970 PST
+  810 |   0 | 00810              | Sun Jan 11 00:00:00 1970 PST
+  811 |   1 | 00811              | Mon Jan 12 00:00:00 1970 PST
+  813 | 303 | 00813_update3      | Wed Jan 14 00:00:00 1970 PST
+  814 |   4 | 00814              | Thu Jan 15 00:00:00 1970 PST
+  816 |   6 | 00816              | Sat Jan 17 00:00:00 1970 PST
+  817 | 407 | 00817_update7      | Sun Jan 18 00:00:00 1970 PST
+  818 |   8 | 00818              | Mon Jan 19 00:00:00 1970 PST
+  819 | 509 | 00819_update9      | Tue Jan 20 00:00:00 1970 PST
+  820 |   0 | 00820              | Wed Jan 21 00:00:00 1970 PST
+  821 |   1 | 00821              | Thu Jan 22 00:00:00 1970 PST
+  823 | 303 | 00823_update3      | Sat Jan 24 00:00:00 1970 PST
+  824 |   4 | 00824              | Sun Jan 25 00:00:00 1970 PST
+  826 |   6 | 00826              | Tue Jan 27 00:00:00 1970 PST
+  827 | 407 | 00827_update7      | Wed Jan 28 00:00:00 1970 PST
+  828 |   8 | 00828              | Thu Jan 29 00:00:00 1970 PST
+  829 | 509 | 00829_update9      | Fri Jan 30 00:00:00 1970 PST
+  830 |   0 | 00830              | Sat Jan 31 00:00:00 1970 PST
+  831 |   1 | 00831              | Sun Feb 01 00:00:00 1970 PST
+  833 | 303 | 00833_update3      | Tue Feb 03 00:00:00 1970 PST
+  834 |   4 | 00834              | Wed Feb 04 00:00:00 1970 PST
+  836 |   6 | 00836              | Fri Feb 06 00:00:00 1970 PST
+  837 | 407 | 00837_update7      | Sat Feb 07 00:00:00 1970 PST
+  838 |   8 | 00838              | Sun Feb 08 00:00:00 1970 PST
+  839 | 509 | 00839_update9      | Mon Feb 09 00:00:00 1970 PST
+  840 |   0 | 00840              | Tue Feb 10 00:00:00 1970 PST
+  841 |   1 | 00841              | Wed Feb 11 00:00:00 1970 PST
+  843 | 303 | 00843_update3      | Fri Feb 13 00:00:00 1970 PST
+  844 |   4 | 00844              | Sat Feb 14 00:00:00 1970 PST
+  846 |   6 | 00846              | Mon Feb 16 00:00:00 1970 PST
+  847 | 407 | 00847_update7      | Tue Feb 17 00:00:00 1970 PST
+  848 |   8 | 00848              | Wed Feb 18 00:00:00 1970 PST
+  849 | 509 | 00849_update9      | Thu Feb 19 00:00:00 1970 PST
+  850 |   0 | 00850              | Fri Feb 20 00:00:00 1970 PST
+  851 |   1 | 00851              | Sat Feb 21 00:00:00 1970 PST
+  853 | 303 | 00853_update3      | Mon Feb 23 00:00:00 1970 PST
+  854 |   4 | 00854              | Tue Feb 24 00:00:00 1970 PST
+  856 |   6 | 00856              | Thu Feb 26 00:00:00 1970 PST
+  857 | 407 | 00857_update7      | Fri Feb 27 00:00:00 1970 PST
+  858 |   8 | 00858              | Sat Feb 28 00:00:00 1970 PST
+  859 | 509 | 00859_update9      | Sun Mar 01 00:00:00 1970 PST
+  860 |   0 | 00860              | Mon Mar 02 00:00:00 1970 PST
+  861 |   1 | 00861              | Tue Mar 03 00:00:00 1970 PST
+  863 | 303 | 00863_update3      | Thu Mar 05 00:00:00 1970 PST
+  864 |   4 | 00864              | Fri Mar 06 00:00:00 1970 PST
+  866 |   6 | 00866              | Sun Mar 08 00:00:00 1970 PST
+  867 | 407 | 00867_update7      | Mon Mar 09 00:00:00 1970 PST
+  868 |   8 | 00868              | Tue Mar 10 00:00:00 1970 PST
+  869 | 509 | 00869_update9      | Wed Mar 11 00:00:00 1970 PST
+  870 |   0 | 00870              | Thu Mar 12 00:00:00 1970 PST
+  871 |   1 | 00871              | Fri Mar 13 00:00:00 1970 PST
+  873 | 303 | 00873_update3      | Sun Mar 15 00:00:00 1970 PST
+  874 |   4 | 00874              | Mon Mar 16 00:00:00 1970 PST
+  876 |   6 | 00876              | Wed Mar 18 00:00:00 1970 PST
+  877 | 407 | 00877_update7      | Thu Mar 19 00:00:00 1970 PST
+  878 |   8 | 00878              | Fri Mar 20 00:00:00 1970 PST
+  879 | 509 | 00879_update9      | Sat Mar 21 00:00:00 1970 PST
+  880 |   0 | 00880              | Sun Mar 22 00:00:00 1970 PST
+  881 |   1 | 00881              | Mon Mar 23 00:00:00 1970 PST
+  883 | 303 | 00883_update3      | Wed Mar 25 00:00:00 1970 PST
+  884 |   4 | 00884              | Thu Mar 26 00:00:00 1970 PST
+  886 |   6 | 00886              | Sat Mar 28 00:00:00 1970 PST
+  887 | 407 | 00887_update7      | Sun Mar 29 00:00:00 1970 PST
+  888 |   8 | 00888              | Mon Mar 30 00:00:00 1970 PST
+  889 | 509 | 00889_update9      | Tue Mar 31 00:00:00 1970 PST
+  890 |   0 | 00890              | Wed Apr 01 00:00:00 1970 PST
+  891 |   1 | 00891              | Thu Apr 02 00:00:00 1970 PST
+  893 | 303 | 00893_update3      | Sat Apr 04 00:00:00 1970 PST
+  894 |   4 | 00894              | Sun Apr 05 00:00:00 1970 PST
+  896 |   6 | 00896              | Tue Apr 07 00:00:00 1970 PST
+  897 | 407 | 00897_update7      | Wed Apr 08 00:00:00 1970 PST
+  898 |   8 | 00898              | Thu Apr 09 00:00:00 1970 PST
+  899 | 509 | 00899_update9      | Fri Apr 10 00:00:00 1970 PST
+  900 |   0 | 00900              | Thu Jan 01 00:00:00 1970 PST
+  901 |   1 | 00901              | Fri Jan 02 00:00:00 1970 PST
+  903 | 303 | 00903_update3      | Sun Jan 04 00:00:00 1970 PST
+  904 |   4 | 00904              | Mon Jan 05 00:00:00 1970 PST
+  906 |   6 | 00906              | Wed Jan 07 00:00:00 1970 PST
+  907 | 407 | 00907_update7      | Thu Jan 08 00:00:00 1970 PST
+  908 |   8 | 00908              | Fri Jan 09 00:00:00 1970 PST
+  909 | 509 | 00909_update9      | Sat Jan 10 00:00:00 1970 PST
+  910 |   0 | 00910              | Sun Jan 11 00:00:00 1970 PST
+  911 |   1 | 00911              | Mon Jan 12 00:00:00 1970 PST
+  913 | 303 | 00913_update3      | Wed Jan 14 00:00:00 1970 PST
+  914 |   4 | 00914              | Thu Jan 15 00:00:00 1970 PST
+  916 |   6 | 00916              | Sat Jan 17 00:00:00 1970 PST
+  917 | 407 | 00917_update7      | Sun Jan 18 00:00:00 1970 PST
+  918 |   8 | 00918              | Mon Jan 19 00:00:00 1970 PST
+  919 | 509 | 00919_update9      | Tue Jan 20 00:00:00 1970 PST
+  920 |   0 | 00920              | Wed Jan 21 00:00:00 1970 PST
+  921 |   1 | 00921              | Thu Jan 22 00:00:00 1970 PST
+  923 | 303 | 00923_update3      | Sat Jan 24 00:00:00 1970 PST
+  924 |   4 | 00924              | Sun Jan 25 00:00:00 1970 PST
+  926 |   6 | 00926              | Tue Jan 27 00:00:00 1970 PST
+  927 | 407 | 00927_update7      | Wed Jan 28 00:00:00 1970 PST
+  928 |   8 | 00928              | Thu Jan 29 00:00:00 1970 PST
+  929 | 509 | 00929_update9      | Fri Jan 30 00:00:00 1970 PST
+  930 |   0 | 00930              | Sat Jan 31 00:00:00 1970 PST
+  931 |   1 | 00931              | Sun Feb 01 00:00:00 1970 PST
+  933 | 303 | 00933_update3      | Tue Feb 03 00:00:00 1970 PST
+  934 |   4 | 00934              | Wed Feb 04 00:00:00 1970 PST
+  936 |   6 | 00936              | Fri Feb 06 00:00:00 1970 PST
+  937 | 407 | 00937_update7      | Sat Feb 07 00:00:00 1970 PST
+  938 |   8 | 00938              | Sun Feb 08 00:00:00 1970 PST
+  939 | 509 | 00939_update9      | Mon Feb 09 00:00:00 1970 PST
+  940 |   0 | 00940              | Tue Feb 10 00:00:00 1970 PST
+  941 |   1 | 00941              | Wed Feb 11 00:00:00 1970 PST
+  943 | 303 | 00943_update3      | Fri Feb 13 00:00:00 1970 PST
+  944 |   4 | 00944              | Sat Feb 14 00:00:00 1970 PST
+  946 |   6 | 00946              | Mon Feb 16 00:00:00 1970 PST
+  947 | 407 | 00947_update7      | Tue Feb 17 00:00:00 1970 PST
+  948 |   8 | 00948              | Wed Feb 18 00:00:00 1970 PST
+  949 | 509 | 00949_update9      | Thu Feb 19 00:00:00 1970 PST
+  950 |   0 | 00950              | Fri Feb 20 00:00:00 1970 PST
+  951 |   1 | 00951              | Sat Feb 21 00:00:00 1970 PST
+  953 | 303 | 00953_update3      | Mon Feb 23 00:00:00 1970 PST
+  954 |   4 | 00954              | Tue Feb 24 00:00:00 1970 PST
+  956 |   6 | 00956              | Thu Feb 26 00:00:00 1970 PST
+  957 | 407 | 00957_update7      | Fri Feb 27 00:00:00 1970 PST
+  958 |   8 | 00958              | Sat Feb 28 00:00:00 1970 PST
+  959 | 509 | 00959_update9      | Sun Mar 01 00:00:00 1970 PST
+  960 |   0 | 00960              | Mon Mar 02 00:00:00 1970 PST
+  961 |   1 | 00961              | Tue Mar 03 00:00:00 1970 PST
+  963 | 303 | 00963_update3      | Thu Mar 05 00:00:00 1970 PST
+  964 |   4 | 00964              | Fri Mar 06 00:00:00 1970 PST
+  966 |   6 | 00966              | Sun Mar 08 00:00:00 1970 PST
+  967 | 407 | 00967_update7      | Mon Mar 09 00:00:00 1970 PST
+  968 |   8 | 00968              | Tue Mar 10 00:00:00 1970 PST
+  969 | 509 | 00969_update9      | Wed Mar 11 00:00:00 1970 PST
+  970 |   0 | 00970              | Thu Mar 12 00:00:00 1970 PST
+  971 |   1 | 00971              | Fri Mar 13 00:00:00 1970 PST
+  973 | 303 | 00973_update3      | Sun Mar 15 00:00:00 1970 PST
+  974 |   4 | 00974              | Mon Mar 16 00:00:00 1970 PST
+  976 |   6 | 00976              | Wed Mar 18 00:00:00 1970 PST
+  977 | 407 | 00977_update7      | Thu Mar 19 00:00:00 1970 PST
+  978 |   8 | 00978              | Fri Mar 20 00:00:00 1970 PST
+  979 | 509 | 00979_update9      | Sat Mar 21 00:00:00 1970 PST
+  980 |   0 | 00980              | Sun Mar 22 00:00:00 1970 PST
+  981 |   1 | 00981              | Mon Mar 23 00:00:00 1970 PST
+  983 | 303 | 00983_update3      | Wed Mar 25 00:00:00 1970 PST
+  984 |   4 | 00984              | Thu Mar 26 00:00:00 1970 PST
+  986 |   6 | 00986              | Sat Mar 28 00:00:00 1970 PST
+  987 | 407 | 00987_update7      | Sun Mar 29 00:00:00 1970 PST
+  988 |   8 | 00988              | Mon Mar 30 00:00:00 1970 PST
+  989 | 509 | 00989_update9      | Tue Mar 31 00:00:00 1970 PST
+  990 |   0 | 00990              | Wed Apr 01 00:00:00 1970 PST
+  991 |   1 | 00991              | Thu Apr 02 00:00:00 1970 PST
+  993 | 303 | 00993_update3      | Sat Apr 04 00:00:00 1970 PST
+  994 |   4 | 00994              | Sun Apr 05 00:00:00 1970 PST
+  996 |   6 | 00996              | Tue Apr 07 00:00:00 1970 PST
+  997 | 407 | 00997_update7      | Wed Apr 08 00:00:00 1970 PST
+  998 |   8 | 00998              | Thu Apr 09 00:00:00 1970 PST
+  999 | 509 | 00999_update9      | Fri Apr 10 00:00:00 1970 PST
+ 1000 |   0 | 01000              | Thu Jan 01 00:00:00 1970 PST
+ 1001 | 101 | 0000100001         | 
+ 1003 | 403 | 0000300003_update3 | 
+ 1004 | 104 | 0000400004         | 
+ 1006 | 106 | 0000600006         | 
+ 1007 | 507 | 0000700007_update7 | 
+ 1008 | 108 | 0000800008         | 
+ 1009 | 609 | 0000900009_update9 | 
+ 1010 | 100 | 0001000010         | 
+ 1011 | 101 | 0001100011         | 
+ 1013 | 403 | 0001300013_update3 | 
+ 1014 | 104 | 0001400014         | 
+ 1016 | 106 | 0001600016         | 
+ 1017 | 507 | 0001700017_update7 | 
+ 1018 | 108 | 0001800018         | 
+ 1019 | 609 | 0001900019_update9 | 
+ 1020 | 100 | 0002000020         | 
+ 1101 | 201 | aaa                | 
+ 1103 | 503 | ccc_update3        | 
+ 1104 | 204 | ddd                | 
+(819 rows)
+
+EXPLAIN (verbose, costs off)
+INSERT INTO ft2 (c1,c2,c3) VALUES (1200,999,'foo') RETURNING tableoid::regclass;
+                                                                                           QUERY PLAN                                                                                            
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Insert on public.ft2
+   Output: (ft2.tableoid)::regclass
+   Remote SQL: INSERT INTO "S 1"."T 1"("C 1", c2, c3, c4, c5, c6, c7, c8) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
+   ->  Result
+         Output: 1200, 999, NULL::integer, 'foo'::text, NULL::timestamp with time zone, NULL::timestamp without time zone, NULL::character varying, 'ft2       '::character(10), NULL::user_enum
+(5 rows)
+
+INSERT INTO ft2 (c1,c2,c3) VALUES (1200,999,'foo') RETURNING tableoid::regclass;
+ tableoid 
+----------
+ ft2
+(1 row)
+
+EXPLAIN (verbose, costs off)
+UPDATE ft2 SET c3 = 'bar' WHERE c1 = 1200 RETURNING tableoid::regclass;             -- can be pushed down
+                                     QUERY PLAN                                     
+------------------------------------------------------------------------------------
+ Update on public.ft2
+   Output: (tableoid)::regclass
+   ->  Foreign Update on public.ft2
+         Remote SQL: UPDATE "S 1"."T 1" SET c3 = 'bar'::text WHERE (("C 1" = 1200))
+(4 rows)
+
+UPDATE ft2 SET c3 = 'bar' WHERE c1 = 1200 RETURNING tableoid::regclass;
+ tableoid 
+----------
+ ft2
+(1 row)
+
+EXPLAIN (verbose, costs off)
+DELETE FROM ft2 WHERE c1 = 1200 RETURNING tableoid::regclass;                       -- can be pushed down
+                             QUERY PLAN                             
+--------------------------------------------------------------------
+ Delete on public.ft2
+   Output: (tableoid)::regclass
+   ->  Foreign Delete on public.ft2
+         Remote SQL: DELETE FROM "S 1"."T 1" WHERE (("C 1" = 1200))
+(4 rows)
+
+DELETE FROM ft2 WHERE c1 = 1200 RETURNING tableoid::regclass;
+ tableoid 
+----------
+ ft2
+(1 row)
+
+-- Test UPDATE/DELETE with RETURNING on a three-table join
+INSERT INTO ft2 (c1,c2,c3)
+  SELECT id, id - 1200, to_char(id, 'FM00000') FROM generate_series(1201, 1300) id;
+EXPLAIN (verbose, costs off)
+UPDATE ft2 SET c3 = 'foo'
+  FROM ft4 INNER JOIN ft5 ON (ft4.c1 = ft5.c1)
+  WHERE ft2.c1 > 1200 AND ft2.c2 = ft4.c1
+  RETURNING ft2, ft2.*, ft4, ft4.*;       -- can be pushed down
+                                                                                                                                                                          QUERY PLAN                                                                                                                                                                           
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Update on public.ft2
+   Output: ft2.*, ft2.c1, ft2.c2, ft2.c3, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft4.*, ft4.c1, ft4.c2, ft4.c3
+   ->  Foreign Update
+         Remote SQL: UPDATE "S 1"."T 1" r1 SET c3 = 'foo'::text FROM ("S 1"."T 3" r2 INNER JOIN "S 1"."T 4" r3 ON (TRUE)) WHERE ((r2.c1 = r3.c1)) AND ((r1.c2 = r2.c1)) AND ((r1."C 1" > 1200)) RETURNING r1."C 1", r1.c2, r1.c3, r1.c4, r1.c5, r1.c6, r1.c7, r1.c8, CASE WHEN (r2.*)::text IS NOT NULL THEN ROW(r2.c1, r2.c2, r2.c3) END, r2.c1, r2.c2, r2.c3
+(4 rows)
+
+UPDATE ft2 SET c3 = 'foo'
+  FROM ft4 INNER JOIN ft5 ON (ft4.c1 = ft5.c1)
+  WHERE ft2.c1 > 1200 AND ft2.c2 = ft4.c1
+  RETURNING ft2, ft2.*, ft4, ft4.*;
+              ft2               |  c1  | c2 | c3  | c4 | c5 | c6 |     c7     | c8 |      ft4       | c1 | c2 |   c3   
+--------------------------------+------+----+-----+----+----+----+------------+----+----------------+----+----+--------
+ (1206,6,foo,,,,"ft2       ",)  | 1206 |  6 | foo |    |    |    | ft2        |    | (6,7,AAA006)   |  6 |  7 | AAA006
+ (1212,12,foo,,,,"ft2       ",) | 1212 | 12 | foo |    |    |    | ft2        |    | (12,13,AAA012) | 12 | 13 | AAA012
+ (1218,18,foo,,,,"ft2       ",) | 1218 | 18 | foo |    |    |    | ft2        |    | (18,19,AAA018) | 18 | 19 | AAA018
+ (1224,24,foo,,,,"ft2       ",) | 1224 | 24 | foo |    |    |    | ft2        |    | (24,25,AAA024) | 24 | 25 | AAA024
+ (1230,30,foo,,,,"ft2       ",) | 1230 | 30 | foo |    |    |    | ft2        |    | (30,31,AAA030) | 30 | 31 | AAA030
+ (1236,36,foo,,,,"ft2       ",) | 1236 | 36 | foo |    |    |    | ft2        |    | (36,37,AAA036) | 36 | 37 | AAA036
+ (1242,42,foo,,,,"ft2       ",) | 1242 | 42 | foo |    |    |    | ft2        |    | (42,43,AAA042) | 42 | 43 | AAA042
+ (1248,48,foo,,,,"ft2       ",) | 1248 | 48 | foo |    |    |    | ft2        |    | (48,49,AAA048) | 48 | 49 | AAA048
+ (1254,54,foo,,,,"ft2       ",) | 1254 | 54 | foo |    |    |    | ft2        |    | (54,55,AAA054) | 54 | 55 | AAA054
+ (1260,60,foo,,,,"ft2       ",) | 1260 | 60 | foo |    |    |    | ft2        |    | (60,61,AAA060) | 60 | 61 | AAA060
+ (1266,66,foo,,,,"ft2       ",) | 1266 | 66 | foo |    |    |    | ft2        |    | (66,67,AAA066) | 66 | 67 | AAA066
+ (1272,72,foo,,,,"ft2       ",) | 1272 | 72 | foo |    |    |    | ft2        |    | (72,73,AAA072) | 72 | 73 | AAA072
+ (1278,78,foo,,,,"ft2       ",) | 1278 | 78 | foo |    |    |    | ft2        |    | (78,79,AAA078) | 78 | 79 | AAA078
+ (1284,84,foo,,,,"ft2       ",) | 1284 | 84 | foo |    |    |    | ft2        |    | (84,85,AAA084) | 84 | 85 | AAA084
+ (1290,90,foo,,,,"ft2       ",) | 1290 | 90 | foo |    |    |    | ft2        |    | (90,91,AAA090) | 90 | 91 | AAA090
+ (1296,96,foo,,,,"ft2       ",) | 1296 | 96 | foo |    |    |    | ft2        |    | (96,97,AAA096) | 96 | 97 | AAA096
+(16 rows)
+
+EXPLAIN (verbose, costs off)
+DELETE FROM ft2
+  USING ft4 LEFT JOIN ft5 ON (ft4.c1 = ft5.c1)
+  WHERE ft2.c1 > 1200 AND ft2.c1 % 10 = 0 AND ft2.c2 = ft4.c1
+  RETURNING 100;                          -- can be pushed down
+                                                                                            QUERY PLAN                                                                                             
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Delete on public.ft2
+   Output: 100
+   ->  Foreign Delete
+         Remote SQL: DELETE FROM "S 1"."T 1" r1 USING ("S 1"."T 3" r2 LEFT JOIN "S 1"."T 4" r3 ON (((r2.c1 = r3.c1)))) WHERE ((r1.c2 = r2.c1)) AND ((r1."C 1" > 1200)) AND (((r1."C 1" % 10) = 0))
+(4 rows)
+
+DELETE FROM ft2
+  USING ft4 LEFT JOIN ft5 ON (ft4.c1 = ft5.c1)
+  WHERE ft2.c1 > 1200 AND ft2.c1 % 10 = 0 AND ft2.c2 = ft4.c1
+  RETURNING 100;
+ ?column? 
+----------
+      100
+      100
+      100
+      100
+      100
+      100
+      100
+      100
+      100
+      100
+(10 rows)
+
+DELETE FROM ft2 WHERE ft2.c1 > 1200;
+-- Test UPDATE/DELETE with WHERE or JOIN/ON conditions containing
+-- user-defined operators/functions
+ALTER SERVER loopback OPTIONS (DROP extensions);
+INSERT INTO ft2 (c1,c2,c3)
+  SELECT id, id % 10, to_char(id, 'FM00000') FROM generate_series(2001, 2010) id;
+EXPLAIN (verbose, costs off)
+UPDATE ft2 SET c3 = 'bar' WHERE postgres_fdw_abs(c1) > 2000 RETURNING *;            -- can't be pushed down
+                                                QUERY PLAN                                                
+----------------------------------------------------------------------------------------------------------
+ Update on public.ft2
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: UPDATE "S 1"."T 1" SET c3 = $2 WHERE ctid = $1 RETURNING "C 1", c2, c3, c4, c5, c6, c7, c8
+   ->  Foreign Scan on public.ft2
+         Output: c1, c2, NULL::integer, 'bar'::text, c4, c5, c6, c7, c8, ctid
+         Filter: (postgres_fdw_abs(ft2.c1) > 2000)
+         Remote SQL: SELECT "C 1", c2, c4, c5, c6, c7, c8, ctid FROM "S 1"."T 1" FOR UPDATE
+(7 rows)
+
+UPDATE ft2 SET c3 = 'bar' WHERE postgres_fdw_abs(c1) > 2000 RETURNING *;
+  c1  | c2 | c3  | c4 | c5 | c6 |     c7     | c8 
+------+----+-----+----+----+----+------------+----
+ 2001 |  1 | bar |    |    |    | ft2        | 
+ 2002 |  2 | bar |    |    |    | ft2        | 
+ 2003 |  3 | bar |    |    |    | ft2        | 
+ 2004 |  4 | bar |    |    |    | ft2        | 
+ 2005 |  5 | bar |    |    |    | ft2        | 
+ 2006 |  6 | bar |    |    |    | ft2        | 
+ 2007 |  7 | bar |    |    |    | ft2        | 
+ 2008 |  8 | bar |    |    |    | ft2        | 
+ 2009 |  9 | bar |    |    |    | ft2        | 
+ 2010 |  0 | bar |    |    |    | ft2        | 
+(10 rows)
+
+EXPLAIN (verbose, costs off)
+UPDATE ft2 SET c3 = 'baz'
+  FROM ft4 INNER JOIN ft5 ON (ft4.c1 = ft5.c1)
+  WHERE ft2.c1 > 2000 AND ft2.c2 === ft4.c1
+  RETURNING ft2.*, ft4.*, ft5.*;                                                    -- can't be pushed down
+                                                                                                                                    QUERY PLAN                                                                                                                                     
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Update on public.ft2
+   Output: ft2.c1, ft2.c2, ft2.c3, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft4.c1, ft4.c2, ft4.c3, ft5.c1, ft5.c2, ft5.c3
+   Remote SQL: UPDATE "S 1"."T 1" SET c3 = $2 WHERE ctid = $1 RETURNING "C 1", c2, c3, c4, c5, c6, c7, c8
+   ->  Hash Join
+         Output: ft2.c1, ft2.c2, NULL::integer, 'baz'::text, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft2.ctid, ft4.*, ft5.*, ft4.c1, ft4.c2, ft4.c3, ft5.c1, ft5.c2, ft5.c3
+         Hash Cond: (ft4.c1 = ft5.c1)
+         ->  Foreign Scan
+               Output: ft2.c1, ft2.c2, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft2.ctid, ft4.*, ft4.c1, ft4.c2, ft4.c3
+               Filter: (ft2.c2 === ft4.c1)
+               Relations: (public.ft2) INNER JOIN (public.ft4)
+               Remote SQL: SELECT r1."C 1", r1.c2, r1.c4, r1.c5, r1.c6, r1.c7, r1.c8, r1.ctid, CASE WHEN (r2.*)::text IS NOT NULL THEN ROW(r2.c1, r2.c2, r2.c3) END, r2.c1, r2.c2, r2.c3 FROM ("S 1"."T 1" r1 INNER JOIN "S 1"."T 3" r2 ON (((r1."C 1" > 2000)))) FOR UPDATE OF r1
+               ->  Nested Loop
+                     Output: ft2.c1, ft2.c2, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft2.ctid, ft4.*, ft4.c1, ft4.c2, ft4.c3
+                     ->  Foreign Scan on public.ft2
+                           Output: ft2.c1, ft2.c2, ft2.c4, ft2.c5, ft2.c6, ft2.c7, ft2.c8, ft2.ctid
+                           Remote SQL: SELECT "C 1", c2, c4, c5, c6, c7, c8, ctid FROM "S 1"."T 1" WHERE (("C 1" > 2000)) FOR UPDATE
+                     ->  Foreign Scan on public.ft4
+                           Output: ft4.*, ft4.c1, ft4.c2, ft4.c3
+                           Remote SQL: SELECT c1, c2, c3 FROM "S 1"."T 3"
+         ->  Hash
+               Output: ft5.*, ft5.c1, ft5.c2, ft5.c3
+               ->  Foreign Scan on public.ft5
+                     Output: ft5.*, ft5.c1, ft5.c2, ft5.c3
+                     Remote SQL: SELECT c1, c2, c3 FROM "S 1"."T 4"
+(24 rows)
+
+UPDATE ft2 SET c3 = 'baz'
+  FROM ft4 INNER JOIN ft5 ON (ft4.c1 = ft5.c1)
+  WHERE ft2.c1 > 2000 AND ft2.c2 === ft4.c1
+  RETURNING ft2.*, ft4.*, ft5.*;
+  c1  | c2 | c3  | c4 | c5 | c6 |     c7     | c8 | c1 | c2 |   c3   | c1 | c2 |   c3   
+------+----+-----+----+----+----+------------+----+----+----+--------+----+----+--------
+ 2006 |  6 | baz |    |    |    | ft2        |    |  6 |  7 | AAA006 |  6 |  7 | AAA006
+(1 row)
+
+EXPLAIN (verbose, costs off)
+DELETE FROM ft2
+  USING ft4 INNER JOIN ft5 ON (ft4.c1 === ft5.c1)
+  WHERE ft2.c1 > 2000 AND ft2.c2 = ft4.c1
+  RETURNING ft2.c1, ft2.c2, ft2.c3;       -- can't be pushed down
+                                                                                                                                                                     QUERY PLAN                                                                                                                                                                     
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Delete on public.ft2
+   Output: ft2.c1, ft2.c2, ft2.c3
+   Remote SQL: DELETE FROM "S 1"."T 1" WHERE ctid = $1 RETURNING "C 1", c2, c3
+   ->  Foreign Scan
+         Output: ft2.ctid, ft4.*, ft5.*
+         Filter: (ft4.c1 === ft5.c1)
+         Relations: ((public.ft2) INNER JOIN (public.ft4)) INNER JOIN (public.ft5)
+         Remote SQL: SELECT r1.ctid, CASE WHEN (r2.*)::text IS NOT NULL THEN ROW(r2.c1, r2.c2, r2.c3) END, CASE WHEN (r3.*)::text IS NOT NULL THEN ROW(r3.c1, r3.c2, r3.c3) END, r2.c1, r3.c1 FROM (("S 1"."T 1" r1 INNER JOIN "S 1"."T 3" r2 ON (((r1.c2 = r2.c1)) AND ((r1."C 1" > 2000)))) INNER JOIN "S 1"."T 4" r3 ON (TRUE)) FOR UPDATE OF r1
+         ->  Nested Loop
+               Output: ft2.ctid, ft4.*, ft5.*, ft4.c1, ft5.c1
+               ->  Nested Loop
+                     Output: ft2.ctid, ft4.*, ft4.c1
+                     Join Filter: (ft2.c2 = ft4.c1)
+                     ->  Foreign Scan on public.ft2
+                           Output: ft2.ctid, ft2.c2
+                           Remote SQL: SELECT c2, ctid FROM "S 1"."T 1" WHERE (("C 1" > 2000)) FOR UPDATE
+                     ->  Foreign Scan on public.ft4
+                           Output: ft4.*, ft4.c1
+                           Remote SQL: SELECT c1, c2, c3 FROM "S 1"."T 3"
+               ->  Foreign Scan on public.ft5
+                     Output: ft5.*, ft5.c1
+                     Remote SQL: SELECT c1, c2, c3 FROM "S 1"."T 4"
+(22 rows)
+
+DELETE FROM ft2
+  USING ft4 INNER JOIN ft5 ON (ft4.c1 === ft5.c1)
+  WHERE ft2.c1 > 2000 AND ft2.c2 = ft4.c1
+  RETURNING ft2.c1, ft2.c2, ft2.c3;
+  c1  | c2 | c3  
+------+----+-----
+ 2006 |  6 | baz
+(1 row)
+
+DELETE FROM ft2 WHERE ft2.c1 > 2000;
+ALTER SERVER loopback OPTIONS (ADD extensions 'postgres_fdw');
+-- Test that trigger on remote table works as expected
+CREATE OR REPLACE FUNCTION "S 1".F_BRTRIG() RETURNS trigger AS $$
+BEGIN
+    NEW.c3 = NEW.c3 || '_trig_update';
+    RETURN NEW;
+END;
+$$ LANGUAGE plpgsql;
+CREATE TRIGGER t1_br_insert BEFORE INSERT OR UPDATE
+    ON "S 1"."T 1" FOR EACH ROW EXECUTE PROCEDURE "S 1".F_BRTRIG();
+INSERT INTO ft2 (c1,c2,c3) VALUES (1208, 818, 'fff') RETURNING *;
+  c1  | c2  |       c3        | c4 | c5 | c6 |     c7     | c8 
+------+-----+-----------------+----+----+----+------------+----
+ 1208 | 818 | fff_trig_update |    |    |    | ft2        | 
+(1 row)
+
+INSERT INTO ft2 (c1,c2,c3,c6) VALUES (1218, 818, 'ggg', '(--;') RETURNING *;
+  c1  | c2  |       c3        | c4 | c5 |  c6  |     c7     | c8 
+------+-----+-----------------+----+----+------+------------+----
+ 1218 | 818 | ggg_trig_update |    |    | (--; | ft2        | 
+(1 row)
+
+UPDATE ft2 SET c2 = c2 + 600 WHERE c1 % 10 = 8 AND c1 < 1200 RETURNING *;
+  c1  | c2  |           c3           |              c4              |            c5            | c6 |     c7     | c8  
+------+-----+------------------------+------------------------------+--------------------------+----+------------+-----
+    8 | 608 | 00008_trig_update      | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+   18 | 608 | 00018_trig_update      | Mon Jan 19 00:00:00 1970 PST | Mon Jan 19 00:00:00 1970 | 8  | 8          | foo
+   28 | 608 | 00028_trig_update      | Thu Jan 29 00:00:00 1970 PST | Thu Jan 29 00:00:00 1970 | 8  | 8          | foo
+   38 | 608 | 00038_trig_update      | Sun Feb 08 00:00:00 1970 PST | Sun Feb 08 00:00:00 1970 | 8  | 8          | foo
+   48 | 608 | 00048_trig_update      | Wed Feb 18 00:00:00 1970 PST | Wed Feb 18 00:00:00 1970 | 8  | 8          | foo
+   58 | 608 | 00058_trig_update      | Sat Feb 28 00:00:00 1970 PST | Sat Feb 28 00:00:00 1970 | 8  | 8          | foo
+   68 | 608 | 00068_trig_update      | Tue Mar 10 00:00:00 1970 PST | Tue Mar 10 00:00:00 1970 | 8  | 8          | foo
+   78 | 608 | 00078_trig_update      | Fri Mar 20 00:00:00 1970 PST | Fri Mar 20 00:00:00 1970 | 8  | 8          | foo
+   88 | 608 | 00088_trig_update      | Mon Mar 30 00:00:00 1970 PST | Mon Mar 30 00:00:00 1970 | 8  | 8          | foo
+   98 | 608 | 00098_trig_update      | Thu Apr 09 00:00:00 1970 PST | Thu Apr 09 00:00:00 1970 | 8  | 8          | foo
+  108 | 608 | 00108_trig_update      | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+  118 | 608 | 00118_trig_update      | Mon Jan 19 00:00:00 1970 PST | Mon Jan 19 00:00:00 1970 | 8  | 8          | foo
+  128 | 608 | 00128_trig_update      | Thu Jan 29 00:00:00 1970 PST | Thu Jan 29 00:00:00 1970 | 8  | 8          | foo
+  138 | 608 | 00138_trig_update      | Sun Feb 08 00:00:00 1970 PST | Sun Feb 08 00:00:00 1970 | 8  | 8          | foo
+  148 | 608 | 00148_trig_update      | Wed Feb 18 00:00:00 1970 PST | Wed Feb 18 00:00:00 1970 | 8  | 8          | foo
+  158 | 608 | 00158_trig_update      | Sat Feb 28 00:00:00 1970 PST | Sat Feb 28 00:00:00 1970 | 8  | 8          | foo
+  168 | 608 | 00168_trig_update      | Tue Mar 10 00:00:00 1970 PST | Tue Mar 10 00:00:00 1970 | 8  | 8          | foo
+  178 | 608 | 00178_trig_update      | Fri Mar 20 00:00:00 1970 PST | Fri Mar 20 00:00:00 1970 | 8  | 8          | foo
+  188 | 608 | 00188_trig_update      | Mon Mar 30 00:00:00 1970 PST | Mon Mar 30 00:00:00 1970 | 8  | 8          | foo
+  198 | 608 | 00198_trig_update      | Thu Apr 09 00:00:00 1970 PST | Thu Apr 09 00:00:00 1970 | 8  | 8          | foo
+  208 | 608 | 00208_trig_update      | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+  218 | 608 | 00218_trig_update      | Mon Jan 19 00:00:00 1970 PST | Mon Jan 19 00:00:00 1970 | 8  | 8          | foo
+  228 | 608 | 00228_trig_update      | Thu Jan 29 00:00:00 1970 PST | Thu Jan 29 00:00:00 1970 | 8  | 8          | foo
+  238 | 608 | 00238_trig_update      | Sun Feb 08 00:00:00 1970 PST | Sun Feb 08 00:00:00 1970 | 8  | 8          | foo
+  248 | 608 | 00248_trig_update      | Wed Feb 18 00:00:00 1970 PST | Wed Feb 18 00:00:00 1970 | 8  | 8          | foo
+  258 | 608 | 00258_trig_update      | Sat Feb 28 00:00:00 1970 PST | Sat Feb 28 00:00:00 1970 | 8  | 8          | foo
+  268 | 608 | 00268_trig_update      | Tue Mar 10 00:00:00 1970 PST | Tue Mar 10 00:00:00 1970 | 8  | 8          | foo
+  278 | 608 | 00278_trig_update      | Fri Mar 20 00:00:00 1970 PST | Fri Mar 20 00:00:00 1970 | 8  | 8          | foo
+  288 | 608 | 00288_trig_update      | Mon Mar 30 00:00:00 1970 PST | Mon Mar 30 00:00:00 1970 | 8  | 8          | foo
+  298 | 608 | 00298_trig_update      | Thu Apr 09 00:00:00 1970 PST | Thu Apr 09 00:00:00 1970 | 8  | 8          | foo
+  308 | 608 | 00308_trig_update      | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+  318 | 608 | 00318_trig_update      | Mon Jan 19 00:00:00 1970 PST | Mon Jan 19 00:00:00 1970 | 8  | 8          | foo
+  328 | 608 | 00328_trig_update      | Thu Jan 29 00:00:00 1970 PST | Thu Jan 29 00:00:00 1970 | 8  | 8          | foo
+  338 | 608 | 00338_trig_update      | Sun Feb 08 00:00:00 1970 PST | Sun Feb 08 00:00:00 1970 | 8  | 8          | foo
+  348 | 608 | 00348_trig_update      | Wed Feb 18 00:00:00 1970 PST | Wed Feb 18 00:00:00 1970 | 8  | 8          | foo
+  358 | 608 | 00358_trig_update      | Sat Feb 28 00:00:00 1970 PST | Sat Feb 28 00:00:00 1970 | 8  | 8          | foo
+  368 | 608 | 00368_trig_update      | Tue Mar 10 00:00:00 1970 PST | Tue Mar 10 00:00:00 1970 | 8  | 8          | foo
+  378 | 608 | 00378_trig_update      | Fri Mar 20 00:00:00 1970 PST | Fri Mar 20 00:00:00 1970 | 8  | 8          | foo
+  388 | 608 | 00388_trig_update      | Mon Mar 30 00:00:00 1970 PST | Mon Mar 30 00:00:00 1970 | 8  | 8          | foo
+  398 | 608 | 00398_trig_update      | Thu Apr 09 00:00:00 1970 PST | Thu Apr 09 00:00:00 1970 | 8  | 8          | foo
+  408 | 608 | 00408_trig_update      | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+  418 | 608 | 00418_trig_update      | Mon Jan 19 00:00:00 1970 PST | Mon Jan 19 00:00:00 1970 | 8  | 8          | foo
+  428 | 608 | 00428_trig_update      | Thu Jan 29 00:00:00 1970 PST | Thu Jan 29 00:00:00 1970 | 8  | 8          | foo
+  438 | 608 | 00438_trig_update      | Sun Feb 08 00:00:00 1970 PST | Sun Feb 08 00:00:00 1970 | 8  | 8          | foo
+  448 | 608 | 00448_trig_update      | Wed Feb 18 00:00:00 1970 PST | Wed Feb 18 00:00:00 1970 | 8  | 8          | foo
+  458 | 608 | 00458_trig_update      | Sat Feb 28 00:00:00 1970 PST | Sat Feb 28 00:00:00 1970 | 8  | 8          | foo
+  468 | 608 | 00468_trig_update      | Tue Mar 10 00:00:00 1970 PST | Tue Mar 10 00:00:00 1970 | 8  | 8          | foo
+  478 | 608 | 00478_trig_update      | Fri Mar 20 00:00:00 1970 PST | Fri Mar 20 00:00:00 1970 | 8  | 8          | foo
+  488 | 608 | 00488_trig_update      | Mon Mar 30 00:00:00 1970 PST | Mon Mar 30 00:00:00 1970 | 8  | 8          | foo
+  498 | 608 | 00498_trig_update      | Thu Apr 09 00:00:00 1970 PST | Thu Apr 09 00:00:00 1970 | 8  | 8          | foo
+  508 | 608 | 00508_trig_update      | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+  518 | 608 | 00518_trig_update      | Mon Jan 19 00:00:00 1970 PST | Mon Jan 19 00:00:00 1970 | 8  | 8          | foo
+  528 | 608 | 00528_trig_update      | Thu Jan 29 00:00:00 1970 PST | Thu Jan 29 00:00:00 1970 | 8  | 8          | foo
+  538 | 608 | 00538_trig_update      | Sun Feb 08 00:00:00 1970 PST | Sun Feb 08 00:00:00 1970 | 8  | 8          | foo
+  548 | 608 | 00548_trig_update      | Wed Feb 18 00:00:00 1970 PST | Wed Feb 18 00:00:00 1970 | 8  | 8          | foo
+  558 | 608 | 00558_trig_update      | Sat Feb 28 00:00:00 1970 PST | Sat Feb 28 00:00:00 1970 | 8  | 8          | foo
+  568 | 608 | 00568_trig_update      | Tue Mar 10 00:00:00 1970 PST | Tue Mar 10 00:00:00 1970 | 8  | 8          | foo
+  578 | 608 | 00578_trig_update      | Fri Mar 20 00:00:00 1970 PST | Fri Mar 20 00:00:00 1970 | 8  | 8          | foo
+  588 | 608 | 00588_trig_update      | Mon Mar 30 00:00:00 1970 PST | Mon Mar 30 00:00:00 1970 | 8  | 8          | foo
+  598 | 608 | 00598_trig_update      | Thu Apr 09 00:00:00 1970 PST | Thu Apr 09 00:00:00 1970 | 8  | 8          | foo
+  608 | 608 | 00608_trig_update      | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+  618 | 608 | 00618_trig_update      | Mon Jan 19 00:00:00 1970 PST | Mon Jan 19 00:00:00 1970 | 8  | 8          | foo
+  628 | 608 | 00628_trig_update      | Thu Jan 29 00:00:00 1970 PST | Thu Jan 29 00:00:00 1970 | 8  | 8          | foo
+  638 | 608 | 00638_trig_update      | Sun Feb 08 00:00:00 1970 PST | Sun Feb 08 00:00:00 1970 | 8  | 8          | foo
+  648 | 608 | 00648_trig_update      | Wed Feb 18 00:00:00 1970 PST | Wed Feb 18 00:00:00 1970 | 8  | 8          | foo
+  658 | 608 | 00658_trig_update      | Sat Feb 28 00:00:00 1970 PST | Sat Feb 28 00:00:00 1970 | 8  | 8          | foo
+  668 | 608 | 00668_trig_update      | Tue Mar 10 00:00:00 1970 PST | Tue Mar 10 00:00:00 1970 | 8  | 8          | foo
+  678 | 608 | 00678_trig_update      | Fri Mar 20 00:00:00 1970 PST | Fri Mar 20 00:00:00 1970 | 8  | 8          | foo
+  688 | 608 | 00688_trig_update      | Mon Mar 30 00:00:00 1970 PST | Mon Mar 30 00:00:00 1970 | 8  | 8          | foo
+  698 | 608 | 00698_trig_update      | Thu Apr 09 00:00:00 1970 PST | Thu Apr 09 00:00:00 1970 | 8  | 8          | foo
+  708 | 608 | 00708_trig_update      | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+  718 | 608 | 00718_trig_update      | Mon Jan 19 00:00:00 1970 PST | Mon Jan 19 00:00:00 1970 | 8  | 8          | foo
+  728 | 608 | 00728_trig_update      | Thu Jan 29 00:00:00 1970 PST | Thu Jan 29 00:00:00 1970 | 8  | 8          | foo
+  738 | 608 | 00738_trig_update      | Sun Feb 08 00:00:00 1970 PST | Sun Feb 08 00:00:00 1970 | 8  | 8          | foo
+  748 | 608 | 00748_trig_update      | Wed Feb 18 00:00:00 1970 PST | Wed Feb 18 00:00:00 1970 | 8  | 8          | foo
+  758 | 608 | 00758_trig_update      | Sat Feb 28 00:00:00 1970 PST | Sat Feb 28 00:00:00 1970 | 8  | 8          | foo
+  768 | 608 | 00768_trig_update      | Tue Mar 10 00:00:00 1970 PST | Tue Mar 10 00:00:00 1970 | 8  | 8          | foo
+  778 | 608 | 00778_trig_update      | Fri Mar 20 00:00:00 1970 PST | Fri Mar 20 00:00:00 1970 | 8  | 8          | foo
+  788 | 608 | 00788_trig_update      | Mon Mar 30 00:00:00 1970 PST | Mon Mar 30 00:00:00 1970 | 8  | 8          | foo
+  798 | 608 | 00798_trig_update      | Thu Apr 09 00:00:00 1970 PST | Thu Apr 09 00:00:00 1970 | 8  | 8          | foo
+  808 | 608 | 00808_trig_update      | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+  818 | 608 | 00818_trig_update      | Mon Jan 19 00:00:00 1970 PST | Mon Jan 19 00:00:00 1970 | 8  | 8          | foo
+  828 | 608 | 00828_trig_update      | Thu Jan 29 00:00:00 1970 PST | Thu Jan 29 00:00:00 1970 | 8  | 8          | foo
+  838 | 608 | 00838_trig_update      | Sun Feb 08 00:00:00 1970 PST | Sun Feb 08 00:00:00 1970 | 8  | 8          | foo
+  848 | 608 | 00848_trig_update      | Wed Feb 18 00:00:00 1970 PST | Wed Feb 18 00:00:00 1970 | 8  | 8          | foo
+  858 | 608 | 00858_trig_update      | Sat Feb 28 00:00:00 1970 PST | Sat Feb 28 00:00:00 1970 | 8  | 8          | foo
+  868 | 608 | 00868_trig_update      | Tue Mar 10 00:00:00 1970 PST | Tue Mar 10 00:00:00 1970 | 8  | 8          | foo
+  878 | 608 | 00878_trig_update      | Fri Mar 20 00:00:00 1970 PST | Fri Mar 20 00:00:00 1970 | 8  | 8          | foo
+  888 | 608 | 00888_trig_update      | Mon Mar 30 00:00:00 1970 PST | Mon Mar 30 00:00:00 1970 | 8  | 8          | foo
+  898 | 608 | 00898_trig_update      | Thu Apr 09 00:00:00 1970 PST | Thu Apr 09 00:00:00 1970 | 8  | 8          | foo
+  908 | 608 | 00908_trig_update      | Fri Jan 09 00:00:00 1970 PST | Fri Jan 09 00:00:00 1970 | 8  | 8          | foo
+  918 | 608 | 00918_trig_update      | Mon Jan 19 00:00:00 1970 PST | Mon Jan 19 00:00:00 1970 | 8  | 8          | foo
+  928 | 608 | 00928_trig_update      | Thu Jan 29 00:00:00 1970 PST | Thu Jan 29 00:00:00 1970 | 8  | 8          | foo
+  938 | 608 | 00938_trig_update      | Sun Feb 08 00:00:00 1970 PST | Sun Feb 08 00:00:00 1970 | 8  | 8          | foo
+  948 | 608 | 00948_trig_update      | Wed Feb 18 00:00:00 1970 PST | Wed Feb 18 00:00:00 1970 | 8  | 8          | foo
+  958 | 608 | 00958_trig_update      | Sat Feb 28 00:00:00 1970 PST | Sat Feb 28 00:00:00 1970 | 8  | 8          | foo
+  968 | 608 | 00968_trig_update      | Tue Mar 10 00:00:00 1970 PST | Tue Mar 10 00:00:00 1970 | 8  | 8          | foo
+  978 | 608 | 00978_trig_update      | Fri Mar 20 00:00:00 1970 PST | Fri Mar 20 00:00:00 1970 | 8  | 8          | foo
+  988 | 608 | 00988_trig_update      | Mon Mar 30 00:00:00 1970 PST | Mon Mar 30 00:00:00 1970 | 8  | 8          | foo
+  998 | 608 | 00998_trig_update      | Thu Apr 09 00:00:00 1970 PST | Thu Apr 09 00:00:00 1970 | 8  | 8          | foo
+ 1008 | 708 | 0000800008_trig_update |                              |                          |    | ft2        | 
+ 1018 | 708 | 0001800018_trig_update |                              |                          |    | ft2        | 
+(102 rows)
+
+-- Test errors thrown on remote side during update
+ALTER TABLE "S 1"."T 1" ADD CONSTRAINT c2positive CHECK (c2 >= 0);
+INSERT INTO ft1(c1, c2) VALUES(11, 12);  -- duplicate key
+ERROR:  duplicate key value violates unique constraint "t1_pkey"
+DETAIL:  Key ("C 1")=(11) already exists.
+CONTEXT:  remote SQL command: INSERT INTO "S 1"."T 1"("C 1", c2, c3, c4, c5, c6, c7, c8) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
+INSERT INTO ft1(c1, c2) VALUES(11, 12) ON CONFLICT DO NOTHING; -- works
+INSERT INTO ft1(c1, c2) VALUES(11, 12) ON CONFLICT (c1, c2) DO NOTHING; -- unsupported
+ERROR:  there is no unique or exclusion constraint matching the ON CONFLICT specification
+INSERT INTO ft1(c1, c2) VALUES(11, 12) ON CONFLICT (c1, c2) DO UPDATE SET c3 = 'ffg'; -- unsupported
+ERROR:  there is no unique or exclusion constraint matching the ON CONFLICT specification
+INSERT INTO ft1(c1, c2) VALUES(1111, -2);  -- c2positive
+ERROR:  new row for relation "T 1" violates check constraint "c2positive"
+DETAIL:  Failing row contains (1111, -2, null, null, null, null, ft1       , null).
+CONTEXT:  remote SQL command: INSERT INTO "S 1"."T 1"("C 1", c2, c3, c4, c5, c6, c7, c8) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
+UPDATE ft1 SET c2 = -c2 WHERE c1 = 1;  -- c2positive
+ERROR:  new row for relation "T 1" violates check constraint "c2positive"
+DETAIL:  Failing row contains (1, -1, 00001_trig_update, 1970-01-02 08:00:00+00, 1970-01-02 00:00:00, 1, 1         , foo).
+CONTEXT:  remote SQL command: UPDATE "S 1"."T 1" SET c2 = (- c2) WHERE (("C 1" = 1))
+-- Test savepoint/rollback behavior
+select c2, count(*) from ft2 where c2 < 500 group by 1 order by 1;
+ c2  | count 
+-----+-------
+   0 |   100
+   1 |   100
+   4 |   100
+   6 |   100
+ 100 |     2
+ 101 |     2
+ 104 |     2
+ 106 |     2
+ 201 |     1
+ 204 |     1
+ 303 |   100
+ 403 |     2
+ 407 |   100
+(13 rows)
+
+select c2, count(*) from "S 1"."T 1" where c2 < 500 group by 1 order by 1;
+ c2  | count 
+-----+-------
+   0 |   100
+   1 |   100
+   4 |   100
+   6 |   100
+ 100 |     2
+ 101 |     2
+ 104 |     2
+ 106 |     2
+ 201 |     1
+ 204 |     1
+ 303 |   100
+ 403 |     2
+ 407 |   100
+(13 rows)
+
+begin;
+update ft2 set c2 = 42 where c2 = 0;
+select c2, count(*) from ft2 where c2 < 500 group by 1 order by 1;
+ c2  | count 
+-----+-------
+   1 |   100
+   4 |   100
+   6 |   100
+  42 |   100
+ 100 |     2
+ 101 |     2
+ 104 |     2
+ 106 |     2
+ 201 |     1
+ 204 |     1
+ 303 |   100
+ 403 |     2
+ 407 |   100
+(13 rows)
+
+savepoint s1;
+update ft2 set c2 = 44 where c2 = 4;
+select c2, count(*) from ft2 where c2 < 500 group by 1 order by 1;
+ c2  | count 
+-----+-------
+   1 |   100
+   6 |   100
+  42 |   100
+  44 |   100
+ 100 |     2
+ 101 |     2
+ 104 |     2
+ 106 |     2
+ 201 |     1
+ 204 |     1
+ 303 |   100
+ 403 |     2
+ 407 |   100
+(13 rows)
+
+release savepoint s1;
+select c2, count(*) from ft2 where c2 < 500 group by 1 order by 1;
+ c2  | count 
+-----+-------
+   1 |   100
+   6 |   100
+  42 |   100
+  44 |   100
+ 100 |     2
+ 101 |     2
+ 104 |     2
+ 106 |     2
+ 201 |     1
+ 204 |     1
+ 303 |   100
+ 403 |     2
+ 407 |   100
+(13 rows)
+
+savepoint s2;
+update ft2 set c2 = 46 where c2 = 6;
+select c2, count(*) from ft2 where c2 < 500 group by 1 order by 1;
+ c2  | count 
+-----+-------
+   1 |   100
+  42 |   100
+  44 |   100
+  46 |   100
+ 100 |     2
+ 101 |     2
+ 104 |     2
+ 106 |     2
+ 201 |     1
+ 204 |     1
+ 303 |   100
+ 403 |     2
+ 407 |   100
+(13 rows)
+
+rollback to savepoint s2;
+select c2, count(*) from ft2 where c2 < 500 group by 1 order by 1;
+ c2  | count 
+-----+-------
+   1 |   100
+   6 |   100
+  42 |   100
+  44 |   100
+ 100 |     2
+ 101 |     2
+ 104 |     2
+ 106 |     2
+ 201 |     1
+ 204 |     1
+ 303 |   100
+ 403 |     2
+ 407 |   100
+(13 rows)
+
+release savepoint s2;
+select c2, count(*) from ft2 where c2 < 500 group by 1 order by 1;
+ c2  | count 
+-----+-------
+   1 |   100
+   6 |   100
+  42 |   100
+  44 |   100
+ 100 |     2
+ 101 |     2
+ 104 |     2
+ 106 |     2
+ 201 |     1
+ 204 |     1
+ 303 |   100
+ 403 |     2
+ 407 |   100
+(13 rows)
+
+savepoint s3;
+update ft2 set c2 = -2 where c2 = 42 and c1 = 10; -- fail on remote side
+ERROR:  new row for relation "T 1" violates check constraint "c2positive"
+DETAIL:  Failing row contains (10, -2, 00010_trig_update_trig_update, 1970-01-11 08:00:00+00, 1970-01-11 00:00:00, 0, 0         , foo).
+CONTEXT:  remote SQL command: UPDATE "S 1"."T 1" SET c2 = (-2) WHERE ((c2 = 42)) AND (("C 1" = 10))
+rollback to savepoint s3;
+select c2, count(*) from ft2 where c2 < 500 group by 1 order by 1;
+ c2  | count 
+-----+-------
+   1 |   100
+   6 |   100
+  42 |   100
+  44 |   100
+ 100 |     2
+ 101 |     2
+ 104 |     2
+ 106 |     2
+ 201 |     1
+ 204 |     1
+ 303 |   100
+ 403 |     2
+ 407 |   100
+(13 rows)
+
+release savepoint s3;
+select c2, count(*) from ft2 where c2 < 500 group by 1 order by 1;
+ c2  | count 
+-----+-------
+   1 |   100
+   6 |   100
+  42 |   100
+  44 |   100
+ 100 |     2
+ 101 |     2
+ 104 |     2
+ 106 |     2
+ 201 |     1
+ 204 |     1
+ 303 |   100
+ 403 |     2
+ 407 |   100
+(13 rows)
+
+-- none of the above is committed yet remotely
+select c2, count(*) from "S 1"."T 1" where c2 < 500 group by 1 order by 1;
+ c2  | count 
+-----+-------
+   0 |   100
+   1 |   100
+   4 |   100
+   6 |   100
+ 100 |     2
+ 101 |     2
+ 104 |     2
+ 106 |     2
+ 201 |     1
+ 204 |     1
+ 303 |   100
+ 403 |     2
+ 407 |   100
+(13 rows)
+
+commit;
+select c2, count(*) from ft2 where c2 < 500 group by 1 order by 1;
+ c2  | count 
+-----+-------
+   1 |   100
+   6 |   100
+  42 |   100
+  44 |   100
+ 100 |     2
+ 101 |     2
+ 104 |     2
+ 106 |     2
+ 201 |     1
+ 204 |     1
+ 303 |   100
+ 403 |     2
+ 407 |   100
+(13 rows)
+
+select c2, count(*) from "S 1"."T 1" where c2 < 500 group by 1 order by 1;
+ c2  | count 
+-----+-------
+   1 |   100
+   6 |   100
+  42 |   100
+  44 |   100
+ 100 |     2
+ 101 |     2
+ 104 |     2
+ 106 |     2
+ 201 |     1
+ 204 |     1
+ 303 |   100
+ 403 |     2
+ 407 |   100
+(13 rows)
+
+VACUUM ANALYZE "S 1"."T 1";
+-- Above DMLs add data with c6 as NULL in ft1, so test ORDER BY NULLS LAST and NULLs
+-- FIRST behavior here.
+-- ORDER BY DESC NULLS LAST options
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 ORDER BY c6 DESC NULLS LAST, c1 OFFSET 795 LIMIT 10;
+                                                                          QUERY PLAN                                                                           
+---------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" ORDER BY c6 DESC NULLS LAST, "C 1" ASC NULLS LAST LIMIT 10::bigint OFFSET 795::bigint
+(3 rows)
+
+SELECT * FROM ft1 ORDER BY c6 DESC NULLS LAST, c1 OFFSET 795  LIMIT 10;
+  c1  | c2  |         c3         |              c4              |            c5            |  c6  |     c7     | c8  
+------+-----+--------------------+------------------------------+--------------------------+------+------------+-----
+  960 |  42 | 00960_trig_update  | Mon Mar 02 00:00:00 1970 PST | Mon Mar 02 00:00:00 1970 | 0    | 0          | foo
+  970 |  42 | 00970_trig_update  | Thu Mar 12 00:00:00 1970 PST | Thu Mar 12 00:00:00 1970 | 0    | 0          | foo
+  980 |  42 | 00980_trig_update  | Sun Mar 22 00:00:00 1970 PST | Sun Mar 22 00:00:00 1970 | 0    | 0          | foo
+  990 |  42 | 00990_trig_update  | Wed Apr 01 00:00:00 1970 PST | Wed Apr 01 00:00:00 1970 | 0    | 0          | foo
+ 1000 |  42 | 01000_trig_update  | Thu Jan 01 00:00:00 1970 PST | Thu Jan 01 00:00:00 1970 | 0    | 0          | foo
+ 1218 | 818 | ggg_trig_update    |                              |                          | (--; | ft2        | 
+ 1001 | 101 | 0000100001         |                              |                          |      | ft2        | 
+ 1003 | 403 | 0000300003_update3 |                              |                          |      | ft2        | 
+ 1004 | 104 | 0000400004         |                              |                          |      | ft2        | 
+ 1006 | 106 | 0000600006         |                              |                          |      | ft2        | 
+(10 rows)
+
+-- ORDER BY DESC NULLS FIRST options
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 ORDER BY c6 DESC NULLS FIRST, c1 OFFSET 15 LIMIT 10;
+                                                                          QUERY PLAN                                                                           
+---------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" ORDER BY c6 DESC NULLS FIRST, "C 1" ASC NULLS LAST LIMIT 10::bigint OFFSET 15::bigint
+(3 rows)
+
+SELECT * FROM ft1 ORDER BY c6 DESC NULLS FIRST, c1 OFFSET 15 LIMIT 10;
+  c1  | c2  |       c3        |              c4              |            c5            | c6 |     c7     | c8  
+------+-----+-----------------+------------------------------+--------------------------+----+------------+-----
+ 1020 | 100 | 0002000020      |                              |                          |    | ft2        | 
+ 1101 | 201 | aaa             |                              |                          |    | ft2        | 
+ 1103 | 503 | ccc_update3     |                              |                          |    | ft2        | 
+ 1104 | 204 | ddd             |                              |                          |    | ft2        | 
+ 1208 | 818 | fff_trig_update |                              |                          |    | ft2        | 
+    9 | 509 | 00009_update9   | Sat Jan 10 00:00:00 1970 PST | Sat Jan 10 00:00:00 1970 | 9  | ft2        | foo
+   19 | 509 | 00019_update9   | Tue Jan 20 00:00:00 1970 PST | Tue Jan 20 00:00:00 1970 | 9  | ft2        | foo
+   29 | 509 | 00029_update9   | Fri Jan 30 00:00:00 1970 PST | Fri Jan 30 00:00:00 1970 | 9  | ft2        | foo
+   39 | 509 | 00039_update9   | Mon Feb 09 00:00:00 1970 PST | Mon Feb 09 00:00:00 1970 | 9  | ft2        | foo
+   49 | 509 | 00049_update9   | Thu Feb 19 00:00:00 1970 PST | Thu Feb 19 00:00:00 1970 | 9  | ft2        | foo
+(10 rows)
+
+-- ORDER BY ASC NULLS FIRST options
+EXPLAIN (VERBOSE, COSTS OFF) SELECT * FROM ft1 ORDER BY c6 ASC NULLS FIRST, c1 OFFSET 15 LIMIT 10;
+                                                                          QUERY PLAN                                                                          
+--------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan on public.ft1
+   Output: c1, c2, c3, c4, c5, c6, c7, c8
+   Remote SQL: SELECT "C 1", c2, c3, c4, c5, c6, c7, c8 FROM "S 1"."T 1" ORDER BY c6 ASC NULLS FIRST, "C 1" ASC NULLS LAST LIMIT 10::bigint OFFSET 15::bigint
+(3 rows)
+
+SELECT * FROM ft1 ORDER BY c6 ASC NULLS FIRST, c1 OFFSET 15 LIMIT 10;
+  c1  | c2  |        c3         |              c4              |            c5            |  c6  |     c7     | c8  
+------+-----+-------------------+------------------------------+--------------------------+------+------------+-----
+ 1020 | 100 | 0002000020        |                              |                          |      | ft2        | 
+ 1101 | 201 | aaa               |                              |                          |      | ft2        | 
+ 1103 | 503 | ccc_update3       |                              |                          |      | ft2        | 
+ 1104 | 204 | ddd               |                              |                          |      | ft2        | 
+ 1208 | 818 | fff_trig_update   |                              |                          |      | ft2        | 
+ 1218 | 818 | ggg_trig_update   |                              |                          | (--; | ft2        | 
+   10 |  42 | 00010_trig_update | Sun Jan 11 00:00:00 1970 PST | Sun Jan 11 00:00:00 1970 | 0    | 0          | foo
+   20 |  42 | 00020_trig_update | Wed Jan 21 00:00:00 1970 PST | Wed Jan 21 00:00:00 1970 | 0    | 0          | foo
+   30 |  42 | 00030_trig_update | Sat Jan 31 00:00:00 1970 PST | Sat Jan 31 00:00:00 1970 | 0    | 0          | foo
+   40 |  42 | 00040_trig_update | Tue Feb 10 00:00:00 1970 PST | Tue Feb 10 00:00:00 1970 | 0    | 0          | foo
+(10 rows)
+
+-- ===================================================================
+-- test check constraints
+-- ===================================================================
+-- Consistent check constraints provide consistent results
+ALTER FOREIGN TABLE ft1 ADD CONSTRAINT ft1_c2positive CHECK (c2 >= 0);
+EXPLAIN (VERBOSE, COSTS OFF) SELECT count(*) FROM ft1 WHERE c2 < 0;
+                           QUERY PLAN                            
+-----------------------------------------------------------------
+ Foreign Scan
+   Output: (count(*))
+   Relations: Aggregate on (public.ft1)
+   Remote SQL: SELECT count(*) FROM "S 1"."T 1" WHERE ((c2 < 0))
+(4 rows)
+
+SELECT count(*) FROM ft1 WHERE c2 < 0;
+ count 
+-------
+     0
+(1 row)
+
+SET constraint_exclusion = 'on';
+EXPLAIN (VERBOSE, COSTS OFF) SELECT count(*) FROM ft1 WHERE c2 < 0;
+           QUERY PLAN           
+--------------------------------
+ Aggregate
+   Output: count(*)
+   ->  Result
+         One-Time Filter: false
+(4 rows)
+
+SELECT count(*) FROM ft1 WHERE c2 < 0;
+ count 
+-------
+     0
+(1 row)
+
+RESET constraint_exclusion;
+-- check constraint is enforced on the remote side, not locally
+INSERT INTO ft1(c1, c2) VALUES(1111, -2);  -- c2positive
+ERROR:  new row for relation "T 1" violates check constraint "c2positive"
+DETAIL:  Failing row contains (1111, -2, null, null, null, null, ft1       , null).
+CONTEXT:  remote SQL command: INSERT INTO "S 1"."T 1"("C 1", c2, c3, c4, c5, c6, c7, c8) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
+UPDATE ft1 SET c2 = -c2 WHERE c1 = 1;  -- c2positive
+ERROR:  new row for relation "T 1" violates check constraint "c2positive"
+DETAIL:  Failing row contains (1, -1, 00001_trig_update, 1970-01-02 08:00:00+00, 1970-01-02 00:00:00, 1, 1         , foo).
+CONTEXT:  remote SQL command: UPDATE "S 1"."T 1" SET c2 = (- c2) WHERE (("C 1" = 1))
+ALTER FOREIGN TABLE ft1 DROP CONSTRAINT ft1_c2positive;
+-- But inconsistent check constraints provide inconsistent results
+ALTER FOREIGN TABLE ft1 ADD CONSTRAINT ft1_c2negative CHECK (c2 < 0);
+EXPLAIN (VERBOSE, COSTS OFF) SELECT count(*) FROM ft1 WHERE c2 >= 0;
+                            QUERY PLAN                            
+------------------------------------------------------------------
+ Foreign Scan
+   Output: (count(*))
+   Relations: Aggregate on (public.ft1)
+   Remote SQL: SELECT count(*) FROM "S 1"."T 1" WHERE ((c2 >= 0))
+(4 rows)
+
+SELECT count(*) FROM ft1 WHERE c2 >= 0;
+ count 
+-------
+   821
+(1 row)
+
+SET constraint_exclusion = 'on';
+EXPLAIN (VERBOSE, COSTS OFF) SELECT count(*) FROM ft1 WHERE c2 >= 0;
+           QUERY PLAN           
+--------------------------------
+ Aggregate
+   Output: count(*)
+   ->  Result
+         One-Time Filter: false
+(4 rows)
+
+SELECT count(*) FROM ft1 WHERE c2 >= 0;
+ count 
+-------
+     0
+(1 row)
+
+RESET constraint_exclusion;
+-- local check constraint is not actually enforced
+INSERT INTO ft1(c1, c2) VALUES(1111, 2);
+UPDATE ft1 SET c2 = c2 + 1 WHERE c1 = 1;
+ALTER FOREIGN TABLE ft1 DROP CONSTRAINT ft1_c2negative;
+-- ===================================================================
+-- test WITH CHECK OPTION constraints
+-- ===================================================================
+CREATE FUNCTION row_before_insupd_trigfunc() RETURNS trigger AS $$BEGIN NEW.a := NEW.a + 10; RETURN NEW; END$$ LANGUAGE plpgsql;
+CREATE TABLE base_tbl (a int, b int);
+ALTER TABLE base_tbl SET (autovacuum_enabled = 'false');
+CREATE TRIGGER row_before_insupd_trigger BEFORE INSERT OR UPDATE ON base_tbl FOR EACH ROW EXECUTE PROCEDURE row_before_insupd_trigfunc();
+CREATE FOREIGN TABLE foreign_tbl (a int, b int)
+  SERVER loopback OPTIONS (table_name 'base_tbl');
+CREATE VIEW rw_view AS SELECT * FROM foreign_tbl
+  WHERE a < b WITH CHECK OPTION;
+\d+ rw_view
+                           View "public.rw_view"
+ Column |  Type   | Collation | Nullable | Default | Storage | Description 
+--------+---------+-----------+----------+---------+---------+-------------
+ a      | integer |           |          |         | plain   | 
+ b      | integer |           |          |         | plain   | 
+View definition:
+ SELECT foreign_tbl.a,
+    foreign_tbl.b
+   FROM foreign_tbl
+  WHERE foreign_tbl.a < foreign_tbl.b;
+Options: check_option=cascaded
+
+EXPLAIN (VERBOSE, COSTS OFF)
+INSERT INTO rw_view VALUES (0, 5);
+                                   QUERY PLAN                                   
+--------------------------------------------------------------------------------
+ Insert on public.foreign_tbl
+   Remote SQL: INSERT INTO public.base_tbl(a, b) VALUES ($1, $2) RETURNING a, b
+   ->  Result
+         Output: 0, 5
+(4 rows)
+
+INSERT INTO rw_view VALUES (0, 5); -- should fail
+ERROR:  new row violates check option for view "rw_view"
+DETAIL:  Failing row contains (10, 5).
+EXPLAIN (VERBOSE, COSTS OFF)
+INSERT INTO rw_view VALUES (0, 15);
+                                   QUERY PLAN                                   
+--------------------------------------------------------------------------------
+ Insert on public.foreign_tbl
+   Remote SQL: INSERT INTO public.base_tbl(a, b) VALUES ($1, $2) RETURNING a, b
+   ->  Result
+         Output: 0, 15
+(4 rows)
+
+INSERT INTO rw_view VALUES (0, 15); -- ok
+SELECT * FROM foreign_tbl;
+ a  | b  
+----+----
+ 10 | 15
+(1 row)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+UPDATE rw_view SET b = b + 5;
+                                      QUERY PLAN                                       
+---------------------------------------------------------------------------------------
+ Update on public.foreign_tbl
+   Remote SQL: UPDATE public.base_tbl SET b = $2 WHERE ctid = $1 RETURNING a, b
+   ->  Foreign Scan on public.foreign_tbl
+         Output: foreign_tbl.a, (foreign_tbl.b + 5), foreign_tbl.ctid
+         Remote SQL: SELECT a, b, ctid FROM public.base_tbl WHERE ((a < b)) FOR UPDATE
+(5 rows)
+
+UPDATE rw_view SET b = b + 5; -- should fail
+ERROR:  new row violates check option for view "rw_view"
+DETAIL:  Failing row contains (20, 20).
+EXPLAIN (VERBOSE, COSTS OFF)
+UPDATE rw_view SET b = b + 15;
+                                      QUERY PLAN                                       
+---------------------------------------------------------------------------------------
+ Update on public.foreign_tbl
+   Remote SQL: UPDATE public.base_tbl SET b = $2 WHERE ctid = $1 RETURNING a, b
+   ->  Foreign Scan on public.foreign_tbl
+         Output: foreign_tbl.a, (foreign_tbl.b + 15), foreign_tbl.ctid
+         Remote SQL: SELECT a, b, ctid FROM public.base_tbl WHERE ((a < b)) FOR UPDATE
+(5 rows)
+
+UPDATE rw_view SET b = b + 15; -- ok
+SELECT * FROM foreign_tbl;
+ a  | b  
+----+----
+ 20 | 30
+(1 row)
+
+DROP FOREIGN TABLE foreign_tbl CASCADE;
+NOTICE:  drop cascades to view rw_view
+DROP TRIGGER row_before_insupd_trigger ON base_tbl;
+DROP TABLE base_tbl;
+-- test WCO for partitions
+CREATE TABLE child_tbl (a int, b int);
+ALTER TABLE child_tbl SET (autovacuum_enabled = 'false');
+CREATE TRIGGER row_before_insupd_trigger BEFORE INSERT OR UPDATE ON child_tbl FOR EACH ROW EXECUTE PROCEDURE row_before_insupd_trigfunc();
+CREATE FOREIGN TABLE foreign_tbl (a int, b int)
+  SERVER loopback OPTIONS (table_name 'child_tbl');
+CREATE TABLE parent_tbl (a int, b int) PARTITION BY RANGE(a);
+ALTER TABLE parent_tbl ATTACH PARTITION foreign_tbl FOR VALUES FROM (0) TO (100);
+CREATE VIEW rw_view AS SELECT * FROM parent_tbl
+  WHERE a < b WITH CHECK OPTION;
+\d+ rw_view
+                           View "public.rw_view"
+ Column |  Type   | Collation | Nullable | Default | Storage | Description 
+--------+---------+-----------+----------+---------+---------+-------------
+ a      | integer |           |          |         | plain   | 
+ b      | integer |           |          |         | plain   | 
+View definition:
+ SELECT parent_tbl.a,
+    parent_tbl.b
+   FROM parent_tbl
+  WHERE parent_tbl.a < parent_tbl.b;
+Options: check_option=cascaded
+
+EXPLAIN (VERBOSE, COSTS OFF)
+INSERT INTO rw_view VALUES (0, 5);
+         QUERY PLAN          
+-----------------------------
+ Insert on public.parent_tbl
+   ->  Result
+         Output: 0, 5
+(3 rows)
+
+INSERT INTO rw_view VALUES (0, 5); -- should fail
+ERROR:  new row violates check option for view "rw_view"
+DETAIL:  Failing row contains (10, 5).
+EXPLAIN (VERBOSE, COSTS OFF)
+INSERT INTO rw_view VALUES (0, 15);
+         QUERY PLAN          
+-----------------------------
+ Insert on public.parent_tbl
+   ->  Result
+         Output: 0, 15
+(3 rows)
+
+INSERT INTO rw_view VALUES (0, 15); -- ok
+SELECT * FROM foreign_tbl;
+ a  | b  
+----+----
+ 10 | 15
+(1 row)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+UPDATE rw_view SET b = b + 5;
+                                       QUERY PLAN                                       
+----------------------------------------------------------------------------------------
+ Update on public.parent_tbl
+   Foreign Update on public.foreign_tbl
+     Remote SQL: UPDATE public.child_tbl SET b = $2 WHERE ctid = $1 RETURNING a, b
+   ->  Foreign Scan on public.foreign_tbl
+         Output: foreign_tbl.a, (foreign_tbl.b + 5), foreign_tbl.ctid
+         Remote SQL: SELECT a, b, ctid FROM public.child_tbl WHERE ((a < b)) FOR UPDATE
+(6 rows)
+
+UPDATE rw_view SET b = b + 5; -- should fail
+ERROR:  new row violates check option for view "rw_view"
+DETAIL:  Failing row contains (20, 20).
+EXPLAIN (VERBOSE, COSTS OFF)
+UPDATE rw_view SET b = b + 15;
+                                       QUERY PLAN                                       
+----------------------------------------------------------------------------------------
+ Update on public.parent_tbl
+   Foreign Update on public.foreign_tbl
+     Remote SQL: UPDATE public.child_tbl SET b = $2 WHERE ctid = $1 RETURNING a, b
+   ->  Foreign Scan on public.foreign_tbl
+         Output: foreign_tbl.a, (foreign_tbl.b + 15), foreign_tbl.ctid
+         Remote SQL: SELECT a, b, ctid FROM public.child_tbl WHERE ((a < b)) FOR UPDATE
+(6 rows)
+
+UPDATE rw_view SET b = b + 15; -- ok
+SELECT * FROM foreign_tbl;
+ a  | b  
+----+----
+ 20 | 30
+(1 row)
+
+DROP FOREIGN TABLE foreign_tbl CASCADE;
+DROP TRIGGER row_before_insupd_trigger ON child_tbl;
+DROP TABLE parent_tbl CASCADE;
+NOTICE:  drop cascades to view rw_view
+DROP FUNCTION row_before_insupd_trigfunc;
+-- ===================================================================
+-- test serial columns (ie, sequence-based defaults)
+-- ===================================================================
+create table loc1 (f1 serial, f2 text);
+alter table loc1 set (autovacuum_enabled = 'false');
+create foreign table rem1 (f1 serial, f2 text)
+  server loopback options(table_name 'loc1');
+select pg_catalog.setval('rem1_f1_seq', 10, false);
+ setval 
+--------
+     10
+(1 row)
+
+insert into loc1(f2) values('hi');
+insert into rem1(f2) values('hi remote');
+insert into loc1(f2) values('bye');
+insert into rem1(f2) values('bye remote');
+select * from loc1;
+ f1 |     f2     
+----+------------
+  1 | hi
+ 10 | hi remote
+  2 | bye
+ 11 | bye remote
+(4 rows)
+
+select * from rem1;
+ f1 |     f2     
+----+------------
+  1 | hi
+ 10 | hi remote
+  2 | bye
+ 11 | bye remote
+(4 rows)
+
+-- ===================================================================
+-- test generated columns
+-- ===================================================================
+create table gloc1 (a int, b int);
+alter table gloc1 set (autovacuum_enabled = 'false');
+create foreign table grem1 (
+  a int,
+  b int generated always as (a * 2) stored)
+  server loopback options(table_name 'gloc1');
+insert into grem1 (a) values (1), (2);
+update grem1 set a = 22 where a = 2;
+select * from gloc1;
+ a  | b  
+----+----
+  1 |  2
+ 22 | 44
+(2 rows)
+
+select * from grem1;
+ a  | b  
+----+----
+  1 |  2
+ 22 | 44
+(2 rows)
+
+-- ===================================================================
+-- test local triggers
+-- ===================================================================
+-- Trigger functions "borrowed" from triggers regress test.
+CREATE FUNCTION trigger_func() RETURNS trigger LANGUAGE plpgsql AS $$
+BEGIN
+	RAISE NOTICE 'trigger_func(%) called: action = %, when = %, level = %',
+		TG_ARGV[0], TG_OP, TG_WHEN, TG_LEVEL;
+	RETURN NULL;
+END;$$;
+CREATE TRIGGER trig_stmt_before BEFORE DELETE OR INSERT OR UPDATE ON rem1
+	FOR EACH STATEMENT EXECUTE PROCEDURE trigger_func();
+CREATE TRIGGER trig_stmt_after AFTER DELETE OR INSERT OR UPDATE ON rem1
+	FOR EACH STATEMENT EXECUTE PROCEDURE trigger_func();
+CREATE OR REPLACE FUNCTION trigger_data()  RETURNS trigger
+LANGUAGE plpgsql AS $$
+
+declare
+	oldnew text[];
+	relid text;
+    argstr text;
+begin
+
+	relid := TG_relid::regclass;
+	argstr := '';
+	for i in 0 .. TG_nargs - 1 loop
+		if i > 0 then
+			argstr := argstr || ', ';
+		end if;
+		argstr := argstr || TG_argv[i];
+	end loop;
+
+    RAISE NOTICE '%(%) % % % ON %',
+		tg_name, argstr, TG_when, TG_level, TG_OP, relid;
+    oldnew := '{}'::text[];
+	if TG_OP != 'INSERT' then
+		oldnew := array_append(oldnew, format('OLD: %s', OLD));
+	end if;
+
+	if TG_OP != 'DELETE' then
+		oldnew := array_append(oldnew, format('NEW: %s', NEW));
+	end if;
+
+    RAISE NOTICE '%', array_to_string(oldnew, ',');
+
+	if TG_OP = 'DELETE' then
+		return OLD;
+	else
+		return NEW;
+	end if;
+end;
+$$;
+-- Test basic functionality
+CREATE TRIGGER trig_row_before
+BEFORE INSERT OR UPDATE OR DELETE ON rem1
+FOR EACH ROW EXECUTE PROCEDURE trigger_data(23,'skidoo');
+CREATE TRIGGER trig_row_after
+AFTER INSERT OR UPDATE OR DELETE ON rem1
+FOR EACH ROW EXECUTE PROCEDURE trigger_data(23,'skidoo');
+delete from rem1;
+NOTICE:  trigger_func(<NULL>) called: action = DELETE, when = BEFORE, level = STATEMENT
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW DELETE ON rem1
+NOTICE:  OLD: (1,hi)
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW DELETE ON rem1
+NOTICE:  OLD: (10,"hi remote")
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW DELETE ON rem1
+NOTICE:  OLD: (2,bye)
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW DELETE ON rem1
+NOTICE:  OLD: (11,"bye remote")
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW DELETE ON rem1
+NOTICE:  OLD: (1,hi)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW DELETE ON rem1
+NOTICE:  OLD: (10,"hi remote")
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW DELETE ON rem1
+NOTICE:  OLD: (2,bye)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW DELETE ON rem1
+NOTICE:  OLD: (11,"bye remote")
+NOTICE:  trigger_func(<NULL>) called: action = DELETE, when = AFTER, level = STATEMENT
+insert into rem1 values(1,'insert');
+NOTICE:  trigger_func(<NULL>) called: action = INSERT, when = BEFORE, level = STATEMENT
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW INSERT ON rem1
+NOTICE:  NEW: (1,insert)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW INSERT ON rem1
+NOTICE:  NEW: (1,insert)
+NOTICE:  trigger_func(<NULL>) called: action = INSERT, when = AFTER, level = STATEMENT
+update rem1 set f2  = 'update' where f1 = 1;
+NOTICE:  trigger_func(<NULL>) called: action = UPDATE, when = BEFORE, level = STATEMENT
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW UPDATE ON rem1
+NOTICE:  OLD: (1,insert),NEW: (1,update)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW UPDATE ON rem1
+NOTICE:  OLD: (1,insert),NEW: (1,update)
+NOTICE:  trigger_func(<NULL>) called: action = UPDATE, when = AFTER, level = STATEMENT
+update rem1 set f2 = f2 || f2;
+NOTICE:  trigger_func(<NULL>) called: action = UPDATE, when = BEFORE, level = STATEMENT
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW UPDATE ON rem1
+NOTICE:  OLD: (1,update),NEW: (1,updateupdate)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW UPDATE ON rem1
+NOTICE:  OLD: (1,update),NEW: (1,updateupdate)
+NOTICE:  trigger_func(<NULL>) called: action = UPDATE, when = AFTER, level = STATEMENT
+-- cleanup
+DROP TRIGGER trig_row_before ON rem1;
+DROP TRIGGER trig_row_after ON rem1;
+DROP TRIGGER trig_stmt_before ON rem1;
+DROP TRIGGER trig_stmt_after ON rem1;
+DELETE from rem1;
+-- Test WHEN conditions
+CREATE TRIGGER trig_row_before_insupd
+BEFORE INSERT OR UPDATE ON rem1
+FOR EACH ROW
+WHEN (NEW.f2 like '%update%')
+EXECUTE PROCEDURE trigger_data(23,'skidoo');
+CREATE TRIGGER trig_row_after_insupd
+AFTER INSERT OR UPDATE ON rem1
+FOR EACH ROW
+WHEN (NEW.f2 like '%update%')
+EXECUTE PROCEDURE trigger_data(23,'skidoo');
+-- Insert or update not matching: nothing happens
+INSERT INTO rem1 values(1, 'insert');
+UPDATE rem1 set f2 = 'test';
+-- Insert or update matching: triggers are fired
+INSERT INTO rem1 values(2, 'update');
+NOTICE:  trig_row_before_insupd(23, skidoo) BEFORE ROW INSERT ON rem1
+NOTICE:  NEW: (2,update)
+NOTICE:  trig_row_after_insupd(23, skidoo) AFTER ROW INSERT ON rem1
+NOTICE:  NEW: (2,update)
+UPDATE rem1 set f2 = 'update update' where f1 = '2';
+NOTICE:  trig_row_before_insupd(23, skidoo) BEFORE ROW UPDATE ON rem1
+NOTICE:  OLD: (2,update),NEW: (2,"update update")
+NOTICE:  trig_row_after_insupd(23, skidoo) AFTER ROW UPDATE ON rem1
+NOTICE:  OLD: (2,update),NEW: (2,"update update")
+CREATE TRIGGER trig_row_before_delete
+BEFORE DELETE ON rem1
+FOR EACH ROW
+WHEN (OLD.f2 like '%update%')
+EXECUTE PROCEDURE trigger_data(23,'skidoo');
+CREATE TRIGGER trig_row_after_delete
+AFTER DELETE ON rem1
+FOR EACH ROW
+WHEN (OLD.f2 like '%update%')
+EXECUTE PROCEDURE trigger_data(23,'skidoo');
+-- Trigger is fired for f1=2, not for f1=1
+DELETE FROM rem1;
+NOTICE:  trig_row_before_delete(23, skidoo) BEFORE ROW DELETE ON rem1
+NOTICE:  OLD: (2,"update update")
+NOTICE:  trig_row_after_delete(23, skidoo) AFTER ROW DELETE ON rem1
+NOTICE:  OLD: (2,"update update")
+-- cleanup
+DROP TRIGGER trig_row_before_insupd ON rem1;
+DROP TRIGGER trig_row_after_insupd ON rem1;
+DROP TRIGGER trig_row_before_delete ON rem1;
+DROP TRIGGER trig_row_after_delete ON rem1;
+-- Test various RETURN statements in BEFORE triggers.
+CREATE FUNCTION trig_row_before_insupdate() RETURNS TRIGGER AS $$
+  BEGIN
+    NEW.f2 := NEW.f2 || ' triggered !';
+    RETURN NEW;
+  END
+$$ language plpgsql;
+CREATE TRIGGER trig_row_before_insupd
+BEFORE INSERT OR UPDATE ON rem1
+FOR EACH ROW EXECUTE PROCEDURE trig_row_before_insupdate();
+-- The new values should have 'triggered' appended
+INSERT INTO rem1 values(1, 'insert');
+SELECT * from loc1;
+ f1 |         f2         
+----+--------------------
+  1 | insert triggered !
+(1 row)
+
+INSERT INTO rem1 values(2, 'insert') RETURNING f2;
+         f2         
+--------------------
+ insert triggered !
+(1 row)
+
+SELECT * from loc1;
+ f1 |         f2         
+----+--------------------
+  1 | insert triggered !
+  2 | insert triggered !
+(2 rows)
+
+UPDATE rem1 set f2 = '';
+SELECT * from loc1;
+ f1 |      f2      
+----+--------------
+  1 |  triggered !
+  2 |  triggered !
+(2 rows)
+
+UPDATE rem1 set f2 = 'skidoo' RETURNING f2;
+         f2         
+--------------------
+ skidoo triggered !
+ skidoo triggered !
+(2 rows)
+
+SELECT * from loc1;
+ f1 |         f2         
+----+--------------------
+  1 | skidoo triggered !
+  2 | skidoo triggered !
+(2 rows)
+
+DELETE FROM rem1;
+-- Add a second trigger, to check that the changes are propagated correctly
+-- from trigger to trigger
+CREATE TRIGGER trig_row_before_insupd2
+BEFORE INSERT OR UPDATE ON rem1
+FOR EACH ROW EXECUTE PROCEDURE trig_row_before_insupdate();
+INSERT INTO rem1 values(1, 'insert');
+SELECT * from loc1;
+ f1 |               f2               
+----+--------------------------------
+  1 | insert triggered ! triggered !
+(1 row)
+
+INSERT INTO rem1 values(2, 'insert') RETURNING f2;
+               f2               
+--------------------------------
+ insert triggered ! triggered !
+(1 row)
+
+SELECT * from loc1;
+ f1 |               f2               
+----+--------------------------------
+  1 | insert triggered ! triggered !
+  2 | insert triggered ! triggered !
+(2 rows)
+
+UPDATE rem1 set f2 = '';
+SELECT * from loc1;
+ f1 |            f2            
+----+--------------------------
+  1 |  triggered ! triggered !
+  2 |  triggered ! triggered !
+(2 rows)
+
+UPDATE rem1 set f2 = 'skidoo' RETURNING f2;
+               f2               
+--------------------------------
+ skidoo triggered ! triggered !
+ skidoo triggered ! triggered !
+(2 rows)
+
+SELECT * from loc1;
+ f1 |               f2               
+----+--------------------------------
+  1 | skidoo triggered ! triggered !
+  2 | skidoo triggered ! triggered !
+(2 rows)
+
+DROP TRIGGER trig_row_before_insupd ON rem1;
+DROP TRIGGER trig_row_before_insupd2 ON rem1;
+DELETE from rem1;
+INSERT INTO rem1 VALUES (1, 'test');
+-- Test with a trigger returning NULL
+CREATE FUNCTION trig_null() RETURNS TRIGGER AS $$
+  BEGIN
+    RETURN NULL;
+  END
+$$ language plpgsql;
+CREATE TRIGGER trig_null
+BEFORE INSERT OR UPDATE OR DELETE ON rem1
+FOR EACH ROW EXECUTE PROCEDURE trig_null();
+-- Nothing should have changed.
+INSERT INTO rem1 VALUES (2, 'test2');
+SELECT * from loc1;
+ f1 |  f2  
+----+------
+  1 | test
+(1 row)
+
+UPDATE rem1 SET f2 = 'test2';
+SELECT * from loc1;
+ f1 |  f2  
+----+------
+  1 | test
+(1 row)
+
+DELETE from rem1;
+SELECT * from loc1;
+ f1 |  f2  
+----+------
+  1 | test
+(1 row)
+
+DROP TRIGGER trig_null ON rem1;
+DELETE from rem1;
+-- Test a combination of local and remote triggers
+CREATE TRIGGER trig_row_before
+BEFORE INSERT OR UPDATE OR DELETE ON rem1
+FOR EACH ROW EXECUTE PROCEDURE trigger_data(23,'skidoo');
+CREATE TRIGGER trig_row_after
+AFTER INSERT OR UPDATE OR DELETE ON rem1
+FOR EACH ROW EXECUTE PROCEDURE trigger_data(23,'skidoo');
+CREATE TRIGGER trig_local_before BEFORE INSERT OR UPDATE ON loc1
+FOR EACH ROW EXECUTE PROCEDURE trig_row_before_insupdate();
+INSERT INTO rem1(f2) VALUES ('test');
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW INSERT ON rem1
+NOTICE:  NEW: (12,test)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW INSERT ON rem1
+NOTICE:  NEW: (12,"test triggered !")
+UPDATE rem1 SET f2 = 'testo';
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW UPDATE ON rem1
+NOTICE:  OLD: (12,"test triggered !"),NEW: (12,testo)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW UPDATE ON rem1
+NOTICE:  OLD: (12,"test triggered !"),NEW: (12,"testo triggered !")
+-- Test returning a system attribute
+INSERT INTO rem1(f2) VALUES ('test') RETURNING ctid;
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW INSERT ON rem1
+NOTICE:  NEW: (13,test)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW INSERT ON rem1
+NOTICE:  NEW: (13,"test triggered !")
+  ctid  
+--------
+ (1,16)
+(1 row)
+
+-- cleanup
+DROP TRIGGER trig_row_before ON rem1;
+DROP TRIGGER trig_row_after ON rem1;
+DROP TRIGGER trig_local_before ON loc1;
+-- Test direct foreign table modification functionality
+-- Test with statement-level triggers
+CREATE TRIGGER trig_stmt_before
+	BEFORE DELETE OR INSERT OR UPDATE ON rem1
+	FOR EACH STATEMENT EXECUTE PROCEDURE trigger_func();
+EXPLAIN (verbose, costs off)
+UPDATE rem1 set f2 = '';          -- can be pushed down
+                        QUERY PLAN                        
+----------------------------------------------------------
+ Update on public.rem1
+   ->  Foreign Update on public.rem1
+         Remote SQL: UPDATE public.loc1 SET f2 = ''::text
+(3 rows)
+
+EXPLAIN (verbose, costs off)
+DELETE FROM rem1;                 -- can be pushed down
+                 QUERY PLAN                  
+---------------------------------------------
+ Delete on public.rem1
+   ->  Foreign Delete on public.rem1
+         Remote SQL: DELETE FROM public.loc1
+(3 rows)
+
+DROP TRIGGER trig_stmt_before ON rem1;
+CREATE TRIGGER trig_stmt_after
+	AFTER DELETE OR INSERT OR UPDATE ON rem1
+	FOR EACH STATEMENT EXECUTE PROCEDURE trigger_func();
+EXPLAIN (verbose, costs off)
+UPDATE rem1 set f2 = '';          -- can be pushed down
+                        QUERY PLAN                        
+----------------------------------------------------------
+ Update on public.rem1
+   ->  Foreign Update on public.rem1
+         Remote SQL: UPDATE public.loc1 SET f2 = ''::text
+(3 rows)
+
+EXPLAIN (verbose, costs off)
+DELETE FROM rem1;                 -- can be pushed down
+                 QUERY PLAN                  
+---------------------------------------------
+ Delete on public.rem1
+   ->  Foreign Delete on public.rem1
+         Remote SQL: DELETE FROM public.loc1
+(3 rows)
+
+DROP TRIGGER trig_stmt_after ON rem1;
+-- Test with row-level ON INSERT triggers
+CREATE TRIGGER trig_row_before_insert
+BEFORE INSERT ON rem1
+FOR EACH ROW EXECUTE PROCEDURE trigger_data(23,'skidoo');
+EXPLAIN (verbose, costs off)
+UPDATE rem1 set f2 = '';          -- can be pushed down
+                        QUERY PLAN                        
+----------------------------------------------------------
+ Update on public.rem1
+   ->  Foreign Update on public.rem1
+         Remote SQL: UPDATE public.loc1 SET f2 = ''::text
+(3 rows)
+
+EXPLAIN (verbose, costs off)
+DELETE FROM rem1;                 -- can be pushed down
+                 QUERY PLAN                  
+---------------------------------------------
+ Delete on public.rem1
+   ->  Foreign Delete on public.rem1
+         Remote SQL: DELETE FROM public.loc1
+(3 rows)
+
+DROP TRIGGER trig_row_before_insert ON rem1;
+CREATE TRIGGER trig_row_after_insert
+AFTER INSERT ON rem1
+FOR EACH ROW EXECUTE PROCEDURE trigger_data(23,'skidoo');
+EXPLAIN (verbose, costs off)
+UPDATE rem1 set f2 = '';          -- can be pushed down
+                        QUERY PLAN                        
+----------------------------------------------------------
+ Update on public.rem1
+   ->  Foreign Update on public.rem1
+         Remote SQL: UPDATE public.loc1 SET f2 = ''::text
+(3 rows)
+
+EXPLAIN (verbose, costs off)
+DELETE FROM rem1;                 -- can be pushed down
+                 QUERY PLAN                  
+---------------------------------------------
+ Delete on public.rem1
+   ->  Foreign Delete on public.rem1
+         Remote SQL: DELETE FROM public.loc1
+(3 rows)
+
+DROP TRIGGER trig_row_after_insert ON rem1;
+-- Test with row-level ON UPDATE triggers
+CREATE TRIGGER trig_row_before_update
+BEFORE UPDATE ON rem1
+FOR EACH ROW EXECUTE PROCEDURE trigger_data(23,'skidoo');
+EXPLAIN (verbose, costs off)
+UPDATE rem1 set f2 = '';          -- can't be pushed down
+                             QUERY PLAN                              
+---------------------------------------------------------------------
+ Update on public.rem1
+   Remote SQL: UPDATE public.loc1 SET f2 = $2 WHERE ctid = $1
+   ->  Foreign Scan on public.rem1
+         Output: f1, ''::text, ctid, rem1.*
+         Remote SQL: SELECT f1, f2, ctid FROM public.loc1 FOR UPDATE
+(5 rows)
+
+EXPLAIN (verbose, costs off)
+DELETE FROM rem1;                 -- can be pushed down
+                 QUERY PLAN                  
+---------------------------------------------
+ Delete on public.rem1
+   ->  Foreign Delete on public.rem1
+         Remote SQL: DELETE FROM public.loc1
+(3 rows)
+
+DROP TRIGGER trig_row_before_update ON rem1;
+CREATE TRIGGER trig_row_after_update
+AFTER UPDATE ON rem1
+FOR EACH ROW EXECUTE PROCEDURE trigger_data(23,'skidoo');
+EXPLAIN (verbose, costs off)
+UPDATE rem1 set f2 = '';          -- can't be pushed down
+                                  QUERY PLAN                                   
+-------------------------------------------------------------------------------
+ Update on public.rem1
+   Remote SQL: UPDATE public.loc1 SET f2 = $2 WHERE ctid = $1 RETURNING f1, f2
+   ->  Foreign Scan on public.rem1
+         Output: f1, ''::text, ctid, rem1.*
+         Remote SQL: SELECT f1, f2, ctid FROM public.loc1 FOR UPDATE
+(5 rows)
+
+EXPLAIN (verbose, costs off)
+DELETE FROM rem1;                 -- can be pushed down
+                 QUERY PLAN                  
+---------------------------------------------
+ Delete on public.rem1
+   ->  Foreign Delete on public.rem1
+         Remote SQL: DELETE FROM public.loc1
+(3 rows)
+
+DROP TRIGGER trig_row_after_update ON rem1;
+-- Test with row-level ON DELETE triggers
+CREATE TRIGGER trig_row_before_delete
+BEFORE DELETE ON rem1
+FOR EACH ROW EXECUTE PROCEDURE trigger_data(23,'skidoo');
+EXPLAIN (verbose, costs off)
+UPDATE rem1 set f2 = '';          -- can be pushed down
+                        QUERY PLAN                        
+----------------------------------------------------------
+ Update on public.rem1
+   ->  Foreign Update on public.rem1
+         Remote SQL: UPDATE public.loc1 SET f2 = ''::text
+(3 rows)
+
+EXPLAIN (verbose, costs off)
+DELETE FROM rem1;                 -- can't be pushed down
+                             QUERY PLAN                              
+---------------------------------------------------------------------
+ Delete on public.rem1
+   Remote SQL: DELETE FROM public.loc1 WHERE ctid = $1
+   ->  Foreign Scan on public.rem1
+         Output: ctid, rem1.*
+         Remote SQL: SELECT f1, f2, ctid FROM public.loc1 FOR UPDATE
+(5 rows)
+
+DROP TRIGGER trig_row_before_delete ON rem1;
+CREATE TRIGGER trig_row_after_delete
+AFTER DELETE ON rem1
+FOR EACH ROW EXECUTE PROCEDURE trigger_data(23,'skidoo');
+EXPLAIN (verbose, costs off)
+UPDATE rem1 set f2 = '';          -- can be pushed down
+                        QUERY PLAN                        
+----------------------------------------------------------
+ Update on public.rem1
+   ->  Foreign Update on public.rem1
+         Remote SQL: UPDATE public.loc1 SET f2 = ''::text
+(3 rows)
+
+EXPLAIN (verbose, costs off)
+DELETE FROM rem1;                 -- can't be pushed down
+                               QUERY PLAN                               
+------------------------------------------------------------------------
+ Delete on public.rem1
+   Remote SQL: DELETE FROM public.loc1 WHERE ctid = $1 RETURNING f1, f2
+   ->  Foreign Scan on public.rem1
+         Output: ctid, rem1.*
+         Remote SQL: SELECT f1, f2, ctid FROM public.loc1 FOR UPDATE
+(5 rows)
+
+DROP TRIGGER trig_row_after_delete ON rem1;
+-- ===================================================================
+-- test inheritance features
+-- ===================================================================
+CREATE TABLE a (aa TEXT);
+CREATE TABLE loct (aa TEXT, bb TEXT);
+ALTER TABLE a SET (autovacuum_enabled = 'false');
+ALTER TABLE loct SET (autovacuum_enabled = 'false');
+CREATE FOREIGN TABLE b (bb TEXT) INHERITS (a)
+  SERVER loopback OPTIONS (table_name 'loct');
+INSERT INTO a(aa) VALUES('aaa');
+INSERT INTO a(aa) VALUES('aaaa');
+INSERT INTO a(aa) VALUES('aaaaa');
+INSERT INTO b(aa) VALUES('bbb');
+INSERT INTO b(aa) VALUES('bbbb');
+INSERT INTO b(aa) VALUES('bbbbb');
+SELECT tableoid::regclass, * FROM a;
+ tableoid |  aa   
+----------+-------
+ a        | aaa
+ a        | aaaa
+ a        | aaaaa
+ b        | bbb
+ b        | bbbb
+ b        | bbbbb
+(6 rows)
+
+SELECT tableoid::regclass, * FROM b;
+ tableoid |  aa   | bb 
+----------+-------+----
+ b        | bbb   | 
+ b        | bbbb  | 
+ b        | bbbbb | 
+(3 rows)
+
+SELECT tableoid::regclass, * FROM ONLY a;
+ tableoid |  aa   
+----------+-------
+ a        | aaa
+ a        | aaaa
+ a        | aaaaa
+(3 rows)
+
+UPDATE a SET aa = 'zzzzzz' WHERE aa LIKE 'aaaa%';
+SELECT tableoid::regclass, * FROM a;
+ tableoid |   aa   
+----------+--------
+ a        | aaa
+ a        | zzzzzz
+ a        | zzzzzz
+ b        | bbb
+ b        | bbbb
+ b        | bbbbb
+(6 rows)
+
+SELECT tableoid::regclass, * FROM b;
+ tableoid |  aa   | bb 
+----------+-------+----
+ b        | bbb   | 
+ b        | bbbb  | 
+ b        | bbbbb | 
+(3 rows)
+
+SELECT tableoid::regclass, * FROM ONLY a;
+ tableoid |   aa   
+----------+--------
+ a        | aaa
+ a        | zzzzzz
+ a        | zzzzzz
+(3 rows)
+
+UPDATE b SET aa = 'new';
+SELECT tableoid::regclass, * FROM a;
+ tableoid |   aa   
+----------+--------
+ a        | aaa
+ a        | zzzzzz
+ a        | zzzzzz
+ b        | new
+ b        | new
+ b        | new
+(6 rows)
+
+SELECT tableoid::regclass, * FROM b;
+ tableoid | aa  | bb 
+----------+-----+----
+ b        | new | 
+ b        | new | 
+ b        | new | 
+(3 rows)
+
+SELECT tableoid::regclass, * FROM ONLY a;
+ tableoid |   aa   
+----------+--------
+ a        | aaa
+ a        | zzzzzz
+ a        | zzzzzz
+(3 rows)
+
+UPDATE a SET aa = 'newtoo';
+SELECT tableoid::regclass, * FROM a;
+ tableoid |   aa   
+----------+--------
+ a        | newtoo
+ a        | newtoo
+ a        | newtoo
+ b        | newtoo
+ b        | newtoo
+ b        | newtoo
+(6 rows)
+
+SELECT tableoid::regclass, * FROM b;
+ tableoid |   aa   | bb 
+----------+--------+----
+ b        | newtoo | 
+ b        | newtoo | 
+ b        | newtoo | 
+(3 rows)
+
+SELECT tableoid::regclass, * FROM ONLY a;
+ tableoid |   aa   
+----------+--------
+ a        | newtoo
+ a        | newtoo
+ a        | newtoo
+(3 rows)
+
+DELETE FROM a;
+SELECT tableoid::regclass, * FROM a;
+ tableoid | aa 
+----------+----
+(0 rows)
+
+SELECT tableoid::regclass, * FROM b;
+ tableoid | aa | bb 
+----------+----+----
+(0 rows)
+
+SELECT tableoid::regclass, * FROM ONLY a;
+ tableoid | aa 
+----------+----
+(0 rows)
+
+DROP TABLE a CASCADE;
+NOTICE:  drop cascades to foreign table b
+DROP TABLE loct;
+-- Check SELECT FOR UPDATE/SHARE with an inherited source table
+create table loct1 (f1 int, f2 int, f3 int);
+create table loct2 (f1 int, f2 int, f3 int);
+alter table loct1 set (autovacuum_enabled = 'false');
+alter table loct2 set (autovacuum_enabled = 'false');
+create table foo (f1 int, f2 int);
+create foreign table foo2 (f3 int) inherits (foo)
+  server loopback options (table_name 'loct1');
+create table bar (f1 int, f2 int);
+create foreign table bar2 (f3 int) inherits (bar)
+  server loopback options (table_name 'loct2');
+alter table foo set (autovacuum_enabled = 'false');
+alter table bar set (autovacuum_enabled = 'false');
+insert into foo values(1,1);
+insert into foo values(3,3);
+insert into foo2 values(2,2,2);
+insert into foo2 values(4,4,4);
+insert into bar values(1,11);
+insert into bar values(2,22);
+insert into bar values(6,66);
+insert into bar2 values(3,33,33);
+insert into bar2 values(4,44,44);
+insert into bar2 values(7,77,77);
+explain (verbose, costs off)
+select * from bar where f1 in (select f1 from foo) for update;
+                                          QUERY PLAN                                          
+----------------------------------------------------------------------------------------------
+ LockRows
+   Output: bar.f1, bar.f2, bar.ctid, foo.ctid, bar.*, bar.tableoid, foo.*, foo.tableoid
+   ->  Hash Join
+         Output: bar.f1, bar.f2, bar.ctid, foo.ctid, bar.*, bar.tableoid, foo.*, foo.tableoid
+         Inner Unique: true
+         Hash Cond: (bar.f1 = foo.f1)
+         ->  Append
+               ->  Seq Scan on public.bar
+                     Output: bar.f1, bar.f2, bar.ctid, bar.*, bar.tableoid
+               ->  Foreign Scan on public.bar2
+                     Output: bar2.f1, bar2.f2, bar2.ctid, bar2.*, bar2.tableoid
+                     Remote SQL: SELECT f1, f2, f3, ctid FROM public.loct2 FOR UPDATE
+         ->  Hash
+               Output: foo.ctid, foo.f1, foo.*, foo.tableoid
+               ->  HashAggregate
+                     Output: foo.ctid, foo.f1, foo.*, foo.tableoid
+                     Group Key: foo.f1
+                     ->  Append
+                           ->  Seq Scan on public.foo
+                                 Output: foo.ctid, foo.f1, foo.*, foo.tableoid
+                           ->  Foreign Scan on public.foo2
+                                 Output: foo2.ctid, foo2.f1, foo2.*, foo2.tableoid
+                                 Remote SQL: SELECT f1, f2, f3, ctid FROM public.loct1
+(23 rows)
+
+select * from bar where f1 in (select f1 from foo) for update;
+ f1 | f2 
+----+----
+  1 | 11
+  2 | 22
+  3 | 33
+  4 | 44
+(4 rows)
+
+explain (verbose, costs off)
+select * from bar where f1 in (select f1 from foo) for share;
+                                          QUERY PLAN                                          
+----------------------------------------------------------------------------------------------
+ LockRows
+   Output: bar.f1, bar.f2, bar.ctid, foo.ctid, bar.*, bar.tableoid, foo.*, foo.tableoid
+   ->  Hash Join
+         Output: bar.f1, bar.f2, bar.ctid, foo.ctid, bar.*, bar.tableoid, foo.*, foo.tableoid
+         Inner Unique: true
+         Hash Cond: (bar.f1 = foo.f1)
+         ->  Append
+               ->  Seq Scan on public.bar
+                     Output: bar.f1, bar.f2, bar.ctid, bar.*, bar.tableoid
+               ->  Foreign Scan on public.bar2
+                     Output: bar2.f1, bar2.f2, bar2.ctid, bar2.*, bar2.tableoid
+                     Remote SQL: SELECT f1, f2, f3, ctid FROM public.loct2 FOR SHARE
+         ->  Hash
+               Output: foo.ctid, foo.f1, foo.*, foo.tableoid
+               ->  HashAggregate
+                     Output: foo.ctid, foo.f1, foo.*, foo.tableoid
+                     Group Key: foo.f1
+                     ->  Append
+                           ->  Seq Scan on public.foo
+                                 Output: foo.ctid, foo.f1, foo.*, foo.tableoid
+                           ->  Foreign Scan on public.foo2
+                                 Output: foo2.ctid, foo2.f1, foo2.*, foo2.tableoid
+                                 Remote SQL: SELECT f1, f2, f3, ctid FROM public.loct1
+(23 rows)
+
+select * from bar where f1 in (select f1 from foo) for share;
+ f1 | f2 
+----+----
+  1 | 11
+  2 | 22
+  3 | 33
+  4 | 44
+(4 rows)
+
+-- Check UPDATE with inherited target and an inherited source table
+explain (verbose, costs off)
+update bar set f2 = f2 + 100 where f1 in (select f1 from foo);
+                                         QUERY PLAN                                          
+---------------------------------------------------------------------------------------------
+ Update on public.bar
+   Update on public.bar
+   Foreign Update on public.bar2
+     Remote SQL: UPDATE public.loct2 SET f2 = $2 WHERE ctid = $1
+   ->  Hash Join
+         Output: bar.f1, (bar.f2 + 100), bar.ctid, foo.ctid, foo.*, foo.tableoid
+         Inner Unique: true
+         Hash Cond: (bar.f1 = foo.f1)
+         ->  Seq Scan on public.bar
+               Output: bar.f1, bar.f2, bar.ctid
+         ->  Hash
+               Output: foo.ctid, foo.f1, foo.*, foo.tableoid
+               ->  HashAggregate
+                     Output: foo.ctid, foo.f1, foo.*, foo.tableoid
+                     Group Key: foo.f1
+                     ->  Append
+                           ->  Seq Scan on public.foo
+                                 Output: foo.ctid, foo.f1, foo.*, foo.tableoid
+                           ->  Foreign Scan on public.foo2
+                                 Output: foo2.ctid, foo2.f1, foo2.*, foo2.tableoid
+                                 Remote SQL: SELECT f1, f2, f3, ctid FROM public.loct1
+   ->  Hash Join
+         Output: bar2.f1, (bar2.f2 + 100), bar2.f3, bar2.ctid, foo.ctid, foo.*, foo.tableoid
+         Inner Unique: true
+         Hash Cond: (bar2.f1 = foo.f1)
+         ->  Foreign Scan on public.bar2
+               Output: bar2.f1, bar2.f2, bar2.f3, bar2.ctid
+               Remote SQL: SELECT f1, f2, f3, ctid FROM public.loct2 FOR UPDATE
+         ->  Hash
+               Output: foo.ctid, foo.f1, foo.*, foo.tableoid
+               ->  HashAggregate
+                     Output: foo.ctid, foo.f1, foo.*, foo.tableoid
+                     Group Key: foo.f1
+                     ->  Append
+                           ->  Seq Scan on public.foo
+                                 Output: foo.ctid, foo.f1, foo.*, foo.tableoid
+                           ->  Foreign Scan on public.foo2
+                                 Output: foo2.ctid, foo2.f1, foo2.*, foo2.tableoid
+                                 Remote SQL: SELECT f1, f2, f3, ctid FROM public.loct1
+(39 rows)
+
+update bar set f2 = f2 + 100 where f1 in (select f1 from foo);
+select tableoid::regclass, * from bar order by 1,2;
+ tableoid | f1 | f2  
+----------+----+-----
+ bar      |  1 | 111
+ bar      |  2 | 122
+ bar      |  6 |  66
+ bar2     |  3 | 133
+ bar2     |  4 | 144
+ bar2     |  7 |  77
+(6 rows)
+
+-- Check UPDATE with inherited target and an appendrel subquery
+explain (verbose, costs off)
+update bar set f2 = f2 + 100
+from
+  ( select f1 from foo union all select f1+3 from foo ) ss
+where bar.f1 = ss.f1;
+                                      QUERY PLAN                                      
+--------------------------------------------------------------------------------------
+ Update on public.bar
+   Update on public.bar
+   Foreign Update on public.bar2
+     Remote SQL: UPDATE public.loct2 SET f2 = $2 WHERE ctid = $1
+   ->  Hash Join
+         Output: bar.f1, (bar.f2 + 100), bar.ctid, (ROW(foo.f1))
+         Hash Cond: (foo.f1 = bar.f1)
+         ->  Append
+               ->  Seq Scan on public.foo
+                     Output: ROW(foo.f1), foo.f1
+               ->  Foreign Scan on public.foo2
+                     Output: ROW(foo2.f1), foo2.f1
+                     Remote SQL: SELECT f1 FROM public.loct1
+               ->  Seq Scan on public.foo foo_1
+                     Output: ROW((foo_1.f1 + 3)), (foo_1.f1 + 3)
+               ->  Foreign Scan on public.foo2 foo2_1
+                     Output: ROW((foo2_1.f1 + 3)), (foo2_1.f1 + 3)
+                     Remote SQL: SELECT f1 FROM public.loct1
+         ->  Hash
+               Output: bar.f1, bar.f2, bar.ctid
+               ->  Seq Scan on public.bar
+                     Output: bar.f1, bar.f2, bar.ctid
+   ->  Merge Join
+         Output: bar2.f1, (bar2.f2 + 100), bar2.f3, bar2.ctid, (ROW(foo.f1))
+         Merge Cond: (bar2.f1 = foo.f1)
+         ->  Sort
+               Output: bar2.f1, bar2.f2, bar2.f3, bar2.ctid
+               Sort Key: bar2.f1
+               ->  Foreign Scan on public.bar2
+                     Output: bar2.f1, bar2.f2, bar2.f3, bar2.ctid
+                     Remote SQL: SELECT f1, f2, f3, ctid FROM public.loct2 FOR UPDATE
+         ->  Sort
+               Output: (ROW(foo.f1)), foo.f1
+               Sort Key: foo.f1
+               ->  Append
+                     ->  Seq Scan on public.foo
+                           Output: ROW(foo.f1), foo.f1
+                     ->  Foreign Scan on public.foo2
+                           Output: ROW(foo2.f1), foo2.f1
+                           Remote SQL: SELECT f1 FROM public.loct1
+                     ->  Seq Scan on public.foo foo_1
+                           Output: ROW((foo_1.f1 + 3)), (foo_1.f1 + 3)
+                     ->  Foreign Scan on public.foo2 foo2_1
+                           Output: ROW((foo2_1.f1 + 3)), (foo2_1.f1 + 3)
+                           Remote SQL: SELECT f1 FROM public.loct1
+(45 rows)
+
+update bar set f2 = f2 + 100
+from
+  ( select f1 from foo union all select f1+3 from foo ) ss
+where bar.f1 = ss.f1;
+select tableoid::regclass, * from bar order by 1,2;
+ tableoid | f1 | f2  
+----------+----+-----
+ bar      |  1 | 211
+ bar      |  2 | 222
+ bar      |  6 | 166
+ bar2     |  3 | 233
+ bar2     |  4 | 244
+ bar2     |  7 | 177
+(6 rows)
+
+-- Test forcing the remote server to produce sorted data for a merge join,
+-- but the foreign table is an inheritance child.
+truncate table loct1;
+truncate table only foo;
+\set num_rows_foo 2000
+insert into loct1 select generate_series(0, :num_rows_foo, 2), generate_series(0, :num_rows_foo, 2), generate_series(0, :num_rows_foo, 2);
+insert into foo select generate_series(1, :num_rows_foo, 2), generate_series(1, :num_rows_foo, 2);
+SET enable_hashjoin to false;
+SET enable_nestloop to false;
+alter foreign table foo2 options (use_remote_estimate 'true');
+create index i_loct1_f1 on loct1(f1);
+create index i_foo_f1 on foo(f1);
+analyze foo;
+analyze loct1;
+-- inner join; expressions in the clauses appear in the equivalence class list
+explain (verbose, costs off)
+	select foo.f1, loct1.f1 from foo join loct1 on (foo.f1 = loct1.f1) order by foo.f2 offset 10 limit 10;
+                                            QUERY PLAN                                            
+--------------------------------------------------------------------------------------------------
+ Limit
+   Output: foo.f1, loct1.f1, foo.f2
+   ->  Sort
+         Output: foo.f1, loct1.f1, foo.f2
+         Sort Key: foo.f2
+         ->  Merge Join
+               Output: foo.f1, loct1.f1, foo.f2
+               Merge Cond: (foo.f1 = loct1.f1)
+               ->  Merge Append
+                     Sort Key: foo.f1
+                     ->  Index Scan using i_foo_f1 on public.foo
+                           Output: foo.f1, foo.f2
+                     ->  Foreign Scan on public.foo2
+                           Output: foo2.f1, foo2.f2
+                           Remote SQL: SELECT f1, f2 FROM public.loct1 ORDER BY f1 ASC NULLS LAST
+               ->  Index Only Scan using i_loct1_f1 on public.loct1
+                     Output: loct1.f1
+(17 rows)
+
+select foo.f1, loct1.f1 from foo join loct1 on (foo.f1 = loct1.f1) order by foo.f2 offset 10 limit 10;
+ f1 | f1 
+----+----
+ 20 | 20
+ 22 | 22
+ 24 | 24
+ 26 | 26
+ 28 | 28
+ 30 | 30
+ 32 | 32
+ 34 | 34
+ 36 | 36
+ 38 | 38
+(10 rows)
+
+-- outer join; expressions in the clauses do not appear in equivalence class
+-- list but no output change as compared to the previous query
+explain (verbose, costs off)
+	select foo.f1, loct1.f1 from foo left join loct1 on (foo.f1 = loct1.f1) order by foo.f2 offset 10 limit 10;
+                                            QUERY PLAN                                            
+--------------------------------------------------------------------------------------------------
+ Limit
+   Output: foo.f1, loct1.f1, foo.f2
+   ->  Sort
+         Output: foo.f1, loct1.f1, foo.f2
+         Sort Key: foo.f2
+         ->  Merge Left Join
+               Output: foo.f1, loct1.f1, foo.f2
+               Merge Cond: (foo.f1 = loct1.f1)
+               ->  Merge Append
+                     Sort Key: foo.f1
+                     ->  Index Scan using i_foo_f1 on public.foo
+                           Output: foo.f1, foo.f2
+                     ->  Foreign Scan on public.foo2
+                           Output: foo2.f1, foo2.f2
+                           Remote SQL: SELECT f1, f2 FROM public.loct1 ORDER BY f1 ASC NULLS LAST
+               ->  Index Only Scan using i_loct1_f1 on public.loct1
+                     Output: loct1.f1
+(17 rows)
+
+select foo.f1, loct1.f1 from foo left join loct1 on (foo.f1 = loct1.f1) order by foo.f2 offset 10 limit 10;
+ f1 | f1 
+----+----
+ 10 | 10
+ 11 |   
+ 12 | 12
+ 13 |   
+ 14 | 14
+ 15 |   
+ 16 | 16
+ 17 |   
+ 18 | 18
+ 19 |   
+(10 rows)
+
+RESET enable_hashjoin;
+RESET enable_nestloop;
+-- Test that WHERE CURRENT OF is not supported
+begin;
+declare c cursor for select * from bar where f1 = 7;
+fetch from c;
+ f1 | f2  
+----+-----
+  7 | 177
+(1 row)
+
+update bar set f2 = null where current of c;
+ERROR:  WHERE CURRENT OF is not supported for this table type
+rollback;
+explain (verbose, costs off)
+delete from foo where f1 < 5 returning *;
+                                   QUERY PLAN                                   
+--------------------------------------------------------------------------------
+ Delete on public.foo
+   Output: foo.f1, foo.f2
+   Delete on public.foo
+   Foreign Delete on public.foo2
+   ->  Bitmap Heap Scan on public.foo
+         Output: foo.ctid
+         Recheck Cond: (foo.f1 < 5)
+         ->  Bitmap Index Scan on i_foo_f1
+               Index Cond: (foo.f1 < 5)
+   ->  Foreign Delete on public.foo2
+         Remote SQL: DELETE FROM public.loct1 WHERE ((f1 < 5)) RETURNING f1, f2
+(11 rows)
+
+delete from foo where f1 < 5 returning *;
+ f1 | f2 
+----+----
+  1 |  1
+  3 |  3
+  0 |  0
+  2 |  2
+  4 |  4
+(5 rows)
+
+explain (verbose, costs off)
+update bar set f2 = f2 + 100 returning *;
+                                  QUERY PLAN                                  
+------------------------------------------------------------------------------
+ Update on public.bar
+   Output: bar.f1, bar.f2
+   Update on public.bar
+   Foreign Update on public.bar2
+   ->  Seq Scan on public.bar
+         Output: bar.f1, (bar.f2 + 100), bar.ctid
+   ->  Foreign Update on public.bar2
+         Remote SQL: UPDATE public.loct2 SET f2 = (f2 + 100) RETURNING f1, f2
+(8 rows)
+
+update bar set f2 = f2 + 100 returning *;
+ f1 | f2  
+----+-----
+  1 | 311
+  2 | 322
+  6 | 266
+  3 | 333
+  4 | 344
+  7 | 277
+(6 rows)
+
+-- Test that UPDATE/DELETE with inherited target works with row-level triggers
+CREATE TRIGGER trig_row_before
+BEFORE UPDATE OR DELETE ON bar2
+FOR EACH ROW EXECUTE PROCEDURE trigger_data(23,'skidoo');
+CREATE TRIGGER trig_row_after
+AFTER UPDATE OR DELETE ON bar2
+FOR EACH ROW EXECUTE PROCEDURE trigger_data(23,'skidoo');
+explain (verbose, costs off)
+update bar set f2 = f2 + 100;
+                                      QUERY PLAN                                      
+--------------------------------------------------------------------------------------
+ Update on public.bar
+   Update on public.bar
+   Foreign Update on public.bar2
+     Remote SQL: UPDATE public.loct2 SET f2 = $2 WHERE ctid = $1 RETURNING f1, f2, f3
+   ->  Seq Scan on public.bar
+         Output: bar.f1, (bar.f2 + 100), bar.ctid
+   ->  Foreign Scan on public.bar2
+         Output: bar2.f1, (bar2.f2 + 100), bar2.f3, bar2.ctid, bar2.*
+         Remote SQL: SELECT f1, f2, f3, ctid FROM public.loct2 FOR UPDATE
+(9 rows)
+
+update bar set f2 = f2 + 100;
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW UPDATE ON bar2
+NOTICE:  OLD: (3,333,33),NEW: (3,433,33)
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW UPDATE ON bar2
+NOTICE:  OLD: (4,344,44),NEW: (4,444,44)
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW UPDATE ON bar2
+NOTICE:  OLD: (7,277,77),NEW: (7,377,77)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW UPDATE ON bar2
+NOTICE:  OLD: (3,333,33),NEW: (3,433,33)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW UPDATE ON bar2
+NOTICE:  OLD: (4,344,44),NEW: (4,444,44)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW UPDATE ON bar2
+NOTICE:  OLD: (7,277,77),NEW: (7,377,77)
+explain (verbose, costs off)
+delete from bar where f2 < 400;
+                                         QUERY PLAN                                          
+---------------------------------------------------------------------------------------------
+ Delete on public.bar
+   Delete on public.bar
+   Foreign Delete on public.bar2
+     Remote SQL: DELETE FROM public.loct2 WHERE ctid = $1 RETURNING f1, f2, f3
+   ->  Seq Scan on public.bar
+         Output: bar.ctid
+         Filter: (bar.f2 < 400)
+   ->  Foreign Scan on public.bar2
+         Output: bar2.ctid, bar2.*
+         Remote SQL: SELECT f1, f2, f3, ctid FROM public.loct2 WHERE ((f2 < 400)) FOR UPDATE
+(10 rows)
+
+delete from bar where f2 < 400;
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW DELETE ON bar2
+NOTICE:  OLD: (7,377,77)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW DELETE ON bar2
+NOTICE:  OLD: (7,377,77)
+-- cleanup
+drop table foo cascade;
+NOTICE:  drop cascades to foreign table foo2
+drop table bar cascade;
+NOTICE:  drop cascades to foreign table bar2
+drop table loct1;
+drop table loct2;
+-- Test pushing down UPDATE/DELETE joins to the remote server
+create table parent (a int, b text);
+create table loct1 (a int, b text);
+create table loct2 (a int, b text);
+create foreign table remt1 (a int, b text)
+  server loopback options (table_name 'loct1');
+create foreign table remt2 (a int, b text)
+  server loopback options (table_name 'loct2');
+alter foreign table remt1 inherit parent;
+insert into remt1 values (1, 'foo');
+insert into remt1 values (2, 'bar');
+insert into remt2 values (1, 'foo');
+insert into remt2 values (2, 'bar');
+analyze remt1;
+analyze remt2;
+explain (verbose, costs off)
+update parent set b = parent.b || remt2.b from remt2 where parent.a = remt2.a returning *;
+                                                                  QUERY PLAN                                                                   
+-----------------------------------------------------------------------------------------------------------------------------------------------
+ Update on public.parent
+   Output: parent.a, parent.b, remt2.a, remt2.b
+   Update on public.parent
+   Foreign Update on public.remt1
+   ->  Nested Loop
+         Output: parent.a, (parent.b || remt2.b), parent.ctid, remt2.*, remt2.a, remt2.b
+         Join Filter: (parent.a = remt2.a)
+         ->  Seq Scan on public.parent
+               Output: parent.a, parent.b, parent.ctid
+         ->  Foreign Scan on public.remt2
+               Output: remt2.b, remt2.*, remt2.a
+               Remote SQL: SELECT a, b FROM public.loct2
+   ->  Foreign Update
+         Remote SQL: UPDATE public.loct1 r4 SET b = (r4.b || r2.b) FROM public.loct2 r2 WHERE ((r4.a = r2.a)) RETURNING r4.a, r4.b, r2.a, r2.b
+(14 rows)
+
+update parent set b = parent.b || remt2.b from remt2 where parent.a = remt2.a returning *;
+ a |   b    | a |  b  
+---+--------+---+-----
+ 1 | foofoo | 1 | foo
+ 2 | barbar | 2 | bar
+(2 rows)
+
+explain (verbose, costs off)
+delete from parent using remt2 where parent.a = remt2.a returning parent;
+                                                    QUERY PLAN                                                    
+------------------------------------------------------------------------------------------------------------------
+ Delete on public.parent
+   Output: parent.*
+   Delete on public.parent
+   Foreign Delete on public.remt1
+   ->  Nested Loop
+         Output: parent.ctid, remt2.*
+         Join Filter: (parent.a = remt2.a)
+         ->  Seq Scan on public.parent
+               Output: parent.ctid, parent.a
+         ->  Foreign Scan on public.remt2
+               Output: remt2.*, remt2.a
+               Remote SQL: SELECT a, b FROM public.loct2
+   ->  Foreign Delete
+         Remote SQL: DELETE FROM public.loct1 r4 USING public.loct2 r2 WHERE ((r4.a = r2.a)) RETURNING r4.a, r4.b
+(14 rows)
+
+delete from parent using remt2 where parent.a = remt2.a returning parent;
+   parent   
+------------
+ (1,foofoo)
+ (2,barbar)
+(2 rows)
+
+-- cleanup
+drop foreign table remt1;
+drop foreign table remt2;
+drop table loct1;
+drop table loct2;
+drop table parent;
+-- ===================================================================
+-- test tuple routing for foreign-table partitions
+-- ===================================================================
+-- Test insert tuple routing
+create table itrtest (a int, b text) partition by list (a);
+create table loct1 (a int check (a in (1)), b text);
+create foreign table remp1 (a int check (a in (1)), b text) server loopback options (table_name 'loct1');
+create table loct2 (a int check (a in (2)), b text);
+create foreign table remp2 (b text, a int check (a in (2))) server loopback options (table_name 'loct2');
+alter table itrtest attach partition remp1 for values in (1);
+alter table itrtest attach partition remp2 for values in (2);
+insert into itrtest values (1, 'foo');
+insert into itrtest values (1, 'bar') returning *;
+ a |  b  
+---+-----
+ 1 | bar
+(1 row)
+
+insert into itrtest values (2, 'baz');
+insert into itrtest values (2, 'qux') returning *;
+ a |  b  
+---+-----
+ 2 | qux
+(1 row)
+
+insert into itrtest values (1, 'test1'), (2, 'test2') returning *;
+ a |   b   
+---+-------
+ 1 | test1
+ 2 | test2
+(2 rows)
+
+select tableoid::regclass, * FROM itrtest;
+ tableoid | a |   b   
+----------+---+-------
+ remp1    | 1 | foo
+ remp1    | 1 | bar
+ remp1    | 1 | test1
+ remp2    | 2 | baz
+ remp2    | 2 | qux
+ remp2    | 2 | test2
+(6 rows)
+
+select tableoid::regclass, * FROM remp1;
+ tableoid | a |   b   
+----------+---+-------
+ remp1    | 1 | foo
+ remp1    | 1 | bar
+ remp1    | 1 | test1
+(3 rows)
+
+select tableoid::regclass, * FROM remp2;
+ tableoid |   b   | a 
+----------+-------+---
+ remp2    | baz   | 2
+ remp2    | qux   | 2
+ remp2    | test2 | 2
+(3 rows)
+
+delete from itrtest;
+create unique index loct1_idx on loct1 (a);
+-- DO NOTHING without an inference specification is supported
+insert into itrtest values (1, 'foo') on conflict do nothing returning *;
+ a |  b  
+---+-----
+ 1 | foo
+(1 row)
+
+insert into itrtest values (1, 'foo') on conflict do nothing returning *;
+ a | b 
+---+---
+(0 rows)
+
+-- But other cases are not supported
+insert into itrtest values (1, 'bar') on conflict (a) do nothing;
+ERROR:  there is no unique or exclusion constraint matching the ON CONFLICT specification
+insert into itrtest values (1, 'bar') on conflict (a) do update set b = excluded.b;
+ERROR:  there is no unique or exclusion constraint matching the ON CONFLICT specification
+select tableoid::regclass, * FROM itrtest;
+ tableoid | a |  b  
+----------+---+-----
+ remp1    | 1 | foo
+(1 row)
+
+delete from itrtest;
+drop index loct1_idx;
+-- Test that remote triggers work with insert tuple routing
+create function br_insert_trigfunc() returns trigger as $$
+begin
+	new.b := new.b || ' triggered !';
+	return new;
+end
+$$ language plpgsql;
+create trigger loct1_br_insert_trigger before insert on loct1
+	for each row execute procedure br_insert_trigfunc();
+create trigger loct2_br_insert_trigger before insert on loct2
+	for each row execute procedure br_insert_trigfunc();
+-- The new values are concatenated with ' triggered !'
+insert into itrtest values (1, 'foo') returning *;
+ a |        b        
+---+-----------------
+ 1 | foo triggered !
+(1 row)
+
+insert into itrtest values (2, 'qux') returning *;
+ a |        b        
+---+-----------------
+ 2 | qux triggered !
+(1 row)
+
+insert into itrtest values (1, 'test1'), (2, 'test2') returning *;
+ a |         b         
+---+-------------------
+ 1 | test1 triggered !
+ 2 | test2 triggered !
+(2 rows)
+
+with result as (insert into itrtest values (1, 'test1'), (2, 'test2') returning *) select * from result;
+ a |         b         
+---+-------------------
+ 1 | test1 triggered !
+ 2 | test2 triggered !
+(2 rows)
+
+drop trigger loct1_br_insert_trigger on loct1;
+drop trigger loct2_br_insert_trigger on loct2;
+drop table itrtest;
+drop table loct1;
+drop table loct2;
+-- Test update tuple routing
+create table utrtest (a int, b text) partition by list (a);
+create table loct (a int check (a in (1)), b text);
+create foreign table remp (a int check (a in (1)), b text) server loopback options (table_name 'loct');
+create table locp (a int check (a in (2)), b text);
+alter table utrtest attach partition remp for values in (1);
+alter table utrtest attach partition locp for values in (2);
+insert into utrtest values (1, 'foo');
+insert into utrtest values (2, 'qux');
+select tableoid::regclass, * FROM utrtest;
+ tableoid | a |  b  
+----------+---+-----
+ remp     | 1 | foo
+ locp     | 2 | qux
+(2 rows)
+
+select tableoid::regclass, * FROM remp;
+ tableoid | a |  b  
+----------+---+-----
+ remp     | 1 | foo
+(1 row)
+
+select tableoid::regclass, * FROM locp;
+ tableoid | a |  b  
+----------+---+-----
+ locp     | 2 | qux
+(1 row)
+
+-- It's not allowed to move a row from a partition that is foreign to another
+update utrtest set a = 2 where b = 'foo' returning *;
+ERROR:  new row for relation "loct" violates check constraint "loct_a_check"
+DETAIL:  Failing row contains (2, foo).
+CONTEXT:  remote SQL command: UPDATE public.loct SET a = 2 WHERE ((b = 'foo'::text)) RETURNING a, b
+-- But the reverse is allowed
+update utrtest set a = 1 where b = 'qux' returning *;
+ a |  b  
+---+-----
+ 1 | qux
+(1 row)
+
+select tableoid::regclass, * FROM utrtest;
+ tableoid | a |  b  
+----------+---+-----
+ remp     | 1 | foo
+ remp     | 1 | qux
+(2 rows)
+
+select tableoid::regclass, * FROM remp;
+ tableoid | a |  b  
+----------+---+-----
+ remp     | 1 | foo
+ remp     | 1 | qux
+(2 rows)
+
+select tableoid::regclass, * FROM locp;
+ tableoid | a | b 
+----------+---+---
+(0 rows)
+
+-- The executor should not let unexercised FDWs shut down
+update utrtest set a = 1 where b = 'foo';
+-- Test that remote triggers work with update tuple routing
+create trigger loct_br_insert_trigger before insert on loct
+	for each row execute procedure br_insert_trigfunc();
+delete from utrtest;
+insert into utrtest values (2, 'qux');
+-- Check case where the foreign partition is a subplan target rel
+explain (verbose, costs off)
+update utrtest set a = 1 where a = 1 or a = 2 returning *;
+                                          QUERY PLAN                                          
+----------------------------------------------------------------------------------------------
+ Update on public.utrtest
+   Output: remp.a, remp.b
+   Foreign Update on public.remp
+   Update on public.locp
+   ->  Foreign Update on public.remp
+         Remote SQL: UPDATE public.loct SET a = 1 WHERE (((a = 1) OR (a = 2))) RETURNING a, b
+   ->  Seq Scan on public.locp
+         Output: 1, locp.b, locp.ctid
+         Filter: ((locp.a = 1) OR (locp.a = 2))
+(9 rows)
+
+-- The new values are concatenated with ' triggered !'
+update utrtest set a = 1 where a = 1 or a = 2 returning *;
+ a |        b        
+---+-----------------
+ 1 | qux triggered !
+(1 row)
+
+delete from utrtest;
+insert into utrtest values (2, 'qux');
+-- Check case where the foreign partition isn't a subplan target rel
+explain (verbose, costs off)
+update utrtest set a = 1 where a = 2 returning *;
+              QUERY PLAN              
+--------------------------------------
+ Update on public.utrtest
+   Output: locp.a, locp.b
+   Update on public.locp
+   ->  Seq Scan on public.locp
+         Output: 1, locp.b, locp.ctid
+         Filter: (locp.a = 2)
+(6 rows)
+
+-- The new values are concatenated with ' triggered !'
+update utrtest set a = 1 where a = 2 returning *;
+ a |        b        
+---+-----------------
+ 1 | qux triggered !
+(1 row)
+
+drop trigger loct_br_insert_trigger on loct;
+drop table utrtest;
+drop table loct;
+-- Test copy tuple routing
+create table ctrtest (a int, b text) partition by list (a);
+create table loct1 (a int check (a in (1)), b text);
+create foreign table remp1 (a int check (a in (1)), b text) server loopback options (table_name 'loct1');
+create table loct2 (a int check (a in (2)), b text);
+create foreign table remp2 (b text, a int check (a in (2))) server loopback options (table_name 'loct2');
+alter table ctrtest attach partition remp1 for values in (1);
+alter table ctrtest attach partition remp2 for values in (2);
+copy ctrtest from stdin;
+select tableoid::regclass, * FROM ctrtest;
+ tableoid | a |  b  
+----------+---+-----
+ remp1    | 1 | foo
+ remp2    | 2 | qux
+(2 rows)
+
+select tableoid::regclass, * FROM remp1;
+ tableoid | a |  b  
+----------+---+-----
+ remp1    | 1 | foo
+(1 row)
+
+select tableoid::regclass, * FROM remp2;
+ tableoid |  b  | a 
+----------+-----+---
+ remp2    | qux | 2
+(1 row)
+
+-- Copying into foreign partitions directly should work as well
+copy remp1 from stdin;
+select tableoid::regclass, * FROM remp1;
+ tableoid | a |  b  
+----------+---+-----
+ remp1    | 1 | foo
+ remp1    | 1 | bar
+(2 rows)
+
+drop table ctrtest;
+drop table loct1;
+drop table loct2;
+-- ===================================================================
+-- test COPY FROM
+-- ===================================================================
+create table loc2 (f1 int, f2 text);
+alter table loc2 set (autovacuum_enabled = 'false');
+create foreign table rem2 (f1 int, f2 text) server loopback options(table_name 'loc2');
+-- Test basic functionality
+copy rem2 from stdin;
+select * from rem2;
+ f1 | f2  
+----+-----
+  1 | foo
+  2 | bar
+(2 rows)
+
+delete from rem2;
+-- Test check constraints
+alter table loc2 add constraint loc2_f1positive check (f1 >= 0);
+alter foreign table rem2 add constraint rem2_f1positive check (f1 >= 0);
+-- check constraint is enforced on the remote side, not locally
+copy rem2 from stdin;
+copy rem2 from stdin; -- ERROR
+ERROR:  new row for relation "loc2" violates check constraint "loc2_f1positive"
+DETAIL:  Failing row contains (-1, xyzzy).
+CONTEXT:  remote SQL command: INSERT INTO public.loc2(f1, f2) VALUES ($1, $2)
+COPY rem2, line 1: "-1	xyzzy"
+select * from rem2;
+ f1 | f2  
+----+-----
+  1 | foo
+  2 | bar
+(2 rows)
+
+alter foreign table rem2 drop constraint rem2_f1positive;
+alter table loc2 drop constraint loc2_f1positive;
+delete from rem2;
+-- Test local triggers
+create trigger trig_stmt_before before insert on rem2
+	for each statement execute procedure trigger_func();
+create trigger trig_stmt_after after insert on rem2
+	for each statement execute procedure trigger_func();
+create trigger trig_row_before before insert on rem2
+	for each row execute procedure trigger_data(23,'skidoo');
+create trigger trig_row_after after insert on rem2
+	for each row execute procedure trigger_data(23,'skidoo');
+copy rem2 from stdin;
+NOTICE:  trigger_func(<NULL>) called: action = INSERT, when = BEFORE, level = STATEMENT
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW INSERT ON rem2
+NOTICE:  NEW: (1,foo)
+NOTICE:  trig_row_before(23, skidoo) BEFORE ROW INSERT ON rem2
+NOTICE:  NEW: (2,bar)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW INSERT ON rem2
+NOTICE:  NEW: (1,foo)
+NOTICE:  trig_row_after(23, skidoo) AFTER ROW INSERT ON rem2
+NOTICE:  NEW: (2,bar)
+NOTICE:  trigger_func(<NULL>) called: action = INSERT, when = AFTER, level = STATEMENT
+select * from rem2;
+ f1 | f2  
+----+-----
+  1 | foo
+  2 | bar
+(2 rows)
+
+drop trigger trig_row_before on rem2;
+drop trigger trig_row_after on rem2;
+drop trigger trig_stmt_before on rem2;
+drop trigger trig_stmt_after on rem2;
+delete from rem2;
+create trigger trig_row_before_insert before insert on rem2
+	for each row execute procedure trig_row_before_insupdate();
+-- The new values are concatenated with ' triggered !'
+copy rem2 from stdin;
+select * from rem2;
+ f1 |       f2        
+----+-----------------
+  1 | foo triggered !
+  2 | bar triggered !
+(2 rows)
+
+drop trigger trig_row_before_insert on rem2;
+delete from rem2;
+create trigger trig_null before insert on rem2
+	for each row execute procedure trig_null();
+-- Nothing happens
+copy rem2 from stdin;
+select * from rem2;
+ f1 | f2 
+----+----
+(0 rows)
+
+drop trigger trig_null on rem2;
+delete from rem2;
+-- Test remote triggers
+create trigger trig_row_before_insert before insert on loc2
+	for each row execute procedure trig_row_before_insupdate();
+-- The new values are concatenated with ' triggered !'
+copy rem2 from stdin;
+select * from rem2;
+ f1 |       f2        
+----+-----------------
+  1 | foo triggered !
+  2 | bar triggered !
+(2 rows)
+
+drop trigger trig_row_before_insert on loc2;
+delete from rem2;
+create trigger trig_null before insert on loc2
+	for each row execute procedure trig_null();
+-- Nothing happens
+copy rem2 from stdin;
+select * from rem2;
+ f1 | f2 
+----+----
+(0 rows)
+
+drop trigger trig_null on loc2;
+delete from rem2;
+-- Test a combination of local and remote triggers
+create trigger rem2_trig_row_before before insert on rem2
+	for each row execute procedure trigger_data(23,'skidoo');
+create trigger rem2_trig_row_after after insert on rem2
+	for each row execute procedure trigger_data(23,'skidoo');
+create trigger loc2_trig_row_before_insert before insert on loc2
+	for each row execute procedure trig_row_before_insupdate();
+copy rem2 from stdin;
+NOTICE:  rem2_trig_row_before(23, skidoo) BEFORE ROW INSERT ON rem2
+NOTICE:  NEW: (1,foo)
+NOTICE:  rem2_trig_row_before(23, skidoo) BEFORE ROW INSERT ON rem2
+NOTICE:  NEW: (2,bar)
+NOTICE:  rem2_trig_row_after(23, skidoo) AFTER ROW INSERT ON rem2
+NOTICE:  NEW: (1,"foo triggered !")
+NOTICE:  rem2_trig_row_after(23, skidoo) AFTER ROW INSERT ON rem2
+NOTICE:  NEW: (2,"bar triggered !")
+select * from rem2;
+ f1 |       f2        
+----+-----------------
+  1 | foo triggered !
+  2 | bar triggered !
+(2 rows)
+
+drop trigger rem2_trig_row_before on rem2;
+drop trigger rem2_trig_row_after on rem2;
+drop trigger loc2_trig_row_before_insert on loc2;
+delete from rem2;
+-- test COPY FROM with foreign table created in the same transaction
+create table loc3 (f1 int, f2 text);
+begin;
+create foreign table rem3 (f1 int, f2 text)
+	server loopback options(table_name 'loc3');
+copy rem3 from stdin;
+commit;
+select * from rem3;
+ f1 | f2  
+----+-----
+  1 | foo
+  2 | bar
+(2 rows)
+
+drop foreign table rem3;
+drop table loc3;
+-- ===================================================================
+-- test IMPORT FOREIGN SCHEMA
+-- ===================================================================
+CREATE SCHEMA import_source;
+CREATE TABLE import_source.t1 (c1 int, c2 varchar NOT NULL);
+CREATE TABLE import_source.t2 (c1 int default 42, c2 varchar NULL, c3 text collate "POSIX");
+CREATE TYPE typ1 AS (m1 int, m2 varchar);
+CREATE TABLE import_source.t3 (c1 timestamptz default now(), c2 typ1);
+CREATE TABLE import_source."x 4" (c1 float8, "C 2" text, c3 varchar(42));
+CREATE TABLE import_source."x 5" (c1 float8);
+ALTER TABLE import_source."x 5" DROP COLUMN c1;
+CREATE TABLE import_source.t4 (c1 int) PARTITION BY RANGE (c1);
+CREATE TABLE import_source.t4_part PARTITION OF import_source.t4
+  FOR VALUES FROM (1) TO (100);
+CREATE SCHEMA import_dest1;
+IMPORT FOREIGN SCHEMA import_source FROM SERVER loopback INTO import_dest1;
+\det+ import_dest1.*
+                                     List of foreign tables
+    Schema    | Table |  Server  |                   FDW options                   | Description 
+--------------+-------+----------+-------------------------------------------------+-------------
+ import_dest1 | t1    | loopback | (schema_name 'import_source', table_name 't1')  | 
+ import_dest1 | t2    | loopback | (schema_name 'import_source', table_name 't2')  | 
+ import_dest1 | t3    | loopback | (schema_name 'import_source', table_name 't3')  | 
+ import_dest1 | t4    | loopback | (schema_name 'import_source', table_name 't4')  | 
+ import_dest1 | x 4   | loopback | (schema_name 'import_source', table_name 'x 4') | 
+ import_dest1 | x 5   | loopback | (schema_name 'import_source', table_name 'x 5') | 
+(6 rows)
+
+\d import_dest1.*
+                         Foreign table "import_dest1.t1"
+ Column |       Type        | Collation | Nullable | Default |    FDW options     
+--------+-------------------+-----------+----------+---------+--------------------
+ c1     | integer           |           |          |         | (column_name 'c1')
+ c2     | character varying |           | not null |         | (column_name 'c2')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 't1')
+
+                         Foreign table "import_dest1.t2"
+ Column |       Type        | Collation | Nullable | Default |    FDW options     
+--------+-------------------+-----------+----------+---------+--------------------
+ c1     | integer           |           |          |         | (column_name 'c1')
+ c2     | character varying |           |          |         | (column_name 'c2')
+ c3     | text              | POSIX     |          |         | (column_name 'c3')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 't2')
+
+                             Foreign table "import_dest1.t3"
+ Column |           Type           | Collation | Nullable | Default |    FDW options     
+--------+--------------------------+-----------+----------+---------+--------------------
+ c1     | timestamp with time zone |           |          |         | (column_name 'c1')
+ c2     | typ1                     |           |          |         | (column_name 'c2')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 't3')
+
+                    Foreign table "import_dest1.t4"
+ Column |  Type   | Collation | Nullable | Default |    FDW options     
+--------+---------+-----------+----------+---------+--------------------
+ c1     | integer |           |          |         | (column_name 'c1')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 't4')
+
+                           Foreign table "import_dest1.x 4"
+ Column |         Type          | Collation | Nullable | Default |     FDW options     
+--------+-----------------------+-----------+----------+---------+---------------------
+ c1     | double precision      |           |          |         | (column_name 'c1')
+ C 2    | text                  |           |          |         | (column_name 'C 2')
+ c3     | character varying(42) |           |          |         | (column_name 'c3')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 'x 4')
+
+               Foreign table "import_dest1.x 5"
+ Column | Type | Collation | Nullable | Default | FDW options 
+--------+------+-----------+----------+---------+-------------
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 'x 5')
+
+-- Options
+CREATE SCHEMA import_dest2;
+IMPORT FOREIGN SCHEMA import_source FROM SERVER loopback INTO import_dest2
+  OPTIONS (import_default 'true');
+\det+ import_dest2.*
+                                     List of foreign tables
+    Schema    | Table |  Server  |                   FDW options                   | Description 
+--------------+-------+----------+-------------------------------------------------+-------------
+ import_dest2 | t1    | loopback | (schema_name 'import_source', table_name 't1')  | 
+ import_dest2 | t2    | loopback | (schema_name 'import_source', table_name 't2')  | 
+ import_dest2 | t3    | loopback | (schema_name 'import_source', table_name 't3')  | 
+ import_dest2 | t4    | loopback | (schema_name 'import_source', table_name 't4')  | 
+ import_dest2 | x 4   | loopback | (schema_name 'import_source', table_name 'x 4') | 
+ import_dest2 | x 5   | loopback | (schema_name 'import_source', table_name 'x 5') | 
+(6 rows)
+
+\d import_dest2.*
+                         Foreign table "import_dest2.t1"
+ Column |       Type        | Collation | Nullable | Default |    FDW options     
+--------+-------------------+-----------+----------+---------+--------------------
+ c1     | integer           |           |          |         | (column_name 'c1')
+ c2     | character varying |           | not null |         | (column_name 'c2')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 't1')
+
+                         Foreign table "import_dest2.t2"
+ Column |       Type        | Collation | Nullable | Default |    FDW options     
+--------+-------------------+-----------+----------+---------+--------------------
+ c1     | integer           |           |          | 42      | (column_name 'c1')
+ c2     | character varying |           |          |         | (column_name 'c2')
+ c3     | text              | POSIX     |          |         | (column_name 'c3')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 't2')
+
+                             Foreign table "import_dest2.t3"
+ Column |           Type           | Collation | Nullable | Default |    FDW options     
+--------+--------------------------+-----------+----------+---------+--------------------
+ c1     | timestamp with time zone |           |          | now()   | (column_name 'c1')
+ c2     | typ1                     |           |          |         | (column_name 'c2')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 't3')
+
+                    Foreign table "import_dest2.t4"
+ Column |  Type   | Collation | Nullable | Default |    FDW options     
+--------+---------+-----------+----------+---------+--------------------
+ c1     | integer |           |          |         | (column_name 'c1')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 't4')
+
+                           Foreign table "import_dest2.x 4"
+ Column |         Type          | Collation | Nullable | Default |     FDW options     
+--------+-----------------------+-----------+----------+---------+---------------------
+ c1     | double precision      |           |          |         | (column_name 'c1')
+ C 2    | text                  |           |          |         | (column_name 'C 2')
+ c3     | character varying(42) |           |          |         | (column_name 'c3')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 'x 4')
+
+               Foreign table "import_dest2.x 5"
+ Column | Type | Collation | Nullable | Default | FDW options 
+--------+------+-----------+----------+---------+-------------
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 'x 5')
+
+CREATE SCHEMA import_dest3;
+IMPORT FOREIGN SCHEMA import_source FROM SERVER loopback INTO import_dest3
+  OPTIONS (import_collate 'false', import_not_null 'false');
+\det+ import_dest3.*
+                                     List of foreign tables
+    Schema    | Table |  Server  |                   FDW options                   | Description 
+--------------+-------+----------+-------------------------------------------------+-------------
+ import_dest3 | t1    | loopback | (schema_name 'import_source', table_name 't1')  | 
+ import_dest3 | t2    | loopback | (schema_name 'import_source', table_name 't2')  | 
+ import_dest3 | t3    | loopback | (schema_name 'import_source', table_name 't3')  | 
+ import_dest3 | t4    | loopback | (schema_name 'import_source', table_name 't4')  | 
+ import_dest3 | x 4   | loopback | (schema_name 'import_source', table_name 'x 4') | 
+ import_dest3 | x 5   | loopback | (schema_name 'import_source', table_name 'x 5') | 
+(6 rows)
+
+\d import_dest3.*
+                         Foreign table "import_dest3.t1"
+ Column |       Type        | Collation | Nullable | Default |    FDW options     
+--------+-------------------+-----------+----------+---------+--------------------
+ c1     | integer           |           |          |         | (column_name 'c1')
+ c2     | character varying |           |          |         | (column_name 'c2')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 't1')
+
+                         Foreign table "import_dest3.t2"
+ Column |       Type        | Collation | Nullable | Default |    FDW options     
+--------+-------------------+-----------+----------+---------+--------------------
+ c1     | integer           |           |          |         | (column_name 'c1')
+ c2     | character varying |           |          |         | (column_name 'c2')
+ c3     | text              |           |          |         | (column_name 'c3')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 't2')
+
+                             Foreign table "import_dest3.t3"
+ Column |           Type           | Collation | Nullable | Default |    FDW options     
+--------+--------------------------+-----------+----------+---------+--------------------
+ c1     | timestamp with time zone |           |          |         | (column_name 'c1')
+ c2     | typ1                     |           |          |         | (column_name 'c2')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 't3')
+
+                    Foreign table "import_dest3.t4"
+ Column |  Type   | Collation | Nullable | Default |    FDW options     
+--------+---------+-----------+----------+---------+--------------------
+ c1     | integer |           |          |         | (column_name 'c1')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 't4')
+
+                           Foreign table "import_dest3.x 4"
+ Column |         Type          | Collation | Nullable | Default |     FDW options     
+--------+-----------------------+-----------+----------+---------+---------------------
+ c1     | double precision      |           |          |         | (column_name 'c1')
+ C 2    | text                  |           |          |         | (column_name 'C 2')
+ c3     | character varying(42) |           |          |         | (column_name 'c3')
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 'x 4')
+
+               Foreign table "import_dest3.x 5"
+ Column | Type | Collation | Nullable | Default | FDW options 
+--------+------+-----------+----------+---------+-------------
+Server: loopback
+FDW options: (schema_name 'import_source', table_name 'x 5')
+
+-- Check LIMIT TO and EXCEPT
+CREATE SCHEMA import_dest4;
+IMPORT FOREIGN SCHEMA import_source LIMIT TO (t1, nonesuch)
+  FROM SERVER loopback INTO import_dest4;
+\det+ import_dest4.*
+                                     List of foreign tables
+    Schema    | Table |  Server  |                  FDW options                   | Description 
+--------------+-------+----------+------------------------------------------------+-------------
+ import_dest4 | t1    | loopback | (schema_name 'import_source', table_name 't1') | 
+(1 row)
+
+IMPORT FOREIGN SCHEMA import_source EXCEPT (t1, "x 4", nonesuch)
+  FROM SERVER loopback INTO import_dest4;
+\det+ import_dest4.*
+                                     List of foreign tables
+    Schema    | Table |  Server  |                   FDW options                   | Description 
+--------------+-------+----------+-------------------------------------------------+-------------
+ import_dest4 | t1    | loopback | (schema_name 'import_source', table_name 't1')  | 
+ import_dest4 | t2    | loopback | (schema_name 'import_source', table_name 't2')  | 
+ import_dest4 | t3    | loopback | (schema_name 'import_source', table_name 't3')  | 
+ import_dest4 | t4    | loopback | (schema_name 'import_source', table_name 't4')  | 
+ import_dest4 | x 5   | loopback | (schema_name 'import_source', table_name 'x 5') | 
+(5 rows)
+
+-- Assorted error cases
+IMPORT FOREIGN SCHEMA import_source FROM SERVER loopback INTO import_dest4;
+ERROR:  relation "t1" already exists
+CONTEXT:  importing foreign table "t1"
+IMPORT FOREIGN SCHEMA nonesuch FROM SERVER loopback INTO import_dest4;
+ERROR:  schema "nonesuch" is not present on foreign server "loopback"
+IMPORT FOREIGN SCHEMA nonesuch FROM SERVER loopback INTO notthere;
+ERROR:  schema "notthere" does not exist
+IMPORT FOREIGN SCHEMA nonesuch FROM SERVER nowhere INTO notthere;
+ERROR:  server "nowhere" does not exist
+-- Check case of a type present only on the remote server.
+-- We can fake this by dropping the type locally in our transaction.
+CREATE TYPE "Colors" AS ENUM ('red', 'green', 'blue');
+CREATE TABLE import_source.t5 (c1 int, c2 text collate "C", "Col" "Colors");
+CREATE SCHEMA import_dest5;
+BEGIN;
+DROP TYPE "Colors" CASCADE;
+NOTICE:  drop cascades to column Col of table import_source.t5
+IMPORT FOREIGN SCHEMA import_source LIMIT TO (t5)
+  FROM SERVER loopback INTO import_dest5;  -- ERROR
+ERROR:  type "public.Colors" does not exist
+LINE 4:   "Col" public."Colors" OPTIONS (column_name 'Col')
+                ^
+QUERY:  CREATE FOREIGN TABLE t5 (
+  c1 integer OPTIONS (column_name 'c1'),
+  c2 text OPTIONS (column_name 'c2') COLLATE pg_catalog."C",
+  "Col" public."Colors" OPTIONS (column_name 'Col')
+) SERVER loopback
+OPTIONS (schema_name 'import_source', table_name 't5');
+CONTEXT:  importing foreign table "t5"
+ROLLBACK;
+BEGIN;
+CREATE SERVER fetch101 FOREIGN DATA WRAPPER postgres_fdw OPTIONS( fetch_size '101' );
+SELECT count(*)
+FROM pg_foreign_server
+WHERE srvname = 'fetch101'
+AND srvoptions @> array['fetch_size=101'];
+ count 
+-------
+     1
+(1 row)
+
+ALTER SERVER fetch101 OPTIONS( SET fetch_size '202' );
+SELECT count(*)
+FROM pg_foreign_server
+WHERE srvname = 'fetch101'
+AND srvoptions @> array['fetch_size=101'];
+ count 
+-------
+     0
+(1 row)
+
+SELECT count(*)
+FROM pg_foreign_server
+WHERE srvname = 'fetch101'
+AND srvoptions @> array['fetch_size=202'];
+ count 
+-------
+     1
+(1 row)
+
+CREATE FOREIGN TABLE table30000 ( x int ) SERVER fetch101 OPTIONS ( fetch_size '30000' );
+SELECT COUNT(*)
+FROM pg_foreign_table
+WHERE ftrelid = 'table30000'::regclass
+AND ftoptions @> array['fetch_size=30000'];
+ count 
+-------
+     1
+(1 row)
+
+ALTER FOREIGN TABLE table30000 OPTIONS ( SET fetch_size '60000');
+SELECT COUNT(*)
+FROM pg_foreign_table
+WHERE ftrelid = 'table30000'::regclass
+AND ftoptions @> array['fetch_size=30000'];
+ count 
+-------
+     0
+(1 row)
+
+SELECT COUNT(*)
+FROM pg_foreign_table
+WHERE ftrelid = 'table30000'::regclass
+AND ftoptions @> array['fetch_size=60000'];
+ count 
+-------
+     1
+(1 row)
+
+ROLLBACK;
+-- ===================================================================
+-- test partitionwise joins
+-- ===================================================================
+SET enable_partitionwise_join=on;
+CREATE TABLE fprt1 (a int, b int, c varchar) PARTITION BY RANGE(a);
+CREATE TABLE fprt1_p1 (LIKE fprt1);
+CREATE TABLE fprt1_p2 (LIKE fprt1);
+ALTER TABLE fprt1_p1 SET (autovacuum_enabled = 'false');
+ALTER TABLE fprt1_p2 SET (autovacuum_enabled = 'false');
+INSERT INTO fprt1_p1 SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(0, 249, 2) i;
+INSERT INTO fprt1_p2 SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(250, 499, 2) i;
+CREATE FOREIGN TABLE ftprt1_p1 PARTITION OF fprt1 FOR VALUES FROM (0) TO (250)
+	SERVER loopback OPTIONS (table_name 'fprt1_p1', use_remote_estimate 'true');
+CREATE FOREIGN TABLE ftprt1_p2 PARTITION OF fprt1 FOR VALUES FROM (250) TO (500)
+	SERVER loopback OPTIONS (TABLE_NAME 'fprt1_p2');
+ANALYZE fprt1;
+ANALYZE fprt1_p1;
+ANALYZE fprt1_p2;
+CREATE TABLE fprt2 (a int, b int, c varchar) PARTITION BY RANGE(b);
+CREATE TABLE fprt2_p1 (LIKE fprt2);
+CREATE TABLE fprt2_p2 (LIKE fprt2);
+ALTER TABLE fprt2_p1 SET (autovacuum_enabled = 'false');
+ALTER TABLE fprt2_p2 SET (autovacuum_enabled = 'false');
+INSERT INTO fprt2_p1 SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(0, 249, 3) i;
+INSERT INTO fprt2_p2 SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(250, 499, 3) i;
+CREATE FOREIGN TABLE ftprt2_p1 (b int, c varchar, a int)
+	SERVER loopback OPTIONS (table_name 'fprt2_p1', use_remote_estimate 'true');
+ALTER TABLE fprt2 ATTACH PARTITION ftprt2_p1 FOR VALUES FROM (0) TO (250);
+CREATE FOREIGN TABLE ftprt2_p2 PARTITION OF fprt2 FOR VALUES FROM (250) TO (500)
+	SERVER loopback OPTIONS (table_name 'fprt2_p2', use_remote_estimate 'true');
+ANALYZE fprt2;
+ANALYZE fprt2_p1;
+ANALYZE fprt2_p2;
+-- inner join three tables
+EXPLAIN (COSTS OFF)
+SELECT t1.a,t2.b,t3.c FROM fprt1 t1 INNER JOIN fprt2 t2 ON (t1.a = t2.b) INNER JOIN fprt1 t3 ON (t2.b = t3.a) WHERE t1.a % 25 =0 ORDER BY 1,2,3;
+                                                     QUERY PLAN                                                     
+--------------------------------------------------------------------------------------------------------------------
+ Sort
+   Sort Key: t1.a, t3.c
+   ->  Append
+         ->  Foreign Scan
+               Relations: ((public.ftprt1_p1 t1) INNER JOIN (public.ftprt2_p1 t2)) INNER JOIN (public.ftprt1_p1 t3)
+         ->  Foreign Scan
+               Relations: ((public.ftprt1_p2 t1) INNER JOIN (public.ftprt2_p2 t2)) INNER JOIN (public.ftprt1_p2 t3)
+(7 rows)
+
+SELECT t1.a,t2.b,t3.c FROM fprt1 t1 INNER JOIN fprt2 t2 ON (t1.a = t2.b) INNER JOIN fprt1 t3 ON (t2.b = t3.a) WHERE t1.a % 25 =0 ORDER BY 1,2,3;
+  a  |  b  |  c   
+-----+-----+------
+   0 |   0 | 0000
+ 150 | 150 | 0003
+ 250 | 250 | 0005
+ 400 | 400 | 0008
+(4 rows)
+
+-- left outer join + nullable clause
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT t1.a,t2.b,t2.c FROM fprt1 t1 LEFT JOIN (SELECT * FROM fprt2 WHERE a < 10) t2 ON (t1.a = t2.b and t1.b = t2.a) WHERE t1.a < 10 ORDER BY 1,2,3;
+                                                                                                                     QUERY PLAN                                                                                                                     
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ Foreign Scan
+   Output: t1.a, ftprt2_p1.b, ftprt2_p1.c
+   Relations: (public.ftprt1_p1 t1) LEFT JOIN (public.ftprt2_p1 fprt2)
+   Remote SQL: SELECT r5.a, r6.b, r6.c FROM (public.fprt1_p1 r5 LEFT JOIN public.fprt2_p1 r6 ON (((r5.a = r6.b)) AND ((r5.b = r6.a)) AND ((r6.a < 10)))) WHERE ((r5.a < 10)) ORDER BY r5.a ASC NULLS LAST, r6.b ASC NULLS LAST, r6.c ASC NULLS LAST
+(4 rows)
+
+SELECT t1.a,t2.b,t2.c FROM fprt1 t1 LEFT JOIN (SELECT * FROM fprt2 WHERE a < 10) t2 ON (t1.a = t2.b and t1.b = t2.a) WHERE t1.a < 10 ORDER BY 1,2,3;
+ a | b |  c   
+---+---+------
+ 0 | 0 | 0000
+ 2 |   | 
+ 4 |   | 
+ 6 | 6 | 0000
+ 8 |   | 
+(5 rows)
+
+-- with whole-row reference; partitionwise join does not apply
+EXPLAIN (COSTS OFF)
+SELECT t1.wr, t2.wr FROM (SELECT t1 wr, a FROM fprt1 t1 WHERE t1.a % 25 = 0) t1 FULL JOIN (SELECT t2 wr, b FROM fprt2 t2 WHERE t2.b % 25 = 0) t2 ON (t1.a = t2.b) ORDER BY 1,2;
+                       QUERY PLAN                       
+--------------------------------------------------------
+ Sort
+   Sort Key: ((t1.*)::fprt1), ((t2.*)::fprt2)
+   ->  Hash Full Join
+         Hash Cond: (t1.a = t2.b)
+         ->  Append
+               ->  Foreign Scan on ftprt1_p1 t1
+               ->  Foreign Scan on ftprt1_p2 t1_1
+         ->  Hash
+               ->  Append
+                     ->  Foreign Scan on ftprt2_p1 t2
+                     ->  Foreign Scan on ftprt2_p2 t2_1
+(11 rows)
+
+SELECT t1.wr, t2.wr FROM (SELECT t1 wr, a FROM fprt1 t1 WHERE t1.a % 25 = 0) t1 FULL JOIN (SELECT t2 wr, b FROM fprt2 t2 WHERE t2.b % 25 = 0) t2 ON (t1.a = t2.b) ORDER BY 1,2;
+       wr       |       wr       
+----------------+----------------
+ (0,0,0000)     | (0,0,0000)
+ (50,50,0001)   | 
+ (100,100,0002) | 
+ (150,150,0003) | (150,150,0003)
+ (200,200,0004) | 
+ (250,250,0005) | (250,250,0005)
+ (300,300,0006) | 
+ (350,350,0007) | 
+ (400,400,0008) | (400,400,0008)
+ (450,450,0009) | 
+                | (75,75,0001)
+                | (225,225,0004)
+                | (325,325,0006)
+                | (475,475,0009)
+(14 rows)
+
+-- join with lateral reference
+EXPLAIN (COSTS OFF)
+SELECT t1.a,t1.b FROM fprt1 t1, LATERAL (SELECT t2.a, t2.b FROM fprt2 t2 WHERE t1.a = t2.b AND t1.b = t2.a) q WHERE t1.a%25 = 0 ORDER BY 1,2;
+                                   QUERY PLAN                                    
+---------------------------------------------------------------------------------
+ Sort
+   Sort Key: t1.a, t1.b
+   ->  Append
+         ->  Foreign Scan
+               Relations: (public.ftprt1_p1 t1) INNER JOIN (public.ftprt2_p1 t2)
+         ->  Foreign Scan
+               Relations: (public.ftprt1_p2 t1) INNER JOIN (public.ftprt2_p2 t2)
+(7 rows)
+
+SELECT t1.a,t1.b FROM fprt1 t1, LATERAL (SELECT t2.a, t2.b FROM fprt2 t2 WHERE t1.a = t2.b AND t1.b = t2.a) q WHERE t1.a%25 = 0 ORDER BY 1,2;
+  a  |  b  
+-----+-----
+   0 |   0
+ 150 | 150
+ 250 | 250
+ 400 | 400
+(4 rows)
+
+-- with PHVs, partitionwise join selected but no join pushdown
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.phv, t2.b, t2.phv FROM (SELECT 't1_phv' phv, * FROM fprt1 WHERE a % 25 = 0) t1 FULL JOIN (SELECT 't2_phv' phv, * FROM fprt2 WHERE b % 25 = 0) t2 ON (t1.a = t2.b) ORDER BY t1.a, t2.b;
+                      QUERY PLAN                      
+------------------------------------------------------
+ Sort
+   Sort Key: ftprt1_p1.a, ftprt2_p1.b
+   ->  Append
+         ->  Hash Full Join
+               Hash Cond: (ftprt1_p1.a = ftprt2_p1.b)
+               ->  Foreign Scan on ftprt1_p1
+               ->  Hash
+                     ->  Foreign Scan on ftprt2_p1
+         ->  Hash Full Join
+               Hash Cond: (ftprt1_p2.a = ftprt2_p2.b)
+               ->  Foreign Scan on ftprt1_p2
+               ->  Hash
+                     ->  Foreign Scan on ftprt2_p2
+(13 rows)
+
+SELECT t1.a, t1.phv, t2.b, t2.phv FROM (SELECT 't1_phv' phv, * FROM fprt1 WHERE a % 25 = 0) t1 FULL JOIN (SELECT 't2_phv' phv, * FROM fprt2 WHERE b % 25 = 0) t2 ON (t1.a = t2.b) ORDER BY t1.a, t2.b;
+  a  |  phv   |  b  |  phv   
+-----+--------+-----+--------
+   0 | t1_phv |   0 | t2_phv
+  50 | t1_phv |     | 
+ 100 | t1_phv |     | 
+ 150 | t1_phv | 150 | t2_phv
+ 200 | t1_phv |     | 
+ 250 | t1_phv | 250 | t2_phv
+ 300 | t1_phv |     | 
+ 350 | t1_phv |     | 
+ 400 | t1_phv | 400 | t2_phv
+ 450 | t1_phv |     | 
+     |        |  75 | t2_phv
+     |        | 225 | t2_phv
+     |        | 325 | t2_phv
+     |        | 475 | t2_phv
+(14 rows)
+
+-- test FOR UPDATE; partitionwise join does not apply
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t2.b FROM fprt1 t1 INNER JOIN fprt2 t2 ON (t1.a = t2.b) WHERE t1.a % 25 = 0 ORDER BY 1,2 FOR UPDATE OF t1;
+                          QUERY PLAN                          
+--------------------------------------------------------------
+ LockRows
+   ->  Sort
+         Sort Key: t1.a
+         ->  Hash Join
+               Hash Cond: (t2.b = t1.a)
+               ->  Append
+                     ->  Foreign Scan on ftprt2_p1 t2
+                     ->  Foreign Scan on ftprt2_p2 t2_1
+               ->  Hash
+                     ->  Append
+                           ->  Foreign Scan on ftprt1_p1 t1
+                           ->  Foreign Scan on ftprt1_p2 t1_1
+(12 rows)
+
+SELECT t1.a, t2.b FROM fprt1 t1 INNER JOIN fprt2 t2 ON (t1.a = t2.b) WHERE t1.a % 25 = 0 ORDER BY 1,2 FOR UPDATE OF t1;
+  a  |  b  
+-----+-----
+   0 |   0
+ 150 | 150
+ 250 | 250
+ 400 | 400
+(4 rows)
+
+RESET enable_partitionwise_join;
+-- ===================================================================
+-- test partitionwise aggregates
+-- ===================================================================
+CREATE TABLE pagg_tab (a int, b int, c text) PARTITION BY RANGE(a);
+CREATE TABLE pagg_tab_p1 (LIKE pagg_tab);
+CREATE TABLE pagg_tab_p2 (LIKE pagg_tab);
+CREATE TABLE pagg_tab_p3 (LIKE pagg_tab);
+INSERT INTO pagg_tab_p1 SELECT i % 30, i % 50, to_char(i/30, 'FM0000') FROM generate_series(1, 3000) i WHERE (i % 30) < 10;
+INSERT INTO pagg_tab_p2 SELECT i % 30, i % 50, to_char(i/30, 'FM0000') FROM generate_series(1, 3000) i WHERE (i % 30) < 20 and (i % 30) >= 10;
+INSERT INTO pagg_tab_p3 SELECT i % 30, i % 50, to_char(i/30, 'FM0000') FROM generate_series(1, 3000) i WHERE (i % 30) < 30 and (i % 30) >= 20;
+-- Create foreign partitions
+CREATE FOREIGN TABLE fpagg_tab_p1 PARTITION OF pagg_tab FOR VALUES FROM (0) TO (10) SERVER loopback OPTIONS (table_name 'pagg_tab_p1');
+CREATE FOREIGN TABLE fpagg_tab_p2 PARTITION OF pagg_tab FOR VALUES FROM (10) TO (20) SERVER loopback OPTIONS (table_name 'pagg_tab_p2');;
+CREATE FOREIGN TABLE fpagg_tab_p3 PARTITION OF pagg_tab FOR VALUES FROM (20) TO (30) SERVER loopback OPTIONS (table_name 'pagg_tab_p3');;
+ANALYZE pagg_tab;
+ANALYZE fpagg_tab_p1;
+ANALYZE fpagg_tab_p2;
+ANALYZE fpagg_tab_p3;
+-- When GROUP BY clause matches with PARTITION KEY.
+-- Plan with partitionwise aggregates is disabled
+SET enable_partitionwise_aggregate TO false;
+EXPLAIN (COSTS OFF)
+SELECT a, sum(b), min(b), count(*) FROM pagg_tab GROUP BY a HAVING avg(b) < 22 ORDER BY 1;
+                      QUERY PLAN                       
+-------------------------------------------------------
+ Sort
+   Sort Key: fpagg_tab_p1.a
+   ->  HashAggregate
+         Group Key: fpagg_tab_p1.a
+         Filter: (avg(fpagg_tab_p1.b) < '22'::numeric)
+         ->  Append
+               ->  Foreign Scan on fpagg_tab_p1
+               ->  Foreign Scan on fpagg_tab_p2
+               ->  Foreign Scan on fpagg_tab_p3
+(9 rows)
+
+-- Plan with partitionwise aggregates is enabled
+SET enable_partitionwise_aggregate TO true;
+EXPLAIN (COSTS OFF)
+SELECT a, sum(b), min(b), count(*) FROM pagg_tab GROUP BY a HAVING avg(b) < 22 ORDER BY 1;
+                              QUERY PLAN                              
+----------------------------------------------------------------------
+ Sort
+   Sort Key: fpagg_tab_p1.a
+   ->  Append
+         ->  Foreign Scan
+               Relations: Aggregate on (public.fpagg_tab_p1 pagg_tab)
+         ->  Foreign Scan
+               Relations: Aggregate on (public.fpagg_tab_p2 pagg_tab)
+         ->  Foreign Scan
+               Relations: Aggregate on (public.fpagg_tab_p3 pagg_tab)
+(9 rows)
+
+SELECT a, sum(b), min(b), count(*) FROM pagg_tab GROUP BY a HAVING avg(b) < 22 ORDER BY 1;
+ a  | sum  | min | count 
+----+------+-----+-------
+  0 | 2000 |   0 |   100
+  1 | 2100 |   1 |   100
+ 10 | 2000 |   0 |   100
+ 11 | 2100 |   1 |   100
+ 20 | 2000 |   0 |   100
+ 21 | 2100 |   1 |   100
+(6 rows)
+
+-- Check with whole-row reference
+-- Should have all the columns in the target list for the given relation
+EXPLAIN (VERBOSE, COSTS OFF)
+SELECT a, count(t1) FROM pagg_tab t1 GROUP BY a HAVING avg(b) < 22 ORDER BY 1;
+                               QUERY PLAN                               
+------------------------------------------------------------------------
+ Sort
+   Output: t1.a, (count(((t1.*)::pagg_tab)))
+   Sort Key: t1.a
+   ->  Append
+         ->  HashAggregate
+               Output: t1.a, count(((t1.*)::pagg_tab))
+               Group Key: t1.a
+               Filter: (avg(t1.b) < '22'::numeric)
+               ->  Foreign Scan on public.fpagg_tab_p1 t1
+                     Output: t1.a, t1.*, t1.b
+                     Remote SQL: SELECT a, b, c FROM public.pagg_tab_p1
+         ->  HashAggregate
+               Output: t1_1.a, count(((t1_1.*)::pagg_tab))
+               Group Key: t1_1.a
+               Filter: (avg(t1_1.b) < '22'::numeric)
+               ->  Foreign Scan on public.fpagg_tab_p2 t1_1
+                     Output: t1_1.a, t1_1.*, t1_1.b
+                     Remote SQL: SELECT a, b, c FROM public.pagg_tab_p2
+         ->  HashAggregate
+               Output: t1_2.a, count(((t1_2.*)::pagg_tab))
+               Group Key: t1_2.a
+               Filter: (avg(t1_2.b) < '22'::numeric)
+               ->  Foreign Scan on public.fpagg_tab_p3 t1_2
+                     Output: t1_2.a, t1_2.*, t1_2.b
+                     Remote SQL: SELECT a, b, c FROM public.pagg_tab_p3
+(25 rows)
+
+SELECT a, count(t1) FROM pagg_tab t1 GROUP BY a HAVING avg(b) < 22 ORDER BY 1;
+ a  | count 
+----+-------
+  0 |   100
+  1 |   100
+ 10 |   100
+ 11 |   100
+ 20 |   100
+ 21 |   100
+(6 rows)
+
+-- When GROUP BY clause does not match with PARTITION KEY.
+EXPLAIN (COSTS OFF)
+SELECT b, avg(a), max(a), count(*) FROM pagg_tab GROUP BY b HAVING sum(a) < 700 ORDER BY 1;
+                      QUERY PLAN                      
+------------------------------------------------------
+ Sort
+   Sort Key: fpagg_tab_p1.b
+   ->  Finalize HashAggregate
+         Group Key: fpagg_tab_p1.b
+         Filter: (sum(fpagg_tab_p1.a) < 700)
+         ->  Append
+               ->  Partial HashAggregate
+                     Group Key: fpagg_tab_p1.b
+                     ->  Foreign Scan on fpagg_tab_p1
+               ->  Partial HashAggregate
+                     Group Key: fpagg_tab_p2.b
+                     ->  Foreign Scan on fpagg_tab_p2
+               ->  Partial HashAggregate
+                     Group Key: fpagg_tab_p3.b
+                     ->  Foreign Scan on fpagg_tab_p3
+(15 rows)
+
+-- Clean-up
+RESET enable_partitionwise_aggregate;
diff --git a/contrib/test_decoding/Makefile b/contrib/test_decoding/Makefile
index 4afb1d9..056394a 100644
--- a/contrib/test_decoding/Makefile
+++ b/contrib/test_decoding/Makefile
@@ -12,6 +12,9 @@ ISOLATION = mxact delayed_startup ondisk_startup concurrent_ddl_dml \
 REGRESS_OPTS = --temp-config $(top_srcdir)/contrib/test_decoding/logical.conf
 ISOLATION_OPTS = --temp-config $(top_srcdir)/contrib/test_decoding/logical.conf
 
+# Temp fix while zheap is not supported
+PGOPTIONS += -c default_table_access_method=heap
+
 # Disabled because these tests require "wal_level=logical", which
 # typical installcheck users do not have (e.g. buildfarm clients).
 NO_INSTALLCHECK = 1
diff --git a/doc/src/sgml/config.sgml b/doc/src/sgml/config.sgml
index c91e3e1..0fd49fa 100644
--- a/doc/src/sgml/config.sgml
+++ b/doc/src/sgml/config.sgml
@@ -7442,6 +7442,41 @@ COPY postgres_log FROM '/full/path/to/logfile.csv' WITH csv;
       </listitem>
      </varlistentry>
 
+     <varlistentry id="guc-undo-tablespaces" xreflabel="undo_tablespaces">
+      <term><varname>undo_tablespaces</varname> (<type>string</type>)
+      <indexterm>
+       <primary><varname>undo_tablespaces</varname> configuration parameter</primary>
+      </indexterm>
+      <indexterm><primary>tablespace</primary><secondary>temporary</secondary></indexterm>
+      </term>
+      <listitem>
+       <para>
+        This variable specifies tablespaces in which to store undo data, when
+        undo-aware storage managers (initially "zheap") perform writes.
+       </para>
+
+       <para>
+        The value is a list of names of tablespaces.  When there is more than
+        one name in the list, <productname>PostgreSQL</productname> chooses an
+        arbitrary one.  If the name doesn't correspond to an existing
+        tablespace, the next name is tried, and so on until all names have
+        been tried.  If no valid tablespace is specified, an error is raised.
+        The validation of the name doesn't happen until the first attempt to
+        write undo data.
+       </para>
+
+       <para>
+        The variable can only be changed before the first statement is
+        executed in a transaction.
+       </para>
+
+       <para>
+        The default value is an empty string, which results in all temporary
+        objects being created in the default tablespace.
+       </para>
+      </listitem>
+     </varlistentry>
+ 
      <varlistentry id="guc-check-function-bodies" xreflabel="check_function_bodies">
       <term><varname>check_function_bodies</varname> (<type>boolean</type>)
       <indexterm>
diff --git a/doc/src/sgml/func.sgml b/doc/src/sgml/func.sgml
index c2f5a75..8b4cfc9 100644
--- a/doc/src/sgml/func.sgml
+++ b/doc/src/sgml/func.sgml
@@ -19506,6 +19506,11 @@ SELECT collation for ('foo' COLLATE "de_DE");
        <entry><type>timestamp with time zone</type></entry>
       </row>
 
+      <row>
+       <entry><literal>oldest_xid_with_epoch_having_undo</literal></entry>
+       <entry><type>xid</type></entry>
+      </row>
+
      </tbody>
     </tgroup>
    </table>
diff --git a/doc/src/sgml/monitoring.sgml b/doc/src/sgml/monitoring.sgml
index bf72d0c..37a3e8c 100644
--- a/doc/src/sgml/monitoring.sgml
+++ b/doc/src/sgml/monitoring.sgml
@@ -368,6 +368,14 @@ postgres   27093  0.0  0.0  30096  2752 ?        Ss   11:34   0:00 postgres: ser
       </entry>
      </row>
 
+     <row>
+      <entry><structname>pg_stat_undo_logs</structname><indexterm><primary>pg_stat_undo_logs</primary></indexterm></entry>
+      <entry>One row for each undo log, showing current pointers,
+       transactions and backends.
+       See <xref linkend="pg-stat-undo-logs-view"/> for details.
+      </entry>
+     </row>
+
     </tbody>
    </tgroup>
   </table>
@@ -585,7 +593,6 @@ postgres   27093  0.0  0.0  30096  2752 ?        Ss   11:34   0:00 postgres: ser
    into the kernel's handling of I/O.
   </para>
 
-
   <table id="pg-stat-activity-view" xreflabel="pg_stat_activity">
    <title><structname>pg_stat_activity</structname> View</title>
 
@@ -1693,6 +1700,30 @@ postgres   27093  0.0  0.0  30096  2752 ?        Ss   11:34   0:00 postgres: ser
          <entry>Waiting for a write of a two phase state file.</entry>
         </row>
         <row>
+         <entry><literal>UndoCheckpointRead</literal></entry>
+         <entry>Waiting for a read from an undo checkpoint file.</entry>
+        </row>
+        <row>
+         <entry><literal>UndoCheckpointSync</literal></entry>
+         <entry>Waiting for changes to an undo checkpoint file to reach stable storage.</entry>
+        </row>
+        <row>
+         <entry><literal>UndoCheckpointWrite</literal></entry>
+         <entry>Waiting for a write to an undo checkpoint file.</entry>
+        </row>
+         <row>
+         <entry><literal>UndoFileRead</literal></entry>
+         <entry>Waiting for a read from an undo data file.</entry>
+        </row>
+        <row>
+         <entry><literal>UndoFileSync</literal></entry>
+         <entry>Waiting for changes to an undo data file to reach stable storage.</entry>
+        </row>
+        <row>
+         <entry><literal>UndoFileWrite</literal></entry>
+         <entry>Waiting for a write to an undo data file.</entry>
+        </row>
+        <row>
          <entry><literal>WALBootstrapSync</literal></entry>
          <entry>Waiting for WAL to reach stable storage during bootstrapping.</entry>
         </row>
@@ -1768,6 +1799,80 @@ SELECT pid, wait_event_type, wait_event FROM pg_stat_activity WHERE wait_event i
 </programlisting>
    </para>
 
+  <table id="pg-stat-undo-logs-view" xreflabel="pg_stat_undo_logs">
+   <title><structname>pg_stat_undo_logs</structname> View</title>
+
+   <tgroup cols="3">
+    <thead>
+    <row>
+      <entry>Column</entry>
+      <entry>Type</entry>
+      <entry>Description</entry>
+     </row>
+    </thead>
+
+   <tbody>
+    <row>
+     <entry><structfield>log_number</structfield></entry>
+     <entry><type>oid</type></entry>
+     <entry>Identifier of this undo log</entry>
+    </row>
+    <row>
+     <entry><structfield>persistence</structfield></entry>
+     <entry><type>text</type></entry>
+     <entry>Persistence level of data stored in this undo log; one of
+      <literal>permanent</literal>, <literal>unlogged</literal> or
+      <literal>temporary</literal>.</entry>
+    </row>
+    <row>
+     <entry><structfield>tablespace</structfield></entry>
+     <entry><type>text</type></entry>
+     <entry>Tablespace that holds physical storage of this undo log.</entry>
+    </row>
+    <row>
+     <entry><structfield>discard</structfield></entry>
+     <entry><type>text</type></entry>
+     <entry>Location of the oldest data in this undo log.</entry>
+    </row>
+    <row>
+     <entry><structfield>insert</structfield></entry>
+     <entry><type>text</type></entry>
+     <entry>Location where the next data will be written in this undo
+      log.</entry>
+    </row>
+    <row>
+     <entry><structfield>end</structfield></entry>
+     <entry><type>text</type></entry>
+     <entry>Location one byte past the end of the allocated physical storage
+      backing this undo log.</entry>
+    </row>
+    <row>
+     <entry><structfield>xid</structfield></entry>
+     <entry><type>xid</type></entry>
+     <entry>Transaction currently attached to this undo log
+      for writing.</entry>
+    </row>
+    <row>
+     <entry><structfield>pid</structfield></entry>
+     <entry><type>integer</type></entry>
+     <entry>Process ID of the backend currently attached to this undo log
+      for writing.</entry>
+    </row>
+   </tbody>
+   </tgroup>
+  </table>
+
+  <para>
+   The <structname>pg_stat_undo_logs</structname> view will have one row for
+   each undo log that exists.  Undo logs are extents within a contiguous
+   addressing space that have their own head and tail pointers.
+   Each  backend that has written undo data is associated with one or more undo
+   log, and is the only backend that is allowed to write data to those undo
+   logs.  Backends can be associated with up to three undo logs at a time,
+   because different undo logs are used for the undo data associated with
+   permanent, unlogged and temporary relations.
+  </para>
+ 
   <table id="pg-stat-replication-view" xreflabel="pg_stat_replication">
    <title><structname>pg_stat_replication</structname> View</title>
    <tgroup cols="3">
diff --git a/doc/src/sgml/storage.sgml b/doc/src/sgml/storage.sgml
index 1047c77..dda91f1 100644
--- a/doc/src/sgml/storage.sgml
+++ b/doc/src/sgml/storage.sgml
@@ -142,6 +142,11 @@ Item
 </row>
 
 <row>
+ <entry><filename>pg_undo</filename></entry>
+ <entry>Subdirectory containing undo log meta-data files</entry>
+</row>
+
+<row>
  <entry><filename>pg_wal</filename></entry>
  <entry>Subdirectory containing WAL (Write Ahead Log) files</entry>
 </row>
@@ -694,6 +699,57 @@ erased (they will be recreated automatically as needed).
 
 </sect1>
 
+<sect1 id="undo-logs">
+
+<title>Undo Logs</title>
+
+<indexterm>
+ <primary>Undo Logs</primary>
+</indexterm>
+
+<para>
+Undo logs hold data that is used for rolling back and for implementing
+MVCC in access managers that are undo-aware (currently "zheap").  The storage
+format of undo logs is optimized for reusing existing files.
+</para>
+
+<para>
+Undo data exists in a 64 bit address space broken up into numbered undo logs
+that represent 1TB extents, for efficient management.  The space is further
+broken up into 1MB segment files, for physical storage.  The name of each file
+is the address of of the first byte in the file, with a period inserted after
+the part that indicates the undo log number.
+</para>
+
+<para>
+Each undo log is created in a particular tablespace and stores data for a
+particular persistence level.
+Undo logs are global in the sense that they don't belong to any particular
+database and may contain undo data from relations in any database.
+Undo files backing undo logs in the default tablespace are stored under
+<varname>PGDATA</varname><filename>/base/undo</filename>, and for other
+tablespaces under <filename>undo</filename> in the appropriate tablespace
+directory.  The system view <xref linkend="pg-stat-undo-logs-view"/> can be
+used to see the cluster's current list of undo logs along with their
+tablespaces and persistence levels.
+</para>
+
+<para>
+Just as relations can have one of the three persistence levels permanent,
+unlogged or temporary, the undo data that is generated by modifying them must
+be stored in an undo log of the same persistence level.  This enables the
+undo data to be discarded at appropriate times along with the relations that
+reference it.
+</para>
+
+<para>
+Undo log files contain standard page headers as described in the next section,
+but the format of the rest of the page is determined by the undo-aware
+access method that reads and writes it.
+</para>
+
+</sect1>
+
 <sect1 id="storage-page-layout">
 
 <title>Database Page Layout</title>
diff --git a/src/backend/access/Makefile b/src/backend/access/Makefile
index bf6d3fa..42f1bee 100644
--- a/src/backend/access/Makefile
+++ b/src/backend/access/Makefile
@@ -9,6 +9,6 @@ top_builddir = ../../..
 include $(top_builddir)/src/Makefile.global
 
 SUBDIRS	    = brin common gin gist hash heap index nbtree rmgrdesc spgist \
-			  table tablesample transam undo
+			  table tablesample transam undo zheap
 
 include $(top_srcdir)/src/backend/common.mk
diff --git a/src/backend/access/common/heaptuple.c b/src/backend/access/common/heaptuple.c
index a48a6cd..64531a1 100644
--- a/src/backend/access/common/heaptuple.c
+++ b/src/backend/access/common/heaptuple.c
@@ -64,14 +64,6 @@
 #include "utils/expandeddatum.h"
 
 
-/* Does att's datatype allow packing into the 1-byte-header varlena format? */
-#define ATT_IS_PACKABLE(att) \
-	((att)->attlen == -1 && (att)->attstorage != 'p')
-/* Use this if it's already known varlena */
-#define VARLENA_ATT_IS_PACKABLE(att) \
-	((att)->attstorage != 'p')
-
-
 /* ----------------------------------------------------------------
  *						misc support routines
  * ----------------------------------------------------------------
diff --git a/src/backend/access/common/tupconvert.c b/src/backend/access/common/tupconvert.c
index 8cda164..281e390 100644
--- a/src/backend/access/common/tupconvert.c
+++ b/src/backend/access/common/tupconvert.c
@@ -21,6 +21,7 @@
 #include "access/htup_details.h"
 #include "access/tupconvert.h"
 #include "executor/tuptable.h"
+#include "access/zheap.h"
 #include "utils/builtins.h"
 
 
diff --git a/src/backend/access/heap/heapam.c b/src/backend/access/heap/heapam.c
index d768b9b..00b4c5c 100644
--- a/src/backend/access/heap/heapam.c
+++ b/src/backend/access/heap/heapam.c
@@ -52,6 +52,7 @@
 #include "access/xlogutils.h"
 #include "catalog/catalog.h"
 #include "miscadmin.h"
+#include "nodes/lockoptions.h"
 #include "pgstat.h"
 #include "port/atomics.h"
 #include "storage/bufmgr.h"
@@ -79,9 +80,6 @@ static XLogRecPtr log_heap_update(Relation reln, Buffer oldbuf,
 static Bitmapset *HeapDetermineModifiedColumns(Relation relation,
 											   Bitmapset *interesting_cols,
 											   HeapTuple oldtup, HeapTuple newtup);
-static bool heap_acquire_tuplock(Relation relation, ItemPointer tid,
-								 LockTupleMode mode, LockWaitPolicy wait_policy,
-								 bool *have_tuple_lock);
 static void compute_new_xmax_infomask(TransactionId xmax, uint16 old_infomask,
 									  uint16 old_infomask2, TransactionId add_to_xmax,
 									  LockTupleMode mode, bool is_update,
@@ -116,36 +114,8 @@ static HeapTuple ExtractReplicaIdentity(Relation rel, HeapTuple tup, bool key_mo
  * Don't look at lockstatus/updstatus directly!  Use get_mxact_status_for_lock
  * instead.
  */
-static const struct
-{
-	LOCKMODE	hwlock;
-	int			lockstatus;
-	int			updstatus;
-}
 
-			tupleLockExtraInfo[MaxLockTupleMode + 1] =
-{
-	{							/* LockTupleKeyShare */
-		AccessShareLock,
-		MultiXactStatusForKeyShare,
-		-1						/* KeyShare does not allow updating tuples */
-	},
-	{							/* LockTupleShare */
-		RowShareLock,
-		MultiXactStatusForShare,
-		-1						/* Share does not allow updating tuples */
-	},
-	{							/* LockTupleNoKeyExclusive */
-		ExclusiveLock,
-		MultiXactStatusForNoKeyUpdate,
-		MultiXactStatusNoKeyUpdate
-	},
-	{							/* LockTupleExclusive */
-		AccessExclusiveLock,
-		MultiXactStatusForUpdate,
-		MultiXactStatusUpdate
-	}
-};
+extern const struct LockExtraInfo tupleLockExtraInfo[MaxLockTupleMode + 1];
 
 /* Get the LOCKMODE for a given MultiXactStatus */
 #define LOCKMODE_from_mxstatus(status) \
@@ -158,8 +128,6 @@ static const struct
  */
 #define LockTupleTuplock(rel, tup, mode) \
 	LockTuple((rel), (tup), tupleLockExtraInfo[mode].hwlock)
-#define UnlockTupleTuplock(rel, tup, mode) \
-	UnlockTuple((rel), (tup), tupleLockExtraInfo[mode].hwlock)
 #define ConditionalLockTupleTuplock(rel, tup, mode) \
 	ConditionalLockTuple((rel), (tup), tupleLockExtraInfo[mode].hwlock)
 
@@ -1477,9 +1445,10 @@ heap_fetch(Relation relation,
 	valid = HeapTupleSatisfiesVisibility(tuple, snapshot, buffer);
 
 	if (valid)
-		PredicateLockTuple(relation, tuple, snapshot);
+		PredicateLockTid(relation, &(tuple->t_self), snapshot,
+						 HeapTupleHeaderGetXmin(tuple->t_data));
 
-	CheckForSerializableConflictOut(valid, relation, tuple, buffer, snapshot);
+	CheckForSerializableConflictOut(valid, relation, (void *) tuple, buffer, snapshot);
 
 	LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
 
@@ -1621,7 +1590,8 @@ heap_hot_search_buffer(ItemPointer tid, Relation relation, Buffer buffer,
 			if (valid)
 			{
 				ItemPointerSetOffsetNumber(tid, offnum);
-				PredicateLockTuple(relation, heapTuple, snapshot);
+				PredicateLockTid(relation, &(heapTuple)->t_self, snapshot,
+								 HeapTupleHeaderGetXmin(heapTuple->t_data));
 				if (all_dead)
 					*all_dead = false;
 				return true;
@@ -2669,7 +2639,7 @@ l1:
 	 * being visible to the scan (i.e., an exclusive buffer content lock is
 	 * continuously held from this point until the tuple delete is visible).
 	 */
-	CheckForSerializableConflictIn(relation, &tp, buffer);
+	CheckForSerializableConflictIn(relation, &(tp.t_self), buffer);
 
 	/* replace cid with a combo cid if necessary */
 	HeapTupleHeaderAdjustCmax(tp.t_data, &cid, &iscombo);
@@ -3584,7 +3554,7 @@ l2:
 	 * will include checking the relation level, there is no benefit to a
 	 * separate check for the new tuple.
 	 */
-	CheckForSerializableConflictIn(relation, &oldtup, buffer);
+	CheckForSerializableConflictIn(relation, &(oldtup.t_self), buffer);
 
 	/*
 	 * At this point newbuf and buffer are both pinned and locked, and newbuf
@@ -4664,7 +4634,7 @@ out_unlocked:
  * Returns false if it was unable to obtain the lock; this can only happen if
  * wait_policy is Skip.
  */
-static bool
+bool
 heap_acquire_tuplock(Relation relation, ItemPointer tid, LockTupleMode mode,
 					 LockWaitPolicy wait_policy, bool *have_tuple_lock)
 {
diff --git a/src/backend/access/heap/heapam_handler.c b/src/backend/access/heap/heapam_handler.c
index 09bc6fe..3e79676 100644
--- a/src/backend/access/heap/heapam_handler.c
+++ b/src/backend/access/heap/heapam_handler.c
@@ -2164,7 +2164,8 @@ heapam_scan_bitmap_next_block(TableScanDesc scan,
 			if (valid)
 			{
 				hscan->rs_vistuples[ntup++] = offnum;
-				PredicateLockTuple(scan->rs_rd, &loctup, snapshot);
+				PredicateLockTid(scan->rs_rd, &loctup.t_self, snapshot,
+								 HeapTupleHeaderGetXmin(loctup.t_data));
 			}
 			CheckForSerializableConflictOut(valid, scan->rs_rd, &loctup,
 											buffer, snapshot);
diff --git a/src/backend/access/heap/heapam_visibility.c b/src/backend/access/heap/heapam_visibility.c
index 537e681..1c5b07e 100644
--- a/src/backend/access/heap/heapam_visibility.c
+++ b/src/backend/access/heap/heapam_visibility.c
@@ -751,6 +751,7 @@ HeapTupleSatisfiesDirty(HeapTuple htup, Snapshot snapshot,
 	Assert(htup->t_tableOid != InvalidOid);
 
 	snapshot->xmin = snapshot->xmax = InvalidTransactionId;
+	snapshot->subxid = InvalidSubTransactionId;
 	snapshot->speculativeToken = 0;
 
 	if (!HeapTupleHeaderXminCommitted(tuple))
@@ -1716,3 +1717,74 @@ HeapTupleSatisfiesVisibility(HeapTuple tup, Snapshot snapshot, Buffer buffer)
 
 	return false;				/* keep compiler quiet */
 }
+
+/*
+ * This is a helper function for CheckForSerializableConflictOut.
+ *
+ * Check to see whether the tuple has been written to by a concurrent
+ * transaction, either to create it not visible to us, or to delete it
+ * while it is visible to us.  The "visible" bool indicates whether the
+ * tuple is visible to us, while HeapTupleSatisfiesVacuum checks what else
+ * is going on with it.  The caller should have a share lock on the buffer.
+ */
+bool
+HeapTupleHasSerializableConflictOut(bool visible, HeapTuple tuple, Buffer buffer,
+									TransactionId *xid)
+{
+	HTSV_Result htsvResult;
+
+	htsvResult = HeapTupleSatisfiesVacuum(tuple, TransactionXmin, buffer);
+	switch (htsvResult)
+	{
+		case HEAPTUPLE_LIVE:
+			if (visible)
+				return false;
+			*xid = HeapTupleHeaderGetXmin(tuple->t_data);
+			break;
+		case HEAPTUPLE_RECENTLY_DEAD:
+			if (!visible)
+				return false;
+			*xid = HeapTupleHeaderGetUpdateXid(tuple->t_data);
+			break;
+		case HEAPTUPLE_DELETE_IN_PROGRESS:
+			*xid = HeapTupleHeaderGetUpdateXid(tuple->t_data);
+			break;
+		case HEAPTUPLE_INSERT_IN_PROGRESS:
+			*xid = HeapTupleHeaderGetXmin(tuple->t_data);
+			break;
+		case HEAPTUPLE_DEAD:
+			return false;
+		default:
+
+			/*
+			 * The only way to get to this default clause is if a new value is
+			 * added to the enum type without adding it to this switch
+			 * statement.  That's a bug, so elog.
+			 */
+			elog(ERROR, "unrecognized return value from HeapTupleSatisfiesVacuum: %u", htsvResult);
+
+			/*
+			 * In spite of having all enum values covered and calling elog on
+			 * this default, some compilers think this is a code path which
+			 * allows xid to be used below without initialization. Silence
+			 * that warning.
+			 */
+			*xid = InvalidTransactionId;
+	}
+	Assert(TransactionIdIsValid(*xid));
+	Assert(TransactionIdFollowsOrEquals(*xid, TransactionXmin));
+
+	/*
+	 * Find top level xid.  Bail out if xid is too early to be a conflict, or
+	 * if it's our own xid.
+	 */
+	if (TransactionIdEquals(*xid, GetTopTransactionIdIfAny()))
+		return false;
+	*xid = SubTransGetTopmostTransaction(*xid);
+	if (TransactionIdPrecedes(*xid, TransactionXmin))
+		return false;
+	if (TransactionIdEquals(*xid, GetTopTransactionIdIfAny()))
+		return false;
+
+	return true;
+}
diff --git a/src/backend/access/heap/hio.c b/src/backend/access/heap/hio.c
index d41d318..a9d2dda 100644
--- a/src/backend/access/heap/hio.c
+++ b/src/backend/access/heap/hio.c
@@ -19,6 +19,8 @@
 #include "access/hio.h"
 #include "access/htup_details.h"
 #include "access/visibilitymap.h"
+#include "access/zheap.h"
+#include "access/zhtup.h"
 #include "storage/bufmgr.h"
 #include "storage/freespace.h"
 #include "storage/lmgr.h"
@@ -76,7 +78,7 @@ RelationPutHeapTuple(Relation relation,
 /*
  * Read in a buffer in mode, using bulk-insert strategy if bistate isn't NULL.
  */
-static Buffer
+Buffer
 ReadBufferBI(Relation relation, BlockNumber targetBlock,
 			 ReadBufferMode mode, BulkInsertState bistate)
 {
@@ -126,7 +128,7 @@ ReadBufferBI(Relation relation, BlockNumber targetBlock,
  * must not be InvalidBuffer.  If both buffers are specified, block1 must
  * be less than block2.
  */
-static void
+void
 GetVisibilityMapPins(Relation relation, Buffer buffer1, Buffer buffer2,
 					 BlockNumber block1, BlockNumber block2,
 					 Buffer *vmbuffer1, Buffer *vmbuffer2)
@@ -182,7 +184,7 @@ GetVisibilityMapPins(Relation relation, Buffer buffer1, Buffer buffer2,
  * amount which ramps up as the degree of contention ramps up, but limiting
  * the result to some sane overall value.
  */
-static void
+void
 RelationAddExtraBlocks(Relation relation, BulkInsertState bistate)
 {
 	BlockNumber blockNum,
diff --git a/src/backend/access/heap/tuptoaster.c b/src/backend/access/heap/tuptoaster.c
index 55d6e91..33d7e2e 100644
--- a/src/backend/access/heap/tuptoaster.c
+++ b/src/backend/access/heap/tuptoaster.c
@@ -69,21 +69,11 @@ typedef struct toast_compress_header
 static void toast_delete_datum(Relation rel, Datum value, bool is_speculative);
 static Datum toast_save_datum(Relation rel, Datum value,
 							  struct varlena *oldexternal, int options);
-static bool toastrel_valueid_exists(Relation toastrel, Oid valueid);
-static bool toastid_valueid_exists(Oid toastrelid, Oid valueid);
 static struct varlena *toast_fetch_datum(struct varlena *attr);
 static struct varlena *toast_fetch_datum_slice(struct varlena *attr,
 											   int32 sliceoffset, int32 length);
 static struct varlena *toast_decompress_datum(struct varlena *attr);
 static struct varlena *toast_decompress_datum_slice(struct varlena *attr, int32 slicelength);
-static int	toast_open_indexes(Relation toastrel,
-							   LOCKMODE lock,
-							   Relation **toastidxs,
-							   int *num_indexes);
-static void toast_close_indexes(Relation *toastidxs, int num_indexes,
-								LOCKMODE lock);
-static void init_toast_snapshot(Snapshot toast_snapshot);
-
 
 /* ----------
  * heap_tuple_fetch_attr -
@@ -1790,7 +1780,7 @@ toast_delete_datum(Relation rel, Datum value, bool is_speculative)
  *	toast rows with that ID; see notes for GetNewOidWithIndex().
  * ----------
  */
-static bool
+bool
 toastrel_valueid_exists(Relation toastrel, Oid valueid)
 {
 	bool		result = false;
@@ -1838,7 +1828,7 @@ toastrel_valueid_exists(Relation toastrel, Oid valueid)
  *	As above, but work from toast rel's OID not an open relation
  * ----------
  */
-static bool
+bool
 toastid_valueid_exists(Oid toastrelid, Oid valueid)
 {
 	bool		result;
@@ -2321,7 +2311,7 @@ toast_decompress_datum_slice(struct varlena *attr, int32 slicelength)
  *	relation in this array. It is the responsibility of the caller of this
  *	function to close the indexes as well as free them.
  */
-static int
+int
 toast_open_indexes(Relation toastrel,
 				   LOCKMODE lock,
 				   Relation **toastidxs,
@@ -2380,7 +2370,7 @@ toast_open_indexes(Relation toastrel,
  *	Close an array of indexes for a toast relation and free it. This should
  *	be called for a set of indexes opened previously with toast_open_indexes.
  */
-static void
+void
 toast_close_indexes(Relation *toastidxs, int num_indexes, LOCKMODE lock)
 {
 	int			i;
@@ -2399,7 +2389,7 @@ toast_close_indexes(Relation *toastidxs, int num_indexes, LOCKMODE lock)
  *	just use the oldest one.  This is safe: at worst, we will get a "snapshot
  *	too old" error that might have been avoided otherwise.
  */
-static void
+void
 init_toast_snapshot(Snapshot toast_snapshot)
 {
 	Snapshot	snapshot = GetOldestSnapshot();
diff --git a/src/backend/access/heap/vacuumlazy.c b/src/backend/access/heap/vacuumlazy.c
index a3c4a1d..c0f9d62 100644
--- a/src/backend/access/heap/vacuumlazy.c
+++ b/src/backend/access/heap/vacuumlazy.c
@@ -42,6 +42,7 @@
 #include "access/htup_details.h"
 #include "access/multixact.h"
 #include "access/transam.h"
+#include "access/vacuumblk.h"
 #include "access/visibilitymap.h"
 #include "access/xlog.h"
 #include "catalog/storage.h"
@@ -62,36 +63,6 @@
 
 
 /*
- * Space/time tradeoff parameters: do these need to be user-tunable?
- *
- * To consider truncating the relation, we want there to be at least
- * REL_TRUNCATE_MINIMUM or (relsize / REL_TRUNCATE_FRACTION) (whichever
- * is less) potentially-freeable pages.
- */
-#define REL_TRUNCATE_MINIMUM	1000
-#define REL_TRUNCATE_FRACTION	16
-
-/*
- * Timing parameters for truncate locking heuristics.
- *
- * These were not exposed as user tunable GUC values because it didn't seem
- * that the potential for improvement was great enough to merit the cost of
- * supporting them.
- */
-#define VACUUM_TRUNCATE_LOCK_CHECK_INTERVAL		20	/* ms */
-#define VACUUM_TRUNCATE_LOCK_WAIT_INTERVAL		50	/* ms */
-#define VACUUM_TRUNCATE_LOCK_TIMEOUT			5000	/* ms */
-
-/*
- * When a table has no indexes, vacuum the FSM after every 8GB, approximately
- * (it won't be exact because we only vacuum FSM after processing a heap page
- * that has some removable tuples).  When there are indexes, this is ignored,
- * and we vacuum FSM after each index/heap cleaning pass.
- */
-#define VACUUM_FSM_EVERY_PAGES \
-	((BlockNumber) (((uint64) 8 * 1024 * 1024 * 1024) / BLCKSZ))
-
-/*
  * Guesstimation of number of dead tuples per page.  This is used to
  * provide an upper limit to memory allocated when vacuuming small
  * tables.
@@ -104,41 +75,6 @@
  */
 #define SKIP_PAGES_THRESHOLD	((BlockNumber) 32)
 
-/*
- * Size of the prefetch window for lazy vacuum backwards truncation scan.
- * Needs to be a power of 2.
- */
-#define PREFETCH_SIZE			((BlockNumber) 32)
-
-typedef struct LVRelStats
-{
-	/* useindex = true means two-pass strategy; false means one-pass */
-	bool		useindex;
-	/* Overall statistics about rel */
-	BlockNumber old_rel_pages;	/* previous value of pg_class.relpages */
-	BlockNumber rel_pages;		/* total number of pages */
-	BlockNumber scanned_pages;	/* number of pages we examined */
-	BlockNumber pinskipped_pages;	/* # of pages we skipped due to a pin */
-	BlockNumber frozenskipped_pages;	/* # of frozen pages we skipped */
-	BlockNumber tupcount_pages; /* pages whose tuples we counted */
-	double		old_live_tuples;	/* previous value of pg_class.reltuples */
-	double		new_rel_tuples; /* new estimated total # of tuples */
-	double		new_live_tuples;	/* new estimated total # of live tuples */
-	double		new_dead_tuples;	/* new estimated total # of dead tuples */
-	BlockNumber pages_removed;
-	double		tuples_deleted;
-	BlockNumber nonempty_pages; /* actually, last nonempty page + 1 */
-	/* List of TIDs of tuples we intend to delete */
-	/* NB: this list is ordered by TID address */
-	int			num_dead_tuples;	/* current # of entries */
-	int			max_dead_tuples;	/* # slots allocated in array */
-	ItemPointer dead_tuples;	/* array of ItemPointerData */
-	int			num_index_scans;
-	TransactionId latestRemovedXid;
-	bool		lock_waiter_detected;
-} LVRelStats;
-
-
 /* A few variables that don't seem worth passing around as parameters */
 static int	elevel = -1;
 
@@ -155,24 +91,9 @@ static void lazy_scan_heap(Relation onerel, VacuumParams *params,
 						   bool aggressive);
 static void lazy_vacuum_heap(Relation onerel, LVRelStats *vacrelstats);
 static bool lazy_check_needs_freeze(Buffer buf, bool *hastup);
-static void lazy_vacuum_index(Relation indrel,
-							  IndexBulkDeleteResult **stats,
-							  LVRelStats *vacrelstats);
-static void lazy_cleanup_index(Relation indrel,
-							   IndexBulkDeleteResult *stats,
-							   LVRelStats *vacrelstats);
 static int	lazy_vacuum_page(Relation onerel, BlockNumber blkno, Buffer buffer,
 							 int tupindex, LVRelStats *vacrelstats, Buffer *vmbuffer);
-static bool should_attempt_truncation(VacuumParams *params,
-									  LVRelStats *vacrelstats);
-static void lazy_truncate_heap(Relation onerel, LVRelStats *vacrelstats);
-static BlockNumber count_nondeletable_pages(Relation onerel,
-											LVRelStats *vacrelstats);
 static void lazy_space_alloc(LVRelStats *vacrelstats, BlockNumber relblocks);
-static void lazy_record_dead_tuple(LVRelStats *vacrelstats,
-								   ItemPointer itemptr);
-static bool lazy_tid_reaped(ItemPointer itemptr, void *state);
-static int	vac_cmp_itemptr(const void *left, const void *right);
 static bool heap_page_is_all_visible(Relation rel, Buffer buf,
 									 TransactionId *visibility_cutoff_xid, bool *all_frozen);
 
@@ -311,7 +232,7 @@ heap_vacuum_rel(Relation onerel, VacuumParams *params,
 	 * Optionally truncate the relation.
 	 */
 	if (should_attempt_truncation(params, vacrelstats))
-		lazy_truncate_heap(onerel, vacrelstats);
+		lazy_truncate_heap(onerel, vacrelstats, vac_strategy, elevel);
 
 	/* Report that we are now doing final cleanup */
 	pgstat_progress_update_param(PROGRESS_VACUUM_PHASE,
@@ -769,7 +690,9 @@ lazy_scan_heap(Relation onerel, VacuumParams *params, LVRelStats *vacrelstats,
 			for (i = 0; i < nindexes; i++)
 				lazy_vacuum_index(Irel[i],
 								  &indstats[i],
-								  vacrelstats);
+								  vacrelstats,
+								  vac_strategy,
+								  elevel);
 
 			/*
 			 * Report that we are now vacuuming the heap.  We also increase
@@ -1437,7 +1360,9 @@ lazy_scan_heap(Relation onerel, VacuumParams *params, LVRelStats *vacrelstats,
 		for (i = 0; i < nindexes; i++)
 			lazy_vacuum_index(Irel[i],
 							  &indstats[i],
-							  vacrelstats);
+							  vacrelstats,
+							  vac_strategy,
+							  elevel);
 
 		/* Report that we are now vacuuming the heap */
 		hvp_val[0] = PROGRESS_VACUUM_PHASE_VACUUM_HEAP;
@@ -1467,7 +1392,8 @@ lazy_scan_heap(Relation onerel, VacuumParams *params, LVRelStats *vacrelstats,
 	if (vacrelstats->useindex)
 	{
 		for (i = 0; i < nindexes; i++)
-			lazy_cleanup_index(Irel[i], indstats[i], vacrelstats);
+			lazy_cleanup_index(Irel[i], indstats[i], vacrelstats, vac_strategy,
+							   elevel);
 	}
 
 	/* If no indexes, make log report that lazy_vacuum_heap would've made */
@@ -1731,408 +1657,6 @@ lazy_check_needs_freeze(Buffer buf, bool *hastup)
 	return false;
 }
 
-
-/*
- *	lazy_vacuum_index() -- vacuum one index relation.
- *
- *		Delete all the index entries pointing to tuples listed in
- *		vacrelstats->dead_tuples, and update running statistics.
- */
-static void
-lazy_vacuum_index(Relation indrel,
-				  IndexBulkDeleteResult **stats,
-				  LVRelStats *vacrelstats)
-{
-	IndexVacuumInfo ivinfo;
-	PGRUsage	ru0;
-
-	pg_rusage_init(&ru0);
-
-	ivinfo.index = indrel;
-	ivinfo.analyze_only = false;
-	ivinfo.report_progress = false;
-	ivinfo.estimated_count = true;
-	ivinfo.message_level = elevel;
-	/* We can only provide an approximate value of num_heap_tuples here */
-	ivinfo.num_heap_tuples = vacrelstats->old_live_tuples;
-	ivinfo.strategy = vac_strategy;
-
-	/* Do bulk deletion */
-	*stats = index_bulk_delete(&ivinfo, *stats,
-							   lazy_tid_reaped, (void *) vacrelstats);
-
-	ereport(elevel,
-			(errmsg("scanned index \"%s\" to remove %d row versions",
-					RelationGetRelationName(indrel),
-					vacrelstats->num_dead_tuples),
-			 errdetail_internal("%s", pg_rusage_show(&ru0))));
-}
-
-/*
- *	lazy_cleanup_index() -- do post-vacuum cleanup for one index relation.
- */
-static void
-lazy_cleanup_index(Relation indrel,
-				   IndexBulkDeleteResult *stats,
-				   LVRelStats *vacrelstats)
-{
-	IndexVacuumInfo ivinfo;
-	PGRUsage	ru0;
-
-	pg_rusage_init(&ru0);
-
-	ivinfo.index = indrel;
-	ivinfo.analyze_only = false;
-	ivinfo.report_progress = false;
-	ivinfo.estimated_count = (vacrelstats->tupcount_pages < vacrelstats->rel_pages);
-	ivinfo.message_level = elevel;
-
-	/*
-	 * Now we can provide a better estimate of total number of surviving
-	 * tuples (we assume indexes are more interested in that than in the
-	 * number of nominally live tuples).
-	 */
-	ivinfo.num_heap_tuples = vacrelstats->new_rel_tuples;
-	ivinfo.strategy = vac_strategy;
-
-	stats = index_vacuum_cleanup(&ivinfo, stats);
-
-	if (!stats)
-		return;
-
-	/*
-	 * Now update statistics in pg_class, but only if the index says the count
-	 * is accurate.
-	 */
-	if (!stats->estimated_count)
-		vac_update_relstats(indrel,
-							stats->num_pages,
-							stats->num_index_tuples,
-							0,
-							false,
-							InvalidTransactionId,
-							InvalidMultiXactId,
-							false);
-
-	ereport(elevel,
-			(errmsg("index \"%s\" now contains %.0f row versions in %u pages",
-					RelationGetRelationName(indrel),
-					stats->num_index_tuples,
-					stats->num_pages),
-			 errdetail("%.0f index row versions were removed.\n"
-					   "%u index pages have been deleted, %u are currently reusable.\n"
-					   "%s.",
-					   stats->tuples_removed,
-					   stats->pages_deleted, stats->pages_free,
-					   pg_rusage_show(&ru0))));
-
-	pfree(stats);
-}
-
-/*
- * should_attempt_truncation - should we attempt to truncate the heap?
- *
- * Don't even think about it unless we have a shot at releasing a goodly
- * number of pages.  Otherwise, the time taken isn't worth it.
- *
- * Also don't attempt it if we are doing early pruning/vacuuming, because a
- * scan which cannot find a truncated heap page cannot determine that the
- * snapshot is too old to read that page.  We might be able to get away with
- * truncating all except one of the pages, setting its LSN to (at least) the
- * maximum of the truncated range if we also treated an index leaf tuple
- * pointing to a missing heap page as something to trigger the "snapshot too
- * old" error, but that seems fragile and seems like it deserves its own patch
- * if we consider it.
- *
- * This is split out so that we can test whether truncation is going to be
- * called for before we actually do it.  If you change the logic here, be
- * careful to depend only on fields that lazy_scan_heap updates on-the-fly.
- */
-static bool
-should_attempt_truncation(VacuumParams *params, LVRelStats *vacrelstats)
-{
-	BlockNumber possibly_freeable;
-
-	if (params->truncate == VACOPT_TERNARY_DISABLED)
-		return false;
-
-	possibly_freeable = vacrelstats->rel_pages - vacrelstats->nonempty_pages;
-	if (possibly_freeable > 0 &&
-		(possibly_freeable >= REL_TRUNCATE_MINIMUM ||
-		 possibly_freeable >= vacrelstats->rel_pages / REL_TRUNCATE_FRACTION) &&
-		old_snapshot_threshold < 0)
-		return true;
-	else
-		return false;
-}
-
-/*
- * lazy_truncate_heap - try to truncate off any empty pages at the end
- */
-static void
-lazy_truncate_heap(Relation onerel, LVRelStats *vacrelstats)
-{
-	BlockNumber old_rel_pages = vacrelstats->rel_pages;
-	BlockNumber new_rel_pages;
-	PGRUsage	ru0;
-	int			lock_retry;
-
-	pg_rusage_init(&ru0);
-
-	/* Report that we are now truncating */
-	pgstat_progress_update_param(PROGRESS_VACUUM_PHASE,
-								 PROGRESS_VACUUM_PHASE_TRUNCATE);
-
-	/*
-	 * Loop until no more truncating can be done.
-	 */
-	do
-	{
-		/*
-		 * We need full exclusive lock on the relation in order to do
-		 * truncation. If we can't get it, give up rather than waiting --- we
-		 * don't want to block other backends, and we don't want to deadlock
-		 * (which is quite possible considering we already hold a lower-grade
-		 * lock).
-		 */
-		vacrelstats->lock_waiter_detected = false;
-		lock_retry = 0;
-		while (true)
-		{
-			if (ConditionalLockRelation(onerel, AccessExclusiveLock))
-				break;
-
-			/*
-			 * Check for interrupts while trying to (re-)acquire the exclusive
-			 * lock.
-			 */
-			CHECK_FOR_INTERRUPTS();
-
-			if (++lock_retry > (VACUUM_TRUNCATE_LOCK_TIMEOUT /
-								VACUUM_TRUNCATE_LOCK_WAIT_INTERVAL))
-			{
-				/*
-				 * We failed to establish the lock in the specified number of
-				 * retries. This means we give up truncating.
-				 */
-				vacrelstats->lock_waiter_detected = true;
-				ereport(elevel,
-						(errmsg("\"%s\": stopping truncate due to conflicting lock request",
-								RelationGetRelationName(onerel))));
-				return;
-			}
-
-			pg_usleep(VACUUM_TRUNCATE_LOCK_WAIT_INTERVAL * 1000L);
-		}
-
-		/*
-		 * Now that we have exclusive lock, look to see if the rel has grown
-		 * whilst we were vacuuming with non-exclusive lock.  If so, give up;
-		 * the newly added pages presumably contain non-deletable tuples.
-		 */
-		new_rel_pages = RelationGetNumberOfBlocks(onerel);
-		if (new_rel_pages != old_rel_pages)
-		{
-			/*
-			 * Note: we intentionally don't update vacrelstats->rel_pages with
-			 * the new rel size here.  If we did, it would amount to assuming
-			 * that the new pages are empty, which is unlikely. Leaving the
-			 * numbers alone amounts to assuming that the new pages have the
-			 * same tuple density as existing ones, which is less unlikely.
-			 */
-			UnlockRelation(onerel, AccessExclusiveLock);
-			return;
-		}
-
-		/*
-		 * Scan backwards from the end to verify that the end pages actually
-		 * contain no tuples.  This is *necessary*, not optional, because
-		 * other backends could have added tuples to these pages whilst we
-		 * were vacuuming.
-		 */
-		new_rel_pages = count_nondeletable_pages(onerel, vacrelstats);
-
-		if (new_rel_pages >= old_rel_pages)
-		{
-			/* can't do anything after all */
-			UnlockRelation(onerel, AccessExclusiveLock);
-			return;
-		}
-
-		/*
-		 * Okay to truncate.
-		 */
-		RelationTruncate(onerel, new_rel_pages);
-
-		/*
-		 * We can release the exclusive lock as soon as we have truncated.
-		 * Other backends can't safely access the relation until they have
-		 * processed the smgr invalidation that smgrtruncate sent out ... but
-		 * that should happen as part of standard invalidation processing once
-		 * they acquire lock on the relation.
-		 */
-		UnlockRelation(onerel, AccessExclusiveLock);
-
-		/*
-		 * Update statistics.  Here, it *is* correct to adjust rel_pages
-		 * without also touching reltuples, since the tuple count wasn't
-		 * changed by the truncation.
-		 */
-		vacrelstats->pages_removed += old_rel_pages - new_rel_pages;
-		vacrelstats->rel_pages = new_rel_pages;
-
-		ereport(elevel,
-				(errmsg("\"%s\": truncated %u to %u pages",
-						RelationGetRelationName(onerel),
-						old_rel_pages, new_rel_pages),
-				 errdetail_internal("%s",
-									pg_rusage_show(&ru0))));
-		old_rel_pages = new_rel_pages;
-	} while (new_rel_pages > vacrelstats->nonempty_pages &&
-			 vacrelstats->lock_waiter_detected);
-}
-
-/*
- * Rescan end pages to verify that they are (still) empty of tuples.
- *
- * Returns number of nondeletable pages (last nonempty page + 1).
- */
-static BlockNumber
-count_nondeletable_pages(Relation onerel, LVRelStats *vacrelstats)
-{
-	BlockNumber blkno;
-	BlockNumber prefetchedUntil;
-	instr_time	starttime;
-
-	/* Initialize the starttime if we check for conflicting lock requests */
-	INSTR_TIME_SET_CURRENT(starttime);
-
-	/*
-	 * Start checking blocks at what we believe relation end to be and move
-	 * backwards.  (Strange coding of loop control is needed because blkno is
-	 * unsigned.)  To make the scan faster, we prefetch a few blocks at a time
-	 * in forward direction, so that OS-level readahead can kick in.
-	 */
-	blkno = vacrelstats->rel_pages;
-	StaticAssertStmt((PREFETCH_SIZE & (PREFETCH_SIZE - 1)) == 0,
-					 "prefetch size must be power of 2");
-	prefetchedUntil = InvalidBlockNumber;
-	while (blkno > vacrelstats->nonempty_pages)
-	{
-		Buffer		buf;
-		Page		page;
-		OffsetNumber offnum,
-					maxoff;
-		bool		hastup;
-
-		/*
-		 * Check if another process requests a lock on our relation. We are
-		 * holding an AccessExclusiveLock here, so they will be waiting. We
-		 * only do this once per VACUUM_TRUNCATE_LOCK_CHECK_INTERVAL, and we
-		 * only check if that interval has elapsed once every 32 blocks to
-		 * keep the number of system calls and actual shared lock table
-		 * lookups to a minimum.
-		 */
-		if ((blkno % 32) == 0)
-		{
-			instr_time	currenttime;
-			instr_time	elapsed;
-
-			INSTR_TIME_SET_CURRENT(currenttime);
-			elapsed = currenttime;
-			INSTR_TIME_SUBTRACT(elapsed, starttime);
-			if ((INSTR_TIME_GET_MICROSEC(elapsed) / 1000)
-				>= VACUUM_TRUNCATE_LOCK_CHECK_INTERVAL)
-			{
-				if (LockHasWaitersRelation(onerel, AccessExclusiveLock))
-				{
-					ereport(elevel,
-							(errmsg("\"%s\": suspending truncate due to conflicting lock request",
-									RelationGetRelationName(onerel))));
-
-					vacrelstats->lock_waiter_detected = true;
-					return blkno;
-				}
-				starttime = currenttime;
-			}
-		}
-
-		/*
-		 * We don't insert a vacuum delay point here, because we have an
-		 * exclusive lock on the table which we want to hold for as short a
-		 * time as possible.  We still need to check for interrupts however.
-		 */
-		CHECK_FOR_INTERRUPTS();
-
-		blkno--;
-
-		/* If we haven't prefetched this lot yet, do so now. */
-		if (prefetchedUntil > blkno)
-		{
-			BlockNumber prefetchStart;
-			BlockNumber pblkno;
-
-			prefetchStart = blkno & ~(PREFETCH_SIZE - 1);
-			for (pblkno = prefetchStart; pblkno <= blkno; pblkno++)
-			{
-				PrefetchBuffer(onerel, MAIN_FORKNUM, pblkno);
-				CHECK_FOR_INTERRUPTS();
-			}
-			prefetchedUntil = prefetchStart;
-		}
-
-		buf = ReadBufferExtended(onerel, MAIN_FORKNUM, blkno,
-								 RBM_NORMAL, vac_strategy);
-
-		/* In this phase we only need shared access to the buffer */
-		LockBuffer(buf, BUFFER_LOCK_SHARE);
-
-		page = BufferGetPage(buf);
-
-		if (PageIsNew(page) || PageIsEmpty(page))
-		{
-			UnlockReleaseBuffer(buf);
-			continue;
-		}
-
-		hastup = false;
-		maxoff = PageGetMaxOffsetNumber(page);
-		for (offnum = FirstOffsetNumber;
-			 offnum <= maxoff;
-			 offnum = OffsetNumberNext(offnum))
-		{
-			ItemId		itemid;
-
-			itemid = PageGetItemId(page, offnum);
-
-			/*
-			 * Note: any non-unused item should be taken as a reason to keep
-			 * this page.  We formerly thought that DEAD tuples could be
-			 * thrown away, but that's not so, because we'd not have cleaned
-			 * out their index entries.
-			 */
-			if (ItemIdIsUsed(itemid))
-			{
-				hastup = true;
-				break;			/* can stop scanning */
-			}
-		}						/* scan along page */
-
-		UnlockReleaseBuffer(buf);
-
-		/* Done scanning if we found a tuple here */
-		if (hastup)
-			return blkno + 1;
-	}
-
-	/*
-	 * If we fall out of the loop, all the previously-thought-to-be-empty
-	 * pages still are; we need not bother to look at the last known-nonempty
-	 * page.
-	 */
-	return vacrelstats->nonempty_pages;
-}
-
 /*
  * lazy_space_alloc - space allocation decisions for lazy vacuum
  *
@@ -2171,79 +1695,6 @@ lazy_space_alloc(LVRelStats *vacrelstats, BlockNumber relblocks)
 }
 
 /*
- * lazy_record_dead_tuple - remember one deletable tuple
- */
-static void
-lazy_record_dead_tuple(LVRelStats *vacrelstats,
-					   ItemPointer itemptr)
-{
-	/*
-	 * The array shouldn't overflow under normal behavior, but perhaps it
-	 * could if we are given a really small maintenance_work_mem. In that
-	 * case, just forget the last few tuples (we'll get 'em next time).
-	 */
-	if (vacrelstats->num_dead_tuples < vacrelstats->max_dead_tuples)
-	{
-		vacrelstats->dead_tuples[vacrelstats->num_dead_tuples] = *itemptr;
-		vacrelstats->num_dead_tuples++;
-		pgstat_progress_update_param(PROGRESS_VACUUM_NUM_DEAD_TUPLES,
-									 vacrelstats->num_dead_tuples);
-	}
-}
-
-/*
- *	lazy_tid_reaped() -- is a particular tid deletable?
- *
- *		This has the right signature to be an IndexBulkDeleteCallback.
- *
- *		Assumes dead_tuples array is in sorted order.
- */
-static bool
-lazy_tid_reaped(ItemPointer itemptr, void *state)
-{
-	LVRelStats *vacrelstats = (LVRelStats *) state;
-	ItemPointer res;
-
-	res = (ItemPointer) bsearch((void *) itemptr,
-								(void *) vacrelstats->dead_tuples,
-								vacrelstats->num_dead_tuples,
-								sizeof(ItemPointerData),
-								vac_cmp_itemptr);
-
-	return (res != NULL);
-}
-
-/*
- * Comparator routines for use with qsort() and bsearch().
- */
-static int
-vac_cmp_itemptr(const void *left, const void *right)
-{
-	BlockNumber lblk,
-				rblk;
-	OffsetNumber loff,
-				roff;
-
-	lblk = ItemPointerGetBlockNumber((ItemPointer) left);
-	rblk = ItemPointerGetBlockNumber((ItemPointer) right);
-
-	if (lblk < rblk)
-		return -1;
-	if (lblk > rblk)
-		return 1;
-
-	loff = ItemPointerGetOffsetNumber((ItemPointer) left);
-	roff = ItemPointerGetOffsetNumber((ItemPointer) right);
-
-	if (loff < roff)
-		return -1;
-	if (loff > roff)
-		return 1;
-
-	return 0;
-}
-
-/*
  * Check if every tuple in the given page is visible to all current and future
  * transactions. Also return the visibility_cutoff_xid which is the highest
  * xmin amongst the visible tuples.  Set *all_frozen to true if every tuple
diff --git a/src/backend/access/heap/visibilitymap.c b/src/backend/access/heap/visibilitymap.c
index 64dfe06..68bd431 100644
--- a/src/backend/access/heap/visibilitymap.c
+++ b/src/backend/access/heap/visibilitymap.c
@@ -87,6 +87,8 @@
 
 #include "access/heapam_xlog.h"
 #include "access/visibilitymap.h"
+#include "access/zheapam_xlog.h"
+#include "access/zheap.h"
 #include "access/xlog.h"
 #include "miscadmin.h"
 #include "port/pg_bitutils.h"
@@ -254,7 +256,10 @@ visibilitymap_set(Relation rel, BlockNumber heapBlk, Buffer heapBuf,
 #endif
 
 	Assert(InRecovery || XLogRecPtrIsInvalid(recptr));
-	Assert(InRecovery || BufferIsValid(heapBuf));
+
+	/* For zheap we do not set heapBuf's status hence can be invalid */
+	Assert(RelationStorageIsZHeap(rel) ||
+		   (InRecovery || BufferIsValid(heapBuf)));
 	Assert(flags & VISIBILITYMAP_VALID_BITS);
 
 	/* Check that we have the right heap page pinned, if present */
@@ -281,20 +286,33 @@ visibilitymap_set(Relation rel, BlockNumber heapBlk, Buffer heapBuf,
 			if (XLogRecPtrIsInvalid(recptr))
 			{
 				Assert(!InRecovery);
-				recptr = log_heap_visible(rel->rd_node, heapBuf, vmBuf,
-										  cutoff_xid, flags);
-
-				/*
-				 * If data checksums are enabled (or wal_log_hints=on), we
-				 * need to protect the heap page from being torn.
-				 */
-				if (XLogHintBitIsNeeded())
+				if (RelationStorageIsZHeap(rel))
 				{
-					Page		heapPage = BufferGetPage(heapBuf);
+					recptr = log_zheap_visible(rel->rd_node, heapBuf, vmBuf,
+											   cutoff_xid, flags);
 
-					/* caller is expected to set PD_ALL_VISIBLE first */
-					Assert(PageIsAllVisible(heapPage));
-					PageSetLSN(heapPage, recptr);
+					/*
+					 * We do not have a page wise visibility flag in zheap. So
+					 * no need to set LSN on zheap page.
+					 */
+				}
+				else
+				{
+					recptr = log_heap_visible(rel->rd_node, heapBuf, vmBuf,
+											  cutoff_xid, flags);
+
+					/*
+					 * If data checksums are enabled (or wal_log_hints=on), we
+					 * need to protect the heap page from being torn.
+					 */
+					if (XLogHintBitIsNeeded())
+					{
+						Page		heapPage = BufferGetPage(heapBuf);
+
+						/* caller is expected to set PD_ALL_VISIBLE first */
+						Assert(PageIsAllVisible(heapPage));
+						PageSetLSN(heapPage, recptr);
+					}
 				}
 			}
 			PageSetLSN(page, recptr);
diff --git a/src/backend/access/index/genam.c b/src/backend/access/index/genam.c
index 42aaa5b..ae676ac 100644
--- a/src/backend/access/index/genam.c
+++ b/src/backend/access/index/genam.c
@@ -624,6 +624,18 @@ systable_beginscan_ordered(Relation heapRelation,
 }
 
 /*
+ * systable_getnext_ordered_slot --- get next slot in an ordered catalog scan.
+ */
+struct TupleTableSlot *
+systable_getnext_ordered_slot(SysScanDesc sysscan, ScanDirection direction)
+{
+	if (index_getnext_slot(sysscan->iscan, direction, sysscan->slot))
+		return sysscan->slot;
+	else
+		return NULL;
+}
+
+/*
  * systable_getnext_ordered --- get next tuple in an ordered catalog scan
  */
 HeapTuple
diff --git a/src/backend/access/index/indexam.c b/src/backend/access/index/indexam.c
index 28edd4a..ec19e80 100644
--- a/src/backend/access/index/indexam.c
+++ b/src/backend/access/index/indexam.c
@@ -180,7 +180,7 @@ index_insert(Relation indexRelation,
 
 	if (!(indexRelation->rd_indam->ampredlocks))
 		CheckForSerializableConflictIn(indexRelation,
-									   (HeapTuple) NULL,
+									   (ItemPointer) NULL,
 									   InvalidBuffer);
 
 	return indexRelation->rd_indam->aminsert(indexRelation, values, isnull,
diff --git a/src/backend/access/nbtree/nbtinsert.c b/src/backend/access/nbtree/nbtinsert.c
index 602f884..fb39e2f 100644
--- a/src/backend/access/nbtree/nbtinsert.c
+++ b/src/backend/access/nbtree/nbtinsert.c
@@ -17,6 +17,7 @@
 
 #include "access/nbtree.h"
 #include "access/nbtxlog.h"
+#include "access/subtrans.h"
 #include "access/tableam.h"
 #include "access/transam.h"
 #include "access/xloginsert.h"
@@ -34,7 +35,8 @@ static Buffer _bt_newroot(Relation rel, Buffer lbuf, Buffer rbuf);
 static TransactionId _bt_check_unique(Relation rel, BTInsertState insertstate,
 									  Relation heapRel,
 									  IndexUniqueCheck checkUnique, bool *is_unique,
-									  uint32 *speculativeToken);
+									  uint32 *speculativeToken,
+									  SubTransactionId *subxid);
 static OffsetNumber _bt_findinsertloc(Relation rel,
 									  BTInsertState insertstate,
 									  bool checkingunique,
@@ -248,9 +250,10 @@ top:
 	{
 		TransactionId xwait;
 		uint32		speculativeToken;
+		SubTransactionId subxid = InvalidSubTransactionId;
 
 		xwait = _bt_check_unique(rel, &insertstate, heapRel, checkUnique,
-								 &is_unique, &speculativeToken);
+								 &is_unique, &speculativeToken, &subxid);
 
 		if (TransactionIdIsValid(xwait))
 		{
@@ -264,10 +267,14 @@ top:
 			 * wait for the transaction to finish as usual.
 			 */
 			if (speculativeToken)
-				SpeculativeInsertionWait(xwait, speculativeToken);
+				SpeculativeInsertionWait(SubTransGetTopmostTransaction(xwait),
+										 speculativeToken);
+			else if (subxid != InvalidSubTransactionId)
+				SubXactLockTableWait(xwait, subxid, rel, &itup->t_tid,
+									 XLTW_InsertIndex);
 			else
-				XactLockTableWait(xwait, rel, &itup->t_tid, XLTW_InsertIndex);
-
+				XactLockTableWait(xwait, rel, &itup->t_tid,
+								  XLTW_InsertIndex);
 			/* start over... */
 			if (stack)
 				_bt_freestack(stack);
@@ -342,7 +349,7 @@ top:
 static TransactionId
 _bt_check_unique(Relation rel, BTInsertState insertstate, Relation heapRel,
 				 IndexUniqueCheck checkUnique, bool *is_unique,
-				 uint32 *speculativeToken)
+				 uint32 *speculativeToken, SubTransactionId *subxid)
 {
 	IndexTuple	itup = insertstate->itup;
 	BTScanInsert itup_key = insertstate->itup_key;
@@ -489,6 +496,7 @@ _bt_check_unique(Relation rel, BTInsertState insertstate, Relation heapRel,
 							_bt_relbuf(rel, nbuf);
 						/* Tell _bt_doinsert to wait... */
 						*speculativeToken = SnapshotDirty.speculativeToken;
+						*subxid = SnapshotDirty.subxid;
 						/* Caller releases lock on buf immediately */
 						insertstate->bounds_valid = false;
 						return xwait;
diff --git a/src/backend/access/rmgrdesc/Makefile b/src/backend/access/rmgrdesc/Makefile
index 640d37f..43e5e1a 100644
--- a/src/backend/access/rmgrdesc/Makefile
+++ b/src/backend/access/rmgrdesc/Makefile
@@ -12,6 +12,6 @@ OBJS = brindesc.o clogdesc.o committsdesc.o dbasedesc.o genericdesc.o \
 	   gindesc.o gistdesc.o hashdesc.o heapdesc.o logicalmsgdesc.o \
 	   mxactdesc.o nbtdesc.o relmapdesc.o replorigindesc.o seqdesc.o \
 	   smgrdesc.o spgdesc.o standbydesc.o tblspcdesc.o undoactiondesc.o \
-	   undologdesc.o xactdesc.o xlogdesc.o
+	   undologdesc.o xactdesc.o xlogdesc.o tpddesc.o zheapamdesc.o
 
 include $(top_srcdir)/src/backend/common.mk
diff --git a/src/backend/access/rmgrdesc/tpddesc.c b/src/backend/access/rmgrdesc/tpddesc.c
new file mode 100644
index 0000000..5cbacfd
--- /dev/null
+++ b/src/backend/access/rmgrdesc/tpddesc.c
@@ -0,0 +1,73 @@
+/*-------------------------------------------------------------------------
+ *
+ * tpddesc.c
+ *	  rmgr descriptor routines for access/undo/tpdxlog.c
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/rmgrdesc/tpddesc.c
+ *
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include "access/tpd_xlog.h"
+
+void
+tpd_desc(StringInfo buf, XLogReaderState *record)
+{
+	char	   *rec = XLogRecGetData(record);
+	uint8		info = XLogRecGetInfo(record) & ~XLR_INFO_MASK;
+
+	info &= XLOG_TPD_OPMASK;
+	if (info == XLOG_ALLOCATE_TPD_ENTRY)
+	{
+		xl_tpd_allocate_entry *xlrec = (xl_tpd_allocate_entry *) rec;
+
+		appendStringInfo(buf, "prevblk %u nextblk %u offset %u",
+						 xlrec->prevblk, xlrec->nextblk, xlrec->offnum);
+	}
+	else if (info == XLOG_TPD_FREE_PAGE)
+	{
+		xl_tpd_free_page *xlrec = (xl_tpd_free_page *) rec;
+
+		appendStringInfo(buf, "prevblk %u nextblk %u",
+						 xlrec->prevblkno, xlrec->nextblkno);
+	}
+}
+
+const char *
+tpd_identify(uint8 info)
+{
+	const char *id = NULL;
+
+	switch (info & ~XLR_INFO_MASK)
+	{
+		case XLOG_ALLOCATE_TPD_ENTRY:
+			id = "ALLOCATE TPD ENTRY";
+			break;
+		case XLOG_ALLOCATE_TPD_ENTRY | XLOG_TPD_INIT_PAGE:
+			id = "ALLOCATE TPD ENTRY+INIT";
+			break;
+		case XLOG_TPD_CLEAN:
+			id = "TPD CLEAN";
+			break;
+		case XLOG_TPD_CLEAR_LOCATION:
+			id = "TPD CLEAR LOCATION";
+			break;
+		case XLOG_INPLACE_UPDATE_TPD_ENTRY:
+			id = "INPLACE UPDATE TPD ENTRY";
+			break;
+		case XLOG_TPD_FREE_PAGE:
+			id = "TPD FREE PAGE";
+			break;
+		case XLOG_TPD_CLEAN_ALL_ENTRIES:
+			id = "TPD CLEAN ALL ENTRIES";
+			break;
+	}
+
+	return id;
+}
diff --git a/src/backend/access/rmgrdesc/zheapamdesc.c b/src/backend/access/rmgrdesc/zheapamdesc.c
new file mode 100644
index 0000000..90395b2
--- /dev/null
+++ b/src/backend/access/rmgrdesc/zheapamdesc.c
@@ -0,0 +1,237 @@
+/*-------------------------------------------------------------------------
+ *
+ * zheapamdesc.c
+ *	  rmgr descriptor routines for access/zheap/zheapamxlog.c
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/rmgrdesc/zheapamdesc.c
+ *
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include "access/zheapam_xlog.h"
+
+void
+zheap_desc(StringInfo buf, XLogReaderState *record)
+{
+	char	   *rec = XLogRecGetData(record);
+	uint8		info = XLogRecGetInfo(record) & ~XLR_INFO_MASK;
+
+	info &= XLOG_ZHEAP_OPMASK;
+	if (info == XLOG_ZHEAP_CLEAN)
+	{
+		xl_zheap_clean *xlrec = (xl_zheap_clean *) rec;
+
+		appendStringInfo(buf, "remxid %u", xlrec->latestRemovedXid);
+	}
+	else if (info == XLOG_ZHEAP_INSERT)
+	{
+		xl_undo_header *xlundohdr = (xl_undo_header *) rec;
+		xl_zheap_insert *xlrec = (xl_zheap_insert *) ((char *) xlundohdr + SizeOfUndoHeader);
+
+		appendStringInfo(buf, "off %u, blkprev %lu", xlrec->offnum, xlundohdr->blkprev);
+	}
+	else if (info == XLOG_ZHEAP_MULTI_INSERT)
+	{
+		xl_undo_header *xlundohdr = (xl_undo_header *) rec;
+		xl_zheap_multi_insert *xlrec = (xl_zheap_multi_insert *) ((char *) xlundohdr + SizeOfUndoHeader);
+
+		appendStringInfo(buf, "%d tuples", xlrec->ntuples);
+	}
+	else if (info == XLOG_ZHEAP_DELETE)
+	{
+		xl_undo_header *xlundohdr = (xl_undo_header *) rec;
+		xl_zheap_delete *xlrec = (xl_zheap_delete *) ((char *) xlundohdr + SizeOfUndoHeader);
+
+		appendStringInfo(buf, "off %u, trans_slot %u, hasUndoTuple: %c, blkprev %lu",
+						 xlrec->offnum, xlrec->trans_slot_id,
+						 (xlrec->flags & XLZ_HAS_DELETE_UNDOTUPLE) ? 'T' : 'F',
+						 xlundohdr->blkprev);
+	}
+	else if (info == XLOG_ZHEAP_UPDATE)
+	{
+		xl_undo_header *xlundohdr = (xl_undo_header *) rec;
+		xl_zheap_update *xlrec = (xl_zheap_update *) ((char *) xlundohdr + SizeOfUndoHeader);
+
+		appendStringInfo(buf, "oldoff %u, trans_slot %u, hasUndoTuple: %c, newoff: %u, blkprev %lu",
+						 xlrec->old_offnum, xlrec->old_trans_slot_id,
+						 (xlrec->flags & XLZ_HAS_UPDATE_UNDOTUPLE) ? 'T' : 'F',
+						 xlrec->new_offnum,
+						 xlundohdr->blkprev);
+	}
+	else if (info == XLOG_ZHEAP_FREEZE_XACT_SLOT)
+	{
+		xl_zheap_freeze_xact_slot *xlrec = (xl_zheap_freeze_xact_slot *) rec;
+
+		appendStringInfo(buf, "latest frozen xid %u nfrozen %u",
+						 xlrec->lastestFrozenXid, xlrec->nFrozen);
+	}
+	else if (info == XLOG_ZHEAP_INVALID_XACT_SLOT)
+	{
+		uint16		nCompletedSlots = *(uint16 *) rec;
+
+		appendStringInfo(buf, "completed_slots %u", nCompletedSlots);
+	}
+	else if (info == XLOG_ZHEAP_LOCK)
+	{
+		xl_undo_header *xlundohdr = (xl_undo_header *) rec;
+		xl_zheap_lock *xlrec = (xl_zheap_lock *) ((char *) xlundohdr + SizeOfUndoHeader);
+
+		appendStringInfo(buf, "off %u, xid %u, trans_slot_id %u",
+						 xlrec->offnum, xlrec->prev_xid, xlrec->trans_slot_id);
+	}
+}
+
+void
+zheap2_desc(StringInfo buf, XLogReaderState *record)
+{
+	char	   *rec = XLogRecGetData(record);
+	uint8		info = XLogRecGetInfo(record) & ~XLR_INFO_MASK;
+
+	info &= XLOG_ZHEAP_OPMASK;
+	if (info == XLOG_ZHEAP_CONFIRM)
+	{
+		xl_zheap_confirm *xlrec = (xl_zheap_confirm *) rec;
+
+		appendStringInfo(buf, "off %u: flags %u", xlrec->offnum, xlrec->flags);
+	}
+	else if (info == XLOG_ZHEAP_UNUSED)
+	{
+		xl_undo_header *xlundohdr = (xl_undo_header *) rec;
+		xl_zheap_unused *xlrec = (xl_zheap_unused *) ((char *) xlundohdr + SizeOfUndoHeader);
+
+		appendStringInfo(buf, "remxid %u, trans_slot_id %u, blkprev %lu",
+						 xlrec->latestRemovedXid, xlrec->trans_slot_id,
+						 xlundohdr->blkprev);
+	}
+	else if (info == XLOG_ZHEAP_VISIBLE)
+	{
+		xl_zheap_visible *xlrec = (xl_zheap_visible *) rec;
+
+		appendStringInfo(buf, "cutoff xid %u flags %d",
+						 xlrec->cutoff_xid, xlrec->flags);
+	}
+}
+
+void
+zundo_desc(StringInfo buf, XLogReaderState *record)
+{
+	char	   *rec = XLogRecGetData(record);
+	uint8		info = XLogRecGetInfo(record) & ~XLR_INFO_MASK;
+
+	if (info == XLOG_ZUNDO_PAGE)
+	{
+		uint8	   *flags = (uint8 *) rec;
+
+		appendStringInfo(buf, "page_contains_tpd_slot: %c ",
+						 (*flags & XLU_PAGE_CONTAINS_TPD_SLOT) ? 'T' : 'F');
+		appendStringInfo(buf, "is_page_initialized: %c ",
+						 (*flags & XLU_INIT_PAGE) ? 'T' : 'F');
+		if (*flags & XLU_PAGE_CONTAINS_TPD_SLOT)
+		{
+			xl_zundo_page *xlrec =
+			(xl_zundo_page *) ((char *) flags + sizeof(uint8));
+
+			appendStringInfo(buf, "urec_ptr %lu xid %u trans_slot_id %u",
+							 xlrec->urec_ptr,
+							 XidFromFullTransactionId(xlrec->fxid),
+							 xlrec->trans_slot_id);
+		}
+	}
+	else if (info == XLOG_ZUNDO_RESET_SLOT)
+	{
+		xl_zundo_reset_slot *xlrec = (xl_zundo_reset_slot *) rec;
+
+		appendStringInfo(buf, "urec_ptr %lu trans_slot_id %u",
+						 xlrec->urec_ptr, xlrec->trans_slot_id);
+	}
+}
+
+const char *
+zheap_identify(uint8 info)
+{
+	const char *id = NULL;
+
+	switch (info & ~XLR_INFO_MASK)
+	{
+		case XLOG_ZHEAP_CLEAN:
+			id = "CLEAN";
+			break;
+		case XLOG_ZHEAP_INSERT:
+			id = "INSERT";
+			break;
+		case XLOG_ZHEAP_INSERT | XLOG_ZHEAP_INIT_PAGE:
+			id = "INSERT+INIT";
+			break;
+		case XLOG_ZHEAP_DELETE:
+			id = "DELETE";
+			break;
+		case XLOG_ZHEAP_UPDATE:
+			id = "UPDATE";
+			break;
+		case XLOG_ZHEAP_UPDATE | XLOG_ZHEAP_INIT_PAGE:
+			id = "UPDATE+INIT";
+			break;
+		case XLOG_ZHEAP_FREEZE_XACT_SLOT:
+			id = "FREEZE_XACT_SLOT";
+			break;
+		case XLOG_ZHEAP_INVALID_XACT_SLOT:
+			id = "INVALID_XACT_SLOT";
+			break;
+		case XLOG_ZHEAP_LOCK:
+			id = "LOCK";
+			break;
+		case XLOG_ZHEAP_MULTI_INSERT:
+			id = "MULTI_INSERT";
+			break;
+		case XLOG_ZHEAP_MULTI_INSERT | XLOG_ZHEAP_INIT_PAGE:
+			id = "MULTI_INSERT+INIT";
+			break;
+	}
+
+	return id;
+}
+
+const char *
+zheap2_identify(uint8 info)
+{
+	const char *id = NULL;
+
+	switch (info & ~XLR_INFO_MASK)
+	{
+		case XLOG_ZHEAP_CONFIRM:
+			id = "CONFIRM";
+			break;
+		case XLOG_ZHEAP_UNUSED:
+			id = "UNUSED";
+			break;
+		case XLOG_ZHEAP_VISIBLE:
+			id = "VISIBLE";
+			break;
+	}
+
+	return id;
+}
+
+const char *
+zundo_identify(uint8 info)
+{
+	const char *id = NULL;
+
+	switch (info & ~XLR_INFO_MASK)
+	{
+		case XLOG_ZUNDO_PAGE:
+			id = "UNDO PAGE";
+			break;
+		case XLOG_ZUNDO_RESET_SLOT:
+			id = "UNDO RESET SLOT";
+			break;
+	}
+
+	return id;
+}
diff --git a/src/backend/access/table/Makefile b/src/backend/access/table/Makefile
index 55a0e5e..ec09b06 100644
--- a/src/backend/access/table/Makefile
+++ b/src/backend/access/table/Makefile
@@ -12,6 +12,6 @@ subdir = src/backend/access/table
 top_builddir = ../../../..
 include $(top_builddir)/src/Makefile.global
 
-OBJS = table.o tableam.o tableamapi.o
+OBJS = table.o tableam.o tableamapi.o  vacuumblk.o
 
 include $(top_srcdir)/src/backend/common.mk
diff --git a/src/backend/access/table/vacuumblk.c b/src/backend/access/table/vacuumblk.c
new file mode 100644
index 0000000..0029280
--- /dev/null
+++ b/src/backend/access/table/vacuumblk.c
@@ -0,0 +1,559 @@
+/*-------------------------------------------------------------------------
+ *
+ * vacuumblk.c
+ *	  The postgres block level functions.
+ *
+ * This file contains the commons functions for block level vacuum that
+ * can be used by different storage engines.
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * IDENTIFICATION
+ *	  src/backend/commands/vacuumblk.c
+ *
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include "access/multixact.h"
+#include "access/vacuumblk.h"
+#include "catalog/storage.h"
+#include "commands/progress.h"
+#include "commands/vacuum.h"
+#include "miscadmin.h"
+#include "pgstat.h"
+#include "storage/bufmgr.h"
+#include "storage/lmgr.h"
+#include "utils/pg_rusage.h"
+
+/*
+ * Space/time tradeoff parameters: do these need to be user-tunable?
+ *
+ * To consider truncating the relation, we want there to be at least
+ * REL_TRUNCATE_MINIMUM or (relsize / REL_TRUNCATE_FRACTION) (whichever
+ * is less) potentially-freeable pages.
+ */
+#define REL_TRUNCATE_MINIMUM	1000
+#define REL_TRUNCATE_FRACTION	16
+
+/*
+ * Timing parameters for truncate locking heuristics.
+ *
+ * These were not exposed as user tunable GUC values because it didn't seem
+ * that the potential for improvement was great enough to merit the cost of
+ * supporting them.
+ */
+#define VACUUM_TRUNCATE_LOCK_CHECK_INTERVAL		20	/* ms */
+#define VACUUM_TRUNCATE_LOCK_WAIT_INTERVAL		50	/* ms */
+#define VACUUM_TRUNCATE_LOCK_TIMEOUT			5000	/* ms */
+
+/*
+ * Size of the prefetch window for lazy vacuum backwards truncation scan.
+ * Needs to be a power of 2.
+ */
+#define PREFETCH_SIZE			((BlockNumber) 32)
+
+static bool lazy_tid_reaped(ItemPointer itemptr, void *state);
+static int	vac_cmp_itemptr(const void *left, const void *right);
+static BlockNumber count_nondeletable_pages(Relation onerel,
+											LVRelStats *vacrelstats,
+											BufferAccessStrategy vac_strategy,
+											int elevel);
+
+/*
+ *	lazy_vacuum_index() -- vacuum one index relation.
+ *
+ *		Delete all the index entries pointing to tuples listed in
+ *		vacrelstats->dead_tuples, and update running statistics.
+ */
+void
+lazy_vacuum_index(Relation indrel,
+				  IndexBulkDeleteResult **stats,
+				  LVRelStats *vacrelstats,
+				  BufferAccessStrategy vac_strategy,
+				  int elevel)
+{
+	IndexVacuumInfo ivinfo;
+	PGRUsage	ru0;
+
+	pg_rusage_init(&ru0);
+
+	ivinfo.index = indrel;
+	ivinfo.analyze_only = false;
+	ivinfo.estimated_count = true;
+	ivinfo.message_level = elevel;
+	/* We can only provide an approximate value of num_heap_tuples here */
+	ivinfo.num_heap_tuples = vacrelstats->old_live_tuples;
+	ivinfo.strategy = vac_strategy;
+
+	/* Do bulk deletion */
+	*stats = index_bulk_delete(&ivinfo, *stats,
+							   lazy_tid_reaped, (void *) vacrelstats);
+
+	ereport(elevel,
+			(errmsg("scanned index \"%s\" to remove %d row versions",
+					RelationGetRelationName(indrel),
+					vacrelstats->num_dead_tuples),
+			 errdetail_internal("%s", pg_rusage_show(&ru0))));
+}
+
+/*
+ *	lazy_cleanup_index() -- do post-vacuum cleanup for one index relation.
+ */
+void
+lazy_cleanup_index(Relation indrel,
+				   IndexBulkDeleteResult *stats,
+				   LVRelStats *vacrelstats,
+				   BufferAccessStrategy vac_strategy,
+				   int elevel)
+{
+	IndexVacuumInfo ivinfo;
+	PGRUsage	ru0;
+
+	pg_rusage_init(&ru0);
+
+	ivinfo.index = indrel;
+	ivinfo.analyze_only = false;
+	ivinfo.report_progress = false;
+	ivinfo.estimated_count = (vacrelstats->tupcount_pages < vacrelstats->rel_pages);
+	ivinfo.message_level = elevel;
+
+	/*
+	 * Now we can provide a better estimate of total number of surviving
+	 * tuples (we assume indexes are more interested in that than in the
+	 * number of nominally live tuples).
+	 */
+	ivinfo.num_heap_tuples = vacrelstats->new_rel_tuples;
+	ivinfo.strategy = vac_strategy;
+
+	stats = index_vacuum_cleanup(&ivinfo, stats);
+
+	if (!stats)
+		return;
+
+	/*
+	 * Now update statistics in pg_class, but only if the index says the count
+	 * is accurate.
+	 */
+	if (!stats->estimated_count)
+		vac_update_relstats(indrel,
+							stats->num_pages,
+							stats->num_index_tuples,
+							0,
+							false,
+							InvalidTransactionId,
+							InvalidMultiXactId,
+							false);
+
+	ereport(elevel,
+			(errmsg("index \"%s\" now contains %.0f row versions in %u pages",
+					RelationGetRelationName(indrel),
+					stats->num_index_tuples,
+					stats->num_pages),
+			 errdetail("%.0f index row versions were removed.\n"
+					   "%u index pages have been deleted, %u are currently reusable.\n"
+					   "%s.",
+					   stats->tuples_removed,
+					   stats->pages_deleted, stats->pages_free,
+					   pg_rusage_show(&ru0))));
+
+	pfree(stats);
+}
+
+/*
+ * should_attempt_truncation - should we attempt to truncate the heap?
+ *
+ * Don't even think about it unless we have a shot at releasing a goodly
+ * number of pages.  Otherwise, the time taken isn't worth it.
+ *
+ * Also don't attempt it if we are doing early pruning/vacuuming, because a
+ * scan which cannot find a truncated heap page cannot determine that the
+ * snapshot is too old to read that page.  We might be able to get away with
+ * truncating all except one of the pages, setting its LSN to (at least) the
+ * maximum of the truncated range if we also treated an index leaf tuple
+ * pointing to a missing heap page as something to trigger the "snapshot too
+ * old" error, but that seems fragile and seems like it deserves its own patch
+ * if we consider it.
+ *
+ * This is split out so that we can test whether truncation is going to be
+ * called for before we actually do it.  If you change the logic here, be
+ * careful to depend only on fields that lazy_scan_heap updates on-the-fly.
+ */
+bool
+should_attempt_truncation(VacuumParams *params, LVRelStats *vacrelstats)
+{
+	BlockNumber possibly_freeable;
+
+
+	if (params->truncate == VACOPT_TERNARY_DISABLED)
+		return false;
+
+	possibly_freeable = vacrelstats->rel_pages - vacrelstats->nonempty_pages;
+	if (possibly_freeable > 0 &&
+		(possibly_freeable >= REL_TRUNCATE_MINIMUM ||
+		 possibly_freeable >= vacrelstats->rel_pages / REL_TRUNCATE_FRACTION) &&
+		old_snapshot_threshold < 0)
+		return true;
+	else
+		return false;
+}
+
+/*
+ * lazy_truncate_heap - try to truncate off any empty pages at the end
+ */
+void
+lazy_truncate_heap(Relation onerel, LVRelStats *vacrelstats,
+				   BufferAccessStrategy vac_strategy, int elevel)
+{
+	BlockNumber old_rel_pages = vacrelstats->rel_pages;
+	BlockNumber new_rel_pages;
+	PGRUsage	ru0;
+	int			lock_retry;
+
+	pg_rusage_init(&ru0);
+
+	/* Report that we are now truncating */
+	pgstat_progress_update_param(PROGRESS_VACUUM_PHASE,
+								 PROGRESS_VACUUM_PHASE_TRUNCATE);
+
+	/*
+	 * Loop until no more truncating can be done.
+	 */
+	do
+	{
+		/*
+		 * We need full exclusive lock on the relation in order to do
+		 * truncation. If we can't get it, give up rather than waiting --- we
+		 * don't want to block other backends, and we don't want to deadlock
+		 * (which is quite possible considering we already hold a lower-grade
+		 * lock).
+		 */
+		vacrelstats->lock_waiter_detected = false;
+		lock_retry = 0;
+		while (true)
+		{
+			if (ConditionalLockRelation(onerel, AccessExclusiveLock))
+				break;
+
+			/*
+			 * Check for interrupts while trying to (re-)acquire the exclusive
+			 * lock.
+			 */
+			CHECK_FOR_INTERRUPTS();
+
+			if (++lock_retry > (VACUUM_TRUNCATE_LOCK_TIMEOUT /
+								VACUUM_TRUNCATE_LOCK_WAIT_INTERVAL))
+			{
+				/*
+				 * We failed to establish the lock in the specified number of
+				 * retries. This means we give up truncating.
+				 */
+				vacrelstats->lock_waiter_detected = true;
+				ereport(elevel,
+						(errmsg("\"%s\": stopping truncate due to conflicting lock request",
+								RelationGetRelationName(onerel))));
+				return;
+			}
+
+			pg_usleep(VACUUM_TRUNCATE_LOCK_WAIT_INTERVAL * 1000L);
+		}
+
+		/*
+		 * Now that we have exclusive lock, look to see if the rel has grown
+		 * whilst we were vacuuming with non-exclusive lock.  If so, give up;
+		 * the newly added pages presumably contain non-deletable tuples.
+		 */
+		new_rel_pages = RelationGetNumberOfBlocks(onerel);
+		if (new_rel_pages != old_rel_pages)
+		{
+			/*
+			 * Note: we intentionally don't update vacrelstats->rel_pages with
+			 * the new rel size here.  If we did, it would amount to assuming
+			 * that the new pages are empty, which is unlikely. Leaving the
+			 * numbers alone amounts to assuming that the new pages have the
+			 * same tuple density as existing ones, which is less unlikely.
+			 */
+			UnlockRelation(onerel, AccessExclusiveLock);
+			return;
+		}
+
+		/*
+		 * Scan backwards from the end to verify that the end pages actually
+		 * contain no tuples.  This is *necessary*, not optional, because
+		 * other backends could have added tuples to these pages whilst we
+		 * were vacuuming.
+		 */
+		new_rel_pages = count_nondeletable_pages(onerel, vacrelstats,
+												 vac_strategy, elevel);
+
+		if (new_rel_pages >= old_rel_pages)
+		{
+			/* can't do anything after all */
+			UnlockRelation(onerel, AccessExclusiveLock);
+			return;
+		}
+
+		/*
+		 * Okay to truncate.
+		 */
+
+		/* make sure it's not the metapage */
+		if (RelationStorageIsZHeap(onerel))
+			Assert(new_rel_pages > 0);
+
+		RelationTruncate(onerel, new_rel_pages);
+
+		/*
+		 * We can release the exclusive lock as soon as we have truncated.
+		 * Other backends can't safely access the relation until they have
+		 * processed the smgr invalidation that smgrtruncate sent out ... but
+		 * that should happen as part of standard invalidation processing once
+		 * they acquire lock on the relation.
+		 */
+		UnlockRelation(onerel, AccessExclusiveLock);
+
+		/*
+		 * Update statistics.  Here, it *is* correct to adjust rel_pages
+		 * without also touching reltuples, since the tuple count wasn't
+		 * changed by the truncation.
+		 */
+		vacrelstats->pages_removed += old_rel_pages - new_rel_pages;
+		vacrelstats->rel_pages = new_rel_pages;
+
+		ereport(elevel,
+				(errmsg("\"%s\": truncated %u to %u pages",
+						RelationGetRelationName(onerel),
+						old_rel_pages, new_rel_pages),
+				 errdetail_internal("%s",
+									pg_rusage_show(&ru0))));
+		old_rel_pages = new_rel_pages;
+	} while (new_rel_pages > vacrelstats->nonempty_pages &&
+			 vacrelstats->lock_waiter_detected);
+}
+
+/*
+ * lazy_record_dead_tuple - remember one deletable tuple
+ */
+void
+lazy_record_dead_tuple(LVRelStats *vacrelstats,
+					   ItemPointer itemptr)
+{
+	/*
+	 * The array shouldn't overflow under normal behavior, but perhaps it
+	 * could if we are given a really small maintenance_work_mem. In that
+	 * case, just forget the last few tuples (we'll get 'em next time).
+	 */
+	if (vacrelstats->num_dead_tuples < vacrelstats->max_dead_tuples)
+	{
+		vacrelstats->dead_tuples[vacrelstats->num_dead_tuples] = *itemptr;
+		vacrelstats->num_dead_tuples++;
+		pgstat_progress_update_param(PROGRESS_VACUUM_NUM_DEAD_TUPLES,
+									 vacrelstats->num_dead_tuples);
+	}
+}
+
+/*
+ *	lazy_tid_reaped() -- is a particular tid deletable?
+ *
+ *		This has the right signature to be an IndexBulkDeleteCallback.
+ *
+ *		Assumes dead_tuples array is in sorted order.
+ */
+static bool
+lazy_tid_reaped(ItemPointer itemptr, void *state)
+{
+	LVRelStats *vacrelstats = (LVRelStats *) state;
+	ItemPointer res;
+
+	res = (ItemPointer) bsearch((void *) itemptr,
+								(void *) vacrelstats->dead_tuples,
+								vacrelstats->num_dead_tuples,
+								sizeof(ItemPointerData),
+								vac_cmp_itemptr);
+
+	return (res != NULL);
+}
+
+/*
+ * Comparator routines for use with qsort() and bsearch().
+ */
+static int
+vac_cmp_itemptr(const void *left, const void *right)
+{
+	BlockNumber lblk,
+				rblk;
+	OffsetNumber loff,
+				roff;
+
+	lblk = ItemPointerGetBlockNumber((ItemPointer) left);
+	rblk = ItemPointerGetBlockNumber((ItemPointer) right);
+
+	if (lblk < rblk)
+		return -1;
+	if (lblk > rblk)
+		return 1;
+
+	loff = ItemPointerGetOffsetNumber((ItemPointer) left);
+	roff = ItemPointerGetOffsetNumber((ItemPointer) right);
+
+	if (loff < roff)
+		return -1;
+	if (loff > roff)
+		return 1;
+
+	return 0;
+}
+
+/*
+ * Rescan end pages to verify that they are (still) empty of tuples.
+ *
+ * Returns number of nondeletable pages (last nonempty page + 1).
+ */
+static BlockNumber
+count_nondeletable_pages(Relation onerel, LVRelStats *vacrelstats,
+						 BufferAccessStrategy vac_strategy, int elevel)
+{
+	BlockNumber blkno;
+	BlockNumber prefetchedUntil;
+	instr_time	starttime;
+
+	/* Initialize the starttime if we check for conflicting lock requests */
+	INSTR_TIME_SET_CURRENT(starttime);
+
+	/*
+	 * Start checking blocks at what we believe relation end to be and move
+	 * backwards.  (Strange coding of loop control is needed because blkno is
+	 * unsigned.)  To make the scan faster, we prefetch a few blocks at a time
+	 * in forward direction, so that OS-level readahead can kick in.
+	 */
+	blkno = vacrelstats->rel_pages;
+	StaticAssertStmt((PREFETCH_SIZE & (PREFETCH_SIZE - 1)) == 0,
+					 "prefetch size must be power of 2");
+	prefetchedUntil = InvalidBlockNumber;
+	while (blkno > vacrelstats->nonempty_pages)
+	{
+		Buffer		buf;
+		Page		page;
+		OffsetNumber offnum,
+					maxoff;
+		bool		hastup;
+
+		/*
+		 * Check if another process requests a lock on our relation. We are
+		 * holding an AccessExclusiveLock here, so they will be waiting. We
+		 * only do this once per VACUUM_TRUNCATE_LOCK_CHECK_INTERVAL, and we
+		 * only check if that interval has elapsed once every 32 blocks to
+		 * keep the number of system calls and actual shared lock table
+		 * lookups to a minimum.
+		 */
+		if ((blkno % 32) == 0)
+		{
+			instr_time	currenttime;
+			instr_time	elapsed;
+
+			INSTR_TIME_SET_CURRENT(currenttime);
+			elapsed = currenttime;
+			INSTR_TIME_SUBTRACT(elapsed, starttime);
+			if ((INSTR_TIME_GET_MICROSEC(elapsed) / 1000)
+				>= VACUUM_TRUNCATE_LOCK_CHECK_INTERVAL)
+			{
+				if (LockHasWaitersRelation(onerel, AccessExclusiveLock))
+				{
+					ereport(elevel,
+							(errmsg("\"%s\": suspending truncate due to conflicting lock request",
+									RelationGetRelationName(onerel))));
+
+					vacrelstats->lock_waiter_detected = true;
+					return blkno;
+				}
+				starttime = currenttime;
+			}
+		}
+
+		/*
+		 * We don't insert a vacuum delay point here, because we have an
+		 * exclusive lock on the table which we want to hold for as short a
+		 * time as possible.  We still need to check for interrupts however.
+		 */
+		CHECK_FOR_INTERRUPTS();
+
+		blkno--;
+
+		/* If we haven't prefetched this lot yet, do so now. */
+		if (prefetchedUntil > blkno)
+		{
+			BlockNumber prefetchStart;
+			BlockNumber pblkno;
+
+			prefetchStart = blkno & ~(PREFETCH_SIZE - 1);
+			for (pblkno = prefetchStart; pblkno <= blkno; pblkno++)
+			{
+				PrefetchBuffer(onerel, MAIN_FORKNUM, pblkno);
+				CHECK_FOR_INTERRUPTS();
+			}
+			prefetchedUntil = prefetchStart;
+		}
+
+		buf = ReadBufferExtended(onerel, MAIN_FORKNUM, blkno,
+								 RBM_NORMAL, vac_strategy);
+
+		/* In this phase we only need shared access to the buffer */
+		LockBuffer(buf, BUFFER_LOCK_SHARE);
+
+		page = BufferGetPage(buf);
+
+		if (PageIsNew(page) || PageIsEmpty(page))
+		{
+			UnlockReleaseBuffer(buf);
+			continue;
+		}
+
+		hastup = false;
+		maxoff = PageGetMaxOffsetNumber(page);
+		for (offnum = FirstOffsetNumber;
+			 offnum <= maxoff;
+			 offnum = OffsetNumberNext(offnum))
+		{
+			ItemId		itemid;
+
+			itemid = PageGetItemId(page, offnum);
+
+			/*
+			 * Note: any non-unused item should be taken as a reason to keep
+			 * this page.  We formerly thought that DEAD tuples could be
+			 * thrown away, but that's not so, because we'd not have cleaned
+			 * out their index entries.
+			 *
+			 * XXX - This function is used by both heap and zheap and the
+			 * behavior must be same in both the cases.  However, for zheap,
+			 * there could be some unused items that contain pending xact
+			 * information for the current transaction.  It is okay to
+			 * truncate such pages as even if the transaction rolled back
+			 * after this point, we won't be reclaiming the truncated pages or
+			 * making the unused items back to dead.  We can add Assert to
+			 * check if the pending xact is the current transaction, but to do
+			 * that we need some storage engine specific check which seems too
+			 * much for the purpose for which it is required.
+			 */
+			if (ItemIdIsUsed(itemid))
+			{
+				hastup = true;
+				break;			/* can stop scanning */
+			}
+		}						/* scan along page */
+
+		UnlockReleaseBuffer(buf);
+
+		/* Done scanning if we found a tuple here */
+		if (hastup)
+			return blkno + 1;
+	}
+
+	/*
+	 * If we fall out of the loop, all the previously-thought-to-be-empty
+	 * pages still are; we need not bother to look at the last known-nonempty
+	 * page.
+	 */
+	return vacrelstats->nonempty_pages;
+}
diff --git a/src/backend/access/transam/rmgr.c b/src/backend/access/transam/rmgr.c
index c57eca2..f707556 100644
--- a/src/backend/access/transam/rmgr.c
+++ b/src/backend/access/transam/rmgr.c
@@ -18,10 +18,13 @@
 #include "access/multixact.h"
 #include "access/nbtxlog.h"
 #include "access/spgxlog.h"
+#include "access/tpd_xlog.h"
 #include "access/undoaction_xlog.h"
 #include "access/undolog_xlog.h"
 #include "access/xact.h"
 #include "access/xlog_internal.h"
+#include "access/zheap.h"
+#include "access/zheapam_xlog.h"
 #include "catalog/storage_xlog.h"
 #include "commands/dbcommands_xlog.h"
 #include "commands/sequence.h"
diff --git a/src/backend/access/transam/twophase.c b/src/backend/access/transam/twophase.c
index c401885..fc26d30 100644
--- a/src/backend/access/transam/twophase.c
+++ b/src/backend/access/transam/twophase.c
@@ -1532,6 +1532,10 @@ FinishPreparedTransaction(const char *gid, bool isCommit)
 	memcpy(start_urec_ptr, hdr->start_urec_ptr, sizeof(start_urec_ptr));
 	memcpy(end_urec_ptr, hdr->end_urec_ptr, sizeof(end_urec_ptr));
 
+	/* save the start and end undo record pointers */
+	memcpy(start_urec_ptr, hdr->start_urec_ptr, sizeof(start_urec_ptr));
+	memcpy(end_urec_ptr, hdr->end_urec_ptr, sizeof(end_urec_ptr));
+
 	/* compute latestXid among all children */
 	latestXid = TransactionIdLatest(xid, hdr->nsubxacts, children);
 
@@ -1691,6 +1695,86 @@ FinishPreparedTransaction(const char *gid, bool isCommit)
 		}
 	}
 
+	/*
+	 * Perform undo actions, if there are undologs for this transaction. We
+	 * need to perform undo actions while we are still in transaction. Never
+	 * push rollbacks of temp tables to undo worker.
+	 */
+	for (i = 0; i < UndoPersistenceLevels; i++)
+	{
+		volatile UndoRequestInfo urinfo;
+		uint32		epoch;
+		FullTransactionId full_xid;
+
+		/*
+		 * We don't allow XIDs with an age of more than 2 billion in undo, so
+		 * we can infer the epoch here. (XXX We can add full transaction id in
+		 * TwoPhaseFileHeader instead. )
+		 */
+		epoch = GetEpochForXid(hdr->xid);
+		full_xid = FullTransactionIdFromEpochAndXid(epoch, hdr->xid);
+
+		if (end_urec_ptr[i] != InvalidUndoRecPtr && !isCommit)
+		{
+			uint32		save_holdoff;
+
+			save_holdoff = InterruptHoldoffCount;
+			PG_TRY();
+			{
+				bool		result = false;
+
+				/*
+				 * Prepare required undo request info so that it can be used
+				 * in exception.
+				 */
+				ResetUndoRequestInfo(&urinfo);
+				urinfo.dbid = MyDatabaseId;
+				urinfo.full_xid = full_xid;
+
+				if (i != UNDO_TEMP)
+					result = RegisterRollbackReq(end_urec_ptr[i],
+												 start_urec_ptr[i],
+												 hdr->database,
+												 full_xid);
+
+				if (!result)
+					execute_undo_actions(full_xid, end_urec_ptr[i],
+										 start_urec_ptr[i], true);
+			}
+			PG_CATCH();
+			{
+				if (i == UNDO_TEMP)
+					pg_rethrow_as_fatal();
+
+				/*
+				 * Add the request into an error queue so that it can be
+				 * processed in a timely fashion.
+				 *
+				 * If we fail to add the request in an error queue, then
+				 * remove the entry from the hash table and continue to
+				 * process the remaining undo requests if any.  This request
+				 * will be later processed by discard worker.
+				 */
+				if (!InsertRequestIntoErrorUndoQueue(&urinfo))
+					RollbackHTRemoveEntry(urinfo.full_xid, urinfo.start_urec_ptr);
+
+				/*
+				 * Errors can reset holdoff count, so restore back.  This is
+				 * required because this function can be called after holding
+				 * interrupts.
+				 */
+				InterruptHoldoffCount = save_holdoff;
+
+				/* Send the error only to server log. */
+				err_out_to_client(false);
+				EmitErrorReport();
+
+				FlushErrorState();
+			}
+			PG_END_TRY();
+		}
+	}
+
 	RESUME_INTERRUPTS();
 
 	pfree(buf);
diff --git a/src/backend/access/transam/varsup.c b/src/backend/access/transam/varsup.c
index e74155d..ba5a952 100644
--- a/src/backend/access/transam/varsup.c
+++ b/src/backend/access/transam/varsup.c
@@ -305,6 +305,64 @@ AdvanceNextFullTransactionIdPastXid(TransactionId xid)
 }
 
 /*
+ * ZBORKED: Document, test, and move to a better place?
+ *
+ * Should always be safe due to protections against too old transactions
+ * running on the master.
+ */
+FullTransactionId
+XLogRecGetFullXid(XLogReaderState *record)
+{
+	TransactionId xid = XLogRecGetXid(record);
+	uint32		epoch;
+	TransactionId next_xid;
+
+	/*
+	 * this function isn't safe otherwise, as it depends on the current replay
+	 * state
+	 */
+	Assert(AmStartupProcess() || !IsUnderPostmaster);
+
+	/* see AdvanceNextFullTransactionIdPastXid() as to why this is safe */
+
+	next_xid = XidFromFullTransactionId(ShmemVariableCache->nextFullXid);
+	epoch = EpochFromFullTransactionId(ShmemVariableCache->nextFullXid);
+
+	/*
+	 * If xid is numerically bigger than next_xid, it has to be from the last
+	 * epoch.
+	 */
+	if (unlikely(xid > next_xid))
+		epoch--;
+
+	return FullTransactionIdFromEpochAndXid(epoch, xid);
+}
+
+/*
+ * ZBORKED: Blindly written - and should be removed ASAP
+ */
+uint32
+GetEpochForXid(TransactionId xid)
+{
+	FullTransactionId next_fxid;
+	TransactionId next_xid;
+	uint32		epoch;
+
+	next_fxid = ReadNextFullTransactionId();
+	next_xid = XidFromFullTransactionId(next_fxid);
+	epoch = EpochFromFullTransactionId(next_fxid);
+
+	/*
+	 * If xid is numerically bigger than next_xid, it has to be from the last
+	 * epoch.
+	 */
+	if (unlikely(xid > next_xid))
+		epoch--;
+
+	return epoch;
+}
+
+/*
  * Advance the cluster-wide value for the oldest valid clog entry.
  *
  * We must acquire CLogTruncationLock to advance the oldestClogXid. It's not
@@ -422,6 +480,13 @@ SetTransactionIdLimit(TransactionId oldest_datfrozenxid, Oid oldest_datoid)
 	curXid = XidFromFullTransactionId(ShmemVariableCache->nextFullXid);
 	LWLockRelease(XidGenLock);
 
+	/*
+	 * Fixme - The messages in below code need some adjustment for zheap. They
+	 * should reflect that the system needs to discard the undo.  We can add
+	 * it once we have a pluggable storage API which might provide us some way
+	 * to distinguish among differnt storage engines.
+	 */
+
 	/* Log the info */
 	ereport(DEBUG1,
 			(errmsg("transaction ID wrap limit is %u, limited by database with OID %u",
@@ -590,26 +655,3 @@ GetNewObjectId(void)
 	return result;
 }
 
-/*
- * Get epoch for the given xid.
- */
-uint32
-GetEpochForXid(TransactionId xid)
-{
-	FullTransactionId next_fxid;
-	TransactionId next_xid;
-	uint32		epoch;
-
-	next_fxid = ReadNextFullTransactionId();
-	next_xid = XidFromFullTransactionId(next_fxid);
-	epoch = EpochFromFullTransactionId(next_fxid);
-
-	/*
-	 * If xid is numerically bigger than next_xid, it has to be from the last
-	 * epoch.
-	 */
-	if (unlikely(xid > next_xid))
-		epoch--;
-
-	return epoch;
-}
diff --git a/src/backend/access/transam/xact.c b/src/backend/access/transam/xact.c
index 91ad62c..286199e 100644
--- a/src/backend/access/transam/xact.c
+++ b/src/backend/access/transam/xact.c
@@ -24,6 +24,7 @@
 #include "access/multixact.h"
 #include "access/parallel.h"
 #include "access/subtrans.h"
+#include "access/tpd.h"
 #include "access/transam.h"
 #include "access/twophase.h"
 #include "access/undodiscard.h"
@@ -69,6 +70,7 @@
 #include "utils/timestamp.h"
 #include "pg_trace.h"
 
+#define	AtAbort_ResetTPDBuffers	ResetTPDBuffers()
 
 /*
  *	User-tweakable parameters
@@ -196,6 +198,7 @@ typedef struct TransactionStateData
 	bool		didLogXid;		/* has xid been included in WAL record? */
 	int			parallelModeLevel;	/* Enter/ExitParallelMode counter */
 	bool		chain;			/* start a new block after this one */
+	bool		subXactLock;    /* has lock created for subtransaction? */
 
 	/* start and end undo record location for each persistence level */
 	UndoRecPtr	start_urec_ptr[UndoLogCategories];	/* this is 'to' location */
@@ -312,7 +315,6 @@ typedef struct SubXactCallbackItem
 
 static SubXactCallbackItem *SubXact_callbacks = NULL;
 
-
 /* local function prototypes */
 static void AssignTransactionId(TransactionState s);
 static void AbortTransaction(void);
@@ -717,6 +719,28 @@ AssignTransactionId(TransactionState s)
 }
 
 /*
+ *	SetCurrentSubTransactionLocked
+ */
+void
+SetCurrentSubTransactionLocked()
+{
+	TransactionState s = CurrentTransactionState;
+
+	s->subXactLock = true;
+}
+
+/*
+ *	HasCurrentSubTransactionLock
+ */
+bool
+HasCurrentSubTransactionLock()
+{
+	TransactionState s = CurrentTransactionState;
+
+	return s->subXactLock;
+}
+
+/*
  *	GetCurrentSubTransactionId
  */
 SubTransactionId
@@ -728,6 +752,17 @@ GetCurrentSubTransactionId(void)
 }
 
 /*
+ * GetCurrentTransactionResOwner
+ */
+ResourceOwner
+GetCurrentTransactionResOwner(void)
+{
+	TransactionState s = CurrentTransactionState;
+
+	return s->curTransactionOwner;
+}
+
+/*
  *	SubTransactionIsActive
  *
  * Test if the specified subxact ID is still active.  Note caller is
@@ -781,6 +816,15 @@ GetCurrentCommandId(bool used)
 }
 
 /*
+ *	GetCurrentCommandIdUsed
+ */
+bool
+GetCurrentCommandIdUsed(void)
+{
+	return currentCommandIdUsed;
+}
+
+/*
  *	SetParallelStartTimestamps
  *
  * In a parallel worker, we should inherit the parent transaction's
@@ -1017,6 +1061,26 @@ IsInParallelMode(void)
 }
 
 /*
+ * SetUndoActionsInfo - set the start and end undo record pointers before
+ * performing the undo actions.
+ */
+void
+SetUndoActionsInfo(void)
+{
+	TransactionState s = CurrentTransactionState;
+	int			i;
+
+	for (i = 0; i < UndoPersistenceLevels; i++)
+	{
+		if (s->latest_urec_ptr[i])
+		{
+			s->performUndoActions = true;
+			break;
+		}
+	}
+}
+
+/*
  *	CommandCounterIncrement
  */
 void
@@ -1983,6 +2047,15 @@ StartTransaction(void)
 	currentCommandId = FirstCommandId;
 	currentCommandIdUsed = false;
 
+	/* initialize undo record locations for the transaction */
+	for (i = 0; i < UndoPersistenceLevels; i++)
+	{
+		s->start_urec_ptr[i] = InvalidUndoRecPtr;
+		s->latest_urec_ptr[i] = InvalidUndoRecPtr;
+	}
+	s->performUndoActions = false;
+	s->subXactLock = false;
+
 	/*
 	 * initialize reported xid accounting
 	 */
@@ -2564,6 +2637,10 @@ PrepareTransaction(UndoRecPtr *start_urec_ptr, UndoRecPtr *end_urec_ptr)
 	AtEOXact_Snapshot(true, true);
 	pgstat_report_xact_timestamp(0);
 
+	/* In single user mode, discard all the undo logs, once committed. */
+	if (!IsUnderPostmaster)
+		UndoLogDiscardAll();
+
 	CurrentResourceOwner = NULL;
 	ResourceOwnerDelete(TopTransactionResourceOwner);
 	s->curTransactionOwner = NULL;
@@ -2583,6 +2660,8 @@ PrepareTransaction(UndoRecPtr *start_urec_ptr, UndoRecPtr *end_urec_ptr)
 	XactTopFullTransactionId = InvalidFullTransactionId;
 	nParallelCurrentXids = 0;
 
+	ResetUndoActionsInfo();
+
 	/*
 	 * done with 1st phase commit processing, set current transaction state
 	 * back to default
@@ -2768,6 +2847,7 @@ AbortTransaction(void)
 		AtEOXact_PgStat(false, is_parallel_worker);
 		AtEOXact_ApplyLauncher(false);
 		pgstat_report_xact_timestamp(0);
+		AtAbort_ResetTPDBuffers;
 	}
 
 	/*
@@ -2820,6 +2900,8 @@ CleanupTransaction(void)
 
 	ResetUndoActionsInfo();
 
+	ResetUndoActionsInfo();
+
 	/*
 	 * done with abort processing, set current transaction state back to
 	 * default
@@ -3085,6 +3167,24 @@ CommitTransactionCommand(void)
 		case TBLOCK_SUBRELEASE:
 			do
 			{
+				int			i;
+
+				/*
+				 * Before cleaning up the current sub transaction state,
+				 * overwrite parent transaction's latest_urec_ptr with current
+				 * transaction's latest_urec_ptr so that in case parent
+				 * transaction get aborted we must not skip performing undo
+				 * for this transaction.  Also set the start_urec_ptr if
+				 * parent start_urec_ptr is not valid.
+				 */
+				for (i = 0; i < UndoPersistenceLevels; i++)
+				{
+					if (UndoRecPtrIsValid(s->latest_urec_ptr[i]))
+						s->parent->latest_urec_ptr[i] = s->latest_urec_ptr[i];
+					if (!UndoRecPtrIsValid(s->parent->start_urec_ptr[i]))
+						s->parent->start_urec_ptr[i] = s->start_urec_ptr[i];
+				}
+
 				CommitSubTransaction();
 				s = CurrentTransactionState;	/* changed by pop */
 			} while (s->blockState == TBLOCK_SUBRELEASE);
@@ -5039,6 +5139,14 @@ TransactionBlockStatusCode(void)
 {
 	TransactionState s = CurrentTransactionState;
 
+	/*
+	 * Here, we just detect whether there are any pending undo actions so that
+	 * we can skip releasing the locks during abort transaction.  We don't
+	 * release the locks till we execute undo actions otherwise, there is a
+	 * risk of deadlock.
+	 */
+	SetUndoActionsInfo();
+
 	switch (s->blockState)
 	{
 		case TBLOCK_DEFAULT:
diff --git a/src/backend/access/transam/xlog.c b/src/backend/access/transam/xlog.c
index 99e4322..d4a6fce 100644
--- a/src/backend/access/transam/xlog.c
+++ b/src/backend/access/transam/xlog.c
@@ -972,6 +972,7 @@ static void WALInsertLockUpdateInsertingAt(XLogRecPtr insertingAt);
 XLogRecPtr
 XLogInsertRecord(XLogRecData *rdata,
 				 XLogRecPtr fpw_lsn,
+				 XLogRecPtr OldRedoRecPtr,
 				 uint8 flags)
 {
 	XLogCtlInsert *Insert = &XLogCtl->Insert;
@@ -1067,6 +1068,20 @@ XLogInsertRecord(XLogRecData *rdata,
 	}
 
 	/*
+	 * If the redo point is changed and wal need to include the undo attach
+	 * information i.e. (this is the first WAL which after the checkpoint).
+	 * then return from here so that the caller can restart.
+	 */
+	if (rechdr->xl_rmid == RM_ZHEAP_ID &&
+		OldRedoRecPtr != InvalidXLogRecPtr &&
+		OldRedoRecPtr != RedoRecPtr)
+	{
+		WALInsertLockRelease();
+		END_CRIT_SECTION();
+		return InvalidXLogRecPtr;
+	}
+
+	/*
 	 * Reserve space for the record in the WAL. This also sets the xl_prev
 	 * pointer.
 	 */
@@ -4520,6 +4535,8 @@ WriteControlFile(void)
 	ControlFile->float4ByVal = FLOAT4PASSBYVAL;
 	ControlFile->float8ByVal = FLOAT8PASSBYVAL;
 
+	ControlFile->zheap_page_trans_slots = ZHEAP_PAGE_TRANS_SLOTS;
+
 	/* Contents are protected with a CRC */
 	INIT_CRC32C(ControlFile->crc);
 	COMP_CRC32C(ControlFile->crc,
@@ -4752,6 +4769,13 @@ ReadControlFile(void)
 						   " but the server was compiled without USE_FLOAT8_BYVAL."),
 				 errhint("It looks like you need to recompile or initdb.")));
 #endif
+	if (ControlFile->zheap_page_trans_slots != ZHEAP_PAGE_TRANS_SLOTS)
+		ereport(FATAL,
+				(errmsg("database files are incompatible with server"),
+				 errdetail("The database cluster was initialized with ZHEAP_PAGE_TRANS_SLOTS %d,"
+						   " but the server was compiled with ZHEAP_PAGE_TRANS_SLOTS %d.",
+						   ControlFile->zheap_page_trans_slots, (int) ZHEAP_PAGE_TRANS_SLOTS),
+				 errhint("It looks like you need to recompile or initdb.")));
 
 	wal_segment_size = ControlFile->xlog_seg_size;
 
@@ -6722,6 +6746,9 @@ StartupXLOG(void)
 	/* Recover undo log meta data corresponding to this checkpoint. */
 	StartupUndoLogs(ControlFile->checkPointCopy.redo);
 
+	/* Recover undo log meta data corresponding to this checkpoint. */
+	StartupUndoLogs(ControlFile->checkPointCopy.redo);
+
 	lastFullPageWrites = checkPoint.fullPageWrites;
 
 	RedoRecPtr = XLogCtl->RedoRecPtr = XLogCtl->Insert.RedoRecPtr = checkPoint.redo;
@@ -8740,7 +8767,6 @@ CreateCheckPoint(int flags)
 	checkPoint.oldestFullXidHavingUnappliedUndo =
 		FullTransactionIdFromU64(pg_atomic_read_u64(&ProcGlobal->oldestFullXidHavingUnappliedUndo));
 
-
 	MultiXactGetCheckptMulti(shutdown,
 							 &checkPoint.nextMulti,
 							 &checkPoint.nextMultiOffset,
@@ -9009,6 +9035,7 @@ CheckPointGuts(XLogRecPtr checkPointRedo, int flags)
 	CheckPointSnapBuild();
 	CheckPointLogicalRewriteHeap();
 	CheckPointBuffers(flags);	/* performs all required fsyncs */
+	CheckPointUndoLogs(checkPointRedo, ControlFile->checkPointCopy.redo);
 	CheckPointReplicationOrigin();
 	/* We deliberately delay 2PC checkpointing as long as possible */
 	CheckPointTwoPhase(checkPointRedo);
@@ -9784,6 +9811,9 @@ xlog_redo(XLogReaderState *record)
 		XLogCtl->ckptFullXid = checkPoint.nextFullXid;
 		SpinLockRelease(&XLogCtl->info_lck);
 
+		/* Write an undo log metadata snapshot. */
+		CheckPointUndoLogs(checkPoint.redo, ControlFile->checkPointCopy.redo);
+
 		/* TLI should not change in an on-line checkpoint */
 		if (checkPoint.ThisTimeLineID != ThisTimeLineID)
 			ereport(PANIC,
diff --git a/src/backend/access/transam/xloginsert.c b/src/backend/access/transam/xloginsert.c
index 001d7cb..90d55e5 100644
--- a/src/backend/access/transam/xloginsert.c
+++ b/src/backend/access/transam/xloginsert.c
@@ -459,7 +459,8 @@ XLogInsert(RmgrId rmid, uint8 info)
 		rdt = XLogRecordAssemble(rmid, info, RedoRecPtr, doPageWrites,
 								 &fpw_lsn);
 
-		EndPos = XLogInsertRecord(rdt, fpw_lsn, curinsert_flags);
+		EndPos = XLogInsertRecord(rdt, fpw_lsn, InvalidXLogRecPtr,
+								  curinsert_flags);
 	} while (EndPos == InvalidXLogRecPtr);
 
 	XLogResetInsertion();
@@ -468,6 +469,63 @@ XLogInsert(RmgrId rmid, uint8 info)
 }
 
 /*
+ * XLogInsertExtended
+ *		Like XLogInsert, but with extra options.
+ *
+ * The internal logic of this function is almost same as XLogInsert, but there
+ * are some differences: unlike XLogInsert, this function will not retry for WAL
+ * insert if the page image inclusion decision got changed instead it will
+ * return immediately, and it will not calculate the latest value of RedoRecPtr
+ * like XLogInsert, instead it will take that as input from caller so that if
+ * the caller has not included the tuple info (because page image is not present
+ * in the WAL) it can start over again if including page image decision got
+ * changed later during WAL insertion.
+ */
+XLogRecPtr
+XLogInsertExtended(RmgrId rmid, uint8 info, XLogRecPtr RedoRecPtr,
+				   bool doPageWrites)
+{
+	XLogRecPtr	EndPos;
+	XLogRecPtr	fpw_lsn;
+	XLogRecData *rdt;
+
+	/* XLogBeginInsert() must have been called. */
+	if (!begininsert_called)
+		elog(ERROR, "XLogBeginInsert was not called");
+
+	/*
+	 * The caller can set rmgr bits, XLR_SPECIAL_REL_UPDATE and
+	 * XLR_CHECK_CONSISTENCY; the rest are reserved for use by me.
+	 */
+	if ((info & ~(XLR_RMGR_INFO_MASK |
+				  XLR_SPECIAL_REL_UPDATE |
+				  XLR_CHECK_CONSISTENCY)) != 0)
+		elog(PANIC, "invalid xlog info mask %02X", info);
+
+	TRACE_POSTGRESQL_WAL_INSERT(rmid, info);
+
+	/*
+	 * In bootstrap mode, we don't actually log anything but XLOG resources;
+	 * return a phony record pointer.
+	 */
+	if (IsBootstrapProcessingMode() && rmid != RM_XLOG_ID)
+	{
+		XLogResetInsertion();
+		EndPos = SizeOfXLogLongPHD; /* start of 1st chkpt record */
+		return EndPos;
+	}
+
+	rdt = XLogRecordAssemble(rmid, info, RedoRecPtr, doPageWrites,
+							 &fpw_lsn);
+
+	EndPos = XLogInsertRecord(rdt, fpw_lsn, RedoRecPtr, curinsert_flags);
+
+	XLogResetInsertion();
+
+	return EndPos;
+}
+
+/*
  * Assemble a WAL record from the registered data and buffers into an
  * XLogRecData chain, ready for insertion with XLogInsertRecord().
  *
@@ -798,8 +856,14 @@ XLogRecordAssemble(RmgrId rmid, uint8 info,
 	 * Fill in the fields in the record header. Prev-link is filled in later,
 	 * once we know where in the WAL the record will be inserted. The CRC does
 	 * not include the record header yet.
+	 *
+	 * Since zheap storage always use TopTransactionId, if this xlog is for
+	 * the zheap then get the TopTransactionId.
 	 */
-	rechdr->xl_xid = GetCurrentTransactionIdIfAny();
+	if (rmid == RM_ZHEAP_ID)
+		rechdr->xl_xid = GetTopTransactionIdIfAny();
+	else
+		rechdr->xl_xid = GetCurrentTransactionIdIfAny();
 	rechdr->xl_tot_len = total_len;
 	rechdr->xl_info = info;
 	rechdr->xl_rmid = rmid;
diff --git a/src/backend/access/undo/undoworker.c b/src/backend/access/undo/undoworker.c
index 4f6927b..ecefe31 100644
--- a/src/backend/access/undo/undoworker.c
+++ b/src/backend/access/undo/undoworker.c
@@ -82,7 +82,7 @@ int			undo_worker_quantum_ms = 10000;
 /* Flags set by signal handlers */
 static volatile sig_atomic_t got_SIGHUP = false;
 static volatile sig_atomic_t got_SIGTERM = false;
-
+static volatile sig_atomic_t got_SIGTERM = false;
 static TimestampTz last_xact_processed_at;
 
 typedef struct UndoApplyWorker
@@ -153,6 +153,16 @@ UndoworkerSigtermHandler(SIGNAL_ARGS)
 	SetLatch(MyLatch);
 }
 
+/* SIGTERM: set flag to exit at next convenient time */
+static void
+UndoworkerSigtermHandler(SIGNAL_ARGS)
+{
+	got_SIGTERM = true;
+
+	/* Waken anything waiting on the process latch */
+	SetLatch(MyLatch);
+}
+
 /* SIGHUP: set flag to reload configuration at next convenient time */
 static void
 UndoLauncherSighup(SIGNAL_ARGS)
diff --git a/src/backend/access/zheap/Makefile b/src/backend/access/zheap/Makefile
new file mode 100644
index 0000000..e8fa271
--- /dev/null
+++ b/src/backend/access/zheap/Makefile
@@ -0,0 +1,20 @@
+#-------------------------------------------------------------------------
+#
+# Makefile--
+#    Makefile for access/zheap
+#
+# IDENTIFICATION
+#    src/backend/access/zheap/Makefile
+#
+#-------------------------------------------------------------------------
+
+subdir = src/backend/access/zheap
+top_builddir = ../../../..
+include $(top_builddir)/src/Makefile.global
+
+OBJS = prunetpd.o prunezheap.o rewritezheap.o tpd.o tpdxlog.o zheapam.o \
+	zheapam_handler.o zheapam_visibility.o zheapamxlog.o zhio.o \
+	zmultilocker.o zpage.o zscan.o ztuple.o zundo.o zvacuumlazy.o \
+	ztuptoaster.o
+
+include $(top_srcdir)/src/backend/common.mk
diff --git a/src/backend/access/zheap/README b/src/backend/access/zheap/README
new file mode 100644
index 0000000..31f1269
--- /dev/null
+++ b/src/backend/access/zheap/README
@@ -0,0 +1,591 @@
+src/backend/access/zheap/README
+
+Zheap
+=====
+
+The main purpose of this README is to provide an overview of the current
+design of zheap, a new storage format for PostgreSQL.  This project has three
+major objectives:
+
+1. Provide better control over bloat.  In the existing  heap, we always create
+a new version of tuple when it is  updated. These new versions are later
+removed by vacuum or hot-pruning, but this only frees up space for reuse by
+future inserts or updates; nothing is returned to the operating system.  A
+similar problem occurs for tuples that are deleted. zheap will prevent bloat
+(a) by allowing in-place updates in common cases and (b) by reusing space as
+soon as a transaction that has performed a delete or non-in-place-update has
+committed.  In short, with this new storage, whenever possible, well avoid
+creating bloat in the first place.
+
+2. Reduce write amplification both by avoiding rewrites of heap pages and by
+making it possible to do an update that touches indexed columns without
+updating every index.
+
+3. Reduce the tuple size by (a) shrinking the  tuple header and
+(b) eliminating most alignment padding.
+
+In-place updates will be supported except when (a) the new tuple is larger
+than the old tuple and the increase in size makes it impossible to fit the
+larger tuple onto the same page or (b) some column is modified which is
+covered by an index that has not been modified to support delete-marking.
+We have not begun work on delete-marking support for indexes yet, but intend
+to support it at least for btree indexes.
+
+General idea of zheap with undo
+--------------------------------
+Each backend is attached to a separate undo log to which it writes undo
+records.  Each undo record is identified by a 64-bit undo record pointer of
+which the first 24 bits are used for the log number and the remaining 40 bits
+are used for an offset within that undo log.  Only one transaction at a time
+can write to any given undo log, so the undo records for any given transaction
+are always consecutive.
+
+Each zheap page has fixed set of transaction slots each of which contains the
+transaction information (transaction id and epoch) and the latest undo record
+pointer for that transaction.  As of now, we have four transaction slots per
+page, but this can be changed.  Currently, this is a compile-time option;  we
+can decide later whether such an option is desirable in general for users.
+Each transaction slot occupies 16 bytes. We allow the transaction slots to be
+reused after the transaction is committed which allows us to operate without
+needing too many slots.  We can allow slots to be reused after a transaction
+abort as well, once undo actions are complete.  We have observed that smaller
+tables say having very few pages typically need more slots; for larger tables,
+four slots are enough.  In our internal testing, we have found that 16 slots
+give a very good performance, but more tests are needed to identify the right
+number of slots.  The one known problem with the fixed number of slots is that
+it can lead to deadlock, so we are planning to add  a mechanism to allow the
+array of transactions slots to be continued on a separate overflow page.  We
+also need such a mechanism to support cases where a large number of
+transactions acquire SHARE or KEY SHARE locks on a single page.  The overflow
+pages will be stored in the zheap itself, interleaved with regular pages.
+These overflow pages will be marked in such a way that sequential scans will
+ignore them.  We will have a meta page in zheap from which all overflow pages
+will be tracked.
+
+Typically, each zheap operation that modifies a page needs to first allocate a
+transaction slot on that page and then prepare an undo record for the operation.
+Then, in a critical section, it must write the undo record, perform the
+operation on heap page, update the transaction slot in a page, and finally
+write a WAL record for the operation.  What we write as part of undo record
+and WAL depends on the operation.
+
+Insert: Apart from the generic info, we write the TID (block number and offset
+number) of the tuple in undo record to identify the record during undo replay.
+In WAL, we write the offset number and the tuple, plus some minimal
+information which will be needed to regenerate the undo record during replay.
+
+Delete: We write the complete tuple in the undo record even though we could get
+away with just  writing the TID as we do for an insert operation.  This allows
+us to reuse the space occupied by the deleted record as soon as the transaction
+that has performed the operation commits.  In WAL, we need to write the tuple
+only if full page writes are not enabled.  If full page writes are enabled, we
+can rely on the page state to be same during recovery as it is during the
+actual operation, so we can retrieve the tuple from page to copy it into the
+undo record.
+
+Update: For in-place updates, we have to write the old tuple in the undo log
+and the new tuple in the zheap.  We could optimize and write the diff tuple
+instead of the complete tuple in undo, but as of now, we are writing the
+complete tuple.  For non-in-place updates, we write the old tuple and the new
+TID in undo; essentially this is equivalent to DELETE+INSERT.  As for DELETE,
+this allows space to be recycled as soon as the updating transaction commits.
+In the WAL, we write a copy of the old tuple only if full pages writes are off
+and we write diff tuple for the new tuple (irrespective of the value of
+full-page writes) as we do in a current heap.  In the case where a
+non-in-place-update happens to insert new tuple on a separate page, we write
+two undo records, one for old page and another for the new page.  One can
+imagine that writing one undo record would be sufficient as we generally reach
+to a new tuple from old tuple if required, but we want to maintain a separate
+undo chain for each page.
+
+Select .. For [Key] Share/Update
+Tuple locking will work much like a DML operation: reserve a transaction slot,
+update the tuple header with the lock information, write UNDO and WAL for the
+operation.  To detect conflicts, we sometimes need to traverse the undo chains
+of all the active transactions on a page.  We will always mark the tuple with
+the strongest lock mode that might be present, just as is done in the current
+heap, so that we can cheaply detect whether there is a potential conflict.  If
+there is, we must get information about all the locks from undo in order to
+decide whether there is an actual conflict.  The tuple will always contain
+either the strongest locker information or if all the lockers are of same
+strength, then it will contain the latest locker information.  Whenever there
+is more than one locker operating on a tuple, we set the multi-locker bit on a
+tuple to indicate that the tuple has multiple lockers. Note, that we clear the
+multi-locker bit lazily (which means when we decide to wait for all the
+lockers to go away and there is no more locker alive on the tuple).  During
+Rollback operation, we retain the strongest locker information on the tuple
+if there are multiple lockers on a tuple. This is because the conflict
+detection mechanism works based on strongest locker.  Now, even if we want to
+remove strongest locker information, we don't have second strongest locker
+information handy.
+
+Copy: Similar to insert, we need to store the corresponding TID (block number,
+offset number) for a tuple in undo to identify the same during undo replay. But,
+we can minimize the number of undo records written for a page. First, we
+identify the unused offset ranges for a page, then insert one undo record for
+each offset range. For example, if were about to insert in offsets
+(2,3,5,9,10,11), we insert three undo records covering offset ranges (2,3),
+(5,5), and (9,11), respectively. For recovery, we insert a single WAL record
+containing the above-mentioned offset ranges along with some minimal
+information to regenerate the undo records and tuples.
+
+Scans: During scans, we need to make a copy of the tuple instead of just
+holding the pin on a page.  In the current heap, holding a pin on the buffer
+containing the tuple is sufficient because operations like vacuum which can
+rearrange the page always take a cleanup lock on a buffer. In zheap, however,
+in-place-updates work with just a exclusive lock on a buffer, so a tuple to
+which we hold a pointer might be updated under us.
+
+Insert .. On Conflict: The design is similar to current heap such that we use the
+speculative token to detect conflicts.  We store the speculative token in undo
+instead of in the tuple header (CTID) simply because zheaps tuple header
+doesnt have CTID. Additionally, we set a bit in tuple header to indicate
+speculative insertion.  ZheapTupleSatisfiesDirty routine checks this bit and
+fetches a speculative token from undo.
+
+Toast Tables: Toast tables can use zheap, too.  Since zheap uses shorter tuple
+headers, this saves space. In the future, someone might want to support
+in-place updates for toast table data instead of doing delete+insert as we do
+today.
+
+Transaction slot reuse
+-----------------------
+Transaction slots can be freely reused if the transaction is committed and
+all-visible, or if the transaction is aborted and undo actions for that
+transaction, at least relating to that page, have been performed.  If the
+transaction is committed but not yet all-visible, we can reuse the slot after
+writing an additional, special undo record that lets us make subsequent tuple
+visibility decisions correctly.
+
+For committed transactions, there are two possibilities.  If the transaction
+slot is not referenced by any tuple in the page, we simply clear the xid from
+the transaction slot. The undo record pointer is kept as it is to ensure that
+we don't break the undo chain for that slot.  Otherwise, we write an undo
+record for each tuple that points to one of the committed transactions.  We
+also mark the tuple indicating that the associated slot has been reused.  In
+such a case, it is quite possible that the tuple has not been modified, but it
+is still pointing to transaction slot which has been reused for a new
+transaction which is not yet all-visible.  During the visibility check for
+such a tuple, it might appear that the tuple is modified by a current
+transaction which is clearly wrong and can lead to wrong results.
+
+Subtransactions
+----------------
+zheap only uses the toplevel transaction ID; subtransactions that modify a
+zheap do not need separate transaction IDs.  In the regular heap, when
+subtransactions are present, the subtransactions XID is used to make tuple
+visibility decisions correctly.  In a zheap, subtransaction abort is instead
+handled by using undo to reverse changes to the zheap pages. This design
+minimizes consumption of transaction slots and pg_xact space, and ensures that
+all undo records for a toplevel transaction remain consecutive in the undo
+log.
+
+Reclaiming space within a page
+-------------------------------
+Space can be reclaimed within a page after (a) a delete, (b) a non-in-place
+update, or (c) an in-place update that reduces the width of the tuple. We can
+reuse the space when as soon as  the transaction that has performed the
+operation has committed.  We can also reclaim space after inserts or
+non-in-place updates have been undone.  There is some difference between the
+way space is reclaimed for transactions that are committed and all-visible vs.
+the transactions that are committed but still not all-visible. In the former
+case, we can just indicate in the line pointer that the corresponding item is
+dead whereas for later we need the capability to fetch the prior version of a
+tuple for transactions to which the delete is not visible. To allow that, we
+copy the transaction slot information into the line pointer so that we can
+easily reach the prior version of the tuple.  As a net result, the space for a
+deleted tuple can be reclaimed immediately after the delete commits, but the
+space consumed by line pointer can only be freed once we delete the
+corresponding index tuples.  For an aborted transaction, space can be
+reclaimed once undo is complete.  We set the prune xid in page header during
+delete or update operations and during rollback of inserts to permit pruning
+to happen only when there is a possible benefit.  When we try to prune, we
+first check if the prune xid is in progress; only if not will we attempt to
+prune the page.
+
+Pruning will be attempted when update operation lands to a page where there is
+not enough space to accommodate a new tuple.  We can also allow pruning to
+occur when we evict the page from shared buffers or read the page from disk as
+those are I/O intensive operations, so doing some CPU intensive operation
+doesn't cost much.
+
+With the above idea, it is quite possible that sometimes we try to prune the
+page when there is no immediate benefit of doing so. For example, even after
+pruning, the page might still not have enough space in the page to accommodate
+new tuple.  One idea is to track the space at the transaction slot level, so
+that we can know exactly how much space can be freed in page after pruning,
+but that will lead to increase in a space used by each transaction slot.
+
+We can also reuse space if a transaction frees up space on the page (e.g. by
+delete) and then tries to use additional space (e.g. by a subsequent insert).
+We cant in general reuse space freed up by a transaction until it commits,
+because if it aborts well need that space during undo; but an insert or
+update could reuse space freed up by earlier operations in the same
+transaction, since all or none of them will roll back. This is a good
+optimization, but this needs some more thought.
+
+Free Space Map
+---------------
+We can optimistically update the freespace map when we remove the tuples from
+a page in the hope that eventually most of the transactions will commit and
+space will be available. Additionally, we might want to update FSM during
+aborts when space-consuming actions like inserts are rolled back.  When
+requesting free space, we would need to adjust things so that we continue the
+search from the previous block instead of repeatedly returning the same block.
+
+I think updating it on every such operation can be costly, so we can perform
+it only after some threshold number, so later we might want to add a facility
+to track potentially available freespace and merge into the main data
+structure.  We also want to make FSM crash-safe, since we cant count on
+VACUUM to recover free space that we neglect to record.
+
+Page format
+------------
+zheap uses a standard page header,  stores transaction slots in the special
+space.
+
+Tuple format
+-------------
+The tuple header is reduced from 24 bytes to 5 bytes (8 bytes with alignment):
+2 bytes each for informask and infomask2, and one byte for t_hoff.  I think we
+might be able to squeeze some space from t_infomask, but for now, I have kept
+it as two bytes.  All transactional information is stored in undo, so fields
+that store such information are not needed here.
+
+The idea is that we occupy somewhat more space at the page level, but save
+much more at tuple level, so we come out ahead overall.
+
+Alignment padding
+------------------
+We omit all alignment padding for pass-by-value types. Even in the current heap,
+we never point directly to such values, so the alignment padding doesnt help
+much; it lets us fetch the value using a single instruction, but that is all.
+Pass-by-reference types will work as they do in the heap.  Many pass-by-reference
+data types will be varlena data types (typlen = -1) with short varlena headers so
+no alignment padding will be introduced in that case anyway, but if we have varlenas
+with 4-byte headers or if we have fixed-length pass-by-reference types (e.g. interval,
+box) then we'll still end up with padding.  We can't directly access unaligned values;
+instead, we need to use memcpy.  We believe that the space savings will more than pay
+for the additional CPU costs.
+
+We dont need alignment padding between the tuple header and the tuple data as
+we always make a copy of the tuple to support in-place updates. Likewise, we ideally
+don't need any alignment padding between tuples. However, there are places in zheap
+code where we access tuple header directly from page (e.g. zheap_delete, zheap_update,
+etc.) for which we want them to be aligned at two-byte boundary).
+
+Undo chain
+-----------
+Each undo record header contains the location of previous undo record pointer
+of the transaction that is performing the operation.  For example, if
+transaction T1 has updated the tuple two times, the undo record for the last
+update will have a link for undo record of the previous update.  Thus, the
+undo records for a particular page in a particular transaction form a single,
+linked chain.
+
+Snapshots and visibility
+-------------------------
+Given a TID and a snapshot, there are three possibilities: (a) the tuple
+currently stored at the given TID; (b) some tuple previously stored at the
+given TID and subsequently written to the undo log might be visible; or
+(c) there might be nothing visible at all.  To check the visibility of a
+tuple, we fetch the transaction slot number stored in the tuple header, and
+then get the transaction id and undo record pointer from transaction slot.
+Next, we check the current tuples visibility based on transaction id fetched
+from transaction slot and the last operation performed on the tuple.  For
+example, if the last operation on tuple is a delete and the xid is visible to
+our snapshot, then we return NULL indicating no visible tuple. But if the xid
+that has last operated on tuple is not visible to the snapshot, then we use
+the undo record pointer to fetch the prior tuple from undo and similarly check
+its visibility.  The only difference in checking the visibility for the undo
+tuple is that the xid that previously operated on undo tuple is present in the
+undo record, so we can use that instead of relying on the transaction slot.
+If the tuple from undo is also not visible, then we fetch the prior tuple from
+the undo chain.  We need to traverse undo chains until we find a visible tuple
+or reach the initially inserted tuple; if that is also not visible, we can
+return NULL.
+
+During visibility checking of a tuple in a zheap page or an undo chain, if we
+find that the tuples transaction slot has been reused, we retrieve the
+transaction information (xid and cid that has modified the tuple) of that
+tuple from undo.
+
+EvalPlanQual mechanism
+-----------------------
+This works in basically the same way as for the existing heap. The only
+special consideration is that the updated tuple could have the same TID as the
+original one if it was updated in place, so we might want to optimize such
+that we need not release the buffer lock and again refetch the tuple.
+However, at this stage, we are not sure if there is any big advantage in such
+an optimization.
+
+64-bit transaction ids
+-----------------------
+Transaction slots in zheap pages store both the epoch and the XID; this
+eliminates the confusion between a use of a given XID in the current epoch and
+a use in some previous epoch, which means that we never need to freeze tuples.
+The difference between the oldest running XID and the newest XID is still
+limited to 2 billion because of the way that snapshots work.  Moreover, the
+oldest XID that still has undo must have an XID age less than 2 billion: among
+other problems, this is currently the limit for how long commit status data
+can be retained, and it would be bad if we had undo data but didnt know
+whether or not to apply the undo actions.  Currently, this limitation is
+enforced by piggybacking on the existing wraparound machinery.
+
+Indexing
+---------
+Current index AMs are not prepared to cope with multiple tuples at the same
+TID with different values stored in the index column.  We plan to introduce
+special index AM support for in-place updates; when an index lacks such
+support, any modification to the value stored in a column covered by that
+index will prevent the use of in-place update.  Additionally, indexes lacking
+such support will still require routine vacuuming, which we believe can be
+avoided when such support is present.
+
+The basic idea is that we need to delete-mark index entries when they might no
+longer be valid, either because of a delete or because of an update affecting
+the indexed column.  An in-place update that does not modify the indexed
+column need not delete-mark the corresponding index entries.  Note that an
+entry which is delete-marked might still be valid for some snapshots; once no
+relevant snapshots remain, we can remove the entry.  In some cases, we may
+remove a delete-mark from an entry rather than removing the entry, either
+because the transaction which applied the delete-mark has rolled back, or
+because the indexed column was changed from value A to value B and then
+eventually back to value A.
+It is very desirable for performance reasons to have be able to distinguish
+from the index page whether or not the corresponding heap tuple is definitely
+all-visible, but the delete-marking approach is not quite sufficient for this
+purpose unless recently-inserted tuples are also delete-marked -- and that is
+undesirable, since the delete-markings would have to be cleared after the
+inserting transaction committed, which might end up dirtying many or all
+index pages.  An alternative approach is to write undo for index insertions;
+then, the undo pointers in the index page tells us whether any index entries
+on that page may be recently-inserted, and the presence or absence of a
+delete-mark tells us whether any index entries on that page may no longer be
+valid.  We intend to adopt this approach; it should allow index-only scans in
+most cases without the need for a separately-maintained visibility map.
+
+With this approach, an in-place update touches each index whose indexed
+columns are modified twice -- once to delete-mark the old entry (or entries)
+and once to insert the new entries.  In some use cases, this will compare
+favorably with the existing approach, which touches every index exactly once.
+Specifically, it figures to reduce write amplification and index bloat when
+only one or a few indexed columns are updated at a time.
+
+Indexes that don't have delete-marking
+---------------------------------------
+Although indexes which lack delete-marking support still require vacuum, we
+can use undo to reduce the current three-pass approach to just two passes,
+avoiding the final heap scan.  When a row is deleted, the vacuum will directly
+mark the line pointer as unused, writing an undo record as it does,  and then
+mark the corresponding index entries as dead.  If vacuum fails midway through
+the undo can ensure that changes to the heap page are rolled back.  If the
+vacuum goes on to commit, we don't need to revisit the heap page after index
+cleanup.
+
+We must be careful about  TID reuse: we will only allow a TID to be reused
+when the transaction that has marked it as unused has committed. At that
+point, we can be assured that all the index entries corresponding to dead
+tuples will be marked as dead.
+
+Undo actions
+-------------
+We need to apply undo actions during explicit ROLLBACK or ROLLBACK TO
+SAVEPOINT operations and when an error causes a transaction or subtransaction
+abort.  These actions reverse whatever work was done when the operation was
+performed; for example, if an update aborts, we must restore the old version
+of the tuple.  During an explicit ROLLBACK or ROLLBACK TO SAVEPOINT, the
+transaction is in a good state and we have relevant locks on objects, so
+applying undo actions is straightforward, but the same is not true in error
+paths.  In the case of a subtransaction abort, undo actions are performed
+after rolling back the subtransaction; the parent transaction is still good.
+In the case of a top-level abort, we begin an entirely new transaction to
+perform the undo actions.  If this new transaction aborts, it can be retried
+later.  For short transactions (say, one which generates only few kB of undo
+data), it is okay to apply the actions in the foreground but for longer
+transactions, it is advisable to delegate the work to an undo worker running
+in the background.  The user is provided with a knob to control this behavior.
+
+Just like the DML operations to which they correspond, undo actions require us
+to write WAL.  Otherwise, we would be unable to recover after a crash, and
+standby servers would not be properly updated.
+
+Applying undo actions
+----------------------
+In many cases, the same page will be modified multiple times by the same
+transaction.  We can save locking and reduce WAL generation by collecting all
+of the undo records for a given page and then applying them all at once.
+However, its difficult to collect all of the records that might apply to a
+page from an arbitrarily large undo log in an efficient manner; in particular,
+we want to avoid rereading the same undo pages multiple times.  Currently, we
+collect all consecutive records which apply to the same page and then apply
+them at one shot.  This will cover the cases where most of the changes to heap
+pages are performed together.  This algorithm could be improved.  For example,
+we could do something like this:
+
+1. Read the last 32MB of undo for the transaction being undone (or all of the
+undo for the transaction, if there is less than 32MB).
+2. For each block that is touched by at least one record in the 32MB chunk,
+consolidate all records from this chunk that apply to that block.
+3. Sort the blocks by buffer tag and apply the changes in ascending
+block-number order within each relation.  Do this even for incomplete chains,
+so nothing is saved for later.
+4. Go to step 1.
+
+After applying undo actions for a page, we clear the transaction slot on a
+page if the oldest undo record we applied is the oldest undo record for that
+block generated by that transaction. Otherwise, we rewind the undo pointer in
+the page slot to the last record for that block that precedes the last undo
+record we applied.  Because applying undo also always updates the transaction
+slot on the page, either rewinding it or clearing it completely, we can
+always skip applying undo if we find that its already been applied
+previously.  This could happen if the application of undo for a given
+transaction is interrupted a crash, or if it fails for some reason and is
+retried later.
+
+This also prevents us from getting confused when the relation is (a) dropped,
+(b) rewritten using a new relfilenode, or (c) truncated to a shorter length
+(and perhaps subsequently re-extended).  We apply the undo action only if the
+page contains the effect of the transaction for which we are applying undo
+actions, which can always be determined by examining the undo pointer in the
+transaction slot. If there is no transaction slot for the current transaction
+or if it is present but the undo record pointer in the slot is less than the
+undo record pointer of the undo record under consideration, the undo record
+can be ignored; it has already been applied or is no longer relevant.  After a
+toplevel transaction abort, undo space is not recycled.  However, after a
+subtransaction abort, we rewind the insert pointer to wherever it was at the
+start of the subtransaction, so that the undo for the toplevel transaction
+remains contiguous.  We cant do the same for toplevel aborts as that might
+contain special undo records related to transaction slots that were reused and
+we cant afford to lose those.  We write these special undo records only for
+toplevel transaction when it doesnt find any free transaction slot or there
+is no transaction slot which contains transaction that is all-visible.  In
+such cases, we reuse the committed transaction slots and write undo record
+which contains transaction information for them as we might need that
+information for transaction which still cant see the committed transaction.
+We mark all such slots (that belongs to committed transactions) as available
+for reuse in one shot as doing it one slot at a time is quite costly.  Since
+we might still need the special undo records for the transaction slots other
+than the current transaction, we cant simply rewind the insert pointer.  Note
+that we do this only for toplevel transactions; if we need the new slot when
+in a subtransaction, we reclaim only a single transaction slot.
+
+WAL consideration
+------------------
+Undo records are critical data and must be protected via WAL.  Because an undo
+record must be written if and only if a page modification occurs, the undo
+record and the record for the page modification must be one and the same.
+Moreover, it is very important not to duplicate any information or store any
+unnecessary information, since WAL volume has a significant impact on overall
+system performance.  In particular, there is no need to log the undo record
+pointer.  We only need to ensure that after crash recovery undo record pointer
+is set correctly for each of the undo logs.  To ensure that, we log a WAL
+record after XID change or at the first operation after checkpoint on undo
+log.  The WAL record contains the information of insert point, log number, and
+Xid.  This is enough to form an XID->(Log no. + Log insertion point) map which
+will be used to calculate the location of undo insertion during recovery.
+
+Another important consideration is that we don't need to have full page images
+for data in undo logs. Because the undo logs are always written serially, torn
+pages are not an issue.  Suppose that  some block in one of the undo log is
+half filled and synced properly to disk; now, a checkpoint occurs  Next, we
+add some more data to the block.  During the following checkpoint, the system
+crashes while flushing the block.  The block could be in a condition such that
+first few bytes of it say 512 bytes are flushed appropriately and rest are
+old, but this won't cause problem because anyway old bytes will be intact and
+we can always start inserting new records at insert location in undo
+reconstructed during recovery.
+
+Undo Worker
+------------
+Currently, we have one background undo worker which performs undo actions as
+required and discards undo logs when they are no longer needed.  Typically, it
+performs undo actions in response to a notification from a backend that has
+just aborted a transaction, but it will eventually detect and perform undo
+actions for any aborted transaction that does not otherwise get cleaned up.
+
+We allow the undo worker to hibernate when there is no activity in the system.
+It hibernates for a minimum of 100ms and maximum of 10s, based on the time
+the system has remained idle.  The undo worker mechanism will be extended to
+multiple undo workers to perform various jobs related to undo logs. For
+example, if there are many pending rollback requests, then we can spawn a new
+undo worker which can help in processing the requests.
+
+UndoDiscard routine will be called by the undo worker for discarding the old
+undo records. UndoDiscard will process all the active undo logs.   It reads
+each undo log and checks whether the log corresponding to the first
+transaction in a log can be discarded (committed and all visible or aborted
+and undo already applied). If so, it moves to the next transaction in that
+undo log and continues in the same way. When it finds the first transaction
+whose undo  can't be discard yet, it first discards the undo log prior to that
+point and then remembers the transaction ID and undo location in shared memory.
+We consider undo for a transaction to be discardable once its XID  is smaller
+than oldestXmin.
+
+Ideally, for the aborted transactions once the undo actions are replayed, we
+should be able to discard its undo, however, it might contain the undo records
+for reused transaction slots, so we cant discard them until it becomes
+smaller than oldestXmin.  Also, we cant discard the undo for the aborted
+transaction if there is a preceding transaction which is committed and not
+all-visible.  We can allow undo for aborted transactions to be discarded
+immediately if we remember in the first undo record of the transaction whether
+it contains undo of reused transaction slot.  This will help the cases where
+the aborted transaction is the last transaction in undo log which is smaller
+than oldestXmin.
+
+In Hot Standby mode, undo is discarded via WAL replay.  Before discarding
+undo, we ensure that there are no queries running which need to get tuple from
+discarded undo.  If there are any, a recovery conflict will occur, similar to
+what happens in other cases where a resource held by a particular backend
+prevents replay from advancing.
+
+For each undo log, the undo discard module maintains in memory array to hold
+the latest undiscarded xid and its start undo record pointer.  The first XID
+in the undo log will be compared against GlobalXmin, if the xid is greater
+than GlobalXmin then nothing can be discarded;  otherwise, scan  the undo log
+starting with the oldest transaction it contains. To avoid processing every
+record in the undo log, we maintain a transaction start header in the first
+undo record written by any given transaction with space to store a pointer to
+the next transaction start undo record in that same undo log. This allows us
+to read an undo log transaction by transaction.  When discarding undo, the
+background worker will read all active undo logs transaction by transaction
+until it finds a transaction with an XID greater than equal to the GlobalXmin.
+Once it finds such a transaction, it will discard all earlier undo records in
+that undo log, without even writing unflushed buffers to disk.
+
+Avoid fetching discarded undo record
+-------------------------------------
+The system must never attempt to fetch undo records which have already been
+discarded.  Undo is generally discarded in the background by the undo worker,
+so we must account for the possibility that undo could be discarded at any
+time.  We do maintain the oldest xid that have undo (oldestXidHavingUndo).
+Undo worker updates the value of oldestXidHavingUndo after discarding all the
+undo.  Backends consider all transactions that precede oldestXidHavingUndo as
+all-visible, so they normally dont try to fetch the undo which is already
+discarded.  However, there is a race condition where backend decides that the
+transaction is greater than oldestXidHavingUndo and it needs to fetch the undo
+record and in the meantime undo worker discards the corresponding undo record.
+To handle such race conditions, we need to maintain some synchronization
+between backends and undo worker so that backends dont try to access already
+discarded undo.  So whenever undo fetch is trying to read a undo record from
+an undo log, first it needs to acquire a log->discard_lock in SHARED mode for
+the undo log and check that the undo record pointer is not less than
+log->oldest_data, if so, then don't fetch that undo record and return
+NULL (that means the previous version is all visible).  And undo worker will
+take log->discard_lock in EXCLUSIVE mode for updating the
+log->oldest_data. We hold this lock just to update the value in shared
+memory, the actual discard happens outside this lock.
+
+Undo Log Storage
+-----------------
+This subsystem is responsible for life cycle management of undo logs and
+backing files, associating undo logs with backends, allocating and managing
+space within undo logs.  It provides access to undo log contents via shared
+buffers. The list of available undo logs is maintained in shared memory.
+Whenever a backend request for undo log allocation, it attaches a first free
+undo log to a backend, and if all existing undo logs are busy, it will create
+a new one. A set of APIs is provided by this subsystem to efficiently allocate
+and discard undo logs.
+
+During a checkpoint, all the undo segment files and undo meta data files will
+be flushed to the disk.
diff --git a/src/backend/access/zheap/prunetpd.c b/src/backend/access/zheap/prunetpd.c
new file mode 100644
index 0000000..2936c9a
--- /dev/null
+++ b/src/backend/access/zheap/prunetpd.c
@@ -0,0 +1,512 @@
+/*-------------------------------------------------------------------------
+ *
+ * prunetpd.c
+ *	  TPD page pruning
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/zheap/prunetpd.c
+ *
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include "access/tpd.h"
+#include "access/tpd_xlog.h"
+#include "miscadmin.h"
+#include "storage/bufpage.h"
+#include "storage/freespace.h"
+#include "storage/proc.h"
+
+typedef struct TPDPruneState
+{
+	int			nunused;
+	OffsetNumber nowunused[MaxTPDTuplesPerPage];
+} TPDPruneState;
+
+static void TPDEntryPrune(Buffer buf, OffsetNumber offnum, TPDPruneState *prstate,
+						  Size *space_freed);
+static XLogRecPtr LogTPDClean(Relation rel, Buffer tpdbuf,
+							  OffsetNumber *nowunused, int nunused,
+							  OffsetNumber target_offnum, Size space_required);
+static int	TPDPruneEntirePage(Relation rel, Buffer tpdbuf);
+
+/*
+ * TPDPagePrune - Prune the TPD page.
+ *
+ * Process all the TPD entries in the page and remove the old entries which
+ * are all-visible.  We first collect all such entries and then process them
+ * in one-shot.
+ *
+ * We expect caller must have an exclusive lock on the page.
+ *
+ * Returns the number of entries pruned.
+ */
+int
+TPDPagePrune(Relation rel, Buffer tpdbuf, BufferAccessStrategy strategy,
+			 OffsetNumber target_offnum, Size space_required, bool can_free,
+			 bool *update_tpd_inplace, bool *tpd_e_pruned)
+{
+	Page		tpdpage,
+				tmppage = NULL;
+	TPDPageOpaque tpdopaque;
+	TPDPruneState prstate;
+	OffsetNumber offnum,
+				maxoff;
+	ItemId		itemId;
+	Size		space_freed;
+	FullTransactionId	oldest_fxid_having_undo;
+
+	prstate.nunused = 0;
+	tpdpage = BufferGetPage(tpdbuf);
+
+	/* Page should be a TPD page. */
+	Assert(IsTPDPage(tpdpage));
+
+	/* Initialize the out variables. */
+	if (update_tpd_inplace)
+		*update_tpd_inplace = false;
+	if (tpd_e_pruned)
+		*tpd_e_pruned = false;
+
+	/* Can we prune the entire page? */
+	tpdopaque = (TPDPageOpaque) PageGetSpecialPointer(tpdpage);
+	oldest_fxid_having_undo = FullTransactionIdFromU64(
+							   pg_atomic_read_u64(&ProcGlobal->oldestFullXidHavingUnappliedUndo));
+	if (FullTransactionIdPrecedes(tpdopaque->tpd_latest_fxid, oldest_fxid_having_undo))
+	{
+		prstate.nunused = TPDPruneEntirePage(rel, tpdbuf);
+		goto free_tpd_page;
+	}
+
+	/* initialize the space_free with already existing free space in page */
+	space_freed = PageGetExactFreeSpace(tpdpage);
+
+	/* Scan the page */
+	maxoff = PageGetMaxOffsetNumber(tpdpage);
+	for (offnum = FirstOffsetNumber;
+		 offnum <= maxoff;
+		 offnum = OffsetNumberNext(offnum))
+	{
+		itemId = PageGetItemId(tpdpage, offnum);
+
+		/* Nothing to do if slot is empty. */
+		if (!ItemIdIsUsed(itemId))
+			continue;
+
+		TPDEntryPrune(tpdbuf, offnum, &prstate, &space_freed);
+	}
+
+	/*
+	 * There is not much advantage in continuing, if we can't free the space
+	 * required by the caller or we are not asked to forcefully prune the
+	 * page.
+	 *
+	 * XXX - In theory, we can still continue and perform pruning in the hope
+	 * that some future update in this page will be able to use that space.
+	 * However, it will lead to additional writes without any guaranteed
+	 * benefit, so we skip the pruning for now.
+	 */
+	if (space_freed < space_required)
+		return 0;
+
+	/*
+	 * We prepare the temporary copy of the page so that during page repair
+	 * fragmentation we can use it to copy the actual tuples.
+	 */
+	if (prstate.nunused > 0 || OffsetNumberIsValid(target_offnum))
+		tmppage = PageGetTempPageCopy(tpdpage);
+
+	/* Any error while applying the changes is critical */
+	START_CRIT_SECTION();
+
+	/*
+	 * Have we found any prunable items or caller has asked us to make space
+	 * next to target_offnum?
+	 */
+	if (prstate.nunused > 0 || OffsetNumberIsValid(target_offnum))
+	{
+		/*
+		 * Apply the planned item changes, then repair page fragmentation, and
+		 * update the page's hint bit about whether it has free line pointers.
+		 */
+		TPDPagePruneExecute(tpdbuf, prstate.nowunused, prstate.nunused);
+
+		/*
+		 * Finally, repair any fragmentation, and update the page's hint bit
+		 * about whether it has free pointers.  It is quite possible that
+		 * there are no prunable items on the page in which case it will
+		 * rearrange the page to make the space at the required offset.
+		 */
+		TPDPageRepairFragmentation(tpdpage, tmppage, target_offnum,
+								   space_required);
+
+		MarkBufferDirty(tpdbuf);
+
+		/*
+		 * Emit a WAL TPD_CLEAN record showing what we did.
+		 *
+		 * XXX Unlike heap pruning, we don't need to remember latestRemovedXid
+		 * for the purpose of generating conflicts on standby.  We use
+		 * oldestXidHavingUndo as the horizon to prune the TPD entries which
+		 * means all the prior undo must have discarded and during undo
+		 * discard we already generate such xid (see undolog_xlog_discard)
+		 * which should serve our purpose as this WAL must reach after that.
+		 */
+		if (RelationNeedsWAL(rel))
+		{
+			XLogRecPtr	recptr;
+
+			recptr = LogTPDClean(rel, tpdbuf, prstate.nowunused,
+								 prstate.nunused, target_offnum,
+								 space_required);
+
+			PageSetLSN(tpdpage, recptr);
+		}
+
+		if (update_tpd_inplace)
+			*update_tpd_inplace = true;
+	}
+
+	END_CRIT_SECTION();
+
+	/* be tidy. */
+	if (tmppage)
+		pfree(tmppage);
+
+free_tpd_page:
+	if (can_free && PageIsEmpty(tpdpage))
+	{
+		Size		freespace;
+
+		/* If the page is empty, we have certainly pruned all the tpd entries. */
+		if (tpd_e_pruned)
+			*tpd_e_pruned = true;
+
+		/*
+		 * We can reuse empty page as either a heap page or a TPD page, so no
+		 * need to consider opaque space.
+		 */
+		freespace = BLCKSZ - SizeOfPageHeaderData;
+
+		/*
+		 * TPD page is empty, remove it from TPD used page list and record it
+		 * in FSM.
+		 */
+		if (TPDFreePage(rel, tpdbuf, strategy))
+			RecordPageWithFreeSpace(rel, BufferGetBlockNumber(tpdbuf),
+									freespace);
+	}
+
+	return prstate.nunused;
+}
+
+/*
+ * TPDEntryPrune - Check whether the TPD entry is prunable.
+ *
+ * Process all the transaction slots of a TPD entry present at a given offset.
+ * TPD entry will be considered prunable, if all the transaction slots either
+ * contains transaction that is older than oldestXidHavingUndo or
+ * doesn't have a valid transaction.
+ */
+static void
+TPDEntryPrune(Buffer tpdbuf, OffsetNumber offnum, TPDPruneState *prstate,
+			  Size *space_freed)
+{
+	Page		tpdpage;
+	TPDEntryHeaderData tpd_e_hdr;
+	TransInfo  *trans_slots;
+	ItemId		itemId;
+	Size		size_tpd_e_slots,
+				size_tpd_e_map;
+	Size		size_tpd_entry;
+	int			num_trans_slots,
+				slot_no;
+	int			loc_trans_slots;
+	uint16		tpd_e_offset;
+	bool		prune_entry = true;
+	FullTransactionId oldestXidWithEpochHavingUndo;
+
+	tpdpage = BufferGetPage(tpdbuf);
+	itemId = PageGetItemId(tpdpage, offnum);
+	tpd_e_offset = ItemIdGetOffset(itemId);
+	size_tpd_entry = ItemIdGetLength(itemId);
+
+	memcpy((char *) &tpd_e_hdr, tpdpage + tpd_e_offset, SizeofTPDEntryHeader);
+
+	/*
+	 * We can prune the deleted entries as no one will be referring to such
+	 * entries.
+	 */
+	if (TPDEntryIsDeleted(tpd_e_hdr))
+		goto prune_tpd_entry;
+
+	if (tpd_e_hdr.tpe_flags & TPE_ONE_BYTE)
+		size_tpd_e_map = tpd_e_hdr.tpe_num_map_entries * sizeof(uint8);
+	else
+	{
+		Assert(tpd_e_hdr.tpe_flags & TPE_FOUR_BYTE);
+		size_tpd_e_map = tpd_e_hdr.tpe_num_map_entries * sizeof(uint32);
+	}
+
+	num_trans_slots = tpd_e_hdr.tpe_num_slots;
+	size_tpd_e_slots = num_trans_slots * sizeof(TransInfo);
+	loc_trans_slots = tpd_e_offset + SizeofTPDEntryHeader + size_tpd_e_map;
+
+	trans_slots = (TransInfo *) palloc(size_tpd_e_slots);
+	memcpy((char *) trans_slots, tpdpage + loc_trans_slots, size_tpd_e_slots);
+
+	oldestXidWithEpochHavingUndo = FullTransactionIdFromU64(
+															pg_atomic_read_u64(&ProcGlobal->oldestFullXidHavingUnappliedUndo));
+
+	for (slot_no = 0; slot_no < num_trans_slots; slot_no++)
+	{
+		FullTransactionId slot_fxid;
+		UndoRecPtr	urec_ptr = trans_slots[slot_no].urec_ptr;
+
+		slot_fxid = trans_slots[slot_no].fxid;
+
+		/*
+		 * Check whether transaction slot can be considered frozen? If both
+		 * transaction id and undo record pointer are invalid or xid is
+		 * invalid and its undo has been discarded or xid is older than the
+		 * oldest xid with undo.
+		 */
+		if ((!FullTransactionIdIsValid(slot_fxid) &&
+			 (!UndoRecPtrIsValid(urec_ptr) || UndoLogIsDiscarded(urec_ptr))) ||
+			(FullTransactionIdIsValid(slot_fxid) &&
+			 FullTransactionIdPrecedes(slot_fxid, oldestXidWithEpochHavingUndo)))
+			continue;
+		else
+		{
+			prune_entry = false;
+			break;
+		}
+	}
+
+	pfree(trans_slots);
+
+prune_tpd_entry:
+	if (prune_entry)
+	{
+		Assert(prstate->nunused < MaxTPDTuplesPerPage);
+		prstate->nowunused[prstate->nunused] = offnum;
+		prstate->nunused++;
+
+		*space_freed += size_tpd_entry;
+	}
+}
+
+/*
+ * TPDPagePruneExecute - Guts of the TPD page pruning.
+ *
+ * Here, we mark all the entries that can be pruned as unused and then call page
+ * repair fragmentation to compact the page.
+ */
+void
+TPDPagePruneExecute(Buffer tpdbuf, OffsetNumber *nowunused, int nunused)
+{
+	Page		tpdpage;
+	OffsetNumber *offnum;
+	int			i;
+
+	tpdpage = BufferGetPage(tpdbuf);
+
+	/* Update all now-unused line pointers */
+	offnum = nowunused;
+	for (i = 0; i < nunused; i++)
+	{
+		OffsetNumber off = *offnum++;
+		ItemId		lp = PageGetItemId(tpdpage, off);
+
+		ItemIdSetUnused(lp);
+	}
+}
+
+/*
+ * TPDPageRepairFragmentation - Frees fragmented space on a tpd page.
+ *
+ * It doesn't remove unused line pointers because some heap page might
+ * still point to the line pointer.  If we remove the line pointer, then
+ * the same space could be occupied by actual TPD entry in which case somebody
+ * trying to access that line pointer will get unpredictable behavior.
+ */
+void
+TPDPageRepairFragmentation(Page page, Page tmppage, OffsetNumber target_offnum,
+						   Size space_required)
+{
+	Offset		pd_lower = ((PageHeader) page)->pd_lower;
+	Offset		pd_upper = ((PageHeader) page)->pd_upper;
+	Offset		pd_special = ((PageHeader) page)->pd_special;
+	itemIdSortData itemidbase[MaxTPDTuplesPerPage];
+	itemIdSort	itemidptr;
+	ItemId		lp;
+	int			nline,
+				nstorage,
+				nunused;
+	int			i;
+	Size		totallen;
+
+	/*
+	 * It's worth the trouble to be more paranoid here than in most places,
+	 * because we are about to reshuffle data in (what is usually) a shared
+	 * disk buffer.  If we aren't careful then corrupted pointers, lengths,
+	 * etc. could cause us to clobber adjacent disk buffers, spreading the
+	 * data loss further.  So, check everything.
+	 */
+	if (pd_lower < SizeOfPageHeaderData ||
+		pd_lower > pd_upper ||
+		pd_upper > pd_special ||
+		pd_special > BLCKSZ)
+		ereport(ERROR,
+				(errcode(ERRCODE_DATA_CORRUPTED),
+				 errmsg("corrupted page pointers: lower = %u, upper = %u, special = %u",
+						pd_lower, pd_upper, pd_special)));
+
+	/*
+	 * Run through the line pointer array and collect data about live items.
+	 */
+	nline = PageGetMaxOffsetNumber(page);
+	itemidptr = itemidbase;
+	nunused = totallen = 0;
+	for (i = FirstOffsetNumber; i <= nline; i++)
+	{
+		lp = PageGetItemId(page, i);
+		if (ItemIdIsUsed(lp))
+		{
+			if (ItemIdHasStorage(lp))
+			{
+				itemidptr->offsetindex = i - 1;
+				itemidptr->itemoff = ItemIdGetOffset(lp);
+				if (unlikely(itemidptr->itemoff < (int) pd_upper ||
+							 itemidptr->itemoff >= (int) pd_special))
+					ereport(ERROR,
+							(errcode(ERRCODE_DATA_CORRUPTED),
+							 errmsg("corrupted item pointer: %u",
+									itemidptr->itemoff)));
+				if (i == target_offnum)
+					itemidptr->alignedlen = ItemIdGetLength(lp) +
+						space_required;
+				else
+					itemidptr->alignedlen = ItemIdGetLength(lp);
+				totallen += itemidptr->alignedlen;
+				itemidptr++;
+			}
+		}
+		else
+		{
+			/* Unused entries should have lp_len = 0, but make sure */
+			ItemIdSetUnused(lp);
+			nunused++;
+		}
+	}
+
+	nstorage = itemidptr - itemidbase;
+	if (nstorage == 0)
+	{
+		/* Page is completely empty, so just reset it quickly */
+		((PageHeader) page)->pd_lower = SizeOfPageHeaderData;
+		((PageHeader) page)->pd_upper = pd_special;
+	}
+	else
+	{
+		/* Need to compact the page the hard way */
+		if (totallen > (Size) (pd_special - pd_lower))
+			ereport(ERROR,
+					(errcode(ERRCODE_DATA_CORRUPTED),
+					 errmsg("corrupted item lengths: total %u, available space %u",
+							(unsigned int) totallen, pd_special - pd_lower)));
+
+		compactify_ztuples(itemidbase, nstorage, page, tmppage);
+	}
+
+	/* Set hint bit for TPDPageAddEntry */
+	if (nunused > 0)
+		PageSetHasFreeLinePointers(page);
+	else
+		PageClearHasFreeLinePointers(page);
+}
+
+/*
+ * LogTPDClean - Write WAL for TPD entries that can be pruned.
+ */
+XLogRecPtr
+LogTPDClean(Relation rel, Buffer tpdbuf,
+			OffsetNumber *nowunused, int nunused,
+			OffsetNumber target_offnum, Size space_required)
+{
+	XLogRecPtr	recptr;
+	xl_tpd_clean xl_rec;
+
+	/* Caller should not call me on a non-WAL-logged relation */
+	Assert(RelationNeedsWAL(rel));
+
+	xl_rec.flags = 0;
+	XLogBeginInsert();
+
+	if (target_offnum != InvalidOffsetNumber)
+		xl_rec.flags |= XL_TPD_CONTAINS_OFFSET;
+	XLogRegisterData((char *) &xl_rec, SizeOfTPDClean);
+
+	/* Register the offset information. */
+	if (target_offnum != InvalidOffsetNumber)
+	{
+		XLogRegisterData((char *) &target_offnum, sizeof(OffsetNumber));
+		XLogRegisterData((char *) &space_required, sizeof(space_required));
+	}
+
+	XLogRegisterBuffer(0, tpdbuf, REGBUF_STANDARD);
+
+	/*
+	 * The OffsetNumber array is not actually in the buffer, but we pretend it
+	 * is.  When XLogInsert stores the whole buffer, the offset array need not
+	 * be stored too.  Note that even if the array is empty, we want to expose
+	 * the buffer as a candidate for whole-page storage, since this record
+	 * type implies a defragmentation operation even if no item pointers
+	 * changed state.
+	 */
+	if (nunused > 0)
+		XLogRegisterBufData(0, (char *) nowunused,
+							nunused * sizeof(OffsetNumber));
+
+	recptr = XLogInsert(RM_TPD_ID, XLOG_TPD_CLEAN);
+
+	return recptr;
+}
+
+/*
+ * TPDPruneEntirePage
+ */
+static int
+TPDPruneEntirePage(Relation rel, Buffer tpdbuf)
+{
+	Page		page = BufferGetPage(tpdbuf);
+	int			entries_removed = PageGetMaxOffsetNumber(page);
+
+	START_CRIT_SECTION();
+
+	/* Page is completely empty, so just reset it quickly */
+	((PageHeader) page)->pd_lower = SizeOfPageHeaderData;
+	((PageHeader) page)->pd_upper = ((PageHeader) page)->pd_special;
+
+	MarkBufferDirty(tpdbuf);
+
+	if (RelationNeedsWAL(rel))
+	{
+		XLogRecPtr	recptr;
+
+		XLogBeginInsert();
+
+		XLogRegisterBuffer(0, tpdbuf, REGBUF_STANDARD);
+
+		recptr = XLogInsert(RM_TPD_ID, XLOG_TPD_CLEAN_ALL_ENTRIES);
+
+		PageSetLSN(BufferGetPage(tpdbuf), recptr);
+	}
+
+	END_CRIT_SECTION();
+
+	return entries_removed;
+}
diff --git a/src/backend/access/zheap/prunezheap.c b/src/backend/access/zheap/prunezheap.c
new file mode 100644
index 0000000..6d92bc9
--- /dev/null
+++ b/src/backend/access/zheap/prunezheap.c
@@ -0,0 +1,958 @@
+/*-------------------------------------------------------------------------
+ *
+ * prunezheap.c
+ *	  zheap page pruning
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/heap/prunezheap.c
+ *
+ * In Zheap, we can reclaim space on following operations
+ * a. non-inplace updates, when committed or rolled back.
+ * b. inplace updates that reduces the tuple length, when committed.
+ * c. deletes, when committed.
+ * d. inserts, when rolled back.
+ *
+ * Since we only store xid which changed the page in pd_prune_xid, to prune
+ * the page, we can check if pd_prune_xid is in progress.  This can sometimes
+ * lead to unwanted page pruning calls as a side effect, example in case of
+ * rolled back deletes.  If there is nothing to prune, then the call to prune
+ * is cheap, so we don't want to optimize it at this stage.
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include "access/tpd.h"
+#include "access/zheap.h"
+#include "access/zheapam_xlog.h"
+#include "utils/ztqual.h"
+#include "catalog/catalog.h"
+#include "miscadmin.h"
+#include "pgstat.h"
+#include "storage/bufmgr.h"
+#include "storage/procarray.h"
+
+/* Working data for zheap_page_prune and subroutines */
+typedef struct
+{
+	TransactionId new_prune_xid;	/* new prune hint value for page */
+	TransactionId latestRemovedXid; /* latest xid to be removed by this prune */
+	int			ndeleted;		/* numbers of entries in arrays below */
+	int			ndead;
+	int			nunused;
+	/* arrays that accumulate indexes of items to be changed */
+
+	/*
+	 * Fixme - arrays must use MaxZHeapTuplesPerPage, once we have constant
+	 * value for the same.
+	 */
+	OffsetNumber nowdeleted[MaxZHeapTuplesPerPage];
+	OffsetNumber nowdead[MaxZHeapTuplesPerPage];
+	OffsetNumber nowunused[MaxZHeapTuplesPerPage];
+	/* marked[i] is TRUE if item i is entered in one of the above arrays */
+	bool		marked[MaxZHeapTuplesPerPage + 1];
+} ZPruneState;
+
+static int	zheap_prune_item(Relation relation, Buffer buffer,
+							 OffsetNumber rootoffnum, TransactionId OldestXmin,
+							 ZPruneState *prstate, int *space_freed);
+static void zheap_prune_record_prunable(ZPruneState *prstate,
+										TransactionId xid);
+static void zheap_prune_record_dead(ZPruneState *prstate, OffsetNumber offnum);
+static void zheap_prune_record_deleted(ZPruneState *prstate,
+									   OffsetNumber offnum);
+
+/*
+ * Optionally prune and repair fragmentation in the specified page.
+ *
+ * Caller must have exclusive lock on the page.
+ *
+ * OldestXmin is the cutoff XID used to distinguish whether tuples are DEAD
+ * or RECENTLY_DEAD (see ZHeapTupleSatisfiesOldestXmin).
+ *
+ * This is an opportunistic function.  It will perform housekeeping only if
+ * the page has effect of transaction that has modified data which can be
+ * pruned.
+ *
+ * Note: This is called only when we need some space in page to perform the
+ * action which otherwise would need a different page.  It is called when an
+ * update statement has to update the existing tuple such that new tuple is
+ * bigger than old tuple and the same can't fit on page.
+ *
+ * Returns true, if we are able to free up the space such that the new tuple
+ * can fit into same page, otherwise, false.
+*/
+bool
+zheap_page_prune_opt(Relation relation, Buffer buffer,
+					 OffsetNumber offnum, Size space_required)
+{
+	Page		page;
+	TransactionId OldestXmin;
+	TransactionId ignore = InvalidTransactionId;
+	Size		pagefree;
+	bool		force_prune = false;
+	bool		pruned;
+
+	page = BufferGetPage(buffer);
+
+	/*
+	 * We can't write WAL in recovery mode, so there's no point trying to
+	 * clean the page. The master will likely issue a cleaning WAL record soon
+	 * anyway, so this is no particular loss.
+	 */
+	if (RecoveryInProgress())
+		return false;
+
+	/*
+	 * Use the appropriate xmin horizon for this relation. If it's a proper
+	 * catalog relation or a user defined, additional, catalog relation, we
+	 * need to use the horizon that includes slots, otherwise the data-only
+	 * horizon can be used. Note that the toast relation of user defined
+	 * relations are *not* considered catalog relations.
+	 *
+	 * It is OK to apply the old snapshot limit before acquiring the cleanup
+	 * lock because the worst that can happen is that we are not quite as
+	 * aggressive about the cleanup (by however many transaction IDs are
+	 * consumed between this point and acquiring the lock).  This allows us to
+	 * save significant overhead in the case where the page is found not to be
+	 * prunable.
+	 */
+	if (IsCatalogRelation(relation) ||
+		RelationIsAccessibleInLogicalDecoding(relation))
+		OldestXmin = RecentGlobalXmin;
+	else
+		OldestXmin = RecentGlobalDataXmin;
+
+	Assert(TransactionIdIsValid(OldestXmin));
+
+	if (OffsetNumberIsValid(offnum))
+	{
+		pagefree = PageGetExactFreeSpace(page);
+
+		/*
+		 * We want to forcefully prune the page if we are sure that the
+		 * required space is available.  This will help in rearranging the
+		 * page such that we will be able to make space adjacent to required
+		 * offset number.
+		 */
+		if (space_required < pagefree)
+			force_prune = true;
+	}
+
+
+	/*
+	 * Let's see if we really need pruning.
+	 *
+	 * Forget it if page is not hinted to contain something prunable that's
+	 * committed and we don't want to forcefully prune the page.
+	 */
+	if (!ZPageIsPrunable(page) && !force_prune)
+		return false;
+
+	zheap_page_prune_guts(relation, buffer, OldestXmin, offnum,
+						  space_required, true, force_prune,
+						  &ignore, &pruned);
+	if (pruned)
+		return true;
+
+	return false;
+}
+
+/*
+ * Prune and repair fragmentation in the specified page.
+ *
+ * Caller must have pin and buffer cleanup lock on the page.
+ *
+ * OldestXmin is the cutoff XID used to distinguish whether tuples are DEAD
+ * or RECENTLY_DEAD (see ZHeapTupleSatisfiesOldestXmin).
+ *
+ * To perform pruning, we make the copy of the page.  We don't scribble on
+ * that copy, rather it is only used during repair fragmentation to copy
+ * the tuples.  So, we need to ensure that after making the copy, we operate
+ * on tuples, otherwise, the temporary copy will become useless.  It is okay
+ * scribble on itemid's or special space of page.
+ *
+ * If report_stats is true then we send the number of reclaimed tuples to
+ * pgstats.  (This must be false during vacuum, since vacuum will send its own
+ * own new total to pgstats, and we don't want this delta applied on top of
+ * that.)
+ *
+ * Returns the number of tuples deleted from the page and sets
+ * latestRemovedXid.  It returns 0, when removed the dead tuples can't free up
+ * the space required.
+ */
+int
+zheap_page_prune_guts(Relation relation, Buffer buffer,
+					  TransactionId OldestXmin, OffsetNumber target_offnum,
+					  Size space_required, bool report_stats,
+					  bool force_prune, TransactionId *latestRemovedXid,
+					  bool *pruned)
+{
+	int			ndeleted = 0;
+	int			space_freed = 0;
+	Page		page = BufferGetPage(buffer);
+	Page		tmppage = NULL;
+	OffsetNumber offnum,
+				maxoff;
+	ZPruneState prstate;
+	bool		execute_pruning = false;
+
+	if (pruned)
+		*pruned = false;
+
+	/* initialize the space_free with already existing free space in page */
+	space_freed = PageGetExactFreeSpace(page);
+
+	/*
+	 * Our strategy is to scan the page and make lists of items to change,
+	 * then apply the changes within a critical section.  This keeps as much
+	 * logic as possible out of the critical section, and also ensures that
+	 * WAL replay will work the same as the normal case.
+	 *
+	 * First, initialize the new pd_prune_xid value to zero (indicating no
+	 * prunable tuples).  If we find any tuples which may soon become
+	 * prunable, we will save the lowest relevant XID in new_prune_xid. Also
+	 * initialize the rest of our working state.
+	 */
+	prstate.new_prune_xid = InvalidTransactionId;
+	prstate.latestRemovedXid = *latestRemovedXid;
+	prstate.ndeleted = prstate.ndead = prstate.nunused = 0;
+	memset(prstate.marked, 0, sizeof(prstate.marked));
+
+	/*
+	 * If caller has asked to rearrange the page and page is not marked for
+	 * pruning, then skip scanning the page.
+	 *
+	 * XXX We might want to remove this check once we have some optimal
+	 * strategy to rearrange the page where we anyway need to traverse all
+	 * rows.
+	 */
+	if (force_prune && !ZPageIsPrunable(page))
+	{
+		;						/* no need to scan */
+	}
+	else
+	{
+		/* Scan the page */
+		maxoff = PageGetMaxOffsetNumber(page);
+		for (offnum = FirstOffsetNumber;
+			 offnum <= maxoff;
+			 offnum = OffsetNumberNext(offnum))
+		{
+			ItemId		itemid;
+
+			/* Ignore items already processed as part of an earlier chain */
+			if (prstate.marked[offnum])
+				continue;
+
+			/*
+			 * Nothing to do if slot is empty, already dead or marked as
+			 * deleted.
+			 */
+			itemid = PageGetItemId(page, offnum);
+			if (!ItemIdIsUsed(itemid) || ItemIdIsDead(itemid) ||
+				ItemIdIsDeleted(itemid))
+				continue;
+
+			/* Process this item */
+			ndeleted += zheap_prune_item(relation, buffer, offnum,
+										 OldestXmin,
+										 &prstate,
+										 &space_freed);
+		}
+	}
+
+	/*
+	 * There is not much advantage in continuing, if we can't free the space
+	 * required by the caller or we are not asked to forcefully prune the
+	 * page.
+	 *
+	 * XXX - In theory, we can still continue and perform pruning in the hope
+	 * that some future update in this page will be able to use that space.
+	 * However, it will lead to additional writes without any guaranteed
+	 * benefit, so we skip the pruning for now.
+	 */
+	if (space_freed < space_required)
+		return 0;
+
+	/* Do we want to prune? */
+	if (prstate.ndeleted > 0 || prstate.ndead > 0 ||
+		prstate.nunused > 0 || force_prune)
+	{
+		PageHeader	phdr;
+
+		execute_pruning = true;
+
+		/*
+		 * Lock the TPD page before starting critical section.  We might need
+		 * to access it during page repair fragmentation.
+		 */
+		phdr = (PageHeader) page;
+		if (ZHeapPageHasTPDSlot(phdr))
+			TPDPageLock(relation, buffer);
+
+		/*
+		 * We prepare the temporary copy of the page so that during page
+		 * repair fragmentation we can use it to copy the actual tuples.
+		 */
+		tmppage = PageGetTempPageCopy(page);
+	}
+
+	/* Any error while applying the changes is critical */
+	START_CRIT_SECTION();
+
+	if (execute_pruning)
+	{
+		bool		has_pruned = false;
+
+		/*
+		 * Apply the planned item changes, then repair page fragmentation, and
+		 * update the page's hint bit about whether it has free line pointers.
+		 */
+		zheap_page_prune_execute(buffer, target_offnum,
+								 prstate.nowdeleted, prstate.ndeleted,
+								 prstate.nowdead, prstate.ndead,
+								 prstate.nowunused, prstate.nunused);
+
+		/*
+		 * Finally, repair any fragmentation, and update the page's hint bit
+		 * whether it has free pointers.
+		 */
+		ZPageRepairFragmentation(buffer, tmppage, target_offnum,
+								 space_required, false, &has_pruned, false);
+
+		/*
+		 * Update the page's pd_prune_xid field to either zero, or the lowest
+		 * XID of any soon-prunable tuple.
+		 */
+		((PageHeader) page)->pd_prune_xid = prstate.new_prune_xid;
+
+		/*
+		 * Also clear the "page is full" flag, since there's no point in
+		 * repeating the prune/defrag process until something else happens to
+		 * the page.
+		 */
+		PageClearFull(page);
+
+		MarkBufferDirty(buffer);
+
+		/*
+		 * Emit a WAL ZHEAP_CLEAN record showing what we did
+		 */
+		if (RelationNeedsWAL(relation))
+		{
+			XLogRecPtr	recptr;
+
+			recptr = log_zheap_clean(relation, buffer, target_offnum,
+									 space_required, prstate.nowdeleted,
+									 prstate.ndeleted, prstate.nowdead,
+									 prstate.ndead, prstate.nowunused,
+									 prstate.nunused,
+									 prstate.latestRemovedXid, has_pruned);
+
+			PageSetLSN(BufferGetPage(buffer), recptr);
+		}
+
+		if (pruned)
+			*pruned = has_pruned;
+	}
+	else
+	{
+		/*
+		 * If we didn't prune anything, but have found a new value for the
+		 * pd_prune_xid field, update it and mark the buffer dirty. This is
+		 * treated as a non-WAL-logged hint.
+		 *
+		 * Also clear the "page is full" flag if it is set, since there's no
+		 * point in repeating the prune/defrag process until something else
+		 * happens to the page.
+		 */
+		if (((PageHeader) page)->pd_prune_xid != prstate.new_prune_xid ||
+			PageIsFull(page))
+		{
+			((PageHeader) page)->pd_prune_xid = prstate.new_prune_xid;
+			PageClearFull(page);
+			MarkBufferDirtyHint(buffer, true);
+		}
+	}
+
+	END_CRIT_SECTION();
+
+	/*
+	 * Report the number of tuples reclaimed to pgstats. This is ndeleted
+	 * minus ndead, because we don't want to count a now-DEAD item or a
+	 * now-DELETED item as a deletion for this purpose.
+	 */
+	if (report_stats && ndeleted > (prstate.ndead + prstate.ndeleted))
+		pgstat_update_heap_dead_tuples(relation, ndeleted - (prstate.ndead + prstate.ndeleted));
+
+	*latestRemovedXid = prstate.latestRemovedXid;
+
+	/* be tidy. */
+	if (tmppage)
+		pfree(tmppage);
+	UnlockReleaseTPDBuffers();
+
+	/*
+	 * XXX Should we update FSM information for this?  Not doing so will
+	 * increase the chances of in-place updates.  See heap_page_prune for a
+	 * detailed reason.
+	 */
+
+	return ndeleted;
+}
+
+/*
+ * Perform the actual page changes needed by zheap_page_prune_guts.
+ * It is expected that the caller has suitable pin and lock on the
+ * buffer, and is inside a critical section.
+ */
+void
+zheap_page_prune_execute(Buffer buffer, OffsetNumber target_offnum,
+						 OffsetNumber *deleted, int ndeleted,
+						 OffsetNumber *nowdead, int ndead,
+						 OffsetNumber *nowunused, int nunused)
+{
+	Page		page = (Page) BufferGetPage(buffer);
+	OffsetNumber *offnum;
+	int			i;
+
+	/* Update all deleted line pointers */
+	offnum = deleted;
+	for (i = 0; i < ndeleted; i++)
+	{
+		ZHeapTupleHeader tup;
+		int			trans_slot;
+		uint8		vis_info = 0;
+		OffsetNumber off = *offnum++;
+		ItemId		lp;
+
+		/* The target offset must not be deleted. */
+		Assert(target_offnum != off);
+
+		lp = PageGetItemId(page, off);
+
+		tup = (ZHeapTupleHeader) PageGetItem(page, lp);
+		trans_slot = ZHeapTupleHeaderGetXactSlot(tup);
+
+		/*
+		 * The frozen slot indicates tuple is dead, so we must not see them in
+		 * the array of tuples to be marked as deleted.
+		 */
+		Assert(trans_slot != ZHTUP_SLOT_FROZEN);
+
+		if (ZHeapTupleDeleted(tup))
+			vis_info = ITEMID_DELETED;
+		if (ZHeapTupleHasInvalidXact(tup->t_infomask))
+			vis_info |= ITEMID_XACT_INVALID;
+
+		/*
+		 * Mark the Item as deleted and copy the visibility info and
+		 * transaction slot information from tuple to ItemId.
+		 */
+		ItemIdSetDeleted(lp, trans_slot, vis_info);
+	}
+
+	/* Update all now-dead line pointers */
+	offnum = nowdead;
+	for (i = 0; i < ndead; i++)
+	{
+		OffsetNumber off = *offnum++;
+		ItemId		lp;
+
+		/* The target offset must not be dead. */
+		Assert(target_offnum != off);
+
+		lp = PageGetItemId(page, off);
+
+		ItemIdSetDead(lp);
+	}
+
+	/* Update all now-unused line pointers */
+	offnum = nowunused;
+	for (i = 0; i < nunused; i++)
+	{
+		OffsetNumber off = *offnum++;
+		ItemId		lp;
+
+		/* The target offset must not be unused. */
+		Assert(target_offnum != off);
+
+		lp = PageGetItemId(page, off);
+
+		ItemIdSetUnused(lp);
+	}
+}
+
+/*
+ * Prune specified item pointer.
+ *
+ * OldestXmin is the cutoff XID used to identify dead tuples.
+ *
+ * We don't actually change the page here.  We just add entries to the arrays in
+ * prstate showing the changes to be made.  Items to be set to LP_DEAD state are
+ * added to nowdead[]; items to be set to LP_DELETED are added to nowdeleted[];
+ * and items to be set to LP_UNUSED state are added to nowunused[].
+ *
+ * Returns the number of tuples (to be) deleted from the page.
+ */
+static int
+zheap_prune_item(Relation relation, Buffer buffer, OffsetNumber offnum,
+				 TransactionId OldestXmin, ZPruneState *prstate,
+				 int *space_freed)
+{
+	ZHeapTupleData tup;
+	ItemId		lp;
+	Page		dp = (Page) BufferGetPage(buffer);
+	int			ndeleted = 0;
+	TransactionId xid;
+	bool		tupdead,
+				recent_dead;
+
+	lp = PageGetItemId(dp, offnum);
+
+	Assert(ItemIdIsNormal(lp));
+
+	tup.t_data = (ZHeapTupleHeader) PageGetItem(dp, lp);
+	tup.t_len = ItemIdGetLength(lp);
+	ItemPointerSet(&(tup.t_self), BufferGetBlockNumber(buffer), offnum);
+	tup.t_tableOid = RelationGetRelid(relation);
+
+	/*
+	 * Check tuple's visibility status.
+	 */
+	tupdead = recent_dead = false;
+
+	switch (ZHeapTupleSatisfiesOldestXmin(&tup, OldestXmin, buffer, false,
+										  NULL, &xid, NULL))
+	{
+		case ZHEAPTUPLE_DEAD:
+			tupdead = true;
+			break;
+
+		case ZHEAPTUPLE_RECENTLY_DEAD:
+			recent_dead = true;
+			break;
+
+		case ZHEAPTUPLE_DELETE_IN_PROGRESS:
+
+			/*
+			 * This tuple may soon become DEAD.  Update the hint field so that
+			 * the page is reconsidered for pruning in future.
+			 */
+			zheap_prune_record_prunable(prstate, xid);
+			break;
+
+		case ZHEAPTUPLE_LIVE:
+		case ZHEAPTUPLE_INSERT_IN_PROGRESS:
+
+			/*
+			 * If we wanted to optimize for aborts, we might consider marking
+			 * the page prunable when we see INSERT_IN_PROGRESS. But we don't.
+			 * See related decisions about when to mark the page prunable in
+			 * heapam.c.
+			 */
+			break;
+
+		case ZHEAPTUPLE_ABORT_IN_PROGRESS:
+
+			/*
+			 * We can simply skip the tuple if it has inserted/operated by
+			 * some aborted transaction and its rollback is still pending.
+			 * It'll be taken care of by future prune calls.
+			 */
+			break;
+		default:
+			elog(ERROR, "unexpected ZHeapTupleSatisfiesOldestXmin result");
+			break;
+	}
+
+	if (tupdead)
+		ZHeapTupleHeaderAdvanceLatestRemovedXid(tup.t_data, xid, &prstate->latestRemovedXid);
+
+	if (tupdead || recent_dead)
+	{
+		/*
+		 * Count dead or recently dead tuple in result and update the space
+		 * that can be freed.
+		 */
+		ndeleted++;
+
+		/* short aligned */
+		*space_freed += SHORTALIGN(tup.t_len);
+	}
+
+	/* Record dead item */
+	if (tupdead)
+		zheap_prune_record_dead(prstate, offnum);
+
+	/* Record deleted item */
+	if (recent_dead)
+		zheap_prune_record_deleted(prstate, offnum);
+
+	return ndeleted;
+}
+
+/* Record lowest soon-prunable XID */
+static void
+zheap_prune_record_prunable(ZPruneState *prstate, TransactionId xid)
+{
+	/*
+	 * This should exactly match the PageSetPrunable macro.  We can't store
+	 * directly into the page header yet, so we update working state.
+	 */
+	Assert(TransactionIdIsNormal(xid));
+	if (!TransactionIdIsValid(prstate->new_prune_xid) ||
+		TransactionIdPrecedes(xid, prstate->new_prune_xid))
+		prstate->new_prune_xid = xid;
+}
+
+/* Record item pointer to be marked dead */
+static void
+zheap_prune_record_dead(ZPruneState *prstate, OffsetNumber offnum)
+{
+	Assert(prstate->ndead < MaxZHeapTuplesPerPage);
+	prstate->nowdead[prstate->ndead] = offnum;
+	prstate->ndead++;
+	Assert(!prstate->marked[offnum]);
+	prstate->marked[offnum] = true;
+}
+
+/* Record item pointer to be deleted */
+static void
+zheap_prune_record_deleted(ZPruneState *prstate, OffsetNumber offnum)
+{
+	Assert(prstate->ndead < MaxZHeapTuplesPerPage);
+	prstate->nowdeleted[prstate->ndeleted] = offnum;
+	prstate->ndeleted++;
+	Assert(!prstate->marked[offnum]);
+	prstate->marked[offnum] = true;
+}
+
+/*
+ * log_zheap_clean - Perform XLogInsert for a zheap-clean operation.
+ *
+ * Caller must already have modified the buffer and marked it dirty.
+ *
+ * We also include latestRemovedXid, which is the greatest XID present in
+ * the removed tuples. That allows recovery processing to cancel or wait
+ * for long standby queries that can still see these tuples.
+ */
+XLogRecPtr
+log_zheap_clean(Relation reln, Buffer buffer, OffsetNumber target_offnum,
+				Size space_required, OffsetNumber *nowdeleted, int ndeleted,
+				OffsetNumber *nowdead, int ndead, OffsetNumber *nowunused,
+				int nunused, TransactionId latestRemovedXid, bool pruned)
+{
+	XLogRecPtr	recptr;
+	xl_zheap_clean xl_rec;
+
+	/* Caller should not call me on a non-WAL-logged relation */
+	Assert(RelationNeedsWAL(reln));
+
+	xl_rec.latestRemovedXid = latestRemovedXid;
+	xl_rec.ndeleted = ndeleted;
+	xl_rec.ndead = ndead;
+	xl_rec.flags = 0;
+	XLogBeginInsert();
+
+	if (pruned)
+		xl_rec.flags |= XLZ_CLEAN_ALLOW_PRUNING;
+	XLogRegisterData((char *) &xl_rec, SizeOfZHeapClean);
+
+	/* Register the offset information. */
+	if (target_offnum != InvalidOffsetNumber)
+	{
+		xl_rec.flags |= XLZ_CLEAN_CONTAINS_OFFSET;
+		XLogRegisterData((char *) &target_offnum, sizeof(OffsetNumber));
+		XLogRegisterData((char *) &space_required, sizeof(space_required));
+	}
+
+	XLogRegisterBuffer(0, buffer, REGBUF_STANDARD);
+
+	/*
+	 * The OffsetNumber arrays are not actually in the buffer, but we pretend
+	 * that they are.  When XLogInsert stores the whole buffer, the offset
+	 * arrays need not be stored too.  Note that even if all three arrays are
+	 * empty, we want to expose the buffer as a candidate for whole-page
+	 * storage, since this record type implies a defragmentation operation
+	 * even if no item pointers changed state.
+	 */
+	if (ndeleted > 0)
+		XLogRegisterBufData(0, (char *) nowdeleted,
+							ndeleted * sizeof(OffsetNumber) * 2);
+
+	if (ndead > 0)
+		XLogRegisterBufData(0, (char *) nowdead,
+							ndead * sizeof(OffsetNumber));
+
+	if (nunused > 0)
+		XLogRegisterBufData(0, (char *) nowunused,
+							nunused * sizeof(OffsetNumber));
+
+	recptr = XLogInsert(RM_ZHEAP_ID, XLOG_ZHEAP_CLEAN);
+
+	return recptr;
+}
+
+/*
+ * After removing or marking some line pointers unused, move the tuples to
+ * remove the gaps caused by the removed items.  Here, we are rearranging
+ * the page such that tuples will be placed in itemid order.  It will help
+ * in the speedup of future sequential scans.
+ *
+ * Note that we use the temporary copy of the page to copy the tuples as
+ * writing in itemid order will overwrite some tuples.
+ */
+void
+compactify_ztuples(itemIdSort itemidbase, int nitems, Page page, Page tmppage)
+{
+	PageHeader	phdr = (PageHeader) page;
+	Offset		upper;
+	int			i;
+
+	Assert(PageIsValid(tmppage));
+	upper = phdr->pd_special;
+	for (i = nitems - 1; i >= 0; i--)
+	{
+		itemIdSort	itemidptr = &itemidbase[i];
+		ItemId		lp;
+
+		lp = PageGetItemId(page, itemidptr->offsetindex + 1);
+		upper -= itemidptr->alignedlen;
+		memcpy((char *) page + upper,
+			   (char *) tmppage + itemidptr->itemoff,
+			   lp->lp_len);
+		lp->lp_off = upper;
+	}
+
+	phdr->pd_upper = upper;
+}
+
+/*
+ * ZPageRepairFragmentation
+ *
+ * Frees fragmented space on a page.
+ *
+ * The basic idea is same as PageRepairFragmentation, but here we additionally
+ * deal with unused items that can't be immediately reclaimed.  We don't allow
+ * page to be pruned, if there is an inplace update from an open transaction.
+ * The reason is that we don't know the size of previous row in undo which
+ * could be bigger in which case we might not be able to perform rollback once
+ * the page is repaired.  Now, we can always traverse the undo chain to find
+ * the size of largest tuple in the chain, but we don't do that for now as it
+ * can take time especially if there are many such tuples on the page.
+ *
+ * The unused_set boolean argument is used to prevent re-evaluation of
+ * itemId when it is already set with transaction slot information in the
+ * caller function.
+ */
+void
+ZPageRepairFragmentation(Buffer buffer, Page tmppage,
+						 OffsetNumber target_offnum, Size space_required,
+						 bool NoTPDBufLock, bool *pruned, bool unused_set)
+{
+	Page		page = BufferGetPage(buffer);
+	Offset		pd_lower = ((PageHeader) page)->pd_lower;
+	Offset		pd_upper = ((PageHeader) page)->pd_upper;
+	Offset		pd_special = ((PageHeader) page)->pd_special;
+	itemIdSortData itemidbase[MaxZHeapTuplesPerPage];
+	itemIdSort	itemidptr;
+	ItemId		lp;
+	int			nline,
+				nstorage,
+				nunused;
+	int			i;
+	Size		totallen;
+
+	/*
+	 * It's worth the trouble to be more paranoid here than in most places,
+	 * because we are about to reshuffle data in (what is usually) a shared
+	 * disk buffer.  If we aren't careful then corrupted pointers, lengths,
+	 * etc. could cause us to clobber adjacent disk buffers, spreading the
+	 * data loss further.  So, check everything.
+	 */
+	if (pd_lower < SizeOfPageHeaderData ||
+		pd_lower > pd_upper ||
+		pd_upper > pd_special ||
+		pd_special > BLCKSZ ||
+		pd_special != MAXALIGN(pd_special))
+		ereport(ERROR,
+				(errcode(ERRCODE_DATA_CORRUPTED),
+				 errmsg("corrupted page pointers: lower = %u, upper = %u, special = %u",
+						pd_lower, pd_upper, pd_special)));
+
+	nline = PageGetMaxOffsetNumber(page);
+
+	/*
+	 * If there are any tuples which are inplace updated by any open
+	 * transactions we shall not compactify the page contents, otherwise,
+	 * rollback of those transactions will not be possible.  There could be a
+	 * case, where within a transaction tuple is first inplace updated and
+	 * then, either updated or deleted. So for now avoid compaction if there
+	 * are any tuples which are marked inplace updated, updated or deleted by
+	 * an open transaction.
+	 */
+	for (i = FirstOffsetNumber; i <= nline; i++)
+	{
+		lp = PageGetItemId(page, i);
+		if (ItemIdIsUsed(lp) && ItemIdHasStorage(lp))
+		{
+			ZHeapTupleHeader tup;
+
+			tup = (ZHeapTupleHeader) PageGetItem(page, lp);
+
+			if (!(tup->t_infomask & (ZHEAP_INPLACE_UPDATED |
+									 ZHEAP_UPDATED | ZHEAP_DELETED)))
+				continue;
+
+			if (!ZHeapTupleHasInvalidXact(tup->t_infomask))
+			{
+				ZHeapTupleTransInfo zinfo;
+
+				zinfo.trans_slot = ZHeapTupleHeaderGetXactSlot(tup);
+				if (zinfo.trans_slot == ZHTUP_SLOT_FROZEN)
+					continue;
+
+				/*
+				 * XXX There is possibility that the updater's slot got reused
+				 * by a locker in such a case the INVALID_XACT will be moved
+				 * to lockers undo.  Now, we will find that the tuple has
+				 * in-place update flag but it doesn't have INVALID_XACT flag
+				 * and the slot transaction is also running, in such case we
+				 * will not prune this page.  Ideally if the multi-locker is
+				 * set we can get the actual transaction and check the status
+				 * of the transaction.
+				 */
+				GetTransactionSlotInfo(buffer, i, zinfo.trans_slot,
+									   NoTPDBufLock, false, &zinfo);
+
+				/*
+				 * It is quite possible that the item is showing some valid
+				 * transaction slot, but actual slot has been frozen. This can
+				 * happen when the slot belongs to TPD entry and the
+				 * corresponding TPD entry is pruned.
+				 */
+				if (zinfo.trans_slot == ZHTUP_SLOT_FROZEN)
+					continue;
+
+				if (!TransactionIdDidCommit(zinfo.xid))
+					return;
+			}
+		}
+	}
+
+	/*
+	 * Run through the line pointer array and collect data about live items.
+	 */
+	itemidptr = itemidbase;
+	nunused = totallen = 0;
+	for (i = FirstOffsetNumber; i <= nline; i++)
+	{
+		lp = PageGetItemId(page, i);
+		if (ItemIdIsUsed(lp))
+		{
+			if (ItemIdHasStorage(lp))
+			{
+				itemidptr->offsetindex = i - 1;
+				itemidptr->itemoff = ItemIdGetOffset(lp);
+				if (unlikely(itemidptr->itemoff < (int) pd_upper ||
+							 itemidptr->itemoff >= (int) pd_special))
+					ereport(ERROR,
+							(errcode(ERRCODE_DATA_CORRUPTED),
+							 errmsg("corrupted item pointer: %u",
+									itemidptr->itemoff)));
+
+				/*
+				 * We need to save additional space for the target offset, so
+				 * that we can save the space for new tuple.
+				 */
+				if (i == target_offnum)
+					itemidptr->alignedlen = SHORTALIGN(ItemIdGetLength(lp) + space_required);
+				else
+					itemidptr->alignedlen = SHORTALIGN(ItemIdGetLength(lp));
+				totallen += itemidptr->alignedlen;
+				itemidptr++;
+			}
+		}
+		else
+		{
+			nunused++;
+
+			/*
+			 * We allow Unused entries to be reused only if there is no
+			 * transaction information for the entry or the transaction is
+			 * committed.
+			 */
+			if (ItemIdHasPendingXact(lp))
+			{
+				ZHeapTupleTransInfo zinfo;
+
+				/*
+				 * If unused_set is true, it means that itemIds are already
+				 * set unused with transaction slot information by the caller
+				 * and we should not clear it.
+				 */
+				if (unused_set)
+					continue;
+				zinfo.trans_slot = ItemIdGetTransactionSlot(lp);
+
+				/*
+				 * Here, we are relying on the transaction information in slot
+				 * as if the corresponding slot has been reused, then
+				 * transaction information from the entry would have been
+				 * cleared.  See PageFreezeTransSlots.
+				 */
+				if (zinfo.trans_slot != ZHTUP_SLOT_FROZEN)
+				{
+					GetTransactionSlotInfo(buffer, i, zinfo.trans_slot,
+										   NoTPDBufLock, false, &zinfo);
+
+					/*
+					 * It is quite possible that the item is showing some
+					 * valid transaction slot, but actual slot has been
+					 * frozen. This can happen when the slot belongs to TPD
+					 * entry and the corresponding TPD entry is pruned.
+					 */
+					if (zinfo.trans_slot != ZHTUP_SLOT_FROZEN &&
+						!TransactionIdDidCommit(zinfo.xid))
+						continue;
+				}
+			}
+
+			/* Unused entries should have lp_len = 0, but make sure */
+			ItemIdSetUnused(lp);
+		}
+	}
+
+	nstorage = itemidptr - itemidbase;
+	if (nstorage == 0)
+	{
+		/* Page is completely empty, so just reset it quickly */
+		((PageHeader) page)->pd_upper = pd_special;
+	}
+	else
+	{
+		/* Need to compact the page the hard way */
+		if (totallen > (Size) (pd_special - pd_lower))
+			ereport(ERROR,
+					(errcode(ERRCODE_DATA_CORRUPTED),
+					 errmsg("corrupted item lengths: total %u, available space %u",
+							(unsigned int) totallen, pd_special - pd_lower)));
+
+		compactify_ztuples(itemidbase, nstorage, page, tmppage);
+	}
+
+	/* Set hint bit for PageAddItem */
+	if (nunused > 0)
+		PageSetHasFreeLinePointers(page);
+	else
+		PageClearHasFreeLinePointers(page);
+
+	/* indicate that the page has been pruned */
+	if (pruned)
+		*pruned = true;
+}
diff --git a/src/backend/access/zheap/rewritezheap.c b/src/backend/access/zheap/rewritezheap.c
new file mode 100644
index 0000000..f37196a
--- /dev/null
+++ b/src/backend/access/zheap/rewritezheap.c
@@ -0,0 +1,374 @@
+/*-------------------------------------------------------------------------
+ *
+ * rewritezheap.c
+ *	  Support functions to rewrite zheap tables.
+ *
+ * These functions provide a facility to completely rewrite a heap.
+ *
+ * INTERFACE
+ *
+ * The caller is responsible for creating the new heap, all catalog
+ * changes, supplying the tuples to be written to the new heap, and
+ * rebuilding indexes.  The caller must hold AccessExclusiveLock on the
+ * target table, because we assume no one else is writing into it.
+ *
+ * To use the facility:
+ *
+ * begin_heap_rewrite
+ * while (fetch next tuple)
+ * {
+ *	   if (tuple is dead)
+ *		   rewrite_heap_dead_tuple
+ *	   else
+ *	   {
+ *		   // do any transformations here if required
+ *		   rewrite_heap_tuple
+ *	   }
+ * }
+ * end_zheap_rewrite
+ *
+ * The contents of the new relation shouldn't be relied on until after
+ * end_zheap_rewrite is called.
+ *
+ *
+ * IMPLEMENTATION
+ *
+ * As of now, this layer gets only LIVE tuples and we freeze them before
+ * storing in new heap.  This is not a good idea as we lose all the
+ * visibility information of tuples, but OTOH, the same can't be copied
+ * from the original tuple as that is maintained in undo and we don't have
+ * facility to modify undo records.
+ *
+ * One idea to capture the visibility information is that we should write a
+ * special undo record such that it stores previous version's visibility
+ * information and later if the current version is not visible as per latest
+ * xid (which is of cluster/vacuum full command), then we should get previous
+ * xid information from undo.  It seems along with previous versions xid, we
+ * need to write previous version tuples as well and somehow need to fix the
+ * ctid information in the undo records.
+ *
+ * We can't use the normal zheap_insert function to insert into the new
+ * heap, because heap_insert overwrites the visibility information and
+ * it uses buffer management layer to process the tuples which is bit
+ * slower.  We use a special-purpose raw_zheap_insert function instead, which
+ * is optimized for bulk inserting a lot of tuples, knowing that we have
+ * exclusive access to the heap.  raw_zheap_insert builds new pages in
+ * local storage.  When a page is full, or at the end of the process,
+ * we insert it to WAL as a single record and then write it to disk
+ * directly through smgr.  Note, however, that any data sent to the new
+ * heap's TOAST table will go through the normal bufmgr.
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994-5, Regents of the University of California
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/zheap/rewritezheap.c
+ *
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include <sys/stat.h>
+#include <unistd.h>
+
+#include "access/heapam.h"		/* for heap_sync() */
+#include "access/rewritezheap.h"
+#include "access/tuptoaster.h"
+#include "access/zheap.h"
+#include "miscadmin.h"
+#include "storage/bufmgr.h"
+#include "storage/smgr.h"
+#include "storage/procarray.h"
+#include "utils/memutils.h"
+
+
+/*
+ * State associated with a rewrite operation. This is opaque to the user
+ * of the rewrite facility.
+ */
+typedef struct RewriteZheapStateData
+{
+	Relation	rs_new_rel;		/* destination heap */
+	Page		rs_buffer;		/* page currently being built */
+	BlockNumber rs_blockno;		/* block where page will go */
+	bool		rs_buffer_valid;	/* T if any tuples in buffer */
+	bool		rs_use_wal;		/* must we WAL-log inserts? */
+	MemoryContext rs_cxt;		/* for hash tables and entries and tuples in
+								 * them */
+}			RewriteZheapStateData;
+
+
+/* prototypes for internal functions */
+static void raw_zheap_insert(RewriteZheapState state, ZHeapTuple tup);
+
+/*
+ * Begin a rewrite of a table
+ *
+ * old_heap		old, locked heap relation tuples will be read from
+ * new_heap		new, locked heap relation to insert tuples to
+ * oldest_xmin	xid used by the caller to determine which tuples are dead
+ * freeze_xid	this is kept for API compatability with heap, it's value will
+ *				be InvalidTransactionId.
+ * min_multi	this is kept for API compatability with heap, it's value will
+ *				will be InvalidMultiXactId
+ * use_wal		should the inserts to the new heap be WAL-logged?
+ *
+ * Returns an opaque RewriteState, allocated in current memory context,
+ * to be used in subsequent calls to the other functions.
+ */
+RewriteZheapState
+begin_zheap_rewrite(Relation old_heap, Relation new_heap,
+					TransactionId oldest_xmin, TransactionId freeze_xid,
+					MultiXactId cutoff_multi, bool use_wal)
+{
+	RewriteZheapState state;
+	MemoryContext rw_cxt;
+	MemoryContext old_cxt;
+
+	/*
+	 * To ease cleanup, make a separate context that will contain the
+	 * RewriteState struct itself plus all subsidiary data.
+	 */
+	rw_cxt = AllocSetContextCreate(CurrentMemoryContext,
+								   "Table rewrite",
+								   ALLOCSET_DEFAULT_SIZES);
+	old_cxt = MemoryContextSwitchTo(rw_cxt);
+
+	/* Create and fill in the state struct */
+	state = palloc0(sizeof(RewriteZheapStateData));
+
+	state->rs_new_rel = new_heap;
+	state->rs_buffer = (Page) palloc(BLCKSZ);
+	/* new_heap needn't be empty, just locked */
+	state->rs_blockno = RelationGetNumberOfBlocks(new_heap);
+	state->rs_buffer_valid = false;
+	state->rs_use_wal = use_wal;
+	state->rs_cxt = rw_cxt;
+
+	MemoryContextSwitchTo(old_cxt);
+
+	return state;
+}
+
+/*
+ * End a rewrite.
+ *
+ * state and any other resources are freed.
+ */
+void
+end_zheap_rewrite(RewriteZheapState state)
+{
+	/* Write the last page, if any */
+	if (state->rs_buffer_valid)
+	{
+		if (state->rs_use_wal)
+			log_newpage(SMGR_MD,
+						&state->rs_new_rel->rd_node,
+						MAIN_FORKNUM,
+						state->rs_blockno,
+						state->rs_buffer,
+						true);
+		RelationOpenSmgr(state->rs_new_rel);
+
+		PageSetChecksumInplace(state->rs_buffer, state->rs_blockno);
+
+		smgrextend(state->rs_new_rel->rd_smgr, MAIN_FORKNUM, state->rs_blockno,
+				   (char *) state->rs_buffer, true);
+	}
+
+	/*
+	 * If the rel is WAL-logged, must fsync before commit.  We use heap_sync
+	 * to ensure that the toast table gets fsync'd too.
+	 *
+	 * It's obvious that we must do this when not WAL-logging. It's less
+	 * obvious that we have to do it even if we did WAL-log the pages. The
+	 * reason is the same as in tablecmds.c's copy_relation_data(): we're
+	 * writing data that's not in shared buffers, and so a CHECKPOINT
+	 * occurring during the rewritezheap operation won't have fsync'd data we
+	 * wrote before the checkpoint.
+	 */
+	if (RelationNeedsWAL(state->rs_new_rel))
+		heap_sync(state->rs_new_rel);
+
+	/* Deleting the context frees everything */
+	MemoryContextDelete(state->rs_cxt);
+}
+
+/*
+ * Reconstruct and rewrite the given tuple
+ *
+ * We cannot simply copy the tuple as-is, see reform_and_rewrite_tuple for
+ * reasons.
+ */
+void
+reform_and_rewrite_ztuple(TupleDesc oldTupDesc, TupleDesc newTupDesc,
+						  Datum *values, bool *isnull,
+						  RewriteZheapState rwstate)
+{
+	ZHeapTuple	copiedTuple;
+	int			i;
+
+	/* Be sure to null out any dropped columns */
+	for (i = 0; i < newTupDesc->natts; i++)
+	{
+		if (TupleDescAttr(newTupDesc, i)->attisdropped)
+			isnull[i] = true;
+	}
+
+	copiedTuple = zheap_form_tuple(newTupDesc, values, isnull);
+
+	rewrite_zheap_tuple(rwstate, copiedTuple);
+
+	zheap_freetuple(copiedTuple);
+}
+
+/*
+ * Add a tuple to the new heap.
+ *
+ * Maintaining previous version's visibility information needs much more work
+ * (see atop of this file), so for now, we freeze all the tuples.  We only get
+ * LIVE versions of the tuple as input.
+ *
+ * Note that since we scribble on new_tuple, it had better be temp storage
+ * not a pointer to the original tuple.
+ *
+ * state		opaque state as returned by begin_heap_rewrite
+ * old_tuple	original tuple in the old heap
+ * new_tuple	new, rewritten tuple to be inserted to new heap
+ */
+void
+rewrite_zheap_tuple(RewriteZheapState state, ZHeapTuple new_tuple)
+{
+	MemoryContext old_cxt;
+
+	old_cxt = MemoryContextSwitchTo(state->rs_cxt);
+
+	/*
+	 * As of now, we copy only LIVE tuples in zheap, so we can mark them as
+	 * frozen.
+	 */
+	new_tuple->t_data->t_infomask &= ~ZHEAP_VIS_STATUS_MASK;
+	new_tuple->t_data->t_infomask2 &= ~ZHEAP_XACT_SLOT;
+	ZHeapTupleHeaderSetXactSlot(new_tuple->t_data, ZHTUP_SLOT_FROZEN);
+
+	raw_zheap_insert(state, new_tuple);
+
+	MemoryContextSwitchTo(old_cxt);
+}
+
+/*
+ * Insert a tuple to the new relation.  This has to track zheap_insert
+ * and its subsidiary functions!
+ *
+ * t_self of the tuple is set to the new TID of the tuple.
+ */
+static void
+raw_zheap_insert(RewriteZheapState state, ZHeapTuple tup)
+{
+	Page		page = state->rs_buffer;
+	Size		pageFreeSpace,
+				saveFreeSpace;
+	Size		len;
+	OffsetNumber newoff;
+	ZHeapTuple	heaptup;
+
+	/*
+	 * If the new tuple is too big for storage or contains already toasted
+	 * out-of-line attributes from some other relation, invoke the toaster.
+	 *
+	 * Note: below this point, heaptup is the data we actually intend to store
+	 * into the relation; tup is the caller's original untoasted data.
+	 */
+	if (state->rs_new_rel->rd_rel->relkind == RELKIND_TOASTVALUE)
+	{
+		/* toast table entries should never be recursively toasted */
+		Assert(!ZHeapTupleHasExternal(tup));
+		heaptup = tup;
+	}
+	else if (ZHeapTupleHasExternal(tup) || tup->t_len > TOAST_TUPLE_THRESHOLD)
+	{
+		/*
+		 * As of now, we copy only LIVE tuples in zheap, so we can mark them
+		 * as frozen.
+		 */
+		heaptup = ztoast_insert_or_update(state->rs_new_rel, tup, NULL,
+										  ZHEAP_INSERT_FROZEN |
+										  ZHEAP_INSERT_SKIP_FSM |
+										  (state->rs_use_wal ?
+										   0 : ZHEAP_INSERT_SKIP_WAL), 0);
+	}
+	else
+		heaptup = tup;
+
+	len = SHORTALIGN(heaptup->t_len);
+
+	/*
+	 * If we're gonna fail for oversize tuple, do it right away
+	 */
+	if (len > MaxZHeapTupleSize)
+		ereport(ERROR,
+				(errcode(ERRCODE_PROGRAM_LIMIT_EXCEEDED),
+				 errmsg("row is too big: size %zu, maximum size %zu",
+						len, MaxZHeapTupleSize)));
+
+	/* Compute desired extra freespace due to fillfactor option */
+	saveFreeSpace = RelationGetTargetPageFreeSpace(state->rs_new_rel,
+												   HEAP_DEFAULT_FILLFACTOR);
+
+	/* Now we can check to see if there's enough free space already. */
+	if (state->rs_buffer_valid)
+	{
+		pageFreeSpace = PageGetHeapFreeSpace(page);
+
+		if (len + saveFreeSpace > pageFreeSpace)
+		{
+			/* Doesn't fit, so write out the existing page */
+
+			/* XLOG stuff */
+			if (state->rs_use_wal)
+				log_newpage(SMGR_MD,
+							&state->rs_new_rel->rd_node,
+							MAIN_FORKNUM,
+							state->rs_blockno,
+							page,
+							true);
+
+			/*
+			 * Now write the page. We say isTemp = true even if it's not a
+			 * temp table, because there's no need for smgr to schedule an
+			 * fsync for this write; we'll do it ourselves in
+			 * end_zheap_rewrite.
+			 */
+			RelationOpenSmgr(state->rs_new_rel);
+
+			PageSetChecksumInplace(page, state->rs_blockno);
+
+			smgrextend(state->rs_new_rel->rd_smgr, MAIN_FORKNUM,
+					   state->rs_blockno, (char *) page, true);
+
+			state->rs_blockno++;
+			state->rs_buffer_valid = false;
+		}
+	}
+
+	if (!state->rs_buffer_valid)
+	{
+		/* Initialize a new empty page */
+		ZheapInitPage(page, BLCKSZ);
+		state->rs_buffer_valid = true;
+	}
+
+	/* And now we can insert the tuple into the page */
+	newoff = ZPageAddItem(InvalidBuffer, page, (Item) heaptup->t_data,
+						  heaptup->t_len, InvalidOffsetNumber, false, true,
+						  true);
+	if (newoff == InvalidOffsetNumber)
+		elog(ERROR, "failed to add tuple");
+
+	/* Update caller's t_self to the actual position where it was stored */
+	ItemPointerSet(&(tup->t_self), state->rs_blockno, newoff);
+
+	/* If heaptup is a private copy, release it. */
+	if (heaptup != tup)
+		zheap_freetuple(heaptup);
+}
diff --git a/src/backend/access/zheap/tpd.c b/src/backend/access/zheap/tpd.c
new file mode 100644
index 0000000..58a1ac7
--- /dev/null
+++ b/src/backend/access/zheap/tpd.c
@@ -0,0 +1,3269 @@
+/*-------------------------------------------------------------------------
+ *
+ * tpd.c
+ *	  zheap transaction overflow pages code
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * TPD is nothing but temporary data page consisting of extended transaction
+ * slots from heap pages.  There are two primary reasons for having TPD (a) In
+ * the heap page, we have fixed number of transaction slots which can lead to
+ * deadlock, (b) To support cases where a large number of transactions acquire
+ * SHARE or KEY SHARE locks on a single page.
+ *
+ * The TPD overflow pages will be stored in the zheap itself, interleaved with
+ * regular pages.  We have a meta page in zheap from which all overflow pages
+ * are tracked.
+ *
+ * TPD Entry acts like an extension of the transaction slot array in heap
+ * page.  Tuple headers normally point to the transaction slot responsible for
+ * the last modification, but since there aren't enough bits available to do
+ * this in the case where a TPD is used, an offset -> slot mapping is stored
+ * in the TPD entry itself.  This array can be used to get the slot for tuples
+ * in heap page, but for undo tuples we can't use it because we can't track
+ * multiple slots that have updated the same tuple.  So for undo records, we
+ * record the TPD transaction slot number along with the undo record.
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/zheap/tpd.c
+ *
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include "access/tpd.h"
+#include "access/tpd_xlog.h"
+#include "access/zheap.h"
+#include "access/zheapam_xlog.h"
+#include "miscadmin.h"
+#include "storage/bufmgr.h"
+#include "storage/buf_internals.h"
+#include "storage/lmgr.h"
+#include "storage/proc.h"
+#include "utils/lsyscache.h"
+#include "utils/relfilenodemap.h"
+
+/*
+ * We never need more than two TPD buffers per zheap page, so the maximum
+ * number of TPD buffers required will be four.  This can happen for
+ * non-inplace updates that insert new record to a different zheap page.  In
+ * general, we require one tpd page for zheap page, but for the cases when
+ * we need to extend the tpd entry to a different page, we will operate on
+ * two tpd buffers.
+ */
+#define MAX_TPD_BUFFERS	4
+
+/* Undo block number to buffer mapping. */
+typedef struct TPDBuffers
+{
+	BlockNumber blk;			/* block number */
+	Buffer		buf;			/* buffer allocated for the block */
+} TPDBuffers;
+
+/*
+ * GetTPDBuffer operations
+ *
+ * TPD_BUF_FIND - Find the buffer in existing array of tpd buffers.
+ * TPD_BUF_FIND_OR_ENTER - Like previous, but if not found then allocate a new
+ * buffer and add it to tpd buffers array for future use.
+ * TPD_BUF_FIND_OR_KNOWN_ENTER - Like TPD_BUF_FIND, but if not found, then add
+ * the already known buffer to tpd buffers array for future use.
+ * TPD_BUF_ENTER - Allocate a new TPD buffer and add it to tpd buffers array
+ * for future use.
+ */
+typedef enum
+{
+	TPD_BUF_FIND,
+	TPD_BUF_FIND_OR_ENTER,
+	TPD_BUF_FIND_OR_KNOWN_ENTER,
+	TPD_BUF_ENTER
+} TPDACTION;
+
+static Buffer registered_tpd_buffers[MAX_TPD_BUFFERS];
+static TPDBuffers tpd_buffers[MAX_TPD_BUFFERS];
+static int	tpd_buf_idx;
+static int	registered_tpd_buf_idx;
+static int	GetTPDBuffer(Relation rel, BlockNumber blk, Buffer tpd_buf,
+						 TPDACTION tpd_action, bool *already_exists);
+static void TPDEntryUpdate(Relation relation, Buffer tpd_buf,
+						   uint16 tpd_e_offset, OffsetNumber tpd_item_off,
+						   char *tpd_entry, Size size_tpd_entry);
+static void TPDAllocatePageAndAddEntry(Relation relation, Buffer metabuf,
+									   Buffer pagebuf, Buffer old_tpd_buf,
+									   OffsetNumber old_off_num, char *tpd_entry,
+									   Size size_tpd_entry, bool add_new_tpd_page,
+									   bool delete_old_entry, bool always_extend);
+static bool TPDBufferAlreadyRegistered(Buffer tpd_buf);
+static void ReleaseLastTPDBuffer(Buffer buf, bool locked);
+static void LogAndClearTPDLocation(Relation relation, Buffer heapbuf,
+								   bool *tpd_e_pruned);
+static bool TPDPageIsValid(Relation relation, Buffer heapbuf,
+						   bool *tpd_e_pruned, Buffer tpd_buf,
+						   OffsetNumber tpdItemOff,
+						   TPDEntryHeaderData *tpd_e_hdr,
+						   bool clean_tpd_loc,
+						   bool is_tpd_buf_locked);
+
+void
+ResetRegisteredTPDBuffers()
+{
+	registered_tpd_buf_idx = 0;
+}
+
+/*
+ * GetTPDBuffer - Get the tpd buffer corresponding to give block number.
+ *
+ * Returns -1, if the tpd_action is TPD_BUF_FIND and buffer for the required
+ * block is not present in tpd buffers array, otherwise returns the index of
+ * buffer in the array.
+ *
+ * rel can be NULL, if user intends to just search for existing buffer.
+ */
+static int
+GetTPDBuffer(Relation rel, BlockNumber blk, Buffer tpd_buf,
+			 TPDACTION tpd_action, bool *already_exists)
+{
+	int			i;
+	Buffer		buf;
+
+	/* The number of active TPD buffers must be less than MAX_TPD_BUFFERS. */
+	Assert(tpd_buf_idx <= MAX_TPD_BUFFERS);
+	*already_exists = false;
+
+	/*
+	 * If new block needs to be allocated, then we don't need to search
+	 * existing set of buffers.
+	 */
+	if (tpd_action != TPD_BUF_ENTER)
+	{
+		/*
+		 * Don't do anything, if we already have a buffer pinned for the
+		 * required block.
+		 */
+		for (i = 0; i < tpd_buf_idx; i++)
+		{
+			if (blk == tpd_buffers[i].blk)
+			{
+				*already_exists = true;
+				return i;
+			}
+		}
+	}
+	else
+		i = tpd_buf_idx;
+
+	/*
+	 * If the buffer doesn't exist and caller doesn't intend to allocate new
+	 * buffer, then we are done.
+	 */
+	if (tpd_action == TPD_BUF_FIND && !(*already_exists))
+		return -1;
+
+	if (tpd_action == TPD_BUF_FIND_OR_KNOWN_ENTER)
+	{
+		Assert(i == tpd_buf_idx);
+		Assert(BufferIsValid(tpd_buf));
+
+		tpd_buffers[tpd_buf_idx].blk = BufferGetBlockNumber(tpd_buf);
+		tpd_buffers[tpd_buf_idx].buf = tpd_buf;
+		tpd_buf_idx++;
+
+		return i;
+	}
+
+	/*
+	 * Caller must have passed relation, if it intends to read a block that is
+	 * not already read.
+	 */
+	Assert(rel != NULL);
+
+	/*
+	 * We don't have the required buffer, so read it and remember in the TPD
+	 * buffer array.
+	 */
+	if (i == tpd_buf_idx)
+	{
+		buf = ReadBuffer(rel, blk);
+		tpd_buffers[tpd_buf_idx].blk = BufferGetBlockNumber(buf);
+		tpd_buffers[tpd_buf_idx].buf = buf;
+		tpd_buf_idx++;
+	}
+
+	return i;
+}
+
+/*
+ * TPDBufferAlreadyRegistered - Check whether the buffer is already registered.
+ *
+ * Returns true if the buffer is already registered, otherwise add it to the
+ * registered buffer array and return false.
+ */
+static bool
+TPDBufferAlreadyRegistered(Buffer tpd_buf)
+{
+	int			i;
+
+	for (i = 0; i < registered_tpd_buf_idx; i++)
+	{
+		if (tpd_buf == registered_tpd_buffers[i])
+			return true;
+	}
+
+	registered_tpd_buffers[registered_tpd_buf_idx++] = tpd_buf;
+
+	return false;
+}
+
+/*
+ * ReleaseLastTPDBuffer - Release last tpd buffer.
+ */
+static void
+ReleaseLastTPDBuffer(Buffer buf, bool locked)
+{
+	Buffer		last_tpd_buf PG_USED_FOR_ASSERTS_ONLY;
+
+	last_tpd_buf = tpd_buffers[tpd_buf_idx - 1].buf;
+	Assert(buf == last_tpd_buf);
+	if (locked)
+		UnlockReleaseBuffer(buf);
+	else
+		ReleaseBuffer(buf);
+	tpd_buffers[tpd_buf_idx - 1].buf = InvalidBuffer;
+	tpd_buffers[tpd_buf_idx - 1].blk = InvalidBlockNumber;
+	tpd_buf_idx--;
+}
+
+/*
+ * AllocateAndFormTPDEntry - Allocate and form the new TPD entry.
+ *
+ * We initialize the TPD entry and also move the last transaction slot
+ * information from heap page to first slot in TPD entry.
+ *
+ * reserved_slot - returns the first available slot.
+ */
+static char *
+AllocateAndFormTPDEntry(Buffer buf, OffsetNumber offset,
+						Size *size_tpd_entry, int *reserved_slot)
+{
+	Size		size_tpd_e_map;
+	Size		size_tpd_e_slots;
+	int			i;
+	OffsetNumber offnum,
+				max_required_offset;
+	char	   *tpd_entry;
+	char	   *tpd_entry_data;
+	ZHeapPageOpaque zopaque;
+	TransInfo	last_trans_slot_info;
+	TransInfo  *tpd_e_trans_slots;
+	Page		page;
+	TPDEntryHeaderData tpe_header;
+	uint16		num_map_entries;
+
+	page = BufferGetPage(buf);
+	if (OffsetNumberIsValid(offset))
+		max_required_offset = offset;
+	else
+		max_required_offset = PageGetMaxOffsetNumber(page);
+
+	num_map_entries = max_required_offset + ADDITIONAL_MAP_ELEM_IN_TPD_ENTRY;
+	Assert(num_map_entries > PageGetMaxOffsetNumber(page));
+
+	/* form tpd entry header */
+	tpe_header.blkno = BufferGetBlockNumber(buf);
+	tpe_header.tpe_num_map_entries = num_map_entries;
+	tpe_header.tpe_num_slots = INITIAL_TRANS_SLOTS_IN_TPD_ENTRY;
+	tpe_header.tpe_flags = TPE_ONE_BYTE;
+
+	size_tpd_e_map = num_map_entries * sizeof(uint8);
+	size_tpd_e_slots = INITIAL_TRANS_SLOTS_IN_TPD_ENTRY * sizeof(TransInfo);
+
+	/* form transaction slots for tpd entry */
+	tpd_e_trans_slots = (TransInfo *) palloc(size_tpd_e_slots);
+
+	for (i = 0; i < INITIAL_TRANS_SLOTS_IN_TPD_ENTRY; i++)
+	{
+		tpd_e_trans_slots[i].fxid = InvalidFullTransactionId;
+		tpd_e_trans_slots[i].urec_ptr = InvalidUndoRecPtr;
+	}
+
+	/*
+	 * Move the last transaction slot information from heap page to first
+	 * transaction slot in TPD entry.
+	 */
+	zopaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+	last_trans_slot_info = zopaque->transinfo[ZHEAP_PAGE_TRANS_SLOTS - 1];
+
+	tpd_e_trans_slots[0].fxid = last_trans_slot_info.fxid;
+	tpd_e_trans_slots[0].urec_ptr = last_trans_slot_info.urec_ptr;
+
+	/* form tpd entry */
+	*size_tpd_entry = SizeofTPDEntryHeader + size_tpd_e_map +
+		size_tpd_e_slots;
+
+	tpd_entry = (char *) palloc0(*size_tpd_entry);
+
+	memcpy(tpd_entry, (char *) &tpe_header, SizeofTPDEntryHeader);
+
+	tpd_entry_data = tpd_entry + SizeofTPDEntryHeader;
+
+	/*
+	 * Update the itemid to slot map for all the itemid's that point to last
+	 * transaction slot in the heap page.
+	 */
+	for (offnum = FirstOffsetNumber;
+		 offnum <= PageGetMaxOffsetNumber(page);
+		 offnum = OffsetNumberNext(offnum))
+	{
+		ZHeapTupleHeader tup_hdr;
+		ItemId		itemid;
+		int			trans_slot;
+
+		itemid = PageGetItemId(page, offnum);
+
+		if (ItemIdIsDead(itemid))
+			continue;
+
+		if (!ItemIdIsUsed(itemid))
+		{
+			if (!ItemIdHasPendingXact(itemid))
+				continue;
+			trans_slot = ItemIdGetTransactionSlot(itemid);
+		}
+		else if (ItemIdIsDeleted(itemid))
+		{
+			trans_slot = ItemIdGetTransactionSlot(itemid);
+		}
+		else
+		{
+			tup_hdr = (ZHeapTupleHeader) PageGetItem(page, itemid);
+			trans_slot = ZHeapTupleHeaderGetXactSlot(tup_hdr);
+		}
+
+		/*
+		 * Update the itemid to slot map in tpd entry such that all of the
+		 * offsets corresponding to tuples that were pointing to last slot in
+		 * heap page will now point to first slot in TPD entry.
+		 */
+		if (trans_slot == ZHEAP_PAGE_TRANS_SLOTS)
+		{
+			uint8		offset_tpd_e_loc;
+
+			offset_tpd_e_loc = ZHEAP_PAGE_TRANS_SLOTS + 1;
+
+			/*
+			 * One byte access shouldn't cause unaligned access, but using
+			 * memcpy for the sake of consistency.
+			 */
+			memcpy(tpd_entry_data + (offnum - 1), (char *) &offset_tpd_e_loc,
+				   sizeof(uint8));
+		}
+	}
+
+	memcpy(tpd_entry + SizeofTPDEntryHeader + size_tpd_e_map,
+		   (char *) tpd_e_trans_slots, size_tpd_e_slots);
+
+	/*
+	 * The first slot location has been already assigned to last slot moved
+	 * from heap page.  We can safely reserve the second slot location in new
+	 * TPD entry.
+	 */
+	*reserved_slot = ZHEAP_PAGE_TRANS_SLOTS + 2;
+
+	/* be tidy */
+	pfree(tpd_e_trans_slots);
+
+	return tpd_entry;
+}
+
+/*
+ * ExtendTPDEntry - Allocate bigger TPD entry and copy the contents of old TPD
+ *  entry to new TPD entry.
+ *
+ * We are quite conservative in extending the TPD entry because the bigger the
+ * entry more is the chance of space wastage.  OTOH, it might have some
+ * performance impact because smaller the entry more is the chance of getting
+ * a request for extension.  However, we feel that as we have a mechanism to
+ * reuse the transaction slots, we shouldn't get the frequent requests for
+ * extending the entry, at the very least not in performance critical paths.
+ */
+static void
+ExtendTPDEntry(Relation relation, Buffer heapbuf, TransInfo *trans_slots,
+			   OffsetNumber offnum, int buf_idx, int old_num_map_entries,
+			   int old_num_slots, int *reserved_slot_no, UndoRecPtr *urecptr,
+			   bool *tpd_e_pruned, bool always_extend)
+{
+	TPDEntryHeaderData old_tpd_e_header,
+				tpd_e_header;
+	Page		old_tpd_page;
+	Page		heappage;
+	Buffer		old_tpd_buf;
+	Buffer		metabuf = InvalidBuffer;
+	BlockNumber tpdblk;
+	OffsetNumber max_page_offnum;
+	Size		tpdpageFreeSpace;
+	Size		new_size_tpd_entry,
+				old_size_tpd_entry,
+				new_size_tpd_e_map,
+				new_size_tpd_e_slots,
+				old_size_tpd_e_map,
+				old_size_tpd_e_slots;
+	ItemId		itemId;
+	OffsetNumber tpdItemOff;
+	int			old_loc_tpd_e_map,
+				old_loc_trans_slots;
+	int			max_reqd_map_entries;
+	int			max_reqd_slots = 0;
+	int			num_free_slots = 0;
+	int			slot_no;
+	int			entries_removed;
+	uint16		tpd_e_offset;
+	char	   *tpd_entry;
+	bool		already_exists;
+	bool		allocate_new_tpd_page = false;
+	bool		update_tpd_inplace,
+				tpd_pruned;
+
+	heappage = BufferGetPage(heapbuf);
+	max_page_offnum = PageGetMaxOffsetNumber(heappage);
+
+	/*
+	 * Select the maximum among required offset num, current map entries, and
+	 * highest page offset as the number of offset-map entries for a new TPD
+	 * entry.  We do allocate few additional map entries so that we don't need
+	 * to allocate new TPD entry soon. Also, we ensure that we don't try to
+	 * allocate more than MaxZHeapTuplesPerPage offset-map entries.
+	 */
+	max_reqd_map_entries = Max(offnum,
+							   Max(old_num_map_entries, max_page_offnum));
+	max_reqd_map_entries += ADDITIONAL_MAP_ELEM_IN_TPD_ENTRY;
+	max_reqd_map_entries = Min(max_reqd_map_entries,
+							   MaxZHeapTuplesPerPage);
+
+	/*
+	 * If there are more than fifty percent of empty slots available, then we
+	 * don't extend the number of transaction slots in new TPD entry.
+	 * Otherwise also, we extend the slots quite conservatively to avoid space
+	 * wastage.
+	 */
+	if (*reserved_slot_no != InvalidXactSlotId)
+	{
+		for (slot_no = 0; slot_no < old_num_slots; slot_no++)
+		{
+			/*
+			 * Check for the number of unreserved transaction slots in the TPD
+			 * entry.
+			 */
+			if (!FullTransactionIdIsValid(trans_slots[slot_no].fxid))
+				num_free_slots++;
+		}
+
+		if (num_free_slots >= old_num_slots / 2)
+			max_reqd_slots = old_num_slots;
+	}
+
+	if (max_reqd_slots <= 0)
+		max_reqd_slots = old_num_slots + INITIAL_TRANS_SLOTS_IN_TPD_ENTRY;
+
+	/*
+	 * The transaction slots in TPD entry are in addition to the maximum slots
+	 * in the heap page. The one-byte offset-map can store maximum up to 255
+	 * transaction slot number.
+	 */
+	if (max_reqd_slots + ZHEAP_PAGE_TRANS_SLOTS < 256)
+		new_size_tpd_e_map = max_reqd_map_entries * sizeof(uint8);
+	else
+		new_size_tpd_e_map = max_reqd_map_entries * sizeof(uint32);
+	new_size_tpd_e_slots = max_reqd_slots * sizeof(TransInfo);
+	new_size_tpd_entry = SizeofTPDEntryHeader + new_size_tpd_e_map +
+		new_size_tpd_e_slots;
+
+	/* TPD entries can't span in multiple blocks. */
+	if (new_size_tpd_entry > MaxTPDEntrySize)
+	{
+		/*
+		 * FIXME:  what we should do if TPD entry can not fit in one page?
+		 * currently we are giving error.
+		 */
+		elog(ERROR, "TPD entry size (%lu) cannot be greater than \
+			 MaxTPDEntrySize (%u)", new_size_tpd_entry, MaxTPDEntrySize);
+
+		*reserved_slot_no = InvalidXactSlotId;
+		return;
+	}
+
+	if (buf_idx != -1)
+		old_tpd_buf = tpd_buffers[buf_idx].buf;
+	else
+	{
+		GetTPDBlockAndOffset(heappage, &tpdblk, NULL);
+		buf_idx = GetTPDBuffer(relation, tpdblk, InvalidBuffer,
+							   TPD_BUF_FIND_OR_ENTER, &already_exists);
+		old_tpd_buf = tpd_buffers[buf_idx].buf;
+
+		/*
+		 * The tpd buffer must already exists as before reaching here we must
+		 * have called TPDPageGetTransactionSlots which would have read the
+		 * required buffer.
+		 */
+		Assert(already_exists);
+	}
+
+	/* The last slot in page has the address of the required TPD entry. */
+	old_tpd_page = BufferGetPage(old_tpd_buf);
+	GetTPDBlockAndOffset(BufferGetPage(heapbuf), NULL, &tpdItemOff);
+	itemId = PageGetItemId(old_tpd_page, tpdItemOff);
+	old_size_tpd_entry = ItemIdGetLength(itemId);
+
+	/* We have a lock on tpd page, so nobody can prune our tpd entry. */
+	Assert(ItemIdIsUsed(itemId));
+
+	tpdpageFreeSpace = PageGetTPDFreeSpace(old_tpd_page);
+
+	/*
+	 * Call TPDPagePrune to ensure that it will create a space adjacent to
+	 * current offset for the new (bigger) TPD entry, if possible.  Note that,
+	 * we set can_free as false. When we free a TPD page, we've to take lock
+	 * on previous block. It's possible that we already have a lock on the
+	 * same (non-inplace update on other buffer). In that case, we'll wait on
+	 * ourselves.
+	 */
+	entries_removed = TPDPagePrune(relation, old_tpd_buf, NULL, tpdItemOff,
+								   (new_size_tpd_entry - old_size_tpd_entry),
+								   false, &update_tpd_inplace, &tpd_pruned);
+
+	/*
+	 * If the item got pruned, then clear the TPD slot from the page and
+	 * return.  The entry can be pruned by ourselves or by anyone else as we
+	 * release the lock during pruning if the page is empty.
+	 */
+	if (PageIsEmpty(old_tpd_page) ||
+		!ItemIdIsUsed(itemId) ||
+		tpd_pruned)
+	{
+		LogAndClearTPDLocation(relation, heapbuf, tpd_e_pruned);
+		*reserved_slot_no = InvalidXactSlotId;
+		*tpd_e_pruned = true;
+		if (metabuf != InvalidBuffer)
+			ReleaseBuffer(metabuf);
+		return;
+	}
+
+	if (!update_tpd_inplace)
+	{
+		if (entries_removed > 0)
+			tpdpageFreeSpace = PageGetTPDFreeSpace(old_tpd_page);
+
+		if (tpdpageFreeSpace < new_size_tpd_entry)
+		{
+			/*
+			 * XXX Here, we can have an optimization such that instead of
+			 * allocating a new page, we can search other TPD pages starting
+			 * from the first_used_tpd_page till we reach last_used_tpd_page.
+			 * It is not clear whether such an optimization can help because
+			 * checking all the TPD pages isn't free either.
+			 */
+			metabuf = ReadBuffer(relation, ZHEAP_METAPAGE);
+			allocate_new_tpd_page = true;
+		}
+		else
+		{
+			/*
+			 * We must not reach here because if the new tpd entry can fit on
+			 * the same page, then update_tpd_inplace would have been set by
+			 * TPDPagePrune.
+			 */
+			Assert(false);
+		}
+	}
+
+	/* form tpd entry header */
+	tpd_e_header.blkno = BufferGetBlockNumber(heapbuf);
+	tpd_e_header.tpe_num_map_entries = max_reqd_map_entries;
+	tpd_e_header.tpe_num_slots = max_reqd_slots;
+
+	/*
+	 * The transaction slots in TPD entry are in addition to the maximum slots
+	 * in the heap page. The one-byte offset-map can store maximum up to 255
+	 * transaction slot number.
+	 */
+	if (max_reqd_slots + ZHEAP_PAGE_TRANS_SLOTS < 256)
+		tpd_e_header.tpe_flags = TPE_ONE_BYTE;
+	else
+		tpd_e_header.tpe_flags = TPE_FOUR_BYTE;
+
+	/*
+	 * If we reach here, then the page must be a TPD page.
+	 */
+	Assert(IsTPDPage(old_tpd_page));
+
+	/* TPD entry isn't pruned */
+	tpd_e_offset = ItemIdGetOffset(itemId);
+
+	memcpy((char *) &old_tpd_e_header, old_tpd_page + tpd_e_offset, SizeofTPDEntryHeader);
+
+	/* We should never access deleted entry. */
+	Assert(!TPDEntryIsDeleted(old_tpd_e_header));
+
+	/* This TPD entry can't be for some other block. */
+	Assert(old_tpd_e_header.blkno == BufferGetBlockNumber(heapbuf));
+
+	if (old_tpd_e_header.tpe_flags & TPE_ONE_BYTE)
+		old_size_tpd_e_map = old_tpd_e_header.tpe_num_map_entries * sizeof(uint8);
+	else
+	{
+		Assert(old_tpd_e_header.tpe_flags & TPE_FOUR_BYTE);
+		old_size_tpd_e_map = old_tpd_e_header.tpe_num_map_entries * sizeof(uint32);
+	}
+
+	old_size_tpd_e_slots = old_tpd_e_header.tpe_num_slots * sizeof(TransInfo);
+	old_loc_tpd_e_map = tpd_e_offset + SizeofTPDEntryHeader;
+	old_loc_trans_slots = tpd_e_offset + SizeofTPDEntryHeader + old_size_tpd_e_map;
+
+	/* Form new TPD entry.  Whatever be the case, header will remain same. */
+	tpd_entry = (char *) palloc0(new_size_tpd_entry);
+	memcpy(tpd_entry, (char *) &tpd_e_header, SizeofTPDEntryHeader);
+
+	if (tpd_e_header.tpe_flags & TPE_ONE_BYTE ||
+		(tpd_e_header.tpe_flags & TPE_FOUR_BYTE &&
+		 old_tpd_e_header.tpe_flags & TPE_FOUR_BYTE))
+	{
+		/*
+		 * Caller must try to extend the TPD entry iff either there is a need
+		 * of more offset-map entries or transaction slots.
+		 */
+		Assert(tpd_e_header.tpe_num_map_entries >= old_num_map_entries);
+		Assert(tpd_e_header.tpe_num_slots >= old_num_slots);
+
+		/*
+		 * In this case we can copy the contents of old offset-map and old
+		 * transaction slots as it is.
+		 */
+		memcpy(tpd_entry + SizeofTPDEntryHeader,
+			   old_tpd_page + old_loc_tpd_e_map,
+			   old_size_tpd_e_map);
+		memcpy(tpd_entry + SizeofTPDEntryHeader + new_size_tpd_e_map,
+			   old_tpd_page + old_loc_trans_slots,
+			   old_size_tpd_e_slots);
+	}
+	else if (tpd_e_header.tpe_flags & TPE_FOUR_BYTE &&
+			 old_tpd_e_header.tpe_flags & TPE_ONE_BYTE)
+	{
+		int			i;
+		char	   *new_start_loc,
+				   *old_start_loc;
+
+		/*
+		 * Here, we can't directly copy the offset-map because we are
+		 * expanding it from one byte to four-bytes.  We need to perform
+		 * byte-by-byte copy for the offset-map.  However, transaction slots
+		 * can be directly copied as the size for each slot still remains
+		 * same.
+		 */
+		Assert(old_tpd_e_header.tpe_num_map_entries == old_num_map_entries);
+
+		new_start_loc = tpd_entry + SizeofTPDEntryHeader;
+		old_start_loc = old_tpd_page + old_loc_tpd_e_map;
+
+		for (i = 0; i < old_num_map_entries; i++)
+		{
+			memcpy(new_start_loc, old_start_loc, sizeof(uint8));
+			old_start_loc += sizeof(uint8);
+			new_start_loc += sizeof(uint32);
+		}
+
+		memcpy(tpd_entry + SizeofTPDEntryHeader + new_size_tpd_e_map,
+			   old_tpd_page + old_loc_trans_slots,
+			   old_size_tpd_e_slots);
+	}
+	else
+	{
+		/* All the valid cases should have been dealt above. */
+		Assert(false);
+	}
+
+	if (update_tpd_inplace)
+	{
+		TPDEntryUpdate(relation, old_tpd_buf, tpd_e_offset, tpdItemOff,
+					   tpd_entry, new_size_tpd_entry);
+	}
+	else
+	{
+		/*
+		 * Note that if we have to allocate a new page, we must delete the old
+		 * tpd entry in old tpd buffer.
+		 */
+		TPDAllocatePageAndAddEntry(relation, metabuf, heapbuf, old_tpd_buf,
+								   tpdItemOff, tpd_entry, new_size_tpd_entry,
+								   allocate_new_tpd_page,
+								   allocate_new_tpd_page, always_extend);
+	}
+
+	/* Release the meta buffer. */
+	if (metabuf != InvalidBuffer)
+		ReleaseBuffer(metabuf);
+
+	if (*reserved_slot_no == InvalidXactSlotId)
+	{
+		int			slot_no;
+
+		trans_slots = (TransInfo *) (tpd_entry + SizeofTPDEntryHeader + new_size_tpd_e_map);
+
+		for (slot_no = 0; slot_no < tpd_e_header.tpe_num_slots; slot_no++)
+		{
+			/* Check for an unreserved transaction slot in the TPD entry */
+			if (!FullTransactionIdIsValid(trans_slots[slot_no].fxid))
+			{
+				*reserved_slot_no = slot_no;
+				break;
+			}
+		}
+	}
+
+	if (*reserved_slot_no != InvalidXactSlotId)
+		*urecptr = trans_slots[*reserved_slot_no].urec_ptr;
+
+	pfree(tpd_entry);
+
+	return;
+}
+
+/*
+ * TPDPageAddEntry - Add the given to TPD entry on the page and
+ * move the upper to point to the next free location.
+ *
+ * Return value is the offset at which it was inserted, or InvalidOffsetNumber
+ * if the item is not inserted for any reason.  A WARNING is issued indicating
+ * the reason for the refusal.
+ *
+ * This function is same as PageAddItemExtended, but has different
+ * alignment requirements.  We might want to deal with that by passing
+ * additional argument to PageAddItemExtended, but for now we have kept
+ * it as a separate function.
+ */
+OffsetNumber
+TPDPageAddEntry(Page tpdpage, char *tpd_entry, Size size,
+				OffsetNumber offnum)
+{
+	PageHeader	phdr = (PageHeader) tpdpage;
+	OffsetNumber limit;
+	ItemId		itemId;
+	uint16		lower;
+	uint16		upper;
+
+	/*
+	 * Be wary about corrupted page pointers
+	 */
+	if (phdr->pd_lower < SizeOfPageHeaderData ||
+		phdr->pd_lower > phdr->pd_upper ||
+		phdr->pd_upper > phdr->pd_special ||
+		phdr->pd_special > BLCKSZ)
+		ereport(PANIC,
+				(errcode(ERRCODE_DATA_CORRUPTED),
+				 errmsg("corrupted page pointers: lower = %u, upper = %u, special = %u",
+						phdr->pd_lower, phdr->pd_upper, phdr->pd_special)));
+
+	/*
+	 * Select offsetNumber to place the new item at
+	 */
+	limit = OffsetNumberNext(PageGetMaxOffsetNumber(tpdpage));
+
+	lower = phdr->pd_lower + sizeof(ItemIdData);
+
+	if (OffsetNumberIsValid(offnum))
+	{
+		/*
+		 * In TPD, we send valid offset number only during recovery. Hence, we
+		 * don't need to shuffle the offsets as well.
+		 */
+		Assert(InRecovery);
+		if (offnum < limit)
+		{
+			itemId = PageGetItemId(phdr, offnum);
+			if (ItemIdIsUsed(itemId) || ItemIdHasStorage(itemId))
+			{
+				elog(WARNING, "will not overwrite a used ItemId");
+				return InvalidOffsetNumber;
+			}
+		}
+	}
+	else
+	{
+		/* offsetNumber was not passed in, so find a free slot */
+		/* if no free slot, we'll put it at limit (1st open slot) */
+		if (PageHasFreeLinePointers(phdr))
+		{
+			/*
+			 * Look for "recyclable" (unused) ItemId.  We check for no storage
+			 * as well, just to be paranoid --- unused items should never have
+			 * storage.
+			 */
+			for (offnum = 1; offnum < limit; offnum++)
+			{
+				itemId = PageGetItemId(phdr, offnum);
+				if (!ItemIdIsUsed(itemId) && !ItemIdHasStorage(itemId))
+					break;
+			}
+			if (offnum >= limit)
+			{
+				/* the hint is wrong, so reset it */
+				PageClearHasFreeLinePointers(phdr);
+			}
+		}
+		else
+		{
+			offnum = limit;
+		}
+	}
+
+	/* Reject placing items beyond the first unused line pointer */
+	if (offnum > limit)
+	{
+		elog(WARNING, "specified item offset is too large");
+		return InvalidOffsetNumber;
+	}
+
+	/* Reject placing items beyond tpd boundary */
+	if (offnum > MaxTPDTuplesPerPage)
+	{
+		elog(WARNING, "can't put more than MaxTPDTuplesPerPage items in a tpd page");
+		return InvalidOffsetNumber;
+	}
+
+	/*
+	 * Compute new lower and upper pointers for page, see if it'll fit.
+	 *
+	 * Note: do arithmetic as signed int, to avoid mistakes if, say,
+	 * alignedSize > pd_upper.
+	 */
+	if (offnum == limit)
+		lower = phdr->pd_lower + sizeof(ItemIdData);
+	else
+		lower = phdr->pd_lower;
+
+	upper = (int) phdr->pd_upper - (int) size;
+
+	if (lower > upper)
+		return InvalidOffsetNumber;
+
+	/* OK to insert the item. */
+	itemId = PageGetItemId(phdr, offnum);
+
+	/* set the item pointer */
+	ItemIdSetNormal(itemId, upper, size);
+
+	/* copy the item's data onto the page */
+	memcpy((char *) tpdpage + upper, tpd_entry, size);
+
+	phdr->pd_lower = (LocationIndex) lower;
+	phdr->pd_upper = (LocationIndex) upper;
+
+	return offnum;
+}
+
+/*
+ * SetTPDLocation - Set TPD entry location in the last transaction slot of
+ *		heap page and indicate the same in page.
+ */
+void
+SetTPDLocation(Buffer heapbuffer, Buffer tpdbuffer, OffsetNumber offset)
+{
+	Page		heappage;
+	PageHeader	phdr;
+	ZHeapPageOpaque opaque;
+	TransInfo  *transinfo;
+
+	heappage = BufferGetPage(heapbuffer);
+	phdr = (PageHeader) heappage;
+
+	opaque = (ZHeapPageOpaque) PageGetSpecialPointer(heappage);
+	transinfo = &opaque->transinfo[ZHEAP_PAGE_TRANS_SLOTS - 1];
+
+	/* clear the last transaction slot info */
+	transinfo->fxid = InvalidFullTransactionId;
+	transinfo->urec_ptr = InvalidUndoRecPtr;
+	/* set TPD location in last transaction slot */
+	transinfo->fxid = FullTransactionIdFromEpochAndXid(
+													   BufferGetBlockNumber(tpdbuffer), offset);
+
+	phdr->pd_flags |= PD_PAGE_HAS_TPD_SLOT;
+}
+
+/*
+ * ClearTPDLocation - Clear TPD entry location in the last transaction slot of
+ *		heap page and indicate the same in page.
+ */
+void
+ClearTPDLocation(Buffer heapbuf)
+{
+	PageHeader	phdr;
+	ZHeapPageOpaque opaque;
+	Page		heappage;
+	int			frozen_slots = ZHEAP_PAGE_TRANS_SLOTS - 1;
+	TransInfo  *transinfo;
+
+	heappage = BufferGetPage(heapbuf);
+	phdr = (PageHeader) heappage;
+
+	/*
+	 * Before clearing the TPD slot, mark all the tuples pointing to TPD slot
+	 * as frozen.
+	 */
+	zheap_freeze_or_invalidate_tuples(heapbuf, 1, &frozen_slots,
+									  true, false);
+
+	opaque = (ZHeapPageOpaque) PageGetSpecialPointer(heappage);
+	transinfo = &opaque->transinfo[ZHEAP_PAGE_TRANS_SLOTS - 1];
+
+	/* clear the last transaction slot info */
+	transinfo->fxid = InvalidFullTransactionId;
+	transinfo->urec_ptr = InvalidUndoRecPtr;
+
+	phdr->pd_flags &= ~PD_PAGE_HAS_TPD_SLOT;
+}
+
+/*
+ * LogClearTPDLocation - Write a WAL record for clearing TPD location.
+ */
+static void
+LogClearTPDLocation(Buffer buffer)
+{
+	XLogRecPtr	recptr;
+
+	XLogBeginInsert();
+	XLogRegisterBuffer(0, buffer, REGBUF_STANDARD);
+
+	recptr = XLogInsert(RM_TPD_ID, XLOG_TPD_CLEAR_LOCATION);
+
+	PageSetLSN(BufferGetPage(buffer), recptr);
+}
+
+/*
+ * LogAndClearTPDLocation - Clear the TPD location from heap page and WAL log
+ *			it.
+ */
+static void
+LogAndClearTPDLocation(Relation relation, Buffer heapbuf, bool *tpd_e_pruned)
+{
+	START_CRIT_SECTION();
+
+	ClearTPDLocation(heapbuf);
+	MarkBufferDirty(heapbuf);
+	if (RelationNeedsWAL(relation))
+		LogClearTPDLocation(heapbuf);
+
+	END_CRIT_SECTION();
+
+	if (tpd_e_pruned)
+		*tpd_e_pruned = true;
+}
+
+/*
+ * TPDInitPage - Initialize the TPD page.
+ */
+void
+TPDInitPage(Page page, Size pageSize)
+{
+	TPDPageOpaque tpdopaque;
+
+	PageInit(page, pageSize, sizeof(TPDPageOpaqueData));
+
+	tpdopaque = (TPDPageOpaque) PageGetSpecialPointer(page);
+	tpdopaque->tpd_prevblkno = InvalidBlockNumber;
+	tpdopaque->tpd_nextblkno = InvalidBlockNumber;
+	tpdopaque->tpd_latest_fxid = InvalidFullTransactionId;
+}
+
+/*
+ * TPDFreePage - Remove the TPD page from the chain.
+ *
+ * Initialize the empty page and remove it from the chain.  This function
+ * ensures that the buffers are locked such that the block that exists prior
+ * in chain gets locked first and meta page is locked at end after which no
+ * existing page is locked.  This is to avoid deadlocks, see comments atop
+ * function TPDAllocatePageAndAddEntry.
+ *
+ * We expect that the caller must have acquired EXCLUSIVE lock on the current
+ * buffer (buf) and will be responsible for releasing the same.
+ *
+ * Returns true, if we are able to successfully remove the page from chain,
+ * false, otherwise.
+ */
+bool
+TPDFreePage(Relation rel, Buffer buf, BufferAccessStrategy bstrategy)
+{
+	TPDPageOpaque tpdopaque,
+				prevtpdopaque,
+				nexttpdopaque;
+	ZHeapMetaPage metapage;
+	Page		page,
+				prevpage = NULL,
+				nextpage = NULL;
+	BlockNumber curblkno PG_USED_FOR_ASSERTS_ONLY = InvalidBlockNumber;
+	BlockNumber prevblkno = InvalidBlockNumber;
+	BlockNumber nextblkno = InvalidBlockNumber;
+	Buffer		prevbuf = InvalidBuffer;
+	Buffer		nextbuf = InvalidBuffer;
+	Buffer		metabuf = InvalidBuffer;
+	bool		update_meta = false;
+
+	/* Get the page from buffer. */
+	page = BufferGetPage(buf);
+
+	/* Page should be an empty TPD page. */
+	Assert(IsTPDPage(page) && PageIsEmpty(page));
+
+	/*
+	 * We must acquire the cleanup lock here to wait for backends that have
+	 * already read this buffer and might be in the process of deciding
+	 * whether this is a valid TPD page (aka it contain valid TPD entries).
+	 * All of them must reach a conclusion, that there is no valid TPD entry
+	 * in this page as we have already pruned all TPD entries from this page
+	 * by this time.  If we don't wait here for other backends who have
+	 * already read this page, then it is possible that by the time they try
+	 * to acquire lock on this page, we would have freed this page and some
+	 * other backend could have reused it as heap page and had a lock on it.
+	 * In such a situation, the system can deadlock because the backend-1
+	 * which tries to acquire a lock on this page thinking it is a TPD page
+	 * would wait on backend-2 which has reused it as a heap page and
+	 * backend-2 can wait start waiting on some page on which backend-1 has a
+	 * lock (this can usually happen when multiple heap buffers are involved
+	 * in a single operation like in case of non-in-place updates).
+	 *
+	 * For new backends that come to access this as a TPD page after we
+	 * acquire cleanup lock here would definitely see this as a invalid TPD
+	 * page (no valid TPD entries).
+	 *
+	 * One can imagine that after we release the lock, vacuum or some other
+	 * process can record this page in FSM, but that is not possible as we
+	 * haven't cleared the special space which will make it appear as a TPD
+	 * page and it will just ignore this page.  See lazy_scan_zheap.
+	 */
+	LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+	LockBufferForCleanup(buf);
+
+	/*
+	 * Page should be still a TPD page but it can be non-empty because we
+	 * re-acquiried the lock.
+	 */
+	Assert(IsTPDPage(page));
+
+	/*
+	 * After re-acquiring the lock, check whether page is still empty, if not,
+	 * then we don't need to do anything.  As of now, there is no possibility
+	 * that the empty page in the chain can be reused, however, in future, we
+	 * can use it.
+	 */
+	if (!PageIsEmpty(page))
+		return false;
+
+	curblkno = BufferGetBlockNumber(buf);
+	tpdopaque = (TPDPageOpaque) PageGetSpecialPointer(page);
+	prevblkno = tpdopaque->tpd_prevblkno;
+
+	/* Fetch and lock the previous block, if exists. */
+	if (BlockNumberIsValid(prevblkno))
+	{
+		/*
+		 * Before taking the lock on previous block, we need to release the
+		 * lock on the current buffer.  This is to ensure that we always lock
+		 * the buffers in the order in which they are present in list.  This
+		 * avoids the deadlock risks.  See atop TPDAllocatePageAndAddEntry.
+		 */
+		LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+		prevbuf = ReadBufferExtended(rel, MAIN_FORKNUM, prevblkno, RBM_NORMAL,
+									 bstrategy);
+		LockBuffer(prevbuf, BUFFER_LOCK_EXCLUSIVE);
+		LockBuffer(buf, BUFFER_LOCK_EXCLUSIVE);
+
+		/*
+		 * After re-acquiring the lock, check whether page is still empty, if
+		 * not, then we don't need to do anything.  As of now, there is no
+		 * possibility that the empty page in the chain can be reused,
+		 * however, in future, we can use it.
+		 *
+		 * Page should be still a TPD page but it can be non-empty because we
+		 * re-acquiried the lock.
+		 */
+		Assert(IsTPDPage(page));
+		if (!PageIsEmpty(page))
+		{
+			UnlockReleaseBuffer(prevbuf);
+			return false;
+		}
+	}
+
+	nextblkno = tpdopaque->tpd_nextblkno;
+
+	/* Fetch and lock the next buffer. */
+	if (BlockNumberIsValid(nextblkno))
+	{
+		nextbuf = ReadBufferExtended(rel, MAIN_FORKNUM, nextblkno, RBM_NORMAL,
+									 bstrategy);
+		LockBuffer(nextbuf, BUFFER_LOCK_EXCLUSIVE);
+	}
+
+	metabuf = ReadBufferExtended(rel, MAIN_FORKNUM, ZHEAP_METAPAGE,
+								 RBM_NORMAL, bstrategy);
+	LockBuffer(metabuf, BUFFER_LOCK_EXCLUSIVE);
+
+	metapage = ZHeapPageGetMeta(BufferGetPage(metabuf));
+	Assert(metapage->zhm_magic == ZHEAP_MAGIC);
+
+	START_CRIT_SECTION();
+
+	/*
+	 * Update the current page so that it can be reused as new TPD or zheap
+	 * page from FSM.
+	 * Here, we will meset full page as zero because if we will not do this,
+	 * then from RelationGetBufferForZTuple, it will be costly to decide that
+	 * page is still in meta list or not because it is possible that empty TPD
+	 * page is still in meta list(see ExtendTPDEntry, there we can make page
+	 * as empty and will not remove from mera list to avoid deadlock).
+	 */
+	MemSet((PageHeader) page, 0, BufferGetPageSize(buf));
+
+	MarkBufferDirty(buf);
+
+	/* Update the previous page. */
+	if (BufferIsValid(prevbuf))
+	{
+		prevpage = BufferGetPage(prevbuf);
+		prevtpdopaque = (TPDPageOpaque) PageGetSpecialPointer(prevpage);
+
+		prevtpdopaque->tpd_nextblkno = nextblkno;
+		MarkBufferDirty(prevbuf);
+	}
+	/* Update the next page. */
+	if (BufferIsValid(nextbuf))
+	{
+		nextpage = BufferGetPage(nextbuf);
+		nexttpdopaque = (TPDPageOpaque) PageGetSpecialPointer(nextpage);
+
+		nexttpdopaque->tpd_prevblkno = prevblkno;
+		MarkBufferDirty(nextbuf);
+	}
+
+	/*
+	 * Update the metapage.  If the previous or next block is invalid, the
+	 * page to be removed could be first or last page in the chain in which
+	 * case we need to update the metapage accordingly.
+	 */
+	if (!BlockNumberIsValid(prevblkno) ||
+		!BlockNumberIsValid(nextblkno))
+	{
+		if (!BlockNumberIsValid(prevblkno) && !BlockNumberIsValid(nextblkno))
+		{
+			/*
+			 * If there is no prevblock and nextblock, then the current page
+			 * must be the first and the last page.
+			 */
+			Assert(metapage->zhm_first_used_tpd_page == curblkno);
+			Assert(metapage->zhm_last_used_tpd_page == curblkno);
+			metapage->zhm_first_used_tpd_page = InvalidBlockNumber;
+			metapage->zhm_last_used_tpd_page = InvalidBlockNumber;
+		}
+		else if (!BlockNumberIsValid(prevblkno))
+		{
+			/*
+			 * If there is no prevblock, then the current block must be first
+			 * used page.
+			 */
+			Assert(BlockNumberIsValid(nextblkno));
+			metapage->zhm_first_used_tpd_page = nextblkno;
+		}
+		else if (!BlockNumberIsValid(nextblkno))
+		{
+			/*
+			 * If next block is invalid, then the current block must be last
+			 * used page.
+			 */
+			Assert(metapage->zhm_last_used_tpd_page == curblkno);
+			metapage->zhm_last_used_tpd_page = prevblkno;
+		}
+		else
+		{
+			/* one of the above two conditions must be satisfied. */
+			Assert(false);
+		}
+
+		MarkBufferDirty(metabuf);
+		update_meta = true;
+	}
+	else
+	{
+		/*
+		 * If next block is a valid block then the last used page can't be the
+		 * current page being removed.
+		 */
+		Assert(metapage->zhm_last_used_tpd_page != curblkno);
+	}
+
+	if (RelationNeedsWAL(rel))
+	{
+		XLogRecPtr	recptr;
+		xl_tpd_free_page xlrec;
+		uint8		info = XLOG_TPD_FREE_PAGE;
+
+		xlrec.prevblkno = prevblkno;
+		xlrec.nextblkno = nextblkno;
+
+		XLogBeginInsert();
+		XLogRegisterData((char *) &xlrec, SizeOfTPDFreePage);
+		if (BufferIsValid(prevbuf))
+			XLogRegisterBuffer(0, prevbuf, REGBUF_STANDARD);
+		XLogRegisterBuffer(1, buf, REGBUF_STANDARD);
+		if (BufferIsValid(nextbuf))
+			XLogRegisterBuffer(2, nextbuf, REGBUF_STANDARD);
+		if (update_meta)
+		{
+			xl_zheap_metadata xl_meta;
+
+			info |= XLOG_TPD_INIT_PAGE;
+			xl_meta.first_used_tpd_page = metapage->zhm_first_used_tpd_page;
+			xl_meta.last_used_tpd_page = metapage->zhm_last_used_tpd_page;
+			XLogRegisterBuffer(3, metabuf, REGBUF_STANDARD | REGBUF_WILL_INIT);
+			XLogRegisterBufData(3, (char *) &xl_meta, SizeOfMetaData);
+		}
+
+		recptr = XLogInsert(RM_TPD_ID, info);
+
+		if (BufferIsValid(prevbuf))
+			PageSetLSN(prevpage, recptr);
+		if (BufferIsValid(nextbuf))
+			PageSetLSN(nextpage, recptr);
+		if (update_meta)
+			PageSetLSN(BufferGetPage(metabuf), recptr);
+	}
+
+	END_CRIT_SECTION();
+
+	if (BufferIsValid(prevbuf))
+		UnlockReleaseBuffer(prevbuf);
+	if (BufferIsValid(nextbuf))
+		UnlockReleaseBuffer(nextbuf);
+	UnlockReleaseBuffer(metabuf);
+
+	return true;
+}
+
+/*
+ * TPDEntryUpdate - Update the TPD entry inplace and write a WAL record for
+ *					the same.
+ */
+static void
+TPDEntryUpdate(Relation relation, Buffer tpd_buf, uint16 tpd_e_offset,
+			   OffsetNumber tpd_item_off, char *tpd_entry,
+			   Size size_tpd_entry)
+{
+	Page		tpd_page = BufferGetPage(tpd_buf);
+	ItemId		itemId = PageGetItemId(tpd_page, tpd_item_off);
+
+	START_CRIT_SECTION();
+
+	memcpy((char *) (tpd_page + tpd_e_offset),
+		   tpd_entry,
+		   size_tpd_entry);
+	ItemIdChangeLen(itemId, size_tpd_entry);
+
+	MarkBufferDirty(tpd_buf);
+
+	if (RelationNeedsWAL(relation))
+	{
+		XLogRecPtr	recptr;
+
+		XLogBeginInsert();
+		XLogRegisterBuffer(0, tpd_buf, REGBUF_STANDARD);
+		XLogRegisterBufData(0, (char *) &tpd_item_off, sizeof(OffsetNumber));
+		XLogRegisterBufData(0, (char *) tpd_entry, size_tpd_entry);
+
+		recptr = XLogInsert(RM_TPD_ID, XLOG_INPLACE_UPDATE_TPD_ENTRY);
+
+		PageSetLSN(tpd_page, recptr);
+	}
+
+	END_CRIT_SECTION();
+}
+
+/*
+ * TPDAllocatePageAndAddEntry - Allocates a new tpd page if required and adds
+ *								tpd entry.
+ *
+ * This function takes care of inserting the new tpd entry to a page and
+ * allows to mark old entry as deleted when requested.  The typical actions
+ * performed in this function are (a) add a TPD entry in the newly allocated
+ * or an existing TPD page, (b) update the metapage to indicate the addition of
+ * a new page (if allocated) and for updating zhm_last_used_tpd_page, (c) mark
+ * the old TPD entry as prunable, (c) update the new offset number of TPD
+ * entry in heap page. Finally write a WAL entry and corresponding replay
+ * routine to cover all these operations and release all the buffers.
+ *
+ * The other aspect this function needs to ensure is the buffer locking order
+ * to avoid deadlocks.  We operate on four buffers: metapage buffer, old tpd
+ * page buffer, last used tpd page buffer and new tpd page buffer.  The old
+ * buffer is always locked by the caller and we ensure that this function first
+ * locks the last used tpd page buffer, then locks the metapage buffer and then
+ * the newly allocated page buffer.  This locking can never lead to deadlock as
+ * old buffer block will always be lesser (or equal) than last buffer block.
+ * However, if anytime we change our strategy such that after acquiring
+ * metapage lock we try to acquire lock on any existing page, then we might
+ * need to reconsider our locking order.
+ *
+ * always_extend, this parameter indicates whether we can use FSM to get the
+ * new TPD page or not.  This is required to avoid some deadlock hazards by
+ * the callers, basically they don't want to lock any tpd page with lower
+ * number, when they already have lock on some other tpd page.
+ */
+static void
+TPDAllocatePageAndAddEntry(Relation relation, Buffer metabuf, Buffer pagebuf,
+						   Buffer old_tpd_buf, OffsetNumber old_off_num,
+						   char *tpd_entry, Size size_tpd_entry,
+						   bool add_new_tpd_page, bool delete_old_entry,
+						   bool always_extend)
+{
+	ZHeapMetaPage metapage = NULL;
+	TPDPageOpaque tpdopaque,
+				last_tpdopaque;
+	TPDEntryHeader old_tpd_entry;
+	Buffer		last_used_tpd_buf = InvalidBuffer;
+	Buffer		tpd_buf;
+	Page		tpdpage;
+	BlockNumber prevblk = InvalidBlockNumber;
+	BlockNumber nextblk = InvalidBlockNumber;
+	BlockNumber last_used_tpd_page;
+	OffsetNumber offset_num;
+	bool		free_last_used_tpd_buf = false;
+
+	if (add_new_tpd_page)
+	{
+		BlockNumber targetBlock = InvalidBlockNumber;
+		Size		len = MaxTPDEntrySize;
+		int			buf_idx;
+		bool		needLock;
+		bool		already_exists;
+
+		/*
+		 * While adding a new page, if we've to delete the old entry, the old
+		 * buffer must be valid. Else, it should be invalid.
+		 */
+		Assert(!delete_old_entry || BufferIsValid(old_tpd_buf));
+		Assert(delete_old_entry || !BufferIsValid(old_tpd_buf));
+
+		/*
+		 * FIXME: We can allow the free pages to be used from FSM once we fix
+		 * lock ordering w.r.t buffer locks, otherwise it can lead to
+		 * deadlocks.
+		 */
+		always_extend = true;
+
+		/* Always extend when asked to do so. */
+		if (!always_extend)
+		{
+			/* Before extending the relation, check the FSM for free page. */
+			targetBlock = GetPageWithFreeSpace(relation, len);
+
+			while (targetBlock != InvalidBlockNumber)
+			{
+				Page		page;
+				Size		pageFreeSpace;
+
+				tpd_buf = ReadBuffer(relation, targetBlock);
+
+				/*
+				 * We need to take the lock on meta page before new page to
+				 * avoid deadlocks.  See comments atop of function.
+				 */
+				LockBuffer(metabuf, BUFFER_LOCK_EXCLUSIVE);
+
+				/*
+				 * It's possible that FSM returns a zheap page on which the
+				 * current backend already holds a lock in exclusive mode.
+				 * Hence, try using conditional lock. If it can't get the lock
+				 * immediately, extend the relation and allocate a new TPD
+				 * block.
+				 */
+				if (ConditionalLockBuffer(tpd_buf))
+				{
+					page = BufferGetPage(tpd_buf);
+
+					if (PageIsNew(page) || PageIsEmpty(page))
+					{
+						GetTPDBuffer(relation, targetBlock, tpd_buf,
+									 TPD_BUF_FIND_OR_KNOWN_ENTER,
+									 &already_exists);
+						break;
+					}
+
+					LockBuffer(metabuf, BUFFER_LOCK_UNLOCK);
+
+					if (IsTPDPage(page))
+						pageFreeSpace = PageGetTPDFreeSpace(page);
+					else
+						pageFreeSpace = PageGetZHeapFreeSpace(page);
+
+					/*
+					 * Update FSM as to condition of this page, and ask for
+					 * another page to try.
+					 */
+					targetBlock = RecordAndGetPageWithFreeSpace(relation,
+																targetBlock,
+																pageFreeSpace,
+																len);
+					UnlockReleaseBuffer(tpd_buf);
+				}
+				else
+				{
+					LockBuffer(metabuf, BUFFER_LOCK_UNLOCK);
+					ReleaseBuffer(tpd_buf);
+					targetBlock = InvalidBlockNumber;
+				}
+			}
+		}
+
+		/* Extend the relation, if required? */
+		if (targetBlock == InvalidBlockNumber)
+		{
+			/* Acquire the extension lock, if extension is required. */
+			needLock = !RELATION_IS_LOCAL(relation);
+			if (needLock)
+				LockRelationForExtension(relation, ExclusiveLock);
+
+			buf_idx = GetTPDBuffer(relation, P_NEW, InvalidBuffer,
+								   TPD_BUF_ENTER, &already_exists);
+			/* This must be a new buffer. */
+			Assert(!already_exists);
+			tpd_buf = tpd_buffers[buf_idx].buf;
+			LockBuffer(metabuf, BUFFER_LOCK_EXCLUSIVE);
+			LockBuffer(tpd_buf, BUFFER_LOCK_EXCLUSIVE);
+			targetBlock = BufferGetBlockNumber(tpd_buf);
+
+			if (needLock)
+				UnlockRelationForExtension(relation, ExclusiveLock);
+		}
+
+		/*
+		 * Once we've allocated a TPD page, we should update the FSM with the
+		 * available freespace which is zero in this case. This restricts
+		 * other backends from getting the same page from FSM.
+		 */
+		RecordPageWithFreeSpace(relation, targetBlock, 0);
+
+		/*
+		 * Lock the last tpd page in list, so that we can append new page to
+		 * it.
+		 */
+		metapage = ZHeapPageGetMeta(BufferGetPage(metabuf));
+		Assert(metapage->zhm_magic == ZHEAP_MAGIC);
+
+recheck_meta:
+		last_used_tpd_page = metapage->zhm_last_used_tpd_page;
+		if (metapage->zhm_last_used_tpd_page != InvalidBlockNumber)
+		{
+			last_used_tpd_page = metapage->zhm_last_used_tpd_page;
+			buf_idx = GetTPDBuffer(relation, last_used_tpd_page, InvalidBuffer,
+								   TPD_BUF_FIND, &already_exists);
+
+			if (buf_idx == -1)
+			{
+				last_used_tpd_buf = ReadBuffer(relation,
+											   metapage->zhm_last_used_tpd_page);
+
+				/*
+				 * To avoid deadlock, ensure that we never acquire lock on any
+				 * existing block after acquiring meta page lock.  See
+				 * comments atop function.
+				 */
+				LockBuffer(metabuf, BUFFER_LOCK_UNLOCK);
+				LockBuffer(last_used_tpd_buf, BUFFER_LOCK_EXCLUSIVE);
+				LockBuffer(metabuf, BUFFER_LOCK_EXCLUSIVE);
+
+				if (metapage->zhm_last_used_tpd_page != last_used_tpd_page)
+				{
+					UnlockReleaseBuffer(last_used_tpd_buf);
+					goto recheck_meta;
+				}
+
+				free_last_used_tpd_buf = true;
+			}
+			else
+			{
+				/* We don't need to lock the buffer, if it is already locked */
+				last_used_tpd_buf = tpd_buffers[buf_idx].buf;
+			}
+		}
+	}
+	else
+	{
+		/* old buffer must be valid */
+		Assert(BufferIsValid(old_tpd_buf));
+		tpd_buf = old_tpd_buf;
+	}
+
+	/* No ereport(ERROR) from here till changes are logged */
+	START_CRIT_SECTION();
+
+	tpdpage = BufferGetPage(tpd_buf);
+
+	/* Update metapage and add the new TPD page in the TPD page list. */
+	if (add_new_tpd_page)
+	{
+		BlockNumber tpdblkno;
+
+		/* Page must be new or empty. */
+		Assert(PageIsEmpty(tpdpage) || PageIsNew(tpdpage));
+
+		TPDInitPage(tpdpage, BufferGetPageSize(tpd_buf));
+		tpdblkno = BufferGetBlockNumber(tpd_buf);
+		tpdopaque = (TPDPageOpaque) PageGetSpecialPointer(tpdpage);
+
+		if (metapage->zhm_first_used_tpd_page == InvalidBlockNumber)
+			metapage->zhm_first_used_tpd_page = tpdblkno;
+		else
+		{
+			Assert(BufferIsValid(last_used_tpd_buf));
+
+			/* Add the new TPD page at the end of the TPD page list. */
+			last_tpdopaque = (TPDPageOpaque)
+				PageGetSpecialPointer(BufferGetPage(last_used_tpd_buf));
+			prevblk = tpdopaque->tpd_prevblkno = metapage->zhm_last_used_tpd_page;
+			nextblk = last_tpdopaque->tpd_nextblkno = tpdblkno;
+
+			MarkBufferDirty(last_used_tpd_buf);
+		}
+
+		metapage->zhm_last_used_tpd_page = tpdblkno;
+
+		MarkBufferDirty(metabuf);
+	}
+	else
+	{
+		/*
+		 * TPD chain should remain unchanged.
+		 */
+		tpdopaque = (TPDPageOpaque) PageGetSpecialPointer(tpdpage);
+		prevblk = tpdopaque->tpd_prevblkno;
+		nextblk = tpdopaque->tpd_nextblkno;
+	}
+
+	/* Mark the old tpd entry as dead before adding new entry. */
+	if (delete_old_entry)
+	{
+		Page		otpdpage;
+		ItemId		old_item_id;
+
+		/* We must be adding new TPD entry into a new page. */
+		Assert(add_new_tpd_page);
+		Assert(old_tpd_buf != tpd_buf);
+
+		otpdpage = BufferGetPage(old_tpd_buf);
+		old_item_id = PageGetItemId(otpdpage, old_off_num);
+		old_tpd_entry = (TPDEntryHeader) PageGetItem(otpdpage, old_item_id);
+		old_tpd_entry->tpe_flags |= TPE_DELETED;
+		MarkBufferDirty(old_tpd_buf);
+	}
+
+	/* Add tpd entry to page */
+	offset_num = TPDPageAddEntry(tpdpage, tpd_entry, size_tpd_entry,
+								 InvalidOffsetNumber);
+	if (offset_num == InvalidOffsetNumber)
+		elog(PANIC, "failed to add TPD entry");
+
+	MarkBufferDirty(tpd_buf);
+
+	/*
+	 * Now that the last transaction slot from zheap page has moved to TPD, we
+	 * need to assign TPD location in the last transaction slot of heap.
+	 */
+	SetTPDLocation(pagebuf, tpd_buf, offset_num);
+	MarkBufferDirty(pagebuf);
+
+	/* XLOG stuff */
+	if (RelationNeedsWAL(relation))
+	{
+		XLogRecPtr	recptr;
+		xl_tpd_allocate_entry xlrec;
+		xl_zheap_metadata metadata;
+		int			bufflags = 0;
+		uint8		info = XLOG_ALLOCATE_TPD_ENTRY;
+
+		xlrec.offnum = offset_num;
+		xlrec.prevblk = prevblk;
+		xlrec.nextblk = nextblk;
+		xlrec.flags = 0;
+
+		/*
+		 * If we are adding TPD entry to a new page, we will reinitialize the
+		 * page during replay.
+		 */
+		if (add_new_tpd_page)
+		{
+			info |= XLOG_TPD_INIT_PAGE;
+			bufflags |= REGBUF_WILL_INIT;
+		}
+
+		XLogBeginInsert();
+		XLogRegisterData((char *) &xlrec, SizeOfTPDAllocateEntry);
+		XLogRegisterBuffer(0, tpd_buf, REGBUF_STANDARD | bufflags);
+		XLogRegisterBufData(0, (char *) tpd_entry, size_tpd_entry);
+		XLogRegisterBuffer(1, pagebuf, REGBUF_STANDARD);
+		if (add_new_tpd_page)
+		{
+			XLogRegisterBuffer(2, metabuf, REGBUF_WILL_INIT | REGBUF_STANDARD);
+			metadata.first_used_tpd_page = metapage->zhm_first_used_tpd_page;
+			metadata.last_used_tpd_page = metapage->zhm_last_used_tpd_page;
+			XLogRegisterBufData(2, (char *) &metadata, SizeOfMetaData);
+
+			if (BufferIsValid(last_used_tpd_buf))
+				XLogRegisterBuffer(3, last_used_tpd_buf, REGBUF_STANDARD);
+
+			/* The old entry is deleted only when new page is allocated. */
+			if (delete_old_entry)
+			{
+				/*
+				 * If the last tpd buffer and the old tpd buffer are same, we
+				 * don't need to register old_tpd_buf.
+				 */
+				if (last_used_tpd_buf == old_tpd_buf)
+				{
+					xlrec.flags = XLOG_OLD_TPD_BUF_EQ_LAST_TPD_BUF;
+					XLogRegisterBufData(3, (char *) &old_off_num, sizeof(OffsetNumber));
+				}
+				else
+				{
+					XLogRegisterBuffer(4, old_tpd_buf, REGBUF_STANDARD);
+					XLogRegisterBufData(4, (char *) &old_off_num, sizeof(OffsetNumber));
+				}
+			}
+		}
+
+		recptr = XLogInsert(RM_TPD_ID, info);
+
+		PageSetLSN(tpdpage, recptr);
+		PageSetLSN(BufferGetPage(pagebuf), recptr);
+		if (add_new_tpd_page)
+		{
+			PageSetLSN(BufferGetPage(metabuf), recptr);
+			if (BufferIsValid(last_used_tpd_buf))
+				PageSetLSN(BufferGetPage(last_used_tpd_buf), recptr);
+			if (delete_old_entry)
+				PageSetLSN(BufferGetPage(old_tpd_buf), recptr);
+		}
+	}
+
+	END_CRIT_SECTION();
+
+	if (add_new_tpd_page)
+		LockBuffer(metabuf, BUFFER_LOCK_UNLOCK);
+	if (free_last_used_tpd_buf)
+	{
+		Assert(last_used_tpd_buf != tpd_buf);
+		UnlockReleaseBuffer(last_used_tpd_buf);
+	}
+}
+
+/*
+ * TPDAllocateAndReserveTransSlot - Allocates a new TPD entry and reserve a
+ *		transaction slot in that entry.
+ *
+ * To allocate a new TPD entry, we first check if there is a space in any
+ * existing TPD page starting from the last used TPD page and in case we
+ * don't find any such page, then allocate a new TPD page and add it to the
+ * existing list of TPD pages.
+ *
+ * We intentionally don't release the TPD buffer here as that will be
+ * released once we have updated the transaction slot with required
+ * information.  Caller must call UnlockReleaseTPDBuffers after doing
+ * necessary updates.
+ *
+ * pagebuf - Caller must have an exclusive lock on this buffer.
+ */
+int
+TPDAllocateAndReserveTransSlot(Relation relation, Buffer pagebuf,
+							   OffsetNumber offnum, UndoRecPtr *urec_ptr,
+							   bool always_extend)
+{
+	ZHeapMetaPage metapage;
+	Buffer		metabuf;
+	Buffer		tpd_buf = InvalidBuffer;
+	Page		heappage;
+	uint32		first_used_tpd_page;
+	uint32		last_used_tpd_page;
+	char	   *tpd_entry;
+	Size		size_tpd_entry;
+	int			reserved_slot = InvalidXactSlotId;
+	int			buf_idx;
+	bool		allocate_new_tpd_page = false;
+	bool		update_meta = false;
+	bool		already_exists;
+
+	metabuf = ReadBuffer(relation, ZHEAP_METAPAGE);
+	LockBuffer(metabuf, BUFFER_LOCK_SHARE);
+	metapage = ZHeapPageGetMeta(BufferGetPage(metabuf));
+	Assert(metapage->zhm_magic == ZHEAP_MAGIC);
+
+	first_used_tpd_page = metapage->zhm_first_used_tpd_page;
+	last_used_tpd_page = metapage->zhm_last_used_tpd_page;
+
+	LockBuffer(metabuf, BUFFER_LOCK_UNLOCK);
+
+	heappage = BufferGetPage(pagebuf);
+
+	if (last_used_tpd_page != InvalidBlockNumber)
+	{
+		Size		tpdpageFreeSpace;
+		Size		size_tpd_e_map,
+					size_tpd_entry,
+					size_tpd_e_slots;
+		uint16		num_map_entries;
+		OffsetNumber max_required_offset;
+
+		if (OffsetNumberIsValid(offnum))
+			max_required_offset = offnum;
+		else
+			max_required_offset = PageGetMaxOffsetNumber(heappage);
+		num_map_entries = max_required_offset +
+			ADDITIONAL_MAP_ELEM_IN_TPD_ENTRY;
+
+		size_tpd_e_map = num_map_entries * sizeof(uint8);
+		size_tpd_e_slots = INITIAL_TRANS_SLOTS_IN_TPD_ENTRY * sizeof(TransInfo);
+		size_tpd_entry = SizeofTPDEntryHeader + size_tpd_e_map +
+			size_tpd_e_slots;
+
+		buf_idx = GetTPDBuffer(relation, last_used_tpd_page, InvalidBuffer,
+							   TPD_BUF_FIND_OR_ENTER, &already_exists);
+		tpd_buf = tpd_buffers[buf_idx].buf;
+		/* We don't need to lock the buffer, if it is already locked */
+		if (!already_exists)
+			LockBuffer(tpd_buf, BUFFER_LOCK_EXCLUSIVE);
+
+		/* Page should be a TPD page. */
+		Assert(IsTPDPage(BufferGetPage(tpd_buf)));
+
+		tpdpageFreeSpace = PageGetTPDFreeSpace(BufferGetPage(tpd_buf));
+
+		if (tpdpageFreeSpace < size_tpd_entry)
+		{
+			int			entries_removed;
+
+			/*
+			 * Prune the TPD page to make space for new TPD entries.  After
+			 * pruning, check again to see if the TPD entry can be
+			 * accommodated on the page. We can't afford to free the page
+			 * while pruning as we need to use it to insert the TPD entry.
+			 */
+			entries_removed = TPDPagePrune(relation, tpd_buf, NULL,
+										   InvalidOffsetNumber, 0, false, NULL,
+										   NULL);
+
+			if (entries_removed > 0)
+				tpdpageFreeSpace = PageGetTPDFreeSpace(BufferGetPage(tpd_buf));
+
+			if (tpdpageFreeSpace < size_tpd_entry)
+			{
+				/*
+				 * XXX Here, we can have an optimization such that instead of
+				 * allocating a new page, we can search other TPD pages
+				 * starting from the first_used_tpd_page till we reach
+				 * last_used_tpd_page. It is not clear whether such an
+				 * optimization can help because checking all the TPD pages
+				 * isn't free either.
+				 */
+				if (!already_exists)
+					ReleaseLastTPDBuffer(tpd_buf, true);
+				allocate_new_tpd_page = true;
+			}
+		}
+	}
+
+	if (allocate_new_tpd_page ||
+		(last_used_tpd_page == InvalidBlockNumber &&
+		 first_used_tpd_page == InvalidBlockNumber))
+	{
+		tpd_buf = InvalidBuffer;
+		update_meta = true;
+	}
+
+	/* Allocate a new TPD entry */
+	tpd_entry = AllocateAndFormTPDEntry(pagebuf, offnum, &size_tpd_entry,
+										&reserved_slot);
+	Assert(tpd_entry != NULL);
+
+	TPDAllocatePageAndAddEntry(relation, metabuf, pagebuf, tpd_buf,
+							   InvalidOffsetNumber, tpd_entry, size_tpd_entry,
+							   update_meta, false, always_extend);
+
+	ReleaseBuffer(metabuf);
+
+	/*
+	 * Here, we don't release the tpd buffer in which we have added the newly
+	 * allocated TPD entry as that will be released once we update the
+	 * required transaction slot info in it.  The caller will later call
+	 * TPDPageSetUndo to update the required information.
+	 */
+
+	pfree(tpd_entry);
+
+	/*
+	 * As this is always a fresh transaction slot, so we can assume that there
+	 * is no preexisting undo record pointer.
+	 */
+	*urec_ptr = InvalidUndoRecPtr;
+
+	return reserved_slot;
+}
+
+/*
+ * TPDPageGetTransactionSlots - Get the transaction slots array stored in TPD
+ *			entry.  This is a helper routine for TPDPageReserveTransSlot and
+ *			TPDPageGetSlotIfExists.
+ *
+ * The tpd entries are stored unaligned, so we need to be careful to read
+ * them.  We use memcpy to avoid unaligned reads.
+ *
+ * It is quite possible that the TPD entry containing required transaction slot
+ * information got pruned away (as all the transaction entries are all-visible)
+ * by the time caller tries to inquire about it.  See atop
+ * TPDPageGetTransactionSlotInfo for more details on how we deal with pruned
+ * TPD entries.
+ *
+ * clean_tpd_loc indicates whether we can clear the TPD location from the page
+ * zheap page if the corresponding TPD entry got pruned away.  To clear the TPD
+ * location from the zheap page, the zheap buffer must be locked in exclusive
+ * mode.
+ *
+ * This function returns a pointer to an array of transaction slots, it is the
+ * responsibility of the caller to free it.
+ */
+TransInfo *
+TPDPageGetTransactionSlots(Relation relation, Buffer heapbuf,
+						   OffsetNumber offnum, bool keepTPDBufLock,
+						   bool checkOffset, int *num_map_entries,
+						   int *num_trans_slots, int *tpd_buf_id,
+						   bool *tpd_e_pruned, bool *alloc_bigger_map,
+						   bool clean_tpd_loc)
+{
+	Page		heappage = BufferGetPage(heapbuf);
+	TransInfo  *trans_slots = NULL;
+	Buffer		tpd_buf;
+	Page		tpdpage;
+	BlockNumber tpdblk;
+	BlockNumber lastblock;
+	TPDEntryHeaderData tpd_e_hdr;
+	Size		size_tpd_e_map;
+	Size		size_tpd_e_slots;
+	int			loc_trans_slots;
+	int			buf_idx;
+	OffsetNumber tpdItemOff;
+	ItemId		itemId;
+	uint16		tpd_e_offset;
+	bool		already_exists;
+	bool		valid;
+
+	if (tpd_buf_id)
+		*tpd_buf_id = -1;
+	if (num_map_entries)
+		*num_map_entries = 0;
+	if (num_trans_slots)
+		*num_trans_slots = 0;
+	if (tpd_e_pruned)
+		*tpd_e_pruned = false;
+	if (alloc_bigger_map)
+		*alloc_bigger_map = false;
+
+	/*
+	 * Heap page should be locked in exclusive mode in case the TPD location
+	 * from the can be cleaned.
+	 */
+	Assert(!clean_tpd_loc ||
+		   LWLockHeldByMeInMode(BufferDescriptorGetContentLock(GetBufferDescriptor(heapbuf - 1)),
+								LW_EXCLUSIVE));
+
+	GetTPDBlockAndOffset(heappage, &tpdblk, &tpdItemOff);
+
+	if (!InRecovery)
+	{
+		lastblock = RelationGetNumberOfBlocks(relation);
+
+		if (lastblock <= tpdblk)
+		{
+			/*
+			 * The required TPD block has been pruned and then truncated away
+			 * which means all transaction slots on that page are older than
+			 * oldestXidHavingUndo.  So, we can assume the transaction slot is
+			 * frozen aka transaction is all-visible and can clear the slot
+			 * from heap tuples.
+			 */
+			if (clean_tpd_loc)
+				LogAndClearTPDLocation(relation, heapbuf, tpd_e_pruned);
+			goto failed_and_buf_not_locked;
+		}
+	}
+
+	/*
+	 * Fetch the required TPD entry.  We need to lock the buffer in exclusive
+	 * mode as we later want to set the values in one of the transaction slot.
+	 */
+	buf_idx = GetTPDBuffer(relation, tpdblk, InvalidBuffer,
+						   TPD_BUF_FIND_OR_ENTER, &already_exists);
+	tpd_buf = tpd_buffers[buf_idx].buf;
+
+	/* We don't need to lock the buffer, if it is already locked */
+	if (!already_exists)
+	{
+		/*
+		 * Before acquiring the lock on this page, we need to check whether
+		 * TPD entry can exist on page.  This is mainly to ensure that this
+		 * page hasn't already been reused as a heap page in which case we
+		 * might either start waiting on our own backend or some other backend
+		 * which can lead to dead lock.  See TPDFreePage to know more about
+		 * how we prevent such deadlocks.
+		 *
+		 * There is a race condition (it can become a non-TPD page immediately
+		 * after this check) here as we are checking validity of TPD entry
+		 * without acquiring the lock on page, but we do this check again
+		 * after acquiring the lock, so we are safe here.
+		 */
+		valid = TPDPageIsValid(relation, heapbuf, tpd_e_pruned, tpd_buf,
+							   tpdItemOff, &tpd_e_hdr, clean_tpd_loc, false);
+		if (!valid)
+		{
+			ReleaseLastTPDBuffer(tpd_buf, false);
+			goto failed_and_buf_not_locked;
+		}
+
+		/* We have to lock the TPD buffer. */
+		LockBuffer(tpd_buf, BUFFER_LOCK_EXCLUSIVE);
+		if (tpd_buf_id)
+			*tpd_buf_id = buf_idx;
+	}
+
+	/* Check whether TPD entry can exist on page? */
+	valid = TPDPageIsValid(relation, heapbuf, tpd_e_pruned, tpd_buf,
+						   tpdItemOff, &tpd_e_hdr, clean_tpd_loc, true);
+	if (!valid)
+		goto failed;
+
+	tpdpage = BufferGetPage(tpd_buf);
+	itemId = PageGetItemId(tpdpage, tpdItemOff);
+	tpd_e_offset = ItemIdGetOffset(itemId);
+
+	/* We should never access deleted entry. */
+	Assert(!TPDEntryIsDeleted(tpd_e_hdr));
+
+	/* Allow caller to allocate a bigger TPD entry instead. */
+	if (checkOffset && offnum > tpd_e_hdr.tpe_num_map_entries)
+	{
+		/*
+		 * If the caller has requested to check offset, it must be prepared to
+		 * allocate a TPD entry.
+		 */
+		Assert(alloc_bigger_map);
+		*alloc_bigger_map = true;
+	}
+
+	if (tpd_e_hdr.tpe_flags & TPE_ONE_BYTE)
+		size_tpd_e_map = tpd_e_hdr.tpe_num_map_entries * sizeof(uint8);
+	else
+	{
+		Assert(tpd_e_hdr.tpe_flags & TPE_FOUR_BYTE);
+		size_tpd_e_map = tpd_e_hdr.tpe_num_map_entries * sizeof(uint32);
+	}
+
+	if (num_map_entries)
+		*num_map_entries = tpd_e_hdr.tpe_num_map_entries;
+	if (num_trans_slots)
+		*num_trans_slots = tpd_e_hdr.tpe_num_slots;
+	size_tpd_e_slots = tpd_e_hdr.tpe_num_slots * sizeof(TransInfo);
+	loc_trans_slots = tpd_e_offset + SizeofTPDEntryHeader + size_tpd_e_map;
+
+	trans_slots = (TransInfo *) palloc(size_tpd_e_slots);
+	memcpy((char *) trans_slots, tpdpage + loc_trans_slots, size_tpd_e_slots);
+
+failed:
+	if (!keepTPDBufLock)
+	{
+		/*
+		 * If we don't want to retain the buffer lock, it must have been taken
+		 * now.  We can't release the already existing lock taken.
+		 */
+		Assert(!already_exists);
+		ReleaseLastTPDBuffer(tpd_buf, true);
+
+		if (tpd_buf_id)
+			*tpd_buf_id = -1;
+	}
+
+failed_and_buf_not_locked:
+	return trans_slots;
+}
+
+/*
+ * TPDPageIsValid - To verify TPD page is pruned or not.
+ *
+ * If TPD buffer is pruned and clean_tpd_loc is true then this will clear TPD
+ * location from zheap page.
+ *
+ * Returns false, if the page is pruned, otherwise return true.
+ */
+static bool
+TPDPageIsValid(Relation relation, Buffer heapbuf, bool *tpd_e_pruned,
+			   Buffer tpd_buf, OffsetNumber tpdItemOff,
+			   TPDEntryHeaderData *tpd_e_hdr, bool clean_tpd_loc,
+			   bool is_tpd_buf_locked)
+{
+	Page		tpdpage;
+
+	tpdpage = BufferGetPage(tpd_buf);
+
+	/* Check whether TPD entry can exist on page? */
+	if (PageIsEmpty(tpdpage))
+		goto failed;
+
+	if (!IsTPDPage(tpdpage))
+		goto failed;
+
+	/*
+	 * Only if TPD buffer is locked, we will read TPD entry header because it
+	 * is possible that other backend is re-arranging TPD entries due to
+	 * extend request and we might get wrong information.
+	 */
+	if (is_tpd_buf_locked)
+	{
+		ItemId		itemId;
+		uint16		tpd_e_offset;
+
+		if (tpdItemOff > PageGetMaxOffsetNumber(tpdpage))
+			goto failed;
+
+		itemId = PageGetItemId(tpdpage, tpdItemOff);
+
+		/* TPD entry has been pruned */
+		if (!ItemIdIsUsed(itemId))
+			goto failed;
+
+		tpd_e_offset = ItemIdGetOffset(itemId);
+		memcpy((char *) tpd_e_hdr, tpdpage + tpd_e_offset,
+			   SizeofTPDEntryHeader);
+
+		/*
+		 * This TPD entry is for some other block, so we can't continue.  This
+		 * indicates that the TPD entry corresponding to heap block has been
+		 * pruned and some other TPD entry has been moved at its location.
+		 */
+		if (tpd_e_hdr->blkno != BufferGetBlockNumber(heapbuf))
+			goto failed;
+	}
+
+	/* This TPD buffer is not pruned, so return true. */
+	return true;
+
+failed:
+	/* Clear the TPD location from heap page. */
+	if (clean_tpd_loc)
+		LogAndClearTPDLocation(relation, heapbuf, tpd_e_pruned);
+
+	/* This TPD buffer is pruned, so return true. */
+	return false;
+}
+
+/*
+ * ReleaseLastTPDBufferByTPDBlock - Release last TPD buffer.
+ *
+ * tpdblk - block number of TPD buffer.
+ */
+void
+ReleaseLastTPDBufferByTPDBlock(BlockNumber tpdblk)
+{
+	bool		already_exists = true;
+	int			buf_idx;
+	Buffer		tpd_buf;
+
+	/* Get the corresponding TPD buffer corresponding to tpd block. */
+	buf_idx = GetTPDBuffer(NULL, tpdblk, InvalidBuffer, TPD_BUF_FIND,
+						   &already_exists);
+
+	/* We should have TPD buffer lock. */
+	Assert(already_exists);
+	tpd_buf = tpd_buffers[buf_idx].buf;
+
+	/* Release the last TPD buffer. */
+	ReleaseLastTPDBuffer(tpd_buf, true);
+}
+
+/*
+ * TPDPageReserveTransSlot - Reserve the available transaction in current TPD
+ *		entry if any, otherwise, return InvalidXactSlotId.
+ *
+ * We intentionally don't release the TPD buffer here as that will be
+ * released once we have updated the transaction slot with required
+ * information.  However, if no free slot is available, then we release the
+ * buffer.  Caller must call UnlockReleaseTPDBuffers after doing necessary
+ * updates if it is able to reserve a slot.
+ */
+int
+TPDPageReserveTransSlot(Relation relation, Buffer buf, OffsetNumber offnum,
+						UndoRecPtr *urec_ptr, bool *lock_reacquired,
+						bool always_extend, Buffer other_buf)
+{
+	TransInfo  *trans_slots;
+	int			slot_no;
+	int			num_map_entries;
+	int			num_slots;
+	int			result_slot_no = InvalidXactSlotId;
+	int			buf_idx;
+	bool		tpd_e_pruned;
+	bool		alloc_bigger_map;
+
+	/*
+	 * Since the zheap buffer is locked in exclusive mode, we can clear the
+	 * TPD location from the page if necessary.
+	 */
+	trans_slots = TPDPageGetTransactionSlots(relation, buf, offnum,
+											 true, true, &num_map_entries,
+											 &num_slots, &buf_idx,
+											 &tpd_e_pruned, &alloc_bigger_map,
+											 true);
+	if (tpd_e_pruned)
+	{
+		Assert(trans_slots == NULL);
+		Assert(num_slots == 0);
+	}
+
+	for (slot_no = 0; slot_no < num_slots; slot_no++)
+	{
+		/* Check for an unreserved transaction slot in the TPD entry */
+		if (!FullTransactionIdIsValid(trans_slots[slot_no].fxid))
+		{
+			result_slot_no = slot_no;
+			*urec_ptr = trans_slots[slot_no].urec_ptr;
+			goto extend_entry_if_required;
+		}
+	}
+
+	/* no transaction slot available, try to reuse some existing slot */
+	if (num_slots > 0 &&
+		PageFreezeTransSlots(relation, buf, lock_reacquired, trans_slots, num_slots, other_buf))
+	{
+		pfree(trans_slots);
+
+		/*
+		 * If the lock is re-acquired inside, then the callers must recheck
+		 * that whether they can still perform the required operation.
+		 */
+		if (*lock_reacquired)
+			return InvalidXactSlotId;
+
+		/*
+		 * Since the zheap buffer is locked in exclusive mode, we can clear
+		 * the TPD location from the page if necessary.
+		 */
+		trans_slots = TPDPageGetTransactionSlots(relation, buf, offnum, true,
+												 true, &num_map_entries,
+												 &num_slots, &buf_idx,
+												 &tpd_e_pruned, &alloc_bigger_map,
+												 true);
+
+		/*
+		 * We are already holding TPD buffer lock so the TPD entry can not be
+		 * pruned away.
+		 */
+		Assert(!tpd_e_pruned);
+
+		for (slot_no = 0; slot_no < num_slots; slot_no++)
+		{
+			if (!FullTransactionIdIsValid(trans_slots[slot_no].fxid))
+			{
+				*urec_ptr = trans_slots[slot_no].urec_ptr;
+				result_slot_no = slot_no;
+				goto extend_entry_if_required;
+			}
+		}
+
+		/*
+		 * After freezing transaction slots, we should get at least one free
+		 * slot.
+		 */
+		Assert(result_slot_no != InvalidXactSlotId);
+	}
+
+extend_entry_if_required:
+
+	/*
+	 * Allocate a bigger TPD entry if either we need a bigger offset-map or
+	 * there is no unreserved slot available provided TPD entry is not pruned
+	 * in which case we can use last slot on the heap page.
+	 */
+	if (!tpd_e_pruned &&
+		(alloc_bigger_map || result_slot_no == InvalidXactSlotId))
+	{
+		ExtendTPDEntry(relation, buf, trans_slots, offnum, buf_idx,
+					   num_map_entries, num_slots, &result_slot_no, urec_ptr,
+					   &tpd_e_pruned, always_extend);
+	}
+
+	/* be tidy */
+	if (trans_slots != NULL)
+		pfree(trans_slots);
+
+	/*
+	 * The transaction slots in TPD entry are in addition to the maximum slots
+	 * in the heap page.
+	 */
+	if (result_slot_no != InvalidXactSlotId)
+		result_slot_no += (ZHEAP_PAGE_TRANS_SLOTS + 1);
+	else if (buf_idx != -1)
+		ReleaseLastTPDBuffer(tpd_buffers[buf_idx].buf, true);
+
+	/*
+	 * As TPD entry is pruned, so last transaction slot must be free on the
+	 * heap page.
+	 */
+	if (tpd_e_pruned)
+	{
+		Assert(result_slot_no == InvalidXactSlotId);
+		result_slot_no = ZHEAP_PAGE_TRANS_SLOTS;
+		*urec_ptr = InvalidUndoRecPtr;
+	}
+
+	return result_slot_no;
+}
+
+/*
+ * TPDPageGetSlotIfExists - Get the existing slot for the required transaction
+ *		if exists, otherwise, return InvalidXactSlotId.
+ *
+ * This is similar to the TPDPageReserveTransSlot except that here we find the
+ * existing transaction slot instead of reserving a new one.
+ *
+ * keepTPDBufLock - This indicates whether we need to retain the lock on TPD
+ * buffer if we are able to reserve a transaction slot.
+ */
+int
+TPDPageGetSlotIfExists(Relation relation, Buffer heapbuf, OffsetNumber offnum,
+					   FullTransactionId fxid, UndoRecPtr *urec_ptr,
+					   bool keepTPDBufLock, bool checkOffset)
+{
+	TransInfo  *trans_slots;
+	int			slot_no;
+	int			num_map_entries;
+	int			num_slots;
+	int			result_slot_no = InvalidXactSlotId;
+	int			buf_idx;
+	bool		tpd_e_pruned;
+	bool		alloc_bigger_map;
+
+	/*
+	 * Since the zheap buffer is locked in exclusive mode, we can clear the
+	 * TPD location from the page if necessary.
+	 */
+	trans_slots = TPDPageGetTransactionSlots(relation,
+											 heapbuf,
+											 offnum,
+											 keepTPDBufLock,
+											 checkOffset,
+											 &num_map_entries,
+											 &num_slots,
+											 &buf_idx,
+											 &tpd_e_pruned,
+											 &alloc_bigger_map,
+											 true);
+	if (tpd_e_pruned)
+	{
+		Assert(trans_slots == NULL);
+		Assert(num_slots == 0);
+	}
+
+	for (slot_no = 0; slot_no < num_slots; slot_no++)
+	{
+		/* Check if already have a slot in the TPD entry */
+		if (FullTransactionIdEquals(trans_slots[slot_no].fxid, fxid))
+		{
+			result_slot_no = slot_no;
+			*urec_ptr = trans_slots[slot_no].urec_ptr;
+			break;
+		}
+	}
+
+	/*
+	 * Allocate a bigger TPD entry if we get the required slot in TPD entry,
+	 * but it requires a bigger offset-map.
+	 */
+	if (result_slot_no != InvalidXactSlotId && alloc_bigger_map)
+	{
+		ExtendTPDEntry(relation, heapbuf, trans_slots, offnum, buf_idx,
+					   num_map_entries, num_slots, &result_slot_no, urec_ptr,
+					   &tpd_e_pruned, false);
+	}
+
+	/* be tidy */
+	if (trans_slots)
+		pfree(trans_slots);
+
+	/*
+	 * The transaction slots in TPD entry are in addition to the maximum slots
+	 * in the heap page.
+	 */
+	if (result_slot_no != InvalidXactSlotId)
+		result_slot_no += (ZHEAP_PAGE_TRANS_SLOTS + 1);
+	else if (buf_idx != -1)
+		ReleaseLastTPDBuffer(tpd_buffers[buf_idx].buf, true);
+
+	return result_slot_no;
+}
+
+/*
+ * TPDPageGetTransactionSlotInfo - Get the required transaction information from
+ *		heap page's TPD entry.
+ *
+ * It is quite possible that the TPD entry containing required transaction slot
+ * information got pruned away (as all the transaction entries are all-visible)
+ * by the time caller tries to inquire about it.  One might expect that if the
+ * TPD entry is pruned, the corresponding affected tuples should be updated to
+ * reflect the same, however, we don't do that due to multiple reasons (a) we
+ * don't access heap pages from TPD layer, it can lead to deadlock, (b) it
+ * might lead to dirtying a lot of pages and random I/O.  However, the first
+ * time we detect it and we have exclusive lock on page, we update the
+ * corresponding heap page.
+ *
+ * We can consider TPD entry to be pruned under following conditions: (a) the
+ * tpd block doesn't exist (pruned and truncated by vacuum), (b) the tpd block
+ * is empty which means all the entries in it are pruned, (c) the tpd block
+ * has been reused as a heap page, (d) the corresponding TPD entry has been
+ * pruned away and either the itemid is unused or is reused for some other
+ * block's TPD entry.
+ *
+ * NoTPDBufLock - This indicates that caller doesn't have lock on required tpd
+ * buffer in which case we need to read and lock the required buffer.
+ */
+int
+TPDPageGetTransactionSlotInfo(Buffer heapbuf, int trans_slot,
+							  OffsetNumber offset, uint32 *epoch,
+							  TransactionId *xid, UndoRecPtr *urec_ptr,
+							  bool NoTPDBufLock, bool keepTPDBufLock)
+{
+	TransInfo	trans_slot_info;
+	RelFileNode rnode;
+	Buffer		tpdbuffer;
+	Page		tpdpage;
+	Page		heappage;
+	BlockNumber tpdblk,
+				heapblk;
+	ForkNumber	forknum;
+	TPDEntryHeaderData tpd_e_hdr;
+	Size		size_tpd_e_map;
+	uint32		tpd_e_num_map_entries;
+	int			trans_slot_loc;
+	int			trans_slot_id = trans_slot;
+	char	   *tpd_entry_data;
+	OffsetNumber tpdItemOff;
+	ItemId		itemId;
+	uint16		tpd_e_offset;
+	char		relpersistence;
+	bool		valid;
+
+	heappage = BufferGetPage(heapbuf);
+
+	GetTPDBlockAndOffset(heappage, &tpdblk, &tpdItemOff);
+
+	if (NoTPDBufLock)
+	{
+		SmgrId		smgrid;
+		SMgrRelation smgr;
+		BlockNumber lastblock;
+
+		BufferGetTag(heapbuf, &smgrid, &rnode, &forknum, &heapblk);
+
+		if (InRecovery)
+			relpersistence = RELPERSISTENCE_PERMANENT;
+		else
+		{
+			Oid			reloid;
+
+			reloid = RelidByRelfilenode(rnode.spcNode, rnode.relNode);
+			relpersistence = get_rel_persistence(reloid);
+		}
+
+		smgr = smgropen(smgrid, rnode,
+						relpersistence == RELPERSISTENCE_TEMP ?
+						MyBackendId : InvalidBackendId);
+
+		lastblock = smgrnblocks(smgr, forknum);
+
+		/* required block exists? */
+		if (tpdblk < lastblock)
+		{
+			tpdbuffer = ReadBufferWithoutRelcache(smgrid, rnode, forknum, tpdblk, RBM_NORMAL,
+												  NULL, relpersistence);
+
+			/* Check whether TPD entry can exist on page? */
+			valid = TPDPageIsValid(NULL, heapbuf, NULL, tpdbuffer, tpdItemOff,
+								   &tpd_e_hdr, false, false);
+			if (!valid)
+			{
+				ReleaseBuffer(tpdbuffer);
+				goto slot_is_frozen_and_buf_not_locked;
+			}
+
+			if (keepTPDBufLock)
+				LockBuffer(tpdbuffer, BUFFER_LOCK_EXCLUSIVE);
+			else
+				LockBuffer(tpdbuffer, BUFFER_LOCK_SHARE);
+		}
+		else
+		{
+			/*
+			 * The required TPD block has been pruned and then truncated away
+			 * which means all transaction slots on that page are older than
+			 * oldestXidHavingUndo.  So, we can assume the transaction slot is
+			 * frozen aka transaction is all-visible.
+			 */
+			goto slot_is_frozen_and_buf_not_locked;
+		}
+	}
+	else
+	{
+		int			buf_idx;
+		bool		already_exists PG_USED_FOR_ASSERTS_ONLY;
+
+		buf_idx = GetTPDBuffer(NULL, tpdblk, InvalidBuffer, TPD_BUF_FIND,
+							   &already_exists);
+		/* We must get a valid buffer. */
+		Assert(buf_idx != -1);
+		Assert(already_exists);
+		tpdbuffer = tpd_buffers[buf_idx].buf;
+	}
+
+	/*
+	 * Check whether TPD entry can exist on page?
+	 *
+	 * Ideally, we can clear the TPD location from the zheap page (aka pass
+	 * clean_tpd_loc as true), but for that, we need to have an exclusive lock
+	 * on the heap page.  As this API can be called with a shared lock on a
+	 * heap page, we can't perform that action.
+	 *
+	 * XXX If it ever turns out to be a performance problem, we can release
+	 * the current lock and acquire the exclusive lock on heap page.  Also we
+	 * need to ensure that the lock on TPD page also needs to be released and
+	 * reacquired as we always follow the protocol of acquiring the lock on
+	 * heap page first and then on TPD page, doing it other way can lead to
+	 * undetected deadlock.
+	 */
+	valid = TPDPageIsValid(NULL, heapbuf, NULL, tpdbuffer, tpdItemOff,
+						   &tpd_e_hdr, false, true);
+	if (!valid)
+		goto slot_is_frozen;
+
+	tpdpage = BufferGetPage(tpdbuffer);
+	itemId = PageGetItemId(tpdpage, tpdItemOff);
+	tpd_e_offset = ItemIdGetOffset(itemId);
+
+	/* We should never access deleted entry. */
+	Assert(!TPDEntryIsDeleted(tpd_e_hdr));
+
+	tpd_e_num_map_entries = tpd_e_hdr.tpe_num_map_entries;
+	tpd_entry_data = tpdpage + tpd_e_offset + SizeofTPDEntryHeader;
+	if (tpd_e_hdr.tpe_flags & TPE_ONE_BYTE)
+		size_tpd_e_map = tpd_e_num_map_entries * sizeof(uint8);
+	else
+	{
+		Assert(tpd_e_hdr.tpe_flags & TPE_FOUR_BYTE);
+		size_tpd_e_map = tpd_e_num_map_entries * sizeof(uint32);
+	}
+
+	/*
+	 * If the caller has passed transaction slot number that belongs to TPD
+	 * entry, then we directly go and fetch the required info from the slot.
+	 */
+	if (offset != InvalidOffsetNumber)
+	{
+		/*
+		 * The item for which we want to get the transaction slot information
+		 * must be present in this TPD entry.
+		 */
+		Assert(offset <= tpd_e_num_map_entries);
+
+		/* Get TPD entry map */
+		if (tpd_e_hdr.tpe_flags & TPE_ONE_BYTE)
+		{
+			uint8		offset_tpd_e_loc;
+
+			/*
+			 * One byte access shouldn't cause unaligned access, but using
+			 * memcpy for the sake of consistency.
+			 */
+			memcpy((char *) &offset_tpd_e_loc, tpd_entry_data + (offset - 1),
+				   sizeof(uint8));
+			trans_slot_id = offset_tpd_e_loc;
+		}
+		else
+		{
+			uint32		offset_tpd_e_loc;
+
+			memcpy((char *) &offset_tpd_e_loc,
+				   tpd_entry_data + (sizeof(uint32) * (offset - 1)),
+				   sizeof(uint32));
+			trans_slot_id = offset_tpd_e_loc;
+		}
+	}
+
+	/* Transaction must belong to TPD entry. */
+	Assert(trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS);
+
+	/* Get the required transaction slot information. */
+	trans_slot_loc = (trans_slot_id - ZHEAP_PAGE_TRANS_SLOTS - 1) *
+		sizeof(TransInfo);
+	memcpy((char *) &trans_slot_info,
+		   tpd_entry_data + size_tpd_e_map + trans_slot_loc,
+		   sizeof(TransInfo));
+
+	/* Update the required output */
+	if (epoch)
+		*epoch = EpochFromFullTransactionId(trans_slot_info.fxid);
+	if (xid)
+		*xid = XidFromFullTransactionId(trans_slot_info.fxid);
+	if (urec_ptr)
+		*urec_ptr = trans_slot_info.urec_ptr;
+
+	if (NoTPDBufLock && !keepTPDBufLock)
+		UnlockReleaseBuffer(tpdbuffer);
+
+	return trans_slot_id;
+
+slot_is_frozen:
+	if (NoTPDBufLock && !keepTPDBufLock)
+		UnlockReleaseBuffer(tpdbuffer);
+
+slot_is_frozen_and_buf_not_locked:
+	trans_slot_id = ZHTUP_SLOT_FROZEN;
+	if (epoch)
+		*epoch = 0;
+	if (xid)
+		*xid = InvalidTransactionId;
+	if (urec_ptr)
+		*urec_ptr = InvalidUndoRecPtr;
+
+	return trans_slot_id;
+}
+
+/*
+ * TPDPageSetTransactionSlotInfo - Set the transaction information for a given
+ *		transaction slot in the TPD entry.
+ *
+ * Caller must ensure that it has required lock on tpd buffer which is going to
+ * be updated here.  We can't lock the buffer here as this API is supposed to
+ * be called from critical section and lock acquisition can fail.
+ */
+void
+TPDPageSetTransactionSlotInfo(Buffer heapbuf, int trans_slot_id,
+							  FullTransactionId fxid,
+							  UndoRecPtr urec_ptr)
+{
+	TransInfo	trans_slot_info;
+	BufferDesc *tpdbufhdr PG_USED_FOR_ASSERTS_ONLY;
+	Buffer		tpd_buf;
+	Page		tpdpage;
+	Page		heappage;
+	BlockNumber tpdblk;
+	TPDEntryHeaderData tpd_e_hdr;
+	TPDPageOpaque tpdopaque;
+	Size		size_tpd_e_map;
+	int			trans_slot_loc;
+	int			buf_idx;
+	char	   *tpd_entry_data;
+	OffsetNumber tpdItemOff;
+	ItemId		itemId;
+	uint16		tpd_e_offset;
+	bool		already_exists PG_USED_FOR_ASSERTS_ONLY;
+
+	heappage = BufferGetPage(heapbuf);
+
+	GetTPDBlockAndOffset(heappage, &tpdblk, &tpdItemOff);
+
+	buf_idx = GetTPDBuffer(NULL, tpdblk, InvalidBuffer, TPD_BUF_FIND,
+						   &already_exists);
+	/* We must get a valid buffer. */
+	Assert(buf_idx != -1);
+	Assert(already_exists);
+	tpd_buf = tpd_buffers[buf_idx].buf;
+	Assert(BufferIsValid(tpd_buf));
+	tpdbufhdr = GetBufferDescriptor(tpd_buf - 1);
+	Assert(LWLockHeldByMeInMode(BufferDescriptorGetContentLock(tpdbufhdr),
+								LW_EXCLUSIVE));
+	Assert(BufferGetBlockNumber(tpd_buf) == tpdblk);
+
+	tpdpage = BufferGetPage(tpd_buf);
+	itemId = PageGetItemId(tpdpage, tpdItemOff);
+
+	/*
+	 * TPD entry can't go away as we acquire the lock while reserving the slot
+	 * from TPD entry and keep it till we set the required transaction
+	 * information in the slot.
+	 */
+	Assert(ItemIdIsUsed(itemId));
+
+	tpd_e_offset = ItemIdGetOffset(itemId);
+
+	memcpy((char *) &tpd_e_hdr, tpdpage + tpd_e_offset, SizeofTPDEntryHeader);
+
+	/* TPD entry can't be pruned. */
+	Assert(tpd_e_hdr.blkno == BufferGetBlockNumber(heapbuf));
+
+	/* We should never access deleted entry. */
+	Assert(!TPDEntryIsDeleted(tpd_e_hdr));
+
+	tpd_entry_data = tpdpage + tpd_e_offset + SizeofTPDEntryHeader;
+
+	/* Get TPD entry map */
+	if (tpd_e_hdr.tpe_flags & TPE_ONE_BYTE)
+		size_tpd_e_map = tpd_e_hdr.tpe_num_map_entries * sizeof(uint8);
+	else
+		size_tpd_e_map = tpd_e_hdr.tpe_num_map_entries * sizeof(uint32);
+
+	/* Set the required transaction slot information. */
+	trans_slot_loc = (trans_slot_id - ZHEAP_PAGE_TRANS_SLOTS - 1) *
+		sizeof(TransInfo);
+	trans_slot_info.fxid = fxid;
+	trans_slot_info.urec_ptr = urec_ptr;
+
+	memcpy(tpd_entry_data + size_tpd_e_map + trans_slot_loc,
+		   (char *) &trans_slot_info,
+		   sizeof(TransInfo));
+
+	/* Update latest transaction information on the page. */
+	tpdopaque = (TPDPageOpaque) PageGetSpecialPointer(tpdpage);
+	if (FullTransactionIdPrecedes(tpdopaque->tpd_latest_fxid, fxid))
+		tpdopaque->tpd_latest_fxid = fxid;
+
+	MarkBufferDirty(tpd_buf);
+}
+
+/*
+ * GetTPDEntryData - Helper function for TPDPageGetOffsetMap and
+ *					 TPDPageSetOffsetMap.
+ *
+ * Caller must ensure that it has acquired lock on the TPD buffer.
+ */
+static char *
+GetTPDEntryData(Buffer heapbuf, int *num_entries, int *entry_size,
+				Buffer *tpd_buffer)
+{
+	BufferDesc *tpdbufhdr PG_USED_FOR_ASSERTS_ONLY;
+	Buffer		tpd_buf;
+	Page		tpdpage;
+	Page		heappage;
+	BlockNumber tpdblk;
+	TPDEntryHeaderData tpd_e_hdr;
+	int			buf_idx;
+	char	   *tpd_entry_data;
+	OffsetNumber tpdItemOff;
+	ItemId		itemId;
+	uint16		tpd_e_offset;
+	bool		already_exists PG_USED_FOR_ASSERTS_ONLY;
+	bool		valid;
+
+	heappage = BufferGetPage(heapbuf);
+
+	GetTPDBlockAndOffset(heappage, &tpdblk, &tpdItemOff);
+
+	/*
+	 * Here we don't need to check if the tpd block is pruned and truncated
+	 * away because the tpd buffer must be locked before.
+	 */
+
+	buf_idx = GetTPDBuffer(NULL, tpdblk, InvalidBuffer, TPD_BUF_FIND,
+						   &already_exists);
+	/* We must get a valid buffer. */
+	Assert(buf_idx != -1);
+	Assert(already_exists);
+	tpd_buf = tpd_buffers[buf_idx].buf;
+	Assert(BufferIsValid(tpd_buf));
+	tpdbufhdr = GetBufferDescriptor(tpd_buf - 1);
+	Assert(LWLockHeldByMeInMode(BufferDescriptorGetContentLock(tpdbufhdr),
+								LW_EXCLUSIVE));
+	Assert(BufferGetBlockNumber(tpd_buf) == tpdblk);
+
+	/* Check whether TPD entry can exist on page? */
+	valid = TPDPageIsValid(NULL, heapbuf, NULL, tpd_buf, tpdItemOff,
+						   &tpd_e_hdr, false, true);
+	if (!valid)
+		return NULL;
+
+	tpdpage = BufferGetPage(tpd_buf);
+	itemId = PageGetItemId(tpdpage, tpdItemOff);
+	tpd_e_offset = ItemIdGetOffset(itemId);
+
+	/* We should never access deleted entry. */
+	Assert(!TPDEntryIsDeleted(tpd_e_hdr));
+
+	tpd_entry_data = tpdpage + tpd_e_offset + SizeofTPDEntryHeader;
+	*num_entries = tpd_e_hdr.tpe_num_map_entries;
+
+	if (tpd_e_hdr.tpe_flags & TPE_ONE_BYTE)
+		*entry_size = sizeof(uint8);
+	else
+		*entry_size = sizeof(uint32);
+
+	if (tpd_buffer)
+		*tpd_buffer = tpd_buf;
+
+	return tpd_entry_data;
+}
+
+/*
+ * TPDPageSetOffsetMapSlot - Set the transaction slot for given offset in TPD
+ *							 offset map.
+ *
+ * Caller must ensure that it has required lock on tpd buffer which is going to
+ * be updated here.  We can't lock the buffer here as this API is supposed to
+ * be called from critical section and lock acquisition can fail.
+ */
+void
+TPDPageSetOffsetMapSlot(Buffer heapbuf, int trans_slot_id,
+						OffsetNumber offset)
+{
+	char	   *tpd_entry_data;
+	int			num_entries = 0,
+				entry_size = 0;
+	Buffer		tpd_buf = InvalidBuffer;
+
+	tpd_entry_data = GetTPDEntryData(heapbuf, &num_entries, &entry_size,
+									 &tpd_buf);
+
+	/*
+	 * Caller would have checked that the entry is not pruned after taking
+	 * lock on the tpd page.
+	 */
+	Assert(tpd_entry_data);
+
+	Assert(offset <= num_entries);
+
+	if (entry_size == sizeof(uint8))
+	{
+		uint8		offset_tpd_e_loc = trans_slot_id;
+
+		/*
+		 * One byte access shouldn't cause unaligned access, but using memcpy
+		 * for the sake of consistency.
+		 */
+		memcpy(tpd_entry_data + (offset - 1),
+			   (char *) &offset_tpd_e_loc,
+			   sizeof(uint8));
+	}
+	else
+	{
+		uint32		offset_tpd_e_loc;
+
+		offset_tpd_e_loc = trans_slot_id;
+		memcpy(tpd_entry_data + (sizeof(uint32) * (offset - 1)),
+			   (char *) &offset_tpd_e_loc,
+			   sizeof(uint32));
+	}
+
+	MarkBufferDirty(tpd_buf);
+}
+
+/*
+ * TPDPageGetOffsetMap - Get the Offset map array of the TPD entry.
+ *
+ * This function copy the offset map into tpd_offset_map array allocated by the
+ * caller.
+ */
+void
+TPDPageGetOffsetMap(Buffer heapbuf, char *tpd_offset_map, int map_size)
+{
+	char	   *tpd_entry_data;
+	int			num_entries,
+				entry_size;
+
+	tpd_entry_data = GetTPDEntryData(heapbuf, &num_entries, &entry_size, NULL);
+
+	/*
+	 * Caller would have checked that the entry is not pruned after taking
+	 * lock on the tpd page.
+	 */
+	Assert(tpd_entry_data);
+
+	Assert(map_size == num_entries * entry_size);
+
+	memcpy(tpd_offset_map, tpd_entry_data, map_size);
+}
+
+/*
+ * TPDPageGetOffsetMapSize - Get the Offset map size of the TPD entry.
+ *
+ * Caller must ensure that it has acquired lock on tpd buffer corresponding to
+ * passed heap buffer.
+ *
+ * Returns 0, if the tpd entry gets pruned away, otherwise, return the size of
+ * TPD offset-map.
+ */
+int
+TPDPageGetOffsetMapSize(Buffer heapbuf)
+{
+	int			num_entries,
+				entry_size;
+
+	if (GetTPDEntryData(heapbuf, &num_entries, &entry_size, NULL) == NULL)
+		return 0;
+
+	return (num_entries * entry_size);
+}
+
+/*
+ * TPDPageSetOffsetMap - Overwrite TPD offset map array with input offset map
+ *						 array.
+ *
+ * This function returns a pointer to an array of offset map, it is the
+ * responsibility of the caller to free it.
+ *
+ * Caller must ensure that it has acquired lock on the TPD buffer which is
+ * going to be updated here.
+ */
+void
+TPDPageSetOffsetMap(Buffer heapbuf, char *tpd_offset_map)
+{
+	char	   *tpd_entry_data;
+	int			num_entries = 0,
+				entry_size = 0;
+	Buffer		tpd_buf = InvalidBuffer;
+
+	/* This function should only be called during recovery. */
+	Assert(InRecovery);
+
+	tpd_entry_data = GetTPDEntryData(heapbuf, &num_entries, &entry_size,
+									 &tpd_buf);
+
+	/* Entry can't be pruned during recovery. */
+	Assert(tpd_entry_data);
+
+	memcpy(tpd_entry_data, tpd_offset_map, num_entries * entry_size);
+
+	MarkBufferDirty(tpd_buf);
+}
+
+/*
+ * TPDPageSetUndo - Set the transaction information for a given transaction
+ *		slot in the TPD entry.  The difference between this function and
+ *		TPDPageSetTransactionSlotInfo is that here along with transaction
+ *		info, we update the offset to transaction slot map in the TPD entry as
+ *		well.
+ *
+ * Caller is responsible for WAL logging this operation and release the TPD
+ * buffers.  We have thought of WAL logging this as a separate operation, but
+ * that won't work as the undo record pointer can be bogus during WAL replay;
+ * that is because we regenerate the undo during WAL replay and it is quite
+ * possible that the system crashes after flushing this WAL record but before
+ * flushing WAL of actual heap operation.  Similarly, doing it after heap
+ * operation is not feasible as in that case the tuple's transaction
+ * information can get lost.
+ */
+void
+TPDPageSetUndo(Buffer heapbuf, int trans_slot_id, bool set_tpd_map_slot,
+			   FullTransactionId fxid, UndoRecPtr urec_ptr,
+			   OffsetNumber *usedoff, int ucnt)
+{
+	Page		heappage = BufferGetPage(heapbuf);
+	TransInfo	trans_slot_info;
+	BufferDesc *tpdbufhdr PG_USED_FOR_ASSERTS_ONLY;
+	Buffer		tpd_buf;
+	Page		tpdpage;
+	BlockNumber tpdblk;
+	TPDEntryHeaderData tpd_e_hdr;
+	TPDPageOpaque tpdopaque;
+	Size		size_tpd_e_map;
+	uint32		tpd_e_num_map_entries;
+	int			trans_slot_loc;
+	int			buf_idx;
+	int			i;
+	char	   *tpd_entry_data;
+	OffsetNumber tpdItemOff;
+	ItemId		itemId;
+	uint16		tpd_e_offset;
+	bool		already_exists;
+
+	GetTPDBlockAndOffset(heappage, &tpdblk, &tpdItemOff);
+
+	buf_idx = GetTPDBuffer(NULL, tpdblk, InvalidBuffer, TPD_BUF_FIND,
+						   &already_exists);
+
+	/* We must get a valid buffer. */
+	Assert(buf_idx != -1);
+	Assert(already_exists);
+	tpd_buf = tpd_buffers[buf_idx].buf;
+
+	/*
+	 * Fetch the required TPD entry.  Ensure that we are operating on the
+	 * right buffer.
+	 */
+	tpdbufhdr = GetBufferDescriptor(tpd_buf - 1);
+	Assert(BufferIsValid(tpd_buf));
+	Assert(LWLockHeldByMeInMode(BufferDescriptorGetContentLock(tpdbufhdr),
+								LW_EXCLUSIVE));
+	Assert(BufferGetBlockNumber(tpd_buf) == tpdblk);
+
+	tpdpage = BufferGetPage(tpd_buf);
+	itemId = PageGetItemId(tpdpage, tpdItemOff);
+
+	/*
+	 * TPD entry can't go away as we acquire the lock while reserving the slot
+	 * from TPD entry and keep it till we set the required transaction
+	 * information in the slot.
+	 */
+	Assert(ItemIdIsUsed(itemId));
+
+	tpd_e_offset = ItemIdGetOffset(itemId);
+
+	memcpy((char *) &tpd_e_hdr, tpdpage + tpd_e_offset, SizeofTPDEntryHeader);
+
+	/* TPD entry can't be pruned. */
+	Assert(tpd_e_hdr.blkno == BufferGetBlockNumber(heapbuf));
+
+	/* We should never access deleted entry. */
+	Assert(!TPDEntryIsDeleted(tpd_e_hdr));
+
+	tpd_e_num_map_entries = tpd_e_hdr.tpe_num_map_entries;
+	tpd_entry_data = tpdpage + tpd_e_offset + SizeofTPDEntryHeader;
+
+	if (tpd_e_hdr.tpe_flags & TPE_ONE_BYTE)
+		size_tpd_e_map = tpd_e_num_map_entries * sizeof(uint8);
+	else
+		size_tpd_e_map = tpd_e_num_map_entries * sizeof(uint32);
+
+	/*
+	 * Update TPD entry map for all the modified offsets if we have asked to
+	 * do so.
+	 */
+	if (set_tpd_map_slot)
+	{
+		if (tpd_e_hdr.tpe_flags & TPE_ONE_BYTE)
+		{
+			uint8		offset_tpd_e_loc;
+
+			offset_tpd_e_loc = (uint8) trans_slot_id;
+
+			for (i = 0; i < ucnt; i++)
+			{
+				/*
+				 * The item for which we want to update the transaction slot
+				 * information must be present in this TPD entry.
+				 */
+				Assert(usedoff[i] <= tpd_e_num_map_entries);
+
+				/*
+				 * One byte access shouldn't cause unaligned access, but using
+				 * memcpy for the sake of consistency.
+				 */
+				memcpy(tpd_entry_data + (usedoff[i] - 1),
+					   (char *) &offset_tpd_e_loc,
+					   sizeof(uint8));
+			}
+		}
+		else
+		{
+			uint32		offset_tpd_e_loc;
+
+			Assert(tpd_e_hdr.tpe_flags & TPE_FOUR_BYTE);
+
+			offset_tpd_e_loc = trans_slot_id;
+			for (i = 0; i < ucnt; i++)
+			{
+				/*
+				 * The item for which we want to update the transaction slot
+				 * information must be present in this TPD entry.
+				 */
+				Assert(usedoff[i] <= tpd_e_num_map_entries);
+				memcpy(tpd_entry_data + (sizeof(uint32) * (usedoff[i] - 1)),
+					   (char *) &offset_tpd_e_loc,
+					   sizeof(uint32));
+			}
+		}
+	}
+
+	/* Update the required transaction slot information. */
+	trans_slot_loc = (trans_slot_id - ZHEAP_PAGE_TRANS_SLOTS - 1) *
+		sizeof(TransInfo);
+	trans_slot_info.fxid = fxid;
+	trans_slot_info.urec_ptr = urec_ptr;
+	memcpy(tpd_entry_data + size_tpd_e_map + trans_slot_loc,
+		   (char *) &trans_slot_info,
+		   sizeof(TransInfo));
+	/* Update latest transaction information on the page. */
+	tpdopaque = (TPDPageOpaque) PageGetSpecialPointer(tpdpage);
+
+	if (FullTransactionIdPrecedes(tpdopaque->tpd_latest_fxid, fxid))
+		tpdopaque->tpd_latest_fxid = fxid;
+
+	MarkBufferDirty(tpd_buf);
+}
+
+/*
+ * TPDPageLock - Routine to lock the TPD page corresponding to heap page
+ *
+ * Caller should not already hold the lock.
+ *
+ * Returns false, if couldn't acquire lock because the page is pruned,
+ * otherwise, true.
+ */
+bool
+TPDPageLock(Relation relation, Buffer heapbuf)
+{
+	Page		heappage = BufferGetPage(heapbuf);
+	Buffer		tpd_buf;
+	BlockNumber tpdblk,
+				lastblock;
+	int			buf_idx;
+	bool		already_exists;
+	OffsetNumber tpdItemOff;
+	bool		valid;
+	TPDEntryHeaderData tpd_e_hdr;
+
+	GetTPDBlockAndOffset(heappage, &tpdblk, &tpdItemOff);
+
+	lastblock = RelationGetNumberOfBlocks(relation);
+
+	if (lastblock <= tpdblk)
+	{
+		/*
+		 * The required TPD block has been pruned and then truncated away
+		 * which means all transaction slots on that page are older than
+		 * oldestXidHavingUndo.  So, we can't lock the page.
+		 *
+		 * The required TPD block has been pruned which means all transaction
+		 * slots on that page are older than oldestXidHavingUndo.  So, we can
+		 * assume the TPD transaction slots are frozen aka transactions are
+		 * all-visible and can clear the TPD slots from heap tuples.
+		 */
+		LogAndClearTPDLocation(relation, heapbuf, NULL);
+		return false;
+	}
+
+	/*
+	 * Fetch the required TPD entry.  We need to lock the buffer in exclusive
+	 * mode as we later want to set the values in one of the transaction slot.
+	 */
+	buf_idx = GetTPDBuffer(relation, tpdblk, InvalidBuffer,
+						   TPD_BUF_FIND_OR_ENTER, &already_exists);
+	tpd_buf = tpd_buffers[buf_idx].buf;
+	Assert(!already_exists);
+
+	/*
+	 * We need to check whether TPD page can contain valid TPD entry before
+	 * acquiring lock to avoid deadlock.  See in TPDPageGetTransactionSlots
+	 * where we have used TPDPageIsValid for similar reason.
+	 */
+	valid = TPDPageIsValid(relation, heapbuf, NULL, tpd_buf, tpdItemOff,
+						   &tpd_e_hdr, true, false);
+	if (!valid)
+	{
+		ReleaseLastTPDBuffer(tpd_buf, false);
+		return false;
+	}
+
+	LockBuffer(tpd_buf, BUFFER_LOCK_EXCLUSIVE);
+
+	/* Check whether TPD entry can exist on page? */
+	valid = TPDPageIsValid(relation, heapbuf, NULL, tpd_buf, tpdItemOff,
+						   &tpd_e_hdr, true, true);
+	if (!valid)
+	{
+		ReleaseLastTPDBuffer(tpd_buf, true);
+		return false;
+	}
+
+	return true;
+}
+
+/*
+ * GetTPDBlockAndOffset - Get the TPD block and offset from last transaction
+ *		slot in the heap page.
+ */
+void
+GetTPDBlockAndOffset(Page heap_page, BlockNumber *tpd_blk,
+					 OffsetNumber *tpd_item_off)
+{
+	TransInfo	trans_info;
+	PageHeader	phdr PG_USED_FOR_ASSERTS_ONLY;
+	ZHeapPageOpaque zopaque;
+
+	phdr = (PageHeader) heap_page;
+
+	/* Heap page must have a TPD entry. */
+	Assert(phdr->pd_flags & PD_PAGE_HAS_TPD_SLOT);
+
+	/* The last slot in page has the address of the required TPD entry. */
+	zopaque = (ZHeapPageOpaque) PageGetSpecialPointer(heap_page);
+	trans_info = zopaque->transinfo[ZHEAP_PAGE_TRANS_SLOTS - 1];
+
+	/*
+	 * ZBORKED: This should be done through a union, not an undocumented hack
+	 * like this
+	 */
+	if (tpd_blk)
+		*tpd_blk = EpochFromFullTransactionId(trans_info.fxid);
+	if (tpd_item_off)
+		*tpd_item_off = XidFromFullTransactionId(trans_info.fxid) & OFFSET_MASK;
+}
+
+/*
+ * XLogReadTPDBuffer - Read the TPD buffer.
+ */
+XLogRedoAction
+XLogReadTPDBuffer(XLogReaderState *record, uint8 block_id)
+{
+	Buffer		tpd_buf;
+	XLogRedoAction action;
+	bool		already_exists;
+
+	action = XLogReadBufferForRedo(record, block_id, &tpd_buf);
+
+	/*
+	 * Remember the buffer, so that it can be release later via
+	 * UnlockReleaseTPDBuffers.
+	 */
+	if (action != BLK_NOTFOUND)
+		GetTPDBuffer(NULL, BufferGetBlockNumber(tpd_buf), tpd_buf,
+					 TPD_BUF_FIND_OR_KNOWN_ENTER, &already_exists);
+
+	return action;
+}
+
+/*
+ * RegisterTPDBuffer - Register the TPD buffer
+ *
+ * returns the block_id that can be used to register additional buffers in the
+ * caller.
+ */
+uint8
+RegisterTPDBuffer(Page heappage, uint8 block_id)
+{
+	BufferDesc *tpdbufhdr PG_USED_FOR_ASSERTS_ONLY;
+	Buffer		tpd_buf;
+	BlockNumber tpdblk;
+	int			buf_idx;
+	bool		already_exists;
+
+	GetTPDBlockAndOffset(heappage, &tpdblk, NULL);
+	buf_idx = GetTPDBuffer(NULL, tpdblk, InvalidBuffer, TPD_BUF_FIND,
+						   &already_exists);
+
+	/* We must get a valid buffer. */
+	Assert(buf_idx != -1);
+	Assert(already_exists);
+	tpd_buf = tpd_buffers[buf_idx].buf;
+
+	/* Return same block id if this buffer is already registered. */
+	if (TPDBufferAlreadyRegistered(tpd_buf))
+		return block_id;
+
+	/* We must be in critical section to perform this action. */
+	Assert(CritSectionCount > 0);
+	tpdbufhdr = GetBufferDescriptor(tpd_buf - 1);
+	/* The TPD buffer must be valid and locked by me. */
+	Assert(BufferIsValid(tpd_buf));
+	Assert(LWLockHeldByMeInMode(BufferDescriptorGetContentLock(tpdbufhdr),
+								LW_EXCLUSIVE));
+
+	XLogRegisterBuffer(block_id++, tpd_buf, REGBUF_STANDARD);
+
+	return block_id;
+}
+
+/*
+ * TPDPageSetLSN - Set LSN on TPD pages.
+ */
+void
+TPDPageSetLSN(Page heappage, XLogRecPtr recptr)
+{
+	BufferDesc *tpdbufhdr PG_USED_FOR_ASSERTS_ONLY;
+	Buffer		tpd_buf;
+	BlockNumber tpdblk;
+	int			buf_idx;
+	bool		already_exists;
+
+	GetTPDBlockAndOffset(heappage, &tpdblk, NULL);
+
+	buf_idx = GetTPDBuffer(NULL, tpdblk, InvalidBuffer, TPD_BUF_FIND,
+						   &already_exists);
+
+	/* We must get a valid buffer. */
+	Assert(buf_idx != -1);
+	Assert(already_exists);
+	tpd_buf = tpd_buffers[buf_idx].buf;
+
+	/* Reset the registered buffer index. */
+	registered_tpd_buf_idx = 0;
+
+	/*
+	 * Before recording the LSN, ensure that the TPD buffer must be valid and
+	 * locked by me.
+	 */
+	tpdbufhdr = GetBufferDescriptor(tpd_buf - 1);
+	Assert(BufferIsValid(tpd_buf));
+	Assert(LWLockHeldByMeInMode(BufferDescriptorGetContentLock(tpdbufhdr),
+								LW_EXCLUSIVE));
+	Assert(BufferGetBlockNumber(tpd_buf) == tpdblk);
+
+	PageSetLSN(BufferGetPage(tpd_buf), recptr);
+}
+
+/*
+ * ResetTPDBuffers  - Reset TPD buffer index. Required at the time of
+ * transaction abort or release TPD buffers.
+ */
+void
+ResetTPDBuffers(void)
+{
+	int			i;
+
+	for (i = 0; i < tpd_buf_idx; i++)
+	{
+		tpd_buffers[i].buf = InvalidBuffer;
+		tpd_buffers[i].blk = InvalidBlockNumber;
+	}
+
+	tpd_buf_idx = 0;
+}
+
+/*
+ * UnlockReleaseTPDBuffers - Release all the TPD buffers locked by me.
+ */
+void
+UnlockReleaseTPDBuffers(void)
+{
+	Buffer		tpd_buf;
+	BufferDesc *tpdbufhdr PG_USED_FOR_ASSERTS_ONLY;
+	int			i;
+
+	for (i = 0; i < tpd_buf_idx; i++)
+	{
+		tpd_buf = tpd_buffers[i].buf;
+		Assert(BufferIsValid(tpd_buf));
+		tpdbufhdr = GetBufferDescriptor(tpd_buf - 1);
+		Assert(LWLockHeldByMeInMode(BufferDescriptorGetContentLock(tpdbufhdr),
+									LW_EXCLUSIVE));
+		UnlockReleaseBuffer(tpd_buf);
+	}
+
+	ResetTPDBuffers();
+}
+
+/*
+ * PageGetTPDFreeSpace
+ *		Returns the size of the free (allocatable) space on a page.
+ *
+ * As of now, this is just a wrapper over PageGetFreeSpace, however in future,
+ * the space management in TPD pages could be different.
+ */
+Size
+PageGetTPDFreeSpace(Page page)
+{
+	int			space;
+
+	/*
+	 * Use signed arithmetic here so that we behave sensibly if pd_lower >
+	 * pd_upper.
+	 */
+	space = PageGetFreeSpace(page);
+
+	return (Size) space;
+}
diff --git a/src/backend/access/zheap/tpdxlog.c b/src/backend/access/zheap/tpdxlog.c
new file mode 100644
index 0000000..a4c5db2
--- /dev/null
+++ b/src/backend/access/zheap/tpdxlog.c
@@ -0,0 +1,522 @@
+/*-------------------------------------------------------------------------
+ *
+ * tpdxlog.c
+ *	  WAL replay logic for tpd.
+ *
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/zheap/tpdxlog.c
+ *
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include "access/tpd.h"
+#include "access/tpd_xlog.h"
+#include "access/xlogutils.h"
+#include "access/zheapam_xlog.h"
+
+/*
+ * replay of tpd entry allocation
+ */
+static void
+tpd_xlog_allocate_entry(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	xl_tpd_allocate_entry *xlrec;
+	Buffer		tpdbuffer;
+	Buffer		heap_page_buffer;
+	Buffer		metabuf = InvalidBuffer;
+	Buffer		last_used_buf = InvalidBuffer;
+	Buffer		old_tpd_buf = InvalidBuffer;
+	Page		tpdpage;
+	TPDPageOpaque tpdopaque;
+	XLogRedoAction action;
+
+	xlrec = (xl_tpd_allocate_entry *) XLogRecGetData(record);
+
+	/*
+	 * If we inserted the first and only tpd entry on the page, re-initialize
+	 * the page from scratch.
+	 */
+	if (XLogRecGetInfo(record) & XLOG_TPD_INIT_PAGE)
+	{
+		tpdbuffer = XLogInitBufferForRedo(record, 0);
+		tpdpage = BufferGetPage(tpdbuffer);
+		TPDInitPage(tpdpage, BufferGetPageSize(tpdbuffer));
+		action = BLK_NEEDS_REDO;
+	}
+	else
+		action = XLogReadBufferForRedo(record, 0, &tpdbuffer);
+	if (action == BLK_NEEDS_REDO)
+	{
+		char	   *tpd_entry;
+		Size		size_tpd_entry;
+		OffsetNumber offnum;
+
+		tpd_entry = XLogRecGetBlockData(record, 0, &size_tpd_entry);
+		tpdpage = BufferGetPage(tpdbuffer);
+		offnum = TPDPageAddEntry(tpdpage, tpd_entry, size_tpd_entry,
+								 xlrec->offnum);
+		if (offnum == InvalidOffsetNumber)
+			elog(PANIC, "failed to add TPD entry");
+		MarkBufferDirty(tpdbuffer);
+		PageSetLSN(tpdpage, lsn);
+
+		/* The TPD entry must be added at the provided offset. */
+		Assert(offnum == xlrec->offnum);
+
+		tpdopaque = (TPDPageOpaque) PageGetSpecialPointer(tpdpage);
+		tpdopaque->tpd_prevblkno = xlrec->prevblk;
+
+		MarkBufferDirty(tpdbuffer);
+		PageSetLSN(tpdpage, lsn);
+	}
+	else if (action == BLK_RESTORED)
+	{
+		/*
+		 * Note that we still update the page even if it was restored from a
+		 * full page image, because the special space is not included in the
+		 * image.
+		 */
+		tpdpage = BufferGetPage(tpdbuffer);
+
+		tpdopaque = (TPDPageOpaque) PageGetSpecialPointer(tpdpage);
+		tpdopaque->tpd_prevblkno = xlrec->prevblk;
+
+		MarkBufferDirty(tpdbuffer);
+		PageSetLSN(tpdpage, lsn);
+	}
+
+	if (XLogReadBufferForRedo(record, 1, &heap_page_buffer) == BLK_NEEDS_REDO)
+	{
+		/* Set the TPD location in last transaction slot of heap page. */
+		SetTPDLocation(heap_page_buffer, tpdbuffer, xlrec->offnum);
+		MarkBufferDirty(heap_page_buffer);
+
+		PageSetLSN(BufferGetPage(heap_page_buffer), lsn);
+	}
+
+	/* replay the record for meta page */
+	if (XLogRecHasBlockRef(record, 2))
+	{
+		xl_zheap_metadata *xlrecmeta;
+		char	   *ptr;
+		Size		len;
+
+		metabuf = XLogInitBufferForRedo(record, 2);
+		ptr = XLogRecGetBlockData(record, 2, &len);
+
+		Assert(len == SizeOfMetaData);
+		Assert(BufferGetBlockNumber(metabuf) == ZHEAP_METAPAGE);
+		xlrecmeta = (xl_zheap_metadata *) ptr;
+
+		zheap_init_meta_page(metabuf, xlrecmeta->first_used_tpd_page,
+							 xlrecmeta->last_used_tpd_page);
+		MarkBufferDirty(metabuf);
+		PageSetLSN(BufferGetPage(metabuf), lsn);
+
+		/*
+		 * We can have reference of block 3, iff we have reference for block
+		 * 2.
+		 */
+		if (XLogRecHasBlockRef(record, 3))
+		{
+			action = XLogReadBufferForRedo(record, 3, &last_used_buf);
+
+			/*
+			 * Note that we still update the page even if it was restored from
+			 * a full page image, because the special space is not included in
+			 * the image.
+			 */
+			if (action == BLK_NEEDS_REDO || action == BLK_RESTORED)
+			{
+				Page		last_used_page;
+				TPDPageOpaque last_tpdopaque;
+
+				last_used_page = BufferGetPage(last_used_buf);
+				last_tpdopaque = (TPDPageOpaque) PageGetSpecialPointer(last_used_page);
+				last_tpdopaque->tpd_nextblkno = xlrec->nextblk;
+
+				/* old and last tpd buffer are same. */
+				if (xlrec->flags & XLOG_OLD_TPD_BUF_EQ_LAST_TPD_BUF)
+				{
+					TPDEntryHeader old_tpd_entry;
+					Page		otpdpage;
+					char	   *data;
+					OffsetNumber *off_num;
+					Size		datalen PG_USED_FOR_ASSERTS_ONLY;
+					ItemId		old_item_id;
+
+					if (action == BLK_NEEDS_REDO)
+					{
+						data = XLogRecGetBlockData(record, 3, &datalen);
+
+						off_num = (OffsetNumber *) data;
+						Assert(datalen == sizeof(OffsetNumber));
+
+						otpdpage = BufferGetPage(last_used_buf);
+						old_item_id = PageGetItemId(otpdpage, *off_num);
+						old_tpd_entry = (TPDEntryHeader) PageGetItem(otpdpage, old_item_id);
+						old_tpd_entry->tpe_flags |= TPE_DELETED;
+					}
+
+					/* We can't have a separate reference for old tpd buffer. */
+					Assert(!XLogRecHasBlockRef(record, 4));
+				}
+
+				MarkBufferDirty(last_used_buf);
+				PageSetLSN(last_used_page, lsn);
+			}
+		}
+
+		/*
+		 * We can have reference of block 4, iff we have reference for block
+		 * 2.
+		 */
+		if (XLogRecHasBlockRef(record, 4))
+		{
+			TPDEntryHeader old_tpd_entry;
+			Page		otpdpage;
+			char	   *data;
+			OffsetNumber *off_num;
+			Size		datalen PG_USED_FOR_ASSERTS_ONLY;
+			ItemId		old_item_id;
+
+			action = XLogReadBufferForRedo(record, 4, &old_tpd_buf);
+
+			if (action == BLK_NEEDS_REDO)
+			{
+				data = XLogRecGetBlockData(record, 4, &datalen);
+
+				off_num = (OffsetNumber *) data;
+				Assert(datalen == sizeof(OffsetNumber));
+
+				otpdpage = BufferGetPage(old_tpd_buf);
+				old_item_id = PageGetItemId(otpdpage, *off_num);
+				old_tpd_entry = (TPDEntryHeader) PageGetItem(otpdpage, old_item_id);
+				old_tpd_entry->tpe_flags |= TPE_DELETED;
+
+				MarkBufferDirty(old_tpd_buf);
+				PageSetLSN(BufferGetPage(old_tpd_buf), lsn);
+			}
+		}
+	}
+
+	if (BufferIsValid(tpdbuffer))
+		UnlockReleaseBuffer(tpdbuffer);
+	if (BufferIsValid(heap_page_buffer))
+		UnlockReleaseBuffer(heap_page_buffer);
+	if (BufferIsValid(metabuf))
+		UnlockReleaseBuffer(metabuf);
+	if (BufferIsValid(last_used_buf))
+		UnlockReleaseBuffer(last_used_buf);
+	if (BufferIsValid(old_tpd_buf))
+		UnlockReleaseBuffer(old_tpd_buf);
+}
+
+/*
+ * replay inplace update of TPD entry
+ */
+static void
+tpd_xlog_inplace_update_entry(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	Buffer		tpdbuf;
+	XLogRedoAction action;
+
+	/*
+	 * If we have a full-page image, restore it (using a cleanup lock) and
+	 * we're done.
+	 */
+	action = XLogReadBufferForRedoExtended(record, 0, RBM_NORMAL, true,
+										   &tpdbuf);
+	if (action == BLK_NEEDS_REDO)
+	{
+		Page		tpdpage = (Page) BufferGetPage(tpdbuf);
+		ItemId		item_id;
+		OffsetNumber *off_num;
+		char	   *data;
+		char	   *new_tpd_entry;
+		Size		datalen,
+					size_new_tpd_entry;
+		uint16		tpd_e_offset;
+
+		data = XLogRecGetBlockData(record, 0, &datalen);
+		off_num = (OffsetNumber *) data;
+		new_tpd_entry = (char *) ((char *) data + sizeof(OffsetNumber));
+		size_new_tpd_entry = datalen - sizeof(OffsetNumber);
+
+		item_id = PageGetItemId(tpdpage, *off_num);
+		tpd_e_offset = ItemIdGetOffset(item_id);
+		memcpy((char *) (tpdpage + tpd_e_offset),
+			   new_tpd_entry,
+			   size_new_tpd_entry);
+		ItemIdChangeLen(item_id, size_new_tpd_entry);
+
+		MarkBufferDirty(tpdbuf);
+		PageSetLSN(tpdpage, lsn);
+	}
+	if (BufferIsValid(tpdbuf))
+		UnlockReleaseBuffer(tpdbuf);
+}
+
+/*
+ * replay of pruning tpd page
+ */
+static void
+tpd_xlog_clean(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	xl_tpd_clean *xlrec = (xl_tpd_clean *) XLogRecGetData(record);
+	Buffer		tpdbuf;
+	XLogRedoAction action;
+
+	/*
+	 * If we have a full-page image, restore it (using a cleanup lock) and
+	 * we're done.
+	 */
+	action = XLogReadBufferForRedoExtended(record, 0, RBM_NORMAL, true,
+										   &tpdbuf);
+	if (action == BLK_NEEDS_REDO)
+	{
+		Page		tpdpage = (Page) BufferGetPage(tpdbuf);
+		Page		tmppage;
+		OffsetNumber *end;
+		OffsetNumber *nowunused;
+		OffsetNumber *target_offnum;
+		OffsetNumber tmp_target_off;
+		Size	   *space_required;
+		Size		tmp_spc_rqd;
+		Size		datalen;
+		int			nunused;
+
+		if (xlrec->flags & XLZ_CLEAN_CONTAINS_OFFSET)
+		{
+			target_offnum = (OffsetNumber *) ((char *) xlrec + SizeOfTPDClean);
+			space_required = (Size *) ((char *) target_offnum + sizeof(OffsetNumber));
+		}
+		else
+		{
+			target_offnum = &tmp_target_off;
+			*target_offnum = InvalidOffsetNumber;
+			space_required = &tmp_spc_rqd;
+			*space_required = 0;
+		}
+
+		nowunused = (OffsetNumber *) XLogRecGetBlockData(record, 0, &datalen);
+		end = (OffsetNumber *) ((char *) nowunused + datalen);
+		nunused = (end - nowunused);
+
+		if (nunused >= 0)
+		{
+			/*
+			 * Update all item pointers per the record, and repair
+			 * fragmentation.
+			 */
+			TPDPagePruneExecute(tpdbuf, nowunused, nunused);
+		}
+
+		tmppage = PageGetTempPageCopy(tpdpage);
+		TPDPageRepairFragmentation(tpdpage, tmppage, *target_offnum,
+								   *space_required);
+
+		/*
+		 * Note: we don't worry about updating the page's prunability hints.
+		 * At worst this will cause an extra prune cycle to occur soon.
+		 */
+
+		MarkBufferDirty(tpdbuf);
+		PageSetLSN(tpdpage, lsn);
+
+		pfree(tmppage);
+	}
+	if (BufferIsValid(tpdbuf))
+		UnlockReleaseBuffer(tpdbuf);
+}
+
+/*
+ * replay for clearing tpd location from heap page.
+ */
+static void
+tpd_xlog_clear_location(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	Buffer		buffer;
+
+	if (XLogReadBufferForRedo(record, 0, &buffer) == BLK_NEEDS_REDO)
+	{
+		Page		page = (Page) BufferGetPage(buffer);
+
+		ClearTPDLocation(buffer);
+		MarkBufferDirty(buffer);
+		PageSetLSN(page, lsn);
+	}
+	if (BufferIsValid(buffer))
+		UnlockReleaseBuffer(buffer);
+}
+
+/*
+ * replay for freeing tpd page.
+ */
+static void
+tpd_xlog_free_page(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	RelFileNode rnode;
+	xl_tpd_free_page *xlrec = (xl_tpd_free_page *) XLogRecGetData(record);
+	Buffer		buffer = InvalidBuffer,
+				prevbuf = InvalidBuffer,
+				nextbuf = InvalidBuffer,
+				metabuf = InvalidBuffer;
+	BlockNumber blkno;
+	Page		page;
+	XLogRedoAction action;
+	Size		freespace;
+
+	if (XLogRecHasBlockRef(record, 0))
+	{
+		action = XLogReadBufferForRedo(record, 0, &prevbuf);
+
+		/*
+		 * Note that we still update the page even if it was restored from a
+		 * full page image, because the special space is not included in the
+		 * image.
+		 */
+		if (action == BLK_NEEDS_REDO || action == BLK_RESTORED)
+		{
+			TPDPageOpaque prevtpdopaque;
+			Page		prevpage = (Page) BufferGetPage(prevbuf);
+
+			prevtpdopaque = (TPDPageOpaque) PageGetSpecialPointer(prevpage);
+			prevtpdopaque->tpd_nextblkno = xlrec->nextblkno;
+
+			MarkBufferDirty(prevbuf);
+			PageSetLSN(prevpage, lsn);
+		}
+	}
+
+	XLogRecGetBlockTag(record, 1, NULL, &rnode, NULL, &blkno);
+	action = XLogReadBufferForRedo(record, 1, &buffer);
+	page = (Page) BufferGetPage(buffer);
+
+	/*
+	 * Note that we still update the page even if it was restored from a full
+	 * page image, because the special space is not included in the image.
+	 */
+	if (action == BLK_NEEDS_REDO || action == BLK_RESTORED)
+	{
+		MemSet((PageHeader) page, 0, BufferGetPageSize(buffer));
+
+		MarkBufferDirty(buffer);
+	}
+
+	/* Page should be marked as NEW. */
+	Assert(PageIsNew(page));
+	Assert(blkno == BufferGetBlockNumber(buffer));
+	freespace = BLCKSZ - SizeOfPageHeaderData;
+
+	if (XLogRecHasBlockRef(record, 2))
+	{
+		action = XLogReadBufferForRedo(record, 2, &nextbuf);
+
+		if (action == BLK_NEEDS_REDO || action == BLK_RESTORED)
+		{
+			TPDPageOpaque nexttpdopaque;
+			Page		nextpage = (Page) BufferGetPage(nextbuf);
+
+			nexttpdopaque = (TPDPageOpaque) PageGetSpecialPointer(nextpage);
+			nexttpdopaque->tpd_prevblkno = xlrec->prevblkno;
+
+			MarkBufferDirty(nextbuf);
+			PageSetLSN(nextpage, lsn);
+		}
+	}
+
+	if (XLogRecHasBlockRef(record, 3))
+	{
+		xl_zheap_metadata *xlrecmeta;
+		char	   *ptr;
+		Size		len;
+
+		metabuf = XLogInitBufferForRedo(record, 3);
+		ptr = XLogRecGetBlockData(record, 3, &len);
+
+		Assert(len == SizeOfMetaData);
+		Assert(BufferGetBlockNumber(metabuf) == ZHEAP_METAPAGE);
+		xlrecmeta = (xl_zheap_metadata *) ptr;
+
+		zheap_init_meta_page(metabuf, xlrecmeta->first_used_tpd_page,
+							 xlrecmeta->last_used_tpd_page);
+		MarkBufferDirty(metabuf);
+		PageSetLSN(BufferGetPage(metabuf), lsn);
+	}
+
+	if (BufferIsValid(prevbuf))
+		UnlockReleaseBuffer(prevbuf);
+	if (BufferIsValid(buffer))
+		UnlockReleaseBuffer(buffer);
+	if (BufferIsValid(nextbuf))
+		UnlockReleaseBuffer(nextbuf);
+	if (BufferIsValid(metabuf))
+		UnlockReleaseBuffer(metabuf);
+
+	/* Record the empty page in FSM. */
+	XLogRecordPageWithFreeSpace(rnode, blkno, freespace);
+}
+
+/*
+ * replay of pruning all the entries in tpd page.
+ */
+static void
+tpd_xlog_clean_all_entries(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	Buffer		buffer;
+
+	if (XLogReadBufferForRedo(record, 0, &buffer) == BLK_NEEDS_REDO)
+	{
+		Page		page = (Page) BufferGetPage(buffer);
+
+		((PageHeader) page)->pd_lower = SizeOfPageHeaderData;
+		((PageHeader) page)->pd_upper = ((PageHeader) page)->pd_special;
+
+		MarkBufferDirty(buffer);
+		PageSetLSN(page, lsn);
+	}
+	if (BufferIsValid(buffer))
+		UnlockReleaseBuffer(buffer);
+}
+
+void
+tpd_redo(XLogReaderState *record)
+{
+	uint8		info = XLogRecGetInfo(record) & ~XLR_INFO_MASK;
+
+	switch (info & XLOG_TPD_OPMASK)
+	{
+		case XLOG_ALLOCATE_TPD_ENTRY:
+			tpd_xlog_allocate_entry(record);
+			break;
+		case XLOG_INPLACE_UPDATE_TPD_ENTRY:
+			tpd_xlog_inplace_update_entry(record);
+			break;
+		case XLOG_TPD_CLEAN:
+			tpd_xlog_clean(record);
+			break;
+		case XLOG_TPD_CLEAR_LOCATION:
+			tpd_xlog_clear_location(record);
+			break;
+		case XLOG_TPD_FREE_PAGE:
+			tpd_xlog_free_page(record);
+			break;
+		case XLOG_TPD_CLEAN_ALL_ENTRIES:
+			tpd_xlog_clean_all_entries(record);
+			break;
+		default:
+			elog(PANIC, "tpd_redo: unknown op code %u", info);
+	}
+}
diff --git a/src/backend/access/zheap/zheapam.c b/src/backend/access/zheap/zheapam.c
new file mode 100644
index 0000000..7a99084
--- /dev/null
+++ b/src/backend/access/zheap/zheapam.c
@@ -0,0 +1,8806 @@
+/*-------------------------------------------------------------------------
+ *
+ * zheapam.c
+ *	  zheap access method code
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/heap/zheapam.c
+ *
+ * NOTES
+ *	  This file contains the zheap_ routines which implement
+ *	  the POSTGRES zheap access method used for relations backed
+ *	  by undo storage.
+ *
+ *	  In zheap, we never generate subtransaction id and rather always use top
+ *	  transaction id.  The sub-transaction id is mainly required to detect the
+ *	  visibility of tuple when the sub-transaction state is different from
+ *	  main transaction state, say due to Rollback To SavePoint.  In zheap, we
+ *	  always perform undo actions to make sure that the tuple state reaches to
+ *	  the state where it is at the start of subtransaction in such a case.
+ *	  This will also help in avoiding the transaction slots to grow inside a
+ *	  page and will have lesser clog entries.  Another advantage is that it
+ *	  will help us retaining the undo records for one transaction together
+ *	  in undo log instead of those being interleaved which will avoid having
+ *	  more undo records that have UREC_INFO_TRANSACTION.
+ *
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include "access/bufmask.h"
+#include "access/htup_details.h"
+#include "access/parallel.h"
+#include "access/relscan.h"
+#include "access/sysattr.h"
+#include "access/xact.h"
+#include "access/relation.h"
+#include "access/relscan.h"
+#include "access/tableam.h"
+#include "access/tpd.h"
+#include "access/tuptoaster.h"
+#include "access/undoaccess.h"
+#include "access/undolog.h"
+#include "access/undolog_xlog.h"
+#include "access/undorecord.h"
+#include "access/undorequest.h"
+#include "access/visibilitymap.h"
+#include "access/zheap.h"
+#include "access/zhio.h"
+#include "access/zhtup.h"
+#include "access/zheapam_xlog.h"
+#include "access/zheap.h"
+#include "access/zheapscan.h"
+#include "access/zmultilocker.h"
+#include "catalog/catalog.h"
+#include "executor/tuptable.h"
+#include "miscadmin.h"
+#include "nodes/tidbitmap.h"
+#include "pgstat.h"
+#include "storage/bufmgr.h"
+#include "storage/lmgr.h"
+#include "storage/predicate.h"
+#include "storage/procarray.h"
+#include "storage/itemid.h"
+#include "storage/buf_internals.h"
+#include "utils/datum.h"
+#include "utils/expandeddatum.h"
+#include "utils/inval.h"
+#include "utils/memdebug.h"
+#include "utils/rel.h"
+#include "utils/ztqual.h"
+
+extern bool synchronize_seqscans;
+
+/* defines the return status for a lock wait */
+typedef enum
+{
+	LOCK_WAIT_RECHECK,			/* recheck if we can still modify the tuple */
+	LOCK_WAIT_FAILED,			/* we can't modify the tuple */
+	LOCK_WAIT_SUCCESS			/* we can modify the tuple */
+}			LockWaitStatus;
+
+static bool zheap_delete_wait_helper(Relation relation,
+									 Buffer buffer, ZHeapTuple zheaptup,
+									 FullTransactionId fxid, TransactionId xwait,
+									 int xwait_trans_slot, SubTransactionId xwait_subxid,
+									 ItemId lp,
+									 TransactionId tup_xid, bool *have_tuple_lock,
+									 TransactionId *single_locker_xid,
+									 bool *any_multi_locker_member_alive,
+									 TM_Result *result);
+static bool zheap_update_wait_helper(Relation relation,
+									 Buffer buffer, ZHeapTuple zheaptup,
+									 FullTransactionId fxid, TransactionId xwait,
+									 int xwait_trans_slot, SubTransactionId xwait_subxid,
+									 LockTupleMode lockmode, bool key_intact,
+									 ItemId lp,
+									 TransactionId tup_xid, bool *have_tuple_lock,
+									 TransactionId *single_locker_xid,
+									 bool *any_multi_locker_member_alive,
+									 bool *checked_lockers, bool *locker_remains,
+									 TM_Result *result);
+static bool zheap_tuple_already_locked(ZHeapTuple zhtup, UndoRecPtr urec_ptr,
+									   TransactionId xid, LockTupleMode mode,
+									   int trans_slot_id, uint16 infomask, TM_Result *result);
+static LockWaitStatus zheap_lock_wait_helper(Relation relation, Buffer buffer,
+											 ZHeapTuple zhtup, FullTransactionId fxid, TransactionId xwait,
+											 int xwait_trans_slot, SubTransactionId xwait_subxid,
+											 CommandId cid, LockTupleMode mode, LockWaitPolicy wait_policy,
+											 LockOper lockopr, ItemPointer ctid, ItemId lp,
+											 TransactionId tup_xid, uint16 infomask, bool follow_updates,
+											 TransactionId *single_locker_xid, TM_Result *result,
+											 bool *any_multi_locker_member_alive, bool *have_tuple_lock);
+static ZHeapTuple zheap_prepare_insert(Relation relation, ZHeapTuple tup,
+									   int options, uint32 specToken);
+static TM_Result zheap_lock_updated_tuple(Relation rel, ZHeapTuple tuple, ItemPointer ctid,
+										  FullTransactionId fxid, LockTupleMode mode, LockOper lockopr,
+										  CommandId cid, bool *rollback_and_relocked);
+static UndoRecPtr zheap_lock_tuple_guts(Buffer buf, ZHeapTuple zhtup,
+										ZHeapTupleTransInfo *tup_info, TransactionId tup_single_locker_xid,
+										FullTransactionId current_fxid, int current_trans_slot,
+										LockTupleMode mode, LockOper lockopr, bool hasSubXactLock,
+										bool clear_multi_locker, bool needs_wal,
+										ZHeapPrepareUndoInfo *zh_undo_info, int *out_result_trans_slot);
+static void compute_new_xid_infomask(ZHeapTuple zhtup, Buffer buf,
+									 TransactionId tup_xid, int tup_trans_slot,
+									 uint16 old_infomask, TransactionId add_to_xid,
+									 int trans_slot, TransactionId single_locker_xid,
+									 LockTupleMode mode, LockOper lockoper,
+									 uint16 *result_infomask, int *result_trans_slot);
+static void log_zheap_insert(ZHeapWALInfo *walinfo, Relation relation,
+							 int options, bool skip_undo);
+static void log_zheap_update(ZHeapWALInfo *oldinfo, ZHeapWALInfo *newinfo, bool inplace_update);
+static void log_zheap_delete(ZHeapWALInfo *walinfo, bool changingPart,
+							 SubTransactionId subxid, TransactionId tup_xid);
+static void log_zheap_multi_insert(ZHeapMultiInsertWALInfo *walinfo, bool skip_undo, char *scratch);
+static void log_zheap_lock_tuple(ZHeapWALInfo *walinfo, TransactionId tup_xid,
+								 int trans_slot_id, bool hasSubXactLock, LockTupleMode mode);
+static Bitmapset *ZHeapDetermineModifiedColumns(Relation relation, Bitmapset *interesting_cols,
+												ZHeapTuple oldtup, ZHeapTuple newtup);
+static inline void CheckAndLockTPDPage(Relation relation, int new_trans_slot_id,
+									   int old_trans_slot_id, Buffer newbuf,
+									   Buffer oldbuf);
+static bool RefetchAndCheckTupleStatus(Relation relation, Buffer buffer,
+									   int old_infomask, TransactionId tup_xid,
+									   TransactionId *single_locker_xid,
+									   LockTupleMode *mode, ZHeapTupleData *zhtup);
+static bool CheckZheapPageSlotsAreEmpty(Page page);
+
+/*
+ * Subroutine for zheap_insert(). Prepares a tuple for insertion.
+ *
+ * This is similar to heap_prepare_insert except that we don't set
+ * information in tuple header as that needs to be either set in
+ * TPD entry or undorecord for this tuple.
+ */
+static ZHeapTuple
+zheap_prepare_insert(Relation relation, ZHeapTuple tup, int options,
+					 uint32 specToken)
+{
+
+	/*
+	 * In zheap, we don't support the optimization for TABLE_INSERT_SKIP_WAL.
+	 * If we skip writing/using WAL, we must force the relation down to disk
+	 * (using heap_sync) before it's safe to commit the transaction. This
+	 * requires writing out any dirty buffers of that relation and then doing
+	 * a forced fsync. For zheap, we've to fsync the corresponding undo
+	 * buffers as well. It is difficult to keep track of dirty undo buffers
+	 * and fsync them at end of the operation in some function similar to
+	 * heap_sync. But, if we're freezing the tuple during insertion, we can
+	 * use the TABLE_INSERT_SKIP_WAL optimization since we don't write undo
+	 * for the same. Thus just skip the optimization if only
+	 * TABLE_INSERT_SKIP_WAL is specified.
+	 */
+
+	/*
+	 * Parallel operations are required to be strictly read-only in a parallel
+	 * worker.  Parallel inserts are not safe even in the leader in the
+	 * general case, because group locking means that heavyweight locks for
+	 * relation extension or GIN page locks will not conflict between members
+	 * of a lock group, but we don't prohibit that case here because there are
+	 * useful special cases that we can safely allow, such as CREATE TABLE AS.
+	 */
+	if (IsParallelWorker())
+		ereport(ERROR,
+				(errcode(ERRCODE_INVALID_TRANSACTION_STATE),
+				 errmsg("cannot insert tuples in a parallel worker")));
+
+	tup->t_data->t_infomask &= ~ZHEAP_VIS_STATUS_MASK;
+	tup->t_data->t_infomask2 &= ~ZHEAP_XACT_SLOT;
+
+	if (options & ZHEAP_INSERT_FROZEN)
+		ZHeapTupleHeaderSetXactSlot(tup->t_data, ZHTUP_SLOT_FROZEN);
+	tup->t_tableOid = RelationGetRelid(relation);
+
+	/*
+	 * If the new tuple is too big for storage or contains already toasted
+	 * out-of-line attributes from some other relation, invoke the toaster.
+	 */
+	if (relation->rd_rel->relkind != RELKIND_RELATION &&
+		relation->rd_rel->relkind != RELKIND_MATVIEW)
+	{
+		/* toast table entries should never be recursively toasted */
+		Assert(!ZHeapTupleHasExternal(tup));
+		return tup;
+	}
+	else if (ZHeapTupleHasExternal(tup) || tup->t_len > TOAST_TUPLE_THRESHOLD)
+		return ztoast_insert_or_update(relation, tup, NULL, options, specToken);
+	else
+		return tup;
+}
+
+/*
+ * Given two versions of the same t_infomask for a tuple, compare them and
+ * return whether the relevant status for a tuple xid has changed.  This is
+ * used after a buffer lock has been released and reacquired: we want to ensure
+ * that the tuple state continues to be the same it was when we previously
+ * examined it.
+ *
+ * Note the xid field itself must be compared separately.
+ */
+static inline bool
+xid_infomask_changed(uint16 new_infomask, uint16 old_infomask)
+{
+	const uint16 interesting =
+	ZHEAP_MULTI_LOCKERS | ZHEAP_XID_LOCK_ONLY | ZHEAP_LOCK_MASK;
+
+	if ((new_infomask & interesting) != (old_infomask & interesting))
+		return true;
+
+	return false;
+}
+
+/*
+ * zheap_insert - insert tuple into a zheap
+ *
+ * The functionality related to the heap is quite similar to heap_insert.
+ * Additionally this function inserts an undo record and updates the undo
+ * pointer in the page header or in TPD entry for this page.
+ *
+ * We do need to clear the visibility map bit for this page if it is not
+ * cleared already.
+ */
+void
+zheap_insert(Relation relation, ZHeapTuple tup, CommandId cid,
+			 int options, BulkInsertState bistate, uint32 specToken)
+{
+	FullTransactionId fxid = InvalidFullTransactionId;
+	ZHeapTuple	zheaptup;
+	UnpackedUndoRecord undorecord;
+	Buffer		buffer;
+	Buffer		vmbuffer = InvalidBuffer;
+	bool		all_visible_cleared = false;
+	int			trans_slot_id = InvalidXactSlotId;
+	Page		page;
+	UndoRecPtr	urecptr = InvalidUndoRecPtr,
+				prev_urecptr = InvalidUndoRecPtr;
+	uint8		vm_status = 0;
+	bool		lock_reacquired;
+	bool		skip_undo;
+	ZHeapPrepareUndoInfo zh_undo_info;
+
+	/*
+	 * We can skip inserting undo records if the tuples are to be marked as
+	 * frozen.
+	 */
+	skip_undo = (options & ZHEAP_INSERT_FROZEN);
+
+	/* We don't need a transaction id if we are skipping undo */
+	if (!skip_undo)
+		fxid = GetTopFullTransactionId();
+
+	/*
+	 * Fill in tuple header fields and toast the tuple if necessary.
+	 *
+	 * Note: below this point, zheaptup is the data we actually intend to
+	 * store into the relation; tup is the caller's original untoasted data.
+	 */
+	zheaptup = zheap_prepare_insert(relation, tup, options, specToken);
+
+reacquire_buffer:
+
+	/*
+	 * Find buffer to insert this tuple into.  If the page is all visible,
+	 * this will also pin the requisite visibility map page.
+	 */
+	if (BufferIsValid(vmbuffer))
+	{
+		ReleaseBuffer(vmbuffer);
+		vmbuffer = InvalidBuffer;
+	}
+
+	buffer = RelationGetBufferForZTuple(relation, zheaptup->t_len,
+										InvalidBuffer, options, bistate,
+										&vmbuffer, NULL);
+	page = BufferGetPage(buffer);
+
+	if (!skip_undo)
+	{
+		/*
+		 * The transaction information of tuple needs to be set in transaction
+		 * slot, so needs to reserve the slot before proceeding with the
+		 * actual operation.  It will be costly to wait for getting the slot,
+		 * but we do that by releasing the buffer lock.
+		 *
+		 * We don't yet know the offset number of the inserting tuple so just
+		 * pass the 'max_offset_number + 1' so that if it need to get slot
+		 * from the TPD it can ensure that the TPD has sufficient map entries.
+		 */
+		trans_slot_id = PageReserveTransactionSlot(relation,
+												   buffer,
+												   PageGetMaxOffsetNumber(page) + 1,
+												   fxid,
+												   &prev_urecptr,
+												   &lock_reacquired,
+												   false,
+												   InvalidBuffer,
+												   NULL);
+		if (lock_reacquired)
+		{
+			UnlockReleaseBuffer(buffer);
+			goto reacquire_buffer;
+		}
+
+		if (trans_slot_id == InvalidXactSlotId)
+		{
+			UnlockReleaseBuffer(buffer);
+
+			pgstat_report_wait_start(PG_WAIT_PAGE_TRANS_SLOT);
+			pg_usleep(10000L);	/* 10 ms */
+			pgstat_report_wait_end();
+
+			goto reacquire_buffer;
+		}
+
+		/* transaction slot must be reserved before adding tuple to page */
+		Assert(trans_slot_id != InvalidXactSlotId);
+	}
+
+	if (options & ZHEAP_INSERT_SPECULATIVE)
+	{
+		/*
+		 * We can't skip writing undo speculative insertions as we have to
+		 * write the token in undo.
+		 */
+		Assert(!skip_undo);
+
+		/* Mark the tuple as speculatively inserted tuple. */
+		zheaptup->t_data->t_infomask |= ZHEAP_SPECULATIVE_INSERT;
+	}
+
+	/*
+	 * See heap_insert to know why checking conflicts is important before
+	 * actually inserting the tuple.
+	 */
+	CheckForSerializableConflictIn(relation, NULL, InvalidBuffer);
+
+	if (!skip_undo)
+	{
+		/* Prepare an undo record for this operation. */
+		zh_undo_info.reloid = relation->rd_id;
+		zh_undo_info.blkno = BufferGetBlockNumber(buffer);
+		zh_undo_info.offnum = InvalidOffsetNumber;
+		zh_undo_info.prev_urecptr = prev_urecptr;
+		zh_undo_info.fxid = fxid;
+		zh_undo_info.cid = cid;
+		zh_undo_info.undo_persistence = UndoPersistenceForRelation(relation);
+
+		urecptr = zheap_prepare_undoinsert(&zh_undo_info, specToken,
+										   (options & ZHEAP_INSERT_SPECULATIVE) ? true : false,
+										   &undorecord, NULL);
+	}
+
+	/*
+	 * Get the page visibility status from visibility map.  If the page is
+	 * all-visible, we need to clear it after inserting the tuple.  Note that,
+	 * for newly added pages (vm buffer will be invalid, see
+	 * RelationGetBufferForZTuple), vm status must be clear, so we don't need
+	 * to do anything for them.
+	 */
+	if (BufferIsValid(vmbuffer))
+		vm_status = visibilitymap_get_status(relation,
+											 BufferGetBlockNumber(buffer),
+											 &vmbuffer);
+
+	/*
+	 * Lock the TPD page before starting critical section.  We might need to
+	 * access it in ZPageAddItemExtended.  Note that if the transaction slot
+	 * belongs to TPD entry, then the TPD page must be locked during slot
+	 * reservation.
+	 *
+	 * XXX We can optimize this by avoid taking TPD page lock unless the page
+	 * has some unused item which requires us to fetch the transaction
+	 * information from TPD.
+	 */
+	if (trans_slot_id <= ZHEAP_PAGE_TRANS_SLOTS &&
+		ZHeapPageHasTPDSlot((PageHeader) page) &&
+		PageHasFreeLinePointers((PageHeader) page))
+		TPDPageLock(relation, buffer);
+
+	/* No ereport(ERROR) from here till changes are logged */
+	START_CRIT_SECTION();
+
+	if (!(options & ZHEAP_INSERT_FROZEN))
+		ZHeapTupleHeaderSetXactSlot(zheaptup->t_data, trans_slot_id);
+
+	RelationPutZHeapTuple(relation, buffer, zheaptup);
+
+	if ((vm_status & VISIBILITYMAP_ALL_VISIBLE) ||
+		(vm_status & VISIBILITYMAP_POTENTIAL_ALL_VISIBLE))
+	{
+		all_visible_cleared = true;
+		visibilitymap_clear(relation,
+							ItemPointerGetBlockNumber(&(zheaptup->t_self)),
+							vmbuffer, VISIBILITYMAP_VALID_BITS);
+	}
+
+	if (!skip_undo)
+	{
+		Assert(undorecord.uur_block == ItemPointerGetBlockNumber(&(zheaptup->t_self)));
+		undorecord.uur_offset = ItemPointerGetOffsetNumber(&(zheaptup->t_self));
+		InsertPreparedUndo(&zh_undo_info.context);
+		PageSetUNDO(undorecord, buffer, trans_slot_id, true, fxid,
+					urecptr, NULL, 0);
+	}
+
+	MarkBufferDirty(buffer);
+
+	/* XLOG stuff */
+	if (RelationNeedsWAL(relation))
+	{
+		ZHeapWALInfo ins_wal_info;
+
+		ins_wal_info.buffer = buffer;
+		ins_wal_info.ztuple = zheaptup;
+		ins_wal_info.urecptr = urecptr;
+		ins_wal_info.prev_urecptr = prev_urecptr;
+		ins_wal_info.new_trans_slot_id = trans_slot_id;
+		ins_wal_info.prior_trans_slot_id = InvalidXactSlotId;
+		ins_wal_info.all_visible_cleared = all_visible_cleared;
+		ins_wal_info.undorecord = NULL;
+		ins_wal_info.context = &zh_undo_info.context;
+
+		log_zheap_insert(&ins_wal_info, relation, options, skip_undo);
+	}
+
+	END_CRIT_SECTION();
+
+	UnlockReleaseBuffer(buffer);
+	if (vmbuffer != InvalidBuffer)
+		ReleaseBuffer(vmbuffer);
+	if (!skip_undo)
+	{
+		/* be tidy */
+		if (undorecord.uur_payload.len > 0)
+			pfree(undorecord.uur_payload.data);
+		FinishUndoRecordInsert(&zh_undo_info.context);
+	}
+	UnlockReleaseTPDBuffers();
+
+	/* Note: speculative insertions are counted too, even if aborted later */
+	pgstat_count_heap_insert(relation, 1);
+
+	/*
+	 * If zheaptup is a private copy, release it.  Don't forget to copy t_self
+	 * back to the caller's image, too.
+	 */
+	if (zheaptup != tup)
+	{
+		tup->t_self = zheaptup->t_self;
+
+		/*
+		 * Since in ZHeap we have speculative flag in the tuple header only,
+		 * copy the speculative flag to the new tuple if required.
+		 */
+		if (ZHeapTupleHeaderIsSpeculative(zheaptup->t_data))
+			tup->t_data->t_infomask |= ZHEAP_SPECULATIVE_INSERT;
+
+		zheap_freetuple(zheaptup);
+	}
+}
+
+/*
+ * simple_zheap_delete - delete a zheap tuple
+ *
+ * This routine may be used to delete a tuple when concurrent updates of
+ * the target tuple are not expected (for example, because we have a lock
+ * on the relation associated with the tuple).  Any failure is reported
+ * via ereport().
+ */
+void
+simple_zheap_delete(Relation relation, ItemPointer tid, Snapshot snapshot)
+{
+	TM_Result	result;
+	TM_FailureData tmfd;
+
+	result = zheap_delete(relation, tid,
+						  GetCurrentCommandId(true), InvalidSnapshot, snapshot,
+						  true, /* wait for commit */
+						  &tmfd, false /* changingPart */ );
+	switch (result)
+	{
+		case TM_SelfModified:
+			/* Tuple was already updated in current command? */
+			elog(ERROR, "tuple already updated by self");
+			break;
+
+		case TM_Ok:
+			/* done successfully */
+			break;
+
+		case TM_Updated:
+			elog(ERROR, "tuple concurrently updated");
+			break;
+
+		case TM_Deleted:
+			elog(ERROR, "tuple concurrently deleted");
+			break;
+
+		default:
+			elog(ERROR, "unrecognized zheap_delete status: %u", result);
+			break;
+	}
+}
+
+/*
+ * zheap_delete - delete a tuple
+ *
+ * The functionality related to heap is quite similar to heap_delete,
+ * additionaly this function inserts an undo record and updates the undo
+ * pointer in page header or in TPD entry for this page.
+ *
+ * We do need to clear the visibility map bit for this page if it is not
+ * cleared already.
+ */
+TM_Result
+zheap_delete(Relation relation, ItemPointer tid,
+			 CommandId cid, Snapshot crosscheck, Snapshot snapshot, bool wait,
+			 TM_FailureData *tmfd, bool changingPart)
+{
+	TM_Result	result;
+	FullTransactionId fxid = GetTopFullTransactionId();
+	TransactionId xid = XidFromFullTransactionId(fxid);
+	TransactionId oldestXidHavingUndo,
+				single_locker_xid;
+	SubTransactionId tup_subxid = InvalidSubTransactionId,
+				subxid = InvalidSubTransactionId;
+	ItemId		lp;
+	ZHeapTupleData zheaptup;
+	ZHeapPrepareUndoInfo zh_undo_info;
+	UnpackedUndoRecord undorecord;
+	Page		page;
+	BlockNumber blkno;
+	OffsetNumber offnum;
+	Buffer		buffer;
+	Buffer		vmbuffer = InvalidBuffer;
+	UndoRecPtr	urecptr,
+				prev_urecptr;
+	ItemPointerData ctid;
+	int			trans_slot_id,
+				new_trans_slot_id,
+				single_locker_trans_slot;
+	uint16		new_infomask,
+				temp_infomask;
+	bool		have_tuple_lock = false;
+	bool		in_place_updated_or_locked = false;
+	bool		all_visible_cleared = false;
+	bool		any_multi_locker_member_alive = false;
+	bool		lock_reacquired;
+	uint8		vm_status;
+	ZHeapTupleTransInfo zinfo;
+
+	Assert(ItemPointerIsValid(tid));
+
+	/*
+	 * Forbid this during a parallel operation, lest it allocate a combocid.
+	 * Other workers might need that combocid for visibility checks, and we
+	 * have no provision for broadcasting it to them.
+	 */
+	if (IsInParallelMode())
+		ereport(ERROR,
+				(errcode(ERRCODE_INVALID_TRANSACTION_STATE),
+				 errmsg("cannot delete tuples during a parallel operation")));
+
+	blkno = ItemPointerGetBlockNumber(tid);
+	buffer = ReadBuffer(relation, blkno);
+	page = BufferGetPage(buffer);
+
+	/*
+	 * Before locking the buffer, pin the visibility map page mainly to avoid
+	 * doing I/O after locking the buffer.
+	 */
+	visibilitymap_pin(relation, blkno, &vmbuffer);
+
+	LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+
+	offnum = ItemPointerGetOffsetNumber(tid);
+	lp = PageGetItemId(page, offnum);
+	Assert(ItemIdIsNormal(lp) || ItemIdIsDeleted(lp));
+
+check_tup_satisfies_update:
+	any_multi_locker_member_alive = true;
+	result = ZHeapTupleSatisfiesUpdate(relation, tid, &zheaptup, cid, buffer, &ctid,
+									   &zinfo, &tup_subxid, &single_locker_xid,
+									   &single_locker_trans_slot, false,
+									   snapshot, &in_place_updated_or_locked);
+
+	if (result == TM_Invisible)
+	{
+		UnlockReleaseBuffer(buffer);
+		ereport(ERROR,
+				(errcode(ERRCODE_OBJECT_NOT_IN_PREREQUISITE_STATE),
+				 errmsg("attempted to delete invisible tuple")));
+	}
+	else if ((result == TM_BeingModified ||
+			  ((result == TM_Ok) &&
+			   ZHeapTupleHasMultiLockers(zheaptup.t_data->t_infomask))) &&
+			 wait)
+	{
+		TransactionId xwait;
+		int			xwait_trans_slot;
+
+		if (TransactionIdIsValid(single_locker_xid))
+		{
+			xwait = single_locker_xid;
+			xwait_trans_slot = single_locker_trans_slot;
+		}
+		else
+		{
+			xwait = zinfo.xid;
+			xwait_trans_slot = zinfo.trans_slot;
+		}
+
+		if (!zheap_delete_wait_helper(relation, buffer, &zheaptup, fxid,
+									  xwait, xwait_trans_slot, tup_subxid,
+									  lp, zinfo.xid, &have_tuple_lock,
+									  &single_locker_xid,
+									  &any_multi_locker_member_alive, &result))
+			goto check_tup_satisfies_update;
+	}
+	else if (result == TM_Updated && zheaptup.t_data != NULL
+			 && ZHeapTupleHasMultiLockers(zheaptup.t_data->t_infomask))
+	{
+		/*
+		 * Get the transaction slot and undo record pointer if we are already
+		 * in a transaction.
+		 */
+		trans_slot_id = PageGetTransactionSlotId(relation, buffer, fxid,
+												 &prev_urecptr, false, false,
+												 NULL);
+
+		/*
+		 * If any subtransaction of the current top transaction already holds
+		 * a lock as strong as or stronger than what we're requesting, we
+		 * effectively hold the desired lock already.  We *must* succeed
+		 * without trying to take the tuple lock, else we will deadlock
+		 * against anyone wanting to acquire a stronger lock.
+		 */
+		if (trans_slot_id != InvalidXactSlotId &&
+			ZCurrentXactHasTupleLockMode(&zheaptup, prev_urecptr,
+										 LockTupleExclusive))
+			result = TM_Ok;
+	}
+
+	if (crosscheck != InvalidSnapshot && result == TM_Ok)
+	{
+		/* Perform additional check for transaction-snapshot mode RI updates */
+		if (!ZHeapTupleFetch(relation, buffer, offnum, crosscheck, NULL, NULL))
+			result = TM_Updated;
+	}
+
+	if (result != TM_Ok)
+	{
+		Assert(result == TM_SelfModified ||
+			   result == TM_Updated ||
+			   result == TM_Deleted ||
+			   result == TM_BeingModified);
+		Assert(ItemIdIsDeleted(lp) ||
+			   IsZHeapTupleModified(zheaptup.t_data->t_infomask));
+
+		/* If item id is deleted, tuple can't be marked as moved. */
+		if (!ItemIdIsDeleted(lp) &&
+			ZHeapTupleIsMoved(zheaptup.t_data->t_infomask))
+			ItemPointerSetMovedPartitions(&tmfd->ctid);
+		else
+			tmfd->ctid = ctid;
+		tmfd->xmax = zinfo.xid;
+		if (result == TM_SelfModified)
+			tmfd->cmax = zinfo.cid;
+		else
+			tmfd->cmax = InvalidCommandId;
+		UnlockReleaseBuffer(buffer);
+		tmfd->in_place_updated_or_locked = in_place_updated_or_locked;
+		if (have_tuple_lock)
+			UnlockTupleTuplock(relation, &(zheaptup.t_self), LockTupleExclusive);
+		if (vmbuffer != InvalidBuffer)
+			ReleaseBuffer(vmbuffer);
+		return result;
+	}
+
+	/*
+	 * Acquire subtransaction lock, if current transaction is a
+	 * subtransaction.
+	 */
+	if (IsSubTransaction())
+	{
+		subxid = GetCurrentSubTransactionId();
+		SubXactLockTableInsert(subxid);
+	}
+
+	/*
+	 * The transaction information of tuple needs to be set in transaction
+	 * slot, so needs to reserve the slot before proceeding with the actual
+	 * operation.  It will be costly to wait for getting the slot, but we do
+	 * that by releasing the buffer lock.
+	 */
+	trans_slot_id = PageReserveTransactionSlot(relation, buffer,
+											   PageGetMaxOffsetNumber(page),
+											   fxid, &prev_urecptr,
+											   &lock_reacquired, false, InvalidBuffer,
+											   NULL);
+	if (lock_reacquired)
+		goto check_tup_satisfies_update;
+
+	if (trans_slot_id == InvalidXactSlotId)
+	{
+		LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+
+		pgstat_report_wait_start(PG_WAIT_PAGE_TRANS_SLOT);
+		pg_usleep(10000L);		/* 10 ms */
+		pgstat_report_wait_end();
+
+		LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+		goto check_tup_satisfies_update;
+	}
+
+	/* transaction slot must be reserved before adding tuple to page */
+	Assert(trans_slot_id != InvalidXactSlotId);
+
+	/*
+	 * It's possible that tuple slot is now marked as frozen. Hence, we
+	 * refetch the tuple here.
+	 */
+	Assert(!ItemIdIsDeleted(lp));
+	zheaptup.t_data = (ZHeapTupleHeader) PageGetItem(page, lp);
+	zheaptup.t_len = ItemIdGetLength(lp);
+
+	/*
+	 * If the slot is marked as frozen, the latest modifier of the tuple must
+	 * be frozen.
+	 */
+	if (ZHeapTupleHeaderGetXactSlot((ZHeapTupleHeader) (zheaptup.t_data)) == ZHTUP_SLOT_FROZEN)
+	{
+		zinfo.trans_slot = ZHTUP_SLOT_FROZEN;
+		zinfo.xid = InvalidTransactionId;
+	}
+
+	temp_infomask = zheaptup.t_data->t_infomask;
+
+	/*
+	 * If all the members were lockers and are all gone, we can do away with
+	 * the MULTI_LOCKERS bit.
+	 */
+	if (ZHeapTupleHasMultiLockers(temp_infomask) &&
+		!any_multi_locker_member_alive)
+		temp_infomask &= ~ZHEAP_MULTI_LOCKERS;
+
+	/* Compute the new xid and infomask to store into the tuple. */
+	compute_new_xid_infomask(&zheaptup, buffer, zinfo.xid, zinfo.trans_slot,
+							 temp_infomask, xid, trans_slot_id,
+							 single_locker_xid, LockTupleExclusive, ForUpdate,
+							 &new_infomask, &new_trans_slot_id);
+
+	/*
+	 * There must not be any stronger locker than the current operation,
+	 * otherwise it would have waited for it to finish.
+	 */
+	Assert(new_trans_slot_id == trans_slot_id);
+
+	/*
+	 * If the last transaction that has updated the tuple is already too old,
+	 * then consider it as frozen which means it is all-visible.  This ensures
+	 * that we don't need to store epoch in the undo record to check if the
+	 * undo tuple belongs to previous epoch and hence all-visible.  See
+	 * comments atop of file zheapam_visibility.c.
+	 */
+	oldestXidHavingUndo = GetXidFromEpochXid(
+											 pg_atomic_read_u64(&ProcGlobal->oldestFullXidHavingUnappliedUndo));
+	if (TransactionIdPrecedes(zinfo.xid, oldestXidHavingUndo))
+		zinfo.xid = FrozenTransactionId;
+
+	CheckForSerializableConflictIn(relation, &(zheaptup.t_self), buffer);
+
+	/* Prepare an undo record for this operation. */
+	zh_undo_info.reloid = relation->rd_id;
+	zh_undo_info.blkno = blkno;
+	zh_undo_info.offnum = offnum;
+	zh_undo_info.prev_urecptr = prev_urecptr;
+	zh_undo_info.fxid = fxid;
+	zh_undo_info.cid = cid;
+	zh_undo_info.undo_persistence = UndoPersistenceForRelation(relation);
+	urecptr = zheap_prepare_undodelete(&zh_undo_info,
+									   &zheaptup,
+									   zinfo.xid,
+									   zinfo.trans_slot,
+									   subxid,
+									   &undorecord, NULL);
+
+	/* We must have a valid vmbuffer. */
+	Assert(BufferIsValid(vmbuffer));
+	vm_status = visibilitymap_get_status(relation,
+										 BufferGetBlockNumber(buffer), &vmbuffer);
+
+	START_CRIT_SECTION();
+
+	if ((vm_status & VISIBILITYMAP_ALL_VISIBLE) ||
+		(vm_status & VISIBILITYMAP_POTENTIAL_ALL_VISIBLE))
+	{
+		all_visible_cleared = true;
+		visibilitymap_clear(relation, BufferGetBlockNumber(buffer),
+							vmbuffer, VISIBILITYMAP_VALID_BITS);
+	}
+
+	InsertPreparedUndo(&zh_undo_info.context);
+	PageSetUNDO(undorecord, buffer, trans_slot_id, true, fxid,
+				urecptr, NULL, 0);
+
+	/*
+	 * If this transaction commits, the tuple will become DEAD sooner or
+	 * later.  If the transaction finally aborts, the subsequent page pruning
+	 * will be a no-op and the hint will be cleared.
+	 */
+	ZPageSetPrunable(page, xid);
+
+	ZHeapTupleHeaderSetXactSlot(zheaptup.t_data, new_trans_slot_id);
+	zheaptup.t_data->t_infomask &= ~ZHEAP_VIS_STATUS_MASK;
+	zheaptup.t_data->t_infomask |= ZHEAP_DELETED | new_infomask;
+
+	/* Signal that this is actually a move into another partition */
+	if (changingPart)
+		ZHeapTupleHeaderSetMovedPartitions(zheaptup.t_data);
+
+	MarkBufferDirty(buffer);
+
+	/* do xlog stuff */
+	if (RelationNeedsWAL(relation))
+	{
+		ZHeapWALInfo del_wal_info;
+
+		del_wal_info.buffer = buffer;
+		del_wal_info.ztuple = &zheaptup;
+		del_wal_info.urecptr = urecptr;
+		del_wal_info.prev_urecptr = prev_urecptr;
+		del_wal_info.new_trans_slot_id = trans_slot_id;
+		del_wal_info.prior_trans_slot_id = zinfo.trans_slot;
+		del_wal_info.all_visible_cleared = all_visible_cleared;
+		del_wal_info.undorecord = &undorecord;
+		del_wal_info.context = &zh_undo_info.context;
+		log_zheap_delete(&del_wal_info, changingPart, subxid, zinfo.xid);
+	}
+
+	END_CRIT_SECTION();
+
+	/* be tidy */
+	pfree(undorecord.uur_tuple.data);
+	if (undorecord.uur_payload.len > 0)
+		pfree(undorecord.uur_payload.data);
+
+	LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+
+	if (vmbuffer != InvalidBuffer)
+		ReleaseBuffer(vmbuffer);
+
+	FinishUndoRecordInsert(&zh_undo_info.context);
+
+	/*
+	 * If the tuple has toasted out-of-line attributes, we need to delete
+	 * those items too.  We have to do this before releasing the buffer
+	 * because we need to look at the contents of the tuple, but it's OK to
+	 * release the content lock on the buffer first.
+	 */
+	if (relation->rd_rel->relkind != RELKIND_RELATION &&
+		relation->rd_rel->relkind != RELKIND_MATVIEW)
+	{
+		/* toast table entries should never be recursively toasted */
+		Assert(!ZHeapTupleHasExternal(&zheaptup));
+	}
+	else if (ZHeapTupleHasExternal(&zheaptup))
+		ztoast_delete(relation, &zheaptup, false);
+
+	/* now we can release the buffer */
+	ReleaseBuffer(buffer);
+	UnlockReleaseTPDBuffers();
+
+	/*
+	 * Release the lmgr tuple lock, if we had it.
+	 */
+	if (have_tuple_lock)
+		UnlockTupleTuplock(relation, &(zheaptup.t_self), LockTupleExclusive);
+
+	pgstat_count_heap_delete(relation);
+
+	return TM_Ok;
+}
+
+/*
+ * zheap_delete_wait_helper
+ *
+ * This is a helper function that encapsulates some of the logic that
+ * zheap_delete needs to wait for concurrent transactions.
+ *
+ * XXX. Can we name this function better?  What exactly is the remit of this
+ * function vs. other parts of zheap_delete that also wait for stuff?
+ *
+ * XXX. The abstraction that this function provides is quite leaky -- it
+ * should probably take fewer parameters.
+ *
+ * XXX. RefetchAndCheckTupleStatus frobs zheaptup. Yuck!
+ *
+ * XXX. zheap_update_wait_helper is very similar to this.
+ */
+static bool
+zheap_delete_wait_helper(Relation relation, Buffer buffer, ZHeapTuple zheaptup,
+						 FullTransactionId fxid, TransactionId xwait,
+						 int xwait_trans_slot, SubTransactionId xwait_subxid,
+						 ItemId lp,
+						 TransactionId tup_xid, bool *have_tuple_lock,
+						 TransactionId *single_locker_xid,
+						 bool *any_multi_locker_member_alive,
+						 TM_Result *result)
+{
+	List	   *mlmembers = NIL;
+	uint16		infomask;
+	bool		can_continue = false;
+	bool		lock_reacquired = false;
+
+	infomask = zheaptup->t_data->t_infomask;
+
+	/*
+	 * Sleep until concurrent transaction ends -- except when there's a single
+	 * locker and it's our own transaction.  Note we don't care which lock
+	 * mode the locker has, because we need the strongest one.
+	 *
+	 * Before sleeping, we need to acquire tuple lock to establish our
+	 * priority for the tuple (see zheap_lock_tuple).  LockTuple will release
+	 * us when we are next-in-line for the tuple.
+	 *
+	 * If we are forced to "start over" below, we keep the tuple lock; this
+	 * arranges that we stay at the head of the line while rechecking tuple
+	 * state.
+	 */
+	if (ZHeapTupleHasMultiLockers(infomask))
+	{
+		LockTupleMode old_lock_mode;
+		TransactionId update_xact;
+		bool		upd_xact_aborted = false;
+		int			trans_slot_id;
+		UndoRecPtr	prev_urecptr;
+
+		/*
+		 * In ZHeapTupleSatisfiesUpdate, it's not possible to know if current
+		 * transaction has already locked the tuple for update because of
+		 * multilocker flag. In that case, we've to check whether the current
+		 * transaction has already locked the tuple for update.
+		 */
+
+		/*
+		 * Get the transaction slot and undo record pointer if we are already
+		 * in a transaction.
+		 */
+		trans_slot_id = PageGetTransactionSlotId(relation, buffer, fxid,
+												 &prev_urecptr, false, false,
+												 NULL);
+
+		/*
+		 * If any subtransaction of the current top transaction already holds
+		 * a lock as strong as or stronger than what we're requesting, we
+		 * effectively hold the desired lock already.  We *must* succeed
+		 * without trying to take the tuple lock, else we will deadlock
+		 * against anyone wanting to acquire a stronger lock.
+		 */
+		if (trans_slot_id != InvalidXactSlotId &&
+			ZCurrentXactHasTupleLockMode(zheaptup, prev_urecptr,
+										 LockTupleExclusive))
+		{
+			*result = TM_Ok;
+			return true;
+		}
+
+		old_lock_mode = get_old_lock_mode(infomask);
+
+		/*
+		 * For aborted updates, we must allow to reverify the tuple in case
+		 * it's values got changed.  See the similar handling in zheap_update.
+		 */
+		if (!ZHEAP_XID_IS_LOCKED_ONLY(zheaptup->t_data->t_infomask))
+			update_xact = tup_xid;
+		else
+			update_xact = InvalidTransactionId;
+
+		if (DoLockModesConflict(HWLOCKMODE_from_locktupmode(old_lock_mode),
+								HWLOCKMODE_from_locktupmode(LockTupleExclusive)))
+		{
+			/*
+			 * There is a potential conflict.  It is quite possible that by
+			 * this time the locker has already been committed. So we need to
+			 * check for conflict with all the possible lockers and wait for
+			 * each of them after releasing a buffer lock and acquiring a lock
+			 * on a tuple.
+			 */
+			LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+			mlmembers = ZGetMultiLockMembers(relation, zheaptup, buffer,
+											 true);
+
+			/*
+			 * If there is no multi-lock members apart from the current
+			 * transaction then no need for tuplock, just go ahead.
+			 */
+			if (mlmembers != NIL)
+			{
+				heap_acquire_tuplock(relation, &(zheaptup->t_self), LockTupleExclusive,
+									 LockWaitBlock, have_tuple_lock);
+				ZMultiLockMembersWait(relation, mlmembers, zheaptup, buffer,
+									  update_xact, LockTupleExclusive, false,
+									  XLTW_Delete, NULL, &upd_xact_aborted);
+			}
+			LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+
+			/*
+			 * If the aborted xact is for update, then we need to reverify the
+			 * tuple.
+			 */
+			if (upd_xact_aborted)
+				return false;
+			lock_reacquired = true;
+
+			/*
+			 * There was no UPDATE in the Multilockers. No
+			 * TransactionIdIsInProgress() call needed here, since we called
+			 * ZMultiLockMembersWait() above.
+			 */
+			if (!TransactionIdIsValid(update_xact))
+				can_continue = true;
+		}
+	}
+	else if (!TransactionIdIsCurrentTransactionId(xwait))
+	{
+		/*
+		 * Wait for regular transaction to end; but first, acquire tuple lock.
+		 */
+		LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+		heap_acquire_tuplock(relation, &(zheaptup->t_self), LockTupleExclusive,
+							 LockWaitBlock, have_tuple_lock);
+		if (xwait_subxid != InvalidSubTransactionId)
+			SubXactLockTableWait(xwait, xwait_subxid, relation,
+								 &zheaptup->t_self, XLTW_Delete);
+		else
+			XactLockTableWait(xwait, relation, &zheaptup->t_self,
+							  XLTW_Delete);
+		LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+		lock_reacquired = true;
+	}
+
+	if (lock_reacquired)
+	{
+		bool		pending_actions_applied = false;
+
+		/*
+		 * By the time, we require the lock on buffer, some other xact could
+		 * have updated this tuple.  We need take care of the cases when page
+		 * is pruned after we release the buffer lock.  If TID is already
+		 * delete marked due to pruning, then tell caller to loop and update
+		 * the new tuple.
+		 *
+		 * We also need to ensure that no new lockers have been added in the
+		 * meantime, if there is any new locker, then start again.
+		 */
+		if (ItemIdIsDeleted(lp))
+			return false;
+
+		if (ZHeapTupleHasMultiLockers(infomask))
+		{
+			List	   *new_mlmembers;
+
+			new_mlmembers = ZGetMultiLockMembers(relation, zheaptup,
+												 buffer, false);
+
+			/*
+			 * Ensure, no new lockers have been added, if so, then start
+			 * again.
+			 */
+			if (!ZMultiLockMembersSame(mlmembers, new_mlmembers))
+			{
+				list_free_deep(mlmembers);
+				list_free_deep(new_mlmembers);
+				return false;
+			}
+
+			*any_multi_locker_member_alive =
+				ZIsAnyMultiLockMemberRunning(relation, xwait_trans_slot,
+											 new_mlmembers, zheaptup,
+											 buffer, &pending_actions_applied);
+			list_free_deep(mlmembers);
+			list_free_deep(new_mlmembers);
+		}
+
+		/*
+		 * xwait is done, but if xwait had just locked the tuple then some
+		 * other xact could update/lock this tuple before we get to this
+		 * point.  Check for xid change, and start over if so.  We need to do
+		 * some special handling for lockers because their xid is never stored
+		 * on the tuples.  If there was a single locker on the tuple and that
+		 * locker is gone and some new locker has locked the tuple, we won't
+		 * be able to identify that by infomask/xid on the tuple, rather we
+		 * need to fetch the locker xid.
+		 */
+		if (pending_actions_applied || !RefetchAndCheckTupleStatus(relation,
+																   buffer, infomask,
+																   tup_xid,
+																   single_locker_xid, NULL, zheaptup))
+			return false;
+
+		/* Aborts of multi-lockers are already dealt above. */
+		if (!ZHeapTupleHasMultiLockers(infomask))
+		{
+			bool		has_update = false;
+			bool		isCommitted;
+
+			if (!ZHEAP_XID_IS_LOCKED_ONLY(zheaptup->t_data->t_infomask))
+				has_update = true;
+
+			isCommitted = TransactionIdDidCommit(xwait);
+
+			/*
+			 * For aborted transaction, if the undo actions are not applied
+			 * yet, then apply them before modifying the page.
+			 */
+			if (!isCommitted)
+				zheap_exec_pending_rollback(relation,
+											buffer,
+											xwait_trans_slot,
+											xwait,
+											NULL);
+
+			if (!isCommitted)
+			{
+				/*
+				 * For aborted updates, we must allow to reverify the tuple in
+				 * case it's values got changed.
+				 */
+				if (has_update)
+					return false;
+
+				/*
+				 * While executing the undo action we have released the buffer
+				 * lock.  So if the tuple infomask got changed while applying
+				 * the undo action then we must reverify the tuple.
+				 */
+				if (!RefetchAndCheckTupleStatus(relation, buffer, infomask,
+												tup_xid,
+												single_locker_xid,
+												NULL, zheaptup))
+					return false;
+			}
+
+			if (!has_update)
+				can_continue = true;
+		}
+	}
+	else
+	{
+		/*
+		 * We can proceed with the delete, when there's a single locker and
+		 * it's our own transaction.
+		 */
+		if (ZHEAP_XID_IS_LOCKED_ONLY(zheaptup->t_data->t_infomask))
+			can_continue = true;
+	}
+
+	/*
+	 * We may overwrite if previous xid is aborted or committed, but only
+	 * locked the tuple without updating it. ZBORKED: This, and many other
+	 * places, needs to return TM_Deleted if appropriate
+	 */
+	if (*result != TM_Ok)
+		*result = can_continue ? TM_Ok : TM_Updated;
+	return true;
+}
+
+/*
+ * zheap_update - update a tuple
+ *
+ * This function either updates the tuple in-place or it deletes the old
+ * tuple and new tuple for non-in-place updates.  Additionally this function
+ * inserts an undo record and updates the undo pointer in page header or in
+ * TPD entry for this page.
+ *
+ * We do need to clear the visibility map bit for this page if it is not
+ * cleared already.
+ *
+ * For input and output values, see heap_update.
+ */
+TM_Result
+zheap_update(Relation relation, ItemPointer otid, ZHeapTuple newtup,
+			 CommandId cid, Snapshot crosscheck, Snapshot snapshot, bool wait,
+			 TM_FailureData *tmfd, LockTupleMode *lockmode)
+{
+	TM_Result	result;
+	FullTransactionId fxid = GetTopFullTransactionId();
+	TransactionId xid = XidFromFullTransactionId(fxid);
+	TransactionId save_tup_xid,
+				oldestXidHavingUndo,
+				single_locker_xid;
+	SubTransactionId tup_subxid = InvalidSubTransactionId;
+	Bitmapset  *inplace_upd_attrs = NULL;
+	Bitmapset  *key_attrs = NULL;
+	Bitmapset  *interesting_attrs = NULL;
+	bool		computed_modified_attrs = false;
+	Bitmapset  *modified_attrs = NULL;
+	ItemId		lp;
+	ZHeapTupleData oldtup;
+	ZHeapTuple	zheaptup;
+	UndoRecPtr	urecptr,
+				prev_urecptr,
+				new_prev_urecptr;
+	UndoRecPtr	new_urecptr = InvalidUndoRecPtr;
+	UnpackedUndoRecord undorecord,
+				new_undorecord;
+	Page		page;
+	BlockNumber block;
+	ItemPointerData ctid;
+	Buffer		buffer,
+				newbuf,
+				vmbuffer = InvalidBuffer,
+				vmbuffer_new = InvalidBuffer;
+	Size		newtupsize,
+				oldtupsize,
+				pagefree;
+	int			oldtup_new_trans_slot,
+				newtup_trans_slot,
+				result_trans_slot_id,
+				single_locker_trans_slot;
+	uint16		old_infomask;
+	uint16		new_infomask,
+				temp_infomask;
+	uint16		infomask_old_tuple = 0;
+	uint16		infomask_new_tuple = 0;
+	OffsetNumber old_offnum,
+				max_offset;
+	bool		all_visible_cleared = false;
+	bool		new_all_visible_cleared = false;
+	bool		have_tuple_lock = false;
+	bool		is_index_updated = false;
+	bool		use_inplace_update;
+	bool		in_place_updated_or_locked = false;
+	bool		key_intact = false;
+	bool		checked_lockers = false;
+	bool		locker_remains = false;
+	bool		any_multi_locker_member_alive = false;
+	bool		lock_reacquired;
+	bool		need_toast;
+	bool		hasSubXactLock = false;
+	uint8		vm_status;
+	uint8		vm_status_new = 0;
+	bool		slot_reused_or_TPD_slot = false;
+	ZHeapTupleTransInfo zinfo;
+	ZHeapPrepareUndoInfo gen_undo_info;
+	ZHeapPrepareUpdateUndoInfo zh_up_undo_info;
+
+	Assert(ItemPointerIsValid(otid));
+
+	/*
+	 * Forbid this during a parallel operation, lest it allocate a combocid.
+	 * Other workers might need that combocid for visibility checks, and we
+	 * have no provision for broadcasting it to them.
+	 */
+	if (IsInParallelMode())
+		ereport(ERROR,
+				(errcode(ERRCODE_INVALID_TRANSACTION_STATE),
+				 errmsg("cannot update tuples during a parallel operation")));
+
+	/*
+	 * Fetch the list of attributes to be checked for various operations.
+	 *
+	 * For in-place update considerations, this is wasted effort if we fail to
+	 * update or have to put the new tuple on a different page.  But we must
+	 * compute the list before obtaining buffer lock --- in the worst case, if
+	 * we are doing an update on one of the relevant system catalogs, we could
+	 * deadlock if we try to fetch the list later.  Note, that as of now
+	 * system catalogs are always stored in heap, so we might not hit the
+	 * deadlock case, but it can be supported in future.  In any case, the
+	 * relcache caches the data so this is usually pretty cheap.
+	 *
+	 * Note that we get a copy here, so we need not worry about relcache flush
+	 * happening midway through.
+	 */
+	inplace_upd_attrs = RelationGetIndexAttrBitmap(relation, INDEX_ATTR_BITMAP_ALL);
+	key_attrs = RelationGetIndexAttrBitmap(relation, INDEX_ATTR_BITMAP_KEY);
+
+	block = ItemPointerGetBlockNumber(otid);
+	buffer = ReadBuffer(relation, block);
+	page = BufferGetPage(buffer);
+
+	interesting_attrs = NULL;
+	interesting_attrs = bms_add_members(interesting_attrs, inplace_upd_attrs);
+	interesting_attrs = bms_add_members(interesting_attrs, key_attrs);
+
+	/*
+	 * Before locking the buffer, pin the visibility map page mainly to avoid
+	 * doing I/O after locking the buffer.
+	 */
+	visibilitymap_pin(relation, block, &vmbuffer);
+
+	LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+
+	old_offnum = ItemPointerGetOffsetNumber(otid);
+	lp = PageGetItemId(page, old_offnum);
+	Assert(ItemIdIsNormal(lp) || ItemIdIsDeleted(lp));
+
+check_tup_satisfies_update:
+	checked_lockers = false;
+	locker_remains = false;
+	any_multi_locker_member_alive = true;
+	result = ZHeapTupleSatisfiesUpdate(relation, otid, &oldtup, cid, buffer,
+									   &ctid, &zinfo, &tup_subxid,
+									   &single_locker_xid,
+									   &single_locker_trans_slot, false,
+									   snapshot, &in_place_updated_or_locked);
+	/* Determine columns modified by the update, if not yet done. */
+	if (!computed_modified_attrs && oldtup.t_data != NULL)
+	{
+		computed_modified_attrs = true;
+		modified_attrs =
+			ZHeapDetermineModifiedColumns(relation, interesting_attrs,
+										  &oldtup, newtup);
+
+		/*
+		 * Similar to heap, if we're not updating any "key" column, we can
+		 * grab weaker lock type.  See heap_update.
+		 */
+		key_intact = !bms_overlap(modified_attrs, key_attrs);
+		*lockmode = key_intact ? LockTupleNoKeyExclusive : LockTupleExclusive;
+	}
+
+	if (result == TM_Invisible)
+	{
+		UnlockReleaseBuffer(buffer);
+		ereport(ERROR,
+				(errcode(ERRCODE_OBJECT_NOT_IN_PREREQUISITE_STATE),
+				 errmsg("attempted to update invisible tuple")));
+	}
+	else if ((result == TM_BeingModified ||
+			  ((result == TM_Ok) &&
+			   ZHeapTupleHasMultiLockers(oldtup.t_data->t_infomask))) &&
+			 wait)
+	{
+		TransactionId xwait;
+		int			xwait_trans_slot;
+
+		if (TransactionIdIsValid(single_locker_xid))
+		{
+			xwait = single_locker_xid;
+			xwait_trans_slot = single_locker_trans_slot;
+		}
+		else
+		{
+			xwait = zinfo.xid;
+			xwait_trans_slot = zinfo.trans_slot;
+		}
+
+		if (!zheap_update_wait_helper(relation, buffer, &oldtup, fxid,
+									  xwait, xwait_trans_slot, tup_subxid,
+									  *lockmode, key_intact, lp, zinfo.xid,
+									  &have_tuple_lock, &single_locker_xid,
+									  &any_multi_locker_member_alive,
+									  &checked_lockers, &locker_remains,
+									  &result))
+			goto check_tup_satisfies_update;
+	}
+	else if (result == TM_Ok)
+	{
+		/*
+		 * There is no active locker on the tuple, so we avoid grabbing the
+		 * lock on new tuple.
+		 */
+		checked_lockers = true;
+		locker_remains = false;
+	}
+	else if (result == TM_Updated && oldtup.t_data != NULL &&
+			 ZHeapTupleHasMultiLockers(oldtup.t_data->t_infomask))
+	{
+		/*
+		 * If a tuple is updated and is visible to our snapshot, we allow to
+		 * update it;  Else, we return TM_Updated and visit EvalPlanQual path
+		 * to check whether the quals still match.  In that path, we also lock
+		 * the tuple so that nobody can update it before us.
+		 *
+		 * In ZHeapTupleSatisfiesUpdate, it's not possible to know if current
+		 * transaction has already locked the tuple for update because of
+		 * multilocker flag. In that case, we've to check whether the current
+		 * transaction has already locked the tuple for update.
+		 */
+
+		/*
+		 * Get the transaction slot and undo record pointer if we are already
+		 * in a transaction.
+		 */
+		oldtup_new_trans_slot = PageGetTransactionSlotId(relation, buffer, fxid,
+														 &prev_urecptr, false, false,
+														 NULL);
+
+		/*
+		 * If any subtransaction of the current top transaction already holds
+		 * a lock as strong as or stronger than what we're requesting, we
+		 * effectively hold the desired lock already.  We *must* succeed
+		 * without trying to take the tuple lock, else we will deadlock
+		 * against anyone wanting to acquire a stronger lock.
+		 */
+		if (oldtup_new_trans_slot != InvalidXactSlotId &&
+			ZCurrentXactHasTupleLockMode(&oldtup, prev_urecptr,
+										 *lockmode))
+		{
+			result = TM_Ok;
+			checked_lockers = true;
+			locker_remains = false;
+		}
+	}
+
+	if (crosscheck != InvalidSnapshot && result == TM_Ok)
+	{
+		/* Perform additional check for transaction-snapshot mode RI updates */
+		if (!ZHeapTupleFetch(relation, buffer, old_offnum, crosscheck, NULL,
+							 NULL))
+			result = TM_Updated;
+	}
+
+	if (result != TM_Ok)
+	{
+		Assert(result == TM_SelfModified ||
+			   result == TM_Updated ||
+			   result == TM_Deleted ||
+			   result == TM_BeingModified);
+		Assert(ItemIdIsDeleted(lp) ||
+			   IsZHeapTupleModified(oldtup.t_data->t_infomask));
+
+		/* If item id is deleted, tuple can't be marked as moved. */
+		if (!ItemIdIsDeleted(lp) &&
+			ZHeapTupleIsMoved(oldtup.t_data->t_infomask))
+			ItemPointerSetMovedPartitions(&tmfd->ctid);
+		else
+			tmfd->ctid = ctid;
+		tmfd->xmax = zinfo.xid;
+		if (result == TM_SelfModified)
+			tmfd->cmax = zinfo.cid;
+		else
+			tmfd->cmax = InvalidCommandId;
+		UnlockReleaseBuffer(buffer);
+		tmfd->in_place_updated_or_locked = in_place_updated_or_locked;
+		if (have_tuple_lock)
+			UnlockTupleTuplock(relation, &(oldtup.t_self), *lockmode);
+		if (vmbuffer != InvalidBuffer)
+			ReleaseBuffer(vmbuffer);
+		bms_free(inplace_upd_attrs);
+		bms_free(key_attrs);
+		return result;
+	}
+
+	/* the new tuple is ready, except for this: */
+	newtup->t_tableOid = RelationGetRelid(relation);
+
+	is_index_updated = bms_overlap(modified_attrs, inplace_upd_attrs);
+
+	if (relation->rd_rel->relkind != RELKIND_RELATION &&
+		relation->rd_rel->relkind != RELKIND_MATVIEW)
+	{
+		/* toast table entries should never be recursively toasted */
+		Assert(!ZHeapTupleHasExternal(&oldtup));
+		Assert(!ZHeapTupleHasExternal(newtup));
+		need_toast = false;
+	}
+	else
+		need_toast = (newtup->t_len >= TOAST_TUPLE_THRESHOLD ||
+					  ZHeapTupleHasExternal(&oldtup) ||
+					  ZHeapTupleHasExternal(newtup));
+
+	oldtupsize = SHORTALIGN(oldtup.t_len);
+	newtupsize = SHORTALIGN(newtup->t_len);
+
+	/*
+	 * An in-place update is only possible if there are no index column
+	 * updates and no attribute that have been moved to an external TOAST
+	 * table.  If the new tuple is no larger than the old one, that's enough;
+	 * otherwise, we also need sufficient free space to be available in the
+	 * page.
+	 */
+	if (is_index_updated || need_toast)
+		use_inplace_update = false;
+	else if (newtupsize <= oldtupsize)
+		use_inplace_update = true;
+	else
+	{
+		/* Pass delta space required to accommodate the new tuple. */
+		use_inplace_update =
+			zheap_page_prune_opt(relation, buffer, old_offnum,
+								 newtupsize - oldtupsize);
+
+		/* The page might have been modified, so refresh t_data */
+		oldtup.t_data = (ZHeapTupleHeader) PageGetItem(page, lp);
+	}
+
+	/*
+	 * Acquire subtransaction lock, if current transaction is a
+	 * subtransaction.
+	 */
+	if (IsSubTransaction())
+	{
+		SubXactLockTableInsert(GetCurrentSubTransactionId());
+		hasSubXactLock = true;
+	}
+
+	max_offset = PageGetMaxOffsetNumber(BufferGetPage(buffer));
+	pagefree = PageGetZHeapFreeSpace(page);
+
+	/*
+	 * In case of the non in-place update we also need to reserve a map for
+	 * the new tuple.
+	 */
+	if (!use_inplace_update)
+		max_offset += 1;
+
+	/*
+	 * The transaction information of tuple needs to be set in transaction
+	 * slot, so needs to reserve the slot before proceeding with the actual
+	 * operation.  It will be costly to wait for getting the slot, but we do
+	 * that by releasing the buffer lock.
+	 */
+	oldtup_new_trans_slot = PageReserveTransactionSlot(relation, buffer, max_offset,
+													   fxid, &prev_urecptr,
+													   &lock_reacquired, false, InvalidBuffer,
+													   &slot_reused_or_TPD_slot);
+	if (lock_reacquired)
+		goto check_tup_satisfies_update;
+
+	if (oldtup_new_trans_slot == InvalidXactSlotId)
+	{
+		LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+
+		pgstat_report_wait_start(PG_WAIT_PAGE_TRANS_SLOT);
+		pg_usleep(10000L);		/* 10 ms */
+		pgstat_report_wait_end();
+
+		LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+
+		goto check_tup_satisfies_update;
+	}
+
+	/* transaction slot must be reserved before adding tuple to page */
+	Assert(oldtup_new_trans_slot != InvalidXactSlotId);
+
+	/*
+	 * It's possible that tuple slot is now marked as frozen. Hence, we
+	 * refetch the tuple here.
+	 */
+	Assert(!ItemIdIsDeleted(lp));
+	oldtup.t_data = (ZHeapTupleHeader) PageGetItem(page, lp);
+	oldtup.t_len = ItemIdGetLength(lp);
+
+	/*
+	 * Using a transaction slot of transaction that is still not all-visible
+	 * will lead to undo access during tuple visibility checks and that sucks
+	 * the performance.  To avoid accessing undo, we perform non-inplace
+	 * updates so as to distribute the tuple across pages so that we don't
+	 * face scarcity of transaction slots on the page.  However, we must have
+	 * a hard limit for this optimization, else the number of blocks will
+	 * increase without any bound.
+	 *
+	 * Note that the similar optimization applies when we use TPD slots as
+	 * that will also lead to another hop during visibility checks.
+	 */
+	if (slot_reused_or_TPD_slot)
+	{
+		BlockNumber nblocks = RelationGetNumberOfBlocks(relation);
+
+		if (nblocks <= NUM_BLOCKS_FOR_NON_INPLACE_UPDATES)
+			use_inplace_update = false;
+		else
+			slot_reused_or_TPD_slot = false;
+	}
+
+	/*
+	 * If the slot is marked as frozen, the latest modifier of the tuple must
+	 * be frozen.
+	 */
+	if (ZHeapTupleHeaderGetXactSlot((ZHeapTupleHeader) (oldtup.t_data)) == ZHTUP_SLOT_FROZEN)
+	{
+		zinfo.trans_slot = ZHTUP_SLOT_FROZEN;
+		zinfo.xid = InvalidTransactionId;
+	}
+
+	/*
+	 * Save the xid that has updated the tuple to compute infomask for tuple.
+	 */
+	save_tup_xid = zinfo.xid;
+
+	/*
+	 * If the last transaction that has updated the tuple is already too old,
+	 * then consider it as frozen which means it is all-visible.  This ensures
+	 * that we don't need to store epoch in the undo record to check if the
+	 * undo tuple belongs to previous epoch and hence all-visible.  See
+	 * comments atop of file zheapam_visibility.c.
+	 */
+	oldestXidHavingUndo = GetXidFromEpochXid(
+											 pg_atomic_read_u64(&ProcGlobal->oldestFullXidHavingUnappliedUndo));
+	if (TransactionIdPrecedes(zinfo.xid, oldestXidHavingUndo))
+		zinfo.xid = FrozenTransactionId;
+
+	/*
+	 * updated tuple doesn't fit on current page or the toaster needs to be
+	 * activated or transaction slot has been reused.  To prevent concurrent
+	 * sessions from updating the tuple, we have to temporarily mark it
+	 * locked, while we release the page lock.
+	 */
+	Assert(!slot_reused_or_TPD_slot || !use_inplace_update);
+	if (slot_reused_or_TPD_slot ||
+		(!use_inplace_update && newtupsize > pagefree) ||
+		need_toast)
+	{
+		UndoRecPtr	latest_urecptr;
+		BlockNumber oldblk,
+					newblk;
+		ZHeapPrepareUndoInfo zh_undo_info;
+
+		/* Prepare an undo record for this operation. */
+		zh_undo_info.reloid = relation->rd_id;
+		zh_undo_info.blkno = BufferGetBlockNumber(buffer);
+		zh_undo_info.offnum = ItemPointerGetOffsetNumber(&(oldtup.t_self));
+		zh_undo_info.prev_urecptr = prev_urecptr;
+		zh_undo_info.fxid = fxid;
+		zh_undo_info.cid = cid;
+		zh_undo_info.undo_persistence = UndoPersistenceForRelation(relation);
+
+		latest_urecptr = zheap_lock_tuple_guts(buffer, &oldtup, &zinfo,
+											   single_locker_xid, fxid, oldtup_new_trans_slot,
+											   *lockmode, LockForUpdate, hasSubXactLock,
+											   !any_multi_locker_member_alive,
+											   RelationNeedsWAL(relation),
+											   &zh_undo_info, &result_trans_slot_id);
+
+		/* Set prev_urecptr to the latest undo record in the slot. */
+		prev_urecptr = latest_urecptr;
+
+		LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+
+		/*
+		 * Let the toaster do its thing, if needed.
+		 *
+		 * Note: below this point, zheaptup is the data we actually intend to
+		 * store into the relation; newtup is the caller's original untoasted
+		 * data.
+		 */
+		if (need_toast)
+		{
+			zheaptup = ztoast_insert_or_update(relation, newtup, &oldtup, 0,
+											   0);
+			newtupsize = SHORTALIGN(zheaptup->t_len);	/* short aligned */
+		}
+		else
+			zheaptup = newtup;
+reacquire_buffer:
+
+		/*
+		 * Get a new page for inserting tuple.  We will need to acquire buffer
+		 * locks on both old and new pages.  See heap_update.
+		 */
+		if (BufferIsValid(vmbuffer_new))
+		{
+			ReleaseBuffer(vmbuffer_new);
+			vmbuffer_new = InvalidBuffer;
+		}
+
+		/*
+		 * If we have reused the transaction slot, we must use new page to
+		 * perform non-inplace update in a separate page so as to reduce
+		 * contention on transaction slots.
+		 */
+		if (slot_reused_or_TPD_slot || newtupsize > pagefree)
+		{
+			Assert(!use_inplace_update);
+			newbuf = RelationGetBufferForZTuple(relation, zheaptup->t_len,
+												buffer, 0, NULL,
+												&vmbuffer_new, &vmbuffer);
+		}
+		else
+		{
+			/* Re-acquire the lock on the old tuple's page. */
+			LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+			/* Re-check using the up-to-date free space */
+			pagefree = PageGetZHeapFreeSpace(page);
+			if (newtupsize > pagefree)
+			{
+				/*
+				 * Rats, it doesn't fit anymore.  We must now unlock and
+				 * relock to avoid deadlock.  Fortunately, this path should
+				 * seldom be taken.
+				 */
+				LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+				newbuf = RelationGetBufferForZTuple(relation, zheaptup->t_len,
+													buffer, 0, NULL,
+													&vmbuffer_new, &vmbuffer);
+			}
+			else
+			{
+				/* OK, it fits here, so we're done. */
+				newbuf = buffer;
+			}
+		}
+
+		max_offset = PageGetMaxOffsetNumber(BufferGetPage(newbuf));
+		oldblk = BufferGetBlockNumber(buffer);
+		newblk = BufferGetBlockNumber(newbuf);
+
+		/*
+		 * If we have got the new block than reserve the slot in same order in
+		 * which buffers are locked (ascending).
+		 */
+		if (oldblk == newblk)
+		{
+			newtup_trans_slot = PageReserveTransactionSlot(relation,
+														   newbuf,
+														   max_offset + 1,
+														   fxid,
+														   &new_prev_urecptr,
+														   &lock_reacquired,
+														   false,
+														   true,
+														   NULL);
+
+			/*
+			 * We must get a valid slot and wouldn't have reacquired the
+			 * buffer lock as we already have a reserved slot.
+			 */
+			Assert(!lock_reacquired);
+			Assert(newtup_trans_slot != InvalidXactSlotId);
+
+			/*
+			 * We should get the same slot what we reserved previously because
+			 * our transaction information should already be there.  But,
+			 * there is possibility that our slot might have moved to the TPD
+			 * in such case we should get previous slot_no + 1.
+			 */
+			Assert((newtup_trans_slot == oldtup_new_trans_slot) ||
+				   (ZHeapPageHasTPDSlot((PageHeader) page) &&
+					newtup_trans_slot == oldtup_new_trans_slot + 1));
+
+			oldtup_new_trans_slot = newtup_trans_slot;
+		}
+		else
+			MultiPageReserveTransSlot(relation, buffer, newbuf,
+									  old_offnum, max_offset, fxid,
+									  &prev_urecptr, &new_prev_urecptr,
+									  &oldtup_new_trans_slot, &newtup_trans_slot,
+									  &lock_reacquired);
+
+		if (lock_reacquired || (newtup_trans_slot == InvalidXactSlotId))
+		{
+			/*
+			 * If non in-place update is happening on two different buffers,
+			 * then release the new buffer, and release the lock on old
+			 * buffer. Else, only release the lock on old buffer.
+			 */
+			if (buffer != newbuf)
+			{
+				/*
+				 * If we have reacquired the lock while reserving a slot, then
+				 * we would have already released lock on the old buffer.  See
+				 * other_buf handling in PageFreezeTransSlots.
+				 */
+				if (!lock_reacquired)
+					LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+				else
+				{
+					BufferDesc *buf_hdr PG_USED_FOR_ASSERTS_ONLY;
+
+					/*
+					 * Old buffer should be valid and should not locked
+					 * because we already released lock on the old buffer in
+					 * PageFreezeTransSlots.
+					 */
+					Assert(BufferIsValid(buffer));
+					buf_hdr = GetBufferDescriptor(buffer - 1);
+					Assert(!(LWLockHeldByMeInMode(BufferDescriptorGetContentLock(buf_hdr),
+												  LW_EXCLUSIVE)));
+				}
+
+				/* Release the new buffer. */
+				UnlockReleaseBuffer(newbuf);
+			}
+			else
+				LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+
+			/* Release all the TPD buffer. */
+			UnlockReleaseTPDBuffers();
+
+			if (newtup_trans_slot == InvalidXactSlotId)
+			{
+				pgstat_report_wait_start(PG_WAIT_PAGE_TRANS_SLOT);
+				pg_usleep(10000L);	/* 10 ms */
+				pgstat_report_wait_end();
+			}
+
+			goto reacquire_buffer;
+		}
+
+		/*
+		 * After we release the lock on page, it could be pruned.  As we have
+		 * lock on the tuple, it couldn't be removed underneath us, but its
+		 * position could be changes, so need to refresh the tuple position.
+		 *
+		 * XXX Though the length of the tuple wouldn't have changed, but there
+		 * is no harm in refreshing it for the sake of consistency of code.
+		 */
+		oldtup.t_data = (ZHeapTupleHeader) PageGetItem(page, lp);
+		oldtup.t_len = ItemIdGetLength(lp);
+
+		/*
+		 * If the computed infomask for the updated tuple doesn't contain a
+		 * multilocker flag, we must have stored current transaction slot on
+		 * the tuple (due to LockForUpdate). In that case, we should update
+		 * the tuple xid as well.
+		 *
+		 * Also note that, there is possibility that our slot might have moved
+		 * to the TPD; in such case we should get previous slot_no + 1.
+		 */
+		if (!ZHeapTupleHasMultiLockers(oldtup.t_data->t_infomask))
+		{
+			Assert((result_trans_slot_id == oldtup_new_trans_slot) ||
+				   (ZHeapPageHasTPDSlot((PageHeader) page) &&
+					result_trans_slot_id + 1 == oldtup_new_trans_slot));
+			zinfo.trans_slot = oldtup_new_trans_slot;
+			zinfo.xid = xid;
+			save_tup_xid = zinfo.xid;
+		}
+	}
+	else
+	{
+		/* No TOAST work needed, and it'll fit on same page */
+		newbuf = buffer;
+		newtup_trans_slot = oldtup_new_trans_slot;
+		zheaptup = newtup;
+	}
+
+	CheckForSerializableConflictIn(relation, &(oldtup.t_self), buffer);
+
+	/* Prepare an undo record for this operation. */
+	gen_undo_info.reloid = relation->rd_id;
+	gen_undo_info.blkno = ItemPointerGetBlockNumber(&(oldtup.t_self));
+	gen_undo_info.offnum = ItemPointerGetOffsetNumber(&(oldtup.t_self));
+	gen_undo_info.prev_urecptr = prev_urecptr;
+	gen_undo_info.fxid = fxid;
+	gen_undo_info.cid = cid;
+	gen_undo_info.undo_persistence = UndoPersistenceForRelation(relation);
+
+	zh_up_undo_info.gen_info = &gen_undo_info;
+	zh_up_undo_info.inplace_update = use_inplace_update;
+	zh_up_undo_info.same_buf = (buffer == newbuf);
+	zh_up_undo_info.prevxid = zinfo.xid;
+	zh_up_undo_info.hasSubXactLock = hasSubXactLock;
+	zh_up_undo_info.new_trans_slot_id = newtup_trans_slot;
+	zh_up_undo_info.tup_trans_slot_id = zinfo.trans_slot;
+	zh_up_undo_info.old_undorec = &undorecord;
+	zh_up_undo_info.new_undorec = &new_undorecord;
+	zh_up_undo_info.new_block = BufferGetBlockNumber(newbuf);
+	zh_up_undo_info.new_prev_urecptr = new_prev_urecptr;
+	zh_up_undo_info.recovery_tid = NULL;
+
+	urecptr = zheap_prepare_undoupdate(&zh_up_undo_info, &oldtup, NULL,
+									   &new_urecptr);
+
+	if (!use_inplace_update)
+		/* Check and lock the TPD page before starting critical section. */
+		CheckAndLockTPDPage(relation, newtup_trans_slot, oldtup_new_trans_slot,
+							newbuf, buffer);
+
+	temp_infomask = oldtup.t_data->t_infomask;
+
+	/*
+	 * We can't rely on any_multi_locker_member_alive to clear the multi
+	 * locker bit, if the lock on the buffer is released in between.
+	 */
+	if (buffer == newbuf)
+	{
+		/*
+		 * If all the members were lockers and are all gone, we can do away
+		 * with the MULTI_LOCKERS bit.
+		 */
+		if (ZHeapTupleHasMultiLockers(temp_infomask) &&
+			!any_multi_locker_member_alive)
+			temp_infomask &= ~ZHEAP_MULTI_LOCKERS;
+	}
+
+	/* Compute the new xid and infomask to store into the tuple. */
+	compute_new_xid_infomask(&oldtup, buffer, save_tup_xid, zinfo.trans_slot,
+							 temp_infomask, xid, oldtup_new_trans_slot,
+							 single_locker_xid, *lockmode, ForUpdate,
+							 &old_infomask, &result_trans_slot_id);
+
+	/*
+	 * There must not be any stronger locker than the current operation,
+	 * otherwise it would have waited for it to finish.
+	 */
+	Assert(result_trans_slot_id == oldtup_new_trans_slot);
+
+	/*
+	 * Propagate the lockers information to the new tuple.  Since we're doing
+	 * an update, the only possibility is that the lockers had FOR KEY SHARE
+	 * lock.  For in-place updates, we are not creating any new version, so we
+	 * don't need to propagate anything.
+	 */
+	if ((checked_lockers && !locker_remains) || use_inplace_update)
+		new_infomask = 0;
+	else
+	{
+		/*
+		 * We should also set the multilocker flag if it was there previously,
+		 * else, we set the tuple as locked-only.
+		 */
+		new_infomask = ZHEAP_XID_KEYSHR_LOCK;
+		if (ZHeapTupleHasMultiLockers(old_infomask))
+			new_infomask |= ZHEAP_MULTI_LOCKERS | ZHEAP_XID_LOCK_ONLY;
+		else
+			new_infomask |= ZHEAP_XID_LOCK_ONLY;
+	}
+
+	if (use_inplace_update)
+	{
+		infomask_old_tuple = infomask_new_tuple =
+			old_infomask | new_infomask | ZHEAP_INPLACE_UPDATED;
+	}
+	else
+	{
+		infomask_old_tuple = old_infomask | ZHEAP_UPDATED;
+		infomask_new_tuple = new_infomask;
+	}
+
+	/* We must have a valid buffer. */
+	Assert(BufferIsValid(vmbuffer));
+	vm_status = visibilitymap_get_status(relation,
+										 BufferGetBlockNumber(buffer), &vmbuffer);
+
+	/*
+	 * If the page is new, then there will no valid vmbuffer_new and the
+	 * visibilitymap is reset already, hence, need not to clear anything.
+	 */
+	if (newbuf != buffer && BufferIsValid(vmbuffer_new))
+		vm_status_new = visibilitymap_get_status(relation,
+												 BufferGetBlockNumber(newbuf), &vmbuffer_new);
+
+	/*
+	 * Make sure we have space to register regular pages, a couple of TPD
+	 * pages and undo log pages, before we enter the critical section. TODO:
+	 * what is the maximum number of pages we could touch?
+	 */
+	XLogEnsureRecordSpace(8, 0);
+
+	START_CRIT_SECTION();
+
+	if ((vm_status & VISIBILITYMAP_ALL_VISIBLE) ||
+		(vm_status & VISIBILITYMAP_POTENTIAL_ALL_VISIBLE))
+	{
+		all_visible_cleared = true;
+		visibilitymap_clear(relation, BufferGetBlockNumber(buffer),
+							vmbuffer, VISIBILITYMAP_VALID_BITS);
+	}
+
+	if (newbuf != buffer)
+	{
+		if ((vm_status_new & VISIBILITYMAP_ALL_VISIBLE) ||
+			(vm_status_new & VISIBILITYMAP_POTENTIAL_ALL_VISIBLE))
+		{
+			new_all_visible_cleared = true;
+			visibilitymap_clear(relation, BufferGetBlockNumber(newbuf),
+								vmbuffer_new, VISIBILITYMAP_VALID_BITS);
+		}
+	}
+
+	/*
+	 * A page can be pruned for non-inplace updates or inplace updates that
+	 * results in shorter tuples.  If this transaction commits, the tuple will
+	 * become DEAD sooner or later.  If the transaction finally aborts, the
+	 * subsequent page pruning will be a no-op and the hint will be cleared.
+	 */
+	if (!use_inplace_update || (zheaptup->t_len < oldtup.t_len))
+		ZPageSetPrunable(page, xid);
+
+	/* oldtup should be pointing to right place in page */
+	Assert(oldtup.t_data == (ZHeapTupleHeader) PageGetItem(page, lp));
+
+	ZHeapTupleHeaderSetXactSlot(oldtup.t_data, result_trans_slot_id);
+	oldtup.t_data->t_infomask &= ~ZHEAP_VIS_STATUS_MASK;
+	oldtup.t_data->t_infomask |= infomask_old_tuple;
+
+	/* keep the new tuple copy updated for the caller */
+	ZHeapTupleHeaderSetXactSlot(zheaptup->t_data, newtup_trans_slot);
+	zheaptup->t_data->t_infomask &= ~ZHEAP_VIS_STATUS_MASK;
+	zheaptup->t_data->t_infomask |= infomask_new_tuple;
+
+	if (use_inplace_update)
+	{
+		/*
+		 * For inplace updates, we copy the entire data portion including null
+		 * bitmap of new tuple.
+		 *
+		 * For the special case where we are doing inplace updates even when
+		 * the new tuple is bigger, we need to adjust the old tuple's location
+		 * so that new tuple can be copied at that location as it is.
+		 */
+		ItemIdChangeLen(lp, zheaptup->t_len);
+		memcpy((char *) oldtup.t_data + SizeofZHeapTupleHeader,
+			   (char *) zheaptup->t_data + SizeofZHeapTupleHeader,
+			   zheaptup->t_len - SizeofZHeapTupleHeader);
+
+		/*
+		 * Copy everything from new tuple in infomask apart from visibility
+		 * flags.
+		 */
+		oldtup.t_data->t_infomask = oldtup.t_data->t_infomask &
+			ZHEAP_VIS_STATUS_MASK;
+		oldtup.t_data->t_infomask |= (zheaptup->t_data->t_infomask &
+									  ~ZHEAP_VIS_STATUS_MASK);
+		/* Copy number of attributes in infomask2 of new tuple. */
+		oldtup.t_data->t_infomask2 &= ~ZHEAP_NATTS_MASK;
+		oldtup.t_data->t_infomask2 |=
+			newtup->t_data->t_infomask2 & ZHEAP_NATTS_MASK;
+		/* also update the tuple length and self pointer */
+		oldtup.t_len = zheaptup->t_len;
+		oldtup.t_data->t_hoff = zheaptup->t_data->t_hoff;
+		ItemPointerCopy(&oldtup.t_self, &zheaptup->t_self);
+	}
+	else
+	{
+		/* insert tuple at new location */
+		RelationPutZHeapTuple(relation, newbuf, zheaptup);
+
+		/* update new tuple location in undo record */
+		appendBinaryStringInfoNoExtend(&undorecord.uur_payload,
+									   (char *) &zheaptup->t_self,
+									   sizeof(ItemPointerData));
+		if (zinfo.trans_slot > ZHEAP_PAGE_TRANS_SLOTS)
+			appendBinaryStringInfoNoExtend(&undorecord.uur_payload,
+										   (char *) &zinfo.trans_slot,
+										   sizeof(zinfo.trans_slot));
+		if (hasSubXactLock)
+		{
+			SubTransactionId subxid = GetCurrentSubTransactionId();
+
+			appendBinaryStringInfoNoExtend(&undorecord.uur_payload,
+										   (char *) &subxid,
+										   sizeof(subxid));
+		}
+
+		new_undorecord.uur_offset = ItemPointerGetOffsetNumber(&(zheaptup->t_self));
+	}
+
+	InsertPreparedUndo(&gen_undo_info.context);
+	if (use_inplace_update)
+		PageSetUNDO(undorecord, buffer, oldtup_new_trans_slot, true,
+					fxid, urecptr, NULL, 0);
+	else
+	{
+		if (newbuf == buffer)
+		{
+			OffsetNumber usedoff[2];
+
+			usedoff[0] = undorecord.uur_offset;
+			usedoff[1] = new_undorecord.uur_offset;
+
+			PageSetUNDO(undorecord, buffer, oldtup_new_trans_slot, true,
+						fxid, new_urecptr, usedoff, 2);
+		}
+		else
+		{
+			/* set transaction slot information for old page */
+			PageSetUNDO(undorecord, buffer, oldtup_new_trans_slot, true,
+						fxid, urecptr, NULL, 0);
+			/* set transaction slot information for new page */
+			PageSetUNDO(new_undorecord,
+						newbuf,
+						newtup_trans_slot,
+						true,
+						fxid,
+						new_urecptr,
+						NULL,
+						0);
+
+			MarkBufferDirty(newbuf);
+		}
+	}
+
+	MarkBufferDirty(buffer);
+
+	/* XLOG stuff */
+	if (RelationNeedsWAL(relation))
+	{
+		ZHeapWALInfo oldup_wal_info,
+					newup_wal_info;
+
+		/*
+		 * For logical decoding we need combocids to properly decode the
+		 * catalog.
+		 */
+		if (RelationIsAccessibleInLogicalDecoding(relation))
+		{
+			/*
+			 * Fixme: This won't work as it needs to access cmin/cmax which we
+			 * probably needs to retrieve from UNDO.
+			 */
+			/*
+			 * log_heap_new_cid(relation, &oldtup); log_heap_new_cid(relation,
+			 * heaptup);
+			 */
+		}
+		oldup_wal_info.buffer = buffer;
+		oldup_wal_info.ztuple = &oldtup;
+		oldup_wal_info.urecptr = urecptr;
+		oldup_wal_info.prev_urecptr = InvalidUndoRecPtr;
+		oldup_wal_info.new_trans_slot_id = oldtup_new_trans_slot;
+		oldup_wal_info.prior_trans_slot_id = zinfo.trans_slot;
+		oldup_wal_info.all_visible_cleared = all_visible_cleared;
+		oldup_wal_info.undorecord = &undorecord;
+		oldup_wal_info.context = &gen_undo_info.context;
+
+		newup_wal_info.buffer = newbuf;
+		newup_wal_info.ztuple = zheaptup;
+		newup_wal_info.urecptr = new_urecptr;
+		newup_wal_info.new_trans_slot_id = newtup_trans_slot;
+		newup_wal_info.all_visible_cleared = new_all_visible_cleared;
+		newup_wal_info.undorecord = &new_undorecord;
+		newup_wal_info.prev_urecptr = InvalidUndoRecPtr;
+		newup_wal_info.prior_trans_slot_id = InvalidXactSlotId;
+
+		log_zheap_update(&oldup_wal_info, &newup_wal_info,
+						 use_inplace_update);
+	}
+
+	END_CRIT_SECTION();
+
+	/* be tidy */
+	pfree(undorecord.uur_tuple.data);
+	if (undorecord.uur_payload.len > 0)
+		pfree(undorecord.uur_payload.data);
+
+	if (!use_inplace_update && new_undorecord.uur_payload.len > 0)
+		pfree(new_undorecord.uur_payload.data);
+
+	if (newbuf != buffer)
+		LockBuffer(newbuf, BUFFER_LOCK_UNLOCK);
+	LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+
+	if (BufferIsValid(vmbuffer_new))
+		ReleaseBuffer(vmbuffer_new);
+	if (vmbuffer != InvalidBuffer)
+		ReleaseBuffer(vmbuffer);
+	if (newbuf != buffer)
+		ReleaseBuffer(newbuf);
+	ReleaseBuffer(buffer);
+	FinishUndoRecordInsert(&gen_undo_info.context);
+	UnlockReleaseTPDBuffers();
+
+	/*
+	 * Release the lmgr tuple lock, if we had it.
+	 */
+	if (have_tuple_lock)
+		UnlockTupleTuplock(relation, &(oldtup.t_self), *lockmode);
+
+	/*
+	 * As of now, we only count non-inplace updates as that are required to
+	 * decide whether to trigger autovacuum.
+	 */
+	if (!use_inplace_update)
+	{
+		/*
+		 * If we've performed non-inplace update because of
+		 * slot_reused_or_TPD_slot optimization, we shouldn't increase the
+		 * update stats else, it'll trigger autovacuum unnecessarily. But, we
+		 * want to autoanalyze the table periodically.  Hence, we increase the
+		 * insert count.
+		 */
+		if (!slot_reused_or_TPD_slot)
+			pgstat_count_heap_update(relation, false);
+		else
+			pgstat_count_heap_insert(relation, 1);
+	}
+	else
+		pgstat_count_zheap_update(relation);
+
+	/*
+	 * If heaptup is a private copy, release it.  Don't forget to copy t_self
+	 * back to the caller's image, too.
+	 */
+	if (zheaptup != newtup)
+	{
+		newtup->t_self = zheaptup->t_self;
+		zheap_freetuple(zheaptup);
+	}
+	bms_free(inplace_upd_attrs);
+	bms_free(interesting_attrs);
+	bms_free(modified_attrs);
+
+	bms_free(key_attrs);
+	return TM_Ok;
+}
+
+/*
+ * zheap_update_wait_helper
+ *
+ * This is a helper function that encapsulates some of the logic that
+ * zheap_update needs to wait for concurrent transactions.
+ *
+ * XXX. This is very similar to zheap_delete_wait_helper, q.v.
+ */
+static bool
+zheap_update_wait_helper(Relation relation,
+						 Buffer buffer, ZHeapTuple zheaptup,
+						 FullTransactionId fxid, TransactionId xwait,
+						 int xwait_trans_slot, SubTransactionId xwait_subxid,
+						 LockTupleMode lockmode, bool key_intact,
+						 ItemId lp,
+						 TransactionId tup_xid, bool *have_tuple_lock,
+						 TransactionId *single_locker_xid,
+						 bool *any_multi_locker_member_alive,
+						 bool *checked_lockers, bool *locker_remains,
+						 TM_Result *result)
+{
+	List	   *mlmembers;
+	uint16		infomask;
+	bool		can_continue = false;
+
+	/* must copy state data before unlocking buffer */
+	infomask = zheaptup->t_data->t_infomask;
+
+	if (ZHeapTupleHasMultiLockers(infomask))
+	{
+		TransactionId update_xact;
+		LockTupleMode old_lock_mode;
+		int			remain = 0;
+		bool		isAborted;
+		bool		upd_xact_aborted = false;
+		int			trans_slot_id;
+		UndoRecPtr	prev_urecptr;
+
+		/*
+		 * In ZHeapTupleSatisfiesUpdate, it's not possible to know if current
+		 * transaction has already locked the tuple for update because of
+		 * multilocker flag. In that case, we've to check whether the current
+		 * transaction has already locked the tuple for update.
+		 */
+
+		/*
+		 * Get the transaction slot and undo record pointer if we are already
+		 * in a transaction.
+		 */
+		trans_slot_id =
+			PageGetTransactionSlotId(relation, buffer, fxid,
+									 &prev_urecptr, false, false, NULL);
+
+		/*
+		 * If any subtransaction of the current top transaction already holds
+		 * a lock as strong as or stronger than what we're requesting, we
+		 * effectively hold the desired lock already.  We *must* succeed
+		 * without trying to take the tuple lock, else we will deadlock
+		 * against anyone wanting to acquire a stronger lock.
+		 */
+		if (trans_slot_id != InvalidXactSlotId &&
+			ZCurrentXactHasTupleLockMode(zheaptup, prev_urecptr, lockmode))
+		{
+			*result = TM_Ok;
+			*checked_lockers = true;
+			*locker_remains = true;
+			return true;
+		}
+
+		old_lock_mode = get_old_lock_mode(infomask);
+
+		/*
+		 * For the conflicting lockers, we need to be careful about applying
+		 * pending undo actions for aborted transactions; if we leave any
+		 * transaction whether locker or updater, it can lead to
+		 * inconsistency.  Basically, in such a case after waiting for all the
+		 * conflicting transactions we might clear the multilocker flag and
+		 * proceed with update and it is quite possible that after the update,
+		 * undo worker rollbacks some of the previous locker which can
+		 * overwrite the tuple (Note, till multilocker bit is set, the
+		 * rollback actions won't overwrite the tuple).
+		 *
+		 * OTOH for non-conflicting lockers, as we don't clear the
+		 * multi-locker flag, there is no urgency to perform undo actions for
+		 * aborts of lockers.  The work involved in finding and aborting
+		 * lockers is non-trivial (w.r.t performance), so it is better to
+		 * avoid it.
+		 *
+		 * After abort, if it is only a locker, then it will be completely
+		 * gone; but if it is an update, then after applying pending actions,
+		 * the tuple might get changed and we must allow to reverify the tuple
+		 * in case it's values got changed.
+		 */
+		if (!ZHEAP_XID_IS_LOCKED_ONLY(zheaptup->t_data->t_infomask))
+			update_xact = tup_xid;
+		else
+			update_xact = InvalidTransactionId;
+
+		if (DoLockModesConflict(HWLOCKMODE_from_locktupmode(old_lock_mode),
+								HWLOCKMODE_from_locktupmode(lockmode)))
+		{
+			bool		pending_actions_applied = false;
+
+			/*
+			 * There is a potential conflict.  It is quite possible that by
+			 * this time the locker has already been committed. So we need to
+			 * check for conflict with all the possible lockers and wait for
+			 * each of them after releasing a buffer lock and acquiring a lock
+			 * on a tuple.
+			 */
+			LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+			mlmembers = ZGetMultiLockMembers(relation, zheaptup, buffer,
+											 true);
+
+			/*
+			 * If there is no multi-lock members apart from the current
+			 * transaction then no need for tuplock, just go ahead.
+			 */
+			if (mlmembers != NIL)
+			{
+				heap_acquire_tuplock(relation, &(zheaptup->t_self), lockmode,
+									 LockWaitBlock, have_tuple_lock);
+				ZMultiLockMembersWait(relation, mlmembers, zheaptup, buffer,
+									  update_xact, lockmode, false,
+									  XLTW_Update, &remain,
+									  &upd_xact_aborted);
+			}
+			*checked_lockers = true;
+			*locker_remains = (remain != 0);
+			LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+
+			/*
+			 * If the aborted xact is for update, then we need to reverify the
+			 * tuple.
+			 */
+			if (upd_xact_aborted)
+				return false;
+
+			/*
+			 * Also take care of cases when page is pruned after we release
+			 * the buffer lock. For this we check if ItemId is not deleted and
+			 * refresh the tuple offset position in page.  If TID is already
+			 * delete marked due to pruning, then get new ctid, so that we can
+			 * update the new tuple.
+			 *
+			 * We also need to ensure that no new lockers have been added in
+			 * the meantime, if there is any new locker, then start again.
+			 */
+			if (ItemIdIsDeleted(lp))
+				return false;
+
+			if (ZHeapTupleHasMultiLockers(infomask))
+			{
+				List	   *new_mlmembers;
+
+				new_mlmembers = ZGetMultiLockMembers(relation, zheaptup,
+													 buffer, false);
+
+				/*
+				 * Ensure, no new lockers have been added, if so, then start
+				 * again.
+				 */
+				if (!ZMultiLockMembersSame(mlmembers, new_mlmembers))
+				{
+					list_free_deep(mlmembers);
+					list_free_deep(new_mlmembers);
+					return false;
+				}
+
+				*any_multi_locker_member_alive =
+					ZIsAnyMultiLockMemberRunning(relation, xwait_trans_slot,
+												 new_mlmembers, zheaptup,
+												 buffer,
+												 &pending_actions_applied);
+				list_free_deep(mlmembers);
+				list_free_deep(new_mlmembers);
+			}
+
+			if (pending_actions_applied || !RefetchAndCheckTupleStatus(
+																	   relation, buffer, infomask,
+																	   tup_xid, single_locker_xid, NULL,
+																	   zheaptup))
+				return false;
+		}
+		else if (TransactionIdIsValid(update_xact))
+		{
+			isAborted = TransactionIdDidAbort(update_xact);
+
+			/*
+			 * For aborted transaction, if the undo actions are not applied
+			 * yet, then apply them before modifying the page.
+			 */
+			if (isAborted &&
+				zheap_exec_pending_rollback(relation, buffer,
+											xwait_trans_slot, xwait, NULL))
+				return false;
+		}
+
+		/*
+		 * There was no UPDATE in the Multilockers. No
+		 * TransactionIdIsInProgress() call needed here, since we called
+		 * ZMultiLockMembersWait() above.
+		 */
+		if (!TransactionIdIsValid(update_xact))
+			can_continue = true;
+	}
+	else if (TransactionIdIsCurrentTransactionId(xwait))
+	{
+		/*
+		 * The only locker is ourselves; we can avoid grabbing the tuple lock
+		 * here, but must preserve our locking information.
+		 */
+		*checked_lockers = true;
+		*locker_remains = true;
+		can_continue = true;
+	}
+	else if (ZHEAP_XID_IS_KEYSHR_LOCKED(infomask) && key_intact)
+	{
+		/*
+		 * If it's just a key-share locker, and we're not changing the key
+		 * columns, we don't need to wait for it to end; but we need to
+		 * preserve it as locker.
+		 */
+		*checked_lockers = true;
+		*locker_remains = true;
+		can_continue = true;
+	}
+	else
+	{
+		bool		isCommitted;
+		bool		has_update = false;
+
+		/*
+		 * Wait for regular transaction to end; but first, acquire tuple lock.
+		 */
+		LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+		heap_acquire_tuplock(relation, &(zheaptup->t_self), lockmode,
+							 LockWaitBlock, have_tuple_lock);
+		if (xwait_subxid != InvalidSubTransactionId)
+			SubXactLockTableWait(xwait, xwait_subxid, relation,
+								 &zheaptup->t_self, XLTW_Update);
+		else
+			XactLockTableWait(xwait, relation, &zheaptup->t_self,
+							  XLTW_Update);
+		*checked_lockers = true;
+		LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+
+		/*
+		 * Also take care of cases when page is pruned after we release the
+		 * buffer lock. For this we check if ItemId is not deleted and refresh
+		 * the tuple offset position in page.  If TID is already delete marked
+		 * due to pruning, then get new ctid, so that we can update the new
+		 * tuple.
+		 */
+		if (ItemIdIsDeleted(lp))
+			return false;
+
+		/*
+		 * xwait is done, but if xwait had just locked the tuple then some
+		 * other xact could update/lock this tuple before we get to this
+		 * point.  Check for xid change, and start over if so.  We need to do
+		 * some special handling for lockers because their xid is never stored
+		 * on the tuples.  If there was a single locker on the tuple and that
+		 * locker is gone and some new locker has locked the tuple, we won't
+		 * be able to identify that by infomask/xid on the tuple, rather we
+		 * need to fetch the locker xid.
+		 */
+		if (!RefetchAndCheckTupleStatus(relation, buffer, infomask, tup_xid,
+										single_locker_xid, NULL, zheaptup))
+			return false;
+
+		if (!ZHEAP_XID_IS_LOCKED_ONLY(zheaptup->t_data->t_infomask))
+			has_update = true;
+
+		/*
+		 * We may overwrite if previous xid is aborted, or if it is committed
+		 * but only locked the tuple without updating it.
+		 */
+		isCommitted = TransactionIdDidCommit(xwait);
+
+		/*
+		 * For aborted transaction, if the undo actions are not applied yet,
+		 * then apply them before modifying the page.
+		 */
+		if (!isCommitted)
+			zheap_exec_pending_rollback(relation, buffer, xwait_trans_slot,
+										xwait, NULL);
+
+		if (!isCommitted)
+		{
+			/*
+			 * For aborted updates, we must allow to reverify the tuple in
+			 * case it's values got changed.
+			 */
+			if (has_update)
+				return false;
+
+			/*
+			 * While executing the undo action we have released the buffer
+			 * lock.  So if the tuple infomask got changed while applying the
+			 * undo action then we must reverify the tuple.
+			 */
+			if (!RefetchAndCheckTupleStatus(relation, buffer, infomask, tup_xid,
+											single_locker_xid, NULL, zheaptup))
+				return false;
+		}
+
+		if (!has_update)
+			can_continue = true;
+	}
+
+	/*
+	 * We may overwrite if previous xid is aborted or committed, but only
+	 * locked the tuple without updating it.
+	 */
+	if (*result != TM_Ok)
+		*result = can_continue ? TM_Ok : TM_Updated;
+	return true;
+}
+
+/*
+ * zheap_lock_tuple - lock a tuple.
+ *
+ *	The functionality is same as heap_lock_tuple except that here we always
+ *	make a copy of the tuple before returning to the caller.  We maintain
+ *	the pin on buffer to keep the specs same as heap_lock_tuple.
+ *
+ *	eval - indicates whether the tuple will be evaluated to see if it still
+ *	matches the qualification.
+ *
+ * XXX - Here, we are purposefully not doing anything for visibility map
+ * as it is not clear whether we ever need all_frozen kind of concept for
+ * zheap.
+ */
+TM_Result
+zheap_lock_tuple(Relation relation, ItemPointer tid,
+				 CommandId cid, LockTupleMode mode, LockWaitPolicy wait_policy,
+				 bool follow_updates, bool eval, Snapshot snapshot,
+				 ZHeapTuple tuple, Buffer *buffer, TM_FailureData *tmfd)
+{
+	TM_Result	result;
+	ZHeapTupleData zhtup;
+	UndoRecPtr	prev_urecptr;
+	ItemId		lp;
+	Page		page;
+	ItemPointerData ctid;
+	FullTransactionId fxid = GetTopFullTransactionId();
+	TransactionId single_locker_xid;
+	SubTransactionId tup_subxid = InvalidSubTransactionId;
+	UndoRecPtr	urec_ptr = InvalidUndoRecPtr;
+	int			trans_slot_id,
+				single_locker_trans_slot;
+	OffsetNumber offnum;
+	LockOper	lockopr;
+	bool		have_tuple_lock = false;
+	bool		in_place_updated_or_locked = false;
+	bool		any_multi_locker_member_alive = false;
+	bool		lock_reacquired;
+	bool		hasSubXactLock = false;
+	ZHeapTupleTransInfo zinfo;
+	ZHeapPrepareUndoInfo zh_undo_info;
+
+	lockopr = eval ? LockForUpdate : LockOnly;
+
+	*buffer = ReadBuffer(relation, ItemPointerGetBlockNumber(tid));
+
+	LockBuffer(*buffer, BUFFER_LOCK_EXCLUSIVE);
+
+	page = BufferGetPage(*buffer);
+	offnum = ItemPointerGetOffsetNumber(tid);
+	lp = PageGetItemId(page, offnum);
+	Assert(ItemIdIsNormal(lp) || ItemIdIsDeleted(lp));
+
+	/*
+	 * If TID is already delete marked due to pruning, then get new ctid, so
+	 * that we can lock the new tuple.  We will get new ctid if the tuple was
+	 * non-inplace-updated otherwise we will get same TID.
+	 */
+check_tup_satisfies_update:
+	any_multi_locker_member_alive = true;
+	result = ZHeapTupleSatisfiesUpdate(relation, tid, &zhtup, cid, *buffer,
+									   &ctid, &zinfo, &tup_subxid,
+									   &single_locker_xid,
+									   &single_locker_trans_slot, eval,
+									   snapshot, &in_place_updated_or_locked);
+
+	/*
+	 * Get the transaction slot and undo record pointer if we are already in a
+	 * transaction.
+	 */
+	trans_slot_id = PageGetTransactionSlotId(relation, *buffer, fxid,
+											 &urec_ptr, false, false, NULL);
+
+	if (result == TM_Invisible)
+	{
+		tuple->t_tableOid = RelationGetRelid(relation);
+		tuple->t_len = zhtup.t_len;
+		tuple->t_self = zhtup.t_self;
+		tuple->t_data = palloc0(tuple->t_len);
+		memcpy(tuple->t_data, zhtup.t_data, zhtup.t_len);
+
+		/* Give caller an opportunity to throw a more specific error. */
+		result = TM_Invisible;
+		goto out_locked;
+	}
+	else if (result == TM_BeingModified ||
+			 (result == TM_Updated && zhtup.t_data != NULL) ||
+			 (result == TM_Ok &&
+			  ZHeapTupleHasMultiLockers(zhtup.t_data->t_infomask)))
+	{
+		TransactionId xwait;
+		SubTransactionId xwait_subxid;
+		LockWaitStatus wait_status;
+		int			xwait_trans_slot;
+		uint16		infomask;
+
+		xwait_subxid = tup_subxid;
+
+		if (TransactionIdIsValid(single_locker_xid))
+		{
+			xwait = single_locker_xid;
+			xwait_trans_slot = single_locker_trans_slot;
+		}
+		else
+		{
+			xwait = zinfo.xid;
+			xwait_trans_slot = zinfo.trans_slot;
+		}
+
+		infomask = zhtup.t_data->t_infomask;
+
+		/*
+		 * make a copy of the tuple before releasing the lock as some other
+		 * backend can perform in-place update this tuple once we release the
+		 * lock.
+		 */
+		tuple->t_tableOid = RelationGetRelid(relation);
+		tuple->t_len = zhtup.t_len;
+		tuple->t_self = zhtup.t_self;
+		tuple->t_data = palloc0(tuple->t_len);
+		memcpy(tuple->t_data, zhtup.t_data, zhtup.t_len);
+
+		LockBuffer(*buffer, BUFFER_LOCK_UNLOCK);
+
+		/*
+		 * Check if tuple already holds the desired lock already.  If so, we
+		 * *must* succeed without trying to take the tuple lock, else we will
+		 * deadlock against anyone wanting to acquire a stronger lock.
+		 */
+		if (zheap_tuple_already_locked(&zhtup, urec_ptr, xwait, mode,
+									   trans_slot_id, infomask, &result))
+			goto out_unlocked;
+
+		wait_status = zheap_lock_wait_helper(relation, *buffer, &zhtup, fxid,
+											 xwait, xwait_trans_slot,
+											 xwait_subxid, cid, mode,
+											 wait_policy, lockopr, &ctid, lp,
+											 zinfo.xid, infomask,
+											 follow_updates,
+											 &single_locker_xid, &result,
+											 &any_multi_locker_member_alive,
+											 &have_tuple_lock);
+
+		if (wait_status == LOCK_WAIT_RECHECK)
+			goto check_tup_satisfies_update;
+		else if (wait_status == LOCK_WAIT_FAILED)
+			goto failed;
+		else
+			Assert(wait_status == LOCK_WAIT_SUCCESS);
+	}
+	else if (result == TM_Ok)
+	{
+		TransactionId xwait;
+		uint16		infomask;
+
+		if (TransactionIdIsValid(single_locker_xid))
+			xwait = single_locker_xid;
+		else
+			xwait = zinfo.xid;
+
+		infomask = zhtup.t_data->t_infomask;
+
+		/*
+		 * If any subtransaction of the current top transaction already holds
+		 * a lock as strong as or stronger than what we're requesting, we
+		 * effectively hold the desired lock already.  We *must* succeed
+		 * without trying to take the tuple lock, else we will deadlock
+		 * against anyone wanting to acquire a stronger lock.
+		 *
+		 * Note that inplace-updates without key updates are considered
+		 * equivalent to lock mode LockTupleNoKeyExclusive.
+		 */
+		if (ZHeapTupleHasMultiLockers(infomask))
+		{
+			if (trans_slot_id != InvalidXactSlotId &&
+				ZCurrentXactHasTupleLockMode(&zhtup, urec_ptr, mode))
+			{
+				result = TM_Ok;
+				goto out_locked;
+			}
+		}
+		else if (TransactionIdIsCurrentTransactionId(xwait))
+		{
+			tuple->t_tableOid = RelationGetRelid(relation);
+			tuple->t_len = zhtup.t_len;
+			tuple->t_self = zhtup.t_self;
+			tuple->t_data = palloc0(tuple->t_len);
+			memcpy(tuple->t_data, zhtup.t_data, zhtup.t_len);
+
+			switch (mode)
+			{
+				case LockTupleKeyShare:
+					if (ZHEAP_XID_IS_KEYSHR_LOCKED(infomask) ||
+						ZHEAP_XID_IS_SHR_LOCKED(infomask) ||
+						ZHEAP_XID_IS_NOKEY_EXCL_LOCKED(infomask) ||
+						ZHEAP_XID_IS_EXCL_LOCKED(infomask) ||
+						ZHeapTupleIsInPlaceUpdated(infomask))
+					{
+						goto out_locked;
+					}
+					break;
+				case LockTupleShare:
+					if (ZHEAP_XID_IS_SHR_LOCKED(infomask) ||
+						ZHEAP_XID_IS_NOKEY_EXCL_LOCKED(infomask) ||
+						ZHEAP_XID_IS_EXCL_LOCKED(infomask) ||
+						ZHeapTupleIsInPlaceUpdated(infomask))
+					{
+						goto out_locked;
+					}
+					break;
+				case LockTupleNoKeyExclusive:
+					if (ZHEAP_XID_IS_NOKEY_EXCL_LOCKED(infomask) ||
+						ZHeapTupleIsInPlaceUpdated(infomask))
+					{
+						goto out_locked;
+					}
+					break;
+				case LockTupleExclusive:
+					if (ZHeapTupleIsInPlaceUpdated(infomask) &&
+						ZHEAP_XID_IS_EXCL_LOCKED(infomask))
+					{
+						goto out_locked;
+					}
+					break;
+			}
+		}
+	}
+
+failed:
+	if (result != TM_Ok)
+	{
+		Assert(result == TM_SelfModified || result == TM_Deleted ||
+			   result == TM_Updated || result == TM_WouldBlock);
+		Assert(ItemIdIsDeleted(lp) ||
+			   IsZHeapTupleModified(zhtup.t_data->t_infomask));
+
+		/* If item id is deleted, tuple can't be marked as moved. */
+		if (!ItemIdIsDeleted(lp) &&
+			ZHeapTupleIsMoved(zhtup.t_data->t_infomask))
+			ItemPointerSetMovedPartitions(&tmfd->ctid);
+		else
+			tmfd->ctid = ctid;
+
+		/*
+		 * If item id is deleted, tuple won't be initialized.  In that case,
+		 * we should set t_self with the tuple tid and the length as zero to
+		 * let the caller know that the item id is deleted.
+		 */
+		if (ItemIdIsDeleted(lp))
+		{
+			tuple->t_self = *tid;
+			tuple->t_len = 0;
+			tuple->t_tableOid = RelationGetRelid(relation);
+		}
+
+		tmfd->xmax = zinfo.xid;
+		if (result == TM_SelfModified)
+			tmfd->cmax = zinfo.cid;
+		else
+			tmfd->cmax = InvalidCommandId;
+		tmfd->in_place_updated_or_locked = in_place_updated_or_locked;
+		goto out_locked;
+	}
+
+	/*
+	 * The transaction information of tuple needs to be set in transaction
+	 * slot, so needs to reserve the slot before proceeding with the actual
+	 * operation.  It will be costly to wait for getting the slot, but we do
+	 * that by releasing the buffer lock.
+	 */
+	trans_slot_id = PageReserveTransactionSlot(relation, *buffer,
+											   PageGetMaxOffsetNumber(page),
+											   fxid, &prev_urecptr,
+											   &lock_reacquired, false, InvalidBuffer,
+											   NULL);
+	if (lock_reacquired)
+		goto check_tup_satisfies_update;
+
+	if (trans_slot_id == InvalidXactSlotId)
+	{
+		LockBuffer(*buffer, BUFFER_LOCK_UNLOCK);
+
+		pgstat_report_wait_start(PG_WAIT_PAGE_TRANS_SLOT);
+		pg_usleep(10000L);		/* 10 ms */
+		pgstat_report_wait_end();
+
+		LockBuffer(*buffer, BUFFER_LOCK_EXCLUSIVE);
+
+		goto check_tup_satisfies_update;
+	}
+
+	/* transaction slot must be reserved before locking a tuple */
+	Assert(trans_slot_id != InvalidXactSlotId);
+
+	/*
+	 * It's possible that tuple slot is now marked as frozen. Hence, we
+	 * refetch the tuple here.
+	 */
+	Assert(!ItemIdIsDeleted(lp));
+	zhtup.t_data = (ZHeapTupleHeader) PageGetItem(page, lp);
+	zhtup.t_len = ItemIdGetLength(lp);
+
+	/*
+	 * If the slot is marked as frozen, the latest modifier of the tuple must
+	 * be frozen.
+	 */
+	if (ZHeapTupleHeaderGetXactSlot((ZHeapTupleHeader) (zhtup.t_data)) == ZHTUP_SLOT_FROZEN)
+	{
+		zinfo.trans_slot = ZHTUP_SLOT_FROZEN;
+		zinfo.xid = InvalidTransactionId;
+	}
+
+	/*
+	 * Acquire subtransaction lock, if current transaction is a
+	 * subtransaction.
+	 */
+	if (IsSubTransaction())
+	{
+		SubXactLockTableInsert(GetCurrentSubTransactionId());
+		hasSubXactLock = true;
+	}
+
+	/*
+	 * Prepare an undo record for this operation.  While locking the tuple, we
+	 * set the command id as FirstCommandId since it doesn't modify the tuple,
+	 * just updates the infomask.
+	 */
+	zh_undo_info.reloid = relation->rd_id;
+	zh_undo_info.blkno = BufferGetBlockNumber(*buffer);
+	zh_undo_info.offnum = ItemPointerGetOffsetNumber(&(zhtup.t_self));
+	zh_undo_info.prev_urecptr = prev_urecptr;
+	zh_undo_info.fxid = fxid;
+	zh_undo_info.cid = FirstCommandId;
+	zh_undo_info.undo_persistence = UndoPersistenceForRelation(relation);
+
+	/*
+	 * If all the members were lockers and are all gone, we can do away with
+	 * the MULTI_LOCKERS bit.
+	 */
+	(void) zheap_lock_tuple_guts(*buffer, &zhtup, &zinfo,
+								 single_locker_xid, fxid, trans_slot_id,
+								 mode, lockopr, hasSubXactLock,
+								 !any_multi_locker_member_alive,
+								 RelationNeedsWAL(relation),
+								 &zh_undo_info, NULL);
+
+	tuple->t_tableOid = RelationGetRelid(relation);
+	tuple->t_len = zhtup.t_len;
+	tuple->t_self = zhtup.t_self;
+	tuple->t_data = palloc0(tuple->t_len);
+
+	memcpy(tuple->t_data, zhtup.t_data, zhtup.t_len);
+
+	result = TM_Ok;
+
+out_locked:
+	LockBuffer(*buffer, BUFFER_LOCK_UNLOCK);
+out_unlocked:
+
+	/*
+	 * Don't update the visibility map here. Locking a tuple doesn't change
+	 * visibility info.
+	 */
+
+	/*
+	 * Now that we have successfully marked the tuple as locked, we can
+	 * release the lmgr tuple lock, if we had it.
+	 */
+	if (have_tuple_lock)
+		UnlockTupleTuplock(relation, tid, mode);
+
+	return result;
+}
+
+/*
+ * zheap_tuple_already_locked - Check whether the tuple is already locked in
+ *		given mode.
+ *
+ * We consider tuple to be locked in required mode if any subtransaction of
+ * the current top transaction already holds a lock as strong as or stronger
+ * than what we're requesting.
+ */
+static bool
+zheap_tuple_already_locked(ZHeapTuple zhtup, UndoRecPtr urec_ptr,
+						   TransactionId xid, LockTupleMode mode,
+						   int trans_slot_id, uint16 infomask,
+						   TM_Result *result)
+{
+	if (ZHeapTupleHasMultiLockers(infomask))
+	{
+		if (trans_slot_id != InvalidXactSlotId &&
+			ZCurrentXactHasTupleLockMode(zhtup, urec_ptr, mode))
+		{
+			*result = TM_Ok;
+			return true;
+		}
+	}
+	else if (TransactionIdIsCurrentTransactionId(xid))
+	{
+		switch (mode)
+		{
+			case LockTupleKeyShare:
+				Assert(ZHEAP_XID_IS_KEYSHR_LOCKED(infomask) ||
+					   ZHEAP_XID_IS_SHR_LOCKED(infomask) ||
+					   ZHEAP_XID_IS_NOKEY_EXCL_LOCKED(infomask) ||
+					   ZHEAP_XID_IS_EXCL_LOCKED(infomask));
+				{
+					*result = TM_Ok;
+					return true;
+				}
+				break;
+			case LockTupleShare:
+				if (ZHEAP_XID_IS_SHR_LOCKED(infomask) ||
+					ZHEAP_XID_IS_NOKEY_EXCL_LOCKED(infomask) ||
+					ZHEAP_XID_IS_EXCL_LOCKED(infomask))
+				{
+					*result = TM_Ok;
+					return true;
+				}
+				break;
+			case LockTupleNoKeyExclusive:
+				if (ZHEAP_XID_IS_NOKEY_EXCL_LOCKED(infomask) ||
+					ZHEAP_XID_IS_EXCL_LOCKED(infomask))
+				{
+					*result = TM_Ok;
+					return true;
+				}
+				break;
+			case LockTupleExclusive:
+				if (ZHEAP_XID_IS_EXCL_LOCKED(infomask))
+				{
+					*result = TM_Ok;
+					return true;
+				}
+				break;
+		}
+	}
+
+	return false;
+}
+
+/*
+ * zheap_lock_wait_helper
+ *
+ * This is a helper function that encapsulates some of the logic that
+ * zheap_lock_tuple needs to wait for concurrent transactions.
+ *
+ * XXX. This is very similar to zheap_delete_wait_helper, q.v.
+ */
+static LockWaitStatus
+zheap_lock_wait_helper(Relation relation, Buffer buffer, ZHeapTuple zhtup,
+					   FullTransactionId fxid, TransactionId xwait,
+					   int xwait_trans_slot, SubTransactionId xwait_subxid,
+					   CommandId cid, LockTupleMode mode,
+					   LockWaitPolicy wait_policy, LockOper lockopr,
+					   ItemPointer ctid, ItemId lp, TransactionId tup_xid,
+					   uint16 infomask, bool follow_updates,
+					   TransactionId *single_locker_xid, TM_Result *result,
+					   bool *any_multi_locker_member_alive,
+					   bool *have_tuple_lock)
+{
+	bool		require_sleep;
+	bool		rollback_and_relocked;
+
+	/*
+	 * Initially assume that we will have to wait for the locking
+	 * transaction(s) to finish.  We check various cases below in which this
+	 * can be turned off.
+	 */
+	require_sleep = true;
+	if (mode == LockTupleKeyShare)
+	{
+		if (!(ZHEAP_XID_IS_EXCL_LOCKED(infomask)))
+		{
+			bool		updated;
+
+			updated = !ZHEAP_XID_IS_LOCKED_ONLY(infomask);
+
+			/*
+			 * If there are updates, follow the update chain; bail out if that
+			 * cannot be done.
+			 */
+			if (follow_updates && updated)
+			{
+				if (!ZHeapTupleIsMoved(zhtup->t_data->t_infomask) &&
+					!ItemPointerEquals(&zhtup->t_self, ctid))
+				{
+					TM_Result	res;
+
+					res = zheap_lock_updated_tuple(relation, zhtup, ctid,
+												   fxid, mode, lockopr, cid,
+												   &rollback_and_relocked);
+
+					/*
+					 * If the update was by some aborted transaction and its
+					 * pending undo actions are applied now, then check the
+					 * latest copy of the tuple.
+					 */
+					if (rollback_and_relocked)
+					{
+						LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+						return LOCK_WAIT_RECHECK;
+					}
+					else if (res != TM_Ok)
+					{
+						*result = res;
+						/* recovery code expects to have buffer lock held */
+						LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+						return LOCK_WAIT_FAILED;
+					}
+				}
+			}
+
+			LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+
+			/*
+			 * Also take care of cases when page is pruned after we release
+			 * the buffer lock. For this we check if ItemId is not deleted and
+			 * refresh the tuple offset position in page.  If TID is already
+			 * delete marked due to pruning, then get new ctid, so that we can
+			 * lock the new tuple.
+			 */
+			if (ItemIdIsDeleted(lp))
+				return LOCK_WAIT_RECHECK;
+
+			if (!RefetchAndCheckTupleStatus(relation, buffer, infomask,
+											tup_xid, single_locker_xid,
+											&mode, zhtup))
+				return LOCK_WAIT_RECHECK;
+
+			/* Skip sleeping */
+			require_sleep = false;
+		}
+	}
+	else if (mode == LockTupleShare)
+	{
+		/*
+		 * If we're requesting Share, we can similarly avoid sleeping if
+		 * there's no update and no exclusive lock present.
+		 */
+		if (ZHEAP_XID_IS_LOCKED_ONLY(infomask) &&
+			!ZHEAP_XID_IS_NOKEY_EXCL_LOCKED(infomask) &&
+			!ZHEAP_XID_IS_EXCL_LOCKED(infomask))
+		{
+			LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+
+			/*
+			 * Also take care of cases when page is pruned after we release
+			 * the buffer lock. For this we check if ItemId is not deleted and
+			 * refresh the tuple offset position in page.  If TID is already
+			 * delete marked due to pruning, then get new ctid, so that we can
+			 * lock the new tuple.
+			 */
+			if (ItemIdIsDeleted(lp))
+				return LOCK_WAIT_RECHECK;
+
+			if (!RefetchAndCheckTupleStatus(relation, buffer, infomask,
+											tup_xid, single_locker_xid,
+											&mode, zhtup))
+				return LOCK_WAIT_RECHECK;
+
+			/* Skip sleeping */
+			require_sleep = false;
+		}
+	}
+	else if (mode == LockTupleNoKeyExclusive)
+	{
+		LockTupleMode old_lock_mode;
+		bool		buf_lock_reacquired = false;
+
+		old_lock_mode = get_old_lock_mode(infomask);
+
+		/*
+		 * If we're requesting NoKeyExclusive, we might also be able to avoid
+		 * sleeping; just ensure that there is no conflicting lock already
+		 * acquired.
+		 */
+		if (ZHeapTupleHasMultiLockers(infomask))
+		{
+			if (!DoLockModesConflict(HWLOCKMODE_from_locktupmode(old_lock_mode),
+									 HWLOCKMODE_from_locktupmode(mode)))
+			{
+				LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+				buf_lock_reacquired = true;
+			}
+		}
+		else if (old_lock_mode == LockTupleKeyShare)
+		{
+			LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+			buf_lock_reacquired = true;
+		}
+
+		if (buf_lock_reacquired)
+		{
+			/*
+			 * Also take care of cases when page is pruned after we release
+			 * the buffer lock. For this we check if ItemId is not deleted and
+			 * refresh the tuple offset position in page.  If TID is already
+			 * delete marked due to pruning, then get new ctid, so that we can
+			 * lock the new tuple.
+			 */
+			if (ItemIdIsDeleted(lp))
+				return LOCK_WAIT_RECHECK;
+
+			if (!RefetchAndCheckTupleStatus(relation, buffer, infomask,
+											tup_xid, single_locker_xid,
+											&mode, zhtup))
+				return LOCK_WAIT_RECHECK;
+
+			/* Skip sleeping */
+			require_sleep = false;
+		}
+	}
+
+	/*
+	 * As a check independent from those above, we can also avoid sleeping if
+	 * the current transaction is the sole locker of the tuple.  Note that the
+	 * strength of the lock already held is irrelevant; this is not about
+	 * recording the lock (which will be done regardless of this optimization,
+	 * below).  Also, note that the cases where we hold a lock stronger than
+	 * we are requesting are already handled above by not doing anything.
+	 */
+	if (require_sleep &&
+		!ZHeapTupleHasMultiLockers(infomask) &&
+		TransactionIdIsCurrentTransactionId(xwait))
+	{
+		/*
+		 * If the xid changed in the meantime, start over.
+		 *
+		 * Also take care of cases when page is pruned after we release the
+		 * buffer lock. For this we check if ItemId is not deleted and refresh
+		 * the tuple offset position in page.  If TID is already delete marked
+		 * due to pruning, then get new ctid, so that we can lock the new
+		 * tuple.
+		 */
+		LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+		if (ItemIdIsDeleted(lp))
+			return LOCK_WAIT_RECHECK;
+
+		if (!RefetchAndCheckTupleStatus(relation, buffer, infomask,
+										tup_xid, single_locker_xid,
+										NULL, zhtup))
+			return LOCK_WAIT_RECHECK;
+		require_sleep = false;
+	}
+
+	if (require_sleep && *result == TM_Updated)
+	{
+		LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+		return LOCK_WAIT_FAILED;
+	}
+	else if (require_sleep)
+	{
+		List	   *mlmembers = NIL;
+		bool		upd_xact_aborted = false;
+		bool		pending_actions_applied = false;
+
+		/*
+		 * Acquire tuple lock to establish our priority for the tuple, or die
+		 * trying.  LockTuple will release us when we are next-in-line for the
+		 * tuple.  We must do this even if we are share-locking.
+		 *
+		 * If we are forced to "start over" below, we keep the tuple lock;
+		 * this arranges that we stay at the head of the line while rechecking
+		 * tuple state.
+		 */
+		if (!heap_acquire_tuplock(relation, &zhtup->t_self, mode, wait_policy,
+								  have_tuple_lock))
+		{
+			/*
+			 * This can only happen if wait_policy is Skip and the lock
+			 * couldn't be obtained.
+			 */
+			*result = TM_WouldBlock;
+			/* recovery code expects to have buffer lock held */
+			LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+			return LOCK_WAIT_FAILED;
+		}
+
+		if (ZHeapTupleHasMultiLockers(infomask))
+		{
+			LockTupleMode old_lock_mode;
+			TransactionId update_xact;
+
+			old_lock_mode = get_old_lock_mode(infomask);
+
+			/*
+			 * For aborted updates, we must allow to reverify the tuple in
+			 * case it's values got changed.
+			 */
+			if (!ZHEAP_XID_IS_LOCKED_ONLY(infomask))
+				update_xact = ZHeapTupleGetTransXID(zhtup, buffer, true);
+			else
+				update_xact = InvalidTransactionId;
+
+			if (DoLockModesConflict(HWLOCKMODE_from_locktupmode(old_lock_mode),
+									HWLOCKMODE_from_locktupmode(mode)))
+			{
+				/*
+				 * There is a potential conflict.  It is quite possible that
+				 * by this time the locker has already been committed. So we
+				 * need to check for conflict with all the possible lockers
+				 * and wait for each of them.
+				 */
+				mlmembers = ZGetMultiLockMembers(relation, zhtup,
+												 buffer, true);
+
+				/* wait for multixact to end, or die trying  */
+				switch (wait_policy)
+				{
+					case LockWaitBlock:
+						ZMultiLockMembersWait(relation, mlmembers, zhtup,
+											  buffer, update_xact, mode,
+											  false, XLTW_Lock, NULL,
+											  &upd_xact_aborted);
+						break;
+					case LockWaitSkip:
+						if (!ConditionalZMultiLockMembersWait(relation,
+															  mlmembers,
+															  buffer,
+															  update_xact,
+															  mode,
+															  NULL,
+															  &upd_xact_aborted))
+						{
+							*result = TM_WouldBlock;
+
+							/*
+							 * recovery code expects to have buffer lock held
+							 */
+							LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+							return LOCK_WAIT_FAILED;
+						}
+						break;
+					case LockWaitError:
+						if (!ConditionalZMultiLockMembersWait(relation,
+															  mlmembers,
+															  buffer,
+															  update_xact,
+															  mode,
+															  NULL,
+															  &upd_xact_aborted))
+							ereport(ERROR,
+									(errcode(ERRCODE_LOCK_NOT_AVAILABLE),
+									 errmsg("could not obtain lock on row in relation \"%s\"",
+											RelationGetRelationName(relation))));
+
+						break;
+				}
+			}
+		}
+		else
+		{
+			/* wait for regular transaction to end, or die trying */
+			switch (wait_policy)
+			{
+				case LockWaitBlock:
+					{
+						if (xwait_subxid != InvalidSubTransactionId)
+							SubXactLockTableWait(xwait, xwait_subxid, relation,
+												 &zhtup->t_self, XLTW_Lock);
+						else
+							XactLockTableWait(xwait, relation, &zhtup->t_self,
+											  XLTW_Lock);
+					}
+					break;
+				case LockWaitSkip:
+					if (xwait_subxid != InvalidSubTransactionId)
+					{
+						if (!ConditionalSubXactLockTableWait(xwait, xwait_subxid))
+						{
+							*result = TM_WouldBlock;
+
+							/*
+							 * recovery code expects to have buffer lock held
+							 */
+							LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+							return LOCK_WAIT_FAILED;
+						}
+					}
+					else if (!ConditionalXactLockTableWait(xwait))
+					{
+						*result = TM_WouldBlock;
+						/* recovery code expects to have buffer lock held */
+						LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+						return LOCK_WAIT_FAILED;
+					}
+					break;
+				case LockWaitError:
+					if (xwait_subxid != InvalidSubTransactionId)
+					{
+						if (!ConditionalSubXactLockTableWait(xwait, xwait_subxid))
+							ereport(ERROR,
+									(errcode(ERRCODE_LOCK_NOT_AVAILABLE),
+									 errmsg("could not obtain lock on row in relation \"%s\"",
+											RelationGetRelationName(relation))));
+					}
+					else if (!ConditionalXactLockTableWait(xwait))
+						ereport(ERROR,
+								(errcode(ERRCODE_LOCK_NOT_AVAILABLE),
+								 errmsg("could not obtain lock on row in relation \"%s\"",
+										RelationGetRelationName(relation))));
+					break;
+			}
+		}
+
+		/* if there are updates, follow the update chain */
+		if (follow_updates && !ZHEAP_XID_IS_LOCKED_ONLY(infomask))
+		{
+			TM_Result	res;
+
+			if (!ZHeapTupleIsMoved(zhtup->t_data->t_infomask) &&
+				!ItemPointerEquals(&zhtup->t_self, ctid))
+			{
+				res = zheap_lock_updated_tuple(relation, zhtup, ctid,
+											   fxid, mode, lockopr, cid,
+											   &rollback_and_relocked);
+
+				/*
+				 * If the update was by some aborted transaction and its
+				 * pending undo actions are applied now, then check the latest
+				 * copy of the tuple.
+				 */
+				if (rollback_and_relocked)
+				{
+					LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+					return LOCK_WAIT_RECHECK;
+				}
+				else if (res != TM_Ok)
+				{
+					*result = res;
+					/* recovery code expects to have buffer lock held */
+					LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+					return LOCK_WAIT_FAILED;
+				}
+			}
+		}
+
+		LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+
+		/*
+		 * Also take care of cases when page is pruned after we release the
+		 * buffer lock. For this we check if ItemId is not deleted and refresh
+		 * the tuple offset position in page.  If TID is already delete marked
+		 * due to pruning, then get new ctid, so that we can lock the new
+		 * tuple.
+		 */
+		if (ItemIdIsDeleted(lp))
+			return LOCK_WAIT_RECHECK;
+
+		if (ZHeapTupleHasMultiLockers(infomask))
+		{
+			List	   *new_mlmembers;
+
+			/*
+			 * If the aborted xact is for update, then we need to reverify the
+			 * tuple.
+			 */
+			if (upd_xact_aborted)
+				return LOCK_WAIT_RECHECK;
+
+			new_mlmembers = ZGetMultiLockMembers(relation, zhtup,
+												 buffer, false);
+
+			/*
+			 * Ensure, no new lockers have been added, if so, then start
+			 * again.
+			 */
+			if (!ZMultiLockMembersSame(mlmembers, new_mlmembers))
+			{
+				list_free_deep(mlmembers);
+				list_free_deep(new_mlmembers);
+				return LOCK_WAIT_RECHECK;
+			}
+
+			*any_multi_locker_member_alive =
+				ZIsAnyMultiLockMemberRunning(relation, xwait_trans_slot,
+											 new_mlmembers, zhtup,
+											 buffer,
+											 &pending_actions_applied);
+			list_free_deep(mlmembers);
+			list_free_deep(new_mlmembers);
+		}
+
+		/*
+		 * xwait is done, but if xwait had just locked the tuple then some
+		 * other xact could update/lock this tuple before we get to this
+		 * point.  Check for xid change, and start over if so.  We need to do
+		 * some special handling for lockers because their xid is never stored
+		 * on the tuples.  If there was a single locker on the tuple and that
+		 * locker is gone and some new locker has locked the tuple, we won't
+		 * be able to identify that by infomask/xid on the tuple, rather we
+		 * need to fetch the locker xid.
+		 */
+		if (pending_actions_applied || !RefetchAndCheckTupleStatus(relation,
+																   buffer, infomask,
+																   tup_xid, single_locker_xid,
+																   NULL, zhtup))
+			return LOCK_WAIT_RECHECK;
+	}
+
+	if (TransactionIdIsValid(xwait) && TransactionIdDidAbort(xwait))
+	{
+		/*
+		 * For aborted transaction, if the undo actions are not applied yet,
+		 * then apply them before modifying the page.
+		 */
+		if (!TransactionIdIsCurrentTransactionId(xwait))
+			zheap_exec_pending_rollback(relation, buffer, xwait_trans_slot,
+										xwait, NULL);
+
+		if (!RefetchAndCheckTupleStatus(relation, buffer, infomask,
+										tup_xid, single_locker_xid,
+										NULL, zhtup))
+			return LOCK_WAIT_RECHECK;
+	}
+
+	/*
+	 * We may lock if previous xid committed or aborted but only locked the
+	 * tuple without updating it; or if we didn't have to wait at all for
+	 * whatever reason.
+	 */
+	if (!require_sleep ||
+		ZHEAP_XID_IS_LOCKED_ONLY(zhtup->t_data->t_infomask) ||
+		*result == TM_Ok)
+		*result = TM_Ok;
+	else
+		*result = TM_Updated;
+
+	return LOCK_WAIT_SUCCESS;
+}
+
+/*
+ * test_lockmode_for_conflict - Helper function for zheap_lock_updated_tuple.
+ *
+ * Given a lockmode held by the transaction identified with the given xid,
+ * does the current transaction need to wait, fail, or can it continue if
+ * it wanted to acquire a lock of the given mode (required_mode)?  "needwait"
+ * is set to true if waiting is necessary; if it can continue, then
+ * TM_Ok is returned.  To notify the caller if some pending
+ * rollback is applied, rollback_and_relocked is set to true.
+ */
+static TM_Result
+test_lockmode_for_conflict(Relation rel, Buffer buf, ZHeapTuple zhtup,
+						   UndoRecPtr urec_ptr, LockTupleMode old_mode,
+						   TransactionId xid, int trans_slot_id,
+						   LockTupleMode required_mode, bool has_update,
+						   SubTransactionId *subxid, bool *needwait,
+						   bool *rollback_and_relocked)
+{
+	*needwait = false;
+
+	/*
+	 * Note: we *must* check TransactionIdIsInProgress before
+	 * TransactionIdDidAbort/Commit; see comment at top of tqual.c for an
+	 * explanation.
+	 */
+	if (TransactionIdIsCurrentTransactionId(xid))
+	{
+		/*
+		 * The tuple has already been locked by our own transaction.  This is
+		 * very rare but can happen if multiple transactions are trying to
+		 * lock an ancient version of the same tuple.
+		 */
+		return TM_SelfModified;
+	}
+	else if (TransactionIdIsInProgress(xid))
+	{
+		/*
+		 * If the locking transaction is running, what we do depends on
+		 * whether the lock modes conflict: if they do, then we must wait for
+		 * it to finish; otherwise we can fall through to lock this tuple
+		 * version without waiting.
+		 */
+		if (DoLockModesConflict(HWLOCKMODE_from_locktupmode(old_mode),
+								HWLOCKMODE_from_locktupmode(required_mode)))
+		{
+			OffsetNumber offnum = ItemPointerGetOffsetNumber(&zhtup->t_self);
+
+			*needwait = true;
+			if (subxid)
+				ZHeapTupleGetSubXid(buf, offnum, urec_ptr, subxid);
+		}
+
+		/*
+		 * If we set needwait above, then this value doesn't matter;
+		 * otherwise, this value signals to caller that it's okay to proceed.
+		 */
+		return TM_Ok;
+	}
+	else if (TransactionIdDidAbort(xid))
+	{
+		/*
+		 * For aborted transaction, if the undo actions are not applied yet,
+		 * then apply them before modifying the page.
+		 */
+		zheap_exec_pending_rollback(rel, buf, trans_slot_id, xid, NULL);
+
+		/*
+		 * If it was only a locker, then the lock is completely gone now and
+		 * we can return success; but if it was an update, then after applying
+		 * pending actions, the tuple might have changed and we must report
+		 * error to the caller.  It will allow caller to reverify the tuple in
+		 * case it's values got changed.
+		 */
+
+		*rollback_and_relocked = true;
+
+		return TM_Ok;
+	}
+	else if (TransactionIdDidCommit(xid))
+	{
+		/*
+		 * The other transaction committed.  If it was only a locker, then the
+		 * lock is completely gone now and we can return success; but if it
+		 * was an update, then what we do depends on whether the two lock
+		 * modes conflict.  If they conflict, then we must report error to
+		 * caller. But if they don't, we can fall through to allow the current
+		 * transaction to lock the tuple.
+		 *
+		 * Note: the reason we worry about has_update here is because as soon
+		 * as a transaction ends, all its locks are gone and meaningless, and
+		 * thus we can ignore them; whereas its updates persist.  In the
+		 * TransactionIdIsInProgress case, above, we don't need to check
+		 * because we know the lock is still "alive" and thus a conflict needs
+		 * always be checked.
+		 */
+		if (!has_update)
+			return TM_Ok;
+
+		if (DoLockModesConflict(HWLOCKMODE_from_locktupmode(old_mode),
+								HWLOCKMODE_from_locktupmode(required_mode)))
+			/* bummer */
+			return TM_Updated;
+
+		return TM_Ok;
+	}
+
+	/* Not in progress, not aborted, not committed -- must have crashed */
+	return TM_Ok;
+}
+
+/*
+ * zheap_lock_updated_tuple - Lock all the versions of updated tuple.
+ *
+ * Fetch the tuple pointed to by tid in rel, reserve transaction slot on a
+ * page for a given and mark it as locked by the given xid with the given
+ * mode; if this tuple is updated, recurse to lock the new version as well.
+ * During chain traversal, we might find some intermediate version which
+ * is pruned (due to non-inplace-update got committed and the version only
+ * has line pointer), so we need to continue fetching the newer versions
+ * to lock them.  The bool rolled_and_relocked is used to notify the caller
+ * that the update has been performed by an aborted transaction and it's
+ * pending undo actions are applied here.
+ *
+ * Note that it is important to lock all the versions that are from
+ * non-committed transaction, but if the transaction that has created the
+ * new version is committed, we only care to lock its latest version.
+ *
+ */
+static TM_Result
+zheap_lock_updated_tuple(Relation rel, ZHeapTuple tuple, ItemPointer ctid,
+						 FullTransactionId fxid, LockTupleMode mode,
+						 LockOper lockopr, CommandId cid,
+						 bool *rollback_and_relocked)
+{
+	TM_Result	result;
+	ZHeapTuple	mytup;
+	UndoRecPtr	prev_urecptr;
+	Buffer		buf;
+	Page		page;
+	ItemPointerData tupid;
+	TransactionId priorXmax = InvalidTransactionId;
+	int			trans_slot_id;
+	bool		lock_reacquired;
+	bool		hasSubXactLock = false;
+	OffsetNumber offnum;
+	ZHeapTupleTransInfo zinfo;
+	ZHeapPrepareUndoInfo zh_undo_info;
+
+
+	ItemPointerCopy(ctid, &tupid);
+
+	if (rollback_and_relocked)
+		*rollback_and_relocked = false;
+
+	for (;;)
+	{
+		ZHeapTupleData zhtup;
+		ItemId		lp;
+		uint16		old_infomask;
+		UndoRecPtr	urec_ptr;
+
+		if (!zheap_fetch(rel, SnapshotAny, ctid, &mytup, &buf, false))
+		{
+			/*
+			 * if we fail to find the updated version of the tuple, it's
+			 * because it was vacuumed/pruned/rolled back away after its
+			 * creator transaction aborted.  So behave as if we got to the end
+			 * of the chain, and there's no further tuple to lock: return
+			 * success to caller.
+			 */
+			if (mytup == NULL)
+				return TM_Ok;
+
+			/*
+			 * If we reached the end of the chain, we're done, so return
+			 * success.  See EvalPlanQualZFetch for detailed reason.
+			 */
+			if (TransactionIdIsValid(priorXmax) &&
+				!ValidateTuplesXact(rel, mytup, SnapshotAny, buf,
+									priorXmax, true))
+				return TM_Ok;
+
+			/* deleted or moved to another partition, so forget about it */
+			if (ZHeapTupleIsMoved(mytup->t_data->t_infomask) ||
+				ItemPointerEquals(&(mytup->t_self), ctid))
+				return TM_Ok;
+
+			/* updated row should have xid matching this xmax */
+			priorXmax = ZHeapTupleGetTransXID(mytup, buf, true);
+
+			/* continue to lock the next version of tuple */
+			continue;
+		}
+
+lock_tuple:
+		urec_ptr = InvalidUndoRecPtr;
+
+		CHECK_FOR_INTERRUPTS();
+
+		LockBuffer(buf, BUFFER_LOCK_EXCLUSIVE);
+
+		/*
+		 * If we reached the end of the chain, we're done, so return success.
+		 * See EvalPlanQualZFetch for detailed reason.
+		 */
+		if (TransactionIdIsValid(priorXmax) &&
+			!ValidateTuplesXact(rel, mytup, SnapshotAny,
+								buf, priorXmax, false))
+		{
+			UnlockReleaseBuffer(buf);
+			return TM_Ok;
+		}
+
+		/*
+		 * Since we've reacquired the buffer lock, we should refetch the
+		 * tuple.
+		 */
+		page = BufferGetPage(buf);
+		offnum = ItemPointerGetOffsetNumber(&mytup->t_self);
+		lp = PageGetItemId(page, offnum);
+
+		/* free the old tuple */
+		zheap_freetuple(mytup);
+
+		/*
+		 * If this tuple was created by an aborted (sub)transaction and its
+		 * rollback got applied, then we already locked the last live one in
+		 * the chain, thus we're done, so return success. If tuple is dead,
+		 * then there is no need to lock it.
+		 */
+		if (!ItemIdIsUsed(lp) || ItemIdIsDead(lp))
+		{
+			result = TM_Ok;
+			goto out_locked;
+		}
+		else if (ItemIdIsDeleted(lp))
+		{
+			/* There is no point of locking a deleted and pruned tuple. */
+			ZHeapTupleFetch(rel, buf, offnum, SnapshotAny, &mytup, NULL);
+			ctid = &mytup->t_self;
+			ZHeapPageGetNewCtid(buf, ctid, &zinfo);
+			goto next;
+		}
+		else
+			mytup = zheap_gettuple(rel, buf, offnum);
+
+		ZHeapTupleGetTransInfo(buf, offnum, &zinfo);
+		urec_ptr = zinfo.urec_ptr;
+		old_infomask = mytup->t_data->t_infomask;
+
+		/*
+		 * If this tuple was created by an aborted (sub)transaction, then we
+		 * already locked the last live one in the chain, thus we're done, so
+		 * return success.
+		 */
+		if (!IsZHeapTupleModified(old_infomask) &&
+			TransactionIdDidAbort(zinfo.xid))
+		{
+			result = TM_Ok;
+			goto out_locked;
+		}
+
+		/*
+		 * If this tuple version has been updated or locked by some concurrent
+		 * transaction(s), what we do depends on whether our lock mode
+		 * conflicts with what those other transactions hold, and also on the
+		 * status of them.
+		 */
+		if (IsZHeapTupleModified(old_infomask))
+		{
+			SubTransactionId subxid = InvalidSubTransactionId;
+			LockTupleMode old_lock_mode;
+			bool		needwait;
+			bool		has_update = false;
+
+			if (ZHeapTupleHasMultiLockers(old_infomask))
+			{
+				List	   *mlmembers;
+				ListCell   *lc;
+				TransactionId update_xact = InvalidTransactionId;
+
+				/*
+				 * As we always maintain strongest lock mode on the tuple, it
+				 * must be pointing to the transaction id of the updater.
+				 */
+				if (!ZHEAP_XID_IS_LOCKED_ONLY(old_infomask))
+					update_xact = zinfo.xid;
+
+				mlmembers = ZGetMultiLockMembers(rel, mytup, buf, false);
+				foreach(lc, mlmembers)
+				{
+					ZMultiLockMember *mlmember = (ZMultiLockMember *) lfirst(lc);
+
+					if (TransactionIdIsValid(update_xact))
+					{
+						has_update = (update_xact == mlmember->xid) ?
+							true : false;
+					}
+
+					result = test_lockmode_for_conflict(rel,
+														buf,
+														NULL,
+														InvalidUndoRecPtr,
+														mlmember->mode,
+														mlmember->xid,
+														mlmember->trans_slot_id,
+														mode, has_update,
+														NULL,
+														&needwait,
+														rollback_and_relocked);
+
+					/*
+					 * If the update was by some aborted transaction with
+					 * pending rollback, then it's undo actions are applied.
+					 * Now, notify the caller to check for the latest copy of
+					 * the tuple.
+					 */
+					if (*rollback_and_relocked)
+					{
+						list_free_deep(mlmembers);
+						goto out_locked;
+					}
+
+					if (result == TM_SelfModified)
+					{
+						list_free_deep(mlmembers);
+						goto next;
+					}
+
+					if (needwait)
+					{
+						LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+
+						if (mlmember->subxid != InvalidSubTransactionId)
+							SubXactLockTableWait(mlmember->xid, mlmember->subxid,
+												 rel, &mytup->t_self,
+												 XLTW_LockUpdated);
+						else
+							XactLockTableWait(mlmember->xid, rel,
+											  &mytup->t_self,
+											  XLTW_LockUpdated);
+
+						list_free_deep(mlmembers);
+						goto lock_tuple;
+					}
+					if (result != TM_Ok)
+					{
+						list_free_deep(mlmembers);
+						goto out_locked;
+					}
+				}
+			}
+			else
+			{
+				/*
+				 * For a non-multi locker, we first need to compute the
+				 * corresponding lock mode by using the infomask bits.
+				 */
+				if (ZHEAP_XID_IS_LOCKED_ONLY(old_infomask))
+				{
+					/*
+					 * We don't expect to lock updated version of a tuple if
+					 * there is only a single locker on the tuple and previous
+					 * modifier is all-visible.
+					 */
+					Assert(!(zinfo.trans_slot == ZHTUP_SLOT_FROZEN ||
+							 FullTransactionIdOlderThanAllUndo(zinfo.epoch_xid)));
+
+					if (ZHEAP_XID_IS_KEYSHR_LOCKED(old_infomask))
+						old_lock_mode = LockTupleKeyShare;
+					else if (ZHEAP_XID_IS_SHR_LOCKED(old_infomask))
+						old_lock_mode = LockTupleShare;
+					else if (ZHEAP_XID_IS_NOKEY_EXCL_LOCKED(old_infomask))
+						old_lock_mode = LockTupleNoKeyExclusive;
+					else if (ZHEAP_XID_IS_EXCL_LOCKED(old_infomask))
+						old_lock_mode = LockTupleExclusive;
+					else
+					{
+						/* LOCK_ONLY can't be present alone */
+						pg_unreachable();
+					}
+				}
+				else
+				{
+					has_update = true;
+					/* it's an update, but which kind? */
+					if (old_infomask & ZHEAP_XID_EXCL_LOCK)
+						old_lock_mode = LockTupleExclusive;
+					else
+						old_lock_mode = LockTupleNoKeyExclusive;
+				}
+
+				result = test_lockmode_for_conflict(rel, buf, mytup, urec_ptr,
+													old_lock_mode, zinfo.xid,
+													zinfo.trans_slot, mode,
+													has_update, &subxid,
+													&needwait,
+													rollback_and_relocked);
+
+				/*
+				 * If the update was by some aborted transaction with pending
+				 * rollback, then it's undo actions are applied. Now, notify
+				 * the caller to check for the latest copy of the tuple.
+				 */
+				if (*rollback_and_relocked)
+					goto out_locked;
+
+				/*
+				 * If the tuple was already locked by ourselves in a previous
+				 * iteration of this (say zheap_lock_tuple was forced to
+				 * restart the locking loop because of a change in xid), then
+				 * we hold the lock already on this tuple version and we don't
+				 * need to do anything; and this is not an error condition
+				 * either.  We just need to skip this tuple and continue
+				 * locking the next version in the update chain.
+				 */
+				if (result == TM_SelfModified)
+					goto next;
+
+				if (needwait)
+				{
+					LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+					if (subxid != InvalidSubTransactionId)
+						SubXactLockTableWait(zinfo.xid, subxid, rel,
+											 &mytup->t_self,
+											 XLTW_LockUpdated);
+					else
+						XactLockTableWait(zinfo.xid, rel, &mytup->t_self,
+										  XLTW_LockUpdated);
+					goto lock_tuple;
+				}
+				if (result != TM_Ok)
+				{
+					goto out_locked;
+				}
+			}
+		}
+
+		offnum = ItemPointerGetOffsetNumber(&mytup->t_self);
+
+		/*
+		 * The transaction information of tuple needs to be set in transaction
+		 * slot, so needs to reserve the slot before proceeding with the
+		 * actual operation.  It will be costly to wait for getting the slot,
+		 * but we do that by releasing the buffer lock.
+		 */
+		trans_slot_id = PageReserveTransactionSlot(rel, buf,
+												   PageGetMaxOffsetNumber(BufferGetPage(buf)),
+												   fxid, &prev_urecptr, &lock_reacquired, false,
+												   InvalidBuffer, NULL);
+		if (lock_reacquired)
+		{
+			LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+			goto lock_tuple;
+		}
+
+		if (trans_slot_id == InvalidXactSlotId)
+		{
+			LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+
+			pgstat_report_wait_start(PG_WAIT_PAGE_TRANS_SLOT);
+			pg_usleep(10000L);	/* 10 ms */
+			pgstat_report_wait_end();
+
+			goto lock_tuple;
+		}
+
+		/* transaction slot must be reserved before locking a tuple */
+		Assert(trans_slot_id != InvalidXactSlotId);
+
+		page = BufferGetPage(buf);
+		lp = PageGetItemId(page, offnum);
+
+		Assert(ItemIdIsNormal(lp));
+
+		/*
+		 * It's possible that tuple slot is now marked as frozen. Hence, we
+		 * refetch the tuple here.
+		 */
+		zhtup.t_data = (ZHeapTupleHeader) PageGetItem(page, lp);
+		zhtup.t_len = ItemIdGetLength(lp);
+		zhtup.t_tableOid = mytup->t_tableOid;
+		zhtup.t_self = mytup->t_self;
+
+		/*
+		 * If the slot is marked as frozen, the latest modifier of the tuple
+		 * must be frozen.
+		 */
+		if (ZHeapTupleHeaderGetXactSlot((ZHeapTupleHeader) (zhtup.t_data)) == ZHTUP_SLOT_FROZEN)
+		{
+			zinfo.trans_slot = ZHTUP_SLOT_FROZEN;
+			zinfo.xid = InvalidTransactionId;
+		}
+
+		/*
+		 * Acquire subtransaction lock, if current transaction is a
+		 * subtransaction.
+		 */
+		if (IsSubTransaction())
+		{
+			SubXactLockTableInsert(GetCurrentSubTransactionId());
+			hasSubXactLock = true;
+		}
+
+		/*
+		 * Prepare an undo record for this operation.  While locking the
+		 * tuple, we set the command id as FirstCommandId since it doesn't
+		 * modify the tuple, just updates the infomask.
+		 */
+		zh_undo_info.reloid = rel->rd_id;
+		zh_undo_info.blkno = BufferGetBlockNumber(buf);
+		zh_undo_info.offnum = ItemPointerGetOffsetNumber(&(zhtup.t_self));
+		zh_undo_info.prev_urecptr = prev_urecptr;
+		zh_undo_info.fxid = fxid;
+		zh_undo_info.cid = FirstCommandId;
+		zh_undo_info.undo_persistence = UndoPersistenceForRelation(rel);
+
+		(void) zheap_lock_tuple_guts(buf, &zhtup, &zinfo,
+									 InvalidTransactionId, fxid, trans_slot_id,
+									 mode, lockopr, hasSubXactLock,
+									 false, RelationNeedsWAL(rel),
+									 &zh_undo_info, NULL);
+
+next:
+
+		/*
+		 * if we find the end of update chain, or if the transaction that has
+		 * updated the tuple is aborter, we're done.
+		 */
+		if (TransactionIdDidAbort(zinfo.xid) ||
+			ZHeapTupleIsMoved(zhtup.t_data->t_infomask) ||
+			ItemPointerEquals(&zhtup.t_self, ctid) ||
+			ZHEAP_XID_IS_LOCKED_ONLY(zhtup.t_data->t_infomask))
+		{
+			result = TM_Ok;
+			goto out_locked;
+		}
+
+		/*
+		 * Updated row should have xid matching this xmax.
+		 *
+		 * XXX Using zinfo.xid will work as this must be the xid of updater if
+		 * any on the tuple; that is because we always maintain the strongest
+		 * locker information on the tuple.
+		 */
+		priorXmax = zinfo.xid;
+
+		/*
+		 * As we still hold a snapshot to which priorXmax is not visible,
+		 * neither the transaction slot on tuple can be marked as frozen nor
+		 * the corresponding undo be discarded.
+		 */
+		Assert(TransactionIdIsValid(priorXmax));
+
+		/* be tidy */
+		zheap_freetuple(mytup);
+		UnlockReleaseBuffer(buf);
+	}
+
+	result = TM_Ok;
+
+out_locked:
+	UnlockReleaseBuffer(buf);
+
+	return result;
+}
+
+/*
+ * zheap_lock_tuple_guts - Helper function for locking the tuple.
+ *
+ * It locks the tuple in given mode, writes an undo and WAL for the
+ * operation.
+ *
+ * It is the responsibility of caller to lock and unlock the buffer ('buf').
+ */
+static UndoRecPtr
+zheap_lock_tuple_guts(Buffer buf, ZHeapTuple zhtup, ZHeapTupleTransInfo *tup_info,
+					  TransactionId tup_single_locker_xid,
+					  FullTransactionId current_fxid, int current_trans_slot,
+					  LockTupleMode mode, LockOper lockopr, bool hasSubXactLock,
+					  bool clear_multi_locker, bool needs_wal,
+					  ZHeapPrepareUndoInfo *zh_undo_info,
+					  int *out_result_trans_slot)
+{
+	TransactionId oldestXidHavingUndo;
+	TransactionId tup_xid;
+	UndoRecPtr	urecptr;
+	UnpackedUndoRecord undorecord;
+	uint16		old_infomask;
+	uint16		new_infomask = 0;
+	int			result_trans_slot;
+	ZHeapPrepareLockUndoInfo zh_lock_undo_info;
+
+	/* Compute the new xid and infomask to store into the tuple. */
+	old_infomask = zhtup->t_data->t_infomask;
+
+	/*
+	 * If all the members were lockers and are all gone, we can do away with
+	 * the MULTI_LOCKERS bit.
+	 */
+	if (ZHeapTupleHasMultiLockers(old_infomask) && clear_multi_locker)
+		old_infomask &= ~ZHEAP_MULTI_LOCKERS;
+
+	tup_xid = XidFromFullTransactionId(tup_info->epoch_xid);
+
+	compute_new_xid_infomask(zhtup, buf, tup_xid,
+							 tup_info->trans_slot,
+							 old_infomask,
+							 XidFromFullTransactionId(current_fxid),
+							 current_trans_slot,
+							 tup_single_locker_xid,
+							 mode,
+							 lockopr,
+							 &new_infomask,
+							 &result_trans_slot);
+
+	/*
+	 * If the last transaction that has updated the tuple is already too old,
+	 * then consider it as frozen which means it is all-visible.  This ensures
+	 * that we don't need to store epoch in the undo record to check if the
+	 * undo tuple belongs to previous epoch and hence all-visible.  See
+	 * comments atop of file zheapam_visibility.c.
+	 */
+	oldestXidHavingUndo = GetXidFromEpochXid(
+											 pg_atomic_read_u64(&ProcGlobal->oldestFullXidHavingUnappliedUndo));
+	if (TransactionIdPrecedes(tup_xid, oldestXidHavingUndo))
+		tup_xid = FrozenTransactionId;
+
+	/* Prepare undo info */
+	zh_lock_undo_info.gen_info = zh_undo_info;
+	zh_lock_undo_info.mode = mode;
+	zh_lock_undo_info.tup_hdr = (char *) zhtup->t_data;
+	zh_lock_undo_info.tup_trans_slot = tup_info->trans_slot;
+	zh_lock_undo_info.tup_xid = tup_xid;
+	zh_lock_undo_info.new_infomask = new_infomask;
+	zh_lock_undo_info.IsLockForUpdate = (lockopr == LockForUpdate);
+	zh_lock_undo_info.hasSubXactLock = hasSubXactLock;
+
+	urecptr = zheap_prepare_undolock(&zh_lock_undo_info, &undorecord, NULL);
+
+	START_CRIT_SECTION();
+
+	InsertPreparedUndo(&zh_undo_info->context);
+
+	/*
+	 * For lockers, we only set the slot on tuple when the lock mode is
+	 * LockForUpdate and the tuple doesn't have multilocker flag.  In that
+	 * case, pass set_tpd_map_slot as true, false otherwise.
+	 */
+	PageSetUNDO(undorecord, buf, current_trans_slot,
+				(undorecord.uur_type == UNDO_XID_LOCK_FOR_UPDATE),
+				current_fxid, urecptr, NULL, 0);
+
+	ZHeapTupleHeaderSetXactSlot(zhtup->t_data, result_trans_slot);
+	zhtup->t_data->t_infomask &= ~ZHEAP_VIS_STATUS_MASK;
+	zhtup->t_data->t_infomask |= new_infomask;
+
+	MarkBufferDirty(buf);
+
+	/* do xlog stuff */
+	if (needs_wal)
+	{
+		ZHeapWALInfo lock_wal_info;
+
+		lock_wal_info.buffer = buf;
+		lock_wal_info.ztuple = zhtup;
+		lock_wal_info.urecptr = urecptr;
+		lock_wal_info.prev_urecptr = zh_undo_info->prev_urecptr;
+		lock_wal_info.new_trans_slot_id = result_trans_slot;
+		lock_wal_info.prior_trans_slot_id = tup_info->trans_slot;
+		lock_wal_info.all_visible_cleared = false;
+		lock_wal_info.undorecord = &undorecord;
+		lock_wal_info.context = &zh_undo_info->context;
+
+		log_zheap_lock_tuple(&lock_wal_info, tup_xid,
+							 current_trans_slot,
+							 hasSubXactLock,
+							 mode);
+	}
+	END_CRIT_SECTION();
+
+	pfree(undorecord.uur_tuple.data);
+	pfree(undorecord.uur_payload.data);
+	FinishUndoRecordInsert(&zh_undo_info->context);
+	UnlockReleaseTPDBuffers();
+
+	if (out_result_trans_slot)
+		*out_result_trans_slot = result_trans_slot;
+
+	/*
+	 * Return the latest undo record pointer where current record is inserted.
+	 */
+	return urecptr;
+}
+
+/*
+ * compute_new_xid_infomask - Given the old values of tuple header's infomask,
+ * compute the new values for tuple header which includes lock mode, new
+ * infomask and transaction slot.
+ *
+ * We don't clear the multi lockers bit in this function as for that we need
+ * to ensure that all the lockers are gone.  Unfortunately, it is not easy to
+ * do that as we need to traverse all the undo chains for the current page to
+ * ensure the same and doing it here which is quite common code path doesn't
+ * seem advisable.  We clear this bit lazily when we detect the conflict and
+ * we anyway need to traverse the undo chains for the page.
+ *
+ * We ensure that the tuple always point to the transaction slot of latest
+ * inserter/updater except for cases where we lock first and then update the
+ * tuple (aka locks via EvalPlanQual mechanism).  This is because for visibility
+ * checks, we only need inserter/updater's xact information.  Keeping their
+ * slot on the tuple avoids the overheads of fetching xact information from
+ * undo during visibility checks.  Also, note that the latest inserter/updater
+ * can be an aborted transaction whose rollback actions are still pending.
+ *
+ * For example, say after a committed insert/update, a new request arrives to
+ * lock the tuple in key share mode, we will keep the inserter's/updater's slot
+ * on the tuple and set the multi-locker and key-share bit.  If the inserter/
+ * updater is already known to be having a frozen slot (visible to every one),
+ * we will set the key-share locker bit and the tuple will indicate a frozen
+ * slot.  Similarly, for a new updater, if the tuple has a single locker, then
+ * the undo will have a frozen tuple and for multi-lockers, the undo of updater
+ * will have previous inserter/updater slot; in both cases the new tuple will
+ * point to the updaters slot.  Now, the rollback of a single locker will set
+ * the frozen slot on tuple and the rollback of multi-locker won't change slot
+ * information on tuple.  We don't want to keep the slot of locker on the
+ * tuple as after rollback, we will lose track of last updater/inserter.
+ *
+ * When we are locking for the purpose of updating the tuple, we don't need
+ * to preserve previous updater's information and we also keep the latest
+ * slot on tuple.  This is only true when there are no previous lockers on
+ * the tuple.
+ */
+static void
+compute_new_xid_infomask(ZHeapTuple zhtup, Buffer buf, TransactionId tup_xid,
+						 int tup_trans_slot, uint16 old_infomask,
+						 TransactionId add_to_xid, int trans_slot,
+						 TransactionId single_locker_xid, LockTupleMode mode,
+						 LockOper lockoper, uint16 *result_infomask,
+						 int *result_trans_slot)
+{
+	int			new_trans_slot;
+	uint16		new_infomask;
+	bool		old_tuple_has_update = false;
+	bool		is_update = false;
+
+	Assert(TransactionIdIsValid(add_to_xid));
+
+	new_infomask = 0;
+	new_trans_slot = trans_slot;
+	is_update = (lockoper == ForUpdate || lockoper == LockForUpdate);
+
+	if ((IsZHeapTupleModified(old_infomask) &&
+		 TransactionIdIsInProgress(tup_xid)) ||
+		ZHeapTupleHasMultiLockers(old_infomask))
+	{
+		ZGetMultiLockInfo(old_infomask, tup_xid, tup_trans_slot,
+						  add_to_xid, &new_infomask, &new_trans_slot,
+						  &mode, &old_tuple_has_update, lockoper);
+	}
+	else if (!is_update &&
+			 TransactionIdIsInProgress(single_locker_xid))
+	{
+		LockTupleMode old_mode;
+
+		/*
+		 * When there is a single in-progress locker on the tuple and previous
+		 * inserter/updater became all visible, we've to set multi-locker flag
+		 * and highest lock mode. If current transaction tries to reacquire a
+		 * lock, we don't set multi-locker flag.
+		 */
+		Assert(ZHEAP_XID_IS_LOCKED_ONLY(old_infomask));
+		if (single_locker_xid != add_to_xid)
+		{
+			new_infomask |= ZHEAP_MULTI_LOCKERS;
+			new_trans_slot = tup_trans_slot;
+		}
+
+		old_mode = get_old_lock_mode(old_infomask);
+
+		/* Acquire the strongest of both. */
+		if (mode < old_mode)
+			mode = old_mode;
+
+		/* Keep the old tuple slot as it is */
+		new_trans_slot = tup_trans_slot;
+	}
+	else if (!is_update &&
+			 TransactionIdIsInProgress(tup_xid))
+	{
+		/*
+		 * Normally if the tuple is not modified and the current transaction
+		 * is in progress, the other transaction can't lock the tuple except
+		 * itself.
+		 *
+		 * However, this can happen while locking the updated tuple chain.  We
+		 * keep the transaction slot of original tuple as that will allow us
+		 * to check the visibility of tuple by just referring the current
+		 * transaction slot.
+		 */
+		Assert((tup_xid == add_to_xid) || (mode == LockTupleKeyShare));
+
+		if (tup_xid != add_to_xid)
+			new_infomask |= ZHEAP_MULTI_LOCKERS;
+
+		new_trans_slot = tup_trans_slot;
+	}
+	else if (!is_update &&
+			 tup_trans_slot == ZHTUP_SLOT_FROZEN)
+	{
+		/*
+		 * It's a frozen update or insert, so the locker must not change the
+		 * slot on a tuple.  The lockmode to be used on tuple is computed
+		 * below. There could be a single committed/aborted locker
+		 * (multilocker case is handled in the first condition). In that case,
+		 * we can ignore the locker. If the locker is still in progress, it'll
+		 * be handled in above case.
+		 */
+		new_trans_slot = ZHTUP_SLOT_FROZEN;
+	}
+	else if (!is_update &&
+			 !ZHEAP_XID_IS_LOCKED_ONLY(old_infomask) &&
+			 tup_trans_slot != ZHTUP_SLOT_FROZEN)
+	{
+		/*
+		 * It's a committed update/insert or an aborted update whose rollback
+		 * action is still pending, so we gotta preserve him as updater of the
+		 * tuple.  Also, indicate that tuple has multiple lockers.
+		 *
+		 * Note that tuple xid could be invalid if the undo records
+		 * corresponding to the tuple transaction is discarded.  In that case,
+		 * it can be considered as committed.
+		 */
+		new_infomask |= ZHEAP_MULTI_LOCKERS;
+		old_tuple_has_update = true;
+
+		if (ZHeapTupleIsInPlaceUpdated(old_infomask))
+			new_infomask |= ZHEAP_INPLACE_UPDATED;
+		else if (ZHeapTupleIsUpdated(old_infomask))
+			new_infomask |= ZHEAP_UPDATED;
+		else
+		{
+			/* This is a freshly inserted tuple. */
+			old_tuple_has_update = false;
+		}
+
+		if (!old_tuple_has_update)
+		{
+			/*
+			 * This is a freshly inserted tuple, allow to set the requested
+			 * lock mode on tuple.
+			 */
+		}
+		else
+		{
+			LockTupleMode old_mode;
+
+			if (ZHEAP_XID_IS_EXCL_LOCKED(old_infomask))
+				old_mode = LockTupleExclusive;
+			else if (ZHEAP_XID_IS_NOKEY_EXCL_LOCKED(old_infomask))
+				old_mode = LockTupleNoKeyExclusive;
+			else
+			{
+				/*
+				 * Tuple must not be locked in any other mode as we are here
+				 * because either the tuple is updated or inserted and the
+				 * corresponding transaction is committed.
+				 */
+				Assert(!(ZHEAP_XID_IS_KEYSHR_LOCKED(old_infomask) ||
+						 ZHEAP_XID_IS_SHR_LOCKED(old_infomask)));
+
+				old_mode = LockTupleNoKeyExclusive;
+			}
+
+			if (mode < old_mode)
+				mode = old_mode;
+		}
+
+		new_trans_slot = tup_trans_slot;
+	}
+	else if (!is_update &&
+			 ZHEAP_XID_IS_LOCKED_ONLY(old_infomask) &&
+			 tup_trans_slot != ZHTUP_SLOT_FROZEN)
+	{
+		LockTupleMode old_mode;
+
+		/*
+		 * This case arises for committed/aborted non-inplace updates where
+		 * the newly inserted tuple is marked as locked-only, but multi-locker
+		 * bit is not set.
+		 *
+		 * Note that tuple xid could be invalid if the undo records
+		 * corresponding to the tuple transaction is discarded.  In that case,
+		 * it can be considered as committed.
+		 */
+		new_infomask |= ZHEAP_MULTI_LOCKERS;
+
+		/* The tuple is locked-only. */
+		Assert(!(old_infomask &
+				 (ZHEAP_DELETED | ZHEAP_UPDATED | ZHEAP_INPLACE_UPDATED)));
+
+		old_mode = get_old_lock_mode(old_infomask);
+
+		/* Acquire the strongest of both. */
+		if (mode < old_mode)
+			mode = old_mode;
+
+		/* Keep the old tuple slot as it is */
+		new_trans_slot = tup_trans_slot;
+	}
+	else if (is_update &&
+			 TransactionIdIsValid(single_locker_xid) &&
+			 !TransactionIdDidCommit(single_locker_xid))
+	{
+		LockTupleMode old_mode;
+
+		/*
+		 * There can be a non-conflicting in-progress key share locker on the
+		 * tuple and we want to update the tuple in no-key exclusive mode.  In
+		 * that case, we should set the multilocker flag as well.
+		 *
+		 * Note that, the single locker xid can be aborted whose rollback
+		 * actions are still pending.  The scenario should be handled in the
+		 * same way as an in-progress single locker, i.e., we should set the
+		 * multilocker flag accordingly.  Else, the rollback of single locker
+		 * might resotre the infomask of the tuple incorrectly.
+		 */
+		Assert(ZHEAP_XID_IS_LOCKED_ONLY(old_infomask));
+		if (single_locker_xid != add_to_xid)
+		{
+			new_infomask |= ZHEAP_MULTI_LOCKERS;
+
+			/*
+			 * If the tuple has multilocker and we're locking the tuple for
+			 * update, we insert multilocker type of undo instead of
+			 * lock-for-update undo.  For multilocker undo, we keep the old
+			 * tuple slot as it is.
+			 */
+			if (lockoper == LockForUpdate)
+				new_trans_slot = tup_trans_slot;
+		}
+
+		old_mode = get_old_lock_mode(old_infomask);
+
+		/* Acquire the strongest of both. */
+		Assert(single_locker_xid == add_to_xid || mode > old_mode);
+		if (mode < old_mode)
+			mode = old_mode;
+	}
+
+	/*
+	 * For LockOnly mode and LockForUpdate mode with multilocker flag on the
+	 * tuple, we keep the old transaction slot as it is.  Since we're not
+	 * changing the xid slot in the tuple, we shouldn't remove the existing
+	 * (if any) invalid xact flag from the tuple.
+	 */
+	if (!is_update ||
+		((lockoper == LockForUpdate) && ZHeapTupleHasMultiLockers(new_infomask)))
+	{
+		if (ZHeapTupleHasInvalidXact(old_infomask))
+			new_infomask |= ZHEAP_INVALID_XACT_SLOT;
+	}
+
+
+	if (is_update && !ZHeapTupleHasMultiLockers(new_infomask))
+	{
+		if (lockoper == LockForUpdate)
+		{
+			/*
+			 * When we are locking for the purpose of updating the tuple, we
+			 * don't need to preserve previous updater's information.
+			 */
+			new_infomask |= ZHEAP_XID_LOCK_ONLY;
+			if (mode == LockTupleExclusive)
+				new_infomask |= ZHEAP_XID_EXCL_LOCK;
+			else
+				new_infomask |= ZHEAP_XID_NOKEY_EXCL_LOCK;
+		}
+		else if (mode == LockTupleExclusive)
+			new_infomask |= ZHEAP_XID_EXCL_LOCK;
+	}
+	else
+	{
+		if (lockoper != ForUpdate && !old_tuple_has_update)
+			new_infomask |= ZHEAP_XID_LOCK_ONLY;
+		switch (mode)
+		{
+			case LockTupleKeyShare:
+				new_infomask |= ZHEAP_XID_KEYSHR_LOCK;
+				break;
+			case LockTupleShare:
+				new_infomask |= ZHEAP_XID_SHR_LOCK;
+				break;
+			case LockTupleNoKeyExclusive:
+				new_infomask |= ZHEAP_XID_NOKEY_EXCL_LOCK;
+				break;
+			case LockTupleExclusive:
+				new_infomask |= ZHEAP_XID_EXCL_LOCK;
+				break;
+			default:
+				elog(ERROR, "invalid lock mode");
+		}
+	}
+
+	*result_infomask = new_infomask;
+
+	if (result_trans_slot)
+		*result_trans_slot = new_trans_slot;
+
+	/*
+	 * We store the reserved transaction slot only when we update the tuple.
+	 * For lock only, we keep the old transaction slot in the tuple.
+	 */
+	Assert(is_update || new_trans_slot == tup_trans_slot);
+}
+
+/*
+ *	zheap_finish_speculative - mark speculative insertion as successful
+ *
+ * To successfully finish a speculative insertion we have to clear speculative
+ * flag from tuple.  See heap_finish_speculative why it is important to clear
+ * the information of speculative insertion on tuple.
+ */
+void
+zheap_finish_speculative(Relation relation, ItemPointer tid)
+{
+	Buffer		buffer;
+	Page		page;
+	OffsetNumber offnum;
+	ItemId		lp = NULL;
+	ZHeapTupleHeader zhtup;
+
+	buffer = ReadBuffer(relation, ItemPointerGetBlockNumber(tid));
+	LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+	page = (Page) BufferGetPage(buffer);
+
+	offnum = ItemPointerGetOffsetNumber(tid);
+	if (PageGetMaxOffsetNumber(page) >= offnum)
+		lp = PageGetItemId(page, offnum);
+
+	if (PageGetMaxOffsetNumber(page) < offnum || !ItemIdIsNormal(lp))
+		elog(ERROR, "invalid lp");
+
+	zhtup = (ZHeapTupleHeader) PageGetItem(page, lp);
+
+	/* No ereport(ERROR) from here till changes are logged */
+	START_CRIT_SECTION();
+
+	Assert(ZHeapTupleHeaderIsSpeculative(zhtup));
+
+	MarkBufferDirty(buffer);
+
+	/* Clear the speculative insertion marking from the tuple. */
+	zhtup->t_infomask &= ~ZHEAP_SPECULATIVE_INSERT;
+
+	/* XLOG stuff */
+	if (RelationNeedsWAL(relation))
+	{
+		xl_zheap_confirm xlrec;
+		XLogRecPtr	recptr;
+
+		xlrec.offnum = ItemPointerGetOffsetNumber(tid);
+		xlrec.flags = XLZ_SPEC_INSERT_SUCCESS;
+
+		XLogBeginInsert();
+
+		/* We want the same filtering on this as on a plain insert */
+		XLogSetRecordFlags(XLOG_INCLUDE_ORIGIN);
+
+		XLogRegisterData((char *) &xlrec, SizeOfZHeapConfirm);
+		XLogRegisterBuffer(0, buffer, REGBUF_STANDARD);
+
+		recptr = XLogInsert(RM_ZHEAP2_ID, XLOG_ZHEAP_CONFIRM);
+
+		PageSetLSN(page, recptr);
+	}
+
+	END_CRIT_SECTION();
+
+	UnlockReleaseBuffer(buffer);
+}
+
+/*
+ *	zheap_abort_speculative - kill a speculatively inserted tuple
+ *
+ * Marks a tuple that was speculatively inserted in the same command as dead.
+ * That makes it immediately appear as dead to all transactions, including our
+ * own.  In particular, it makes another backend inserting a duplicate key
+ * value won't unnecessarily wait for our whole transaction to finish (it'll
+ * just wait for our speculative insertion to finish).
+ *
+ * The functionality is same as heap_abort_speculative, but we achieve it
+ * differently.
+ */
+void
+zheap_abort_speculative(Relation relation, ItemPointer tid)
+{
+	TransactionId xid = GetTopTransactionId();
+	ItemId		lp;
+	ZHeapTupleData tp;
+	ZHeapTupleHeader zhtuphdr;
+	Page		page;
+	BlockNumber block;
+	Buffer		buffer;
+	OffsetNumber offnum;
+	int			trans_slot_id;
+	ZHeapTupleTransInfo zinfo;
+
+	Assert(ItemPointerIsValid(tid));
+
+	block = ItemPointerGetBlockNumber(tid);
+	buffer = ReadBuffer(relation, block);
+	page = BufferGetPage(buffer);
+
+	LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+
+	offnum = ItemPointerGetOffsetNumber(tid);
+	lp = PageGetItemId(page, offnum);
+	Assert(ItemIdIsNormal(lp));
+
+	zhtuphdr = (ZHeapTupleHeader) PageGetItem(page, lp);
+
+	tp.t_tableOid = RelationGetRelid(relation);
+	tp.t_data = zhtuphdr;
+	tp.t_len = ItemIdGetLength(lp);
+	tp.t_self = *tid;
+
+	trans_slot_id = ZHeapTupleHeaderGetXactSlot(zhtuphdr);
+
+	/*
+	 * Sanity check that the tuple really is a speculatively inserted tuple,
+	 * inserted by us.
+	 */
+	GetTransactionSlotInfo(buffer, offnum, trans_slot_id, true, false,
+						   &zinfo);
+
+	/* As the transaction is still open, the slot can't be frozen. */
+	Assert(zinfo.trans_slot != ZHTUP_SLOT_FROZEN);
+	Assert(zinfo.xid != InvalidTransactionId);
+
+	if (zinfo.xid != xid)
+		elog(ERROR, "attempted to kill a tuple inserted by another transaction");
+	if (!(IsToastRelation(relation) || ZHeapTupleHeaderIsSpeculative(zhtuphdr)))
+		elog(ERROR, "attempted to kill a non-speculative tuple");
+	Assert(!IsZHeapTupleModified(zhtuphdr->t_infomask));
+
+	START_CRIT_SECTION();
+
+	/*
+	 * The tuple will become DEAD immediately.  However, we mark it dead
+	 * differently by keeping the trans_slot, to identify this is done during
+	 * speculative abort only.  Flag that this page is a candidate for
+	 * pruning.  The action here is exactly same as what we do for rolling
+	 * back insert.
+	 */
+	ItemIdSetDeadExtended(lp, trans_slot_id);
+	ZPageSetPrunable(page, xid);
+
+	MarkBufferDirty(buffer);
+
+	/*
+	 * XLOG stuff
+	 *
+	 * The WAL records generated here match heap_delete().  The same recovery
+	 * routines are used.
+	 */
+	if (RelationNeedsWAL(relation))
+	{
+		xl_zheap_confirm xlrec;
+		XLogRecPtr	recptr;
+
+		xlrec.offnum = ItemPointerGetOffsetNumber(tid);
+		xlrec.flags = XLZ_SPEC_INSERT_FAILED;
+		xlrec.trans_slot_id = trans_slot_id;
+
+		XLogBeginInsert();
+
+		XLogRegisterData((char *) &xlrec, SizeOfZHeapConfirm);
+		XLogRegisterBuffer(0, buffer, REGBUF_STANDARD);
+
+		/* No replica identity & replication origin logged */
+
+		recptr = XLogInsert(RM_ZHEAP2_ID, XLOG_ZHEAP_CONFIRM);
+
+		PageSetLSN(page, recptr);
+	}
+
+	END_CRIT_SECTION();
+
+	LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+
+	if (ZHeapTupleHasExternal(&tp))
+	{
+		Assert(!IsToastRelation(relation));
+		ztoast_delete(relation, &tp, true);
+	}
+
+	/*
+	 * Never need to mark tuple for invalidation, since catalogs don't support
+	 * speculative insertion
+	 */
+
+	/* Now we can release the buffer */
+	ReleaseBuffer(buffer);
+
+	/* count deletion, as we counted the insertion too */
+	pgstat_count_heap_delete(relation);
+}
+
+TransactionId
+zheap_fetchinsertxid(ZHeapTuple zhtup, Buffer buffer)
+{
+	int			trans_slot_id = InvalidXactSlotId;
+	TransactionId result;
+	BlockNumber blk;
+	OffsetNumber offnum;
+	UnpackedUndoRecord *urec;
+	ZHeapTupleHeaderData hdr;
+	ZHeapTupleTransInfo zinfo;
+
+	zinfo.trans_slot = ZHeapTupleHeaderGetXactSlot(zhtup->t_data);
+	blk = ItemPointerGetBlockNumber(&zhtup->t_self);
+	offnum = ItemPointerGetOffsetNumber(&zhtup->t_self);
+	GetTransactionSlotInfo(buffer, offnum, zinfo.trans_slot, true, false,
+						   &zinfo);
+	memcpy(&hdr, zhtup->t_data, SizeofZHeapTupleHeader);
+	zinfo.xid = InvalidTransactionId;
+
+	while (true)
+	{
+		urec = UndoFetchRecord(zinfo.urec_ptr, blk, offnum, zinfo.xid, NULL,
+							   ZHeapSatisfyUndoRecord);
+		if (urec == NULL)
+		{
+			/*
+			 * Undo record could be null only when it's undo log is/about to
+			 * be discarded. We cannot use any assert for checking is the log
+			 * is actually discarded, since UndoFetchRecord can return NULL
+			 * for the records which are not yet discarded but are about to be
+			 * discarded.
+			 */
+			result = FrozenTransactionId;
+			break;
+		}
+
+		/*
+		 * If we have valid undo record, then check if we have reached the
+		 * insert log and return the corresponding transaction id.
+		 */
+		if (urec->uur_type == UNDO_INSERT ||
+			urec->uur_type == UNDO_MULTI_INSERT ||
+			urec->uur_type == UNDO_INPLACE_UPDATE)
+		{
+			result = urec->uur_xid;
+			UndoRecordRelease(urec);
+			break;
+		}
+
+		trans_slot_id =
+			UpdateTupleHeaderFromUndoRecord(urec, &hdr, BufferGetPage(buffer));
+
+		zinfo.xid = urec->uur_prevxid;
+		zinfo.urec_ptr = urec->uur_blkprev;
+		UndoRecordRelease(urec);
+		if (!UndoRecPtrIsValid(zinfo.urec_ptr))
+		{
+			result = FrozenTransactionId;
+			break;
+		}
+
+
+		/*
+		 * Change the undo chain if the undo tuple is stamped with the
+		 * different transaction slot.
+		 */
+		if (trans_slot_id != zinfo.trans_slot)
+			ZHeapUpdateTransactionSlotInfo(trans_slot_id,
+										   buffer, offnum,
+										   &zinfo);
+	}
+
+	return result;
+}
+
+/*
+ * zheap_prepare_undoinsert - prepare the undo record for zheap insert
+ *	operation.
+ *
+ * Returns the undo record pointer (aka location) where the undo record
+ * will be inserted in undo log.  This function prepares and allocates
+ * additional memory required for undorecord.  The caller can modify the
+ * record fields, but can't allocate any new memory for it.
+ */
+UndoRecPtr
+zheap_prepare_undoinsert(ZHeapPrepareUndoInfo *zh_undo_info,
+						 uint32 specToken, bool specIns,
+						 UnpackedUndoRecord *undorecord,
+						 XLogReaderState *xlog_record)
+{
+	UndoRecPtr	urecptr = InvalidUndoRecPtr;
+
+	/*
+	 * Prepare an undo record.  Unlike other operations, insert operation
+	 * doesn't have a prior version to store in undo, so we don't need to
+	 * store any additional information like UREC_INFO_PAYLOAD_CONTAINS_SLOT
+	 * for TPD entries.
+	 */
+	undorecord->uur_rmid = RM_ZHEAP_ID;
+	undorecord->uur_type = UNDO_INSERT;
+	undorecord->uur_info = 0;
+	undorecord->uur_prevlen = 0;
+	undorecord->uur_reloid = zh_undo_info->reloid;
+	undorecord->uur_prevxid = FrozenTransactionId;
+	undorecord->uur_xid = XidFromFullTransactionId(zh_undo_info->fxid);
+	undorecord->uur_cid = zh_undo_info->cid;
+	undorecord->uur_fork = MAIN_FORKNUM;
+	undorecord->uur_blkprev = zh_undo_info->prev_urecptr;
+	undorecord->uur_block = zh_undo_info->blkno;
+	undorecord->uur_offset = zh_undo_info->offnum;
+	undorecord->uur_tuple.len = 0;
+
+	/*
+	 * Store the speculative insertion token in undo, so that we can retrieve
+	 * it during visibility check of the speculatively inserted tuples.
+	 *
+	 * Note that we don't need to WAL log this value as this is a temporary
+	 * information required only on master node to detect conflicts for Insert
+	 * .. On Conflict.
+	 */
+	if (specIns)
+	{
+		undorecord->uur_payload.len = sizeof(uint32);
+		initStringInfo(&undorecord->uur_payload);
+		appendBinaryStringInfo(&undorecord->uur_payload,
+							   (char *) &specToken,
+							   sizeof(uint32));
+	}
+	else
+		undorecord->uur_payload.len = 0;
+
+	BeginUndoRecordInsert(&zh_undo_info->context,
+						  zh_undo_info->undo_persistence,
+						  1,
+						  xlog_record);
+	urecptr = PrepareUndoInsert(&zh_undo_info->context, undorecord,
+								zh_undo_info->fxid);
+
+	return urecptr;
+}
+
+/*
+ * zheap_prepare_undoupdate - prepare the undo record for zheap update
+ *	operation.
+ *
+ * Returns the undo record pointer (aka location) where the undo record
+ * will be inserted in undo log and if it is a non-inplace update then
+ * new_recptr will hold the location of the new tuple entry.
+ */
+UndoRecPtr
+zheap_prepare_undoupdate(ZHeapPrepareUpdateUndoInfo *zh_undoinfo, ZHeapTuple zhtup,
+						 XLogReaderState *xlrec,
+						 UndoRecPtr *new_urecptr)
+{
+	UndoRecPtr	urecptr;
+	Size		payload_len = 0;
+	TransactionId xid = XidFromFullTransactionId(zh_undoinfo->gen_info->fxid);
+
+	/*
+	 * Prepare an undo record for old tuple.  We need to separately store the
+	 * latest transaction id that has changed the tuple to ensure that we
+	 * don't try to process the tuple in undo chain that is already discarded.
+	 * See GetTupleFromUndo.
+	 */
+	zh_undoinfo->old_undorec->uur_rmid = RM_ZHEAP_ID;
+	zh_undoinfo->old_undorec->uur_info = 0;
+	zh_undoinfo->old_undorec->uur_reloid = zh_undoinfo->gen_info->reloid;
+	zh_undoinfo->old_undorec->uur_prevxid = zh_undoinfo->prevxid;
+	zh_undoinfo->old_undorec->uur_xid = xid;
+	zh_undoinfo->old_undorec->uur_cid = zh_undoinfo->gen_info->cid;
+	zh_undoinfo->old_undorec->uur_fork = MAIN_FORKNUM;
+	zh_undoinfo->old_undorec->uur_blkprev = zh_undoinfo->gen_info->prev_urecptr;
+	zh_undoinfo->old_undorec->uur_block = zh_undoinfo->gen_info->blkno;
+	zh_undoinfo->old_undorec->uur_offset = zh_undoinfo->gen_info->offnum;
+	zh_undoinfo->old_undorec->uur_payload.len = 0;
+
+	initStringInfo(&(zh_undoinfo->old_undorec->uur_tuple));
+
+	/*
+	 * Copy the entire old tuple into the undo record. We need this to
+	 * reconstruct the old tuple if current tuple is not visible to some other
+	 * transaction.  We choose to write the complete tuple in undo record for
+	 * update operation so that we can reuse the space of old tuples for
+	 * non-inplace-updates after the transaction performing the operation
+	 * commits.
+	 */
+	appendBinaryStringInfo(&(zh_undoinfo->old_undorec->uur_tuple),
+						   (char *) zhtup->t_data,
+						   zhtup->t_len);
+
+	if (zh_undoinfo->inplace_update)
+	{
+		bool		hasPayload = false;
+
+		zh_undoinfo->old_undorec->uur_type = UNDO_INPLACE_UPDATE;
+
+		/*
+		 * Store the transaction slot number for undo tuple in undo record, if
+		 * the slot belongs to TPD entry.  We can always get the current
+		 * tuple's transaction slot number by referring offset->slot map in
+		 * TPD entry, however that won't be true for tuple in undo.
+		 */
+		if (zh_undoinfo->tup_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		{
+			zh_undoinfo->old_undorec->uur_info |= UREC_INFO_PAYLOAD_CONTAINS_SLOT;
+			initStringInfo(&(zh_undoinfo->old_undorec->uur_payload));
+			appendBinaryStringInfo(&(zh_undoinfo->old_undorec->uur_payload),
+								   (char *) &(zh_undoinfo->tup_trans_slot_id),
+								   sizeof(zh_undoinfo->tup_trans_slot_id));
+			hasPayload = true;
+		}
+
+		/*
+		 * Store subtransaction id in undo record.  See SubXactLockTableWait
+		 * to know why we need to store subtransaction id in undo.
+		 *
+		 * While in recovery, we store the dummy subxact token in the
+		 * undorecord so that, the size of undorecord in DO function matches
+		 * with the size of undorecord in REDO function. This ensures that the
+		 * undo pointer in DO and REDO function remains the same.
+		 */
+		if (zh_undoinfo->hasSubXactLock)
+		{
+			SubTransactionId subxid = (InRecovery) ? 1 : GetCurrentSubTransactionId();
+
+			if (!hasPayload)
+			{
+				initStringInfo(&(zh_undoinfo->old_undorec->uur_payload));
+				hasPayload = true;
+			}
+
+			zh_undoinfo->old_undorec->uur_info |= UREC_INFO_PAYLOAD_CONTAINS_SUBXACT;
+			appendBinaryStringInfo(&(zh_undoinfo->old_undorec->uur_payload),
+								   (char *) &subxid,
+								   sizeof(SubTransactionId));
+		}
+
+		if (!hasPayload)
+			zh_undoinfo->old_undorec->uur_payload.len = 0;
+
+/* ZDFIXME
+ * 		urecptr = PrepareUndoInsert(zh_undoinfo->old_undorec,
+									zh_undoinfo->gen_info->fxid,
+									zh_undoinfo->gen_info->undo_persistence,
+									xlrec);
+ */
+		BeginUndoRecordInsert(&zh_undoinfo->gen_info->context,
+							  zh_undoinfo->gen_info->undo_persistence,
+							  1,
+							  xlrec);
+		urecptr = PrepareUndoInsert(&zh_undoinfo->gen_info->context,
+									zh_undoinfo->old_undorec,
+									zh_undoinfo->gen_info->fxid);
+	}
+	else
+	{
+		UnpackedUndoRecord undorec[2];
+
+		zh_undoinfo->old_undorec->uur_type = UNDO_UPDATE;
+
+		/*
+		 * During recovery (REDO) all the payload information is filled but
+		 * during DO time only the payload length is calculated here as the
+		 * actual entry is made in the critical section in zheap_update.
+		 */
+		if (!InRecovery)
+		{
+			/*
+			 * We need to initialize the length of payload before actually
+			 * knowing the value to ensure that the required space is reserved
+			 * in undo.
+			 */
+			payload_len = sizeof(ItemPointerData);
+			if (zh_undoinfo->tup_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+			{
+				zh_undoinfo->old_undorec->uur_info |= UREC_INFO_PAYLOAD_CONTAINS_SLOT;
+				payload_len += sizeof(zh_undoinfo->tup_trans_slot_id);
+			}
+
+			/*
+			 * Store subtransaction id in undo record.  See
+			 * SubXactLockTableWait to know why we need to store
+			 * subtransaction id in undo.
+			 */
+			if (zh_undoinfo->hasSubXactLock)
+			{
+				zh_undoinfo->old_undorec->uur_info |= UREC_INFO_PAYLOAD_CONTAINS_SUBXACT;
+				payload_len += sizeof(SubTransactionId);
+			}
+
+			zh_undoinfo->old_undorec->uur_payload.len = payload_len;
+		}
+		else					/* during recovery */
+		{
+			initStringInfo(&zh_undoinfo->old_undorec->uur_payload);
+
+			/* update new tuple location in undo record */
+			appendBinaryStringInfo(&zh_undoinfo->old_undorec->uur_payload,
+								   (char *) &zh_undoinfo->recovery_tid,
+								   sizeof(ItemPointerData));
+
+			/* add the TPD slot id */
+			if (zh_undoinfo->tup_trans_slot_id != InvalidXactSlotId)
+			{
+				Assert(zh_undoinfo->tup_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS);
+				appendBinaryStringInfo(&zh_undoinfo->old_undorec->uur_payload,
+									   (char *) &(zh_undoinfo->tup_trans_slot_id),
+									   sizeof(zh_undoinfo->tup_trans_slot_id));
+			}
+
+			/*
+			 * For sub-transactions, we store the dummy contains subxact token
+			 * in the undorecord so that, the size of undorecord in DO
+			 * function matches with the size of undorecord in REDO function.
+			 * This ensures that, for sub-transactions, the assert condition
+			 * used later in this function to ensure that the undo pointer in
+			 * DO and REDO function remains the same is true.
+			 */
+			if (zh_undoinfo->hasSubXactLock)
+			{
+				SubTransactionId dummy_subXactToken = 1;
+
+				appendBinaryStringInfo(&(zh_undoinfo->old_undorec->uur_payload),
+									   (char *) &(dummy_subXactToken),
+									   sizeof(SubTransactionId));
+			}
+
+			zh_undoinfo->new_undorec->uur_offset =
+				ItemPointerGetOffsetNumber(zh_undoinfo->recovery_tid);
+		}
+
+		/* prepare an undo record for new tuple */
+		zh_undoinfo->new_undorec->uur_rmid = RM_ZHEAP_ID;
+		zh_undoinfo->new_undorec->uur_type = UNDO_INSERT;
+		zh_undoinfo->new_undorec->uur_info = 0;
+		zh_undoinfo->new_undorec->uur_reloid = zh_undoinfo->gen_info->reloid;
+		zh_undoinfo->new_undorec->uur_prevxid = xid;
+		zh_undoinfo->new_undorec->uur_xid = xid;
+		zh_undoinfo->new_undorec->uur_cid = zh_undoinfo->gen_info->cid;
+		zh_undoinfo->new_undorec->uur_fork = MAIN_FORKNUM;
+		zh_undoinfo->new_undorec->uur_block = zh_undoinfo->new_block;
+		zh_undoinfo->new_undorec->uur_payload.len = 0;
+		zh_undoinfo->new_undorec->uur_tuple.len = 0;
+
+		if (zh_undoinfo->new_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		{
+			zh_undoinfo->new_undorec->uur_info |= UREC_INFO_PAYLOAD_CONTAINS_SLOT;
+
+			initStringInfo(&(zh_undoinfo->new_undorec->uur_payload));
+			appendBinaryStringInfo(&(zh_undoinfo->new_undorec->uur_payload),
+								   (char *) &(zh_undoinfo->new_trans_slot_id),
+								   sizeof(zh_undoinfo->new_trans_slot_id));
+		}
+		else
+			zh_undoinfo->new_undorec->uur_payload.len = 0;
+
+		undorec[0] = *(zh_undoinfo->old_undorec);
+		undorec[1] = *(zh_undoinfo->new_undorec);
+/*
+ * ZDFIXME
+ * 		UndoSetPrepareSize(undorec, 2, zh_undoinfo->gen_info->fxid,
+						   zh_undoinfo->gen_info->undo_persistence, xlrec);
+*/		
+		BeginUndoRecordInsert(&zh_undoinfo->gen_info->context,
+							  zh_undoinfo->gen_info->undo_persistence,
+							  2,
+							  xlrec);
+
+		/* copy updated record (uur_info might be updated ) */
+		*(zh_undoinfo->old_undorec) = undorec[0];
+		*(zh_undoinfo->new_undorec) = undorec[1];
+
+		urecptr = PrepareUndoInsert(&zh_undoinfo->gen_info->context,
+									zh_undoinfo->old_undorec,
+									zh_undoinfo->gen_info->fxid);
+
+		/* During recovery, make more room for tuple location if needed. */
+		if (!InRecovery)
+		{
+			initStringInfo(&(zh_undoinfo->old_undorec->uur_payload));
+			enlargeStringInfo(&(zh_undoinfo->old_undorec->uur_payload), payload_len);
+		}
+
+		if (zh_undoinfo->same_buf)
+			zh_undoinfo->new_undorec->uur_blkprev = urecptr;
+		else
+			zh_undoinfo->new_undorec->uur_blkprev = zh_undoinfo->new_prev_urecptr;
+
+		*new_urecptr = PrepareUndoInsert(&zh_undoinfo->gen_info->context,
+										 zh_undoinfo->new_undorec,
+										 zh_undoinfo->gen_info->fxid);
+	}
+	return urecptr;
+}
+
+/*
+ * zheap_prepare_undodelete - prepare the undo record for zheap delete
+ *	operation.
+ *
+ * Returns the undo record pointer (aka location) where the undo record
+ * will be inserted in undo log.
+ */
+UndoRecPtr
+zheap_prepare_undodelete(ZHeapPrepareUndoInfo *zhUndoInfo, ZHeapTuple zhtup,
+						 TransactionId tup_xid, int tup_trans_slot_id,
+						 SubTransactionId subxid,
+						 UnpackedUndoRecord *undorecord,
+						 XLogReaderState *xlog_record)
+{
+	UndoRecPtr	urecptr = InvalidUndoRecPtr;
+	bool		hasPayload = false;
+
+	/*
+	 * Prepare an undo record.  We need to separately store the latest
+	 * transaction id that has changed the tuple to ensure that we don't try
+	 * to process the tuple in undo chain that is already discarded. See
+	 * GetTupleFromUndo.
+	 */
+	undorecord->uur_rmid = RM_ZHEAP_ID;
+	undorecord->uur_type = UNDO_DELETE;
+	undorecord->uur_info = 0;
+	undorecord->uur_reloid = zhUndoInfo->reloid;
+	undorecord->uur_prevxid = tup_xid;
+	undorecord->uur_xid = XidFromFullTransactionId(zhUndoInfo->fxid);
+	undorecord->uur_cid = zhUndoInfo->cid;
+	undorecord->uur_fork = MAIN_FORKNUM;
+	undorecord->uur_blkprev = zhUndoInfo->prev_urecptr;
+	undorecord->uur_block = zhUndoInfo->blkno;
+	undorecord->uur_offset = zhUndoInfo->offnum;
+
+	initStringInfo(&undorecord->uur_tuple);
+
+	/*
+	 * Copy the entire old tuple into the undo record. We need this to
+	 * reconstruct the tuple if current tuple is not visible to some other
+	 * transaction.  We choose to write the complete tuple in undo record for
+	 * delete operation so that we can reuse the space after the transaction
+	 * performing the operation commits.
+	 */
+	appendBinaryStringInfo(&undorecord->uur_tuple,
+						   (char *) zhtup->t_data,
+						   zhtup->t_len);
+
+	/*
+	 * Store the transaction slot number for undo tuple in undo record, if the
+	 * slot belongs to TPD entry.  We can always get the current tuple's
+	 * transaction slot number by referring offset->slot map in TPD entry,
+	 * however that won't be true for tuple in undo.
+	 */
+	if (tup_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+	{
+		undorecord->uur_info |= UREC_INFO_PAYLOAD_CONTAINS_SLOT;
+		initStringInfo(&undorecord->uur_payload);
+		appendBinaryStringInfo(&undorecord->uur_payload,
+							   (char *) &tup_trans_slot_id,
+							   sizeof(tup_trans_slot_id));
+		hasPayload = true;
+	}
+
+	/*
+	 * Store subtransaction id in undo record.  See SubXactLockTableWait to
+	 * know why we need to store subtransaction id in undo.
+	 */
+	if (subxid != InvalidSubTransactionId)
+	{
+		if (!hasPayload)
+		{
+			initStringInfo(&undorecord->uur_payload);
+			hasPayload = true;
+		}
+
+		undorecord->uur_info |= UREC_INFO_PAYLOAD_CONTAINS_SUBXACT;
+		appendBinaryStringInfo(&undorecord->uur_payload,
+							   (char *) &subxid,
+							   sizeof(subxid));
+	}
+
+	if (!hasPayload)
+		undorecord->uur_payload.len = 0;
+
+	BeginUndoRecordInsert(&zhUndoInfo->context,
+						  zhUndoInfo->undo_persistence,
+						  1,
+						  xlog_record);
+	urecptr = PrepareUndoInsert(&zhUndoInfo->context,
+								undorecord,
+								zhUndoInfo->fxid);
+
+	return urecptr;
+}
+
+/*
+ * zheap_prepare_undolock - prepare undo record for zheap lock operation.
+ *
+ * Returns the undo record pointer (aka location) where the undo record
+ * will be inserted in undo log.
+ */
+UndoRecPtr
+zheap_prepare_undolock(ZHeapPrepareLockUndoInfo *zh_undo_info,
+					   UnpackedUndoRecord *undorecord,
+					   XLogReaderState *xlog_record)
+{
+	UndoRecPtr	urecptr;
+
+	/*
+	 * Prepare an undo record.  We need to separately store the latest
+	 * transaction id that has changed the tuple to ensure that we don't try
+	 * to process the tuple in undo chain that is already discarded. See
+	 * GetTupleFromUndo.
+	 */
+	undorecord->uur_rmid = RM_ZHEAP_ID;
+	if (ZHeapTupleHasMultiLockers(zh_undo_info->new_infomask))
+		undorecord->uur_type = UNDO_XID_MULTI_LOCK_ONLY;
+	else if (zh_undo_info->IsLockForUpdate)
+		undorecord->uur_type = UNDO_XID_LOCK_FOR_UPDATE;
+	else
+		undorecord->uur_type = UNDO_XID_LOCK_ONLY;
+	undorecord->uur_info = 0;
+	undorecord->uur_reloid = zh_undo_info->gen_info->reloid;
+	undorecord->uur_prevxid = zh_undo_info->tup_xid;
+	undorecord->uur_xid = XidFromFullTransactionId(zh_undo_info->gen_info->fxid);
+	undorecord->uur_cid = zh_undo_info->gen_info->cid;
+	undorecord->uur_fork = MAIN_FORKNUM;
+	undorecord->uur_blkprev = zh_undo_info->gen_info->prev_urecptr;
+	undorecord->uur_block = zh_undo_info->gen_info->blkno;
+	undorecord->uur_offset = zh_undo_info->gen_info->offnum;
+
+	initStringInfo(&undorecord->uur_tuple);
+	initStringInfo(&undorecord->uur_payload);
+
+	/*
+	 * Here, we are storing zheap tuple header which is required to
+	 * reconstruct the old copy of tuple.
+	 */
+	appendBinaryStringInfo(&(undorecord->uur_tuple),
+						   zh_undo_info->tup_hdr,
+						   SizeofZHeapTupleHeader);
+
+	/*
+	 * We keep the lock mode in undo record as for multi lockers we can't have
+	 * that information in tuple header.  We need lock mode later to detect
+	 * conflicts.
+	 */
+	appendBinaryStringInfo(&undorecord->uur_payload,
+						   (char *) &(zh_undo_info->mode),
+						   sizeof(LockTupleMode));
+
+	if (zh_undo_info->tup_trans_slot > ZHEAP_PAGE_TRANS_SLOTS)
+	{
+		undorecord->uur_info |= UREC_INFO_PAYLOAD_CONTAINS_SLOT;
+		appendBinaryStringInfo(&undorecord->uur_payload,
+							   (char *) &(zh_undo_info->tup_trans_slot),
+							   sizeof(int));
+	}
+
+	/*
+	 * Store subtransaction id in undo record.  See SubXactLockTableWait to
+	 * know why we need to store subtransaction id in undo.
+	 *
+	 * While in recovery, we store the dummy subxact token in the undorecord
+	 * so that, the size of undorecord in DO function matches with the size of
+	 * undorecord in REDO function. This ensures that the undo pointer in DO
+	 * and REDO function remains the same.
+	 */
+	if (zh_undo_info->hasSubXactLock)
+	{
+		SubTransactionId subxid = (InRecovery) ? 1 : GetCurrentSubTransactionId();
+
+		undorecord->uur_info |= UREC_INFO_PAYLOAD_CONTAINS_SUBXACT;
+		appendBinaryStringInfo(&(undorecord->uur_payload),
+							   (char *) &subxid,
+							   sizeof(subxid));
+	}
+
+	BeginUndoRecordInsert(&zh_undo_info->gen_info->context,
+						  zh_undo_info->gen_info->undo_persistence,
+						  1,
+						  xlog_record);	
+	urecptr = PrepareUndoInsert(&zh_undo_info->gen_info->context,
+								undorecord,
+								InRecovery ? zh_undo_info->gen_info->fxid : InvalidFullTransactionId);
+
+	return urecptr;
+}
+
+/*
+ * zheap_prepare_undo_multi_insert - prepare the undo record for zheap
+ *	multi-insert operation.
+ *
+ * Returns the undo record pointer (aka location) where the undo record
+ * will be inserted in undo log.
+ */
+UndoRecPtr
+zheap_prepare_undo_multi_insert(ZHeapPrepareUndoInfo *zh_undo_info,
+								int nranges, UnpackedUndoRecord **uur_ptr,
+								XLogReaderState *xlog_record)
+{
+	UndoRecPtr	urecptr;
+	int			i;
+	UnpackedUndoRecord *undorecord;
+
+	/*
+	 * For every contiguous free or new offsets, we insert an undo record. In
+	 * the payload data of each undo record, we store the start and end
+	 * available offset for a contiguous range.
+	 */
+	undorecord = (UnpackedUndoRecord *) palloc(nranges
+												* sizeof(UnpackedUndoRecord));
+
+	/* Start UNDO prepare Stuff */
+	for (i = 0; i < nranges; i++)
+	{
+		/* prepare an undo record */
+		undorecord[i].uur_rmid = RM_ZHEAP_ID;
+		undorecord[i].uur_type = UNDO_MULTI_INSERT;
+		undorecord[i].uur_info = 0;
+		undorecord[i].uur_reloid = zh_undo_info->reloid;
+		undorecord[i].uur_prevxid = FrozenTransactionId;
+		undorecord[i].uur_xid = XidFromFullTransactionId(zh_undo_info->fxid);
+		undorecord[i].uur_cid = zh_undo_info->cid;
+		undorecord[i].uur_fork = MAIN_FORKNUM;
+		undorecord[i].uur_blkprev = zh_undo_info->prev_urecptr;
+		undorecord[i].uur_block = zh_undo_info->blkno;
+		undorecord[i].uur_tuple.len = 0;
+		undorecord[i].uur_offset = 0;
+		undorecord[i].uur_payload.len = 2 * sizeof(OffsetNumber);
+	}
+
+	BeginUndoRecordInsert(&zh_undo_info->context,
+						  zh_undo_info->undo_persistence,
+						  nranges,
+						  NULL);
+
+	for (i = 0; i < nranges; i++)
+	{
+		undorecord[i].uur_blkprev = urecptr;
+		urecptr = PrepareUndoInsert(&zh_undo_info->context,
+									&undorecord[i],
+									InRecovery ? zh_undo_info->fxid : InvalidFullTransactionId);
+
+		initStringInfo(&undorecord[i].uur_payload);
+	}	
+
+	Assert(UndoRecPtrIsValid(urecptr));
+	elog(DEBUG1, "Undo record prepared: %d for Block Number: %d",
+		 nranges, zh_undo_info->blkno);
+
+	*uur_ptr = undorecord;
+	return urecptr;
+}
+
+/*
+ * log_zheap_insert - Perform XLogInsert for a zheap-insert operation.
+ *
+ * We need to store enough information in the WAL record so that undo records
+ * can be regenerated at the WAL replay time.
+ *
+ * Caller must already have modified the buffer(s) and marked them dirty.
+ */
+static void
+log_zheap_insert(ZHeapWALInfo* walinfo, Relation relation,
+				 int options, bool skip_undo)
+{
+	xl_undo_header xlundohdr;
+	xl_zheap_insert xlrec;
+	xl_zheap_header xlhdr;
+	XLogRecPtr	recptr;
+	Page		page = BufferGetPage(walinfo->buffer);
+	uint8		info = XLOG_ZHEAP_INSERT;
+	int			bufflags = 0;
+	XLogRecPtr	RedoRecPtr;
+	bool		doPageWrites;
+
+	/* zheap doesn't support catalog relations. */
+	Assert(!RelationIsAccessibleInLogicalDecoding(relation));
+
+	/*
+	 * If this is the single and first tuple on page, we can reinit the page
+	 * instead of restoring the whole thing.  Set flag, and hide buffer
+	 * references from XLogInsert and we will check that all slots of zheap
+	 * page are empty or not.  If empty, then only we will set reinit flag.
+	 */
+	if (ItemPointerGetOffsetNumber(&(walinfo->ztuple->t_self)) == FirstOffsetNumber &&
+		PageGetMaxOffsetNumber(page) == FirstOffsetNumber &&
+		CheckZheapPageSlotsAreEmpty(page))
+	{
+		info |= XLOG_ZHEAP_INIT_PAGE;
+		bufflags |= REGBUF_WILL_INIT;
+	}
+
+	/*
+	 * Store the information required to generate undo record during replay if
+	 * required.
+	 */
+	if (!skip_undo)
+	{
+		xlundohdr.reloid = relation->rd_id;
+		xlundohdr.urec_ptr = walinfo->urecptr;
+		xlundohdr.blkprev = walinfo->prev_urecptr;
+	}
+
+	/* Heap related part. */
+	xlrec.offnum = ItemPointerGetOffsetNumber(&walinfo->ztuple->t_self);
+	xlrec.flags = 0;
+
+	if (walinfo->all_visible_cleared)
+		xlrec.flags |= XLZ_INSERT_ALL_VISIBLE_CLEARED;
+	if (options & ZHEAP_INSERT_SPECULATIVE)
+		xlrec.flags |= XLZ_INSERT_IS_SPECULATIVE;
+	if (skip_undo)
+		xlrec.flags |= XLZ_INSERT_IS_FROZEN;
+	Assert(ItemPointerGetBlockNumber(&(walinfo->ztuple->t_self)) == BufferGetBlockNumber(walinfo->buffer));
+
+	/*
+	 * For logical decoding, we need the tuple even if we're doing a full page
+	 * write, so make sure it's included even if we take a full-page image.
+	 * (XXX We could alternatively store a pointer into the FPW).
+	 */
+	if (RelationIsLogicallyLogged(relation))
+	{
+		xlrec.flags |= XLZ_INSERT_CONTAINS_NEW_TUPLE;
+		bufflags |= REGBUF_KEEP_DATA;
+	}
+
+prepare_xlog:
+
+	GetFullPageWriteInfo(&RedoRecPtr, &doPageWrites);
+
+	XLogBeginInsert();
+	XLogRegisterData((char *) &xlrec, SizeOfZHeapInsert);
+
+	/* Register undo data only if required. */
+	if (!skip_undo)
+		XLogRegisterData((char *) &xlundohdr, SizeOfUndoHeader);
+
+	if (walinfo->new_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+	{
+		/*
+		 * We can't have a valid transaction slot when we are skipping undo.
+		 */
+		Assert(!skip_undo);
+		xlrec.flags |= XLZ_INSERT_CONTAINS_TPD_SLOT;
+		XLogRegisterData((char *) &walinfo->new_trans_slot_id,
+						 sizeof(walinfo->new_trans_slot_id));
+	}
+
+	xlhdr.t_infomask2 = walinfo->ztuple->t_data->t_infomask2;
+	xlhdr.t_infomask = walinfo->ztuple->t_data->t_infomask;
+	xlhdr.t_hoff = walinfo->ztuple->t_data->t_hoff;
+
+	/*
+	 * note we mark xlhdr as belonging to buffer; if XLogInsert decides to
+	 * write the whole page to the xlog, we don't need to store xl_heap_header
+	 * in the xlog.
+	 */
+	XLogRegisterBuffer(0, walinfo->buffer, REGBUF_STANDARD | bufflags);
+	XLogRegisterBufData(0, (char *) &xlhdr, SizeOfZHeapHeader);
+	/* write bitmap + data */
+	XLogRegisterBufData(0,
+						(char *) walinfo->ztuple->t_data + SizeofZHeapTupleHeader,
+						walinfo->ztuple->t_len - SizeofZHeapTupleHeader);
+	if (xlrec.flags & XLZ_INSERT_CONTAINS_TPD_SLOT)
+		(void) RegisterTPDBuffer(page, 1);
+	RegisterUndoLogBuffers(walinfo->context, 2);
+
+	/* filtering by origin on a row level is much more efficient */
+	XLogSetRecordFlags(XLOG_INCLUDE_ORIGIN);
+
+	recptr = XLogInsertExtended(RM_ZHEAP_ID, info, RedoRecPtr, doPageWrites);
+	if (recptr == InvalidXLogRecPtr)
+	{
+		ResetRegisteredTPDBuffers();
+		goto prepare_xlog;
+	}
+
+	PageSetLSN(page, recptr);
+	if (xlrec.flags & XLZ_INSERT_CONTAINS_TPD_SLOT)
+		TPDPageSetLSN(page, recptr);
+	UndoLogBuffersSetLSN(walinfo->context, recptr);
+}
+
+/*
+ * log_zheap_update - Perform XLogInsert for a zheap-update operation.
+ *
+ * We need to store enough information in the WAL record so that undo records
+ * can be regenerated at the WAL replay time.
+ *
+ * Caller must already have modified the buffer(s) and marked them dirty.
+ *
+ * old_walinfo has the necessary wal information about the existing tuple which is being updated.
+ *
+ * new_walinfo has the necessary wal information about the new tuple which
+ * is inserted in case of a non-inplace update.
+ */
+static void
+log_zheap_update(ZHeapWALInfo *old_walinfo, ZHeapWALInfo *new_walinfo,
+				 bool inplace_update)
+{
+	xl_undo_header xlundohdr,
+				xlnewundohdr;
+	xl_zheap_header xlundotuphdr,
+				xlhdr;
+	xl_zheap_update xlrec;
+	ZHeapTuple	difftup;
+	ZHeapTupleHeader zhtuphdr;
+	uint16		prefix_suffix[2];
+	uint16		prefixlen = 0,
+				suffixlen = 0;
+	XLogRecPtr	recptr;
+	XLogRecPtr	RedoRecPtr;
+	bool		doPageWrites;
+	char	   *oldp = NULL;
+	char	   *newp = NULL;
+	int			oldlen,
+				newlen;
+	int			bufflags = REGBUF_STANDARD;
+	uint8		info = XLOG_ZHEAP_UPDATE;
+
+	zhtuphdr = (ZHeapTupleHeader) old_walinfo->undorecord->uur_tuple.data;
+
+	if (inplace_update)
+	{
+		/*
+		 * For inplace updates the old tuple is in undo record and the new
+		 * tuple is replaced in page where old tuple was present.
+		 */
+		oldp = (char *) zhtuphdr + zhtuphdr->t_hoff;
+		oldlen = old_walinfo->undorecord->uur_tuple.len - zhtuphdr->t_hoff;
+		newp = (char *) old_walinfo->ztuple->t_data + old_walinfo->ztuple->t_data->t_hoff;
+		newlen = old_walinfo->ztuple->t_len - old_walinfo->ztuple->t_data->t_hoff;
+
+		difftup = old_walinfo->ztuple;
+	}
+	else if (old_walinfo->buffer == new_walinfo->buffer)
+	{
+		oldp = (char *) old_walinfo->ztuple->t_data + old_walinfo->ztuple->t_data->t_hoff;
+		oldlen = old_walinfo->ztuple->t_len - old_walinfo->ztuple->t_data->t_hoff;
+		newp = (char *) new_walinfo->ztuple->t_data + new_walinfo->ztuple->t_data->t_hoff;
+		newlen = new_walinfo->ztuple->t_len - new_walinfo->ztuple->t_data->t_hoff;
+
+		difftup = new_walinfo->ztuple;
+	}
+	else
+	{
+		difftup = new_walinfo->ztuple;
+	}
+
+	/*
+	 * See log_heap_update to know under what some circumstances we can use
+	 * prefix-suffix compression.
+	 */
+	if (old_walinfo->buffer == new_walinfo->buffer
+		&& !XLogCheckBufferNeedsBackup(new_walinfo->buffer))
+	{
+		Assert(oldp != NULL && newp != NULL);
+
+		/* Check for common prefix between undo and old tuple */
+		for (prefixlen = 0; prefixlen < Min(oldlen, newlen); prefixlen++)
+		{
+			if (oldp[prefixlen] != newp[prefixlen])
+				break;
+		}
+
+		/*
+		 * Storing the length of the prefix takes 2 bytes, so we need to save
+		 * at least 3 bytes or there's no point.
+		 */
+		if (prefixlen < 3)
+			prefixlen = 0;
+
+		/* Same for suffix */
+		for (suffixlen = 0; suffixlen < Min(oldlen, newlen) - prefixlen; suffixlen++)
+		{
+			if (oldp[oldlen - suffixlen - 1] != newp[newlen - suffixlen - 1])
+				break;
+		}
+		if (suffixlen < 3)
+			suffixlen = 0;
+	}
+
+	/*
+	 * Store the information required to generate undo record during replay.
+	 */
+	xlundohdr.reloid = old_walinfo->undorecord->uur_reloid;
+	xlundohdr.urec_ptr = old_walinfo->urecptr;
+	xlundohdr.blkprev = old_walinfo->undorecord->uur_blkprev;
+
+	xlrec.prevxid = old_walinfo->undorecord->uur_prevxid;
+	xlrec.old_offnum = ItemPointerGetOffsetNumber(&old_walinfo->ztuple->t_self);
+	xlrec.old_infomask = old_walinfo->ztuple->t_data->t_infomask;
+	xlrec.old_trans_slot_id = old_walinfo->new_trans_slot_id;
+	xlrec.new_offnum = ItemPointerGetOffsetNumber(&difftup->t_self);
+	xlrec.flags = 0;
+	if (old_walinfo->all_visible_cleared)
+		xlrec.flags |= XLZ_UPDATE_OLD_ALL_VISIBLE_CLEARED;
+	if (new_walinfo->all_visible_cleared)
+		xlrec.flags |= XLZ_UPDATE_NEW_ALL_VISIBLE_CLEARED;
+	if (prefixlen > 0)
+		xlrec.flags |= XLZ_UPDATE_PREFIX_FROM_OLD;
+	if (suffixlen > 0)
+		xlrec.flags |= XLZ_UPDATE_SUFFIX_FROM_OLD;
+	if (old_walinfo->undorecord->uur_info & UREC_INFO_PAYLOAD_CONTAINS_SUBXACT)
+		xlrec.flags |= XLZ_UPDATE_CONTAINS_SUBXACT;
+
+	if (!inplace_update)
+	{
+		Page		page = BufferGetPage(new_walinfo->buffer);
+
+		xlrec.flags |= XLZ_NON_INPLACE_UPDATE;
+
+		xlnewundohdr.reloid = new_walinfo->undorecord->uur_reloid;
+		xlnewundohdr.urec_ptr = new_walinfo->urecptr;
+		xlnewundohdr.blkprev = new_walinfo->undorecord->uur_blkprev;
+
+		Assert(new_walinfo->ztuple);
+		/* If new tuple is the single and first tuple on page... */
+		if (ItemPointerGetOffsetNumber(&(new_walinfo->ztuple->t_self)) == FirstOffsetNumber &&
+			PageGetMaxOffsetNumber(page) == FirstOffsetNumber &&
+			CheckZheapPageSlotsAreEmpty(page))
+		{
+			info |= XLOG_ZHEAP_INIT_PAGE;
+			bufflags |= REGBUF_WILL_INIT;
+		}
+	}
+
+	/*
+	 * If full_page_writes is enabled, and the buffer image is not included in
+	 * the WAL then we can rely on the tuple in the page to regenerate the
+	 * undo tuple during recovery.  For detail comments related to handling of
+	 * full_page_writes get changed at run time, refer comments in
+	 * zheap_delete.
+	 */
+prepare_xlog:
+	GetFullPageWriteInfo(&RedoRecPtr, &doPageWrites);
+	if (!doPageWrites || XLogCheckBufferNeedsBackup(old_walinfo->buffer))
+	{
+		xlrec.flags |= XLZ_HAS_UPDATE_UNDOTUPLE;
+
+		xlundotuphdr.t_infomask2 = zhtuphdr->t_infomask2;
+		xlundotuphdr.t_infomask = zhtuphdr->t_infomask;
+		xlundotuphdr.t_hoff = zhtuphdr->t_hoff;
+	}
+
+	XLogBeginInsert();
+	XLogRegisterData((char *) &xlundohdr, SizeOfUndoHeader);
+	XLogRegisterData((char *) &xlrec, SizeOfZHeapUpdate);
+	if (old_walinfo->prior_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+	{
+		xlrec.flags |= XLZ_UPDATE_OLD_CONTAINS_TPD_SLOT;
+		XLogRegisterData((char *) &(old_walinfo->prior_trans_slot_id),
+						 sizeof(old_walinfo->prior_trans_slot_id));
+	}
+	if (!inplace_update)
+	{
+		XLogRegisterData((char *) &xlnewundohdr, SizeOfUndoHeader);
+		if (new_walinfo->new_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		{
+			xlrec.flags |= XLZ_UPDATE_NEW_CONTAINS_TPD_SLOT;
+			XLogRegisterData((char *) &new_walinfo->new_trans_slot_id,
+							 sizeof(new_walinfo->new_trans_slot_id));
+		}
+	}
+	if (xlrec.flags & XLZ_HAS_UPDATE_UNDOTUPLE)
+	{
+		XLogRegisterData((char *) &xlundotuphdr, SizeOfZHeapHeader);
+		/* PG73FORMAT: write bitmap [+ padding] [+ oid] + data */
+		XLogRegisterData((char *) zhtuphdr + SizeofZHeapTupleHeader,
+						 old_walinfo->undorecord->uur_tuple.len - SizeofZHeapTupleHeader);
+	}
+
+	XLogRegisterBuffer(0, new_walinfo->buffer, bufflags);
+	if (old_walinfo->buffer != new_walinfo->buffer)
+	{
+		uint8		block_id;
+
+		XLogRegisterBuffer(1, old_walinfo->buffer, REGBUF_STANDARD);
+		block_id = 2;
+		if (old_walinfo->new_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+			block_id = RegisterTPDBuffer(BufferGetPage(old_walinfo->buffer), block_id);
+		if (new_walinfo->new_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+			RegisterTPDBuffer(BufferGetPage(new_walinfo->buffer), block_id);
+	}
+	else
+	{
+		if (old_walinfo->new_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		{
+			/*
+			 * Block id '1' is reserved for old_walinfo->buffer if that is
+			 * different from new_walinfo->buffer.
+			 */
+			RegisterTPDBuffer(BufferGetPage(old_walinfo->buffer), 2);
+		}
+	}
+	RegisterUndoLogBuffers(old_walinfo->context, 5);
+
+	/*
+	 * Prepare WAL data for the new tuple.
+	 */
+	if (prefixlen > 0 || suffixlen > 0)
+	{
+		if (prefixlen > 0 && suffixlen > 0)
+		{
+			prefix_suffix[0] = prefixlen;
+			prefix_suffix[1] = suffixlen;
+			XLogRegisterBufData(0, (char *) &prefix_suffix, sizeof(uint16) * 2);
+		}
+		else if (prefixlen > 0)
+		{
+			XLogRegisterBufData(0, (char *) &prefixlen, sizeof(uint16));
+		}
+		else
+		{
+			XLogRegisterBufData(0, (char *) &suffixlen, sizeof(uint16));
+		}
+	}
+
+	xlhdr.t_infomask2 = difftup->t_data->t_infomask2;
+	xlhdr.t_infomask = difftup->t_data->t_infomask;
+	xlhdr.t_hoff = difftup->t_data->t_hoff;
+	Assert(SizeofZHeapTupleHeader + prefixlen + suffixlen <= difftup->t_len);
+
+	/*
+	 * PG73FORMAT: write bitmap [+ padding] [+ oid] + data
+	 *
+	 * The 'data' doesn't include the common prefix or suffix.
+	 */
+	XLogRegisterBufData(0, (char *) &xlhdr, SizeOfZHeapHeader);
+	if (prefixlen == 0)
+	{
+		XLogRegisterBufData(0,
+							((char *) difftup->t_data) + SizeofZHeapTupleHeader,
+							difftup->t_len - SizeofZHeapTupleHeader - suffixlen);
+	}
+	else
+	{
+		/*
+		 * Have to write the null bitmap and data after the common prefix as
+		 * two separate rdata entries.
+		 */
+		/* bitmap [+ padding] [+ oid] */
+		if (difftup->t_data->t_hoff - SizeofZHeapTupleHeader > 0)
+		{
+			XLogRegisterBufData(0,
+								((char *) difftup->t_data) + SizeofZHeapTupleHeader,
+								difftup->t_data->t_hoff - SizeofZHeapTupleHeader);
+		}
+
+		/* data after common prefix */
+		XLogRegisterBufData(0,
+							((char *) difftup->t_data) + difftup->t_data->t_hoff + prefixlen,
+							difftup->t_len - difftup->t_data->t_hoff - prefixlen - suffixlen);
+	}
+
+	/* filtering by origin on a row level is much more efficient */
+	XLogSetRecordFlags(XLOG_INCLUDE_ORIGIN);
+
+	recptr = XLogInsertExtended(RM_ZHEAP_ID, info, RedoRecPtr, doPageWrites);
+	if (recptr == InvalidXLogRecPtr)
+	{
+		ResetRegisteredTPDBuffers();
+		goto prepare_xlog;
+	}
+
+	if (new_walinfo->buffer != old_walinfo->buffer)
+	{
+		PageSetLSN(BufferGetPage(new_walinfo->buffer), recptr);
+		if (new_walinfo->new_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+			TPDPageSetLSN(BufferGetPage(new_walinfo->buffer), recptr);
+	}
+	PageSetLSN(BufferGetPage(old_walinfo->buffer), recptr);
+	if (old_walinfo->new_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		TPDPageSetLSN(BufferGetPage(old_walinfo->buffer), recptr);
+	UndoLogBuffersSetLSN(old_walinfo->context, recptr);
+}
+
+/*
+ * CheckZheapPageSlotsAreEmpty - To check zheap page slots
+ *
+ * Returns true if all the slots are empty except current transaction slot.
+ */
+static bool
+CheckZheapPageSlotsAreEmpty(Page page)
+{
+	ZHeapPageOpaque opaque;
+	TransInfo  *thistrans;
+	int			i;
+	FullTransactionId fxid;
+
+	/* If page has TPD slot, then we will not reinit page. */
+	if (ZHeapPageHasTPDSlot((PageHeader) page))
+		return false;
+
+	fxid = GetTopFullTransactionId();
+	opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+
+	for (i = 0; i < ZHEAP_PAGE_TRANS_SLOTS; i++)
+	{
+		thistrans = &opaque->transinfo[i];
+
+		/* If fxid is valid then it should be current trasaction fxid. */
+		if ((FullTransactionIdIsValid(thistrans->fxid) &&
+			 FullTransactionIdEquals(thistrans->fxid, fxid)) ||
+			(!FullTransactionIdIsValid(thistrans->fxid) &&
+			 thistrans->urec_ptr == InvalidUndoRecPtr))
+			continue;
+
+		/*
+		 * Return false, because page has valid slot info other than current
+		 * transaction.
+		 */
+		return false;
+	}
+
+	/* Return true, because page have only one valid slot. */
+	return true;
+}
+
+/*
+ * log_zheap_delete - Perform XLogInsert for a zheap-delete operation.
+ */
+static void
+log_zheap_delete(ZHeapWALInfo *walinfo, bool changingPart,
+				 SubTransactionId subxid, TransactionId tup_xid)
+{
+	ZHeapTupleHeader zhtuphdr = NULL;
+	xl_undo_header xlundohdr;
+	xl_zheap_delete xlrec;
+	xl_zheap_header xlhdr;
+	XLogRecPtr	recptr;
+	XLogRecPtr	RedoRecPtr;
+	bool		doPageWrites;
+	Page		page = BufferGetPage(walinfo->buffer);
+
+	/* Store the information required to generate undo record during replay. */
+	xlundohdr.reloid = walinfo->undorecord->uur_reloid;
+	xlundohdr.urec_ptr = walinfo->urecptr;
+	xlundohdr.blkprev = walinfo->prev_urecptr;
+
+	xlrec.prevxid = tup_xid;
+	xlrec.offnum = ItemPointerGetOffsetNumber(&walinfo->ztuple->t_self);
+	xlrec.infomask = walinfo->ztuple->t_data->t_infomask;
+	xlrec.trans_slot_id = walinfo->new_trans_slot_id;
+	xlrec.flags = walinfo->all_visible_cleared ? XLZ_DELETE_ALL_VISIBLE_CLEARED : 0;
+
+	if (changingPart)
+		xlrec.flags |= XLZ_DELETE_IS_PARTITION_MOVE;
+	if (subxid != InvalidSubTransactionId)
+		xlrec.flags |= XLZ_DELETE_CONTAINS_SUBXACT;
+
+	/*
+	 * If full_page_writes is enabled, and the buffer image is not included in
+	 * the WAL then we can rely on the tuple in the page to regenerate the
+	 * undo tuple during recovery as the tuple state must be same as now,
+	 * otherwise we need to store it explicitly.
+	 *
+	 * Since we don't yet have the insert lock, including the page image
+	 * decision could change later and in that case we need prepare the WAL
+	 * record again.
+	 */
+prepare_xlog:
+
+	GetFullPageWriteInfo(&RedoRecPtr, &doPageWrites);
+	if (!doPageWrites || XLogCheckBufferNeedsBackup(walinfo->buffer))
+	{
+		xlrec.flags |= XLZ_HAS_DELETE_UNDOTUPLE;
+
+		zhtuphdr = (ZHeapTupleHeader) walinfo->undorecord->uur_tuple.data;
+
+		xlhdr.t_infomask2 = zhtuphdr->t_infomask2;
+		xlhdr.t_infomask = zhtuphdr->t_infomask;
+		xlhdr.t_hoff = zhtuphdr->t_hoff;
+	}
+	if (walinfo->prior_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		xlrec.flags |= XLZ_DELETE_CONTAINS_TPD_SLOT;
+
+	XLogBeginInsert();
+	XLogRegisterData((char *) &xlundohdr, SizeOfUndoHeader);
+	XLogRegisterData((char *) &xlrec, SizeOfZHeapDelete);
+	if (xlrec.flags & XLZ_DELETE_CONTAINS_TPD_SLOT)
+		XLogRegisterData((char *) &walinfo->prior_trans_slot_id,
+						 sizeof(walinfo->prior_trans_slot_id));
+	if (xlrec.flags & XLZ_HAS_DELETE_UNDOTUPLE)
+	{
+		XLogRegisterData((char *) &xlhdr, SizeOfZHeapHeader);
+		/* PG73FORMAT: write bitmap [+ padding] [+ oid] + data */
+		XLogRegisterData((char *) zhtuphdr + SizeofZHeapTupleHeader,
+						 walinfo->undorecord->uur_tuple.len - SizeofZHeapTupleHeader);
+	}
+
+	XLogRegisterBuffer(0, walinfo->buffer, REGBUF_STANDARD);
+	if (walinfo->new_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		(void) RegisterTPDBuffer(page, 1);
+	RegisterUndoLogBuffers(walinfo->context, 2);
+
+	/* filtering by origin on a row level is much more efficient */
+	XLogSetRecordFlags(XLOG_INCLUDE_ORIGIN);
+
+	recptr = XLogInsertExtended(RM_ZHEAP_ID, XLOG_ZHEAP_DELETE,
+								RedoRecPtr, doPageWrites);
+	if (recptr == InvalidXLogRecPtr)
+	{
+		ResetRegisteredTPDBuffers();
+		goto prepare_xlog;
+	}
+	PageSetLSN(page, recptr);
+	if (walinfo->new_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		TPDPageSetLSN(page, recptr);
+	UndoLogBuffersSetLSN(walinfo->context, recptr);
+}
+
+/*
+ * log_zheap_multi_insert
+ * Perform XLogInsert for a zheap multi-insert operation.
+ *
+ * We need to store enough information in the WAL record so that undo records
+ * can be regenerated at the WAL replay time.
+ *
+ * Caller must already have modified the buffer(s) and marked them dirty.
+ *
+ * multi_walinfo - all the information required to insert WAL
+ * skip_undo - is undo insertion skipped?
+ * scratch - pre-allocated scratch space for WAL construction
+ */
+static void
+log_zheap_multi_insert(ZHeapMultiInsertWALInfo *multi_walinfo, bool skip_undo,
+					   char *scratch)
+{
+	xl_undo_header xlundohdr;
+	XLogRecPtr	recptr;
+	xl_zheap_multi_insert *xlrec;
+	uint8		info = XLOG_ZHEAP_MULTI_INSERT;
+	char	   *tupledata;
+	char	   *scratchptr = scratch;
+	int			bufflags = 0,
+				i,
+				totaldatalen;
+	XLogRecPtr	RedoRecPtr;
+	bool		doPageWrites,
+				init,
+				need_tuple_data = RelationIsLogicallyLogged(multi_walinfo->relation);
+	Page		page = BufferGetPage(multi_walinfo->gen_walinfo->buffer);
+
+	/*
+	 * Store the information required to generate undo record during replay.
+	 * All undo records have same information apart from the payload data.
+	 * Hence, we can copy the same from the last record.
+	 */
+	xlundohdr.reloid = multi_walinfo->relation->rd_id;
+	xlundohdr.urec_ptr = multi_walinfo->gen_walinfo->urecptr;
+	xlundohdr.blkprev = multi_walinfo->gen_walinfo->prev_urecptr;
+
+	/* allocate xl_zheap_multi_insert struct from the scratch area */
+	xlrec = (xl_zheap_multi_insert *) scratchptr;
+	xlrec->flags = multi_walinfo->gen_walinfo->all_visible_cleared ?
+		XLZ_INSERT_ALL_VISIBLE_CLEARED : 0;
+	if (skip_undo)
+		xlrec->flags |= XLZ_INSERT_IS_FROZEN;
+	xlrec->ntuples = multi_walinfo->curpage_ntuples;
+	scratchptr += SizeOfZHeapMultiInsert;
+
+	/* copy the offset ranges as well */
+	memcpy((char *) scratchptr,
+		   (char *) &multi_walinfo->zfree_offsets->nranges,
+		   sizeof(int));
+	scratchptr += sizeof(int);
+	for (i = 0; i < multi_walinfo->zfree_offsets->nranges; i++)
+	{
+		memcpy((char *) scratchptr,
+			   (char *) &multi_walinfo->zfree_offsets->startOffset[i],
+			   sizeof(OffsetNumber));
+		scratchptr += sizeof(OffsetNumber);
+		memcpy((char *) scratchptr,
+			   (char *) &multi_walinfo->zfree_offsets->endOffset[i],
+			   sizeof(OffsetNumber));
+		scratchptr += sizeof(OffsetNumber);
+	}
+
+	/* the rest of the scratch space is used for tuple data */
+	tupledata = scratchptr;
+
+	/*
+	 * Write out an xl_multi_insert_tuple and the tuple data itself for each
+	 * tuple.
+	 */
+	for (i = 0; i < multi_walinfo->curpage_ntuples; i++)
+	{
+		ZHeapTuple	zheaptup = multi_walinfo->ztuples[multi_walinfo->ndone + i];
+		xl_multi_insert_ztuple *tuphdr;
+		int			datalen;
+
+		/* xl_multi_insert_tuple needs two-byte alignment. */
+		tuphdr = (xl_multi_insert_ztuple *) SHORTALIGN(scratchptr);
+		scratchptr = ((char *) tuphdr) + SizeOfMultiInsertZTuple;
+
+		tuphdr->t_infomask2 = zheaptup->t_data->t_infomask2;
+		tuphdr->t_infomask = zheaptup->t_data->t_infomask;
+		tuphdr->t_hoff = zheaptup->t_data->t_hoff;
+
+		/* write bitmap [+ padding] [+ oid] + data */
+		datalen = zheaptup->t_len - SizeofZHeapTupleHeader;
+		memcpy(scratchptr,
+			   (char *) zheaptup->t_data + SizeofZHeapTupleHeader,
+			   datalen);
+		tuphdr->datalen = datalen;
+		scratchptr += datalen;
+	}
+	totaldatalen = scratchptr - tupledata;
+	Assert((scratchptr - scratch) < BLCKSZ);
+
+	if (need_tuple_data)
+		xlrec->flags |= XLZ_INSERT_CONTAINS_NEW_TUPLE;
+
+	/*
+	 * Signal that this is the last xl_zheap_multi_insert record emitted by
+	 * this call to zheap_multi_insert(). Needed for logical decoding so it
+	 * knows when to cleanup temporary data.
+	 */
+	if (multi_walinfo->ndone + multi_walinfo->curpage_ntuples ==
+		multi_walinfo->ntuples)
+		xlrec->flags |= XLZ_INSERT_LAST_IN_MULTI;
+
+	/*
+	 * If the page was previously empty, we can reinitialize the page instead
+	 * of restoring the whole thing.
+	 */
+	init = (ItemPointerGetOffsetNumber(&(multi_walinfo->ztuples[multi_walinfo->ndone]->t_self)) ==
+			FirstOffsetNumber &&
+			PageGetMaxOffsetNumber(page) ==
+			FirstOffsetNumber + multi_walinfo->curpage_ntuples - 1);
+
+	if (init)
+	{
+		info |= XLOG_ZHEAP_INIT_PAGE;
+		bufflags |= REGBUF_WILL_INIT;
+	}
+
+	/*
+	 * If we're doing logical decoding, include the new tuple data even if we
+	 * take a full-page image of the page.
+	 */
+	if (need_tuple_data)
+		bufflags |= REGBUF_KEEP_DATA;
+
+prepare_xlog:
+	GetFullPageWriteInfo(&RedoRecPtr, &doPageWrites);
+
+	XLogBeginInsert();
+	/* copy undo related info in maindata */
+	XLogRegisterData((char *) &xlundohdr, SizeOfUndoHeader);
+	/* copy xl_multi_insert_tuple in maindata */
+	XLogRegisterData((char *) xlrec, tupledata - scratch);
+
+	/* If we've skipped undo insertion, we don't need a slot in page. */
+	if (!skip_undo &&
+		multi_walinfo->gen_walinfo->new_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+	{
+		xlrec->flags |= XLZ_INSERT_CONTAINS_TPD_SLOT;
+		XLogRegisterData((char *) &multi_walinfo->gen_walinfo->new_trans_slot_id,
+						 sizeof(multi_walinfo->gen_walinfo->new_trans_slot_id));
+	}
+	XLogRegisterBuffer(0, multi_walinfo->gen_walinfo->buffer,
+					   REGBUF_STANDARD | bufflags);
+
+	/* copy tuples in block data */
+	XLogRegisterBufData(0, tupledata, totaldatalen);
+	if (xlrec->flags & XLZ_INSERT_CONTAINS_TPD_SLOT)
+		(void) RegisterTPDBuffer(page, 1);
+
+	RegisterUndoLogBuffers(multi_walinfo->gen_walinfo->context, 2);
+
+	/* filtering by origin on a row level is much more efficient */
+	XLogSetRecordFlags(XLOG_INCLUDE_ORIGIN);
+
+	recptr = XLogInsertExtended(RM_ZHEAP_ID, info, RedoRecPtr,
+								doPageWrites);
+	if (recptr == InvalidXLogRecPtr)
+	{
+		ResetRegisteredTPDBuffers();
+		goto prepare_xlog;
+	}
+
+	PageSetLSN(page, recptr);
+	if (xlrec->flags & XLZ_INSERT_CONTAINS_TPD_SLOT)
+		TPDPageSetLSN(page, recptr);
+	UndoLogBuffersSetLSN(multi_walinfo->gen_walinfo->context, recptr);
+}
+
+/*
+ * log_zheap_lock_tuple
+ *
+ * We need to store enough information in the WAL record so that undo records
+ * can be regenerated at the WAL replay time.
+ */
+static void
+log_zheap_lock_tuple(ZHeapWALInfo *walinfo, TransactionId tup_xid,
+					 int trans_slot_id, bool hasSubXactLock, LockTupleMode mode)
+{
+	Page		page = BufferGetPage(walinfo->buffer);
+	xl_zheap_lock xlrec;
+	xl_undo_header xlundohdr;
+	XLogRecPtr	recptr;
+	XLogRecPtr	RedoRecPtr;
+	bool		doPageWrites;
+
+	/* Store the information required to generate undo record during replay. */
+	xlundohdr.reloid = walinfo->undorecord->uur_reloid;
+	xlundohdr.urec_ptr = walinfo->urecptr;
+	xlundohdr.blkprev = walinfo->prev_urecptr;
+
+	xlrec.prev_xid = tup_xid;
+	xlrec.offnum = ItemPointerGetOffsetNumber(&(walinfo->ztuple->t_self));
+	xlrec.infomask = walinfo->ztuple->t_data->t_infomask;
+	xlrec.trans_slot_id = walinfo->new_trans_slot_id;
+	xlrec.flags = 0;
+	if (walinfo->new_trans_slot_id != trans_slot_id)
+	{
+		Assert(walinfo->new_trans_slot_id == walinfo->prior_trans_slot_id);
+		xlrec.flags |= XLZ_LOCK_TRANS_SLOT_FOR_UREC;
+	}
+	else if (walinfo->prior_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		xlrec.flags |= XLZ_LOCK_CONTAINS_TPD_SLOT;
+
+	if (hasSubXactLock)
+		xlrec.flags |= XLZ_LOCK_CONTAINS_SUBXACT;
+
+	if (walinfo->undorecord->uur_type == UNDO_XID_LOCK_FOR_UPDATE)
+		xlrec.flags |= XLZ_LOCK_FOR_UPDATE;
+
+prepare_xlog:
+
+	GetFullPageWriteInfo(&RedoRecPtr, &doPageWrites);
+	XLogBeginInsert();
+	XLogRegisterBuffer(0, walinfo->buffer, REGBUF_STANDARD);
+	if (trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		(void) RegisterTPDBuffer(page, 1);
+	XLogRegisterData((char *) &xlundohdr, SizeOfUndoHeader);
+	XLogRegisterData((char *) &xlrec, SizeOfZHeapLock);
+	RegisterUndoLogBuffers(walinfo->context, 2);
+
+	/*
+	 * We always include old tuple header for undo in WAL record irrespective
+	 * of full page image is taken or not. This is done since savings for not
+	 * including a zheap tuple header are less compared to code complexity.
+	 * However in future, if required we can do it similar to what we have
+	 * done in zheap_update or zheap_delete.
+	 */
+	XLogRegisterData((char *) walinfo->undorecord->uur_tuple.data,
+					 SizeofZHeapTupleHeader);
+	XLogRegisterData((char *) &mode, sizeof(LockTupleMode));
+
+	if (xlrec.flags & XLZ_LOCK_TRANS_SLOT_FOR_UREC)
+		XLogRegisterData((char *) &trans_slot_id, sizeof(trans_slot_id));
+	else if (xlrec.flags & XLZ_LOCK_CONTAINS_TPD_SLOT)
+		XLogRegisterData((char *) &(walinfo->prior_trans_slot_id),
+						 sizeof(walinfo->prior_trans_slot_id));
+
+	recptr = XLogInsertExtended(RM_ZHEAP_ID, XLOG_ZHEAP_LOCK, RedoRecPtr,
+								doPageWrites);
+
+	if (recptr == InvalidXLogRecPtr)
+	{
+		ResetRegisteredTPDBuffers();
+		goto prepare_xlog;
+	}
+
+	PageSetLSN(page, recptr);
+
+	if (trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		TPDPageSetLSN(page, recptr);
+
+	UndoLogBuffersSetLSN(walinfo->context, recptr);
+}
+
+/*
+ * ZHeapDetermineModifiedColumns - Check which columns are being updated.
+ *	This is same as HeapDetermineModifiedColumns except that it takes
+ *	ZHeapTuple as input.
+ */
+static Bitmapset *
+ZHeapDetermineModifiedColumns(Relation relation, Bitmapset *interesting_cols,
+							  ZHeapTuple oldtup, ZHeapTuple newtup)
+{
+	return zheap_tuple_attr_equals(RelationGetDescr(relation),
+								   interesting_cols,
+								   oldtup,
+								   newtup);
+}
+
+/*
+ * -----------
+ * Zheap transaction information related API's.
+ * -----------
+ */
+
+/*
+ * GetTransactionSlotInfo - Get the required transaction slot info.  We also
+ *	return the transaction slot number, if the transaction slot is in TPD entry.
+ *
+ * We can directly call this function to get transaction slot info if we are
+ * sure that the corresponding tuple is not deleted or we don't care if the
+ * tuple has multi-locker flag in which case we need to call
+ * ZHeapTupleGetTransInfo.
+ *
+ * NoTPDBufLock - See TPDPageGetTransactionSlotInfo.
+ * TPDSlot - true, if the passed transaction_slot_id is the slot number in TPD
+ * entry.
+ */
+void
+GetTransactionSlotInfo(Buffer buf, OffsetNumber offset, int trans_slot_id,
+					   bool NoTPDBufLock, bool TPDSlot,
+					   ZHeapTupleTransInfo *zinfo)
+{
+	ZHeapPageOpaque opaque;
+	Page		page;
+	PageHeader	phdr PG_USED_FOR_ASSERTS_ONLY;
+	uint32		epoch = 0;
+
+	zinfo->trans_slot = trans_slot_id;
+	zinfo->cid = InvalidCommandId;
+
+	page = BufferGetPage(buf);
+	phdr = (PageHeader) page;
+	opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+
+	/*
+	 * Fetch the required information from the transaction slot. The
+	 * transaction slot can either be on the heap page or TPD page.
+	 */
+	if (trans_slot_id == ZHTUP_SLOT_FROZEN)
+	{
+		zinfo->xid = InvalidTransactionId;
+		zinfo->urec_ptr = InvalidUndoRecPtr;
+	}
+	else if (trans_slot_id < ZHEAP_PAGE_TRANS_SLOTS ||
+			 (trans_slot_id == ZHEAP_PAGE_TRANS_SLOTS &&
+			  !ZHeapPageHasTPDSlot(phdr)))
+	{
+		TransInfo  *thistrans = &opaque->transinfo[trans_slot_id - 1];
+
+		epoch = EpochFromFullTransactionId(thistrans->fxid);
+		zinfo->xid = XidFromFullTransactionId(thistrans->fxid);
+		zinfo->urec_ptr = thistrans->urec_ptr;
+	}
+	else
+	{
+		Assert((ZHeapPageHasTPDSlot(phdr)));
+		if (TPDSlot)
+		{
+			/*
+			 * The heap page's last transaction slot data is copied over to
+			 * first slot in TPD entry, so we need fetch it from there.  See
+			 * AllocateAndFormTPDEntry.
+			 */
+			if (trans_slot_id == ZHEAP_PAGE_TRANS_SLOTS)
+				trans_slot_id = ZHEAP_PAGE_TRANS_SLOTS + 1;
+			zinfo->trans_slot =
+				TPDPageGetTransactionSlotInfo(buf,
+											  trans_slot_id,
+											  InvalidOffsetNumber,
+											  &epoch,
+											  &zinfo->xid,
+											  &zinfo->urec_ptr,
+											  NoTPDBufLock,
+											  false);
+		}
+		else
+		{
+			Assert(offset != InvalidOffsetNumber);
+			zinfo->trans_slot =
+				TPDPageGetTransactionSlotInfo(buf,
+											  trans_slot_id,
+											  offset,
+											  &epoch,
+											  &zinfo->xid,
+											  &zinfo->urec_ptr,
+											  NoTPDBufLock,
+											  false);
+		}
+	}
+
+	zinfo->epoch_xid = FullTransactionIdFromEpochAndXid(epoch, zinfo->xid);
+}
+
+/*
+ * PageSetUNDO - Set the transaction information pointer for a given
+ *		transaction slot.
+ */
+void
+PageSetUNDO(UnpackedUndoRecord undorecord, Buffer buffer, int trans_slot_id,
+			bool set_tpd_map_slot, FullTransactionId fxid,
+			UndoRecPtr urecptr, OffsetNumber *usedoff, int ucnt)
+{
+	ZHeapPageOpaque opaque;
+	Page		page = BufferGetPage(buffer);
+	PageHeader	phdr;
+
+	Assert(trans_slot_id != InvalidXactSlotId);
+
+	phdr = (PageHeader) page;
+	opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+
+	/*
+	 * Set the required information in the transaction slot. The transaction
+	 * slot can either be on the heap page or TPD page.
+	 *
+	 * During recovery, we set the required information in TPD separately only
+	 * if required.
+	 */
+	if (trans_slot_id < ZHEAP_PAGE_TRANS_SLOTS ||
+		(trans_slot_id == ZHEAP_PAGE_TRANS_SLOTS &&
+		 !ZHeapPageHasTPDSlot(phdr)))
+	{
+		TransInfo  *thistrans = &opaque->transinfo[trans_slot_id - 1];
+
+		thistrans->fxid = fxid;
+		thistrans->urec_ptr = urecptr;
+	}
+	/* TPD information is set separately during recovery. */
+	else if (!InRecovery)
+	{
+		if (ucnt <= 0)
+		{
+			Assert(ucnt == 0);
+
+			usedoff = &undorecord.uur_offset;
+			ucnt++;
+		}
+
+		TPDPageSetUndo(buffer, trans_slot_id, set_tpd_map_slot, fxid,
+					   urecptr, usedoff, ucnt);
+	}
+
+	elog(DEBUG1, "undo record: TransSlot: %d, Epoch: %d, TransactionId: %d, urec: " UndoRecPtrFormat ", prev_urec: " UndoRecPtrFormat ", block: %d, offset: %d, undo_op: %d, xid_tup: %d, reloid: %d",
+		 trans_slot_id, EpochFromFullTransactionId(fxid),
+		 XidFromFullTransactionId(fxid),
+		 urecptr, undorecord.uur_blkprev, undorecord.uur_block, undorecord.uur_offset, undorecord.uur_type,
+		 undorecord.uur_prevxid, undorecord.uur_reloid);
+}
+
+/*
+ * PageSetTransactionSlotInfo - Set the transaction slot info for the given
+ *			slot.
+ *
+ * This is similar to PageSetUNDO except that it doesn't need to update offset
+ * map in TPD.
+ */
+void
+PageSetTransactionSlotInfo(Buffer buf, int trans_slot_id,
+						   FullTransactionId fxid, UndoRecPtr urec_ptr)
+{
+	ZHeapPageOpaque opaque;
+	Page		page;
+	PageHeader	phdr;
+
+	page = BufferGetPage(buf);
+	phdr = (PageHeader) page;
+	opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+
+	if (trans_slot_id < ZHEAP_PAGE_TRANS_SLOTS ||
+		(trans_slot_id == ZHEAP_PAGE_TRANS_SLOTS &&
+		 !ZHeapPageHasTPDSlot(phdr)))
+	{
+		TransInfo  *thistrans = &opaque->transinfo[trans_slot_id - 1];
+
+		thistrans->fxid = fxid;
+		thistrans->urec_ptr = urec_ptr;
+	}
+	else
+	{
+		TPDPageSetTransactionSlotInfo(buf, trans_slot_id, fxid,
+									  urec_ptr);
+	}
+}
+
+/*
+ * PageGetTransactionSlotId - Get the transaction slot for the given epoch and
+ *			xid.
+ *
+ * If the slot is not in the TPD page but the caller has asked to lock the TPD
+ * buffer then do so.  tpd_page_locked will be set to true if the required page
+ * is locked, false, otherwise.
+ */
+int
+PageGetTransactionSlotId(Relation rel, Buffer buf, FullTransactionId fxid,
+						 UndoRecPtr *urec_ptr, bool keepTPDBufLock,
+						 bool locktpd, bool *tpd_page_locked)
+{
+	ZHeapPageOpaque opaque;
+	Page		page;
+	PageHeader	phdr;
+	int			slot_no;
+	int			total_slots_in_page;
+	bool		check_tpd;
+
+	page = BufferGetPage(buf);
+	phdr = (PageHeader) page;
+	opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+
+	if (ZHeapPageHasTPDSlot(phdr))
+	{
+		total_slots_in_page = ZHEAP_PAGE_TRANS_SLOTS - 1;
+		check_tpd = true;
+	}
+	else
+	{
+		total_slots_in_page = ZHEAP_PAGE_TRANS_SLOTS;
+		check_tpd = false;
+	}
+
+	/* Check if the required slot exists on the page. */
+	for (slot_no = 0; slot_no < total_slots_in_page; slot_no++)
+	{
+		TransInfo  *thistrans = &opaque->transinfo[slot_no];
+
+		if (FullTransactionIdEquals(thistrans->fxid, fxid))
+		{
+			*urec_ptr = thistrans->urec_ptr;
+
+			/* Check if TPD has page slot, then lock TPD page */
+			if (locktpd && ZHeapPageHasTPDSlot(phdr))
+			{
+				Assert(tpd_page_locked);
+				*tpd_page_locked = TPDPageLock(rel, buf);
+			}
+
+			return slot_no + 1;
+		}
+	}
+
+	/* Check if the slot exists on the TPD page. */
+	if (check_tpd)
+	{
+		int			tpd_e_slot;
+
+		tpd_e_slot = TPDPageGetSlotIfExists(rel, buf, InvalidOffsetNumber,
+											fxid, urec_ptr,
+											keepTPDBufLock, false);
+		if (tpd_e_slot != InvalidXactSlotId)
+		{
+			/*
+			 * If we get the valid slot then the TPD page must be locked and
+			 * the lock will be retained if asked for.
+			 */
+			if (tpd_page_locked)
+				*tpd_page_locked = keepTPDBufLock;
+			return tpd_e_slot;
+		}
+	}
+	else
+	{
+		/*
+		 * Lock the TPD page if the caller has instructed so and the page has
+		 * tpd slot.
+		 */
+		if (locktpd && ZHeapPageHasTPDSlot(phdr))
+		{
+			Assert(tpd_page_locked);
+			*tpd_page_locked = TPDPageLock(rel, buf);
+		}
+	}
+
+	return InvalidXactSlotId;
+}
+
+/*
+ * PageGetTransactionSlotInfo - Get the transaction slot info for the given
+ *	slot no.
+ */
+void
+PageGetTransactionSlotInfo(Buffer buf, int slot_no, uint32 *epoch,
+						   TransactionId *xid, UndoRecPtr *urec_ptr,
+						   bool keepTPDBufLock)
+{
+	ZHeapPageOpaque opaque;
+	Page		page;
+	PageHeader	phdr;
+
+	page = BufferGetPage(buf);
+	phdr = (PageHeader) page;
+	opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+
+	/*
+	 * Fetch the required information from the transaction slot. The
+	 * transaction slot can either be on the heap page or TPD page.
+	 */
+	if (slot_no < ZHEAP_PAGE_TRANS_SLOTS ||
+		(slot_no == ZHEAP_PAGE_TRANS_SLOTS &&
+		 !ZHeapPageHasTPDSlot(phdr)))
+	{
+		TransInfo  *thistrans = &opaque->transinfo[slot_no - 1];
+
+		if (epoch)
+			*epoch = EpochFromFullTransactionId(thistrans->fxid);
+		if (xid)
+			*xid = XidFromFullTransactionId(thistrans->fxid);
+		if (urec_ptr)
+			*urec_ptr = thistrans->urec_ptr;
+	}
+	else
+	{
+		Assert((ZHeapPageHasTPDSlot(phdr)));
+		(void) TPDPageGetTransactionSlotInfo(buf,
+											 slot_no,
+											 InvalidOffsetNumber,
+											 epoch,
+											 xid,
+											 urec_ptr,
+											 false,
+											 true);
+	}
+}
+
+/*
+ *  MultiPageReserveTransSlot - Reserve the transaction slots on old and
+ *		new buffer.
+ *
+ * Here, we need to ensure that we always first reserve slot in the page
+ * which has corresponding lower numbered TPD page to avoid deadlocks
+ * caused by locking ordering of TPD pages.
+ */
+void
+MultiPageReserveTransSlot(Relation relation,
+						  Buffer oldbuf, Buffer newbuf,
+						  OffsetNumber oldbuf_offnum,
+						  OffsetNumber newbuf_offnum,
+						  FullTransactionId fxid,
+						  UndoRecPtr *oldbuf_prev_urecptr,
+						  UndoRecPtr *newbuf_prev_urecptr,
+						  int *oldbuf_trans_slot_id,
+						  int *newbuf_trans_slot_id,
+						  bool *lock_reacquired)
+{
+	bool		always_extend;
+	bool		is_tpdblk_order_changed;
+	int			slot_id;
+	BlockNumber tmp_new_tpd_blk,
+				tmp_old_tpd_blk;
+	BlockNumber oldbuf_tpd_blk = InvalidBlockNumber;
+	Page		old_heap_page,
+				new_heap_page;
+
+	old_heap_page = BufferGetPage(oldbuf);
+	new_heap_page = BufferGetPage(newbuf);
+
+	/*
+	 * If previously reserved slot is from TPD then we should have TPD page
+	 * into heap buffer.
+	 */
+	Assert(*oldbuf_trans_slot_id <= ZHEAP_PAGE_TRANS_SLOTS ||
+		   ZHeapPageHasTPDSlot((PageHeader) old_heap_page));
+
+	/* If TPD exist, then get corresponding TPD block number for old buffer. */
+	if (ZHeapPageHasTPDSlot((PageHeader) old_heap_page))
+		GetTPDBlockAndOffset(old_heap_page, &oldbuf_tpd_blk, NULL);
+	tmp_old_tpd_blk = oldbuf_tpd_blk;
+
+retry_tpd_lock:
+
+	/* Initialize flags with default values. */
+	always_extend = false;
+	is_tpdblk_order_changed = false;
+
+	/*
+	 * Only if previously reserved slot is from TPD or last slot and now we
+	 * have TPD, then we will check that we can verify slot on old buffer
+	 * first or we should get slot for new buffer first.
+	 */
+	if (*oldbuf_trans_slot_id >= ZHEAP_PAGE_TRANS_SLOTS &&
+		ZHeapPageHasTPDSlot((PageHeader) old_heap_page))
+	{
+		/*
+		 * If TPD exists on both the buffers then reserve the slot in the
+		 * increasing order of TPD blocks to avoid deadlock.
+		 */
+		if (ZHeapPageHasTPDSlot((PageHeader) new_heap_page))
+		{
+			GetTPDBlockAndOffset(new_heap_page, &tmp_new_tpd_blk, NULL);
+
+			/*
+			 * If both the buffers has TPD entry, then reserve the transaction
+			 * slot in increasing order of corresponding TPD blocks to avoid
+			 * deadlock.
+			 */
+			if (tmp_old_tpd_blk > tmp_new_tpd_blk)
+				is_tpdblk_order_changed = true;
+		}
+	}
+
+	/* Now reserve the slots in both the pages. */
+	if (!is_tpdblk_order_changed)
+	{
+		/* Verify the transaction slot for old buffer. */
+		slot_id = PageReserveTransactionSlot(relation,
+											 oldbuf,
+											 oldbuf_offnum,
+											 fxid,
+											 oldbuf_prev_urecptr,
+											 lock_reacquired,
+											 false,
+											 InvalidBuffer,
+											 NULL);
+
+		/*
+		 * If old buffer has TPD page, then TPD block of old buffer should not
+		 * change. We must get a valid slot and wouldn't have reacquired the
+		 * buffer lock as we already have a reserved slot.
+		 */
+		if (oldbuf_tpd_blk != InvalidBlockNumber)
+			GetTPDBlockAndOffset(old_heap_page, &tmp_old_tpd_blk, NULL);
+
+		Assert(!(*lock_reacquired));
+		Assert(slot_id != InvalidXactSlotId);
+		Assert(oldbuf_tpd_blk == InvalidBlockNumber ||
+			   oldbuf_tpd_blk == tmp_old_tpd_blk);
+
+		/*
+		 * If reserved transaction slot for old buffer is from TPD page, then
+		 * for new buffer, we should not allow to use FSM TPD page, instead we
+		 * will extend to get new TPD buffer with higher block number to avoid
+		 * deadlock.
+		 */
+		if (slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+			always_extend = true;
+
+		/* Reserve the transaction slot for new buffer. */
+		*newbuf_trans_slot_id = PageReserveTransactionSlot(relation,
+														   newbuf,
+														   newbuf_offnum + 1,
+														   fxid,
+														   newbuf_prev_urecptr,
+														   lock_reacquired,
+														   always_extend,
+														   oldbuf,
+														   NULL);
+	}
+	else
+	{
+		/* Reserve the transaction slot for new buffer. */
+		*newbuf_trans_slot_id = PageReserveTransactionSlot(relation,
+														   newbuf,
+														   newbuf_offnum + 1,
+														   fxid,
+														   newbuf_prev_urecptr,
+														   lock_reacquired,
+														   false,
+														   oldbuf,
+														   NULL);
+
+		/*
+		 * Try again if the buffer lock is released and reacquired. Or if we
+		 * are not able to reserve any slot.
+		 */
+		if (*lock_reacquired || (*newbuf_trans_slot_id == InvalidXactSlotId))
+			return;
+
+		/*
+		 * If reserved transaction slot for new buffer is from TPD page, then
+		 * we should check block number of TPD page.  Because, it is quite
+		 * possible that if we don't have space in the current TPD page, we
+		 * may get a new TPD page from FSM or by extending the relation that
+		 * may have greater block number as compared to old buffer TPD block.
+		 */
+		if (*newbuf_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		{
+			GetTPDBlockAndOffset(new_heap_page, &tmp_new_tpd_blk, NULL);
+
+			/*
+			 * If TPD block of new buffer gets changed and becomes greater
+			 * than old buffer TPD block, then we should release TPD buffer
+			 * lock of new buffer and try again to avoid deadlock.
+			 *
+			 * For new buffer, there is no guarantee that we will get same TPD
+			 * block after releasing TPD buffer lock, because vacuum can free
+			 * that page, so always try again to reserve slot.
+			 */
+			if (tmp_new_tpd_blk > tmp_old_tpd_blk)
+			{
+				/* Release lock to avoid deadlock. */
+				ReleaseLastTPDBufferByTPDBlock(tmp_new_tpd_blk);
+				goto retry_tpd_lock;
+			}
+		}
+
+		/* Get the transaction slot for old buffer. */
+		slot_id = PageReserveTransactionSlot(relation,
+											 oldbuf,
+											 oldbuf_offnum,
+											 fxid,
+											 oldbuf_prev_urecptr,
+											 lock_reacquired,
+											 false,
+											 InvalidBuffer,
+											 NULL);
+
+		/*
+		 * TPD block of old buffer must not change as we already have a
+		 * reserved slot in the old buffer and for in-progress transactions,
+		 * TPD block can't be pruned.  Due to the same reason, we must get a
+		 * valid slot and wouldn't have reacquired the buffer lock.
+		 */
+		GetTPDBlockAndOffset(old_heap_page, &tmp_old_tpd_blk, NULL);
+		Assert(!(*lock_reacquired));
+		Assert(slot_id != InvalidXactSlotId);
+		Assert(oldbuf_tpd_blk == tmp_old_tpd_blk);
+	}
+
+	/*
+	 * We should definitely get the slot for old page as we have reserved it
+	 * previously, but it is possible that it might have moved to TPD in which
+	 * case it's value will be previous_slot_number + 1.
+	 */
+	Assert((slot_id == *oldbuf_trans_slot_id) ||
+		   (ZHeapPageHasTPDSlot((PageHeader) old_heap_page) &&
+			slot_id == (*oldbuf_trans_slot_id) + 1));
+
+	*oldbuf_trans_slot_id = slot_id;
+}
+
+/*
+ * PageReserveTransactionSlot - Reserve the transaction slot in page.
+ *
+ *	This function returns transaction slot number if either the page already
+ *	has some slot that contains the transaction info or there is an empty
+ *	slot or it manages to reuse some existing slot or it manages to get the
+ *  slot in TPD; otherwise returns InvalidXactSlotId.
+ *
+ *  Note that we always return array location of slot plus one as zeroth slot
+ *  number is reserved for frozen slot number (ZHTUP_SLOT_FROZEN).
+ *
+ *  If we've reserved a transaction slot of a committed but not all-visible
+ *  transaction or a transaction slot from a TPD page, we set slot_reused_or_TPD_slot
+ *  as true, false otherwise.
+ */
+int
+PageReserveTransactionSlot(Relation relation, Buffer buf, OffsetNumber offset,
+						   FullTransactionId fxid,
+						   UndoRecPtr *urec_ptr, bool *lock_reacquired,
+						   bool always_extend, Buffer other_buf,
+						   bool *slot_reused_or_TPD_slot)
+{
+	ZHeapPageOpaque opaque;
+	Page		page;
+	PageHeader	phdr;
+	int			latestFreeTransSlot = InvalidXactSlotId;
+	int			slot_no;
+	int			total_slots_in_page;
+	bool		check_tpd;
+
+	*lock_reacquired = false;
+
+	page = BufferGetPage(buf);
+	phdr = (PageHeader) page;
+	opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+
+	if (ZHeapPageHasTPDSlot(phdr))
+	{
+		total_slots_in_page = ZHEAP_PAGE_TRANS_SLOTS - 1;
+		check_tpd = true;
+	}
+	else
+	{
+		total_slots_in_page = ZHEAP_PAGE_TRANS_SLOTS;
+		check_tpd = false;
+	}
+
+	/*
+	 * For temp relations, we don't have to check all the slots since no other
+	 * backend can access the same relation. If a slot is available, we return
+	 * it from here. Else, we freeze the slot in PageFreezeTransSlots.
+	 *
+	 * XXX For temp tables, oldestXidWithEpochHavingUndo is not relevant as
+	 * the undo for them can be discarded on commit.  Hence, comparing xid
+	 * with oldestXidWithEpochHavingUndo during visibility checks can lead to
+	 * incorrect behavior.  To avoid that, we can mark the tuple as frozen for
+	 * any previous transaction id.  In that way, we don't have to compare the
+	 * previous xid of tuple with oldestXidWithEpochHavingUndo.
+	 */
+	if (RELATION_IS_LOCAL(relation))
+	{
+		TransInfo  *thistrans;
+
+		/* We can't access temp tables of other backends. */
+		Assert(!RELATION_IS_OTHER_TEMP(relation));
+
+		slot_no = 0;
+		thistrans = &opaque->transinfo[slot_no];
+
+		if (FullTransactionIdEquals(thistrans->fxid, fxid))
+		{
+			*urec_ptr = thistrans->urec_ptr;
+			return (slot_no + 1);
+		}
+		else if (!FullTransactionIdIsValid(thistrans->fxid))
+			latestFreeTransSlot = slot_no;
+	}
+	else
+	{
+		for (slot_no = 0; slot_no < total_slots_in_page; slot_no++)
+		{
+			TransInfo  *thistrans = &opaque->transinfo[slot_no];
+
+			if (FullTransactionIdEquals(thistrans->fxid, fxid))
+			{
+				*urec_ptr = thistrans->urec_ptr;
+				return (slot_no + 1);
+			}
+			else if (!FullTransactionIdIsValid(thistrans->fxid) &&
+					 latestFreeTransSlot == InvalidXactSlotId)
+				latestFreeTransSlot = slot_no;
+		}
+	}
+
+	/* Check if we already have a slot on the TPD page */
+	if (check_tpd)
+	{
+		int			tpd_e_slot;
+
+		tpd_e_slot = TPDPageGetSlotIfExists(relation, buf, offset,
+											fxid, urec_ptr, true, true);
+		if (tpd_e_slot != InvalidXactSlotId)
+			return tpd_e_slot;
+	}
+
+
+	if (latestFreeTransSlot >= 0)
+	{
+		*urec_ptr = opaque->transinfo[latestFreeTransSlot].urec_ptr;
+		return (latestFreeTransSlot + 1);
+	}
+
+	/* no transaction slot available, try to reuse some existing slot */
+	if (PageFreezeTransSlots(relation, buf, lock_reacquired, NULL, 0,
+							 other_buf))
+	{
+		/*
+		 * If the lock is reacquired inside, then we allow callers to reverify
+		 * the condition whether then can still perform the required
+		 * operation.
+		 */
+		if (*lock_reacquired)
+			return InvalidXactSlotId;
+
+		/*
+		 * TPD entry might get pruned in TPDPageGetSlotIfExists, so recheck
+		 * it.
+		 */
+		if (ZHeapPageHasTPDSlot(phdr))
+			total_slots_in_page = ZHEAP_PAGE_TRANS_SLOTS - 1;
+		else
+			total_slots_in_page = ZHEAP_PAGE_TRANS_SLOTS;
+
+		for (slot_no = 0; slot_no < total_slots_in_page; slot_no++)
+		{
+			TransInfo  *thistrans = &opaque->transinfo[slot_no];
+
+			if (!FullTransactionIdIsValid(thistrans->fxid))
+			{
+				*urec_ptr = thistrans->urec_ptr;
+				if (slot_reused_or_TPD_slot && *urec_ptr != InvalidUndoRecPtr)
+					*slot_reused_or_TPD_slot = true;
+				return (slot_no + 1);
+			}
+		}
+
+		/*
+		 * After freezing transaction slots, we should get at least one free
+		 * slot.
+		 */
+		Assert(false);
+	}
+	Assert(!RELATION_IS_LOCAL(relation));
+
+	/*
+	 * Reserve the transaction slot in TPD.  First we check if there already
+	 * exists an TPD entry for this page, then reserve in that, otherwise,
+	 * allocate a new TPD entry and reserve the slot in it.
+	 */
+	if (ZHeapPageHasTPDSlot(phdr))
+	{
+		int			tpd_e_slot;
+
+		tpd_e_slot = TPDPageReserveTransSlot(relation, buf, offset,
+											 urec_ptr, lock_reacquired,
+											 always_extend, other_buf);
+
+		if (tpd_e_slot != InvalidXactSlotId)
+		{
+			if (slot_reused_or_TPD_slot)
+				*slot_reused_or_TPD_slot = true;
+			return tpd_e_slot;
+		}
+
+		/*
+		 * Fixme : We should allow to allocate bigger TPD entries or support
+		 * chained TPD entries.
+		 */
+		return InvalidXactSlotId;
+	}
+	else
+	{
+		slot_no = TPDAllocateAndReserveTransSlot(relation, buf, offset,
+												 urec_ptr,
+												 always_extend);
+		if (slot_no != InvalidXactSlotId)
+		{
+			if (slot_reused_or_TPD_slot)
+				*slot_reused_or_TPD_slot = true;
+			return slot_no;
+		}
+	}
+
+	/* no transaction slot available */
+	return InvalidXactSlotId;
+}
+
+/*
+ * zheap_freeze_or_invalidate_tuples - Clear the slot information or set
+ *									   invalid_xact flags.
+ *
+ * 	Process all the tuples on the page and match their transaction slot with
+ *	the input slot array, if tuple is pointing to the slot then set the tuple
+ *  slot as ZHTUP_SLOT_FROZEN if is frozen is true otherwise set
+ *  ZHEAP_INVALID_XACT_SLOT flag on the tuple
+ */
+void
+zheap_freeze_or_invalidate_tuples(Buffer buf, int nSlots, int *slots,
+								  bool isFrozen, bool TPDSlot)
+{
+	OffsetNumber offnum,
+				maxoff;
+	Page		page = BufferGetPage(buf);
+	int			i;
+
+	/* clear the slot info from tuples */
+	maxoff = PageGetMaxOffsetNumber(page);
+
+	for (offnum = FirstOffsetNumber;
+		 offnum <= maxoff;
+		 offnum = OffsetNumberNext(offnum))
+	{
+		ZHeapTupleHeader tup_hdr;
+		ItemId		itemid;
+		int			trans_slot;
+
+		itemid = PageGetItemId(page, offnum);
+
+		if (ItemIdIsDead(itemid))
+			continue;
+
+		if (!ItemIdIsUsed(itemid))
+		{
+			if (!ItemIdHasPendingXact(itemid))
+				continue;
+			trans_slot = ItemIdGetTransactionSlot(itemid);
+		}
+		else if (ItemIdIsDeleted(itemid))
+		{
+			trans_slot = ItemIdGetTransactionSlot(itemid);
+		}
+		else
+		{
+			tup_hdr = (ZHeapTupleHeader) PageGetItem(page, itemid);
+			trans_slot = ZHeapTupleHeaderGetXactSlot(tup_hdr);
+		}
+
+		/* If we are freezing TPD slot then get the actual slot from the TPD. */
+		if (TPDSlot)
+		{
+			/* Tuple is not pointing to TPD slot so skip it. */
+			if (trans_slot < ZHEAP_PAGE_TRANS_SLOTS)
+				continue;
+
+			/*
+			 * If we come for freezing the TPD slot the fetch the exact slot
+			 * info from the TPD.
+			 */
+			trans_slot = TPDPageGetTransactionSlotInfo(buf, trans_slot, offnum,
+													   NULL, NULL, NULL, false,
+													   false);
+
+			/*
+			 * The input slots array always stores the slot index which starts
+			 * from 0, even for TPD slots, the index will start from 0. So
+			 * convert it into the slot index.
+			 */
+			trans_slot -= (ZHEAP_PAGE_TRANS_SLOTS + 1);
+		}
+		else
+		{
+			/*
+			 * The slot number on tuple is always array location of slot plus
+			 * one, so we need to subtract one here before comparing it with
+			 * frozen slots.  See PageReserveTransactionSlot.
+			 */
+			trans_slot -= 1;
+		}
+
+		for (i = 0; i < nSlots; i++)
+		{
+			if (trans_slot == slots[i])
+			{
+				/*
+				 * Set transaction slots of tuple as frozen to indicate tuple
+				 * is all visible and mark the deleted itemids as dead.
+				 */
+				if (isFrozen)
+				{
+					if (!ItemIdIsUsed(itemid))
+					{
+						/*
+						 * This must be unused entry which has xact
+						 * information.
+						 */
+						Assert(ItemIdHasPendingXact(itemid));
+
+						/*
+						 * The pending xact must be committed if the
+						 * corresponding slot is being marked as frozen.  So,
+						 * clear the pending xact and transaction slot
+						 * information from itemid.
+						 */
+						ItemIdSetUnused(itemid);
+					}
+					else if (ItemIdIsDeleted(itemid))
+					{
+						/*
+						 * The deleted item must not be visible to anyone if
+						 * the corresponding slot is being marked as frozen.
+						 * So, marking it as dead.
+						 */
+						ItemIdSetDead(itemid);
+					}
+					else
+					{
+						tup_hdr = (ZHeapTupleHeader) PageGetItem(page, itemid);
+						ZHeapTupleHeaderSetXactSlot(tup_hdr, ZHTUP_SLOT_FROZEN);
+					}
+				}
+				else
+				{
+					/*
+					 * We just append the invalid xact flag in the
+					 * tuple/itemid to indicate that for this tuple/itemid we
+					 * need to fetch the transaction information from undo
+					 * record.  Also, we ensure to clear the transaction
+					 * information from unused itemid.
+					 */
+					if (!ItemIdIsUsed(itemid))
+					{
+						/*
+						 * This must be unused entry which has xact
+						 * information.
+						 */
+						Assert(ItemIdHasPendingXact(itemid));
+
+						/*
+						 * The pending xact is committed.  So, clear the
+						 * pending xact and transaction slot information from
+						 * itemid.
+						 */
+						ItemIdSetUnused(itemid);
+					}
+					else if (ItemIdIsDeleted(itemid))
+						ItemIdSetInvalidXact(itemid);
+					else
+					{
+						tup_hdr = (ZHeapTupleHeader) PageGetItem(page, itemid);
+						tup_hdr->t_infomask |= ZHEAP_INVALID_XACT_SLOT;
+					}
+					break;
+				}
+				break;
+			}
+		}
+	}
+}
+
+/*
+ * PageFreezeTransSlots - Make the transaction slots available for reuse.
+ *
+ *	This function tries to free up some existing transaction slots so that
+ *	they can be reused.  To reuse the slot, it needs to ensure one of the below
+ *	conditions:
+ *	(a) the xid is committed, all-visible and doesn't have pending rollback
+ *	to perform.
+ *	(b) if the xid is committed, then ensure to mark a special flag on the
+ *	tuples that are modified by that xid on the current page.
+ *	(c) if the xid is rolled back, then ensure that rollback is performed or
+ *	at least undo actions for this page have been replayed.
+ *
+ *	For committed/aborted transactions, we simply clear the xid from the
+ *	transaction slot and undo record pointer is kept as it is to ensure that
+ *	we don't break the undo chain for that slot. We also mark the tuples that
+ *	are modified by committed xid with a special flag indicating that slot for
+ *	this tuple is reused.  The special flag is just an indication that the
+ *	transaction information of the transaction that has modified the tuple can
+ *	be retrieved from the undo.
+ *
+ *	If we don't do so, then after that slot got reused for some other
+ *	unrelated transaction, it might become tricky to traverse the undo chain.
+ *	In such a case, it is quite possible that the particular tuple has not
+ *	been modified, but it is still pointing to transaction slot which has been
+ *	reused by new transaction and that transaction is still not committed.
+ *	During the visibility check for such a tuple, it can appear that the tuple
+ *	is modified by current transaction which is clearly wrong and can lead to
+ *	wrong results.  One such case would be when we try to fetch the commandid
+ *	for that tuple to check the visibility, it will fetch the commandid for a
+ *	different transaction that is already committed.
+ *
+ *	The basic principle used here is to ensure that we can always fetch the
+ *	transaction information of tuple until it is frozen (committed and
+ *	all-visible).
+ *
+ *	This also ensures that we are consistent with how other operations work in
+ *	zheap i.e. the tuple always reflect the current state.
+ *
+ *	We don't need any special handling for the tuples that are locked by
+ *	multiple transactions (aka tuples that have MULTI_LOCKERS bit set).
+ *	Basically, we always maintain either strongest lockers or latest lockers
+ *	(when all the lockers are of same mode) transaction slot on the tuple.
+ *	In either case, we should be able to detect the visibility of tuple based
+ *	on the latest locker information.
+ *
+ *	use_aborted_slot indicates whether we can reuse the slot of aborted
+ *  transaction or not.
+ *
+ *	This function assumes that the caller already has Exclusive lock on the
+ *	buffer.
+ *
+ *	other_buf will be valid only in case of non in-place update in two
+ *	different buffers and other_buf will be old buffer.  Caller of
+ *	MultiPageReserveTransSlot will not try to release lock again.
+ *
+ *	This function returns true if it manages to free some transaction slot,
+ *	false otherwise.
+ */
+bool
+PageFreezeTransSlots(Relation relation, Buffer buf, bool *lock_reacquired,
+					 TransInfo *transinfo, int num_slots, Buffer other_buf)
+{
+	FullTransactionId oldestXidWithEpochHavingUndo;
+	int			slot_no;
+	int		   *frozen_slots = NULL;
+	int			nFrozenSlots = 0;
+	int		   *completed_xact_slots = NULL;
+	uint16		nCompletedXactSlots = 0;
+	int		   *aborted_xact_slots = NULL;
+	int			nAbortedXactSlots = 0;
+	bool		TPDSlot;
+	Page		page;
+	bool		result = false;
+
+	page = BufferGetPage(buf);
+
+	/*
+	 * If the num_slots is 0 then the caller wants to freeze the page slots so
+	 * get the transaction slots information from the page.
+	 */
+	if (num_slots == 0)
+	{
+		PageHeader	phdr;
+		ZHeapPageOpaque opaque;
+
+		phdr = (PageHeader) page;
+		opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+
+		if (ZHeapPageHasTPDSlot(phdr))
+			num_slots = ZHEAP_PAGE_TRANS_SLOTS - 1;
+		else
+			num_slots = ZHEAP_PAGE_TRANS_SLOTS;
+
+		transinfo = opaque->transinfo;
+		TPDSlot = false;
+	}
+	else
+	{
+		Assert(num_slots > 0);
+		TPDSlot = true;
+	}
+
+	oldestXidWithEpochHavingUndo = FullTransactionIdFromU64(
+															pg_atomic_read_u64(&ProcGlobal->oldestFullXidHavingUnappliedUndo));
+
+	frozen_slots = palloc0(num_slots * sizeof(int));
+
+	/*
+	 * Clear the slot information from tuples.  The basic idea is to collect
+	 * all the transaction slots that can be cleared.  Then traverse the page
+	 * to see if any tuple has marking for any of the slots, if so, just clear
+	 * the slot information from the tuple.
+	 *
+	 * For temp relations, we can freeze the first slot since no other backend
+	 * can access the same relation.
+	 */
+	if (RELATION_IS_LOCAL(relation))
+		frozen_slots[nFrozenSlots++] = 0;
+	else
+	{
+		for (slot_no = 0; slot_no < num_slots; slot_no++)
+		{
+			FullTransactionId slot_fxid = transinfo[slot_no].fxid;
+
+			/*
+			 * Transaction slot can be considered frozen if it belongs to
+			 * transaction id is old enough that it is all visible.
+			 */
+			if (FullTransactionIdPrecedes(slot_fxid, oldestXidWithEpochHavingUndo))
+				frozen_slots[nFrozenSlots++] = slot_no;
+		}
+	}
+
+	if (nFrozenSlots > 0)
+	{
+		FullTransactionId latestfxid = InvalidFullTransactionId;
+		int			i;
+		int			slot_no;
+
+
+		START_CRIT_SECTION();
+
+		/* clear the transaction slot info on tuples */
+		zheap_freeze_or_invalidate_tuples(buf, nFrozenSlots, frozen_slots,
+										  true, TPDSlot);
+
+		/* Initialize the frozen slots. */
+		if (TPDSlot)
+		{
+			for (i = 0; i < nFrozenSlots; i++)
+			{
+				TransInfo  *thistrans;
+				int			tpd_slot_id;
+
+				slot_no = frozen_slots[i];
+				thistrans = &transinfo[slot_no];
+
+				/* Remember the latest xid. */
+				if (FullTransactionIdFollows(thistrans->fxid, latestfxid))
+					latestfxid = thistrans->fxid;
+
+				/* Calculate the actual slot no. */
+				tpd_slot_id = slot_no + ZHEAP_PAGE_TRANS_SLOTS + 1;
+
+				/* Initialize the TPD slot. */
+				TPDPageSetTransactionSlotInfo(buf, tpd_slot_id,
+											  InvalidFullTransactionId,
+											  InvalidUndoRecPtr);
+			}
+		}
+		else
+		{
+			for (i = 0; i < nFrozenSlots; i++)
+			{
+				TransInfo  *thistrans;
+
+				slot_no = frozen_slots[i];
+				thistrans = &transinfo[slot_no];
+
+				/* Remember the latest xid. */
+				if (FullTransactionIdFollows(thistrans->fxid, latestfxid))
+					latestfxid = thistrans->fxid;
+
+				thistrans->fxid = InvalidFullTransactionId;
+				thistrans->urec_ptr = InvalidUndoRecPtr;
+			}
+		}
+
+		MarkBufferDirty(buf);
+
+		/*
+		 * xlog Stuff
+		 *
+		 * Log all the frozen_slots number for which we need to clear the
+		 * transaction slot information.  Also, note down the latest xid
+		 * corresponding to the frozen slots. This is required to ensure that
+		 * no standby query conflicts with the frozen xids.
+		 */
+		if (RelationNeedsWAL(relation))
+		{
+			xl_zheap_freeze_xact_slot xlrec = {0};
+			XLogRecPtr	recptr;
+
+			XLogBeginInsert();
+
+			xlrec.nFrozen = nFrozenSlots;
+			xlrec.lastestFrozenXid = XidFromFullTransactionId(latestfxid);
+
+			XLogRegisterData((char *) &xlrec, SizeOfZHeapFreezeXactSlot);
+
+			/*
+			 * Ideally we need the frozen slots information when WAL needs to
+			 * be applied on the page, but in case of the TPD slots freeze we
+			 * need the frozen slot information for both heap page as well as
+			 * for the TPD page.  So the problem is that if we register with
+			 * any one of the buffer it might happen that the data did not
+			 * registered due to fpw of that buffer but we need that data for
+			 * another buffer.
+			 */
+			XLogRegisterData((char *) frozen_slots, nFrozenSlots * sizeof(int));
+			XLogRegisterBuffer(0, buf, REGBUF_STANDARD);
+			if (TPDSlot)
+				RegisterTPDBuffer(page, 1);
+
+			recptr = XLogInsert(RM_ZHEAP_ID, XLOG_ZHEAP_FREEZE_XACT_SLOT);
+			PageSetLSN(page, recptr);
+
+			if (TPDSlot)
+				TPDPageSetLSN(page, recptr);
+		}
+
+		END_CRIT_SECTION();
+
+		result = true;
+		goto cleanup;
+	}
+
+	Assert(!RELATION_IS_LOCAL(relation));
+	completed_xact_slots = palloc0(num_slots * sizeof(int));
+	aborted_xact_slots = palloc0(num_slots * sizeof(int));
+
+	/*
+	 * Try to reuse transaction slots of committed/aborted transactions. This
+	 * is just like above but it will maintain a link to the previous
+	 * transaction undo record in this slot.  This is to ensure that if there
+	 * is still any alive snapshot to which this transaction is not visible,
+	 * it can fetch the record from undo and check the visibility.
+	 */
+	for (slot_no = 0; slot_no < num_slots; slot_no++)
+	{
+		TransactionId slot_xid =
+		XidFromFullTransactionId(transinfo[slot_no].fxid);
+
+		if (!TransactionIdIsInProgress(slot_xid))
+		{
+			if (TransactionIdDidCommit(slot_xid))
+				completed_xact_slots[nCompletedXactSlots++] = slot_no;
+			else
+				aborted_xact_slots[nAbortedXactSlots++] = slot_no;
+		}
+	}
+
+	if (nCompletedXactSlots > 0)
+	{
+		int			i;
+		int			slot_no;
+
+
+		START_CRIT_SECTION();
+
+		/* clear the transaction slot info on tuples */
+		zheap_freeze_or_invalidate_tuples(buf, nCompletedXactSlots,
+										  completed_xact_slots, false, TPDSlot);
+
+		/*
+		 * Clear the xid information from the slot but keep the undo record
+		 * pointer as it is so that undo records of the transaction are
+		 * accessible by traversing slot's undo chain even though the slots
+		 * are reused.
+		 */
+		if (TPDSlot)
+		{
+			for (i = 0; i < nCompletedXactSlots; i++)
+			{
+				int			tpd_slot_id;
+
+				slot_no = completed_xact_slots[i];
+				/* calculate the actual slot no. */
+				tpd_slot_id = slot_no + ZHEAP_PAGE_TRANS_SLOTS + 1;
+
+				/* Clear xid from the TPD slot but keep the urec_ptr intact. */
+				TPDPageSetTransactionSlotInfo(buf, tpd_slot_id,
+											  InvalidFullTransactionId,
+											  transinfo[slot_no].urec_ptr);
+			}
+		}
+		else
+		{
+			for (i = 0; i < nCompletedXactSlots; i++)
+			{
+				slot_no = completed_xact_slots[i];
+				transinfo[slot_no].fxid = InvalidFullTransactionId;
+			}
+		}
+		MarkBufferDirty(buf);
+
+		/*
+		 * Xlog Stuff
+		 */
+		if (RelationNeedsWAL(relation))
+		{
+			XLogRecPtr	recptr;
+
+			XLogBeginInsert();
+
+
+			/* See comments while registering frozen slot. */
+			XLogRegisterData((char *) &nCompletedXactSlots, sizeof(uint16));
+			XLogRegisterData((char *) completed_xact_slots, nCompletedXactSlots * sizeof(int));
+
+			XLogRegisterBuffer(0, buf, REGBUF_STANDARD);
+
+			if (TPDSlot)
+				RegisterTPDBuffer(page, 1);
+
+			recptr = XLogInsert(RM_ZHEAP_ID, XLOG_ZHEAP_INVALID_XACT_SLOT);
+			PageSetLSN(page, recptr);
+
+			if (TPDSlot)
+				TPDPageSetLSN(page, recptr);
+		}
+
+		END_CRIT_SECTION();
+
+		result = true;
+		goto cleanup;
+	}
+	else if (nAbortedXactSlots)
+	{
+		int			i;
+		int			slot_no;
+		UndoRecPtr *urecptr = palloc(nAbortedXactSlots * sizeof(UndoRecPtr));
+		FullTransactionId *fxid = palloc(nAbortedXactSlots * sizeof(FullTransactionId));
+
+		/* Collect slot information before releasing the lock. */
+		for (i = 0; i < nAbortedXactSlots; i++)
+		{
+			TransInfo  *thistrans = &transinfo[aborted_xact_slots[i]];
+
+			urecptr[i] = thistrans->urec_ptr;
+			fxid[i] = thistrans->fxid;
+		}
+
+		/*
+		 * We need to release and the lock before applying undo actions for a
+		 * page as we might need to traverse the long undo chain for a page.
+		 */
+		LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+
+		/*
+		 * Release the lock on the other buffer to avoid deadlock as we need
+		 * to relock the new buffer again.  We could optimize here by
+		 * releasing the lock on old buffer conditionally (when the old block
+		 * number is bigger than new block number), but that would complicate
+		 * the handling.  If we ever want to deal with it, we need to ensure
+		 * that after reacquiring lock on new page, it is still a heap page
+		 * and also we need to pass this information to the caller.
+		 */
+		if (BufferIsValid(other_buf))
+			LockBuffer(other_buf, BUFFER_LOCK_UNLOCK);
+
+		/*
+		 * XXX We release the TPD buffers here even when we are operating on
+		 * heap page slots as we might need to require them during the
+		 * processing of undo actions.  We can optimize it by passing some
+		 * flag, but that seems over complication as we anyway need to release
+		 * and reacquire the lock on TPD buffers after processing the undo
+		 * actions.
+		 *
+		 * It is okay to release all the TPD buffers here as the callers will
+		 * anyway reacquire the lock heap and tpd buffers again.
+		 *
+		 * Instead of just unlocking the TPD buffer like heap buffer its okay
+		 * to unlock and release, because next time while trying to reserve
+		 * the slot if we get the slot in TPD then anyway we will pin it
+		 * again.
+		 *
+		 * Releasing all TPD buffers can release the TPD buffer which was not
+		 * used for current heap page (in case of non-in-place updates via
+		 * MultiPageReserveTransSlot), but that is okay because we anyway need
+		 * to reacquire heap and TPD buffer locks by the caller. This also
+		 * avoids the risk of deadlock where someone acquires the lock on heap
+		 * page before we can reacquire it and waits for the TPD lock held by
+		 * us, so we will wait on that process to release the lock on heap
+		 * page and that process will wait on use.
+		 */
+		UnlockReleaseTPDBuffers();
+
+		for (i = 0; i < nAbortedXactSlots; i++)
+		{
+			slot_no = aborted_xact_slots[i] + 1;
+			process_and_execute_undo_actions_page(urecptr[i],
+												  relation,
+												  buf,
+												  fxid[i],
+												  slot_no);
+		}
+
+		LockBuffer(buf, BUFFER_LOCK_EXCLUSIVE);
+		*lock_reacquired = true;
+
+		pfree(urecptr);
+		pfree(fxid);
+
+		result = true;
+		goto cleanup;
+	}
+
+cleanup:
+	if (frozen_slots != NULL)
+		pfree(frozen_slots);
+	if (completed_xact_slots != NULL)
+		pfree(completed_xact_slots);
+	if (aborted_xact_slots != NULL)
+		pfree(aborted_xact_slots);
+
+	return result;
+}
+
+/*
+ * ZHeapTupleGetCid - Retrieve command id from tuple's undo record.
+ *
+ * It is expected that the caller of this function has at least read lock
+ * on the buffer.
+ */
+CommandId
+ZHeapTupleGetCid(ZHeapTuple zhtup, Buffer buf, UndoRecPtr urec_ptr,
+				 int trans_slot_id)
+{
+	UnpackedUndoRecord *urec;
+	CommandId	current_cid;
+	bool		TPDSlot = true;
+	ZHeapTupleTransInfo zinfo;
+
+	/*
+	 * For undo tuple caller will pass the valid slot id otherwise we can get
+	 * it directly from the tuple.
+	 */
+	if (trans_slot_id == InvalidXactSlotId)
+	{
+		trans_slot_id = ZHeapTupleHeaderGetXactSlot(zhtup->t_data);
+		TPDSlot = false;
+	}
+
+	/*
+	 * If urec_ptr is not provided, fetch the latest undo pointer from the
+	 * page.
+	 */
+	if (!UndoRecPtrIsValid(urec_ptr))
+	{
+		GetTransactionSlotInfo(buf,
+							   ItemPointerGetOffsetNumber(&zhtup->t_self),
+							   trans_slot_id,
+							   true,
+							   TPDSlot,
+							   &zinfo);
+	}
+	else
+	{
+		GetTransactionSlotInfo(buf,
+							   ItemPointerGetOffsetNumber(&zhtup->t_self),
+							   trans_slot_id,
+							   true,
+							   TPDSlot,
+							   &zinfo);
+		zinfo.urec_ptr = urec_ptr;
+	}
+
+	if (zinfo.trans_slot == ZHTUP_SLOT_FROZEN)
+		return InvalidCommandId;
+
+	if (FullTransactionIdOlderThanAllUndo(zinfo.epoch_xid))
+		return InvalidCommandId;
+
+	Assert(UndoRecPtrIsValid(zinfo.urec_ptr));
+	urec = UndoFetchRecord(zinfo.urec_ptr,
+						   ItemPointerGetBlockNumber(&zhtup->t_self),
+						   ItemPointerGetOffsetNumber(&zhtup->t_self),
+						   InvalidTransactionId,
+						   NULL,
+						   ZHeapSatisfyUndoRecord);
+	if (urec == NULL)
+		return InvalidCommandId;
+
+	current_cid = urec->uur_cid;
+
+	UndoRecordRelease(urec);
+
+	return current_cid;
+}
+
+/*
+ * ZHeapTupleGetSubXid - Retrieve subtransaction id from tuple's undo record.
+ *
+ * It is expected that caller of this function has at least read lock.
+ *
+ * Note that we don't handle ZHEAP_INVALID_XACT_SLOT as this function is only
+ * called for in-progress transactions.  If we need to call it for some other
+ * purpose, then we might need to deal with ZHEAP_INVALID_XACT_SLOT.
+ */
+void
+ZHeapTupleGetSubXid(Buffer buf, OffsetNumber offnum, UndoRecPtr urec_ptr,
+					SubTransactionId *subxid)
+{
+	UnpackedUndoRecord *urec;
+
+	*subxid = InvalidSubTransactionId;
+
+	Assert(UndoRecPtrIsValid(urec_ptr));
+	urec = UndoFetchRecord(urec_ptr,
+						   BufferGetBlockNumber(buf),
+						   offnum,
+						   InvalidTransactionId,
+						   NULL,
+						   ZHeapSatisfyUndoRecord);
+
+	/*
+	 * We mostly expect urec here to be valid as it try to fetch
+	 * subtransactionid of tuples that are visible to the snapshot, so
+	 * corresponding undo record can't be discarded.
+	 *
+	 * In case when it is called while index creation, it might be possible
+	 * that the transaction that updated the tuple is committed and is not
+	 * present the calling transaction's snapshot (it uses snapshotany while
+	 * index creation), hence undo is discarded.
+	 */
+	if (urec == NULL)
+		return;
+
+	if (urec->uur_info & UREC_INFO_PAYLOAD_CONTAINS_SUBXACT)
+	{
+		Assert(urec->uur_payload.len > 0);
+
+		/*
+		 * For UNDO_UPDATE, we first store the CTID, then transaction slot and
+		 * after that subtransaction id in payload.  For UNDO_XID_LOCK_ONLY,
+		 * we first store the Lockmode, then transaction slot and after that
+		 * subtransaction id.  So retrieve accordingly.
+		 */
+		if (urec->uur_info & UREC_INFO_PAYLOAD_CONTAINS_SLOT)
+		{
+			if (urec->uur_type == UNDO_UPDATE)
+				*subxid = *(int *) ((char *) urec->uur_payload.data +
+									sizeof(ItemPointerData) + sizeof(TransactionId));
+			else if (urec->uur_type == UNDO_XID_LOCK_ONLY ||
+					 urec->uur_type == UNDO_XID_LOCK_FOR_UPDATE ||
+					 urec->uur_type == UNDO_XID_MULTI_LOCK_ONLY)
+				*subxid = *(int *) ((char *) urec->uur_payload.data +
+									sizeof(LockTupleMode) + sizeof(TransactionId));
+			else
+				*subxid = *(int *) ((char *) urec->uur_payload.data +
+									sizeof(TransactionId));
+		}
+		else
+		{
+			if (urec->uur_type == UNDO_UPDATE)
+				*subxid = *(int *) ((char *) urec->uur_payload.data +
+									sizeof(ItemPointerData));
+			else if (urec->uur_type == UNDO_XID_LOCK_ONLY ||
+					 urec->uur_type == UNDO_XID_LOCK_FOR_UPDATE ||
+					 urec->uur_type == UNDO_XID_MULTI_LOCK_ONLY)
+				*subxid = *(int *) ((char *) urec->uur_payload.data +
+									sizeof(LockTupleMode));
+			else
+				*subxid = *(SubTransactionId *) urec->uur_payload.data;
+		}
+	}
+
+	UndoRecordRelease(urec);
+}
+
+/*
+ * ZHeapTupleGetSpecToken - Retrieve speculative token from tuple's undo
+ *			record.
+ *
+ * It is expected that caller of this function has at least read lock
+ * on the buffer.
+ */
+void
+ZHeapTupleGetSpecToken(ZHeapTuple zhtup, Buffer buf, UndoRecPtr urec_ptr,
+					   uint32 *specToken)
+{
+	UnpackedUndoRecord *urec;
+
+	urec = UndoFetchRecord(urec_ptr,
+						   ItemPointerGetBlockNumber(&zhtup->t_self),
+						   ItemPointerGetOffsetNumber(&zhtup->t_self),
+						   InvalidTransactionId,
+						   NULL,
+						   ZHeapSatisfyUndoRecord);
+
+	/*
+	 * We always expect urec to be valid as it try to fetch speculative token
+	 * of tuples for which inserting transaction hasn't been committed.  So,
+	 * corresponding undo record can't be discarded.
+	 */
+	Assert(urec);
+
+	*specToken = *(uint32 *) urec->uur_payload.data;
+
+	UndoRecordRelease(urec);
+}
+
+/*
+ * ZHeapTupleHeaderAdvanceLatestRemovedXid - Advance the latestRemovedXid, if
+ * tuple is deleted by a transaction greater than latestRemovedXid.  This is
+ * required to generate conflicts on hot standby.
+ *
+ * If we change this function then we need a similar change in
+ * *_xlog_vacuum_get_latestRemovedXid functions as well.
+ *
+ * This is quite similar to HeapTupleHeaderAdvanceLatestRemovedXid.
+ */
+void
+ZHeapTupleHeaderAdvanceLatestRemovedXid(ZHeapTupleHeader tuple,
+										TransactionId xid,
+										TransactionId *latestRemovedXid)
+{
+	/*
+	 * Ignore tuples inserted by an aborted transaction.
+	 *
+	 * XXX we can ignore the tuple if it was non-in-place updated/deleted by
+	 * the inserting transaction, but for that we need to traverse the
+	 * complete undo chain to find the root tuple, is it really worth?
+	 */
+	if (TransactionIdDidCommit(xid))
+	{
+		Assert(tuple->t_infomask & ZHEAP_DELETED ||
+			   tuple->t_infomask & ZHEAP_UPDATED);
+		if (TransactionIdFollows(xid, *latestRemovedXid))
+			*latestRemovedXid = xid;
+	}
+
+	/* *latestRemovedXid may still be invalid at end */
+}
+
+/*
+ * zheap_multi_insert	- insert multiple tuple into a zheap
+ *
+ * Similar to heap_multi_insert(), but inserts zheap tuples.
+ */
+void
+zheap_multi_insert(Relation relation, TupleTableSlot **slots, int ntuples,
+				   CommandId cid, int options, BulkInsertState bistate)
+{
+	ZHeapTuple *zheaptuples;
+	int			i;
+	int			ndone;
+	char	   *scratch = NULL;
+	Page		page;
+	bool		needwal;
+	bool		need_cids = RelationIsAccessibleInLogicalDecoding(relation);
+	Size		saveFreeSpace;
+	FullTransactionId fxid = GetTopFullTransactionId();
+	bool		lock_reacquired;
+	bool		skip_undo;
+
+	needwal = RelationNeedsWAL(relation);
+	saveFreeSpace = RelationGetTargetPageFreeSpace(relation,
+												   HEAP_DEFAULT_FILLFACTOR);
+
+	/*
+	 * We can skip inserting undo records if the tuples are to be marked as
+	 * frozen.
+	 */
+	skip_undo = (options & ZHEAP_INSERT_FROZEN);
+
+	/* Toast and set header data in all the tuples */
+	zheaptuples = palloc(ntuples * sizeof(ZHeapTuple));
+	for (i = 0; i < ntuples; i++)
+	{
+		zheaptuples[i] = zheap_prepare_insert(relation,
+											  ExecGetZHeapTupleFromSlot(slots[i]), options, 0);
+
+		if (slots[i]->tts_tableOid != InvalidOid)
+			zheaptuples[i]->t_tableOid = slots[i]->tts_tableOid;
+	}
+
+	/*
+	 * Allocate some memory to use for constructing the WAL record. Using
+	 * palloc() within a critical section is not safe, so we allocate this
+	 * beforehand. This has consideration that offset ranges and tuples to be
+	 * stored in page will have size lesser than BLCKSZ. This is true since a
+	 * zheap page contains page header and transaction slots in special area
+	 * which are not stored in scratch area. In future, if we reduce the
+	 * number of transaction slots to one, we may need to allocate twice the
+	 * BLCKSZ of scratch area.
+	 */
+	if (needwal)
+		scratch = palloc(BLCKSZ);
+
+	/*
+	 * See heap_multi_insert to know why checking conflicts is important
+	 * before actually inserting the tuple.
+	 */
+	CheckForSerializableConflictIn(relation, NULL, InvalidBuffer);
+
+	ndone = 0;
+	while (ndone < ntuples)
+	{
+		Buffer		buffer;
+		Buffer		vmbuffer = InvalidBuffer;
+		bool		all_visible_cleared = false;
+		int			nthispage = 0;
+		int			trans_slot_id = InvalidXactSlotId;
+		int			ucnt = 0;
+		UndoRecPtr	urecptr = InvalidUndoRecPtr,
+					prev_urecptr = InvalidUndoRecPtr;
+		UnpackedUndoRecord *undorecord = NULL;
+		ZHeapFreeOffsetRanges *zfree_offset_ranges;
+		OffsetNumber usedoff[MaxOffsetNumber];
+		OffsetNumber max_required_offset;
+		uint8		vm_status;
+		ZHeapPrepareUndoInfo zh_undo_info;
+
+		CHECK_FOR_INTERRUPTS();
+
+reacquire_buffer:
+
+		/*
+		 * Find buffer where at least the next tuple will fit.  If the page is
+		 * all-visible, this will also pin the requisite visibility map page.
+		 */
+		if (BufferIsValid(vmbuffer))
+		{
+			ReleaseBuffer(vmbuffer);
+			vmbuffer = InvalidBuffer;
+		}
+
+		buffer = RelationGetBufferForZTuple(relation, zheaptuples[ndone]->t_len,
+											InvalidBuffer, options, bistate,
+											&vmbuffer, NULL);
+		page = BufferGetPage(buffer);
+
+		/*
+		 * Get the unused offset ranges in the page. This is required for
+		 * deciding the number of undo records to be prepared later.
+		 */
+		zfree_offset_ranges = ZHeapGetUsableOffsetRanges(buffer,
+														 &zheaptuples[ndone],
+														 ntuples - ndone,
+														 saveFreeSpace);
+
+		/*
+		 * We've ensured at least one tuple fits in the page. So, there'll be
+		 * at least one offset range.
+		 */
+		Assert(zfree_offset_ranges->nranges > 0);
+
+		max_required_offset =
+			zfree_offset_ranges->endOffset[zfree_offset_ranges->nranges - 1];
+
+		/*
+		 * If we're not inserting an undo record, we don't have to reserve a
+		 * transaction slot as well.
+		 */
+		if (!skip_undo)
+		{
+			/*
+			 * The transaction information of tuple needs to be set in
+			 * transaction slot, so needs to reserve the slot before
+			 * proceeding with the actual operation.  It will be costly to
+			 * wait for getting the slot, but we do that by releasing the
+			 * buffer lock.
+			 */
+			trans_slot_id = PageReserveTransactionSlot(relation,
+													   buffer,
+													   max_required_offset,
+													   fxid,
+													   &prev_urecptr,
+													   &lock_reacquired,
+													   false,
+													   InvalidBuffer,
+													   NULL);
+			if (lock_reacquired)
+				goto reacquire_buffer;
+
+			if (trans_slot_id == InvalidXactSlotId)
+			{
+				UnlockReleaseBuffer(buffer);
+
+				pgstat_report_wait_start(PG_WAIT_PAGE_TRANS_SLOT);
+				pg_usleep(10000L);	/* 10 ms */
+				pgstat_report_wait_end();
+
+				goto reacquire_buffer;
+			}
+
+			/* transaction slot must be reserved before adding tuple to page */
+			Assert(trans_slot_id != InvalidXactSlotId);
+
+			/* Prepare an undo record for this operation. */
+			zh_undo_info.reloid = relation->rd_id;
+			zh_undo_info.blkno = BufferGetBlockNumber(buffer);
+			zh_undo_info.offnum = InvalidOffsetNumber;
+			zh_undo_info.prev_urecptr = prev_urecptr;
+			zh_undo_info.fxid = fxid;
+			zh_undo_info.cid = cid;
+			zh_undo_info.undo_persistence = UndoPersistenceForRelation(relation);
+
+			urecptr = zheap_prepare_undo_multi_insert(&zh_undo_info,
+													  zfree_offset_ranges->nranges,
+													  &undorecord, NULL);
+		}
+		/*
+		 * Get the page visibility status from visibility map.  If the page is
+		 * all-visible, we need to clear it after inserting the tuple.  Note
+		 * that, for newly added pages (vm buffer will be invalid, see
+		 * RelationGetBufferForZTuple), vm status must be clear, so we don't
+		 * need to do anything for them.
+		 */
+		if (BufferIsValid(vmbuffer))
+			vm_status = visibilitymap_get_status(relation,
+												 BufferGetBlockNumber(buffer),
+												 &vmbuffer);
+		else
+			vm_status = 0;
+
+		/*
+		 * Lock the TPD page before starting critical section.  We might need
+		 * to access it in ZPageAddItemExtended.  Note that if the transaction
+		 * slot belongs to TPD entry, then the TPD page must be locked during
+		 * slot reservation.
+		 *
+		 * XXX We can optimize this by avoid taking TPD page lock unless the
+		 * page has some unused item which requires us to fetch the
+		 * transaction information from TPD.
+		 */
+		if (trans_slot_id <= ZHEAP_PAGE_TRANS_SLOTS &&
+			ZHeapPageHasTPDSlot((PageHeader) page) &&
+			PageHasFreeLinePointers((PageHeader) page))
+			TPDPageLock(relation, buffer);
+
+		/* No ereport(ERROR) from here till changes are logged */
+		START_CRIT_SECTION();
+
+		/*
+		 * RelationGetBufferForZTuple has ensured that the first tuple fits.
+		 * Keep calm and put that on the page, and then as many other tuples
+		 * as fit.
+		 */
+		nthispage = 0;
+		for (i = 0; i < zfree_offset_ranges->nranges; i++)
+		{
+			OffsetNumber offnum;
+
+			for (offnum = zfree_offset_ranges->startOffset[i];
+				 offnum <= zfree_offset_ranges->endOffset[i];
+				 offnum++)
+			{
+				ZHeapTuple	zheaptup;
+
+				if (ndone + nthispage == ntuples)
+					break;
+
+				zheaptup = zheaptuples[ndone + nthispage];
+
+				/* Make sure that the tuple fits in the page. */
+				if (PageGetZHeapFreeSpace(page) < zheaptup->t_len + saveFreeSpace)
+					break;
+
+				if (!(options & ZHEAP_INSERT_FROZEN))
+					ZHeapTupleHeaderSetXactSlot(zheaptup->t_data, trans_slot_id);
+
+				RelationPutZHeapTuple(relation, buffer, zheaptup);
+
+				/*
+				 * Let's make sure that we've decided the offset ranges
+				 * correctly.
+				 */
+				Assert(offnum == ItemPointerGetOffsetNumber(&(zheaptup->t_self)));
+
+				/* track used offsets */
+				usedoff[ucnt++] = offnum;
+
+				/*
+				 * We don't use heap_multi_insert for catalog tuples yet, but
+				 * better be prepared... Fixme: This won't work as it needs to
+				 * access cmin/cmax which we probably needs to retrieve from
+				 * TPD or UNDO.
+				 */
+				if (needwal && need_cids)
+				{
+					/* log_heap_new_cid(relation, heaptup); */
+				}
+				nthispage++;
+			}
+
+			/*
+			 * Store the offset ranges in undo payload. We've not calculated
+			 * the end offset for the last range previously. Hence, we set it
+			 * to offnum - 1. There is no harm in doing the same for previous
+			 * undo records as well.
+			 */
+			zfree_offset_ranges->endOffset[i] = offnum - 1;
+			if (!skip_undo)
+			{
+				appendBinaryStringInfo(&undorecord[i].uur_payload,
+									   (char *) &zfree_offset_ranges->startOffset[i],
+									   sizeof(OffsetNumber));
+				appendBinaryStringInfo(&undorecord[i].uur_payload,
+									   (char *) &zfree_offset_ranges->endOffset[i],
+									   sizeof(OffsetNumber));
+			}
+			elog(DEBUG1, "start offset: %d, end offset: %d",
+				 zfree_offset_ranges->startOffset[i], zfree_offset_ranges->endOffset[i]);
+		}
+
+		if ((vm_status & VISIBILITYMAP_ALL_VISIBLE) ||
+			(vm_status & VISIBILITYMAP_POTENTIAL_ALL_VISIBLE))
+		{
+			all_visible_cleared = true;
+			visibilitymap_clear(relation, BufferGetBlockNumber(buffer),
+								vmbuffer, VISIBILITYMAP_VALID_BITS);
+		}
+
+		/*
+		 * XXX Should we set PageSetPrunable on this page ? See heap_insert()
+		 */
+
+		MarkBufferDirty(buffer);
+
+		if (!skip_undo)
+		{
+			/* Insert the undo */
+			InsertPreparedUndo(&zh_undo_info.context);
+
+			/*
+			 * We're sending the undo record for debugging purpose. So, just
+			 * send the last one.
+			 */
+			if (trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+			{
+				PageSetUNDO(undorecord[zfree_offset_ranges->nranges - 1],
+							buffer,
+							trans_slot_id,
+							true,
+							fxid,
+							urecptr,
+							usedoff,
+							ucnt);
+			}
+			else
+			{
+				PageSetUNDO(undorecord[zfree_offset_ranges->nranges - 1],
+							buffer,
+							trans_slot_id,
+							true,
+							fxid,
+							urecptr,
+							NULL,
+							0);
+			}
+		}
+
+		/* XLOG stuff */
+		if (needwal)
+		{
+			ZHeapMultiInsertWALInfo ins_wal_info;
+			ZHeapWALInfo gen_wal_info;
+
+			gen_wal_info.buffer = buffer;
+			gen_wal_info.ztuple = NULL;
+			gen_wal_info.urecptr = urecptr;
+			gen_wal_info.prev_urecptr = prev_urecptr;
+			gen_wal_info.new_trans_slot_id = trans_slot_id;
+			gen_wal_info.prior_trans_slot_id = InvalidXactSlotId;
+			gen_wal_info.all_visible_cleared = all_visible_cleared;
+			gen_wal_info.undorecord = NULL;
+			gen_wal_info.context = &zh_undo_info.context;
+
+			ins_wal_info.gen_walinfo = &gen_wal_info;
+			ins_wal_info.relation = relation;
+			ins_wal_info.ztuples = zheaptuples;
+			ins_wal_info.zfree_offsets = zfree_offset_ranges;
+			ins_wal_info.ntuples = ntuples;
+			ins_wal_info.curpage_ntuples = nthispage;
+			ins_wal_info.ndone = ndone;
+
+			log_zheap_multi_insert(&ins_wal_info, skip_undo, scratch);
+		}
+
+		END_CRIT_SECTION();
+
+		/* be tidy */
+		if (!skip_undo)
+		{
+			for (i = 0; i < zfree_offset_ranges->nranges; i++)
+				pfree(undorecord[i].uur_payload.data);
+			pfree(undorecord);
+		}
+		pfree(zfree_offset_ranges);
+
+		UnlockReleaseBuffer(buffer);
+		if (vmbuffer != InvalidBuffer)
+			ReleaseBuffer(vmbuffer);
+		FinishUndoRecordInsert(&zh_undo_info.context);
+		UnlockReleaseTPDBuffers();
+
+		ndone += nthispage;
+	}
+
+	/*
+	 * We're done with the actual inserts.  Check for conflicts again, to
+	 * ensure that all rw-conflicts in to these inserts are detected.  Without
+	 * this final check, a sequential scan of the heap may have locked the
+	 * table after the "before" check, missing one opportunity to detect the
+	 * conflict, and then scanned the table before the new tuples were there,
+	 * missing the other chance to detect the conflict.
+	 *
+	 * For heap inserts, we only need to check for table-level SSI locks. Our
+	 * new tuples can't possibly conflict with existing tuple locks, and heap
+	 * page locks are only consolidated versions of tuple locks; they do not
+	 * lock "gaps" as index page locks do.  So we don't need to specify a
+	 * buffer when making the call.
+	 */
+	CheckForSerializableConflictIn(relation, NULL, InvalidBuffer);
+
+	/*
+	 * Copy t_self fields back to the caller's original tuples. This does
+	 * nothing for untoasted tuples (tuples[i] == heaptuples[i)], but it's
+	 * probably faster to always copy than check.
+	 */
+	for (i = 0; i < ntuples; i++)
+		slots[i]->tts_tid = zheaptuples[i]->t_self;
+
+	pgstat_count_heap_insert(relation, ntuples);
+}
+
+/*
+ *	zheap_get_latest_tid -  get the latest tid of a specified tuple
+ *
+ * Functionally, it serves the same purpose as heap_get_latest_tid(), but it
+ * follows a different way of traversing the ctid chain of updated tuples.
+ */
+void
+zheap_get_latest_tid(TableScanDesc sscan,
+					 ItemPointer tid)
+{
+	Relation	relation = sscan->rs_rd;
+	Snapshot	snapshot = sscan->rs_snapshot;
+	ItemPointerData ctid;
+	TransactionId priorXmax;
+
+	/* this is to avoid Assert failures on bad input */
+	if (!ItemPointerIsValid(tid))
+		return;
+
+	/*
+	 * table_get_latest_tid verified that the passed in tid is valid.  Assume
+	 * that t_ctid links are valid however - there shouldn't be invalid ones
+	 * in the table.
+	 */
+	Assert(ItemPointerIsValid(tid));
+
+	/*
+	 * Loop to chase down ctid links.  At top of loop, ctid is the tuple we
+	 * need to examine, and *tid is the TID we will return if ctid turns out
+	 * to be bogus.
+	 *
+	 * Note that we will loop until we reach the end of the t_ctid chain.
+	 * Depending on the snapshot passed, there might be at most one visible
+	 * version of the row, but we don't try to optimize for that.
+	 */
+	ctid = *tid;
+	priorXmax = InvalidTransactionId;
+	for (;;)
+	{
+		Buffer		buffer;
+		Page		page;
+		OffsetNumber offnum;
+		ItemId		lp;
+		ZHeapTuple	tp = NULL;
+		ZHeapTuple	resulttup = NULL;
+		ItemPointerData new_ctid;
+		uint16		infomask;
+
+		/*
+		 * Read, pin, and lock the page.
+		 */
+		buffer = ReadBuffer(relation, ItemPointerGetBlockNumber(&ctid));
+		LockBuffer(buffer, BUFFER_LOCK_SHARE);
+		page = BufferGetPage(buffer);
+
+		/*
+		 * Check for bogus item number.  This is not treated as an error
+		 * condition because it can happen while following a ctid link. We
+		 * just assume that the prior tid is OK and return it unchanged.
+		 */
+		offnum = ItemPointerGetOffsetNumber(&ctid);
+		if (offnum < FirstOffsetNumber || offnum > PageGetMaxOffsetNumber(page))
+		{
+			UnlockReleaseBuffer(buffer);
+			break;
+		}
+		lp = PageGetItemId(page, offnum);
+		if (!ItemIdIsNormal(lp))
+		{
+			UnlockReleaseBuffer(buffer);
+			break;
+		}
+
+		/*
+		 * We always need to make a copy of zheap tuple; if an older version
+		 * is returned from the undo record, the passed in tuple gets freed.
+		 */
+		tp = zheap_gettuple(relation, buffer, offnum);
+
+		/* Save the infomask. The tuple might get freed, as mentioned above */
+		infomask = tp->t_data->t_infomask;
+
+		/*
+		 * Ensure that the tuple is same as what we are expecting.  If the
+		 * current or any prior version of tuple doesn't contain the effect of
+		 * priorXmax, then the slot must have been recycled and reused for an
+		 * unrelated tuple.  This implies that the latest version of the row
+		 * was deleted, so we need do nothing.
+		 */
+		if (TransactionIdIsValid(priorXmax) &&
+			!ValidateTuplesXact(relation, tp, snapshot,
+								buffer, priorXmax, false))
+		{
+			UnlockReleaseBuffer(buffer);
+			break;
+		}
+
+		/*
+		 * Get the transaction which modified this tuple. Ideally we need to
+		 * get this only when there is a ctid chain to follow.
+		 */
+		priorXmax = ZHeapTupleGetTransXID(tp, buffer, false);
+		pfree(tp);
+
+		/*
+		 * Check time qualification of tuple; if visible, set it as the new
+		 * result candidate.
+		 */
+		ItemPointerSetInvalid(&new_ctid);
+		ZHeapTupleFetch(relation, buffer, offnum, snapshot,
+						&resulttup, &new_ctid);
+
+		/*
+		 * If any prior version is visible, we pass latest visible as true.
+		 * The state of latest version of tuple is determined by the called
+		 * function.
+		 *
+		 * Note that, it's possible that tuple is updated in-place and we're
+		 * seeing some prior version of that. We handle that case in
+		 * ZHeapTupleHasSerializableConflictOut.
+		 */
+		CheckForSerializableConflictOut((resulttup != NULL), relation,
+										(void *) &ctid,
+										buffer, snapshot);
+
+		/* Pass back the tuple ctid if it's visible */
+		if (resulttup != NULL)
+			*tid = ctid;
+
+		/* If there's a valid ctid link, follow it, else we're done. */
+		if (!ItemPointerIsValid(&new_ctid) ||
+			ZHEAP_XID_IS_LOCKED_ONLY(infomask) ||
+			ZHeapTupleIsMoved(infomask) ||
+			ItemPointerEquals(&ctid, &new_ctid))
+		{
+			if (resulttup != NULL)
+				zheap_freetuple(resulttup);
+			UnlockReleaseBuffer(buffer);
+			break;
+		}
+
+		ctid = new_ctid;
+
+		if (resulttup != NULL)
+			zheap_freetuple(resulttup);
+		UnlockReleaseBuffer(buffer);
+	}							/* end of loop */
+}
+
+/*
+ * Perform XLogInsert for a zheap-visible operation. vm_buffer is the buffer
+ * containing the corresponding visibility map block.  The vm_buffer should
+ * have already been modified and dirtied.
+ */
+XLogRecPtr
+log_zheap_visible(RelFileNode rnode, Buffer heap_buffer, Buffer vm_buffer,
+				  TransactionId cutoff_xid, uint8 vmflags)
+{
+	xl_zheap_visible xlrec;
+	XLogRecPtr	recptr;
+
+	Assert(BufferIsValid(heap_buffer));
+	Assert(BufferIsValid(vm_buffer));
+
+	xlrec.cutoff_xid = cutoff_xid;
+	xlrec.flags = vmflags;
+	xlrec.heapBlk = BufferGetBlockNumber(heap_buffer);
+
+	XLogBeginInsert();
+	XLogRegisterData((char *) &xlrec, SizeOfZHeapVisible);
+
+	XLogRegisterBuffer(0, vm_buffer, 0);
+
+	recptr = XLogInsert(RM_ZHEAP2_ID, XLOG_ZHEAP_VISIBLE);
+
+	return recptr;
+}
+
+/*
+ * GetTransactionsSlotsForPage - returns transaction slots for a zheap page
+ *
+ * This method returns all the transaction slots for the input zheap page
+ * including the corresponding TPD page. It also returns the corresponding
+ * TPD buffer if there is one.
+ *
+ * The caller should hold a buffer content lock on the zheap buffer.
+ */
+TransInfo *
+GetTransactionsSlotsForPage(Relation rel, Buffer buf, int *total_trans_slots,
+							BlockNumber *tpd_blkno)
+{
+	Page		page;
+	PageHeader	phdr;
+	TransInfo  *tpd_trans_slots;
+	TransInfo  *trans_slots = NULL;
+	bool		tpd_e_pruned;
+
+	*total_trans_slots = 0;
+	if (tpd_blkno)
+		*tpd_blkno = InvalidBlockNumber;
+
+	page = BufferGetPage(buf);
+	phdr = (PageHeader) page;
+
+	if (ZHeapPageHasTPDSlot(phdr))
+	{
+		int			num_tpd_trans_slots;
+
+		/*
+		 * TPD entry can be cleaned only if the zheap buffer is locked in
+		 * exclusive mode. But, in this path, the zheap buffer can be locked
+		 * in shared mode as well (see ZGetMultiLockMembers()).  Hence, we
+		 * pass clean_tpd_loc as false.
+		 */
+		tpd_trans_slots = TPDPageGetTransactionSlots(rel,
+													 buf,
+													 InvalidOffsetNumber,
+													 false,
+													 false,
+													 NULL,
+													 &num_tpd_trans_slots,
+													 NULL,
+													 &tpd_e_pruned,
+													 NULL,
+													 false);
+
+		/* TPD location should not be cleaned from the zheap buffer page. */
+		Assert(!tpd_e_pruned);
+		if (num_tpd_trans_slots > 0)
+		{
+			GetTPDBlockAndOffset(page, tpd_blkno, NULL);
+
+			/*
+			 * The last slot in page contains TPD information, so we don't
+			 * need to include it.
+			 */
+			*total_trans_slots = num_tpd_trans_slots + ZHEAP_PAGE_TRANS_SLOTS - 1;
+			trans_slots = (TransInfo *)
+				palloc(*total_trans_slots * sizeof(TransInfo));
+			/* Copy the transaction slots from the page. */
+			memcpy(trans_slots, page + phdr->pd_special,
+				   (ZHEAP_PAGE_TRANS_SLOTS - 1) * sizeof(TransInfo));
+			/* Copy the transaction slots from the tpd entry. */
+			memcpy((char *) trans_slots + ((ZHEAP_PAGE_TRANS_SLOTS - 1) * sizeof(TransInfo)),
+				   tpd_trans_slots, num_tpd_trans_slots * sizeof(TransInfo));
+
+			pfree(tpd_trans_slots);
+			Assert(*total_trans_slots >= ZHEAP_PAGE_TRANS_SLOTS);
+			return trans_slots;
+		}
+		else if (num_tpd_trans_slots == 0)
+		{
+			*total_trans_slots = ZHEAP_PAGE_TRANS_SLOTS - 1;
+			trans_slots = (TransInfo *)
+				palloc(*total_trans_slots * sizeof(TransInfo));
+			memcpy(trans_slots, page + phdr->pd_special,
+				   *total_trans_slots * sizeof(TransInfo));
+			return trans_slots;
+		}
+	}
+
+	Assert(!ZHeapPageHasTPDSlot(phdr) || tpd_e_pruned);
+	Assert(trans_slots == NULL);
+
+	*total_trans_slots = ZHEAP_PAGE_TRANS_SLOTS;
+	trans_slots = (TransInfo *)
+		palloc(*total_trans_slots * sizeof(TransInfo));
+	memcpy(trans_slots, page + phdr->pd_special,
+		   *total_trans_slots * sizeof(TransInfo));
+
+	return trans_slots;
+}
+
+/*
+ * CheckAndLockTPDPage - Check and lock the TPD page before starting critical
+ * section.
+ *
+ * We might need to access it in ZPageAddItemExtended.  Note that if the
+ * transaction slot belongs to TPD entry, then the TPD page must be locked during
+ * slot reservation.  Also, if the old buffer and new buffer refers to the
+ * same TPD page and the old transaction slot corresponds to a TPD slot,
+ * the TPD page must be locked during slot reservation.
+ *
+ * XXX We can optimize this by avoid taking TPD page lock unless the page
+ * has some unused item which requires us to fetch the transaction
+ * information from TPD.
+ */
+static inline void
+CheckAndLockTPDPage(Relation relation, int new_trans_slot_id, int old_trans_slot_id,
+					Buffer newbuf, Buffer oldbuf)
+{
+	if (new_trans_slot_id <= ZHEAP_PAGE_TRANS_SLOTS &&
+		ZHeapPageHasTPDSlot((PageHeader) BufferGetPage(newbuf)) &&
+		PageHasFreeLinePointers((PageHeader) BufferGetPage(newbuf)))
+	{
+		BlockNumber oldbuf_tpd_blk = InvalidBlockNumber,
+					newbuf_tpd_blk;
+
+		/*
+		 * If TPD exists for old buffer, then get the corresponding TPD block
+		 * number.
+		 */
+		if (ZHeapPageHasTPDSlot((PageHeader) BufferGetPage(oldbuf)))
+			GetTPDBlockAndOffset(BufferGetPage(oldbuf), &oldbuf_tpd_blk, NULL);
+		GetTPDBlockAndOffset(BufferGetPage(newbuf), &newbuf_tpd_blk, NULL);
+
+		/*
+		 * If the old buffer and new buffer refers to the same TPD page and
+		 * the old transaction slot corresponds to a TPD slot, we must have
+		 * locked the TPD page during slot reservation.
+		 */
+		if (old_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		{
+			/* old page must point to valid TPD block */
+			Assert(oldbuf_tpd_blk != InvalidBlockNumber);
+
+			/*
+			 * To avoid deadlock, we need to ensure that we always lock the
+			 * lower numbered TPD block first.
+			 *
+			 * Releasing and reacquiring the lock on higher numbered TPD block
+			 * is safe because we have reserved the transaction slot in that
+			 * block which will avoid pruning the TPD entry. We also have lock
+			 * on the heap page, so no one can extend the TPD entry.
+			 */
+			if (newbuf_tpd_blk < oldbuf_tpd_blk)
+			{
+				ReleaseLastTPDBufferByTPDBlock(oldbuf_tpd_blk);
+				TPDPageLock(relation, newbuf);
+				TPDPageLock(relation, oldbuf);
+			}
+			else if (newbuf_tpd_blk > oldbuf_tpd_blk)
+				TPDPageLock(relation, newbuf);
+		}
+		else
+			TPDPageLock(relation, newbuf);
+	}
+}
+
+/*
+ * copy_zrelation_data - copy zheap data
+ *
+ * In this method, we copy the main fork of a zheap relation block by block.
+ * Here is the algorithm for the same:
+ * For each zheap page,
+ * a. If it's a meta page, copy it as it is.
+ * b. If it's a TPD page, copy it as it is.
+ * c. If it's a zheap data page, apply pending aborts, copy the page and
+ *    the corresponding TPD page (if any).
+ *
+ * Please note that we may copy a tpd page multiple times. The reason is one
+ * tpd page can be referred by multiple zheap pages. While applying pending
+ * aborts on a zheap page, we also need to modify the transaction and undo
+ * information in the corresponding TPD page, hence, we need to copy it again
+ * to reflect the changes.
+ */
+void
+copy_zrelation_data(Relation srcRel, SMgrRelation dst)
+{
+	Page		page;
+	bool		use_wal;
+	BlockNumber nblocks;
+	BlockNumber blkno;
+	SMgrRelation src = srcRel->rd_smgr;
+	char		relpersistence = srcRel->rd_rel->relpersistence;
+
+	/*
+	 * We need to log the copied data in WAL iff WAL archiving/streaming is
+	 * enabled AND it's a permanent relation.
+	 */
+	use_wal = XLogIsNeeded() && (relpersistence == RELPERSISTENCE_PERMANENT);
+
+	nblocks = smgrnblocks(src, MAIN_FORKNUM);
+
+	for (blkno = 0; blkno < nblocks; blkno++)
+	{
+		BlockNumber target_blkno = InvalidBlockNumber;
+		BlockNumber tpd_blkno = InvalidBlockNumber;
+		Buffer		buffer = InvalidBuffer;
+
+		/* If we got a cancel signal during the copy of the data, quit */
+		CHECK_FOR_INTERRUPTS();
+
+		if (blkno != ZHEAP_METAPAGE)
+		{
+			buffer = ReadBuffer(srcRel, blkno);
+
+			/* If it's a zheap page, apply the pending undo actions */
+			if (!IsTPDPage(BufferGetPage(buffer)))
+				zheap_exec_pending_rollback(srcRel, buffer, InvalidXactSlotId,
+											InvalidTransactionId, &tpd_blkno);
+		}
+
+		target_blkno = blkno;
+
+copy_buffer:
+		/* Read the buffer if not already done. */
+		if (!BufferIsValid(buffer))
+			buffer = ReadBuffer(srcRel, target_blkno);
+		page = (Page) BufferGetPage(buffer);
+
+		/*
+		 * WAL-log the copied page. Unfortunately we don't know what kind of a
+		 * page this is, so we have to log the full page including any unused
+		 * space.
+		 */
+		if (use_wal)
+			log_newpage(SMGR_MD, &dst->smgr_rnode.node, MAIN_FORKNUM, target_blkno, page, false);
+
+		PageSetChecksumInplace(page, target_blkno);
+
+		/*
+		 * Now write the page.  We say isTemp = true even if it's not a temp
+		 * rel, because there's no need for smgr to schedule an fsync for this
+		 * write; we'll do it ourselves below.
+		 */
+		smgrextend(dst, MAIN_FORKNUM, target_blkno, page, true);
+
+		ReleaseBuffer(buffer);
+
+		/*
+		 * If we have rolled back some transaction from TPD of the target page
+		 * and the TPD block number is lesser than the target block number, we
+		 * have to write the TPD page again.
+		 */
+		if (BlockNumberIsValid(tpd_blkno) && tpd_blkno < target_blkno)
+		{
+			target_blkno = tpd_blkno;
+			tpd_blkno = InvalidBlockNumber;
+			buffer = InvalidBuffer;
+			goto copy_buffer;
+		}
+	}
+
+	/*
+	 * If the rel is WAL-logged, must fsync before commit.  We use heap_sync
+	 * to ensure that the toast table gets fsync'd too.  (For a temp or
+	 * unlogged rel we don't care since the data will be gone after a crash
+	 * anyway.)
+	 *
+	 * It's obvious that we must do this when not WAL-logging the copy. It's
+	 * less obvious that we have to do it even if we did WAL-log the copied
+	 * pages. The reason is that since we're copying outside shared buffers, a
+	 * CHECKPOINT occurring during the copy has no way to flush the previously
+	 * written data to disk (indeed it won't know the new rel even exists).  A
+	 * crash later on would replay WAL from the checkpoint, therefore it
+	 * wouldn't replay our earlier WAL entries. If we do not fsync those pages
+	 * here, they might still not be on disk when the crash occurs.
+	 */
+	if (relpersistence == RELPERSISTENCE_PERMANENT)
+		smgrimmedsync(dst, MAIN_FORKNUM);
+}
+
+/*
+ * Get the latestRemovedXid from the zheap pages pointed at by the index
+ * tuples being deleted.
+ *
+ * This puts the work for calculating latestRemovedXid into the recovery path
+ * rather than the primary path.
+ *
+ * It's possible that this generates a fair amount of I/O, since an index
+ * block may have hundreds of tuples being deleted. To amortize that cost to
+ * some degree, this uses prefetching and combines repeat accesses to the same
+ * block.
+ *
+ * XXX: might be worth being smarter about looking up transaction information
+ * in bulk too.
+ */
+TransactionId
+zheap_compute_xid_horizon_for_tuples(Relation rel,
+									 ItemPointerData *tids,
+									 int nitems)
+{
+	TransactionId latestRemovedXid = InvalidTransactionId;
+	BlockNumber hblkno;
+	Buffer		buf = InvalidBuffer;
+	Page		hpage;
+
+	/*
+	 * Sort to avoid repeated lookups for the same page, and to make it more
+	 * likely to access items in an efficient order. In particular this
+	 * ensures that if there are multiple pointers to the same page, they all
+	 * get processed looking up and locking the page just once.
+	 */
+	qsort((void *) tids, nitems, sizeof(ItemPointerData),
+		  (int (*) (const void *, const void *)) ItemPointerCompare);
+
+	/* prefetch all pages */
+#ifdef USE_PREFETCH
+	hblkno = InvalidBlockNumber;
+	for (int i = 0; i < nitems; i++)
+	{
+		ItemPointer htid = &tids[i];
+
+		if (hblkno == InvalidBlockNumber ||
+			ItemPointerGetBlockNumber(htid) != hblkno)
+		{
+			hblkno = ItemPointerGetBlockNumber(htid);
+
+			PrefetchBuffer(rel, MAIN_FORKNUM, hblkno);
+		}
+	}
+#endif
+
+	/* Iterate over all tids, and check their horizon */
+	hblkno = InvalidBlockNumber;
+	for (int i = 0; i < nitems; i++)
+	{
+		ItemPointer htid = &tids[i];
+		ItemId		hitemid;
+		OffsetNumber hoffnum;
+
+		/*
+		 * Read zheap buffer, but avoid refetching if it's the same block as
+		 * required for the last tid.
+		 */
+		if (hblkno == InvalidBlockNumber ||
+			ItemPointerGetBlockNumber(htid) != hblkno)
+		{
+			/* release old buffer */
+			if (BufferIsValid(buf))
+			{
+				LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+				ReleaseBuffer(buf);
+			}
+
+			hblkno = ItemPointerGetBlockNumber(htid);
+
+			buf = ReadBuffer(rel, hblkno);
+			hpage = BufferGetPage(buf);
+
+			LockBuffer(buf, BUFFER_LOCK_SHARE);
+		}
+
+		hoffnum = ItemPointerGetOffsetNumber(htid);
+		hitemid = PageGetItemId(hpage, hoffnum);
+
+		/*
+		 * If the zheap item has storage, then read the header and use that to
+		 * set latestRemovedXid.
+		 *
+		 * We have special handling for zheap tuples that are deleted and
+		 * don't have storage.
+		 *
+		 * Some LP_DEAD items may not be accessible, so we ignore them.
+		 */
+		if (ItemIdIsDeleted(hitemid))
+		{
+			TransactionId xid;
+			ZHeapTupleData ztup;
+
+			ztup.t_self = *htid;
+			ztup.t_len = ItemIdGetLength(hitemid);
+			ztup.t_tableOid = InvalidOid;
+			ztup.t_data = NULL;
+			xid = ZHeapTupleGetTransXID(&ztup, buf, false);
+			if (TransactionIdDidCommit(xid) &&
+				TransactionIdFollows(xid, latestRemovedXid))
+				latestRemovedXid = xid;
+		}
+		else if (ItemIdHasStorage(hitemid))
+		{
+			ZHeapTupleHeader ztuphdr;
+			ZHeapTupleData ztup;
+
+			ztuphdr = (ZHeapTupleHeader) PageGetItem(hpage, hitemid);
+			ztup.t_self = *htid;
+			ztup.t_len = ItemIdGetLength(hitemid);
+			ztup.t_tableOid = InvalidOid;
+			ztup.t_data = ztuphdr;
+
+			if (ztuphdr->t_infomask & ZHEAP_DELETED
+				|| ztuphdr->t_infomask & ZHEAP_UPDATED)
+			{
+				TransactionId xid;
+
+				xid = ZHeapTupleGetTransXID(&ztup, buf, false);
+				ZHeapTupleHeaderAdvanceLatestRemovedXid(ztuphdr, xid, &latestRemovedXid);
+			}
+		}
+		else if (ItemIdIsDead(hitemid))
+		{
+			/*
+			 * Conjecture: if hitemid is dead then it had xids before the xids
+			 * marked on LP_NORMAL items. So we just ignore this item and move
+			 * onto the next, for the purposes of calculating
+			 * latestRemovedxids.
+			 */
+		}
+		else
+			Assert(!ItemIdIsUsed(hitemid));
+
+	}
+
+	if (BufferIsValid(buf))
+	{
+		LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+		ReleaseBuffer(buf);
+	}
+
+	return latestRemovedXid;
+}
+
+/*
+ * RefetchAndCheckTupleStatus - refetch and check whether the tuple infomask or
+ * xid has been changed while the buffer lock has been released.
+ *
+ * single_locker_xid - This is an INOUT parameter. For key share lock and
+ * share lock mode, if a new locker has come, it must be compatible
+ * with the current lock mode. In that case, we don't have to perform the
+ * conflict check again, but we return the single locker xid that'll be used in
+ * compute_new_xid_infomask later.
+ * mode - If not NULL, mode specific status checks are performed.
+ */
+static bool
+RefetchAndCheckTupleStatus(Relation relation,
+						   Buffer buffer,
+						   int old_infomask,
+						   TransactionId tup_xid,
+						   TransactionId *single_locker_xid,
+						   LockTupleMode *mode,
+						   ZHeapTupleData *zhtup)
+{
+	ItemId		lp;
+	Page		page;
+	TransactionId current_tup_xid = InvalidTransactionId;
+
+	page = BufferGetPage(buffer);
+	lp = PageGetItemId(page, ItemPointerGetOffsetNumber(&(zhtup->t_self)));
+	Assert(ItemIdIsNormal(lp));
+
+	/* Refetch the tuple */
+	zhtup->t_data = (ZHeapTupleHeader) PageGetItem(page, lp);
+	zhtup->t_len = ItemIdGetLength(lp);
+
+	/*
+	 * If some lockmode has been specified, perform some early checks to
+	 * determine whether the tuple has been modified by some other xacts and a
+	 * conflict check is again needed.
+	 */
+	if (mode)
+	{
+		if (*mode == LockTupleKeyShare)
+		{
+			/*
+			 * Make sure it's still an appropriate lock, else start over.
+			 * Also, if it wasn't updated before we released the lock, but is
+			 * updated now, we start over too; the reason is that we now need
+			 * to follow the update chain to lock the new versions.
+			 */
+			if (!ZHEAP_XID_IS_LOCKED_ONLY(zhtup->t_data->t_infomask) &&
+				(ZHEAP_XID_IS_EXCL_LOCKED(zhtup->t_data->t_infomask) ||
+				 ZHEAP_XID_IS_LOCKED_ONLY(old_infomask)))
+				return false;
+		}
+		else if (*mode == LockTupleShare)
+		{
+
+			/* Make sure it's still an appropriate lock, else start over. */
+			if (!ZHEAP_XID_IS_LOCKED_ONLY(zhtup->t_data->t_infomask) ||
+				ZHEAP_XID_IS_NOKEY_EXCL_LOCKED(zhtup->t_data->t_infomask) ||
+				ZHEAP_XID_IS_EXCL_LOCKED(zhtup->t_data->t_infomask))
+				return false;
+		}
+	}
+
+	if (xid_infomask_changed(zhtup->t_data->t_infomask, old_infomask))
+		return false;
+
+	/*
+	 * Other updaters/lock-for-update operations could have modified it before
+	 * we grabbed the buffer lock.  In that case, we've to go back and perform
+	 * the conflict check again, so return false.
+	 */
+	current_tup_xid = ZHeapTupleGetTransXID(zhtup, buffer, false);
+
+	if (!TransactionIdEquals(current_tup_xid, tup_xid))
+		return false;
+
+	/*
+	 * Other lockers that don't change the slot on the tuple could have
+	 * modified it before we grabbed the buffer lock.  In that case, we've to
+	 * go back and perform the conflict check again, so return false.
+	 */
+	if (ZHEAP_XID_IS_LOCKED_ONLY(zhtup->t_data->t_infomask) &&
+		!ZHeapTupleHasMultiLockers(zhtup->t_data->t_infomask))
+	{
+		FullTransactionId current_single_locker_fxid;
+		TransactionId current_single_locker_xid;
+
+		GetLockerTransInfo(relation, &zhtup->t_self, buffer,
+						   NULL, &current_single_locker_fxid);
+		current_single_locker_xid =
+			XidFromFullTransactionId(current_single_locker_fxid);
+
+		if (mode && (*mode == LockTupleKeyShare || *mode == LockTupleShare))
+		{
+			/*
+			 * For key share lock and share lock mode, even if a new locker
+			 * has come, it must be compatible with the current lock mode.  In
+			 * that case, we don't have to perform the conflict check again,
+			 * but we should update the single locker xid that'll be used in
+			 * compute_new_xid_infomask later.
+			 */
+			*single_locker_xid = current_single_locker_xid;
+		}
+		else if (!TransactionIdEquals(current_single_locker_xid,
+									  *single_locker_xid))
+			return false;
+	}
+
+	return true;
+}
diff --git a/src/backend/access/zheap/zheapam_handler.c b/src/backend/access/zheap/zheapam_handler.c
new file mode 100644
index 0000000..5b1bba5
--- /dev/null
+++ b/src/backend/access/zheap/zheapam_handler.c
@@ -0,0 +1,2163 @@
+/*-------------------------------------------------------------------------
+ *
+ * zheapam_handler.c
+ *	  zheap table access method code
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/zheap/zheapam_handler.c
+ *
+ *
+ * NOTES
+ *	  This file contains the zheap_ routines which implement
+ *	  the POSTGRES zheap table access method used for all POSTGRES
+ *	  relations.
+ *
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include <math.h>
+
+#include "miscadmin.h"
+
+#include "access/multixact.h"
+#include "access/relscan.h"
+#include "access/rewritezheap.h"
+#include "access/tableam.h"
+#include "access/tpd.h"
+#include "access/tsmapi.h"
+#include "access/tuptoaster.h"
+#include "access/visibilitymap.h"
+#include "access/xact.h"
+#include "access/zheap.h"
+#include "access/zheapscan.h"
+#include "catalog/catalog.h"
+#include "catalog/index.h"
+#include "catalog/pg_am_d.h"
+#include "catalog/storage.h"
+#include "catalog/storage_xlog.h"
+#include "commands/vacuum.h"
+#include "executor/executor.h"
+#include "optimizer/plancat.h"
+#include "pgstat.h"
+#include "storage/lmgr.h"
+#include "storage/bufpage.h"
+#include "storage/bufmgr.h"
+#include "storage/predicate.h"
+#include "storage/procarray.h"
+#include "storage/smgr.h"
+#include "utils/builtins.h"
+#include "utils/rel.h"
+#include "utils/ztqual.h"
+
+
+/*
+ * ZBORKED: don't want to include heapam.h to avoid mistakes - the syncscan
+ * stuff should probably be moved to a different header.
+ */
+extern void ss_report_location(Relation rel, BlockNumber location);
+
+/* ----------------------------------------------------------------
+ *				storage AM support routines for zheapam
+ * ----------------------------------------------------------------
+ */
+
+static bool
+zheapam_fetch_row_version(Relation relation,
+						  ItemPointer tid,
+						  Snapshot snapshot,
+						  TupleTableSlot *slot)
+{
+	ZHeapTupleTableSlot *zslot = (ZHeapTupleTableSlot *) slot;
+	Buffer		buffer;
+
+	ExecClearTuple(slot);
+
+	if (zheap_fetch(relation, snapshot, tid, &zslot->tuple, &buffer, false))
+	{
+		ExecStoreZHeapTuple(zslot->tuple, slot, true);
+		ReleaseBuffer(buffer);
+
+		slot->tts_tableOid = RelationGetRelid(relation);
+
+		return true;
+	}
+
+	slot->tts_tableOid = RelationGetRelid(relation);
+
+	return false;
+}
+
+/*
+ * Insert a heap tuple from a slot, which may contain an OID and speculative
+ * insertion token.
+ */
+static void
+zheapam_insert(Relation relation, TupleTableSlot *slot, CommandId cid,
+			   int options, BulkInsertState bistate)
+{
+	ZHeapTuple	tuple = ExecGetZHeapTupleFromSlot(slot);
+
+	/* Update the tuple with table oid */
+	slot->tts_tableOid = RelationGetRelid(relation);
+	if (slot->tts_tableOid != InvalidOid)
+		tuple->t_tableOid = slot->tts_tableOid;
+
+	/* Perform the insertion, and copy the resulting ItemPointer */
+	zheap_insert(relation, tuple, cid, options, bistate, 0);
+	ItemPointerCopy(&tuple->t_self, &slot->tts_tid);
+}
+
+static void
+zheapam_insert_speculative(Relation relation, TupleTableSlot *slot, CommandId cid,
+						   int options, BulkInsertState bistate, uint32 specToken)
+{
+	ZHeapTuple	tuple = ExecGetZHeapTupleFromSlot(slot);
+
+	/* Update the tuple with table oid */
+	slot->tts_tableOid = RelationGetRelid(relation);
+	if (slot->tts_tableOid != InvalidOid)
+		tuple->t_tableOid = slot->tts_tableOid;
+
+	options |= ZHEAP_INSERT_SPECULATIVE;
+
+	/* Perform the insertion, and copy the resulting ItemPointer */
+	zheap_insert(relation, tuple, cid, options, bistate, specToken);
+	ItemPointerCopy(&tuple->t_self, &slot->tts_tid);
+}
+
+static void
+zheapam_complete_speculative(Relation relation, TupleTableSlot *slot, uint32 spekToken,
+							 bool succeeded)
+{
+	/* adjust the tuple's state accordingly */
+	if (succeeded)
+		zheap_finish_speculative(relation, &slot->tts_tid);
+	else
+		zheap_abort_speculative(relation, &slot->tts_tid);
+}
+
+
+static TM_Result
+zheapam_delete(Relation relation, ItemPointer tid, CommandId cid,
+			   Snapshot snapshot, Snapshot crosscheck, bool wait,
+			   TM_FailureData *tmfd, bool changingPart)
+{
+	/*
+	 * Currently Deleting of index tuples are handled at vacuum, in case if
+	 * the storage itself is cleaning the dead tuples by itself, it is the
+	 * time to call the index tuple deletion also.
+	 */
+	return zheap_delete(relation, tid, cid, crosscheck, snapshot, wait, tmfd, changingPart);
+}
+
+
+/*
+ * Locks tuple and fetches its newest version and TID.
+ *
+ *	relation - table containing tuple
+ *	tid - TID of tuple to lock
+ *	snapshot - snapshot identifying required version (used for assert check only)
+ *	slot - tuple to be returned
+ *	cid - current command ID (used for visibility test, and stored into
+ *		  tuple's cmax if lock is successful)
+ *	mode - indicates if shared or exclusive tuple lock is desired
+ *	wait_policy - what to do if tuple lock is not available
+ *	flags  indicating how do we handle updated tuples
+ *	*tmfd - filled in failure cases
+ *
+ * Function result may be:
+ *	HeapTupleMayBeUpdated: lock was successfully acquired
+ *	HeapTupleInvisible: lock failed because tuple was never visible to us
+ *	HeapTupleSelfUpdated: lock failed because tuple updated by self
+ *	HeapTupleUpdated: lock failed because tuple updated by other xact
+ *	HeapTupleDeleted: lock failed because tuple deleted by other xact
+ *	HeapTupleWouldBlock: lock couldn't be acquired and wait_policy is skip
+ *
+ * In the failure cases other than HeapTupleInvisible, the routine fills
+ * *tmfd with the tuple's t_ctid, t_xmax (resolving a possible MultiXact,
+ * if necessary), and t_cmax (the last only for HeapTupleSelfUpdated,
+ * since we cannot obtain cmax from a combocid generated by another
+ * transaction).
+ * See comments for struct TM_FailureData for additional info.
+ */
+static TM_Result
+zheapam_lock_tuple(Relation relation, ItemPointer tid, Snapshot snapshot,
+				   TupleTableSlot *slot, CommandId cid, LockTupleMode mode,
+				   LockWaitPolicy wait_policy, uint8 flags,
+				   TM_FailureData *tmfd)
+{
+	ZHeapTupleTableSlot *zslot = (ZHeapTupleTableSlot *) slot;
+	TM_Result	result;
+	Buffer		buffer;
+	ZHeapTuple	tuple = &zslot->tupdata;
+	bool		doWeirdEval = (flags & TUPLE_LOCK_FLAG_WEIRD) != 0;
+
+	tmfd->traversed = false;
+
+	/* ZBORKED: Currently zheap, due to doWeirdEval, doesn't actually signal */
+	/* properly that we're traversing. That sucks. */
+	if (doWeirdEval)
+		tmfd->traversed = true;
+
+retry:
+	result = zheap_lock_tuple(relation, tid, cid, mode, wait_policy,
+							  (flags & TUPLE_LOCK_FLAG_LOCK_UPDATE_IN_PROGRESS) ? true : false,
+							  doWeirdEval,
+							  snapshot, tuple, &buffer, tmfd);
+
+	if (result == TM_Updated &&
+		(flags & TUPLE_LOCK_FLAG_FIND_LAST_VERSION))
+	{
+		SnapshotData SnapshotDirty;
+		TransactionId priorXmax = tmfd->xmax;
+
+		ReleaseBuffer(buffer);
+
+		/* it was updated, so look at the updated version */
+		*tid = tmfd->ctid;
+		/* updated row should have xmin matching this xmax */
+		priorXmax = tmfd->xmax;
+
+		/*
+		 * We should not encounter a speculative tuple on recheck.  Also, for
+		 * a deleted item pointer, tuple data is not initialized.
+		 */
+		Assert((tuple->t_len == 0) ||
+			   !(tuple->t_data->t_infomask & ZHEAP_SPECULATIVE_INSERT));
+
+		if (ItemPointerEquals(&tmfd->ctid, &tuple->t_self) &&
+			!tmfd->in_place_updated_or_locked)
+		{
+			/* tuple was deleted, so give up */
+			return TM_Deleted;
+		}
+
+		/* signal that a tuple later in the chain is getting locked */
+		tmfd->traversed = true;
+
+		/*
+		 * fetch target tuple
+		 *
+		 * Loop here to deal with updated or busy tuples
+		 */
+		InitDirtySnapshot(SnapshotDirty);
+		for (;;)
+		{
+			/* check whether next version would be in a different partition */
+			if (ItemPointerIndicatesMovedPartitions(&tmfd->ctid))
+				ereport(ERROR,
+						(errcode(ERRCODE_T_R_SERIALIZATION_FAILURE),
+						 errmsg("tuple to be locked was already moved to another partition due to concurrent update")));
+
+			if (zheap_fetch(relation, &SnapshotDirty, tid, &tuple, &buffer, true))
+			{
+				/*
+				 * Ensure that the tuple is same as what we are expecting.  If
+				 * the current or any prior version of tuple doesn't contain
+				 * the effect of priorXmax, then the slot must have been
+				 * recycled and reused for an unrelated tuple.  This implies
+				 * that the latest version of the row was deleted, so we need
+				 * do nothing.
+				 */
+				if (!ValidateTuplesXact(relation, tuple, &SnapshotDirty,
+										buffer, priorXmax, true))
+				{
+					ReleaseBuffer(buffer);
+					return TM_Deleted;
+				}
+
+				/* otherwise xmin should not be dirty... */
+				if (TransactionIdIsValid(SnapshotDirty.xmin))
+					elog(ERROR, "t_xmin is uncommitted in tuple to be updated");
+
+				/*
+				 * If tuple is being updated by other (sub)transaction then we
+				 * have to wait for its commit/abort, or die trying.
+				 */
+				if (SnapshotDirty.subxid != InvalidSubTransactionId &&
+					TransactionIdIsValid(SnapshotDirty.xmax))
+				{
+					ReleaseBuffer(buffer);
+					switch (wait_policy)
+					{
+						case LockWaitBlock:
+							SubXactLockTableWait(SnapshotDirty.xmax,
+												 SnapshotDirty.subxid,
+												 relation, &tuple->t_self,
+												 XLTW_FetchUpdated);
+							break;
+						case LockWaitSkip:
+							if (!ConditionalSubXactLockTableWait(SnapshotDirty.xmax,
+																 SnapshotDirty.subxid))
+								return result;	/* skip instead of waiting */
+							break;
+						case LockWaitError:
+							if (ConditionalSubXactLockTableWait(SnapshotDirty.xmax,
+																SnapshotDirty.subxid))
+								ereport(ERROR,
+										(errcode(ERRCODE_LOCK_NOT_AVAILABLE),
+										 errmsg("could not obtain lock on row in relation \"%s\"",
+												RelationGetRelationName(relation))));
+
+							break;
+					}
+					continue;	/* loop back to repeat zheap_fetch */
+				}
+				else if (TransactionIdIsValid(SnapshotDirty.xmax))
+				{
+					ReleaseBuffer(buffer);
+					switch (wait_policy)
+					{
+						case LockWaitBlock:
+							XactLockTableWait(SnapshotDirty.xmax, relation,
+											  &tuple->t_self, XLTW_FetchUpdated);
+							break;
+						case LockWaitSkip:
+							if (!ConditionalXactLockTableWait(SnapshotDirty.xmax))
+								return result;	/* skip instead of waiting */
+							break;
+						case LockWaitError:
+							if (!ConditionalXactLockTableWait(SnapshotDirty.xmax))
+								ereport(ERROR,
+										(errcode(ERRCODE_LOCK_NOT_AVAILABLE),
+										 errmsg("could not obtain lock on row in relation \"%s\"",
+												RelationGetRelationName(relation))));
+							break;
+					}
+					continue;	/* loop back to repeat zheap_fetch */
+				}
+
+				/*
+				 * If tuple was inserted by our own transaction, we have to
+				 * check cmin against es_output_cid: cmin >= current CID means
+				 * our command cannot see the tuple, so we should ignore it.
+				 * Otherwise zheap_lock_tuple() will throw an error, and so
+				 * would any later attempt to update or delete the tuple.  (We
+				 * need not check cmax because ZHeapTupleSatisfiesDirty will
+				 * consider a tuple deleted by our transaction dead,
+				 * regardless of cmax.) We just checked that priorXmax ==
+				 * xmin, so we can test that variable instead of doing
+				 * ZHeapTupleHeaderGetXid again.
+				 */
+				if (TransactionIdIsCurrentTransactionId(priorXmax))
+				{
+					CommandId	tup_cid;
+
+					LockBuffer(buffer, BUFFER_LOCK_SHARE);
+
+					/*
+					 * Fixme -If the tuple is updated such that its
+					 * transaction slot has been changed, then we will never
+					 * be able to get the correct tuple from undo.  To avoid,
+					 * that we need to get the latest tuple from page rather
+					 * than relying on it's in-memory copy.  See
+					 * ValidateTuplesXact.
+					 */
+					tup_cid = ZHeapTupleGetCid(tuple, buffer, InvalidUndoRecPtr,
+											   InvalidXactSlotId);
+					if (tup_cid >= cid)
+					{
+						/* ZBORKED: check equivalent heap code */
+						tmfd->xmax = priorXmax;
+						tmfd->cmax = tup_cid;
+						UnlockReleaseBuffer(buffer);
+						/* ZBORKED: is this correct? */
+						return TM_SelfModified;
+					}
+					LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+				}
+
+				doWeirdEval = true;
+				ReleaseBuffer(buffer);
+				goto retry;
+			}
+
+			/*
+			 * If we don't get any tuple, the latest version of the row must
+			 * have been deleted, so we need do nothing.
+			 */
+			if (tuple == NULL)
+			{
+				ReleaseBuffer(buffer);
+				return TM_Deleted;
+			}
+
+			/*
+			 * Ensure that the tuple is same as what we are expecting as
+			 * above.
+			 */
+			if (!ValidateTuplesXact(relation, tuple, &SnapshotDirty,
+									buffer, priorXmax, true))
+			{
+				if (BufferIsValid(buffer))
+					ReleaseBuffer(buffer);
+				return TM_Deleted;
+			}
+
+			/* check whether next version would be in a different partition */
+			if (ZHeapTupleIsMoved(tuple->t_data->t_infomask))
+				ereport(ERROR,
+						(errcode(ERRCODE_T_R_SERIALIZATION_FAILURE),
+						 errmsg("tuple to be locked was already moved to another partition due to concurrent update")));
+
+			if (ItemPointerEquals(&(tuple->t_self), tid))
+			{
+				/* deleted, so forget about it */
+				ReleaseBuffer(buffer);
+				return TM_Deleted;
+			}
+
+			/* updated row should have xid matching this xmax */
+			priorXmax = ZHeapTupleGetTransXID(tuple, buffer, true);
+
+			/*
+			 * As we still hold a snapshot to which priorXmax is not visible,
+			 * neither the transaction slot on tuple can be marked as frozen
+			 * nor the corresponding undo be discarded.
+			 */
+			Assert(TransactionIdIsValid(priorXmax));
+
+			/* be tidy */
+			zheap_freetuple(tuple);
+			ReleaseBuffer(buffer);
+			/* loop back to fetch next in chain */
+		}
+	}
+
+	slot->tts_tableOid = RelationGetRelid(relation);
+	ExecStoreZHeapTuple(tuple, slot, false);
+	/* FIXME:invent option to just transfer pin ? */
+	ReleaseBuffer(buffer);
+
+	return result;
+}
+
+
+static TM_Result
+zheapam_update(Relation relation, ItemPointer otid, TupleTableSlot *slot,
+			   CommandId cid, Snapshot snapshot, Snapshot crosscheck,
+			   bool wait, TM_FailureData *tmfd, LockTupleMode *lockmode,
+			   bool *update_indexes)
+{
+	ZHeapTuple	ztuple = ExecGetZHeapTupleFromSlot(slot);
+	TM_Result	result;
+
+	/* Update the tuple with table oid */
+	if (slot->tts_tableOid != InvalidOid)
+		ztuple->t_tableOid = slot->tts_tableOid;
+
+	result = zheap_update(relation, otid, ztuple, cid, crosscheck, snapshot,
+						  wait, tmfd, lockmode);
+	ItemPointerCopy(&ztuple->t_self, &slot->tts_tid);
+
+	slot->tts_tableOid = RelationGetRelid(relation);
+
+	/*
+	 * Note: instead of having to update the old index tuples associated with
+	 * the heap tuple, all we do is form and insert new index tuples. This is
+	 * because UPDATEs are actually DELETEs and INSERTs, and index tuple
+	 * deletion is done later by VACUUM (see notes in ExecDelete). All we do
+	 * here is insert new index tuples.  -cim 9/27/89
+	 */
+
+	/*
+	 * insert index entries for tuple
+	 *
+	 * Note: heap_update returns the tid (location) of the new tuple in the
+	 * t_self field.
+	 *
+	 * If it's a HOT update, we mustn't insert new index entries.
+	 */
+	*update_indexes = result == TM_Ok &&
+		!ZHeapTupleIsInPlaceUpdated(ztuple->t_data->t_infomask);
+
+	return result;
+}
+
+static const TupleTableSlotOps *
+zheapam_slot_callbacks(Relation relation)
+{
+	return &TTSOpsZHeapTuple;
+}
+
+static bool
+zheapam_tuple_satisfies_snapshot(Relation rel, TupleTableSlot *slot, Snapshot snapshot)
+{
+	ZHeapTupleTableSlot *zslot = (ZHeapTupleTableSlot *) slot;
+	Buffer		buffer;
+	ItemPointer tid;
+	ZHeapTuple	tup;
+	bool		res;
+
+	Assert(TTS_IS_ZHEAP(slot));
+	Assert(zslot->tuple);
+
+	tid = &(zslot->tuple->t_self);
+
+	buffer = ReadBuffer(rel, ItemPointerGetBlockNumber(tid));
+	LockBuffer(buffer, BUFFER_LOCK_SHARE);
+
+	/*
+	 * NB: current transaction has inserted/updated the tuple, so it can't be
+	 * deleted
+	 */
+
+	ZHeapTupleFetch(rel, buffer, ItemPointerGetOffsetNumber(tid), snapshot,
+					&tup, NULL);
+
+	LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+	ReleaseBuffer(buffer);
+
+	if (!tup)
+	{
+		/* satisfies routine returned no tuple, so clearly invisible */
+		res = false;
+	}
+	else if (tup->t_len != zslot->tuple->t_len)
+	{
+		/* length differs, the input tuple can't be visible */
+		res = false;
+	}
+	else if (memcmp(tup->t_data, zslot->tuple->t_data, tup->t_len) != 0)
+	{
+		/*
+		 * ZBORKED: compare tuple contents, to be sure the tuple returned by
+		 * the visibility routine is the input tuple. There *got* to be a
+		 * better solution than this.
+		 */
+		res = false;
+	}
+	else
+		res = true;
+
+	if (tup)
+		pfree(tup);
+
+	return res;
+}
+
+static bool
+zheapam_tuple_tid_valid(TableScanDesc scan, ItemPointer tid)
+{
+	ZHeapScanDesc zscan = (ZHeapScanDesc) scan;
+
+	return ItemPointerIsValid(tid) &&
+		ItemPointerGetBlockNumber(tid) < zscan->rs_nblocks;
+}
+
+static IndexFetchTableData *
+zheapam_begin_index_fetch(Relation rel)
+{
+	IndexFetchZHeapData *hscan = palloc0(sizeof(IndexFetchZHeapData));
+
+	hscan->xs_base.rel = rel;
+	hscan->xs_cbuf = InvalidBuffer;
+	/* hscan->xs_continue_hot = false; */
+
+	return &hscan->xs_base;
+}
+
+
+static void
+zheapam_reset_index_fetch(IndexFetchTableData *scan)
+{
+	IndexFetchZHeapData *hscan = (IndexFetchZHeapData *) scan;
+
+	if (BufferIsValid(hscan->xs_cbuf))
+	{
+		ReleaseBuffer(hscan->xs_cbuf);
+		hscan->xs_cbuf = InvalidBuffer;
+	}
+
+	/* hscan->xs_continue_hot = false; */
+}
+
+static void
+zheapam_end_index_fetch(IndexFetchTableData *scan)
+{
+	IndexFetchZHeapData *hscan = (IndexFetchZHeapData *) scan;
+
+	zheapam_reset_index_fetch(scan);
+
+	pfree(hscan);
+}
+
+static bool
+zheapam_index_fetch_tuple(struct IndexFetchTableData *scan,
+						  ItemPointer tid,
+						  Snapshot snapshot,
+						  TupleTableSlot *slot,
+						  bool *call_again, bool *all_dead)
+{
+	IndexFetchZHeapData *hscan = (IndexFetchZHeapData *) scan;
+	ZHeapTuple	zheapTuple = NULL;
+
+	/*
+	 * No HOT chains in zheap.
+	 */
+	Assert(!*call_again);
+
+	/* Switch to correct buffer if we don't have it already */
+	hscan->xs_cbuf = ReleaseAndReadBuffer(hscan->xs_cbuf,
+										  hscan->xs_base.rel,
+										  ItemPointerGetBlockNumber(tid));
+
+	LockBuffer(hscan->xs_cbuf, BUFFER_LOCK_SHARE);
+	zheapTuple = zheap_search_buffer(tid, hscan->xs_base.rel,
+									 hscan->xs_cbuf,
+									 snapshot,
+									 all_dead);
+	LockBuffer(hscan->xs_cbuf, BUFFER_LOCK_UNLOCK);
+
+	if (zheapTuple)
+	{
+		slot->tts_tableOid = RelationGetRelid(scan->rel);
+		ExecStoreZHeapTuple(zheapTuple, slot, false);
+	}
+
+	return zheapTuple != NULL;
+}
+
+/*
+ * Similar to IndexBuildHeapRangeScan, but for zheap relations.
+ */
+static double
+IndexBuildZHeapRangeScan(Relation heapRelation,
+						 Relation indexRelation,
+						 IndexInfo *indexInfo,
+						 bool allow_sync,
+						 bool anyvisible,
+						 bool progress,
+						 BlockNumber start_blockno,
+						 BlockNumber numblocks,
+						 IndexBuildCallback callback,
+						 void *callback_state,
+						 TableScanDesc sscan)
+{
+	ZHeapScanDesc scan = (ZHeapScanDesc) sscan;
+	bool		is_system_catalog;
+	bool		checking_uniqueness;
+	HeapTuple	heapTuple;
+	ZHeapTuple	zheapTuple;
+	Datum		values[INDEX_MAX_KEYS];
+	bool		isnull[INDEX_MAX_KEYS];
+	double		reltuples;
+	ExprState  *predicate;
+	TupleTableSlot *slot;
+	ZHeapTupleTableSlot *zslot;
+	EState	   *estate;
+	ExprContext *econtext;
+	Snapshot	snapshot;
+	TransactionId OldestXmin;
+	bool		need_unregister_snapshot = false;
+	SubTransactionId subxid_xwait = InvalidSubTransactionId;
+
+	/*
+	 * sanity checks
+	 */
+	Assert(OidIsValid(indexRelation->rd_rel->relam));
+	Assert(RelationStorageIsZHeap(heapRelation));
+
+	/* Remember if it's a system catalog */
+	is_system_catalog = IsSystemRelation(heapRelation);
+
+	/* See whether we're verifying uniqueness/exclusion properties */
+	checking_uniqueness = (indexInfo->ii_Unique ||
+						   indexInfo->ii_ExclusionOps != NULL);
+
+	/*
+	 * "Any visible" mode is not compatible with uniqueness checks; make sure
+	 * only one of those is requested.
+	 */
+	Assert(!(anyvisible && checking_uniqueness));
+
+	/*
+	 * Need an EState for evaluation of index expressions and partial-index
+	 * predicates.  Also a slot to hold the current tuple.
+	 */
+	estate = CreateExecutorState();
+	econtext = GetPerTupleExprContext(estate);
+	slot = table_slot_create(heapRelation, NULL);
+	zslot = (ZHeapTupleTableSlot *) slot;
+
+	/* Arrange for econtext's scan tuple to be the tuple under test */
+	econtext->ecxt_scantuple = slot;
+
+	/* Set up execution state for predicate, if any. */
+	predicate = ExecPrepareQual(indexInfo->ii_Predicate, estate);
+
+
+	heapTuple = (HeapTuple) palloc0(SizeofHeapTupleHeader);
+
+	/*
+	 * Prepare for scan of the base relation.  In a normal index build, we use
+	 * SnapshotAny because we must retrieve all tuples and do our own time
+	 * qual checks (because we have to index RECENTLY_DEAD tuples). In a
+	 * concurrent build, or during bootstrap, we take a regular MVCC snapshot
+	 * and index whatever is live according to that.
+	 */
+	OldestXmin = InvalidTransactionId;
+
+	/* It is okay to ignore lazy vacuums here */
+	if (!IsBootstrapProcessingMode() && !indexInfo->ii_Concurrent)
+		OldestXmin = GetOldestXmin(heapRelation, PROCARRAY_FLAGS_VACUUM);
+
+	if (!scan)
+	{
+		/*
+		 * Serial index build.
+		 *
+		 * Must begin our own heap scan in this case.  We may also need to
+		 * register a snapshot whose lifetime is under our direct control.
+		 */
+		if (!TransactionIdIsValid(OldestXmin))
+		{
+			snapshot = RegisterSnapshot(GetTransactionSnapshot());
+			need_unregister_snapshot = true;
+		}
+		else
+			snapshot = SnapshotAny;
+
+		sscan = table_beginscan_strat(heapRelation, /* relation */
+									  snapshot, /* snapshot */
+									  0,	/* number of keys */
+									  NULL, /* scan key */
+									  true, /* buffer access strategy OK */
+									  allow_sync);	/* syncscan OK? */
+		scan = (ZHeapScanDesc) sscan;
+	}
+	else
+	{
+		/*
+		 * Parallel index build.
+		 *
+		 * Parallel case never registers/unregisters own snapshot.  Snapshot
+		 * is taken from parallel heap scan, and is SnapshotAny or an MVCC
+		 * snapshot, based on same criteria as serial case.
+		 */
+		Assert(!IsBootstrapProcessingMode());
+		Assert(allow_sync);
+		snapshot = scan->rs_base.rs_snapshot;
+	}
+
+	/*
+	 * Must call GetOldestXmin() with SnapshotAny.  Should never call
+	 * GetOldestXmin() with MVCC snapshot. (It's especially worth checking
+	 * this for parallel builds, since ambuild routines that support parallel
+	 * builds must work these details out for themselves.)
+	 */
+	Assert(snapshot == SnapshotAny || IsMVCCSnapshot(snapshot));
+	Assert(snapshot == SnapshotAny ? TransactionIdIsValid(OldestXmin) :
+		   !TransactionIdIsValid(OldestXmin));
+	Assert(snapshot == SnapshotAny || !anyvisible);
+
+	/* set our scan endpoints */
+	if (!allow_sync)
+		zheap_setscanlimits(sscan, start_blockno, numblocks);
+	else
+	{
+		/* syncscan can only be requested on whole relation */
+		Assert(start_blockno == 0);
+		start_blockno = ZHEAP_METAPAGE + 1;
+		Assert(numblocks == InvalidBlockNumber);
+	}
+
+	reltuples = 0;
+
+	/*
+	 * Scan all tuples in the base relation.
+	 */
+	while (zheap_getnextslot(sscan, ForwardScanDirection, slot))
+	{
+		bool		tupleIsAlive;
+		ZHeapTuple	targztuple = NULL;
+
+		zheapTuple = ExecGetZHeapTupleFromSlot(slot);
+
+		CHECK_FOR_INTERRUPTS();
+
+		if (snapshot == SnapshotAny)
+		{
+			/* do our own time qual check */
+			bool		indexIt;
+			TransactionId xwait;
+
+	recheck:
+
+			/*
+			 * We could possibly get away with not locking the buffer here,
+			 * since caller should hold ShareLock on the relation, but let's
+			 * be conservative about it.
+			 */
+			LockBuffer(scan->rs_cbuf, BUFFER_LOCK_SHARE);
+
+			targztuple = zheap_copytuple(zheapTuple);
+			switch (ZHeapTupleSatisfiesOldestXmin(targztuple, OldestXmin,
+												  scan->rs_cbuf, true,
+												  &targztuple, &xwait,
+												  &subxid_xwait))
+			{
+				case ZHEAPTUPLE_DEAD:
+					/* Definitely dead, we can ignore it */
+					indexIt = false;
+					tupleIsAlive = false;
+					break;
+				case ZHEAPTUPLE_LIVE:
+					/* Normal case, index and unique-check it */
+					indexIt = true;
+					tupleIsAlive = true;
+					break;
+				case ZHEAPTUPLE_RECENTLY_DEAD:
+
+					/*
+					 * If tuple is recently deleted then we must index it
+					 * anyway to preserve MVCC semantics. (Pre-existing
+					 * transactions could try to use the index after we finish
+					 * building it, and may need to see such tuples.)
+					 */
+					indexIt = true;
+					tupleIsAlive = false;
+					break;
+				case ZHEAPTUPLE_INSERT_IN_PROGRESS:
+
+					/*
+					 * In "anyvisible" mode, this tuple is visible and we
+					 * don't need any further checks.
+					 */
+					if (anyvisible)
+					{
+						indexIt = true;
+						tupleIsAlive = true;
+						break;
+					}
+
+					/*
+					 * Since caller should hold ShareLock or better, normally
+					 * the only way to see this is if it was inserted earlier
+					 * in our own transaction.  However, it can happen in
+					 * system catalogs, since we tend to release write lock
+					 * before commit there.  Give a warning if neither case
+					 * applies.
+					 */
+					if (!TransactionIdIsCurrentTransactionId(xwait))
+					{
+						if (!is_system_catalog)
+							elog(WARNING, "concurrent insert in progress within table \"%s\"",
+								 RelationGetRelationName(heapRelation));
+
+						/*
+						 * If we are performing uniqueness checks, indexing
+						 * such a tuple could lead to a bogus uniqueness
+						 * failure.  In that case we wait for the inserting
+						 * transaction to finish and check again.
+						 */
+						if (checking_uniqueness)
+						{
+							/*
+							 * Must drop the lock on the buffer before we wait
+							 */
+							LockBuffer(scan->rs_cbuf, BUFFER_LOCK_UNLOCK);
+							if (subxid_xwait != InvalidSubTransactionId)
+								SubXactLockTableWait(xwait, subxid_xwait, heapRelation,
+													 &zheapTuple->t_self,
+													 XLTW_InsertIndexUnique);
+							else
+								XactLockTableWait(xwait, heapRelation,
+												  &zheapTuple->t_self,
+												  XLTW_InsertIndexUnique);
+							CHECK_FOR_INTERRUPTS();
+
+							if (targztuple != NULL)
+								pfree(targztuple);
+
+							goto recheck;
+						}
+					}
+
+					/*
+					 * We must index such tuples, since if the index build
+					 * commits then they're good.
+					 */
+					indexIt = true;
+					tupleIsAlive = true;
+					break;
+				case ZHEAPTUPLE_DELETE_IN_PROGRESS:
+
+					/*
+					 * As with INSERT_IN_PROGRESS case, this is unexpected
+					 * unless it's our own deletion or a system catalog; but
+					 * in anyvisible mode, this tuple is visible.
+					 */
+					if (anyvisible)
+					{
+						indexIt = true;
+						tupleIsAlive = false;
+						break;
+					}
+
+					if (!TransactionIdIsCurrentTransactionId(xwait))
+					{
+						if (!is_system_catalog)
+							elog(WARNING, "concurrent insert in progress within table \"%s\"",
+								 RelationGetRelationName(heapRelation));
+
+						/*
+						 * If we are performing uniqueness checks, indexing
+						 * such a tuple could lead to a bogus uniqueness
+						 * failure.  In that case we wait for the inserting
+						 * transaction to finish and check again.
+						 */
+						if (checking_uniqueness)
+						{
+							/*
+							 * Must drop the lock on the buffer before we wait
+							 */
+							LockBuffer(scan->rs_cbuf, BUFFER_LOCK_UNLOCK);
+							if (subxid_xwait != InvalidTransactionId)
+								SubXactLockTableWait(xwait, subxid_xwait,
+													 heapRelation,
+													 &zheapTuple->t_self,
+													 XLTW_InsertIndexUnique);
+							else
+								XactLockTableWait(xwait, heapRelation,
+												  &zheapTuple->t_self,
+												  XLTW_InsertIndexUnique);
+							CHECK_FOR_INTERRUPTS();
+
+							if (targztuple != NULL)
+								pfree(targztuple);
+
+							goto recheck;
+						}
+
+						/*
+						 * Otherwise index it but don't check for uniqueness,
+						 * the same as a RECENTLY_DEAD tuple.
+						 */
+						indexIt = true;
+					}
+					else
+					{
+						/*
+						 * It's a regular tuple deleted by our own xact. Index
+						 * it but don't check for uniqueness, the same as a
+						 * RECENTLY_DEAD tuple.
+						 */
+						indexIt = true;
+					}
+					/* In any case, exclude the tuple from unique-checking */
+					tupleIsAlive = false;
+					break;
+				default:
+					elog(ERROR, "unexpected ZHeapTupleSatisfiesOldestXmin result");
+					indexIt = tupleIsAlive = false; /* keep compiler quiet */
+					break;
+			}
+
+			LockBuffer(scan->rs_cbuf, BUFFER_LOCK_UNLOCK);
+
+			if (!indexIt)
+				continue;
+		}
+		else
+		{
+			/* zheap_getnextslot did the time qual check */
+			tupleIsAlive = true;
+			targztuple = zheapTuple;
+		}
+
+		reltuples += 1;
+
+		MemoryContextReset(econtext->ecxt_per_tuple_memory);
+
+		/*
+		 * In a partial index, discard tuples that don't satisfy the
+		 * predicate.
+		 */
+		if (predicate != NULL)
+		{
+			if (!ExecQual(predicate, econtext))
+			{
+				/*
+				 * For SnapshotAny, targztuple is locally palloced above. So,
+				 * free it.
+				 */
+				if (snapshot == SnapshotAny && targztuple != NULL)
+					pfree(targztuple);
+				continue;
+			}
+		}
+
+		/*
+		 * For the current tuple, extract all the attributes we use in this
+		 * index, and note which are null.  This also performs evaluation of
+		 * any expressions needed.
+		 *
+		 * NOTE: We can't free the zheap tuple fetched by the scan method
+		 * before next iteration since this tuple is also referenced by
+		 * scan->rs_cztup. which is used by zheap scan API's to fetch the next
+		 * tuple. But, for forming and creating the index, we've to store the
+		 * correct version of the tuple in the slot. Hence, after forming the
+		 * index and calling the callback function, we restore the zheap tuple
+		 * fetched by the scan method in the slot.
+		 */
+		zslot->tuple = targztuple;
+		FormIndexDatum(indexInfo,
+					   slot,
+					   estate,
+					   values,
+					   isnull);
+
+		/*
+		 * FIXME: buildCallback functions accepts heaptuple as an argument.
+		 * But, it needs only the tid. So, we set t_self for the zheap tuple
+		 * and call the AM's callback.
+		 */
+		heapTuple->t_self = zheapTuple->t_self;
+
+		/* Call the AM's callback routine to process the tuple */
+		callback(indexRelation, heapTuple, values, isnull, tupleIsAlive,
+				 callback_state);
+
+		zslot->tuple = zheapTuple;
+
+		/*
+		 * For SnapshotAny, targztuple is locally palloc'd above. So, free it.
+		 */
+		if (snapshot == SnapshotAny && targztuple != NULL)
+			pfree(targztuple);
+	}
+
+	table_endscan(sscan);
+
+	/* we can now forget our snapshot, if set and registered by us */
+	if (need_unregister_snapshot)
+		UnregisterSnapshot(snapshot);
+
+	ExecDropSingleTupleTableSlot(slot);
+
+	pfree(heapTuple);
+
+	/* These may have been pointing to the now-gone estate */
+	indexInfo->ii_ExpressionsState = NIL;
+	indexInfo->ii_PredicateState = NULL;
+
+	return reltuples;
+}
+
+/*
+ * validate_index_zheapscan - second table scan for concurrent index build
+ *
+ * This has much code in common with IndexBuildZHeapScan, but it's enough
+ * different that it seems cleaner to have two routines not one.
+ */
+static void
+validate_index_zheapscan(Relation heapRelation,
+						 Relation indexRelation,
+						 IndexInfo *indexInfo,
+						 Snapshot snapshot,
+						 ValidateIndexState *state)
+{
+	TableScanDesc sscan;
+	ZHeapScanDesc scan;
+	Datum		values[INDEX_MAX_KEYS];
+	bool		isnull[INDEX_MAX_KEYS];
+	ExprState  *predicate;
+	TupleTableSlot *slot;
+	EState	   *estate;
+	ExprContext *econtext;
+	bool		in_index[MaxZHeapTuplesPerPage];
+
+	/* state variables for the merge */
+	ItemPointer indexcursor = NULL;
+	ItemPointerData decoded;
+	bool		tuplesort_empty = false;
+
+	/*
+	 * sanity checks
+	 */
+	Assert(OidIsValid(indexRelation->rd_rel->relam));
+
+	/*
+	 * Need an EState for evaluation of index expressions and partial-index
+	 * predicates.  Also a slot to hold the current tuple.
+	 */
+	estate = CreateExecutorState();
+	econtext = GetPerTupleExprContext(estate);
+	slot = table_slot_create(heapRelation, NULL);
+
+	/* Arrange for econtext's scan tuple to be the tuple under test */
+	econtext->ecxt_scantuple = slot;
+
+	/* Set up execution state for predicate, if any. */
+	predicate = ExecPrepareQual(indexInfo->ii_Predicate, estate);
+
+	/*
+	 * Prepare for scan of the base relation.  We need just those tuples
+	 * satisfying the passed-in reference snapshot.  We must disable syncscan
+	 * here, because it's critical that we read from block zero forward to
+	 * match the sorted TIDs.
+	 */
+	sscan = table_beginscan_strat(heapRelation, /* relation */
+								  snapshot, /* snapshot */
+								  0,	/* number of keys */
+								  NULL, /* scan key */
+								  true, /* buffer access strategy OK */
+								  false);	/* syncscan not OK */
+	scan = (ZHeapScanDesc) sscan;
+
+	/*
+	 * Scan all tuples matching the snapshot.
+	 */
+	while (zheap_getnextslot(sscan, ForwardScanDirection, slot))
+	{
+		OffsetNumber offnum = ItemPointerGetOffsetNumber(&slot->tts_tid);
+
+		CHECK_FOR_INTERRUPTS();
+
+		state->htups += 1;
+
+		/*
+		 * "merge" by skipping through the index tuples until we find or pass
+		 * the current tuple.
+		 */
+		while (!tuplesort_empty &&
+			   (!indexcursor ||
+				ItemPointerCompare(indexcursor, &slot->tts_tid) < 0))
+		{
+			Datum		ts_val;
+			bool		ts_isnull;
+
+			if (indexcursor)
+			{
+				/*
+				 * Remember index items seen earlier on the current heap page
+				 */
+				if (ItemPointerGetBlockNumber(indexcursor) == scan->rs_cblock)
+					in_index[ItemPointerGetOffsetNumber(indexcursor) - 1] = true;
+			}
+
+			tuplesort_empty = !tuplesort_getdatum(state->tuplesort, true,
+												  &ts_val, &ts_isnull, NULL);
+			Assert(tuplesort_empty || !ts_isnull);
+			if (!tuplesort_empty)
+			{
+				itemptr_decode(&decoded, DatumGetInt64(ts_val));
+				indexcursor = &decoded;
+
+				/* If int8 is pass-by-ref, free (encoded) TID Datum memory */
+#ifndef USE_FLOAT8_BYVAL
+				pfree(DatumGetPointer(ts_val));
+#endif
+			}
+			else
+			{
+				/* Be tidy */
+				indexcursor = NULL;
+			}
+		}
+
+		/*
+		 * If the tuplesort has overshot *and* we didn't see a match earlier,
+		 * then this tuple is missing from the index, so insert it.
+		 */
+		if ((tuplesort_empty ||
+			 ItemPointerCompare(indexcursor, &slot->tts_tid) > 0) &&
+			!in_index[offnum - 1])
+		{
+
+			/* Set up for predicate or expression evaluation */
+
+			/*
+			 * In a partial index, discard tuples that don't satisfy the
+			 * predicate.
+			 */
+			if (predicate != NULL)
+			{
+				if (!ExecQual(predicate, econtext))
+					continue;
+			}
+
+			/*
+			 * For the current heap tuple, extract all the attributes we use
+			 * in this index, and note which are null.  This also performs
+			 * evaluation of any expressions needed.
+			 */
+			FormIndexDatum(indexInfo,
+						   slot,
+						   estate,
+						   values,
+						   isnull);
+
+			/*
+			 * You'd think we should go ahead and build the index tuple here,
+			 * but some index AMs want to do further processing on the data
+			 * first. So pass the values[] and isnull[] arrays, instead.
+			 */
+
+			/*
+			 * If the tuple is already committed dead, you might think we
+			 * could suppress uniqueness checking, but this is no longer true
+			 * in the presence of HOT, because the insert is actually a proxy
+			 * for a uniqueness check on the whole HOT-chain.  That is, the
+			 * tuple we have here could be dead because it was already
+			 * HOT-updated, and if so the updating transaction will not have
+			 * thought it should insert index entries.  The index AM will
+			 * check the whole HOT-chain and correctly detect a conflict if
+			 * there is one.
+			 */
+
+			index_insert(indexRelation,
+						 values,
+						 isnull,
+						 &slot->tts_tid,
+						 heapRelation,
+						 indexInfo->ii_Unique ?
+						 UNIQUE_CHECK_YES : UNIQUE_CHECK_NO,
+						 indexInfo);
+
+			state->tups_inserted += 1;
+
+			MemoryContextReset(econtext->ecxt_per_tuple_memory);
+		}
+	}
+
+	table_endscan(sscan);
+
+	ExecDropSingleTupleTableSlot(slot);
+
+	FreeExecutorState(estate);
+
+	/* These may have been pointing to the now-gone estate */
+	indexInfo->ii_ExpressionsState = NIL;
+	indexInfo->ii_PredicateState = NULL;
+}
+
+static bool
+zheapam_scan_analyze_next_block(TableScanDesc sscan, BlockNumber blockno, BufferAccessStrategy bstrategy)
+{
+	ZHeapScanDesc scan = (ZHeapScanDesc) sscan;
+	Page		targpage;
+
+	/*
+	 * We must maintain a pin on the target page's buffer to ensure that the
+	 * maxoffset value stays good (else concurrent VACUUM might delete tuples
+	 * out from under us).  Hence, pin the page until we are done looking at
+	 * it.  We also choose to hold sharelock on the buffer throughout --- we
+	 * could release and re-acquire sharelock for each tuple, but since we
+	 * aren't doing much work per tuple, the extra lock traffic is probably
+	 * better avoided.
+	 */
+	scan->rs_cblock = blockno;
+	scan->rs_cindex = FirstOffsetNumber;
+
+	if (blockno == ZHEAP_METAPAGE)
+		return false;
+
+	scan->rs_cbuf = ReadBufferExtended(scan->rs_base.rs_rd, MAIN_FORKNUM, blockno,
+									   RBM_NORMAL, bstrategy);
+	LockBuffer(scan->rs_cbuf, BUFFER_LOCK_SHARE);
+
+	/* Skip TPD pages for zheap relations. */
+	targpage = BufferGetPage(scan->rs_cbuf);
+	if (IsTPDPage(targpage))
+	{
+		UnlockReleaseBuffer(scan->rs_cbuf);
+		scan->rs_cbuf = InvalidBuffer;
+
+		return false;
+	}
+
+	return true;
+}
+
+static bool
+zheapam_scan_analyze_next_tuple(TableScanDesc sscan, TransactionId OldestXmin, double *liverows, double *deadrows, TupleTableSlot *slot)
+{
+	ZHeapScanDesc scan = (ZHeapScanDesc) sscan;
+	Page		targpage;
+	OffsetNumber maxoffset;
+
+	Assert(TTS_IS_ZHEAP(slot));
+	Assert(scan->rs_cblock != ZHEAP_METAPAGE);
+
+	targpage = BufferGetPage(scan->rs_cbuf);
+	maxoffset = PageGetMaxOffsetNumber(targpage);
+
+	Assert(!IsTPDPage(targpage));
+
+	/* Inner loop over all tuples on the selected page */
+	for (; scan->rs_cindex <= maxoffset; scan->rs_cindex++)
+	{
+		ItemId		itemid;
+		ZHeapTuple	targtuple;
+		bool		sample_it = false;
+		TransactionId xid;
+
+		itemid = PageGetItemId(targpage, scan->rs_cindex);
+
+		/*
+		 * For zheap, we need to count delete committed rows towards dead rows
+		 * which would have been same, if the tuple was present in heap.
+		 */
+		if (ItemIdIsDeleted(itemid))
+		{
+			*deadrows += 1;
+			continue;
+		}
+
+		/*
+		 * We ignore unused and redirect line pointers.  DEAD line pointers
+		 * should be counted as dead, because we need vacuum to run to get rid
+		 * of them.  Note that this rule agrees with the way that
+		 * heap_page_prune() counts things.
+		 */
+		if (!ItemIdIsNormal(itemid))
+		{
+			if (ItemIdIsDead(itemid))
+				*deadrows += 1;
+			continue;
+		}
+
+		/* Allocate memory for target tuple. */
+		targtuple = zheap_gettuple(scan->rs_base.rs_rd, scan->rs_cbuf,
+								   scan->rs_cindex);
+
+		switch (ZHeapTupleSatisfiesOldestXmin(targtuple, OldestXmin,
+											  scan->rs_cbuf, true,
+											  &targtuple, &xid, NULL))
+		{
+			case ZHEAPTUPLE_LIVE:
+				sample_it = true;
+				*liverows += 1;
+				break;
+
+			case ZHEAPTUPLE_DEAD:
+			case ZHEAPTUPLE_RECENTLY_DEAD:
+				/* Count dead and recently-dead rows */
+				*deadrows += 1;
+				break;
+
+			case ZHEAPTUPLE_INSERT_IN_PROGRESS:
+
+				/*
+				 * Insert-in-progress rows are not counted.  We assume that
+				 * when the inserting transaction commits or aborts, it will
+				 * send a stats message to increment the proper count.  This
+				 * works right only if that transaction ends after we finish
+				 * analyzing the table; if things happen in the other order,
+				 * its stats update will be overwritten by ours.  However, the
+				 * error will be large only if the other transaction runs long
+				 * enough to insert many tuples, so assuming it will finish
+				 * after us is the safer option.
+				 *
+				 * A special case is that the inserting transaction might be
+				 * our own.  In this case we should count and sample the row,
+				 * to accommodate users who load a table and analyze it in one
+				 * transaction.  (pgstat_report_analyze has to adjust the
+				 * numbers we send to the stats collector to make this come
+				 * out right.)
+				 */
+				if (TransactionIdIsCurrentTransactionId(xid))
+				{
+					sample_it = true;
+					*liverows += 1;
+				}
+				break;
+
+			case ZHEAPTUPLE_DELETE_IN_PROGRESS:
+
+				/*
+				 * We count delete-in-progress rows as still live, using the
+				 * same reasoning given above; but we don't bother to include
+				 * them in the sample.
+				 *
+				 * If the delete was done by our own transaction, however, we
+				 * must count the row as dead to make pgstat_report_analyze's
+				 * stats adjustments come out right.  (Note: this works out
+				 * properly when the row was both inserted and deleted in our
+				 * xact.)
+				 */
+				if (TransactionIdIsCurrentTransactionId(xid))
+					*deadrows += 1;
+				else
+					*liverows += 1;
+				break;
+
+			default:
+				elog(ERROR, "unexpected HeapTupleSatisfiesVacuum result");
+				break;
+		}
+
+		if (sample_it)
+		{
+			ExecStoreZHeapTuple(targtuple, slot, false);
+			scan->rs_cindex++;
+
+			/* note that we leave the buffer locked here! */
+			return true;
+		}
+
+		/* Free memory for target tuple. */
+		if (targtuple)
+			zheap_freetuple(targtuple);
+	}
+
+	/* Now release the lock and pin on the page */
+	UnlockReleaseBuffer(scan->rs_cbuf);
+	scan->rs_cbuf = InvalidBuffer;
+
+	return false;
+}
+
+static bool
+zheap_scan_sample_next_block(TableScanDesc sscan, struct SampleScanState *scanstate)
+{
+	ZHeapScanDesc scan = (ZHeapScanDesc) sscan;
+	TsmRoutine *tsm = scanstate->tsmroutine;
+	BlockNumber blockno;
+
+	/* at least meta page should be there */
+	Assert(scan->rs_nblocks > 0);
+
+	/* return false immediately if relation is empty */
+	if (scan->rs_nblocks == ZHEAP_METAPAGE + 1)
+		return false;
+
+nextblock:
+	if (tsm->NextSampleBlock)
+	{
+		blockno = tsm->NextSampleBlock(scanstate, scan->rs_nblocks);
+		scan->rs_cblock = blockno;
+	}
+	else
+	{
+		/* scanning table sequentially */
+
+		if (scan->rs_cblock == InvalidBlockNumber)
+		{
+			Assert(!scan->rs_inited);
+			blockno = scan->rs_startblock;
+		}
+		else
+		{
+			Assert(scan->rs_inited);
+
+			blockno = scan->rs_cblock + 1;
+
+			if (blockno >= scan->rs_nblocks)
+			{
+				/* wrap to beginning of rel, might not have started at 0 */
+				blockno = 0;
+			}
+
+			/*
+			 * Report our new scan position for synchronization purposes.
+			 *
+			 * Note: we do this before checking for end of scan so that the
+			 * final state of the position hint is back at the start of the
+			 * rel.  That's not strictly necessary, but otherwise when you run
+			 * the same query multiple times the starting position would shift
+			 * a little bit backwards on every invocation, which is confusing.
+			 * We don't guarantee any specific ordering in general, though.
+			 */
+			if (scan->rs_base.rs_flags & SO_ALLOW_SYNC)
+				ss_report_location(scan->rs_base.rs_rd, blockno);
+
+			if (blockno == scan->rs_startblock)
+			{
+				blockno = InvalidBlockNumber;
+			}
+		}
+	}
+
+	if (!BlockNumberIsValid(blockno))
+	{
+		if (BufferIsValid(scan->rs_cbuf))
+			ReleaseBuffer(scan->rs_cbuf);
+		scan->rs_cbuf = InvalidBuffer;
+		scan->rs_cblock = InvalidBlockNumber;
+		scan->rs_inited = false;
+
+		return false;
+	}
+
+	scan->rs_inited = true;
+
+	/*
+	 * If the target block isn't valid, e.g. because it's a tpd page, got to
+	 * the next block.
+	 */
+	if (!zheapgetpage(sscan, blockno))
+	{
+		CHECK_FOR_INTERRUPTS();
+		goto nextblock;
+	}
+
+	return true;
+}
+
+static bool
+zheap_scan_sample_next_tuple(TableScanDesc sscan, struct SampleScanState *scanstate, TupleTableSlot *slot)
+{
+	ZHeapScanDesc scan = (ZHeapScanDesc) sscan;
+	TsmRoutine *tsm = scanstate->tsmroutine;
+	BlockNumber blockno = scan->rs_cblock;
+	bool		pagemode = (sscan->rs_flags & SO_ALLOW_PAGEMODE) != 0;
+	Page		page;
+	bool		all_visible = false;
+	OffsetNumber maxoffset;
+	uint8		vmstatus;
+	Buffer		vmbuffer = InvalidBuffer;
+
+	ExecClearTuple(slot);
+
+	/*
+	 * When not using pagemode, we must lock the buffer during tuple
+	 * visibility checks.
+	 */
+	if (!pagemode)
+	{
+		LockBuffer(scan->rs_cbuf, BUFFER_LOCK_SHARE);
+		page = (Page) BufferGetPage(scan->rs_cbuf);
+		maxoffset = PageGetMaxOffsetNumber(page);
+
+		if (!scan->rs_base.rs_snapshot->takenDuringRecovery)
+		{
+			vmstatus = visibilitymap_get_status(scan->rs_base.rs_rd,
+												BufferGetBlockNumber(scan->rs_cbuf),
+												&vmbuffer);
+
+			all_visible = vmstatus;
+
+			if (BufferIsValid(vmbuffer))
+			{
+				ReleaseBuffer(vmbuffer);
+				vmbuffer = InvalidBuffer;
+			}
+		}
+		else
+			all_visible = false;
+	}
+	else
+	{
+		maxoffset = scan->rs_ntuples;
+	}
+
+	for (;;)
+	{
+		OffsetNumber tupoffset;
+
+		CHECK_FOR_INTERRUPTS();
+
+		/* Ask the tablesample method which tuples to check on this page. */
+		tupoffset = tsm->NextSampleTuple(scanstate,
+										 blockno,
+										 maxoffset);
+
+		if (OffsetNumberIsValid(tupoffset))
+		{
+			ZHeapTuple	tuple;
+
+			if (!pagemode)
+			{
+				ItemId		itemid;
+				bool		visible;
+				ItemPointerData tid;
+
+				/* Skip invalid tuple pointers. */
+				itemid = PageGetItemId(page, tupoffset);
+				if (!ItemIdIsNormal(itemid))
+					continue;
+
+				ItemPointerSet(&tid, blockno, tupoffset);
+				if (all_visible)
+				{
+					tuple = zheap_gettuple(scan->rs_base.rs_rd, scan->rs_cbuf,
+										   tupoffset);
+					visible = true;
+				}
+				else
+				{
+					visible = ZHeapTupleFetch(scan->rs_base.rs_rd,
+											  scan->rs_cbuf,
+											  tupoffset,
+											  scan->rs_base.rs_snapshot,
+											  &tuple, NULL);
+				}
+
+				/*
+				 * If any prior version is visible, we pass latest visible as
+				 * true. The state of latest version of tuple is determined by
+				 * the called function.
+				 *
+				 * Note that, it's possible that tuple is updated in-place and
+				 * we're seeing some prior version of that. We handle that
+				 * case in ZHeapTupleHasSerializableConflictOut.
+				 */
+				CheckForSerializableConflictOut(visible, scan->rs_base.rs_rd, (void *) &tid,
+												scan->rs_cbuf, scan->rs_base.rs_snapshot);
+
+				/* Try next tuple from same page. */
+				if (!visible)
+					continue;
+
+				ExecStoreZHeapTuple(tuple, slot, false);
+
+				/* Found visible tuple, return it. */
+				LockBuffer(scan->rs_cbuf, BUFFER_LOCK_UNLOCK);
+
+				/* Count successfully-fetched tuples as heap fetches */
+				pgstat_count_heap_getnext(scan->rs_base.rs_rd);
+
+				return true;
+			}
+			else
+			{
+				tuple = scan->rs_visztuples[tupoffset - 1];
+				if (tuple == NULL)
+					continue;
+
+				ExecStoreZHeapTuple(tuple, slot, false);
+
+				return true;
+			}
+		}
+		else
+		{
+			/*
+			 * If we get here, it means we've exhausted the items on this page
+			 * and it's time to move to the next.
+			 */
+			if (!pagemode)
+				LockBuffer(scan->rs_cbuf, BUFFER_LOCK_UNLOCK);
+
+			break;
+		}
+	}
+
+	return false;
+}
+
+static void
+zheapam_relation_nontransactional_truncate(Relation rel)
+{
+	/*
+	 * Don't truncate the meta page.  We'll re-initialize it later.
+	 */
+	RelationTruncate(rel, ZHEAP_METAPAGE + 1);
+
+	/*
+	 * Re-Initialize the existing meta page.
+	 */
+	ZheapInitMetaPage(rel->rd_node, MAIN_FORKNUM,
+					  rel->rd_rel->relpersistence,
+					  true);
+}
+
+static void
+zheap_copy_for_cluster(Relation OldHeap, Relation NewHeap,
+					   Relation OldIndex, bool use_sort,
+					   TransactionId OldestXmin,
+					   TransactionId *xid_cutoff,
+					   MultiXactId *multi_cutoff,
+					   double *num_tuples,
+					   double *tups_vacuumed,
+					   double *tups_recently_dead)
+{
+	RewriteZheapState rwstate;
+	IndexScanDesc indexScan;
+	TableScanDesc heapScan;
+	bool		use_wal;
+	Tuplesortstate *tuplesort;
+	TupleDesc	oldTupDesc = RelationGetDescr(OldHeap);
+	TupleDesc	newTupDesc = RelationGetDescr(NewHeap);
+	TupleTableSlot *slot;
+	int			natts;
+	Datum	   *values;
+	bool	   *isnull;
+
+	*xid_cutoff = InvalidTransactionId;
+	*multi_cutoff = InvalidMultiXactId;
+
+	/*
+	 * We need to log the copied data in WAL iff WAL archiving/streaming is
+	 * enabled AND it's a WAL-logged rel.
+	 */
+	use_wal = XLogIsNeeded() && RelationNeedsWAL(NewHeap);
+
+	/* use_wal off requires smgr_targblock be initially invalid */
+	Assert(RelationGetTargetBlock(NewHeap) == InvalidBlockNumber);
+
+	/* Preallocate values/isnull arrays */
+	natts = newTupDesc->natts;
+	values = (Datum *) palloc(natts * sizeof(Datum));
+	isnull = (bool *) palloc(natts * sizeof(bool));
+
+	/* Initialize the rewrite operation */
+	rwstate = begin_zheap_rewrite(OldHeap, NewHeap, OldestXmin, *xid_cutoff,
+								  *multi_cutoff, use_wal);
+
+
+	/* Set up sorting if wanted */
+	if (use_sort)
+		tuplesort = tuplesort_begin_cluster(oldTupDesc, OldIndex,
+											maintenance_work_mem,
+											NULL, false);
+	else
+		tuplesort = NULL;
+
+	/*
+	 * Prepare to scan the OldHeap.
+	 *
+	 * We don't have a way to copy visibility information in zheap, so we just
+	 * copy LIVE tuples.  See comments atop rewritezheap.c
+	 *
+	 * While scanning, we skip meta and tpd pages (done by *getnext API's)
+	 * which is okay because we mark the tuples as frozen.  However, when we
+	 * extend current implementation to copy visibility information of tuples,
+	 * we would require to copy meta page and or TPD page information as well
+	 */
+	if (OldIndex != NULL && !use_sort)
+	{
+		heapScan = NULL;
+		indexScan = index_beginscan(OldHeap, OldIndex, GetTransactionSnapshot(), 0, 0);
+		index_rescan(indexScan, NULL, 0, NULL, 0);
+	}
+	else
+	{
+		heapScan = table_beginscan(OldHeap, GetTransactionSnapshot(), 0, (ScanKey) NULL);
+		indexScan = NULL;
+	}
+
+	slot = table_slot_create(OldHeap, NULL);
+
+	/*
+	 * Scan through the OldHeap, either in OldIndex order or sequentially;
+	 * copy each tuple into the NewHeap, or transiently to the tuplesort
+	 * module.  Note that we don't bother sorting dead tuples (they won't get
+	 * to the new table anyway).  While scanning, we skip meta and tpd pages
+	 * (done by *getnext API's) which is okay because we mark the tuples as
+	 * frozen.  However, when we extend current implementation to copy
+	 * visibility information of tuples, we would require to copy meta page
+	 * and or TPD page information as well.
+	 */
+	for (;;)
+	{
+		CHECK_FOR_INTERRUPTS();
+
+		if (indexScan != NULL)
+		{
+			if (!index_getnext_slot(indexScan, ForwardScanDirection, slot))
+				break;
+
+			/* Since we used no scan keys, should never need to recheck */
+			if (indexScan->xs_recheck)
+				elog(ERROR, "CLUSTER does not support lossy index conditions");
+		}
+		else
+		{
+			if (!table_scan_getnextslot(heapScan, ForwardScanDirection, slot))
+				break;
+		}
+
+		num_tuples += 1;
+		if (tuplesort != NULL)
+			tuplesort_putheaptuple(tuplesort, ExecFetchSlotHeapTuple(slot, false, NULL));
+		else
+		{
+			zheap_deform_tuple(ExecGetZHeapTupleFromSlot(slot), oldTupDesc,
+							   values, isnull, oldTupDesc->natts);
+			reform_and_rewrite_ztuple(oldTupDesc, newTupDesc,
+									  values, isnull, rwstate);
+		}
+	}
+
+	if (indexScan != NULL)
+		index_endscan(indexScan);
+	if (heapScan != NULL)
+		table_endscan(heapScan);
+
+	ExecDropSingleTupleTableSlot(slot);
+
+	/*
+	 * In scan-and-sort mode, complete the sort, then read out all live tuples
+	 * from the tuplestore and write them to the new relation.
+	 */
+	if (tuplesort != NULL)
+	{
+		tuplesort_performsort(tuplesort);
+
+		for (;;)
+		{
+			HeapTuple	heapTuple;
+
+			CHECK_FOR_INTERRUPTS();
+
+			heapTuple = tuplesort_getheaptuple(tuplesort, true);
+			if (heapTuple == NULL)
+				break;
+
+			heap_deform_tuple(heapTuple, oldTupDesc, values, isnull);
+
+			reform_and_rewrite_ztuple(oldTupDesc, newTupDesc,
+									  values, isnull, rwstate);
+		}
+
+		tuplesort_end(tuplesort);
+	}
+
+	/* Write out any remaining tuples, and fsync if needed */
+	end_zheap_rewrite(rwstate);
+
+	/* Clean up */
+	pfree(values);
+	pfree(isnull);
+}
+
+static void
+zheapam_set_new_filenode(Relation rel, const RelFileNode *newrnode,
+						 char persistence,
+						 TransactionId *freezeXid, MultiXactId *minmulti)
+{
+	SMgrRelation srel;
+
+	*freezeXid = InvalidTransactionId;
+	*minmulti = InvalidMultiXactId;
+
+	srel = RelationCreateStorage(*newrnode, persistence);
+
+	/* initialize the meta page for zheap */
+	ZheapInitMetaPage(*newrnode, MAIN_FORKNUM, persistence, false);
+
+	/*
+	 * If required, set up an init fork for an unlogged table so that it can
+	 * be correctly reinitialized on restart.  An immediate sync is required
+	 * even if the page has been logged, because the write did not go through
+	 * shared_buffers and therefore a concurrent checkpoint may have moved the
+	 * redo pointer past our xlog record.  Recovery may as well remove it
+	 * while replaying, for example, XLOG_DBASE_CREATE or XLOG_TBLSPC_CREATE
+	 * record. Therefore, logging is necessary even if wal_level=minimal.
+	 */
+	if (persistence == RELPERSISTENCE_UNLOGGED)
+	{
+		Assert(rel->rd_rel->relkind == RELKIND_RELATION ||
+			   rel->rd_rel->relkind == RELKIND_MATVIEW ||
+			   rel->rd_rel->relkind == RELKIND_TOASTVALUE);
+
+		smgrcreate(srel, INIT_FORKNUM, false);
+		log_smgrcreate(newrnode, INIT_FORKNUM);
+		smgrimmedsync(srel, INIT_FORKNUM);
+
+		/* ZBORKED: This causes separate WAL, which doesn't seem optimal */
+		ZheapInitMetaPage(*newrnode, INIT_FORKNUM, persistence, false);
+	}
+
+	smgrclose(srel);
+}
+
+static void
+zheapam_relation_copy_data(Relation rel, const RelFileNode *newrnode)
+{
+	SMgrRelation dstrel;
+
+	dstrel = smgropen(SMGR_MD, *newrnode, rel->rd_backend);
+	RelationOpenSmgr(rel);
+
+	/*
+	 * Since we copy the file directly without looking at the shared buffers,
+	 * we'd better first flush out any pages of the source relation that are
+	 * in shared buffers.  We assume no new changes will be made while we are
+	 * holding exclusive lock on the rel.
+	 */
+	FlushRelationBuffers(rel);
+
+	/*
+	 * Create and copy all forks of the relation, and schedule unlinking of
+	 * old physical files.
+	 *
+	 * NOTE: any conflict in relfilenode value will be caught in
+	 * RelationCreateStorage().
+	 */
+	RelationCreateStorage(*newrnode, rel->rd_rel->relpersistence);
+
+	/* copy main fork */
+	copy_zrelation_data(rel, dstrel);
+
+	/* copy those extra forks that exist */
+	for (ForkNumber forkNum = MAIN_FORKNUM + 1;
+		 forkNum <= MAX_FORKNUM; forkNum++)
+	{
+		if (smgrexists(rel->rd_smgr, forkNum))
+		{
+			smgrcreate(dstrel, forkNum, false);
+
+			/*
+			 * WAL log creation if the relation is persistent, or this is the
+			 * init fork of an unlogged relation.
+			 */
+			if (rel->rd_rel->relpersistence == RELPERSISTENCE_PERMANENT ||
+				(rel->rd_rel->relpersistence == RELPERSISTENCE_UNLOGGED &&
+				 forkNum == INIT_FORKNUM))
+				log_smgrcreate(newrnode, forkNum);
+
+			/*
+			 * In zheap, other forks don't have any undo operation associated
+			 * with them.  Hence, we don't need to undergo the costly process
+			 * of calling copy_zrelation_data where we read the buffers,
+			 * perform undo actions and then copy them.  We can simply copy
+			 * the buffers at smgr level.
+			 */
+			RelationCopyStorage(rel->rd_smgr, dstrel, forkNum,
+								rel->rd_rel->relpersistence);
+		}
+	}
+
+	/* drop old relation, and close new one */
+	RelationDropStorage(rel);
+	smgrclose(dstrel);
+}
+
+static uint64
+zheapam_relation_size(Relation rel, ForkNumber forkNumber)
+{
+	uint64		nblocks = 0;
+
+	/* Open it at the smgr level if not already done */
+	RelationOpenSmgr(rel);
+
+	/* InvalidForkNumber indicates returning the size for all forks */
+	if (forkNumber == InvalidForkNumber)
+	{
+		for (int i = 0; i < MAX_FORKNUM; i++)
+			nblocks += smgrnblocks(rel->rd_smgr, i);
+	}
+	else
+		nblocks = smgrnblocks(rel->rd_smgr, forkNumber);
+
+	return nblocks * BLCKSZ;
+}
+
+/*
+ * Check to see whether the table needs a TOAST table.  It does only if
+ * (1) there are any toastable attributes, and (2) the maximum length
+ * of a tuple could exceed TOAST_TUPLE_THRESHOLD.  (We don't want to
+ * create a toast table for something like "f1 varchar(20)".)
+ */
+static bool
+zheapam_relation_needs_toast_table(Relation rel)
+{
+	int32		data_length = 0;
+	bool		maxlength_unknown = false;
+	bool		has_toastable_attrs = false;
+	TupleDesc	tupdesc = rel->rd_att;
+	int32		tuple_length;
+	int			i;
+
+	for (i = 0; i < tupdesc->natts; i++)
+	{
+		Form_pg_attribute att = TupleDescAttr(tupdesc, i);
+
+		if (att->attisdropped)
+			continue;
+		data_length = att_align_nominal(data_length, att->attalign);
+		if (att->attlen > 0)
+		{
+			/* Fixed-length types are never toastable */
+			data_length += att->attlen;
+		}
+		else
+		{
+			int32		maxlen = type_maximum_size(att->atttypid,
+												   att->atttypmod);
+
+			if (maxlen < 0)
+				maxlength_unknown = true;
+			else
+				data_length += maxlen;
+			if (att->attstorage != 'p')
+				has_toastable_attrs = true;
+		}
+	}
+	if (!has_toastable_attrs)
+		return false;			/* nothing to toast? */
+	if (maxlength_unknown)
+		return true;			/* any unlimited-length attrs? */
+	tuple_length = MAXALIGN(SizeofHeapTupleHeader +
+							BITMAPLEN(tupdesc->natts)) +
+		MAXALIGN(data_length);
+	return (tuple_length > TOAST_TUPLE_THRESHOLD);
+}
+
+
+static void
+zheapam_estimate_rel_size(Relation rel, int32 *attr_widths,
+						  BlockNumber *pages, double *tuples, double *allvisfrac)
+{
+	BlockNumber curpages;
+	BlockNumber relpages;
+	double		reltuples;
+	BlockNumber relallvisible;
+	double		density;
+
+	/* it has storage, okay to call the smgr */
+	curpages = RelationGetNumberOfBlocks(rel);
+
+	/* coerce values in pg_class to more desirable types */
+	relpages = (BlockNumber) rel->rd_rel->relpages;
+	reltuples = (double) rel->rd_rel->reltuples;
+	relallvisible = (BlockNumber) rel->rd_rel->relallvisible;
+
+	/* subtract one page to account for the meta page */
+	if (curpages > 0)
+		curpages--;
+	if (relpages > 0)
+		relpages--;
+
+	/*
+	 * HACK: if the relation has never yet been vacuumed, use a minimum size
+	 * estimate of 10 pages.  The idea here is to avoid assuming a
+	 * newly-created table is really small, even if it currently is, because
+	 * that may not be true once some data gets loaded into it.  Once a vacuum
+	 * or analyze cycle has been done on it, it's more reasonable to believe
+	 * the size is somewhat stable.
+	 *
+	 * (Note that this is only an issue if the plan gets cached and used again
+	 * after the table has been filled.  What we're trying to avoid is using a
+	 * nestloop-type plan on a table that has grown substantially since the
+	 * plan was made.  Normally, autovacuum/autoanalyze will occur once enough
+	 * inserts have happened and cause cached-plan invalidation; but that
+	 * doesn't happen instantaneously, and it won't happen at all for cases
+	 * such as temporary tables.)
+	 *
+	 * We approximate "never vacuumed" by "has relpages = 0", which means this
+	 * will also fire on genuinely empty relations.  Not great, but
+	 * fortunately that's a seldom-seen case in the real world, and it
+	 * shouldn't degrade the quality of the plan too much anyway to err in
+	 * this direction.
+	 *
+	 * If the table has inheritance children, we don't apply this heuristic.
+	 * Totally empty parent tables are quite common, so we should be willing
+	 * to believe that they are empty.
+	 */
+	if (curpages < 10 &&
+		relpages == 0 &&
+		!rel->rd_rel->relhassubclass)
+		curpages = 10;
+
+	/* report estimated # pages */
+	*pages = curpages;
+	/* quick exit if rel is clearly empty */
+	if (curpages == 0)
+	{
+		*tuples = 0;
+		*allvisfrac = 0;
+		return;
+	}
+
+	/* estimate number of tuples from previous tuple density */
+	if (relpages > 0)
+		density = reltuples / (double) relpages;
+	else
+	{
+		/*
+		 * When we have no data because the relation was truncated, estimate
+		 * tuple width from attribute data types.  We assume here that the
+		 * pages are completely full, which is OK for tables (since they've
+		 * presumably not been vacuumed yet) but is probably an overestimate
+		 * for indexes.  Fortunately get_relation_info() can clamp the
+		 * overestimate to the parent table's size.
+		 *
+		 * Note: this code intentionally disregards alignment considerations,
+		 * because (a) that would be gilding the lily considering how crude
+		 * the estimate is, and (b) it creates platform dependencies in the
+		 * default plans which are kind of a headache for regression testing.
+		 */
+		int32		tuple_width;
+
+		tuple_width = get_rel_data_width(rel, attr_widths);
+		tuple_width += MAXALIGN(SizeofZHeapTupleHeader);
+		tuple_width += sizeof(ItemIdData);
+		/* note: integer division is intentional here */
+		density = (BLCKSZ - SizeOfPageHeaderData) / tuple_width;
+	}
+	*tuples = rint(density * (double) curpages);
+
+	/*
+	 * We use relallvisible as-is, rather than scaling it up like we do for
+	 * the pages and tuples counts, on the theory that any pages added since
+	 * the last VACUUM are most likely not marked all-visible.  But costsize.c
+	 * wants it converted to a fraction.
+	 */
+	if (relallvisible == 0 || curpages <= 0)
+		*allvisfrac = 0;
+	else if ((double) relallvisible >= curpages)
+		*allvisfrac = 1;
+	else
+		*allvisfrac = (double) relallvisible / curpages;
+}
+
+static const TableAmRoutine zheapam_methods = {
+	.type = T_TableAmRoutine,
+
+	.slot_callbacks = zheapam_slot_callbacks,
+
+	.scan_begin = zheap_beginscan,
+	.scan_getnextslot = zheap_getnextslot,
+	.scan_end = zheap_endscan,
+	.scan_rescan = zheap_rescan,
+
+	.parallelscan_estimate = table_block_parallelscan_estimate,
+	.parallelscan_initialize = table_block_parallelscan_initialize,
+	.parallelscan_reinitialize = table_block_parallelscan_reinitialize,
+
+	.index_fetch_begin = zheapam_begin_index_fetch,
+	.index_fetch_reset = zheapam_reset_index_fetch,
+	.index_fetch_end = zheapam_end_index_fetch,
+	.index_fetch_tuple = zheapam_index_fetch_tuple,
+
+	.tuple_insert = zheapam_insert,
+	.tuple_insert_speculative = zheapam_insert_speculative,
+	.tuple_complete_speculative = zheapam_complete_speculative,
+	.multi_insert = zheap_multi_insert,
+	.tuple_delete = zheapam_delete,
+	.tuple_update = zheapam_update,
+	.tuple_lock = zheapam_lock_tuple,
+	/* finish_bulk_insert is currently not needed */
+
+	.tuple_fetch_row_version = zheapam_fetch_row_version,
+	.tuple_get_latest_tid = zheap_get_latest_tid,
+	.tuple_tid_valid = zheapam_tuple_tid_valid,
+	.tuple_satisfies_snapshot = zheapam_tuple_satisfies_snapshot,
+	.compute_xid_horizon_for_tuples = zheap_compute_xid_horizon_for_tuples,
+
+	.relation_vacuum = lazy_vacuum_zheap_rel,
+	.relation_nontransactional_truncate = zheapam_relation_nontransactional_truncate,
+	.relation_copy_for_cluster = zheap_copy_for_cluster,
+	.relation_set_new_filenode = zheapam_set_new_filenode,
+	.relation_copy_data = zheapam_relation_copy_data,
+	.relation_estimate_size = zheapam_estimate_rel_size,
+	.scan_analyze_next_block = zheapam_scan_analyze_next_block,
+	.scan_analyze_next_tuple = zheapam_scan_analyze_next_tuple,
+	.index_build_range_scan = IndexBuildZHeapRangeScan,
+	.index_validate_scan = validate_index_zheapscan,
+
+	.relation_size = zheapam_relation_size,
+	.relation_needs_toast_table = zheapam_relation_needs_toast_table,
+
+	.scan_bitmap_next_block = zheap_scan_bitmap_next_block,
+	.scan_bitmap_next_tuple = zheap_scan_bitmap_next_tuple,
+	.scan_sample_next_block = zheap_scan_sample_next_block,
+	.scan_sample_next_tuple = zheap_scan_sample_next_tuple
+};
+
+Datum
+zheap_tableam_handler(PG_FUNCTION_ARGS)
+{
+	PG_RETURN_POINTER(&zheapam_methods);
+}
diff --git a/src/backend/access/zheap/zheapam_visibility.c b/src/backend/access/zheap/zheapam_visibility.c
new file mode 100644
index 0000000..194811f
--- /dev/null
+++ b/src/backend/access/zheap/zheapam_visibility.c
@@ -0,0 +1,1927 @@
+/*-------------------------------------------------------------------------
+ *
+ * zheapam_visibility.c
+ *	  POSTGRES "time qualification" code, ie, ztuple visibility rules.
+ *
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/zheap/zheapam_visibility.c
+ *
+ * The core idea to check if the tuple is all-visible is to see if it is
+ * modified by transaction smaller than oldestXidWithEpochHavingUndo (aka
+ * there is no undo pending for the transaction) or if the transaction slot
+ * is frozen.  For undo tuples, we additionally check if the transaction id
+ * of a transaction that has modified the tuple is FrozenTransactionId. The
+ * idea is we will always check the visibility of latest tuple based on
+ * epoch+xid and undo tuple's visibility based on xid.  If the heap tuple is
+ * not all-visible (epoch+xid is not older than oldestXidWithEpochHavingUndo),
+ * then the xid corresponding to undo tuple must be in the range of 2-billion
+ * transactions with oldestXidHavingUndo (xid part in
+ * oldestXidWithEpochHavingUndo).  This is true because we don't allow undo
+ * records older than 2-billion transactions.
+ *
+ *-------------------------------------------------------------------------
+ */
+
+#include "postgres.h"
+
+#include "access/subtrans.h"
+#include "access/xact.h"
+#include "access/zheap.h"
+#include "access/zmultilocker.h"
+#include "storage/bufmgr.h"
+#include "storage/proc.h"
+#include "storage/procarray.h"
+#include "utils/ztqual.h"
+#include "storage/proc.h"
+
+typedef enum
+{
+	ZTUPLETID_NEW,				/* inserted */
+	ZTUPLETID_MODIFIED,			/* in-place update or lock */
+	ZTUPLETID_GONE				/* non-in-place update or delete */
+} ZTupleTidOp;
+
+typedef enum
+{
+	ZVERSION_NONE,
+	ZVERSION_CURRENT,
+	ZVERSION_OLDER,
+	ZVERSION_CHECK_CID
+} ZVersionSelector;
+
+#define SNAPSHOT_REQUESTS_SPECTOKEN		0x0001
+#define SNAPSHOT_REQUESTS_SUBXID		0x0002
+
+static bool GetTupleFromUndo(UndoRecPtr urec_ptr,
+							 ZHeapTuple current_tuple, ZHeapTuple *visible_tuple,
+							 Snapshot snapshot, CommandId curcid, Buffer buffer,
+							 OffsetNumber offnum, ItemPointer ctid, int trans_slot);
+static ZTupleTidOp ZHeapTidOpFromInfomask(uint16 infomask);
+static ZVersionSelector ZHeapSelectVersionMVCC(ZTupleTidOp op,
+											   TransactionId xid, Snapshot snapshot);
+static ZVersionSelector ZHeapSelectVersionUpdate(ZTupleTidOp op,
+												 TransactionId xid, CommandId visibility_cid);
+static ZVersionSelector ZHeapCheckCID(ZTupleTidOp op,
+									  CommandId tuple_cid, CommandId visibility_cid);
+static ZVersionSelector ZHeapSelectVersionSelf(ZTupleTidOp op,
+											   TransactionId xid);
+static ZVersionSelector ZHeapSelectVersionDirty(ZTupleTidOp op,
+												bool locked_only, ZHeapTupleTransInfo *zinfo,
+												Snapshot snapshot, int *snapshot_requests);
+static ZVersionSelector ZHeapTupleSatisfies(ZTupleTidOp op, bool locked_only,
+											Snapshot snapshot, ZHeapTupleTransInfo *zinfo,
+											int *snapshot_requests);
+
+/*
+ * FetchTransInfoFromUndo
+ *
+ * Retrieve information about the transaction which has last operated on the
+ * specified tuple.
+ */
+void
+FetchTransInfoFromUndo(BlockNumber blocknum, OffsetNumber offnum,
+					   TransactionId xid, ZHeapTupleTransInfo *zinfo,
+					   ItemPointer new_ctid)
+{
+	UnpackedUndoRecord *urec;
+	uint32		epoch;
+
+	/*
+	 * If caller wants the CTID of the latest version of the tuple, set it to
+	 * that of the tuple we're looking up for starters.  If it's been the
+	 * subject of a non-in-place update, we'll fix that later.
+	 */
+	if (new_ctid)
+		ItemPointerSet(new_ctid, blocknum, offnum);
+
+	while (1)
+	{
+		/*
+		 * The transaction slot referred by the undo tuple could have been
+		 * reused multiple times, so to ensure that we have fetched the right
+		 * undo record we need to verify that the undo record contains xid
+		 * same as the xid that has modified the tuple. (However, when the
+		 * tuple is from the zheap itself rather than from undo, it's OK to
+		 * pass InvalidTransactionId as the XID, because we must be looking
+		 * for the latest version of the tuple in the undo rather than some
+		 * earlier one.)
+		 */
+		urec = UndoFetchRecord(zinfo->urec_ptr, blocknum, offnum,
+							   xid,
+							   &zinfo->urec_ptr,
+							   ZHeapSatisfyUndoRecord);
+
+		/*
+		 * If the undo record containing the information about the last
+		 * transaction that has operated on the tuple has been discarded, this
+		 * version of the tuple must be all-visible.
+		 */
+		if (urec == NULL)
+		{
+			zinfo->epoch_xid = InvalidFullTransactionId;
+			zinfo->xid = InvalidTransactionId;
+			zinfo->cid = InvalidCommandId;
+			zinfo->urec_ptr = InvalidUndoRecPtr;
+			return;
+		}
+
+		/*
+		 * If this is a UNDO_XID_LOCK_ONLY or UNDO_XID_MULTI_LOCK_ONLY
+		 * operation, it doesn't have any useful transaction information and
+		 * should be skipped.  See compute_new_xid_infomask for more details.
+		 * Otherwise, we've found the correct record.
+		 */
+		if (urec->uur_type != UNDO_XID_LOCK_ONLY &&
+			urec->uur_type != UNDO_XID_MULTI_LOCK_ONLY)
+			break;
+
+		/* We'll need to look further back into the undo log. */
+		xid = InvalidTransactionId;
+		zinfo->urec_ptr = urec->uur_blkprev;
+		UndoRecordRelease(urec);
+	}
+
+	epoch = urec->uur_xidepoch;
+	zinfo->xid = urec->uur_xid;
+	zinfo->epoch_xid =
+		FullTransactionIdFromEpochAndXid(epoch, zinfo->xid);
+	zinfo->cid = urec->uur_cid;
+
+	/* If this is a non-in-place update, update ctid if requested. */
+	if (new_ctid && urec->uur_type == UNDO_UPDATE)
+		ItemPointerCopy((ItemPointer) urec->uur_payload.data, new_ctid);
+
+	UndoRecordRelease(urec);
+}
+
+/*
+ * ZHeapUpdateTransactionSlotInfo
+ *
+ * Get the transaction slot information for the specified transaction slot,
+ * and use it to update the trans_slot and urec_ptr values for the
+ * ZHeapTupleTransInfo passed as an argument.
+ */
+void
+ZHeapUpdateTransactionSlotInfo(int trans_slot, Buffer buffer,
+							   OffsetNumber offnum, ZHeapTupleTransInfo *zinfo)
+{
+	ZHeapTupleTransInfo zinfo2;
+
+	/*
+	 * It is quite possible that the tuple is showing some valid transaction
+	 * slot, but actual slot has been frozen.  This can happen when the slot
+	 * belongs to TPD entry and the corresponding TPD entry is pruned.
+	 */
+	GetTransactionSlotInfo(buffer,
+						   offnum,
+						   trans_slot,
+						   true,
+						   true,
+						   &zinfo2);
+	zinfo->trans_slot = zinfo2.trans_slot;
+	zinfo->urec_ptr = zinfo2.urec_ptr;
+}
+
+/*
+ * ZHeapPageGetNewCtid
+ *
+ * 	This should be called for ctid which is already set deleted to get the new
+ * 	ctid, xid and cid which modified the given one.
+ */
+void
+ZHeapPageGetNewCtid(Buffer buffer, ItemPointer ctid,
+					ZHeapTupleTransInfo *zinfo)
+{
+	int			trans_slot;
+	ItemId		lp;
+	Page		page;
+	OffsetNumber offnum = ItemPointerGetOffsetNumber(ctid);
+
+	page = BufferGetPage(buffer);
+	lp = PageGetItemId(page, offnum);
+
+	Assert(ItemIdIsDeleted(lp));
+
+	trans_slot = ItemIdGetTransactionSlot(lp);
+
+	/*
+	 * We need undo record pointer to fetch the transaction information from
+	 * undo.
+	 */
+	GetTransactionSlotInfo(buffer, offnum, trans_slot, true, false, zinfo);
+	FetchTransInfoFromUndo(BufferGetBlockNumber(buffer), offnum,
+						   InvalidTransactionId, zinfo, ctid);
+
+	/*
+	 * We always expect non-frozen transaction slot here as the caller tries
+	 * to fetch the ctid of tuples that are visible to the snapshot, so
+	 * corresponding undo record can't be discarded.
+	 */
+	Assert(zinfo->trans_slot != ZHTUP_SLOT_FROZEN);
+}
+
+/*
+ * ZHeapTupleGetTransInfo - Retrieve transaction information of transaction
+ *			that has modified the tuple.
+ *
+ * nobuflock indicates whether caller has lock on the buffer 'buf'. If nobuflock
+ * is false, we rely on the supplied tuple zhtup to fetch the slot and undo
+ * information. Otherwise, we take buffer lock and fetch the actual tuple.
+ *
+ * snapshot will be used to avoid fetching tuple transaction id from the
+ * undo if the transaction slot is reused.  So caller should pass a valid
+ * snapshot where it's just fetching the xid for the visibility purpose.
+ * InvalidSnapshot indicates that we need the xid of reused transaction
+ * slot even if it is not in the snapshot, this is required to store its
+ * value in undo record, otherwise, that can break the visibility for
+ * other concurrent session holding old snapshot.
+ */
+void
+ZHeapTupleGetTransInfo(Buffer buf, OffsetNumber offnum,
+					   ZHeapTupleTransInfo *zinfo)
+{
+	ItemId		lp;
+	Page		page;
+	BlockNumber blocknum = BufferGetBlockNumber(buf);
+	bool		is_invalid_slot = false;
+
+	page = BufferGetPage(buf);
+	lp = PageGetItemId(page, offnum);
+	Assert(ItemIdIsNormal(lp) || ItemIdIsDeleted(lp));
+	if (!ItemIdIsDeleted(lp))
+	{
+		ZHeapTupleHeaderData hdr;
+
+		memcpy(&hdr, PageGetItem(page, lp), SizeofZHeapTupleHeader);
+		zinfo->trans_slot = ZHeapTupleHeaderGetXactSlot(&hdr);
+		if (ZHeapTupleHasInvalidXact(hdr.t_infomask))
+			is_invalid_slot = true;
+	}
+	else
+	{
+		/*
+		 * If it's deleted and pruned, we fetch the slot and undo information
+		 * from the item pointer itself.
+		 */
+		zinfo->trans_slot = ItemIdGetTransactionSlot(lp);
+		if (ItemIdGetVisibilityInfo(lp) & ITEMID_XACT_INVALID)
+			is_invalid_slot = true;
+	}
+
+	GetTransactionSlotInfo(buf, offnum, zinfo->trans_slot, true, false, zinfo);
+
+	/*
+	 * It is quite possible that the item is showing some valid transaction
+	 * slot, but actual slot has been frozen. This can happen when the slot
+	 * belongs to TPD entry and the corresponding TPD entry is pruned.
+	 */
+	if (zinfo->trans_slot == ZHTUP_SLOT_FROZEN)
+		return;
+
+	/*
+	 * We need to fetch all the transaction related information from undo
+	 * record for the tuples that point to a slot that gets invalidated for
+	 * reuse at some point of time.  See PageFreezeTransSlots.
+	 */
+	if (is_invalid_slot)
+	{
+		/*
+		 * We are intentionally avoiding to fetch the transaction information
+		 * from undo even when the tuple has invalid_xact_slot marking as if
+		 * the slot's current xid is all-visible, then the xid prior to it
+		 * must be all-visible.
+		 */
+		if (FullTransactionIdIsValid(zinfo->epoch_xid) &&
+			FullTransactionIdOlderThanAllUndo(zinfo->epoch_xid))
+		{
+			zinfo->trans_slot = ZHTUP_SLOT_FROZEN;
+			zinfo->epoch_xid = InvalidFullTransactionId;
+			zinfo->xid = InvalidTransactionId;
+			zinfo->cid = InvalidCommandId;
+			zinfo->urec_ptr = InvalidUndoRecPtr;
+			return;
+		}
+
+		FetchTransInfoFromUndo(blocknum, offnum, InvalidTransactionId, zinfo,
+							   NULL);
+	}
+}
+
+/*
+ * ZHeapTupleGetTransXID - Retrieve just the XID that last modified the tuple.
+ */
+TransactionId
+ZHeapTupleGetTransXID(ZHeapTuple zhtup, Buffer buf, bool nobuflock)
+{
+	ZHeapTupleTransInfo zinfo;
+	ZHeapTupleData mytup;
+	ItemPointer tid = &(zhtup->t_self);
+	OffsetNumber offnum = ItemPointerGetOffsetNumber(tid);
+
+	if (nobuflock)
+	{
+		Page		page;
+		ItemId		lp;
+
+		LockBuffer(buf, BUFFER_LOCK_SHARE);
+
+		page = BufferGetPage(buf);
+		lp = PageGetItemId(page, offnum);
+
+		/*
+		 * ZBORKED: Why is there only handling here for the !ItemIdIsDeleted
+		 * case?  Maybe we should have a completely separate function for the
+		 * nbuflock case that does Assert(!ItemIdIsDeleted(lp)).
+		 */
+		if (!ItemIdIsDeleted(lp))
+		{
+			/*
+			 * If the tuple is updated such that its transaction slot has been
+			 * changed, then we will never be able to get the correct tuple
+			 * from undo. To avoid, that we get the latest tuple from page
+			 * rather than relying on it's in-memory copy.
+			 *
+			 * ZBORKED: It should probably be the caller's job to ensure that
+			 * we are passed the correct tuple, rather than our job to go
+			 * re-fetch it.
+			 */
+			memcpy(&mytup, zhtup, sizeof(ZHeapTupleData));
+			mytup.t_data = (ZHeapTupleHeader) PageGetItem(page, lp);
+			mytup.t_len = ItemIdGetLength(lp);
+			zhtup = &mytup;
+		}
+	}
+
+	ZHeapTupleGetTransInfo(buf, offnum, &zinfo);
+
+	/* Release any buffer lock we acquired. */
+	if (nobuflock)
+		LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+
+	return zinfo.xid;
+}
+
+/*
+ * GetTupleFromUndoRecord
+ *
+ * Look up an undo record and copy a tuple from it, updating zinfo and ctid,
+ * and freeing the old tuple if so requested.
+ *
+ * If the undo record cannot be looked up, the tuple passed in as ztuple is
+ * returned and the function returns false.  If the undo record is looked up
+ * and the tuple found there is known to be the root tuple, that tuple is
+ * returned and the function still returns false.  Otherwise, the tuple
+ * looked up is returned and the function returns true.
+ */
+static bool
+GetTupleFromUndoRecord(UndoRecPtr urec_ptr, TransactionId xid, Buffer buffer,
+					   OffsetNumber offnum, ZHeapTupleHeader hdr,
+					   ZHeapTuple *ztuple, bool *free_ztuple,
+					   ZHeapTupleTransInfo *zinfo, ItemPointer ctid)
+{
+	UnpackedUndoRecord *urec;
+	uint32		epoch;
+
+	urec = UndoFetchRecord(urec_ptr,
+						   BufferGetBlockNumber(buffer),
+						   offnum,
+						   xid,
+						   NULL,
+						   ZHeapSatisfyUndoRecord);
+	if (urec == NULL)
+		return false;
+
+	zinfo->trans_slot =
+		UpdateTupleHeaderFromUndoRecord(urec, hdr, BufferGetPage(buffer));
+
+	/*
+	 * If the tuple is being updated or deleted, the payload contains a whole
+	 * new tuple.  If the caller wants it, extract it.
+	 */
+	if (ztuple != NULL &&
+		(urec->uur_type == UNDO_UPDATE ||
+		 urec->uur_type == UNDO_INPLACE_UPDATE ||
+		 urec->uur_type == UNDO_DELETE))
+	{
+		ZHeapTuple	zhtup;
+
+		zhtup = palloc(ZHEAPTUPLESIZE + urec->uur_tuple.len);
+		zhtup->t_len = urec->uur_tuple.len;
+		ItemPointerSet(&zhtup->t_self, urec->uur_block, urec->uur_offset);
+		zhtup->t_tableOid = urec->uur_reloid;
+		zhtup->t_data = (ZHeapTupleHeader) ((char *) zhtup + ZHEAPTUPLESIZE);
+		memcpy(zhtup->t_data, urec->uur_tuple.data, urec->uur_tuple.len);
+
+		if (*free_ztuple)
+			pfree(*ztuple);
+		*ztuple = zhtup;
+		*free_ztuple = true;
+	}
+
+	zinfo->urec_ptr = urec->uur_blkprev;
+	zinfo->xid = urec->uur_prevxid;
+	zinfo->cid = InvalidCommandId;
+
+	/*
+	 * We don't allow XIDs with an age of more than 2 billion in undo, so we
+	 * can infer the epoch here. (XXX Is this a valid justification given that
+	 * we're dealing with uur_prevxid, not uur_xid?)
+	 */
+	epoch = GetEpochForXid(urec->uur_prevxid);
+	zinfo->epoch_xid =
+		FullTransactionIdFromEpochAndXid(epoch, urec->uur_prevxid);
+
+	/* If this is a non-in-place update, update ctid if requested. */
+	if (ctid && urec->uur_type == UNDO_UPDATE)
+		*ctid = *((ItemPointer) urec->uur_payload.data);
+
+	UndoRecordRelease(urec);
+
+	/*
+	 * If slot is frozen or XID is FrozenTransactionId, there are no older
+	 * versions.
+	 */
+	if (zinfo->trans_slot == ZHTUP_SLOT_FROZEN ||
+		TransactionIdEquals(zinfo->xid, FrozenTransactionId))
+		return false;
+
+	/*
+	 * If the XID is older than any XID that has undo, there are no older
+	 * versions.
+	 */
+	if (FullTransactionIdOlderThanAllUndo(zinfo->epoch_xid))
+		return false;
+
+	return true;
+}
+
+/*
+ * GetTupleFromUndo
+ *
+ * Fetch the record from undo and determine if previous version of tuple
+ * is visible for the given snapshot.  If there exists a visible version
+ * of the tuple, return true, otherwise false.
+ *
+ * current_tuple should point to the current version of the tuple on input,
+ * or NULL if the current version is deleted.  visible_tuple, if not NULL,
+ * will be set to the visible version of the tuple on return. This may be
+ * current_tuple, an older version of the tuple retrieved from the undo log,
+ * or NULL.
+ *
+ *	During undo chain traversal, we need to ensure that we switch the undo
+ *	chain if the current version of undo tuple is modified by a transaction
+ *	that is different from transaction that has modified the previous version
+ *	of undo tuple.  This is primarily done because undo chain for a particular
+ *	tuple is formed based on the transaction id that has modified the tuple.
+ *
+ *	Also we don't need to process the chain if the latest xid that has changed
+ *  the tuple precedes smallest xid that has undo.
+ */
+static bool
+GetTupleFromUndo(UndoRecPtr urec_ptr, ZHeapTuple current_tuple,
+				 ZHeapTuple *visible_tuple, Snapshot snapshot,
+				 CommandId curcid, Buffer buffer, OffsetNumber offnum,
+				 ItemPointer ctid, int trans_slot)
+{
+	TransactionId prev_undo_xid = InvalidTransactionId;
+	int			prev_trans_slot_id = trans_slot;
+	ZHeapTupleTransInfo zinfo;
+	bool		free_ztuple = false;
+	BlockNumber blkno = BufferGetBlockNumber(buffer);
+	ZHeapTupleHeaderData hdr;
+
+	if (current_tuple != NULL)
+	{
+		/* Sanity check. */
+		Assert(ItemPointerGetOffsetNumber(&current_tuple->t_self) == offnum);
+
+		/*
+		 * We must set up 'hdr' to point to be a copy of the header bytes from
+		 * the most recent version of the tuple.  This is because in the
+		 * special case where the undo record we find is an UNDO_INSERT
+		 * record, we modify the existing bytes rather than overwriting them
+		 * completely.  If current_tuple == NULL, then the current version of
+		 * the tuple has been deleted or subjected to a non-in-place update,
+		 * so the first record we find won't be UNDO_INSERT.
+		 *
+		 * ZBORKED: We should really change this to get rid of the special
+		 * case for UNDO_INSERT, either by making it so that this function
+		 * doesn't get called in that case, or by making it so that it doesn't
+		 * need the newer tuple header bytes, or some other clever trick. That
+		 * would eliminate a substantial amount of complexity and ugliness
+		 * here.
+		 */
+		memcpy(&hdr, current_tuple->t_data, SizeofZHeapTupleHeader);
+
+		/* Initially, result tuple is same as input tuple. */
+		if (visible_tuple != NULL)
+			*visible_tuple = current_tuple;
+	}
+
+	/*
+	 * If caller wants the CTID of the latest version of the tuple, set it to
+	 * that of the tuple we're looking up for starters.  If it's been the
+	 * subject of a non-in-place update, GetTupleFromUndoRecord will adjust
+	 * the value later.
+	 */
+	if (ctid)
+		ItemPointerSet(ctid, blkno, offnum);
+
+	/*
+	 * tuple is modified after the scan is started, fetch the prior record
+	 * from undo to see if it is visible. loop until we find the visible
+	 * version.
+	 */
+	while (1)
+	{
+		ZTupleTidOp op;
+		ZVersionSelector zselect;
+		bool		have_cid = false;
+
+		if (!GetTupleFromUndoRecord(urec_ptr, prev_undo_xid, buffer,
+									offnum, &hdr, visible_tuple,
+									&free_ztuple, &zinfo, ctid))
+			break;
+
+		/*
+		 * Change the undo chain if the undo tuple is stamped with the
+		 * different transaction.
+		 */
+		if (zinfo.trans_slot != prev_trans_slot_id)
+			ZHeapUpdateTransactionSlotInfo(zinfo.trans_slot, buffer, offnum,
+										   &zinfo);
+
+		op = ZHeapTidOpFromInfomask(hdr.t_infomask);
+
+		/* can't further operate on deleted or non-inplace-updated tuple */
+		Assert(op != ZTUPLETID_GONE);
+
+		/*
+		 * We need to fetch all the transaction related information from undo
+		 * record for the tuples that point to a slot that gets invalidated
+		 * for reuse at some point of time.  See PageFreezeTransSlots.
+		 */
+		if (ZHeapTupleHasInvalidXact(hdr.t_infomask))
+		{
+			FetchTransInfoFromUndo(blkno, offnum, zinfo.xid, &zinfo, NULL);
+			have_cid = true;
+		}
+		else if (zinfo.cid != InvalidCommandId)
+			have_cid = true;
+
+		/*
+		 * The tuple must be all visible if the transaction slot is cleared or
+		 * latest xid that has changed the tuple is too old that it is
+		 * all-visible or it precedes smallest xid that has undo.
+		 */
+		if (zinfo.trans_slot == ZHTUP_SLOT_FROZEN ||
+			TransactionIdEquals(zinfo.xid, FrozenTransactionId) ||
+			FullTransactionIdOlderThanAllUndo(zinfo.epoch_xid))
+			break;
+
+		/* Preliminary visibility check, without relying on the CID. */
+		if (snapshot == NULL)
+			zselect = ZHeapSelectVersionUpdate(op, zinfo.xid, curcid);
+		else if (IsMVCCSnapshot(snapshot))
+			zselect = ZHeapSelectVersionMVCC(op, zinfo.xid, snapshot);
+		else
+		{
+			/* ZBORKED: Why do we always use SnapshotSelf rules here? */
+			zselect = ZHeapSelectVersionSelf(op, zinfo.xid);
+		}
+
+		/* If necessary, get and check CID. */
+		if (zselect == ZVERSION_CHECK_CID)
+		{
+			if (!have_cid)
+			{
+				FetchTransInfoFromUndo(blkno, offnum, zinfo.xid, &zinfo, NULL);
+				have_cid = true;
+			}
+
+			/* OK, now we can make a final visibility decision. */
+			zselect = ZHeapCheckCID(op, zinfo.cid, curcid);
+		}
+
+		/* Return the current version, or nothing, if appropriate. */
+		if (zselect == ZVERSION_CURRENT)
+			break;
+		if (zselect == ZVERSION_NONE)
+		{
+			if (visible_tuple != NULL)
+			{
+				if (free_ztuple)
+					pfree(*visible_tuple);
+				*visible_tuple = NULL;
+			}
+			return false;
+		}
+
+		/* Need to check next older version, so loop around. */
+		Assert(zselect == ZVERSION_OLDER);
+		urec_ptr = zinfo.urec_ptr;
+		prev_undo_xid = zinfo.xid;
+		prev_trans_slot_id = zinfo.trans_slot;
+	}
+
+	/* Copy latest header reconstructed from undo back into ztuple. */
+	if (visible_tuple != NULL && *visible_tuple != NULL)
+		memcpy((*visible_tuple)->t_data, &hdr, SizeofZHeapTupleHeader);
+	return true;
+}
+
+/*
+ * ZHeapTidOpFromInfomask
+ *
+ * Determine the last operation performed on a tuple using the infomask.
+ */
+static ZTupleTidOp
+ZHeapTidOpFromInfomask(uint16 infomask)
+{
+	if ((infomask & (ZHEAP_INPLACE_UPDATED | ZHEAP_XID_LOCK_ONLY)) != 0)
+		return ZTUPLETID_MODIFIED;
+	if ((infomask & (ZHEAP_UPDATED | ZHEAP_DELETED)) != 0)
+		return ZTUPLETID_GONE;
+	return ZTUPLETID_NEW;
+}
+
+/*
+ * ZHeapSelectVersionMVCC
+ *
+ * Decide, for a given MVCC snapshot, whether we should return the current
+ * version of a tuple, an older version, or no version at all.  We only have
+ * the XID available here, so if the CID turns out to be relevant, we must
+ * return ZVERSION_CHECK_CID; caller is responsible for calling ZHeapCheckCID
+ * with the appropriate CID to obtain a final answer.
+ */
+static ZVersionSelector
+ZHeapSelectVersionMVCC(ZTupleTidOp op, TransactionId xid, Snapshot snapshot)
+{
+	Assert(IsMVCCSnapshot(snapshot));
+
+	if (TransactionIdIsCurrentTransactionId(xid))
+	{
+		/*
+		 * This transaction is still running and belongs to the current
+		 * session.  If the current CID has been used to stamp a tuple or the
+		 * snapshot belongs to an older CID, then we need the CID for this
+		 * tuple to make a final visibility decision.
+		 */
+		if (GetCurrentCommandIdUsed() ||
+			GetCurrentCommandId(false) != snapshot->curcid)
+			return ZVERSION_CHECK_CID;
+
+		/* Nothing has changed since our scan started. */
+		return (op == ZTUPLETID_GONE ? ZVERSION_NONE : ZVERSION_CURRENT);
+	}
+
+	if (XidInMVCCSnapshot(xid, snapshot) || !TransactionIdDidCommit(xid))
+	{
+		/*
+		 * The XID is not visible to us, either because it aborted or because
+		 * it's in our MVCC snapshot.  If this is a new tuple, that means we
+		 * can't see it at all; otherwise, we need to check older versions.
+		 */
+		return (op == ZTUPLETID_NEW ? ZVERSION_NONE : ZVERSION_OLDER);
+	}
+
+	/* The XID is visible to us. */
+	return (op == ZTUPLETID_GONE ? ZVERSION_NONE : ZVERSION_CURRENT);
+}
+
+/*
+ * ZHeapSelectVersionUpdate
+ *
+ * Decide whether we should try to update the current version of a tuple,
+ * or an older version, or no version at all.
+ *
+ * Like ZHeapSelectVersionMVCC, we may return ZVERSION_CHECK_CID; the caller
+ * will need to invoke ZHeapCheckCID to get a final answer.  The caller must
+ * provide the CID of the update operation; if it's the latest CID, we can
+ * make a decision without forcing the caller to fetch the tuple CID.
+ */
+static ZVersionSelector
+ZHeapSelectVersionUpdate(ZTupleTidOp op, TransactionId xid,
+						 CommandId visibility_cid)
+{
+	/* Shouldn't be looking at a delete or non-inplace update. */
+	Assert(op != ZTUPLETID_GONE);
+
+	if (TransactionIdIsCurrentTransactionId(xid))
+	{
+		/*
+		 * This transaction is still running and belongs to the current
+		 * session.  If the current CID has been used to stamp a tuple or the
+		 * snapshot belongs to an older CID, then we need the CID for this
+		 * tuple to make a final visibility decision.
+		 */
+		if (GetCurrentCommandIdUsed() ||
+			GetCurrentCommandId(false) != visibility_cid)
+			return ZVERSION_CHECK_CID;
+
+		/* Nothing has changed since our scan started. */
+		return ZVERSION_CURRENT;
+	}
+
+	if (TransactionIdIsInProgress(xid) || !TransactionIdDidCommit(xid))
+	{
+		/* The XID is still in progress, or aborted; we can't see it. */
+		return (op == ZTUPLETID_NEW ? ZVERSION_NONE : ZVERSION_OLDER);
+	}
+
+	/* The XID is visible to us. */
+	return ZVERSION_CURRENT;
+}
+
+/*
+ * ZHeapCheckCID
+ *
+ * For a tuple whose xid satisfies TransactionIdIsCurrentTransactionId(xid),
+ * this function makes a determination about tuple visibility based on CID.
+ */
+static ZVersionSelector
+ZHeapCheckCID(ZTupleTidOp op, CommandId tuple_cid, CommandId visibility_cid)
+{
+	if (op == ZTUPLETID_GONE)
+	{
+		if (tuple_cid >= visibility_cid)
+			return ZVERSION_OLDER;	/* deleted after scan started */
+		else
+			return ZVERSION_NONE;	/* deleted before scan started */
+	}
+	else if (op == ZTUPLETID_MODIFIED)
+	{
+		if (tuple_cid >= visibility_cid)
+			return ZVERSION_OLDER;	/* updated/locked after scan started */
+		else
+			return ZVERSION_CURRENT;	/* updated/locked before scan started */
+	}
+	else
+	{
+		if (tuple_cid >= visibility_cid)
+			return ZVERSION_NONE;	/* inserted after scan started */
+		else
+			return ZVERSION_CURRENT;	/* inserted before scan started */
+	}
+
+	/* should never get here */
+	pg_unreachable();
+}
+
+/*
+ * ZHeapSelectVersionSelf
+ *
+ * Decide, using SnapshotSelf visibility rules, whether we should return the
+ * current version of a tuple, an older version, or no version at all.
+ */
+static ZVersionSelector
+ZHeapSelectVersionSelf(ZTupleTidOp op, TransactionId xid)
+{
+	if (op == ZTUPLETID_GONE)
+	{
+		if (TransactionIdIsCurrentTransactionId(xid))
+			return ZVERSION_NONE;
+		else if (TransactionIdIsInProgress(xid))
+			return ZVERSION_OLDER;
+		else if (TransactionIdDidCommit(xid))
+			return ZVERSION_NONE;
+		else
+			return ZVERSION_OLDER;	/* transaction is aborted */
+	}
+	else if (op == ZTUPLETID_MODIFIED)
+	{
+		if (TransactionIdIsCurrentTransactionId(xid))
+			return ZVERSION_CURRENT;
+		else if (TransactionIdIsInProgress(xid))
+			return ZVERSION_OLDER;
+		else if (TransactionIdDidCommit(xid))
+			return ZVERSION_CURRENT;
+		else
+			return ZVERSION_OLDER;	/* transaction is aborted */
+	}
+	else
+	{
+		if (TransactionIdIsCurrentTransactionId(xid))
+			return ZVERSION_CURRENT;
+		else if (TransactionIdIsInProgress(xid))
+			return ZVERSION_NONE;
+		else if (TransactionIdDidCommit(xid))
+			return ZVERSION_CURRENT;
+		else
+			return ZVERSION_NONE;	/* transaction is aborted */
+	}
+
+	/* should never get here */
+	pg_unreachable();
+}
+
+/*
+ * ZHeapTupleFetch
+ *
+ * Look for a tuple within a given buffer by offset.  If there is a version
+ * of that tuple that is visible to the given snapshot, return true, else
+ * return false.
+ *
+ * If visible_tuple != NULL, then set *visible_tuple to the visible version
+ * of the tuple, if there is one, or otherwise to NULL.
+ *
+ * For aborted transactions, we may need to fetch the visible tuple from undo.
+ * It is possible that actions corresponding to aborted transaction have
+ * been applied, but still xid is present in slot, however we should never
+ * get such an xid.
+ *
+ * For multilockers, the strongest locker information is always present on
+ * the tuple.  So for updaters, we don't need anything special as the tuple
+ * visibility will be determined based on the transaction information present
+ * on tuple.  For the lockers only case, we need to determine if the original
+ * inserter is visible to snapshot.
+ */
+bool
+ZHeapTupleFetch(Relation rel, Buffer buffer, OffsetNumber offnum,
+				Snapshot snapshot, ZHeapTuple *visible_tuple,
+				ItemPointer new_ctid)
+{
+	Page		dp = BufferGetPage(buffer);
+	ItemId		lp = PageGetItemId(dp, offnum);
+	int			trans_slot;
+	int			snapshot_requests = 0;
+	bool		is_invalid_slot;
+	bool		have_trans_info = false;
+	ZHeapTuple	tuple;
+	ZTupleTidOp op;
+	bool		locked_only;
+	ZHeapTupleTransInfo zinfo;
+	ZVersionSelector zselect;
+
+	/*
+	 * If caller wants SNAPSHOT_DIRTY semantics, certain fields need to be
+	 * cleared up front.  We may set them again later to pass back various
+	 * bits of information to the caller. (This is a pretty ugly hack, but
+	 * we've inherited it from the heap.  Is there a way to do this more
+	 * elegantly?)
+	 */
+	if (snapshot->snapshot_type == SNAPSHOT_DIRTY)
+	{
+		snapshot->xmin = snapshot->xmax = InvalidTransactionId;
+		snapshot->subxid = InvalidSubTransactionId;
+		snapshot->speculativeToken = 0;
+	}
+
+	/*
+	 * First, determine the transaction slot for this tuple and whether the
+	 * transaction slot has been reused (i.e. is flagged as invalid).  For
+	 * normal items, this information is stored in the tuple header; for
+	 * deleted ones, it is stored in the line pointer.
+	 */
+	if (ItemIdIsNormal(lp))
+	{
+		tuple = zheap_gettuple(rel, buffer, offnum);
+		trans_slot = ZHeapTupleHeaderGetXactSlot(tuple->t_data);
+		is_invalid_slot = ZHeapTupleHasInvalidXact(tuple->t_data->t_infomask);
+	}
+	else if (ItemIdIsDeleted(lp))
+	{
+		tuple = NULL;
+		trans_slot = ItemIdGetTransactionSlot(lp);
+		is_invalid_slot = (ItemIdGetVisibilityInfo(lp) & ITEMID_XACT_INVALID);
+	}
+	else
+	{
+		/*
+		 * If this item is neither normal nor dead, it must be unused.  In
+		 * that case, there is no version of the tuple visible here, so we can
+		 * exit quickly.
+		 */
+		Assert(!ItemIdIsUsed(lp));
+		if (visible_tuple)
+			*visible_tuple = NULL;
+		return false;
+	}
+
+	/*
+	 * If this is a SNAPSHOT_ANY snapshot, the current version of the tuple is
+	 * always the visible one.
+	 *
+	 * For SNAPSHOT_TOAST, we use the same rule.  Unlike the heap, we don't
+	 * need checks for VACUUM moving conditions as those are for pre-9.0 and
+	 * that doesn't apply for zheap.  For aborted speculative inserts, we
+	 * always marks row as dead, so we don't any check for that.
+	 */
+	if (snapshot->snapshot_type == SNAPSHOT_ANY ||
+		snapshot->snapshot_type == SNAPSHOT_TOAST)
+		goto out;
+
+	/*
+	 * If this is a SNAPSHOT_NON_VACUUMABLE snapshot, it uses a separate code
+	 * path.
+	 */
+	if (snapshot->snapshot_type == SNAPSHOT_NON_VACUUMABLE)
+	{
+		TransactionId xid;
+		ZHTSV_Result result;
+
+		/*
+		 * ZBORKED: ZHeapTupleSatisfiesOldestXmin can't handle a NULL tuple.
+		 * For now, just Assert() that we don't reach this code path in that
+		 * case.  Later, fix this.
+		 */
+		Assert(tuple != NULL);
+
+		result =
+			ZHeapTupleSatisfiesOldestXmin(tuple, snapshot->xmin, buffer, true,
+										  NULL, &xid, NULL);
+
+		if (result == ZHEAPTUPLE_DEAD)
+		{
+			pfree(tuple);
+			tuple = NULL;
+		}
+
+		goto out;
+	}
+
+	/* Look up the transaction slot information. */
+	GetTransactionSlotInfo(buffer, offnum, trans_slot, true, false, &zinfo);
+
+	/*
+	 * Check whether the transaction slot is frozen.  If not, and it is
+	 * invalid (i.e. reused), pull transaction information from the undo log.
+	 */
+	if (zinfo.trans_slot != ZHTUP_SLOT_FROZEN)
+	{
+		uint64		oldestXidHavingUndo;
+
+		oldestXidHavingUndo =
+			pg_atomic_read_u64(&ProcGlobal->oldestFullXidHavingUnappliedUndo);
+
+		if (TransactionIdIsValid(zinfo.xid) &&
+			U64FromFullTransactionId(zinfo.epoch_xid) < oldestXidHavingUndo)
+		{
+			/* The slot is old enough that we can treat it as frozen. */
+			zinfo.trans_slot = ZHTUP_SLOT_FROZEN;
+		}
+		else if (is_invalid_slot)
+		{
+			/*
+			 * The slot has been reused, but we can still skip reading the
+			 * undo if the XID we got from the transaction slot is visible to
+			 * our snapshot.  The real XID has to have committed before that
+			 * one, so it will be visible to our snapshot as well.
+			 */
+			if (TransactionIdIsValid(zinfo.xid) &&
+				IsMVCCSnapshot(snapshot) &&
+				!XidInMVCCSnapshot(zinfo.xid, snapshot))
+				zinfo.trans_slot = ZHTUP_SLOT_FROZEN;
+			else
+			{
+				FetchTransInfoFromUndo(BufferGetBlockNumber(buffer), offnum,
+									   InvalidTransactionId, &zinfo, new_ctid);
+				have_trans_info = true;
+				if (U64FromFullTransactionId(zinfo.epoch_xid) < oldestXidHavingUndo)
+					zinfo.trans_slot = ZHTUP_SLOT_FROZEN;
+			}
+		}
+	}
+
+	/* Attempt to make a visibility determination. */
+	if (tuple == NULL)
+	{
+		op = ZTUPLETID_GONE;
+		locked_only = false;
+	}
+	else
+	{
+		uint16		infomask = tuple->t_data->t_infomask;
+
+		op = ZHeapTidOpFromInfomask(infomask);
+		locked_only = ZHEAP_XID_IS_LOCKED_ONLY(infomask);
+	}
+	zselect = ZHeapTupleSatisfies(op, locked_only, snapshot, &zinfo,
+								  &snapshot_requests);
+
+	/* If necessary, check CID against snapshot. */
+	if (zselect == ZVERSION_CHECK_CID)
+	{
+		if (!have_trans_info)
+		{
+			FetchTransInfoFromUndo(BufferGetBlockNumber(buffer), offnum,
+								   InvalidTransactionId, &zinfo, new_ctid);
+			have_trans_info = true;
+		}
+		zselect = ZHeapCheckCID(op, zinfo.cid, snapshot->curcid);
+	}
+
+	/*
+	 * If we decided that we need to consult the undo log to figure out what
+	 * version our snapshot can see, call GetTupleFromUndo to fetch it.
+	 */
+	if (zselect == ZVERSION_OLDER)
+	{
+		ZHeapTuple	prior_tuple;
+
+		GetTupleFromUndo(zinfo.urec_ptr, tuple, &prior_tuple, snapshot,
+						 snapshot->curcid, buffer,
+						 offnum, new_ctid, zinfo.trans_slot);
+		if (tuple != NULL && tuple != prior_tuple)
+			pfree(tuple);
+		tuple = prior_tuple;
+	}
+
+	/* If we decide that no tuple is visible, free the tuple we built here. */
+	if (zselect == ZVERSION_NONE && tuple != NULL)
+	{
+		pfree(tuple);
+		tuple = NULL;
+	}
+
+	/*
+	 * Handle requests for additional information from undo.
+	 *
+	 * ZBORKED: This design really needs improvement.  All of the information
+	 * from the undo should be fetched at a single, centralized point rather
+	 * than having these add-on bits that have to be done through separate
+	 * code paths after the fact.
+	 */
+	if ((snapshot_requests & SNAPSHOT_REQUESTS_SPECTOKEN) != 0 &&
+		ZHeapTupleHeaderIsSpeculative(tuple->t_data))
+	{
+		ZHeapTupleGetSpecToken(tuple, buffer, zinfo.urec_ptr,
+							   &snapshot->speculativeToken);
+		Assert(snapshot->speculativeToken != 0);
+	}
+	if ((snapshot_requests & SNAPSHOT_REQUESTS_SUBXID) != 0)
+		ZHeapTupleGetSubXid(buffer, offnum, zinfo.urec_ptr,
+							&snapshot->subxid);
+
+	/*
+	 * If this tuple has been subjected to a non-inplace update, try to
+	 * retrieve the new CTID if the caller wants it.  When the tuple has been
+	 * moved to a completely different partition, the new CTID is not
+	 * meaningful, so we skip trying to find it in that case.
+	 *
+	 * ZBORKED: For reasons that aren't clear to me, zheap was somewhat
+	 * erratic about setting this.  It always did it for SNAPSHOT_ANY, skipped
+	 * it for SNAPSHOT_SELF, and did it in other cases only when no visible
+	 * version was found.  I don't know the reason for these rules.  I've
+	 * dropped the not-for-SNAPSHOT_SELF rule here.
+	 *
+	 * Note that when tuple == NULL, there's no reason to do this.  If we get
+	 * to that state after calling GetTupleFromUndo, that function will have
+	 * set new_ctid itself.  Otherwise, the tuple must be deleted and the
+	 * deletion must be all-visible.
+	 */
+	if (new_ctid && !have_trans_info &&
+		(zselect == ZVERSION_NONE ||
+		 snapshot->snapshot_type == SNAPSHOT_ANY) && tuple != NULL &&
+		!ZHeapTupleIsMoved(tuple->t_data->t_infomask) &&
+		ZHeapTupleIsUpdated(tuple->t_data->t_infomask))
+	{
+		FetchTransInfoFromUndo(BufferGetBlockNumber(buffer), offnum,
+							   InvalidTransactionId, &zinfo, new_ctid);
+		have_trans_info = true;
+	}
+
+	/*
+	 * We're all done. Make sure that either caller gets the tuple, or it gets
+	 * freed.
+	 */
+out:
+	if (visible_tuple)
+		*visible_tuple = tuple;
+	else if (tuple)
+		pfree(tuple);
+	return (tuple != NULL);
+}
+
+/*
+ * ZHeapTupleSatisfies
+ *
+ * Determine whether (a) the current version of the tuple is visible to the
+ * snapshot, (b) no version of the tuple is visible to the snapshot, or
+ * (c) the previous version of the tuple should be looked up into the undo
+ * log to determine which version, if any, is visible.
+ *
+ * This function can only handle certain types of snapshots; it is a helper
+ * function for ZHeapTupleFetch, not a general-purpose facility.
+ */
+static ZVersionSelector
+ZHeapTupleSatisfies(ZTupleTidOp op, bool locked_only, Snapshot snapshot,
+					ZHeapTupleTransInfo *zinfo, int *snapshot_requests)
+{
+	ZVersionSelector zselect;
+
+	/* Attempt to make a visibility determination. */
+	if (zinfo->trans_slot == ZHTUP_SLOT_FROZEN)
+	{
+		/*
+		 * The tuple is not associated with a transaction slot that is new
+		 * enough to matter, so all changes previously made to the tuple are
+		 * now all-visible.  If the last operation performed was a delete or a
+		 * non-inplace update, the tuple is now effectively gone; if it was an
+		 * insert or an inplace update, use the current version.
+		 */
+		zselect = (op == ZTUPLETID_GONE) ? ZVERSION_NONE : ZVERSION_CURRENT;
+	}
+	else if (snapshot->snapshot_type == SNAPSHOT_MVCC)
+		zselect = ZHeapSelectVersionMVCC(op, zinfo->xid, snapshot);
+	else if (snapshot->snapshot_type == SNAPSHOT_SELF)
+		zselect = ZHeapSelectVersionSelf(op, zinfo->xid);
+	else if (snapshot->snapshot_type == SNAPSHOT_DIRTY)
+		zselect = ZHeapSelectVersionDirty(op, locked_only, zinfo,
+										  snapshot, snapshot_requests);
+	else
+		elog(ERROR, "unsupported snapshot type %d",
+			 (int) snapshot->snapshot_type);
+
+	return zselect;
+}
+
+/*
+ * ZHeapTupleSatisfiesUpdate
+ *
+ *	The return value for this API are same as HeapTupleSatisfiesUpdate.
+ *	However, there is a notable difference in the way to determine visibility
+ *	of tuples.  We need to traverse undo record chains to determine the
+ *	visibility of tuple.
+ *
+ *	For multilockers, the visibility can be determined by the information
+ *	present on tuple.  See ZHeapTupleSatisfiesMVCC.  Also, this API returns
+ *	TM_Ok, if the strongest locker is committed which means
+ *	the caller need to take care of waiting for other lockers in such a case.
+ *
+ *	ctid - returns the ctid of visible tuple if the tuple is either deleted or
+ *	updated.  ctid needs to be retrieved from undo tuple.
+ *	trans_slot - returns the transaction slot of the transaction that has
+ *	modified the visible tuple.
+ *	xid - returns the xid that has modified the visible tuple.
+ *	subxid - returns the subtransaction id, if any, that has modified the
+ *	visible tuple.  We fetch the subxid from undo only when it is required,
+ *	i.e. when the caller would wait on it to finish.
+ *	cid - returns the cid of visible tuple.
+ *	single_locker_xid - returns the xid of a single in-progress locker, if any.
+ *	single_locker_trans_slot - returns the transaction slot of a single
+ *	in-progress locker, if any.
+ *	lock_allowed - allow caller to lock the tuple if it is in-place updated
+ *	in_place_updated - returns whether the current visible version of tuple is
+ *	updated in place.
+ */
+TM_Result
+ZHeapTupleSatisfiesUpdate(Relation rel, ItemPointer tid, ZHeapTuple zhtup,
+						  CommandId curcid, Buffer buffer, ItemPointer ctid,
+						  ZHeapTupleTransInfo *zinfo,
+						  SubTransactionId *subxid,
+						  TransactionId *single_locker_xid,
+						  int *single_locker_trans_slot,
+						  bool lock_allowed, Snapshot snapshot,
+						  bool *in_place_updated_or_locked)
+{
+	BlockNumber blocknum = ItemPointerGetBlockNumber(tid);
+	OffsetNumber offnum = ItemPointerGetOffsetNumber(tid);
+	Page		page = BufferGetPage(buffer);
+	ItemId		lp = PageGetItemId(page, offnum);
+	ZHeapTupleHeader tuple;
+	CommandId	cur_comm_cid = GetCurrentCommandId(false);
+	bool		fetch_cid = true;
+	bool		have_ctid = false;
+	int			trans_slot;
+	bool		is_invalid_slot;
+	ZTupleTidOp op;
+	TM_Result	result = TM_Invisible;
+	bool		needs_recheck = false;
+	bool		needs_subxid = false;
+
+	*single_locker_xid = InvalidTransactionId;
+	*single_locker_trans_slot = InvalidXactSlotId;
+	*in_place_updated_or_locked = false;
+
+	Assert(ItemPointerIsValid(tid));
+	*ctid = *tid;
+
+	lp = PageGetItemId(page, offnum);
+	Assert(ItemIdIsNormal(lp) || ItemIdIsDeleted(lp));
+
+	zhtup->t_tableOid = RelationGetRelid(rel);
+	zhtup->t_self = *tid;
+
+	if (ItemIdIsDeleted(lp))
+	{
+		zhtup->t_data = NULL;
+		zhtup->t_len = 0;
+		ZHeapPageGetNewCtid(buffer, ctid, zinfo);
+		return TM_Updated;
+	}
+
+	zhtup->t_data = (ZHeapTupleHeader) PageGetItem(page, lp);
+	zhtup->t_len = ItemIdGetLength(lp);
+	tuple = zhtup->t_data;
+
+	/*
+	 * If the current command doesn't need to modify any tuple and the
+	 * snapshot used is not of any previous command, then it can see all the
+	 * modifications made by current transactions till now.  So, we don't even
+	 * attempt to fetch CID from undo in such cases.
+	 */
+	if (!GetCurrentCommandIdUsed() && cur_comm_cid == curcid)
+		fetch_cid = false;
+
+	/* Extract information from tuple header */
+	op = ZHeapTidOpFromInfomask(tuple->t_infomask);
+	trans_slot = ZHeapTupleHeaderGetXactSlot(tuple);
+	is_invalid_slot = ZHeapTupleHasInvalidXact(tuple->t_infomask);
+
+	/* Get transaction info */
+	GetTransactionSlotInfo(buffer, offnum, trans_slot, true, false, zinfo);
+
+	/*
+	 * We need to fetch all the transaction related information from undo
+	 * record for the tuples that point to a slot that gets invalidated for
+	 * reuse at some point of time.  See PageFreezeTransSlots.
+	 */
+	if (is_invalid_slot)
+	{
+		/*
+		 * We are intentionally avoiding to fetch the transaction information
+		 * from undo even when the tuple has invalid_xact_slot marking as if
+		 * the slot's current xid is all-visible, then the xid prior to it
+		 * must be all-visible.
+		 */
+		if (FullTransactionIdIsValid(zinfo->epoch_xid) &&
+			FullTransactionIdOlderThanAllUndo(zinfo->epoch_xid))
+		{
+			zinfo->trans_slot = ZHTUP_SLOT_FROZEN;
+			zinfo->epoch_xid = InvalidFullTransactionId;
+			zinfo->xid = InvalidTransactionId;
+			zinfo->cid = InvalidCommandId;
+			zinfo->urec_ptr = InvalidUndoRecPtr;
+		}
+		else
+			FetchTransInfoFromUndo(blocknum, offnum, InvalidTransactionId,
+								   zinfo, ctid);
+		have_ctid = true;
+	}
+	else if (fetch_cid && TransactionIdIsCurrentTransactionId(zinfo->xid))
+	{
+		FetchTransInfoFromUndo(blocknum, offnum, InvalidTransactionId,
+							   zinfo, ctid);
+		have_ctid = true;
+	}
+
+	if (op == ZTUPLETID_GONE)
+	{
+		/*
+		 * The tuple is deleted or non-inplace-updated and must be all visible
+		 * if the transaction slot is cleared or latest xid that has changed
+		 * the tuple precedes smallest xid that has undo.  However, that is
+		 * not possible at this stage as the tuple has already passed snapshot
+		 * check.
+		 */
+		Assert(!(zinfo->trans_slot == ZHTUP_SLOT_FROZEN &&
+				 FullTransactionIdOlderThanAllUndo(zinfo->epoch_xid)));
+
+		if (TransactionIdIsCurrentTransactionId(zinfo->xid))
+		{
+			if (fetch_cid && zinfo->cid >= curcid)
+			{
+				/* deleted after scan started, check previous tuple from undo */
+				result = TM_SelfModified;
+				needs_recheck = true;
+			}
+		}
+		else if (TransactionIdIsInProgress(zinfo->xid))
+		{
+			result = TM_BeingModified;
+			needs_recheck = true;
+			needs_subxid = true;
+		}
+		else if (TransactionIdDidCommit(zinfo->xid))
+		{
+			/* tuple is deleted or non-inplace-updated */
+			result = TM_Updated;
+		}
+		else					/* transaction is aborted */
+		{
+			/*
+			 * If updating transaction id is aborted and the tuple is visible
+			 * then return TM_BeingModified, so that caller can apply the undo
+			 * before modifying the page.  Here, we don't need to fetch
+			 * subtransaction id as it is only possible for top-level xid to
+			 * have pending undo actions.
+			 */
+			result = TM_BeingModified;
+			needs_recheck = true;
+		}
+	}
+	else if (op == ZTUPLETID_MODIFIED)
+	{
+		*in_place_updated_or_locked = true;
+
+		/*
+		 * The tuple is updated/locked and must be all visible if the
+		 * transaction slot is cleared or latest xid that has touched the
+		 * tuple precedes smallest xid that has undo.  If there is a single
+		 * locker on the tuple, then we fetch the lockers transaction info
+		 * from undo as we never store lockers slot on tuple.  See
+		 * compute_new_xid_infomask for more details about lockers.
+		 */
+		if (zinfo->trans_slot == ZHTUP_SLOT_FROZEN ||
+			FullTransactionIdOlderThanAllUndo(zinfo->epoch_xid))
+		{
+			FullTransactionId single_locker_fxid;
+			bool		found = false;
+
+			if (ZHEAP_XID_IS_LOCKED_ONLY(tuple->t_infomask) &&
+				!ZHeapTupleHasMultiLockers(tuple->t_infomask))
+				found = GetLockerTransInfo(rel, &zhtup->t_self, buffer, single_locker_trans_slot,
+										   &single_locker_fxid);
+
+			if (!found)
+				result = TM_Ok;
+			else
+			{
+				*single_locker_xid =
+					XidFromFullTransactionId(single_locker_fxid);
+
+				/*
+				 * If there is a single locker in-progress/aborted locker,
+				 * it's safe to return being updated so that the caller check
+				 * for lock conflicts or perform rollback if necessary.
+				 *
+				 * If the single locker is our current transaction, then also
+				 * we return being updated.
+				 */
+				result = TM_BeingModified;
+			}
+		}
+		else if (TransactionIdIsCurrentTransactionId(zinfo->xid))
+		{
+			if (fetch_cid && zinfo->cid >= curcid)
+			{
+				/*
+				 * updated/locked after scan started, check previous tuple
+				 * from undo
+				 */
+				if (ZHEAP_XID_IS_LOCKED_ONLY(tuple->t_infomask))
+					result = TM_BeingModified;
+				else
+					result = TM_SelfModified;
+				needs_recheck = true;
+			}
+			else
+			{
+				if (ZHEAP_XID_IS_LOCKED_ONLY(tuple->t_infomask))
+				{
+					/*
+					 * Locked before scan;  caller can check if it is locked
+					 * in lock mode higher or equal to the required mode, then
+					 * it can skip locking the tuple.
+					 */
+					result = TM_BeingModified;
+				}
+				else
+					/* updated before scan is started */
+					result = TM_Ok;
+			}
+		}
+		else if (TransactionIdIsInProgress(zinfo->xid))
+		{
+			result = TM_BeingModified;
+			needs_recheck = true;
+			needs_subxid = true;
+		}
+		else if (TransactionIdDidCommit(zinfo->xid))
+		{
+			/*
+			 * if tuple is updated and not in our snapshot, then allow to
+			 * update it.
+			 */
+			if (lock_allowed || !XidInMVCCSnapshot(zinfo->xid, snapshot))
+				result = TM_Ok;
+			else
+				result = TM_Updated;
+		}
+		else					/* transaction is aborted */
+		{
+			/*
+			 * If updating transaction id is aborted and the tuple is visible
+			 * then return TM_BeingModified, so that caller can apply the undo
+			 * before modifying the page.  Here, we don't need to fetch
+			 * subtransaction id as it is only possible for top-level xid to
+			 * have pending undo actions.
+			 */
+			result = TM_BeingModified;
+			needs_recheck = true;
+		}
+	}
+	else
+	{
+		/*
+		 * The tuple must be all visible if the transaction slot is cleared or
+		 * latest xid that has changed the tuple precedes smallest xid that
+		 * has undo.
+		 */
+		if (zinfo->trans_slot == ZHTUP_SLOT_FROZEN ||
+			FullTransactionIdOlderThanAllUndo(zinfo->epoch_xid))
+			result = TM_Ok;
+		else if (TransactionIdIsCurrentTransactionId(zinfo->xid))
+		{
+			if (fetch_cid && zinfo->cid >= curcid)
+				result = TM_Invisible;	/* inserted after scan started */
+			else
+				result = TM_Ok; /* inserted before scan started */
+		}
+		else if (TransactionIdIsInProgress(zinfo->xid))
+			result = TM_Invisible;
+		else if (TransactionIdDidCommit(zinfo->xid))
+			result = TM_Ok;
+	}
+
+	/*
+	 * If a recheck was requested, we must consult the undo log to determine
+	 * the final answer.
+	 */
+	if (needs_recheck)
+	{
+		if (!GetTupleFromUndo(zinfo->urec_ptr, zhtup, NULL, NULL, curcid,
+							  buffer, offnum, ctid, zinfo->trans_slot))
+		{
+			result = TM_Invisible;
+			needs_subxid = false;
+		}
+
+		/* GetTupleFromUndo has populated CTID */
+		have_ctid = true;
+	}
+
+	/*
+	 * If the tuple was the subject of a non-inplace update and if a CTID was
+	 * requested and if we haven't fetched undo information yet then do so
+	 * now.
+	 */
+	if (ctid && !have_ctid && ZHeapTupleIsUpdated(tuple->t_infomask) &&
+		!ZHeapTupleIsMoved(tuple->t_infomask))
+		FetchTransInfoFromUndo(blocknum, offnum, InvalidTransactionId,
+							   zinfo, ctid);
+
+	if (needs_subxid)
+		ZHeapTupleGetSubXid(buffer, offnum, zinfo->urec_ptr, subxid);
+
+	return result;
+}
+
+/*
+ * ZHeapTupleIsSurelyDead
+ *
+ * Similar to HeapTupleIsSurelyDead, but for zheap tuples.
+ */
+bool
+ZHeapTupleIsSurelyDead(ZHeapTuple zhtup, Buffer buffer, OffsetNumber offnum)
+{
+	ZHeapTupleTransInfo zinfo;
+
+	if (zhtup != NULL &&
+		ZHeapTidOpFromInfomask(zhtup->t_data->t_infomask) != ZTUPLETID_GONE)
+		return false;
+
+	/* Get transaction information. */
+	ZHeapTupleGetTransInfo(buffer, offnum, &zinfo);
+
+	/*
+	 * The tuple is deleted and must be all visible if the transaction slot is
+	 * cleared or latest xid that has changed the tuple precedes smallest xid
+	 * that has undo.
+	 */
+	if (zinfo.trans_slot == ZHTUP_SLOT_FROZEN ||
+		FullTransactionIdOlderThanAllUndo(zinfo.epoch_xid))
+		return true;
+
+	return false;				/* Tuple is still alive */
+}
+
+/*
+ * ZHeapTupleSatisfiesDirty
+ *		Returns the visible version of tuple (including effects of open
+ *		transactions) if any, NULL otherwise.
+ *
+ *	Here, we consider the effects of:
+ *		all committed and in-progress transactions (as of the current instant)
+ *		previous commands of this transaction
+ *		changes made by the current command
+ *
+ *	This is essentially like ZHeapTupleSatisfiesSelf as far as effects of
+ *	the current transaction and committed/aborted xacts are concerned.
+ *	However, we also include the effects of other xacts still in progress.
+ *
+ *	The tuple will be considered visible iff:
+ *	(a) Latest operation on tuple is Delete or non-inplace-update and the
+ *		current transaction is in progress.
+ *	(b) Latest operation on tuple is Insert, In-Place update or tuple is
+ *		locked and the transaction that has performed operation is current
+ *		transaction or is in-progress or is committed.
+ */
+static ZVersionSelector
+ZHeapSelectVersionDirty(ZTupleTidOp op, bool locked_only,
+						ZHeapTupleTransInfo *zinfo,
+						Snapshot snapshot, int *snapshot_requests)
+{
+	if (op == ZTUPLETID_GONE)
+	{
+		if (TransactionIdIsCurrentTransactionId(zinfo->xid))
+			return ZVERSION_NONE;
+		else if (TransactionIdIsInProgress(zinfo->xid))
+		{
+			snapshot->xmax = zinfo->xid;
+			if (UndoRecPtrIsValid(zinfo->urec_ptr))
+				*snapshot_requests |= SNAPSHOT_REQUESTS_SUBXID;
+			return ZVERSION_CURRENT;
+		}
+		else if (TransactionIdDidCommit(zinfo->xid))
+		{
+			/* tuple is deleted or non-inplace-updated */
+			return ZVERSION_NONE;
+		}
+		else					/* transaction is aborted */
+			return ZVERSION_OLDER;
+	}
+	else if (op == ZTUPLETID_MODIFIED)
+	{
+		if (TransactionIdIsCurrentTransactionId(zinfo->xid))
+			return ZVERSION_CURRENT;
+		else if (TransactionIdIsInProgress(zinfo->xid))
+		{
+			if (locked_only)
+			{
+				snapshot->xmax = zinfo->xid;
+				if (UndoRecPtrIsValid(zinfo->urec_ptr))
+					*snapshot_requests |= SNAPSHOT_REQUESTS_SUBXID;
+			}
+			return ZVERSION_CURRENT;	/* being updated */
+		}
+		else if (TransactionIdDidCommit(zinfo->xid))
+			return ZVERSION_CURRENT;	/* tuple is updated by someone else */
+		else					/* transaction is aborted */
+			return ZVERSION_OLDER;
+	}
+	else
+	{
+		if (TransactionIdIsCurrentTransactionId(zinfo->xid))
+			return ZVERSION_CURRENT;
+		else if (TransactionIdIsInProgress(zinfo->xid))
+		{
+			/* Return any speculative token to caller. */
+			*snapshot_requests |= SNAPSHOT_REQUESTS_SPECTOKEN;
+
+			snapshot->xmin = zinfo->xid;
+			if (UndoRecPtrIsValid(zinfo->urec_ptr))
+				*snapshot_requests |= SNAPSHOT_REQUESTS_SUBXID;
+			return ZVERSION_CURRENT;	/* in insertion by other */
+		}
+		else if (TransactionIdDidCommit(zinfo->xid))
+			return ZVERSION_CURRENT;
+		else
+		{
+			/* inserting transaction aborted */
+			return ZVERSION_NONE;
+		}
+	}
+
+	/* should never get here */
+	pg_unreachable();
+}
+
+/*
+ * ZHeapTupleSatisfiesOldestXmin
+ *	The tuple will be considered visible if it is visible to any open
+ *	transaction.
+ *
+ *	ztuple is an input/output parameter.  The caller must send the palloc'ed
+ *	data.  This function can get a tuple from undo to return in which case it
+ *	will free the memory passed by the caller.
+ *
+ *	xid is an output parameter. It is set to the latest committed/in-progress
+ *	xid that inserted/modified the tuple.
+ *	If the latest transaction for the tuple aborted, we fetch a prior committed
+ *	version of the tuple and return the prior committed xid and status as
+ *	HEAPTUPLE_LIVE.
+ *	If the latest transaction for the tuple aborted and it also inserted
+ *	the tuple, we return the aborted transaction id and status as
+ *	HEAPTUPLE_DEAD. In this case, the caller *should* never mark the
+ *	corresponding item id as dead. Because, when undo action for the same will
+ *	be performed, we need the item pointer.
+ */
+ZHTSV_Result
+ZHeapTupleSatisfiesOldestXmin(ZHeapTuple zhtup, TransactionId OldestXmin,
+							  Buffer buffer, bool resolve_abort_in_progress,
+							  ZHeapTuple *preabort_tuple,
+							  TransactionId *xid, SubTransactionId *subxid)
+{
+	ZHeapTupleHeader tuple = zhtup->t_data;
+	ZHeapTupleTransInfo zinfo;
+	OffsetNumber offnum = ItemPointerGetOffsetNumber(&zhtup->t_self);
+
+	Assert(ItemPointerIsValid(&zhtup->t_self));
+	Assert(zhtup->t_tableOid != InvalidOid);
+
+	/* Get transaction id */
+	ZHeapTupleGetTransInfo(buffer, offnum, &zinfo);
+	*xid = zinfo.xid;
+
+	if (tuple->t_infomask & ZHEAP_DELETED ||
+		tuple->t_infomask & ZHEAP_UPDATED)
+	{
+		/*
+		 * The tuple is deleted and must be all visible if the transaction
+		 * slot is cleared or latest xid that has changed the tuple precedes
+		 * smallest xid that has undo.
+		 */
+		if (zinfo.trans_slot == ZHTUP_SLOT_FROZEN ||
+			FullTransactionIdOlderThanAllUndo(zinfo.epoch_xid))
+			return ZHEAPTUPLE_DEAD;
+
+		if (TransactionIdIsCurrentTransactionId(zinfo.xid))
+			return ZHEAPTUPLE_DELETE_IN_PROGRESS;
+		else if (TransactionIdIsInProgress(zinfo.xid))
+		{
+			/* Get Sub transaction id */
+			if (subxid)
+				ZHeapTupleGetSubXid(buffer, offnum, zinfo.urec_ptr, subxid);
+
+			return ZHEAPTUPLE_DELETE_IN_PROGRESS;
+		}
+		else if (TransactionIdDidCommit(zinfo.xid))
+		{
+			/*
+			 * Deleter committed, but perhaps it was recent enough that some
+			 * open transactions could still see the tuple.
+			 */
+			if (!TransactionIdPrecedes(zinfo.xid, OldestXmin))
+				return ZHEAPTUPLE_RECENTLY_DEAD;
+
+			/* Otherwise, it's dead and removable */
+			return ZHEAPTUPLE_DEAD;
+		}
+		else					/* transaction is aborted */
+		{
+			ZHeapTuple	undo_tuple;
+
+			if (!resolve_abort_in_progress)
+				return ZHEAPTUPLE_ABORT_IN_PROGRESS;
+
+			/*
+			 * For aborted transactions, we need to fetch the tuple from undo
+			 * chain.  It should be OK to use SnapshotSelf semantics because
+			 * we know that the latest transaction is aborted; the previous
+			 * transaction therefore can't be current or in-progress or for
+			 * that matter aborted.  It seems like even SnapshotAny semantics
+			 * would be OK here, but GetTupleFromUndo doesn't know about
+			 * those.
+			 *
+			 * ZBORKED: This code path needs tests.  I was not able to hit it
+			 * in either automated or manual testing.
+			 */
+			GetTupleFromUndo(zinfo.urec_ptr, zhtup, &undo_tuple,
+							 SnapshotSelf,
+							 InvalidCommandId, buffer, offnum, NULL,
+							 zinfo.trans_slot);
+
+			if (preabort_tuple)
+				*preabort_tuple = undo_tuple;
+			else if (undo_tuple != zhtup)
+				pfree(undo_tuple);
+
+			if (undo_tuple != NULL)
+				return ZHEAPTUPLE_LIVE;
+			else
+			{
+				/*
+				 * If the transaction that inserted the tuple got aborted, we
+				 * should return the aborted transaction id.
+				 */
+				return ZHEAPTUPLE_DEAD;
+			}
+		}
+	}
+	else if (tuple->t_infomask & ZHEAP_XID_LOCK_ONLY)
+	{
+		/*
+		 * We can't take any decision if the tuple is marked as locked-only.
+		 * It's possible that inserted transaction took a lock on the tuple
+		 * Later, if it rolled back, we should return HEAPTUPLE_DEAD, or if
+		 * it's still in progress, we should return
+		 * HEAPTUPLE_INSERT_IN_PROGRESS. Similarly, if the inserted
+		 * transaction got committed, we should return HEAPTUPLE_LIVE. The
+		 * subsequent checks already takes care of all these possible
+		 * scenarios, so we don't need any extra checks here.
+		 */
+	}
+
+	/* The tuple is either a newly inserted tuple or is in-place updated. */
+
+	/*
+	 * The tuple must be all visible if the transaction slot is cleared or
+	 * latest xid that has changed the tuple precedes smallest xid that has
+	 * undo.
+	 */
+	if (zinfo.trans_slot == ZHTUP_SLOT_FROZEN ||
+		FullTransactionIdOlderThanAllUndo(zinfo.epoch_xid))
+		return ZHEAPTUPLE_LIVE;
+
+	if (TransactionIdIsCurrentTransactionId(zinfo.xid))
+		return ZHEAPTUPLE_INSERT_IN_PROGRESS;
+	else if (TransactionIdIsInProgress(zinfo.xid))
+	{
+		/* Get Sub transaction id */
+		if (subxid)
+			ZHeapTupleGetSubXid(buffer, offnum, zinfo.urec_ptr, subxid);
+		return ZHEAPTUPLE_INSERT_IN_PROGRESS;	/* in insertion by other */
+	}
+	else if (TransactionIdDidCommit(zinfo.xid))
+		return ZHEAPTUPLE_LIVE;
+	else						/* transaction is aborted */
+	{
+		if (!resolve_abort_in_progress)
+			return ZHEAPTUPLE_ABORT_IN_PROGRESS;
+
+		if (tuple->t_infomask & ZHEAP_INPLACE_UPDATED)
+		{
+			ZHeapTuple	undo_tuple;
+
+			/*
+			 * For aborted transactions, we need to fetch the tuple from undo
+			 * chain.  It should be OK to use SnapshotSelf semantics because
+			 * we know that the latest transaction is aborted; the previous
+			 * transaction therefore can't be current or in-progress or for
+			 * that matter aborted.  It seems like even SnapshotAny semantics
+			 * would be OK here, but GetTupleFromUndo doesn't know about
+			 * those.
+			 *
+			 * ZBORKED: This code path needs tests.  I was not able to hit it
+			 * in either automated or manual testing.
+			 */
+			GetTupleFromUndo(zinfo.urec_ptr, zhtup, &undo_tuple, SnapshotSelf,
+							 InvalidCommandId, buffer, offnum, NULL,
+							 zinfo.trans_slot);
+
+			if (preabort_tuple)
+				*preabort_tuple = undo_tuple;
+			else if (undo_tuple != zhtup)
+				pfree(undo_tuple);
+
+			if (undo_tuple != NULL)
+				return ZHEAPTUPLE_LIVE;
+		}
+
+		/*
+		 * If the transaction that inserted the tuple got aborted, we should
+		 * return the aborted transaction id.
+		 */
+		return ZHEAPTUPLE_DEAD;
+	}
+
+	return ZHEAPTUPLE_LIVE;
+}
+
+/*
+ * This is a helper function for CheckForSerializableConflictOut.
+ *
+ * Check to see whether the tuple has been written to by a concurrent
+ * transaction, either to create it not visible to us, or to delete it
+ * while it is visible to us.  The "visible" bool indicates whether the
+ * tuple is visible to us, while ZHeapTupleSatisfiesOldestXmin checks what
+ * else is going on with it. The caller should have a share lock on the buffer.
+ */
+bool
+ZHeapTupleHasSerializableConflictOut(bool visible, Relation relation,
+									 ItemPointer tid, Buffer buffer,
+									 TransactionId *xid)
+{
+	ZHTSV_Result htsvResult;
+	ItemId		lp;
+	OffsetNumber offnum;
+	Page		dp;
+	ZHeapTuple	tuple;
+	bool		tuple_inplace_updated = false;
+	Snapshot	snap;
+
+	Assert(ItemPointerGetBlockNumber(tid) == BufferGetBlockNumber(buffer));
+	offnum = ItemPointerGetOffsetNumber(tid);
+	dp = BufferGetPage(buffer);
+
+	/* check for bogus TID */
+	Assert(offnum >= FirstOffsetNumber &&
+		   offnum <= PageGetMaxOffsetNumber(dp));
+
+	lp = PageGetItemId(dp, offnum);
+
+	/* check for unused or dead items */
+	Assert(ItemIdIsNormal(lp) || ItemIdIsDeleted(lp));
+
+	/*
+	 * If the record is deleted and pruned, its place in the page might have
+	 * been taken by another of its kind.
+	 */
+	if (ItemIdIsDeleted(lp))
+	{
+		/*
+		 * If the tuple is still visible to us, then we've a conflict.
+		 * Because, the transaction that deleted the tuple already got
+		 * committed.
+		 */
+		if (visible)
+		{
+			snap = GetTransactionSnapshot();
+			ZHeapTupleFetch(relation, buffer, offnum, snap, &tuple, NULL);
+			*xid = ZHeapTupleGetTransXID(tuple, buffer, false);
+			pfree(tuple);
+			return true;
+		}
+		else
+			return false;
+	}
+
+	tuple = zheap_gettuple(relation, buffer, offnum);
+
+	if (tuple->t_data->t_infomask & ZHEAP_INPLACE_UPDATED)
+		tuple_inplace_updated = true;
+
+	htsvResult =
+		ZHeapTupleSatisfiesOldestXmin(tuple, TransactionXmin, buffer, true,
+									  NULL, xid, NULL);
+	pfree(tuple);
+	switch (htsvResult)
+	{
+		case ZHEAPTUPLE_LIVE:
+			if (tuple_inplace_updated)
+			{
+				/*
+				 * If xid is invalid, then we know that slot is frozen and
+				 * tuple will be visible so we can return false.
+				 */
+				if (*xid == InvalidTransactionId)
+				{
+					Assert(visible);
+					return false;
+				}
+
+				/*
+				 * We can't rely on callers visibility information for
+				 * in-place updated tuples because they consider the tuple as
+				 * visible if any version of the tuple is visible whereas we
+				 * want to know the status of current tuple.  In case of
+				 * aborted transactions, it is quite possible that the
+				 * rollback actions aren't yet applied and we need the status
+				 * of last committed transaction;
+				 * ZHeapTupleSatisfiesOldestXmin returns us that information.
+				 */
+				if (XidIsConcurrent(*xid))
+					visible = false;
+			}
+			if (visible)
+				return false;
+			break;
+		case ZHEAPTUPLE_RECENTLY_DEAD:
+			if (!visible)
+				return false;
+			break;
+		case ZHEAPTUPLE_DELETE_IN_PROGRESS:
+			break;
+		case ZHEAPTUPLE_INSERT_IN_PROGRESS:
+			break;
+		case ZHEAPTUPLE_DEAD:
+			return false;
+		default:
+
+			/*
+			 * The only way to get to this default clause is if a new value is
+			 * added to the enum type without adding it to this switch
+			 * statement.  That's a bug, so elog.
+			 */
+			elog(ERROR, "unrecognized return value from ZHeapTupleSatisfiesOldestXmin: %u", htsvResult);
+
+			/*
+			 * In spite of having all enum values covered and calling elog on
+			 * this default, some compilers think this is a code path which
+			 * allows xid to be used below without initialization. Silence
+			 * that warning.
+			 */
+			*xid = InvalidTransactionId;
+	}
+	Assert(TransactionIdIsValid(*xid));
+	Assert(TransactionIdFollowsOrEquals(*xid, TransactionXmin));
+
+	/*
+	 * Find top level xid.  Bail out if xid is too early to be a conflict, or
+	 * if it's our own xid.
+	 */
+	if (TransactionIdEquals(*xid, GetTopTransactionIdIfAny()))
+		return false;
+	if (TransactionIdPrecedes(*xid, TransactionXmin))
+		return false;
+	if (TransactionIdEquals(*xid, GetTopTransactionIdIfAny()))
+		return false;
+
+	return true;
+}
diff --git a/src/backend/access/zheap/zheapamxlog.c b/src/backend/access/zheap/zheapamxlog.c
new file mode 100644
index 0000000..0c87778
--- /dev/null
+++ b/src/backend/access/zheap/zheapamxlog.c
@@ -0,0 +1,2194 @@
+/*-------------------------------------------------------------------------
+ *
+ * zheapamxlog.c
+ *	  WAL replay logic for zheap.
+ *
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/zheap/zheapamxlog.c
+ *
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include "miscadmin.h"
+
+#include "access/bufmask.h"
+#include "access/tpd.h"
+#include "access/visibilitymap.h"
+#include "access/xlog.h"
+#include "access/xlogutils.h"
+#include "access/zheap.h"
+#include "access/zheapam_xlog.h"
+#include "storage/standby.h"
+#include "storage/freespace.h"
+
+static void
+zheap_xlog_insert(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	xl_undo_header *xlundohdr;
+	xl_zheap_insert *xlrec = (xl_zheap_insert *) XLogRecGetData(record);
+	Buffer		buffer;
+	Page		page;
+	union
+	{
+		ZHeapTupleHeaderData hdr;
+		char		data[MaxZHeapTupleSize];
+	}			tbuf;
+	ZHeapTupleHeader zhtup;
+	UnpackedUndoRecord undorecord;
+	UndoRecPtr	urecptr = InvalidUndoRecPtr;
+	xl_zheap_header xlhdr;
+	uint32		newlen;
+	RelFileNode target_node;
+	BlockNumber blkno;
+	ItemPointerData target_tid;
+	XLogRedoAction action;
+	int		   *tpd_trans_slot_id = NULL;
+	FullTransactionId fxid = XLogRecGetFullXid(record);
+	bool		skip_undo;
+	ZHeapPrepareUndoInfo zh_undo_info;
+
+	/*
+	 * We can skip inserting undo records if the tuples are to be marked as
+	 * frozen.
+	 */
+	skip_undo = (xlrec->flags & XLZ_INSERT_IS_FROZEN);
+
+	if (!skip_undo)
+	{
+		xlundohdr = (xl_undo_header *) ((char *) xlrec + SizeOfZHeapInsert);
+
+		if (xlrec->flags & XLZ_INSERT_CONTAINS_TPD_SLOT)
+			tpd_trans_slot_id = (int *) ((char *) xlundohdr + SizeOfUndoHeader);
+	}
+	else if (xlrec->flags & XLZ_INSERT_CONTAINS_TPD_SLOT)
+		tpd_trans_slot_id = (int *) ((char *) xlrec + SizeOfZHeapInsert);
+
+	XLogRecGetBlockTag(record, 0, NULL, &target_node, NULL, &blkno);
+	ItemPointerSetBlockNumber(&target_tid, blkno);
+	ItemPointerSetOffsetNumber(&target_tid, xlrec->offnum);
+
+	/*
+	 * The visibility map may need to be fixed even if the heap page is
+	 * already up-to-date.
+	 */
+	if (xlrec->flags & XLZ_INSERT_ALL_VISIBLE_CLEARED)
+	{
+		Relation	reln = CreateFakeRelcacheEntry(target_node);
+		Buffer		vmbuffer = InvalidBuffer;
+
+		visibilitymap_pin(reln, blkno, &vmbuffer);
+		visibilitymap_clear(reln, blkno, vmbuffer, VISIBILITYMAP_VALID_BITS);
+		ReleaseBuffer(vmbuffer);
+		FreeFakeRelcacheEntry(reln);
+	}
+
+	if (!skip_undo)
+	{
+		/*
+		 * For speculative insertions, we store the dummy speculative token in
+		 * the undorecord so that, the size of undorecord in DO function
+		 * matches with the size of undorecord in REDO function. This ensures
+		 * that, for INSERT ... ON CONFLICT statements, the assert condition
+		 * used later in this function to ensure that the undo pointer in DO
+		 * and REDO function remains the same is true. However, it might not
+		 * be useful in the REDO function as it is just required in the master
+		 * node to detect conflicts for insert ... on conflict.
+		 *
+		 * XXX - Once we have undo consistency checker that we can remove the
+		 * assertion as well as the dummy speculative token.
+		 */
+		uint32		dummy_specToken = 1;
+
+		zh_undo_info.reloid = xlundohdr->reloid;
+		zh_undo_info.blkno = ItemPointerGetBlockNumber(&target_tid);
+		zh_undo_info.offnum = ItemPointerGetOffsetNumber(&target_tid);
+		zh_undo_info.prev_urecptr = xlundohdr->blkprev;
+		zh_undo_info.fxid = fxid;
+		zh_undo_info.cid = FirstCommandId;
+		zh_undo_info.undo_persistence = UNDO_PERMANENT;
+
+		/* prepare an undo record */
+		urecptr = zheap_prepare_undoinsert(&zh_undo_info,
+										   dummy_specToken,
+										   xlrec->flags & XLZ_INSERT_IS_SPECULATIVE ? true : false,
+										   &undorecord, record);
+		InsertPreparedUndo(&zh_undo_info.context);
+
+		/*
+		 * undo should be inserted at same location as it was during the
+		 * actual insert (DO operation).
+		 */
+
+		Assert(urecptr == xlundohdr->urec_ptr);
+	}
+
+	/*
+	 * If we inserted the first and only tuple on the page, re-initialize the
+	 * page from scratch.
+	 */
+	if (XLogRecGetInfo(record) & XLOG_ZHEAP_INIT_PAGE)
+	{
+		/* It has asked for page init, insert should not have tpd slot. */
+		Assert(!(xlrec->flags & XLZ_INSERT_CONTAINS_TPD_SLOT));
+		buffer = XLogInitBufferForRedo(record, 0);
+		page = BufferGetPage(buffer);
+		ZheapInitPage(page, BufferGetPageSize(buffer));
+		action = BLK_NEEDS_REDO;
+	}
+	else
+		action = XLogReadBufferForRedo(record, 0, &buffer);
+	if (action == BLK_NEEDS_REDO)
+	{
+		Size		datalen;
+		char	   *data;
+		int			trans_slot_id;
+
+		page = BufferGetPage(buffer);
+
+		if (PageGetMaxOffsetNumber(page) + 1 < xlrec->offnum)
+			elog(PANIC, "invalid max offset number");
+
+		data = XLogRecGetBlockData(record, 0, &datalen);
+
+		newlen = datalen - SizeOfZHeapHeader;
+
+		/*
+		 * For zheap, in case of "SELECT INTO" statement, length of data will
+		 * be equal to the zheap header size, but in heap, it will be always
+		 * greater than heap header size, because in heap, we have one byte
+		 * alignment in case of zero byte data length.
+		 */
+		Assert(datalen >= SizeOfZHeapHeader && newlen <= MaxZHeapTupleSize);
+		memcpy((char *) &xlhdr, data, SizeOfZHeapHeader);
+		data += SizeOfZHeapHeader;
+
+		zhtup = &tbuf.hdr;
+		MemSet((char *) zhtup, 0, SizeofZHeapTupleHeader);
+		/* PG73FORMAT: get bitmap [+ padding] [+ oid] + data */
+		memcpy((char *) zhtup + SizeofZHeapTupleHeader,
+			   data,
+			   newlen);
+		newlen += SizeofZHeapTupleHeader;
+		zhtup->t_infomask2 = xlhdr.t_infomask2;
+		zhtup->t_infomask = xlhdr.t_infomask;
+		zhtup->t_hoff = xlhdr.t_hoff;
+
+		if (ZPageAddItem(buffer, NULL, (Item) zhtup, newlen, xlrec->offnum,
+						 true, true, true) == InvalidOffsetNumber)
+			elog(PANIC, "failed to add tuple");
+
+		if (!skip_undo)
+		{
+			if (tpd_trans_slot_id)
+				trans_slot_id = *tpd_trans_slot_id;
+			else
+				trans_slot_id = ZHeapTupleHeaderGetXactSlot(zhtup);
+
+			PageSetUNDO(undorecord, buffer, trans_slot_id, false,
+						fxid, urecptr, NULL, 0);
+		}
+
+		PageSetLSN(page, lsn);
+
+		MarkBufferDirty(buffer);
+	}
+
+	/* replay the record for tpd buffer */
+	if (XLogRecHasBlockRef(record, 1))
+	{
+		/* We can't have a valid transaction slot when we are skipping undo. */
+		Assert(!skip_undo);
+
+		/*
+		 * We need to replay the record for TPD only when this record contains
+		 * slot from TPD.
+		 */
+		Assert(xlrec->flags & XLZ_INSERT_CONTAINS_TPD_SLOT);
+		action = XLogReadTPDBuffer(record, 1);
+		if (action == BLK_NEEDS_REDO)
+		{
+			TPDPageSetUndo(buffer,
+						   *tpd_trans_slot_id,
+						   true,
+						   fxid,
+						   urecptr,
+						   &undorecord.uur_offset,
+						   1);
+			TPDPageSetLSN(BufferGetPage(buffer), lsn);
+		}
+	}
+
+	if (BufferIsValid(buffer))
+		UnlockReleaseBuffer(buffer);
+	FinishUndoRecordInsert(&zh_undo_info.context);
+	UnlockReleaseTPDBuffers();
+}
+
+static void
+zheap_xlog_delete(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	xl_undo_header *xlundohdr = (xl_undo_header *) XLogRecGetData(record);
+	Size		recordlen = XLogRecGetDataLen(record);
+	xl_zheap_delete *xlrec;
+	Buffer		buffer;
+	Page		page;
+	ZHeapTupleData zheaptup;
+	ZHeapPrepareUndoInfo zh_undo_info;
+	UnpackedUndoRecord undorecord;
+	UndoRecPtr	urecptr;
+	RelFileNode target_node;
+	BlockNumber blkno;
+	ItemPointerData target_tid;
+	XLogRedoAction action;
+	Relation	reln;
+	ItemId		lp = NULL;
+	FullTransactionId fxid = XLogRecGetFullXid(record);
+	SubTransactionId dummy_subXactToken = InvalidSubTransactionId;
+	int		   *tpd_trans_slot_id = NULL;
+
+	xlrec = (xl_zheap_delete *) ((char *) xlundohdr + SizeOfUndoHeader);
+	if (xlrec->flags & XLZ_DELETE_CONTAINS_TPD_SLOT)
+		tpd_trans_slot_id = (int *) ((char *) xlrec + SizeOfZHeapDelete);
+
+	XLogRecGetBlockTag(record, 0, NULL, &target_node, NULL, &blkno);
+	ItemPointerSetBlockNumber(&target_tid, blkno);
+	ItemPointerSetOffsetNumber(&target_tid, xlrec->offnum);
+
+	reln = CreateFakeRelcacheEntry(target_node);
+
+	/*
+	 * The visibility map may need to be fixed even if the heap page is
+	 * already up-to-date.
+	 */
+	if (xlrec->flags & XLZ_DELETE_ALL_VISIBLE_CLEARED)
+	{
+		Buffer		vmbuffer = InvalidBuffer;
+
+		visibilitymap_pin(reln, blkno, &vmbuffer);
+		visibilitymap_clear(reln, blkno, vmbuffer, VISIBILITYMAP_VALID_BITS);
+		ReleaseBuffer(vmbuffer);
+	}
+
+	action = XLogReadBufferForRedo(record, 0, &buffer);
+
+	page = BufferGetPage(buffer);
+
+	if (PageGetMaxOffsetNumber(page) >= xlrec->offnum)
+		lp = PageGetItemId(page, xlrec->offnum);
+
+	if (PageGetMaxOffsetNumber(page) < xlrec->offnum || !ItemIdIsNormal(lp))
+		elog(PANIC, "invalid lp");
+
+	zheaptup.t_tableOid = RelationGetRelid(reln);
+	zheaptup.t_data = (ZHeapTupleHeader) PageGetItem(page, lp);
+	zheaptup.t_len = ItemIdGetLength(lp);
+	zheaptup.t_self = target_tid;
+
+	/*
+	 * If the WAL stream contains undo tuple, then replace it with the
+	 * explicitly stored tuple.
+	 */
+	if (xlrec->flags & XLZ_HAS_DELETE_UNDOTUPLE)
+	{
+		char	   *data;
+		xl_zheap_header xlhdr;
+		union
+		{
+			ZHeapTupleHeaderData hdr;
+			char		data[MaxZHeapTupleSize];
+		}			tbuf;
+		ZHeapTupleHeader zhtup;
+		Size		datalen;
+
+		if (xlrec->flags & XLZ_DELETE_CONTAINS_TPD_SLOT)
+		{
+			data = (char *) xlrec + SizeOfZHeapDelete +
+				sizeof(*tpd_trans_slot_id);
+			datalen = recordlen - SizeOfUndoHeader - SizeOfZHeapDelete -
+				SizeOfZHeapHeader - sizeof(*tpd_trans_slot_id);
+		}
+		else
+		{
+			data = (char *) xlrec + SizeOfZHeapDelete;
+			datalen = recordlen - SizeOfUndoHeader - SizeOfZHeapDelete -
+				SizeOfZHeapHeader;
+		}
+		memcpy((char *) &xlhdr, data, SizeOfZHeapHeader);
+		data += SizeOfZHeapHeader;
+
+		zhtup = &tbuf.hdr;
+		MemSet((char *) zhtup, 0, SizeofZHeapTupleHeader);
+		/* PG73FORMAT: get bitmap [+ padding] [+ oid] + data */
+		memcpy((char *) zhtup + SizeofZHeapTupleHeader,
+			   data,
+			   datalen);
+		datalen += SizeofZHeapTupleHeader;
+		zhtup->t_infomask2 = xlhdr.t_infomask2;
+		zhtup->t_infomask = xlhdr.t_infomask;
+		zhtup->t_hoff = xlhdr.t_hoff;
+
+		zheaptup.t_data = zhtup;
+		zheaptup.t_len = datalen;
+	}
+
+	/*
+	 * For sub-transactions, we store the dummy contains subxact token in the
+	 * undorecord so that, the size of undorecord in DO function matches with
+	 * the size of undorecord in REDO function. This ensures that, for
+	 * sub-transactions, the assert condition used later in this function to
+	 * ensure that the undo pointer in DO and REDO function remains the same
+	 * is true.
+	 */
+	if (xlrec->flags & XLZ_DELETE_CONTAINS_SUBXACT)
+		dummy_subXactToken = 1;
+
+	/* prepare an undo record */
+	zh_undo_info.reloid = xlundohdr->reloid;
+	zh_undo_info.blkno = ItemPointerGetBlockNumber(&target_tid);
+	zh_undo_info.offnum = ItemPointerGetOffsetNumber(&target_tid);
+	zh_undo_info.prev_urecptr = xlundohdr->blkprev;
+	zh_undo_info.fxid = fxid;
+	zh_undo_info.cid = FirstCommandId;
+	zh_undo_info.undo_persistence = UNDO_PERMANENT;
+	urecptr = zheap_prepare_undodelete(&zh_undo_info,
+									   &zheaptup,
+									   xlrec->prevxid,
+									   tpd_trans_slot_id ? *tpd_trans_slot_id : InvalidXactSlotId,
+									   dummy_subXactToken,
+									   &undorecord, record);
+	InsertPreparedUndo(&zh_undo_info.context);
+
+	/*
+	 * undo should be inserted at same location as it was during the actual
+	 * insert (DO operation).
+	 */
+	Assert(urecptr == xlundohdr->urec_ptr);
+
+	if (action == BLK_NEEDS_REDO)
+	{
+		zheaptup.t_data = (ZHeapTupleHeader) PageGetItem(page, lp);
+		zheaptup.t_len = ItemIdGetLength(lp);
+		ZHeapTupleHeaderSetXactSlot(zheaptup.t_data, xlrec->trans_slot_id);
+		zheaptup.t_data->t_infomask &= ~ZHEAP_VIS_STATUS_MASK;
+		zheaptup.t_data->t_infomask = xlrec->infomask;
+
+		if (xlrec->flags & XLZ_DELETE_IS_PARTITION_MOVE)
+			ZHeapTupleHeaderSetMovedPartitions(zheaptup.t_data);
+
+		PageSetUNDO(undorecord, buffer, xlrec->trans_slot_id,
+					false, fxid, urecptr, NULL, 0);
+
+		/* Mark the page as a candidate for pruning */
+		ZPageSetPrunable(page, XLogRecGetXid(record));
+
+		PageSetLSN(page, lsn);
+		MarkBufferDirty(buffer);
+	}
+	/* replay the record for tpd buffer */
+	if (XLogRecHasBlockRef(record, 1))
+	{
+		action = XLogReadTPDBuffer(record, 1);
+		if (action == BLK_NEEDS_REDO)
+		{
+			TPDPageSetUndo(buffer,
+						   xlrec->trans_slot_id,
+						   true,
+						   fxid,
+						   urecptr,
+						   &undorecord.uur_offset,
+						   1);
+			TPDPageSetLSN(page, lsn);
+		}
+	}
+
+	if (BufferIsValid(buffer))
+		UnlockReleaseBuffer(buffer);
+
+	/* be tidy */
+	pfree(undorecord.uur_tuple.data);
+	if (undorecord.uur_payload.len > 0)
+		pfree(undorecord.uur_payload.data);
+
+	FinishUndoRecordInsert(&zh_undo_info.context);
+	UnlockReleaseTPDBuffers();
+	FreeFakeRelcacheEntry(reln);
+}
+
+static void
+zheap_xlog_update(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	xl_undo_header *xlundohdr;
+	xl_undo_header *xlnewundohdr = NULL;
+	xl_zheap_header xlhdr;
+	Size		recordlen;
+	Size		freespace = 0;
+	xl_zheap_update *xlrec;
+	Buffer		oldbuffer,
+				newbuffer;
+	Page		oldpage,
+				newpage;
+	ZHeapTupleData oldtup;
+	ZHeapTupleHeader newtup;
+	union
+	{
+		ZHeapTupleHeaderData hdr;
+		char		data[MaxZHeapTupleSize];
+	}			tbuf;
+	UnpackedUndoRecord undorecord,
+				newundorecord;
+	UndoRecPtr	urecptr = InvalidUndoRecPtr;
+	UndoRecPtr	newurecptr = InvalidUndoRecPtr;
+	RelFileNode rnode;
+	BlockNumber oldblk,
+				newblk;
+	ItemPointerData oldtid,
+				newtid;
+	XLogRedoAction oldaction,
+				newaction;
+	Relation	reln;
+	ItemId		lp = NULL;
+	FullTransactionId fxid = XLogRecGetFullXid(record);
+	int		   *old_tup_trans_slot_id = NULL;
+	int		   *new_trans_slot_id = NULL;
+	int			trans_slot_id;
+	bool		inplace_update;
+	ZHeapPrepareUndoInfo gen_undo_info;
+	ZHeapPrepareUpdateUndoInfo zh_up_undo_info;
+
+	xlundohdr = (xl_undo_header *) XLogRecGetData(record);
+	xlrec = (xl_zheap_update *) ((char *) xlundohdr + SizeOfUndoHeader);
+	recordlen = XLogRecGetDataLen(record);
+
+	if (xlrec->flags & XLZ_UPDATE_OLD_CONTAINS_TPD_SLOT)
+	{
+		old_tup_trans_slot_id = (int *) ((char *) xlrec + SizeOfZHeapUpdate);
+	}
+	if (xlrec->flags & XLZ_NON_INPLACE_UPDATE)
+	{
+		inplace_update = false;
+		if (old_tup_trans_slot_id)
+			xlnewundohdr = (xl_undo_header *) ((char *) old_tup_trans_slot_id + sizeof(*old_tup_trans_slot_id));
+		else
+			xlnewundohdr = (xl_undo_header *) ((char *) xlrec + SizeOfZHeapUpdate);
+
+		if (xlrec->flags & XLZ_UPDATE_NEW_CONTAINS_TPD_SLOT)
+			new_trans_slot_id = (int *) ((char *) xlnewundohdr + SizeOfUndoHeader);
+	}
+	else
+	{
+		inplace_update = true;
+	}
+
+	XLogRecGetBlockTag(record, 0, NULL, &rnode, NULL, &newblk);
+	if (XLogRecGetBlockTag(record, 1, NULL, NULL, NULL, &oldblk))
+	{
+		/* inplace updates are never done across pages */
+		Assert(!inplace_update);
+	}
+	else
+		oldblk = newblk;
+
+	ItemPointerSet(&oldtid, oldblk, xlrec->old_offnum);
+	ItemPointerSet(&newtid, newblk, xlrec->new_offnum);
+
+	reln = CreateFakeRelcacheEntry(rnode);
+
+	/*
+	 * The visibility map may need to be fixed even if the zheap page is
+	 * already up-to-date.
+	 */
+	if (xlrec->flags & XLZ_UPDATE_OLD_ALL_VISIBLE_CLEARED)
+	{
+		Buffer		vmbuffer = InvalidBuffer;
+
+		visibilitymap_pin(reln, oldblk, &vmbuffer);
+		visibilitymap_clear(reln, oldblk, vmbuffer, VISIBILITYMAP_VALID_BITS);
+		ReleaseBuffer(vmbuffer);
+	}
+
+	oldaction = XLogReadBufferForRedo(record, (oldblk == newblk) ? 0 : 1, &oldbuffer);
+
+	oldpage = BufferGetPage(oldbuffer);
+
+	if (PageGetMaxOffsetNumber(oldpage) >= xlrec->old_offnum)
+		lp = PageGetItemId(oldpage, xlrec->old_offnum);
+
+	if (PageGetMaxOffsetNumber(oldpage) < xlrec->old_offnum || !ItemIdIsNormal(lp))
+		elog(PANIC, "invalid lp");
+
+	oldtup.t_tableOid = RelationGetRelid(reln);
+	oldtup.t_data = (ZHeapTupleHeader) PageGetItem(oldpage, lp);
+	oldtup.t_len = ItemIdGetLength(lp);
+	oldtup.t_self = oldtid;
+
+	/*
+	 * If the WAL stream contains undo tuple, then replace it with the
+	 * explicitly stored tuple.
+	 */
+	if (xlrec->flags & XLZ_HAS_UPDATE_UNDOTUPLE)
+	{
+		ZHeapTupleHeader zhtup;
+		Size		datalen;
+		char	   *data;
+
+		/* There is an additional undo header for non-inplace-update. */
+		if (inplace_update)
+		{
+			if (old_tup_trans_slot_id)
+			{
+				data = (char *) ((char *) old_tup_trans_slot_id + sizeof(*old_tup_trans_slot_id));
+				datalen = recordlen - SizeOfUndoHeader - SizeOfZHeapUpdate -
+					sizeof(*old_tup_trans_slot_id) - SizeOfZHeapHeader;
+			}
+			else
+			{
+				data = (char *) xlrec + SizeOfZHeapUpdate;
+				datalen = recordlen - SizeOfUndoHeader - SizeOfZHeapUpdate - SizeOfZHeapHeader;
+			}
+		}
+		else
+		{
+			if (old_tup_trans_slot_id && new_trans_slot_id)
+			{
+				datalen = recordlen - (2 * SizeOfUndoHeader) - SizeOfZHeapUpdate -
+					sizeof(*old_tup_trans_slot_id) - sizeof(*new_trans_slot_id) -
+					SizeOfZHeapHeader;
+				data = (char *) ((char *) new_trans_slot_id + sizeof(*new_trans_slot_id));
+			}
+			else if (new_trans_slot_id)
+			{
+				datalen = recordlen - (2 * SizeOfUndoHeader) - SizeOfZHeapUpdate -
+					sizeof(*new_trans_slot_id) - SizeOfZHeapHeader;
+				data = (char *) ((char *) new_trans_slot_id + sizeof(*new_trans_slot_id));
+			}
+			else if (old_tup_trans_slot_id)
+			{
+				datalen = recordlen - (2 * SizeOfUndoHeader) - SizeOfZHeapUpdate -
+					sizeof(*old_tup_trans_slot_id) - SizeOfZHeapHeader;
+				data = (char *) xlnewundohdr + SizeOfUndoHeader;
+			}
+			else
+			{
+				datalen = recordlen - (2 * SizeOfUndoHeader) - SizeOfZHeapUpdate -
+					SizeOfZHeapHeader;
+				data = (char *) xlnewundohdr + SizeOfUndoHeader;
+			}
+		}
+
+		memcpy((char *) &xlhdr, data, SizeOfZHeapHeader);
+		data += SizeOfZHeapHeader;
+
+		zhtup = &tbuf.hdr;
+		MemSet((char *) zhtup, 0, SizeofZHeapTupleHeader);
+		/* PG73FORMAT: get bitmap [+ padding] [+ oid] + data */
+		memcpy((char *) zhtup + SizeofZHeapTupleHeader,
+			   data,
+			   datalen);
+		datalen += SizeofZHeapTupleHeader;
+		zhtup->t_infomask2 = xlhdr.t_infomask2;
+		zhtup->t_infomask = xlhdr.t_infomask;
+		zhtup->t_hoff = xlhdr.t_hoff;
+
+		oldtup.t_data = zhtup;
+		oldtup.t_len = datalen;
+	}
+
+	/* prepare an undo record */
+	gen_undo_info.reloid = xlundohdr->reloid;
+	gen_undo_info.blkno = ItemPointerGetBlockNumber(&oldtid);
+	gen_undo_info.offnum = ItemPointerGetOffsetNumber(&oldtid);
+	gen_undo_info.prev_urecptr = xlundohdr->blkprev;
+	gen_undo_info.fxid = fxid;
+	gen_undo_info.cid = FirstCommandId;
+	gen_undo_info.undo_persistence = UNDO_PERMANENT;
+
+	zh_up_undo_info.gen_info = &gen_undo_info;
+	zh_up_undo_info.inplace_update = inplace_update;
+	zh_up_undo_info.same_buf = false;
+	zh_up_undo_info.prevxid = xlrec->prevxid;
+	zh_up_undo_info.old_undorec = &undorecord;
+	zh_up_undo_info.new_undorec = &newundorecord;
+	zh_up_undo_info.new_block = ItemPointerGetBlockNumber(&newtid);
+	zh_up_undo_info.hasSubXactLock = xlrec->flags & XLZ_UPDATE_CONTAINS_SUBXACT;
+	zh_up_undo_info.recovery_tid = &newtid;
+	zh_up_undo_info.new_trans_slot_id = (new_trans_slot_id) ?
+		*new_trans_slot_id : InvalidXactSlotId;
+	zh_up_undo_info.tup_trans_slot_id = (old_tup_trans_slot_id) ?
+		*old_tup_trans_slot_id : InvalidXactSlotId;
+	zh_up_undo_info.new_prev_urecptr = (xlnewundohdr) ?
+		(xlnewundohdr->blkprev) : InvalidUndoRecPtr;
+
+	urecptr = zheap_prepare_undoupdate(&zh_up_undo_info, &oldtup, record,
+									   &newurecptr);
+
+	/*
+	 * undo should be inserted at same location as it was during the actual
+	 * insert (DO operation).
+	 */
+	Assert(urecptr == xlundohdr->urec_ptr);
+	Assert(inplace_update || (newurecptr == xlnewundohdr->urec_ptr));
+
+	InsertPreparedUndo(&gen_undo_info.context);
+
+	/* Ensure old tuple points to the tuple in page. */
+	oldtup.t_data = (ZHeapTupleHeader) PageGetItem(oldpage, lp);
+	oldtup.t_len = ItemIdGetLength(lp);
+
+	/* First deal with old tuple */
+	if (oldaction == BLK_NEEDS_REDO)
+	{
+		oldtup.t_data->t_infomask &= ~ZHEAP_VIS_STATUS_MASK;
+		oldtup.t_data->t_infomask = xlrec->old_infomask;
+		ZHeapTupleHeaderSetXactSlot(oldtup.t_data, xlrec->old_trans_slot_id);
+
+		if (oldblk != newblk)
+			PageSetUNDO(undorecord, oldbuffer, xlrec->old_trans_slot_id,
+						false, fxid, urecptr, NULL, 0);
+
+		/* Mark the page as a candidate for pruning */
+		if (!inplace_update)
+			ZPageSetPrunable(oldpage, XLogRecGetXid(record));
+
+		PageSetLSN(oldpage, lsn);
+		MarkBufferDirty(oldbuffer);
+	}
+
+	/*
+	 * Read the page the new tuple goes into, if different from old.
+	 */
+	if (oldblk == newblk)
+	{
+		newbuffer = oldbuffer;
+		newaction = oldaction;
+	}
+	else if (XLogRecGetInfo(record) & XLOG_ZHEAP_INIT_PAGE)
+	{
+		newbuffer = XLogInitBufferForRedo(record, 0);
+		newpage = (Page) BufferGetPage(newbuffer);
+		ZheapInitPage(newpage, BufferGetPageSize(newbuffer));
+		newaction = BLK_NEEDS_REDO;
+	}
+	else
+		newaction = XLogReadBufferForRedo(record, 0, &newbuffer);
+
+	newpage = BufferGetPage(newbuffer);
+
+	/*
+	 * The visibility map may need to be fixed even if the zheap page is
+	 * already up-to-date.
+	 */
+	if (xlrec->flags & XLZ_UPDATE_NEW_ALL_VISIBLE_CLEARED)
+	{
+		Buffer		vmbuffer = InvalidBuffer;
+
+		visibilitymap_pin(reln, newblk, &vmbuffer);
+		visibilitymap_clear(reln, newblk, vmbuffer, VISIBILITYMAP_VALID_BITS);
+		ReleaseBuffer(vmbuffer);
+	}
+
+	if (newaction == BLK_NEEDS_REDO)
+	{
+		uint16		prefixlen = 0,
+					suffixlen = 0;
+		char	   *newp;
+		char	   *recdata;
+		char	   *recdata_end;
+		Size		datalen;
+		Size		tuplen;
+		uint32		newlen;
+
+		if (PageGetMaxOffsetNumber(newpage) + 1 < xlrec->new_offnum)
+			elog(PANIC, "invalid max offset number");
+
+		recdata = XLogRecGetBlockData(record, 0, &datalen);
+		recdata_end = recdata + datalen;
+
+		if (xlrec->flags & XLZ_UPDATE_PREFIX_FROM_OLD)
+		{
+			Assert(newblk == oldblk);
+			memcpy(&prefixlen, recdata, sizeof(uint16));
+			recdata += sizeof(uint16);
+		}
+		if (xlrec->flags & XLZ_UPDATE_SUFFIX_FROM_OLD)
+		{
+			Assert(newblk == oldblk);
+			memcpy(&suffixlen, recdata, sizeof(uint16));
+			recdata += sizeof(uint16);
+		}
+
+		memcpy((char *) &xlhdr, recdata, SizeOfZHeapHeader);
+		recdata += SizeOfZHeapHeader;
+
+		tuplen = recdata_end - recdata;
+		Assert(tuplen <= MaxZHeapTupleSize);
+
+		newtup = &tbuf.hdr;
+		MemSet((char *) newtup, 0, SizeofZHeapTupleHeader);
+
+		/*
+		 * Reconstruct the new tuple using the prefix and/or suffix from the
+		 * old tuple, and the data stored in the WAL record.
+		 */
+		newp = (char *) newtup + SizeofZHeapTupleHeader;
+		if (prefixlen > 0)
+		{
+			int			len;
+
+			/* copy bitmap [+ padding] [+ oid] from WAL record */
+			len = xlhdr.t_hoff - SizeofZHeapTupleHeader;
+			memcpy(newp, recdata, len);
+			recdata += len;
+			newp += len;
+
+			/* copy prefix from old tuple */
+			memcpy(newp, (char *) oldtup.t_data + oldtup.t_data->t_hoff, prefixlen);
+			newp += prefixlen;
+
+			/* copy new tuple data from WAL record */
+			len = tuplen - (xlhdr.t_hoff - SizeofZHeapTupleHeader);
+			memcpy(newp, recdata, len);
+			recdata += len;
+			newp += len;
+		}
+		else
+		{
+			/*
+			 * copy bitmap [+ padding] [+ oid] + data from record, all in one
+			 * go
+			 */
+			memcpy(newp, recdata, tuplen);
+			recdata += tuplen;
+			newp += tuplen;
+		}
+		Assert(recdata == recdata_end);
+
+		/* copy suffix from old tuple */
+		if (suffixlen > 0)
+			memcpy(newp, (char *) oldtup.t_data + oldtup.t_len - suffixlen, suffixlen);
+
+		newlen = SizeofZHeapTupleHeader + tuplen + prefixlen + suffixlen;
+		newtup->t_infomask2 = xlhdr.t_infomask2;
+		newtup->t_infomask = xlhdr.t_infomask;
+		newtup->t_hoff = xlhdr.t_hoff;
+		if (new_trans_slot_id)
+			trans_slot_id = *new_trans_slot_id;
+		else
+			trans_slot_id = ZHeapTupleHeaderGetXactSlot(newtup);
+
+		if (inplace_update)
+		{
+			/*
+			 * For inplace updates, we copy the entire data portion including
+			 * the tuple header.
+			 */
+			ItemIdChangeLen(lp, newlen);
+			memcpy((char *) oldtup.t_data, (char *) newtup, newlen);
+
+			if (newlen < oldtup.t_len)
+			{
+				/* new tuple is smaller, a prunable candidate */
+				Assert(oldpage == newpage);
+				ZPageSetPrunable(newpage, XLogRecGetXid(record));
+			}
+
+			PageSetUNDO(undorecord, newbuffer, xlrec->old_trans_slot_id,
+						false, fxid, urecptr, NULL, 0);
+		}
+		else
+		{
+			if (ZPageAddItem(newbuffer, NULL, (Item) newtup, newlen, xlrec->new_offnum,
+							 true, true, true) == InvalidOffsetNumber)
+				elog(PANIC, "failed to add tuple");
+			PageSetUNDO((newbuffer == oldbuffer) ? undorecord : newundorecord,
+						newbuffer, trans_slot_id, false, fxid,
+						newurecptr, NULL, 0);
+		}
+
+		freespace = PageGetHeapFreeSpace(newpage);	/* needed to update FSM
+													 * below */
+
+		PageSetLSN(newpage, lsn);
+		MarkBufferDirty(newbuffer);
+	}
+
+	/* replay the record for tpd buffer corresponding to old buffer */
+	if (XLogRecHasBlockRef(record, 2))
+	{
+		if (XLogReadTPDBuffer(record, 2) == BLK_NEEDS_REDO)
+		{
+			OffsetNumber usedoff[2];
+			int			ucnt;
+
+			if (!inplace_update && newbuffer == oldbuffer)
+			{
+				usedoff[0] = undorecord.uur_offset;
+				usedoff[1] = newundorecord.uur_offset;
+				ucnt = 2;
+			}
+			else
+			{
+				usedoff[0] = undorecord.uur_offset;
+				ucnt = 1;
+			}
+			if (xlrec->old_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+			{
+				if (inplace_update)
+				{
+					TPDPageSetUndo(oldbuffer,
+								   xlrec->old_trans_slot_id,
+								   true,
+								   fxid,
+								   urecptr,
+								   usedoff,
+								   ucnt);
+				}
+				else
+				{
+					TPDPageSetUndo(oldbuffer,
+								   xlrec->old_trans_slot_id,
+								   true,
+								   fxid,
+								   (oldblk == newblk) ? newurecptr : urecptr,
+								   usedoff,
+								   ucnt);
+				}
+				TPDPageSetLSN(oldpage, lsn);
+			}
+		}
+	}
+
+	/* replay the record for tpd buffer corresponding to new buffer */
+	if (XLogRecHasBlockRef(record, 3))
+	{
+		if (XLogReadTPDBuffer(record, 3) == BLK_NEEDS_REDO)
+		{
+			TPDPageSetUndo(newbuffer,
+						   *new_trans_slot_id,
+						   true,
+						   fxid,
+						   newurecptr,
+						   &newundorecord.uur_offset,
+						   1);
+			TPDPageSetLSN(newpage, lsn);
+		}
+	}
+	else if (new_trans_slot_id && (*new_trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS))
+	{
+		TPDPageSetUndo(newbuffer,
+					   *new_trans_slot_id,
+					   true,
+					   fxid,
+					   newurecptr,
+					   &newundorecord.uur_offset,
+					   1);
+		TPDPageSetLSN(newpage, lsn);
+	}
+	if (BufferIsValid(newbuffer) && newbuffer != oldbuffer)
+		UnlockReleaseBuffer(newbuffer);
+	if (BufferIsValid(oldbuffer))
+		UnlockReleaseBuffer(oldbuffer);
+
+	/* be tidy */
+	pfree(undorecord.uur_tuple.data);
+	if (undorecord.uur_payload.len > 0)
+		pfree(undorecord.uur_payload.data);
+
+	if (!inplace_update && newundorecord.uur_payload.len > 0)
+		pfree(newundorecord.uur_payload.data);
+
+	FinishUndoRecordInsert(&gen_undo_info.context);
+	UnlockReleaseTPDBuffers();
+	FreeFakeRelcacheEntry(reln);
+
+	/*
+	 * Update the freespace.  We don't need to update it for inplace updates
+	 * as they won't freeup any space or consume any extra space assuming the
+	 * new tuple is about the same size as the old one.  See heap_xlog_update.
+	 */
+	if (newaction == BLK_NEEDS_REDO && !inplace_update && freespace < BLCKSZ / 5)
+		XLogRecordPageWithFreeSpace(rnode, newblk, freespace);
+}
+
+static void
+zheap_xlog_freeze_xact_slot(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	Buffer		buffer;
+	Page		page;
+	xl_zheap_freeze_xact_slot *xlrec =
+	(xl_zheap_freeze_xact_slot *) XLogRecGetData(record);
+	XLogRedoAction action,
+				tpdaction = -1;
+	int		   *frozen;
+	int			i;
+	bool		hasTPDSlot = false;
+
+	/* There must be some frozen slots. */
+	Assert(xlrec->nFrozen > 0);
+
+	/*
+	 * In Hot Standby mode, ensure that no running query conflicts with the
+	 * frozen xids.
+	 */
+	if (InHotStandby)
+	{
+		RelFileNode rnode;
+
+		/*
+		 * FIXME: We need some handling for transaction wraparound.
+		 */
+		TransactionId lastestFrozenXid = xlrec->lastestFrozenXid;
+
+		XLogRecGetBlockTag(record, 0, NULL, &rnode, NULL, NULL);
+		ResolveRecoveryConflictWithSnapshot(lastestFrozenXid, rnode);
+	}
+
+	frozen = (int *) ((char *) xlrec + SizeOfZHeapFreezeXactSlot);
+
+	action = XLogReadBufferForRedo(record, 0, &buffer);
+	if (XLogRecHasBlockRef(record, 1))
+	{
+		tpdaction = XLogReadTPDBuffer(record, 1);
+		hasTPDSlot = true;
+	}
+
+	page = BufferGetPage(buffer);
+
+	if (action == BLK_NEEDS_REDO)
+	{
+		ZHeapPageOpaque opaque;
+		int			slot_no;
+
+		if (hasTPDSlot)
+		{
+			zheap_freeze_or_invalidate_tuples(buffer, xlrec->nFrozen, frozen,
+											  true, true);
+		}
+		else
+		{
+			zheap_freeze_or_invalidate_tuples(buffer, xlrec->nFrozen, frozen,
+											  true, false);
+			opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+
+			/* Initialize the frozen slots. */
+			for (i = 0; i < xlrec->nFrozen; i++)
+			{
+				TransInfo  *thistrans;
+
+				slot_no = frozen[i];
+				thistrans = &opaque->transinfo[slot_no];
+
+				thistrans->fxid = InvalidFullTransactionId;
+				thistrans->urec_ptr = InvalidUndoRecPtr;
+			}
+		}
+
+		PageSetLSN(page, lsn);
+		MarkBufferDirty(buffer);
+	}
+
+	if (tpdaction == BLK_NEEDS_REDO)
+	{
+		/* Initialize the frozen slots. */
+		for (i = 0; i < xlrec->nFrozen; i++)
+		{
+			int			tpd_slot_id;
+
+			/* Calculate the actual slot no. */
+			tpd_slot_id = frozen[i] + ZHEAP_PAGE_TRANS_SLOTS + 1;
+
+			/* Clear slot information from the TPD slot. */
+			TPDPageSetTransactionSlotInfo(buffer, tpd_slot_id,
+										  InvalidFullTransactionId,
+										  InvalidUndoRecPtr);
+		}
+
+		TPDPageSetLSN(page, lsn);
+	}
+
+	if (BufferIsValid(buffer))
+		UnlockReleaseBuffer(buffer);
+
+	UnlockReleaseTPDBuffers();
+}
+
+static void
+zheap_xlog_invalid_xact_slot(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	Buffer		buffer;
+	Page		page;
+	char	   *data = XLogRecGetData(record);
+	uint16		nCompletedSlots;
+	XLogRedoAction action,
+				tpdaction = -1;
+	int		   *completed_slots;
+	int			i;
+	bool		hasTPDSlot = false;
+
+	nCompletedSlots = *(uint16 *) data;
+
+	/* There must be some frozen slots. */
+	Assert(nCompletedSlots > 0);
+
+	completed_slots = (int *) ((char *) data + sizeof(uint16));
+
+	action = XLogReadBufferForRedo(record, 0, &buffer);
+	if (XLogRecHasBlockRef(record, 1))
+	{
+		tpdaction = XLogReadTPDBuffer(record, 1);
+		hasTPDSlot = true;
+	}
+	page = BufferGetPage(buffer);
+
+	if (action == BLK_NEEDS_REDO)
+	{
+		ZHeapPageOpaque opaque;
+		int			slot_no;
+
+		opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+
+		/* clear the transaction slot info on tuples. */
+		if (hasTPDSlot)
+		{
+			zheap_freeze_or_invalidate_tuples(buffer, nCompletedSlots,
+											  completed_slots, false, true);
+		}
+		else
+		{
+			zheap_freeze_or_invalidate_tuples(buffer, nCompletedSlots,
+											  completed_slots, false, false);
+
+			/* Clear xid from the slots. */
+			for (i = 0; i < nCompletedSlots; i++)
+			{
+				slot_no = completed_slots[i];
+				opaque->transinfo[slot_no].fxid = InvalidFullTransactionId;
+			}
+		}
+
+		PageSetLSN(page, lsn);
+		MarkBufferDirty(buffer);
+	}
+	if (tpdaction == BLK_NEEDS_REDO)
+	{
+		TransInfo  *tpd_slots;
+
+		/*
+		 * Read TPD slot array. So that we can keep the slot urec_ptr intact
+		 * while clearing the transaction id from the slot.  In recovery, we
+		 * should not clear the TPD location.
+		 */
+		tpd_slots = TPDPageGetTransactionSlots(NULL, buffer,
+											   InvalidOffsetNumber,
+											   true, false, NULL, NULL,
+											   NULL, NULL, NULL,
+											   false);
+
+		for (i = 0; i < nCompletedSlots; i++)
+		{
+			int			tpd_slot_id;
+
+			/* Calculate the actual slot no. */
+			tpd_slot_id = completed_slots[i] + ZHEAP_PAGE_TRANS_SLOTS + 1;
+
+			/* Clear the XID information from the TPD. */
+			TPDPageSetTransactionSlotInfo(buffer, tpd_slot_id,
+										  InvalidFullTransactionId,
+										  tpd_slots[completed_slots[i]].urec_ptr);
+		}
+
+		TPDPageSetLSN(page, lsn);
+	}
+
+	if (BufferIsValid(buffer))
+		UnlockReleaseBuffer(buffer);
+
+	UnlockReleaseTPDBuffers();
+}
+
+static void
+zheap_xlog_lock(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	xl_undo_header *xlundohdr = (xl_undo_header *) XLogRecGetData(record);
+	xl_zheap_lock *xlrec;
+	Buffer		buffer;
+	Page		page;
+	ZHeapTupleData zheaptup;
+	char	   *tup_hdr;
+	UnpackedUndoRecord undorecord;
+	UndoRecPtr	urecptr;
+	RelFileNode target_node;
+	BlockNumber blkno;
+	ItemPointerData target_tid;
+	XLogRedoAction action;
+	Relation	reln;
+	ItemId		lp = NULL;
+	FullTransactionId fxid = XLogRecGetFullXid(record);
+	int		   *trans_slot_for_urec = NULL;
+	int		   *tup_trans_slot_id = NULL;
+	int			undo_slot_no;
+	int			trans_slot = InvalidXactSlotId;
+	ZHeapPrepareUndoInfo zh_gen_undo_info;
+	ZHeapPrepareLockUndoInfo zh_lock_undo_info;
+
+	xlrec = (xl_zheap_lock *) ((char *) xlundohdr + SizeOfUndoHeader);
+
+	XLogRecGetBlockTag(record, 0, NULL, &target_node, NULL, &blkno);
+	ItemPointerSet(&target_tid, blkno, xlrec->offnum);
+
+	reln = CreateFakeRelcacheEntry(target_node);
+	action = XLogReadBufferForRedo(record, 0, &buffer);
+	page = BufferGetPage(buffer);
+
+	if (PageGetMaxOffsetNumber(page) >= xlrec->offnum)
+		lp = PageGetItemId(page, xlrec->offnum);
+
+	if (PageGetMaxOffsetNumber(page) < xlrec->offnum || !ItemIdIsNormal(lp))
+		elog(PANIC, "invalid lp");
+
+	zheaptup.t_tableOid = RelationGetRelid(reln);
+	zheaptup.t_data = (ZHeapTupleHeader) PageGetItem(page, lp);
+	zheaptup.t_len = ItemIdGetLength(lp);
+	zheaptup.t_self = target_tid;
+
+	/*
+	 * WAL stream contains undo tuple header, replace it with the explicitly
+	 * stored tuple header.
+	 */
+	tup_hdr = (char *) xlrec + SizeOfZHeapLock;
+
+	/* prepare an undo record */
+	zh_gen_undo_info.reloid = xlundohdr->reloid;
+	zh_gen_undo_info.blkno = ItemPointerGetBlockNumber(&target_tid);
+	zh_gen_undo_info.offnum = ItemPointerGetOffsetNumber(&target_tid);
+	zh_gen_undo_info.prev_urecptr = xlundohdr->blkprev;
+	zh_gen_undo_info.fxid = fxid;
+	zh_gen_undo_info.cid = FirstCommandId;
+	zh_gen_undo_info.undo_persistence = UNDO_PERMANENT;
+
+	/* Get the trans slot number */
+	if (xlrec->flags & XLZ_LOCK_TRANS_SLOT_FOR_UREC)
+	{
+		trans_slot_for_urec = (int *) ((char *) tup_hdr +
+									   SizeofZHeapTupleHeader + sizeof(LockTupleMode));
+		trans_slot = xlrec->trans_slot_id;
+	}
+	else if (xlrec->flags & XLZ_LOCK_CONTAINS_TPD_SLOT)
+	{
+		/*
+		 * We must have logged the tuple's original transaction slot if it is
+		 * a TPD slot.
+		 */
+		tup_trans_slot_id = (int *) ((char *) tup_hdr +
+									 SizeofZHeapTupleHeader + sizeof(LockTupleMode));
+		trans_slot = *tup_trans_slot_id;
+		Assert(trans_slot > ZHEAP_PAGE_TRANS_SLOTS);
+	}
+
+	zh_lock_undo_info.gen_info = &zh_gen_undo_info;
+	zh_lock_undo_info.mode = *(tup_hdr + SizeofZHeapTupleHeader);
+	zh_lock_undo_info.tup_hdr = tup_hdr;
+	zh_lock_undo_info.tup_trans_slot = trans_slot;
+	zh_lock_undo_info.tup_xid = xlrec->prev_xid;
+	zh_lock_undo_info.new_infomask = xlrec->infomask;
+	zh_lock_undo_info.IsLockForUpdate = (xlrec->flags & XLZ_LOCK_FOR_UPDATE);
+	zh_lock_undo_info.hasSubXactLock = (xlrec->flags & XLZ_LOCK_CONTAINS_SUBXACT);
+
+	urecptr = zheap_prepare_undolock(&zh_lock_undo_info,
+									 &undorecord, record);
+
+	InsertPreparedUndo(&zh_gen_undo_info.context);
+
+	/*
+	 * undo should be inserted at same location as it was during the actual
+	 * insert (DO operation).
+	 */
+	Assert(urecptr == xlundohdr->urec_ptr);
+
+	if (trans_slot_for_urec)
+		undo_slot_no = *trans_slot_for_urec;
+	else
+		undo_slot_no = xlrec->trans_slot_id;
+
+	if (action == BLK_NEEDS_REDO)
+	{
+		zheaptup.t_data = (ZHeapTupleHeader) PageGetItem(page, lp);
+		zheaptup.t_len = ItemIdGetLength(lp);
+		ZHeapTupleHeaderSetXactSlot(zheaptup.t_data, xlrec->trans_slot_id);
+		zheaptup.t_data->t_infomask = xlrec->infomask;
+		PageSetUNDO(undorecord, buffer, undo_slot_no, false,
+					fxid, urecptr, NULL, 0);
+		PageSetLSN(page, lsn);
+		MarkBufferDirty(buffer);
+	}
+	/* replay the record for tpd buffer */
+	if (XLogRecHasBlockRef(record, 1))
+	{
+		action = XLogReadTPDBuffer(record, 1);
+		if (action == BLK_NEEDS_REDO)
+		{
+			TPDPageSetUndo(buffer,
+						   undo_slot_no,
+						   (xlrec->flags & XLZ_LOCK_FOR_UPDATE) ? true : false,
+						   fxid,
+						   urecptr,
+						   &undorecord.uur_offset,
+						   1);
+			TPDPageSetLSN(page, lsn);
+		}
+	}
+
+	if (BufferIsValid(buffer))
+		UnlockReleaseBuffer(buffer);
+
+	/* be tidy */
+	pfree(undorecord.uur_tuple.data);
+	pfree(undorecord.uur_payload.data);
+
+	FinishUndoRecordInsert(&zh_gen_undo_info.context);
+	UnlockReleaseTPDBuffers();
+	FreeFakeRelcacheEntry(reln);
+}
+
+static void
+zheap_xlog_multi_insert(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	xl_undo_header *xlundohdr;
+	xl_zheap_multi_insert *xlrec;
+	RelFileNode rnode;
+	BlockNumber blkno;
+	Buffer		buffer;
+	Page		page;
+	union
+	{
+		ZHeapTupleHeaderData hdr;
+		char		data[MaxZHeapTupleSize];
+	}			tbuf;
+	ZHeapTupleHeader zhtup;
+	uint32		newlen;
+	UnpackedUndoRecord *undorecord = NULL;
+	UndoRecPtr	urecptr = InvalidUndoRecPtr,
+				prev_urecptr = InvalidUndoRecPtr;
+	int			i;
+	int			nranges;
+	int			ucnt = 0;
+	OffsetNumber usedoff[MaxOffsetNumber];
+	bool		isinit = (XLogRecGetInfo(record) & XLOG_ZHEAP_INIT_PAGE) != 0;
+	XLogRedoAction action;
+	char	   *ranges_data;
+	int		   *tpd_trans_slot_id = NULL;
+	Size		ranges_data_size = 0;
+	FullTransactionId fxid = XLogRecGetFullXid(record);
+	ZHeapFreeOffsetRanges *zfree_offset_ranges;
+	bool		skip_undo;
+	ZHeapPrepareUndoInfo zh_undo_info;
+
+	xlundohdr = (xl_undo_header *) XLogRecGetData(record);
+	xlrec = (xl_zheap_multi_insert *) ((char *) xlundohdr + SizeOfUndoHeader);
+
+	XLogRecGetBlockTag(record, 0, NULL, &rnode, NULL, &blkno);
+
+	/*
+	 * The visibility map may need to be fixed even if the heap page is
+	 * already up-to-date.
+	 */
+	if (xlrec->flags & XLZ_INSERT_ALL_VISIBLE_CLEARED)
+	{
+		Relation	reln = CreateFakeRelcacheEntry(rnode);
+		Buffer		vmbuffer = InvalidBuffer;
+
+		visibilitymap_pin(reln, blkno, &vmbuffer);
+		visibilitymap_clear(reln, blkno, vmbuffer, VISIBILITYMAP_VALID_BITS);
+		ReleaseBuffer(vmbuffer);
+		FreeFakeRelcacheEntry(reln);
+	}
+
+	if (isinit)
+	{
+		/* It has asked for page init, insert should not have tpd slot. */
+		Assert(!(xlrec->flags & XLZ_INSERT_CONTAINS_TPD_SLOT));
+		buffer = XLogInitBufferForRedo(record, 0);
+		page = BufferGetPage(buffer);
+		ZheapInitPage(page, BufferGetPageSize(buffer));
+		action = BLK_NEEDS_REDO;
+	}
+	else
+		action = XLogReadBufferForRedo(record, 0, &buffer);
+
+	/* allocate the information related to offset ranges */
+	ranges_data = (char *) xlrec + SizeOfZHeapMultiInsert;
+
+	/* fetch number of distinct ranges */
+	nranges = *(int *) ranges_data;
+	ranges_data += sizeof(int);
+	ranges_data_size += sizeof(int);
+
+	zfree_offset_ranges = (ZHeapFreeOffsetRanges *) palloc0(sizeof(ZHeapFreeOffsetRanges));
+	Assert(nranges > 0);
+	for (i = 0; i < nranges; i++)
+	{
+		memcpy(&zfree_offset_ranges->startOffset[i], (char *) ranges_data, sizeof(OffsetNumber));
+		ranges_data += sizeof(OffsetNumber);
+		memcpy(&zfree_offset_ranges->endOffset[i], (char *) ranges_data, sizeof(OffsetNumber));
+		ranges_data += sizeof(OffsetNumber);
+	}
+
+	/*
+	 * We can skip inserting undo records if the tuples are to be marked as
+	 * frozen.
+	 */
+	skip_undo = (xlrec->flags & XLZ_INSERT_IS_FROZEN);
+	if (!skip_undo)
+	{
+		/* Start UNDO prepare Stuff */
+		prev_urecptr = xlundohdr->blkprev;
+		zh_undo_info.reloid = xlundohdr->reloid;
+		zh_undo_info.blkno = blkno;
+		zh_undo_info.offnum = InvalidOffsetNumber;
+		zh_undo_info.prev_urecptr = prev_urecptr;
+		zh_undo_info.fxid = fxid;
+		zh_undo_info.cid = FirstCommandId;
+		zh_undo_info.undo_persistence = UNDO_PERMANENT;
+
+		urecptr = zheap_prepare_undo_multi_insert(&zh_undo_info, nranges,
+                                                  &undorecord, record);
+
+		elog(DEBUG1, "Undo record prepared: %d for Block Number: %d",
+			 nranges, blkno);
+
+		/*
+		 * undo should be inserted at same location as it was during the
+		 * actual insert (DO operation).
+		 */
+		Assert(urecptr == xlundohdr->urec_ptr);
+
+		InsertPreparedUndo(&zh_undo_info.context);
+	}
+
+	/* Get the tpd transaction slot number */
+	if (xlrec->flags & XLZ_INSERT_CONTAINS_TPD_SLOT)
+	{
+		tpd_trans_slot_id = (int *) ((char *) xlrec + SizeOfZHeapMultiInsert +
+									 ranges_data_size);
+	}
+
+	/* Apply the wal for data */
+	if (action == BLK_NEEDS_REDO)
+	{
+		char	   *tupdata;
+		char	   *endptr;
+		int			trans_slot_id = 0;
+		int			prev_trans_slot_id PG_USED_FOR_ASSERTS_ONLY;
+		Size		len;
+		OffsetNumber offnum;
+		int			j = 0;
+		bool		first_time = true;
+
+		prev_trans_slot_id = -1;
+		page = BufferGetPage(buffer);
+
+		/* Tuples are stored as block data */
+		tupdata = XLogRecGetBlockData(record, 0, &len);
+		endptr = tupdata + len;
+
+		offnum = zfree_offset_ranges->startOffset[j];
+		for (i = 0; i < xlrec->ntuples; i++)
+		{
+			xl_multi_insert_ztuple *xlhdr;
+
+			/*
+			 * If we're reinitializing the page, the tuples are stored in
+			 * order from FirstOffsetNumber. Otherwise there's an array of
+			 * offsets in the WAL record, and the tuples come after that.
+			 */
+			if (isinit)
+				offnum = FirstOffsetNumber + i;
+			else
+			{
+				/*
+				 * Change the offset range if we've reached the end of current
+				 * range.
+				 */
+				if (offnum > zfree_offset_ranges->endOffset[j])
+				{
+					j++;
+					offnum = zfree_offset_ranges->startOffset[j];
+				}
+			}
+			if (PageGetMaxOffsetNumber(page) + 1 < offnum)
+				elog(PANIC, "invalid max offset number");
+
+			xlhdr = (xl_multi_insert_ztuple *) SHORTALIGN(tupdata);
+			tupdata = ((char *) xlhdr) + SizeOfMultiInsertZTuple;
+
+			newlen = xlhdr->datalen;
+			Assert(newlen <= MaxZHeapTupleSize);
+			zhtup = &tbuf.hdr;
+			MemSet((char *) zhtup, 0, SizeofZHeapTupleHeader);
+			/* PG73FORMAT: get bitmap [+ padding] [+ oid] + data */
+			memcpy((char *) zhtup + SizeofZHeapTupleHeader,
+				   (char *) tupdata,
+				   newlen);
+			tupdata += newlen;
+
+			newlen += SizeofZHeapTupleHeader;
+			zhtup->t_infomask2 = xlhdr->t_infomask2;
+			zhtup->t_infomask = xlhdr->t_infomask;
+			zhtup->t_hoff = xlhdr->t_hoff;
+
+			if (ZPageAddItem(buffer, NULL, (Item) zhtup, newlen, offnum,
+							 true, true, true) == InvalidOffsetNumber)
+				elog(PANIC, "failed to add tuple");
+
+			/* track used offsets */
+			usedoff[ucnt++] = offnum;
+
+			/* increase the offset to store next tuple */
+			offnum++;
+
+			if (!skip_undo)
+			{
+				if (tpd_trans_slot_id)
+					trans_slot_id = *tpd_trans_slot_id;
+				else
+					trans_slot_id = ZHeapTupleHeaderGetXactSlot(zhtup);
+				if (first_time)
+				{
+					prev_trans_slot_id = trans_slot_id;
+					first_time = false;
+				}
+				else
+				{
+					/* All the tuples must refer to same transaction slot. */
+					Assert(prev_trans_slot_id == trans_slot_id);
+					prev_trans_slot_id = trans_slot_id;
+				}
+			}
+		}
+
+		if (!skip_undo)
+			PageSetUNDO(undorecord[nranges - 1], buffer, trans_slot_id, false,
+						fxid, urecptr, NULL, 0);
+
+		PageSetLSN(page, lsn);
+
+		MarkBufferDirty(buffer);
+
+		if (tupdata != endptr)
+			elog(ERROR, "total tuple length mismatch");
+	}
+
+	/* replay the record for tpd buffer */
+	if (XLogRecHasBlockRef(record, 1))
+	{
+		/*
+		 * We need to replay the record for TPD only when this record contains
+		 * slot from TPD.
+		 */
+		Assert(xlrec->flags & XLZ_INSERT_CONTAINS_TPD_SLOT);
+		action = XLogReadTPDBuffer(record, 1);
+		if (action == BLK_NEEDS_REDO)
+		{
+			/* prepare for the case where the data page is restored as is */
+			if (ucnt == 0)
+			{
+				for (i = 0; i < nranges; i++)
+				{
+					OffsetNumber start_off,
+								end_off;
+
+					start_off = ((OffsetNumber *) undorecord[i].uur_payload.data)[0];
+					end_off = ((OffsetNumber *) undorecord[i].uur_payload.data)[1];
+
+					while (start_off <= end_off)
+						usedoff[ucnt++] = start_off++;
+				}
+			}
+
+			TPDPageSetUndo(buffer,
+						   *tpd_trans_slot_id,
+						   true,
+						   fxid,
+						   urecptr,
+						   usedoff,
+						   ucnt);
+			TPDPageSetLSN(BufferGetPage(buffer), lsn);
+		}
+	}
+
+	/* be tidy */
+	if (!skip_undo)
+	{
+		for (i = 0; i < nranges; i++)
+			pfree(undorecord[i].uur_payload.data);
+		pfree(undorecord);
+	}
+	pfree(zfree_offset_ranges);
+
+	if (BufferIsValid(buffer))
+		UnlockReleaseBuffer(buffer);
+	FinishUndoRecordInsert(&zh_undo_info.context);
+	UnlockReleaseTPDBuffers();
+}
+
+/*
+ * Handles ZHEAP_CLEAN record type
+ */
+static void
+zheap_xlog_clean(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	xl_zheap_clean *xlrec = (xl_zheap_clean *) XLogRecGetData(record);
+	Buffer		buffer;
+	Size		freespace = 0;
+	RelFileNode rnode;
+	BlockNumber blkno;
+	XLogRedoAction action;
+	OffsetNumber *target_offnum;
+	Size	   *space_required;
+
+	XLogRecGetBlockTag(record, 0, NULL, &rnode, NULL, &blkno);
+
+	/*
+	 * We're about to remove tuples. In Hot Standby mode, ensure that there's
+	 * no queries running for which the removed tuples are still visible.
+	 *
+	 * Not all ZHEAP_CLEAN records remove tuples with xids, so we only want to
+	 * conflict on the records that cause MVCC failures for user queries. If
+	 * latestRemovedXid is invalid, skip conflict processing.
+	 */
+	if (InHotStandby && TransactionIdIsValid(xlrec->latestRemovedXid))
+		ResolveRecoveryConflictWithSnapshot(xlrec->latestRemovedXid, rnode);
+
+	/*
+	 * If we have a full-page image, restore it (using a cleanup lock) and
+	 * we're done.
+	 */
+	action = XLogReadBufferForRedoExtended(record, 0, RBM_NORMAL, true,
+										   &buffer);
+	if (action == BLK_NEEDS_REDO)
+	{
+		Page		page = (Page) BufferGetPage(buffer);
+		OffsetNumber *end;
+		OffsetNumber *deleted;
+		OffsetNumber *nowdead;
+		OffsetNumber *nowunused;
+		OffsetNumber tmp_target_off;
+		int			ndeleted;
+		int			ndead;
+		int			nunused;
+		Size		datalen;
+		Size		tmp_spc_rqd;
+
+		deleted = (OffsetNumber *) XLogRecGetBlockData(record, 0, &datalen);
+
+		ndeleted = xlrec->ndeleted;
+		ndead = xlrec->ndead;
+		end = (OffsetNumber *) ((char *) deleted + datalen);
+		nowdead = deleted + (ndeleted * 2);
+		nowunused = nowdead + ndead;
+		nunused = (end - nowunused);
+		Assert(nunused >= 0);
+
+		/* Update all item pointers per the record, and repair fragmentation */
+		if (xlrec->flags & XLZ_CLEAN_CONTAINS_OFFSET)
+		{
+			target_offnum = (OffsetNumber *) ((char *) xlrec + SizeOfZHeapClean);
+			space_required = (Size *) ((char *) target_offnum + sizeof(OffsetNumber));
+		}
+		else
+		{
+			target_offnum = &tmp_target_off;
+			*target_offnum = InvalidOffsetNumber;
+			space_required = &tmp_spc_rqd;
+			*space_required = 0;
+		}
+
+		zheap_page_prune_execute(buffer, *target_offnum, deleted, ndeleted,
+								 nowdead, ndead, nowunused, nunused);
+
+		if (xlrec->flags & XLZ_CLEAN_ALLOW_PRUNING)
+		{
+			bool		pruned PG_USED_FOR_ASSERTS_ONLY = false;
+			Page		tmppage = NULL;
+
+			/*
+			 * We prepare the temporary copy of the page so that during page
+			 * repair fragmentation we can use it to copy the actual tuples.
+			 * See comments atop zheap_page_prune_guts.
+			 */
+			tmppage = PageGetTempPageCopy(BufferGetPage(buffer));
+			ZPageRepairFragmentation(buffer, tmppage, *target_offnum,
+									 *space_required, true, &pruned, false);
+
+			/*
+			 * Pruning must be successful at redo time, otherwise the page
+			 * contents on master and standby might differ.
+			 */
+			Assert(pruned);
+
+			/* be tidy. */
+			pfree(tmppage);
+		}
+
+		freespace = PageGetZHeapFreeSpace(page);	/* needed to update FSM
+													 * below */
+
+		/*
+		 * Note: we don't worry about updating the page's prunability hints.
+		 * At worst this will cause an extra prune cycle to occur soon.
+		 */
+
+		PageSetLSN(page, lsn);
+		MarkBufferDirty(buffer);
+	}
+	if (BufferIsValid(buffer))
+		UnlockReleaseBuffer(buffer);
+
+	/*
+	 * Update the FSM as well.
+	 *
+	 * XXX: Don't do this if the page was restored from full page image. We
+	 * don't bother to update the FSM in that case, it doesn't need to be
+	 * totally accurate anyway.
+	 */
+	if (action == BLK_NEEDS_REDO)
+		XLogRecordPageWithFreeSpace(rnode, blkno, freespace);
+}
+
+/*
+ * Handles XLOG_ZHEAP_CONFIRM record type
+ */
+static void
+zheap_xlog_confirm(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	xl_zheap_confirm *xlrec = (xl_zheap_confirm *) XLogRecGetData(record);
+	Buffer		buffer;
+	Page		page;
+	OffsetNumber offnum;
+	ItemId		lp = NULL;
+	ZHeapTupleHeader zhtup;
+
+	if (XLogReadBufferForRedo(record, 0, &buffer) == BLK_NEEDS_REDO)
+	{
+		page = BufferGetPage(buffer);
+
+		offnum = xlrec->offnum;
+		if (PageGetMaxOffsetNumber(page) >= offnum)
+			lp = PageGetItemId(page, offnum);
+
+		if (PageGetMaxOffsetNumber(page) < offnum || !ItemIdIsNormal(lp))
+			elog(PANIC, "invalid lp");
+
+		zhtup = (ZHeapTupleHeader) PageGetItem(page, lp);
+
+		if (xlrec->flags == XLZ_SPEC_INSERT_SUCCESS)
+		{
+			/* Confirm tuple as actually inserted */
+			zhtup->t_infomask &= ~ZHEAP_SPECULATIVE_INSERT;
+		}
+		else
+		{
+			Assert(xlrec->flags == XLZ_SPEC_INSERT_FAILED ||
+				   xlrec->flags == XLZ_INSERT_IS_SPECULATIVE);
+			ItemIdSetDeadExtended(lp, xlrec->trans_slot_id);
+			ZPageSetPrunable(page, XLogRecGetXid(record));
+		}
+
+		PageSetLSN(page, lsn);
+		MarkBufferDirty(buffer);
+	}
+	if (BufferIsValid(buffer))
+		UnlockReleaseBuffer(buffer);
+}
+
+/*
+ * Handles XLOG_ZHEAP_UNUSED record type
+ */
+static void
+zheap_xlog_unused(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	xl_undo_header *xlundohdr;
+	xl_zheap_unused *xlrec;
+	UnpackedUndoRecord undorecord;
+	UndoRecPtr	urecptr;
+	FullTransactionId fxid = XLogRecGetFullXid(record);
+	TransactionId xid = XidFromFullTransactionId(fxid);
+	uint16		i,
+				uncnt;
+	Buffer		buffer;
+	OffsetNumber *unused;
+	Size		freespace = 0;
+	RelFileNode rnode;
+	BlockNumber blkno;
+	XLogRedoAction action;
+	bool		unused_set = false;
+	UndoRecordInsertContext	context;
+
+	xlundohdr = (xl_undo_header *) XLogRecGetData(record);
+	xlrec = (xl_zheap_unused *) ((char *) xlundohdr + SizeOfUndoHeader);
+	/* extract the information related to unused offsets */
+	unused = (OffsetNumber *) ((char *) xlrec + SizeOfZHeapUnused);
+	uncnt = xlrec->nunused;
+
+	XLogRecGetBlockTag(record, 0, NULL, &rnode, NULL, &blkno);
+
+	/*
+	 * We're about to remove tuples. In Hot Standby mode, ensure that there's
+	 * no queries running for which the removed tuples are still visible.
+	 *
+	 * Not all ZHEAP_UNUSED records remove tuples with xids, so we only want
+	 * to conflict on the records that cause MVCC failures for user queries.
+	 * If latestRemovedXid is invalid, skip conflict processing.
+	 */
+	if (InHotStandby && TransactionIdIsValid(xlrec->latestRemovedXid))
+		ResolveRecoveryConflictWithSnapshot(xlrec->latestRemovedXid, rnode);
+
+	/* prepare an undo record */
+	undorecord.uur_rmid = RM_ZHEAP_ID;
+	undorecord.uur_type = UNDO_ITEMID_UNUSED;
+	undorecord.uur_info = 0;
+	undorecord.uur_reloid = xlundohdr->reloid;
+	undorecord.uur_prevxid = xid;
+	undorecord.uur_xid = xid;
+	undorecord.uur_cid = FirstCommandId;
+	undorecord.uur_fork = MAIN_FORKNUM;
+	undorecord.uur_blkprev = xlundohdr->blkprev;
+	undorecord.uur_block = blkno;
+	undorecord.uur_offset = 0;
+	undorecord.uur_tuple.len = 0;
+	undorecord.uur_payload.len = uncnt * sizeof(OffsetNumber);
+	undorecord.uur_payload.data =
+		(char *) palloc(uncnt * sizeof(OffsetNumber));
+	memcpy(undorecord.uur_payload.data,
+		   (char *) unused,
+		   undorecord.uur_payload.len);
+
+	BeginUndoRecordInsert(&context, UNDO_PERMANENT, 1, record);
+	urecptr = PrepareUndoInsert(&context, &undorecord, fxid);
+	InsertPreparedUndo(&context);
+
+	/*
+	 * undo should be inserted at same location as it was during the actual
+	 * insert (DO operation).
+	 */
+	Assert(urecptr == xlundohdr->urec_ptr);
+
+	/*
+	 * If we have a full-page image, restore it (using a cleanup lock) and
+	 * we're done.
+	 */
+	action = XLogReadBufferForRedoExtended(record, 0, RBM_NORMAL, true,
+										   &buffer);
+	if (action == BLK_NEEDS_REDO)
+	{
+		Page		page = (Page) BufferGetPage(buffer);
+
+		Assert(uncnt > 0);
+
+		for (i = 0; i < uncnt; i++)
+		{
+			ItemId		itemid;
+
+			itemid = PageGetItemId(page, unused[i]);
+			ItemIdSetUnusedExtended(itemid, xlrec->trans_slot_id);
+		}
+
+		/*
+		 * The flag is used to prevent re-evaluation of itemid, clearing the
+		 * set transaction slot information by ZPageRepairFragmentation.
+		 */
+		if (uncnt > 0)
+			unused_set = true;
+
+		PageSetUNDO(undorecord, buffer, xlrec->trans_slot_id, false,
+					fxid, urecptr, NULL, 0);
+
+		if (xlrec->flags & XLZ_UNUSED_ALLOW_PRUNING)
+		{
+			bool		pruned PG_USED_FOR_ASSERTS_ONLY = false;
+			Page		tmppage = NULL;
+
+			/*
+			 * We prepare the temporary copy of the page so that during page
+			 * repair fragmentation we can use it to copy the actual tuples.
+			 * See comments atop zheap_page_prune_guts.
+			 */
+			tmppage = PageGetTempPageCopy(BufferGetPage(buffer));
+			ZPageRepairFragmentation(buffer, tmppage, InvalidOffsetNumber,
+									 0, true, &pruned, unused_set);
+
+			/*
+			 * Pruning must be successful at redo time, otherwise the page
+			 * contents on master and standby might differ.
+			 */
+			Assert(pruned);
+
+			pfree(tmppage);
+		}
+
+		freespace = PageGetZHeapFreeSpace(page);	/* needed to update FSM
+													 * below */
+
+		PageSetLSN(page, lsn);
+		MarkBufferDirty(buffer);
+	}
+
+	/* replay the record for tpd buffer */
+	if (XLogRecHasBlockRef(record, 1))
+	{
+		/*
+		 * We need to replay the record for TPD only when this record contains
+		 * slot from TPD.
+		 */
+		action = XLogReadTPDBuffer(record, 1);
+		if (action == BLK_NEEDS_REDO)
+		{
+			TPDPageSetUndo(buffer,
+						   xlrec->trans_slot_id,
+						   true,
+						   fxid,
+						   urecptr,
+						   unused,
+						   uncnt);
+			TPDPageSetLSN(BufferGetPage(buffer), lsn);
+		}
+	}
+
+	if (BufferIsValid(buffer))
+		UnlockReleaseBuffer(buffer);
+	FinishUndoRecordInsert(&context);
+	UnlockReleaseTPDBuffers();
+
+	/*
+	 * Update the FSM as well.
+	 *
+	 * XXX: Don't do this if the page was restored from full page image. We
+	 * don't bother to update the FSM in that case, it doesn't need to be
+	 * totally accurate anyway.
+	 */
+	if (action == BLK_NEEDS_REDO)
+		XLogRecordPageWithFreeSpace(rnode, blkno, freespace);
+}
+
+/*
+ * Replay XLOG_ZHEAP_VISIBLE record.
+ */
+static void
+zheap_xlog_visible(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	xl_zheap_visible *xlrec = (xl_zheap_visible *) XLogRecGetData(record);
+	Buffer		vmbuffer = InvalidBuffer;
+	RelFileNode rnode;
+
+	XLogRecGetBlockTag(record, 0, NULL, &rnode, NULL, NULL);
+
+	/*
+	 * If there are any Hot Standby transactions running that have an xmin
+	 * horizon old enough that this page isn't all-visible for them, they
+	 * might incorrectly decide that an index-only scan can skip a zheap
+	 * fetch.
+	 *
+	 * NB: It might be better to throw some kind of "soft" conflict here that
+	 * forces any index-only scan that is in flight to perform zheap fetches,
+	 * rather than killing the transaction outright.
+	 */
+	if (InHotStandby)
+		ResolveRecoveryConflictWithSnapshot(xlrec->cutoff_xid, rnode);
+
+	if (XLogReadBufferForRedoExtended(record, 0, RBM_ZERO_ON_ERROR, false,
+									  &vmbuffer) == BLK_NEEDS_REDO)
+	{
+		Page		vmpage = BufferGetPage(vmbuffer);
+		Relation	reln;
+		BlockNumber blkno = xlrec->heapBlk;;
+
+		/* initialize the page if it was read as zeros */
+		if (PageIsNew(vmpage))
+			PageInit(vmpage, BLCKSZ, 0);
+
+		/*
+		 * XLogReadBufferForRedoExtended locked the buffer. But
+		 * visibilitymap_set will handle locking itself.
+		 */
+		LockBuffer(vmbuffer, BUFFER_LOCK_UNLOCK);
+
+		reln = CreateFakeRelcacheEntry(rnode);
+		visibilitymap_pin(reln, blkno, &vmbuffer);
+
+		/*
+		 * Don't set the bit if replay has already passed this point.
+		 *
+		 * It might be safe to do this unconditionally; if replay has passed
+		 * this point, we'll replay at least as far this time as we did
+		 * before, and if this bit needs to be cleared, the record responsible
+		 * for doing so should be again replayed, and clear it.  For right
+		 * now, out of an abundance of conservatism, we use the same test here
+		 * we did for the zheap page.  If this results in a dropped bit, no
+		 * real harm is done; and the next VACUUM will fix it.
+		 */
+		if (lsn > PageGetLSN(vmpage))
+			visibilitymap_set(reln, blkno, InvalidBuffer, lsn, vmbuffer,
+							  xlrec->cutoff_xid, xlrec->flags);
+
+		ReleaseBuffer(vmbuffer);
+		FreeFakeRelcacheEntry(reln);
+	}
+	else if (BufferIsValid(vmbuffer))
+		UnlockReleaseBuffer(vmbuffer);
+}
+
+/*
+ * replay of undo page operation
+ */
+static void
+zheap_undo_xlog_page(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	Buffer		buf;
+	xl_zundo_page *xlrec = NULL;
+	char	   *offsetmap = NULL,
+			   *data = NULL;
+	XLogRedoAction action;
+	uint8	   *flags = (uint8 *) XLogRecGetData(record);
+
+	if (*flags & XLU_PAGE_CONTAINS_TPD_SLOT ||
+		*flags & XLU_CONTAINS_TPD_OFFSET_MAP)
+	{
+		data = (char *) flags + sizeof(uint8);
+		if (*flags & XLU_PAGE_CONTAINS_TPD_SLOT)
+		{
+			xlrec = (xl_zundo_page *) data;
+			data += sizeof(xl_zundo_page);
+		}
+		if (*flags & XLU_CONTAINS_TPD_OFFSET_MAP)
+			offsetmap = data;
+	}
+
+	if (XLogReadBufferForRedo(record, 0, &buf) != BLK_RESTORED)
+		elog(ERROR, "Undo page record did not contain a full-page image");
+
+	/* replay the record for tpd buffer */
+	if (XLogRecHasBlockRef(record, 1))
+	{
+		/*
+		 * We need to replay the record for TPD only when this record contains
+		 * slot from TPD.
+		 */
+		Assert(*flags & XLU_PAGE_CONTAINS_TPD_SLOT ||
+			   *flags & XLU_CONTAINS_TPD_OFFSET_MAP);
+		action = XLogReadTPDBuffer(record, 1);
+		if (action == BLK_NEEDS_REDO)
+		{
+			if (*flags & XLU_PAGE_CONTAINS_TPD_SLOT)
+				TPDPageSetTransactionSlotInfo(buf, xlrec->trans_slot_id,
+											  xlrec->fxid, xlrec->urec_ptr);
+
+			if (offsetmap)
+				TPDPageSetOffsetMap(buf, offsetmap);
+
+			TPDPageSetLSN(BufferGetPage(buf), lsn);
+		}
+	}
+
+	if (*flags & XLU_PAGE_CLEAR_VISIBILITY_MAP)
+	{
+		Relation	reln;
+		Buffer		vmbuffer = InvalidBuffer;
+		RelFileNode target_node;
+		BlockNumber blkno;
+
+		XLogRecGetBlockTag(record, 0, NULL, &target_node, NULL, &blkno);
+		reln = CreateFakeRelcacheEntry(target_node);
+		visibilitymap_pin(reln, blkno, &vmbuffer);
+		visibilitymap_clear(reln, blkno, vmbuffer, VISIBILITYMAP_VALID_BITS);
+		ReleaseBuffer(vmbuffer);
+		FreeFakeRelcacheEntry(reln);
+	}
+
+	/*
+	 * Reset Page only at the end if asked, page level flag
+	 * PD_PAGE_HAS_TPD_SLOT and TPD slot are needed before that TPD routines.
+	 */
+	if (*flags & XLU_INIT_PAGE)
+		ZheapInitPage(BufferGetPage(buf), (Size) BLCKSZ);
+
+	UnlockReleaseBuffer(buf);
+	UnlockReleaseTPDBuffers();
+}
+
+/*
+ * replay of undo reset slot operation
+ */
+static void
+zheap_undo_xlog_reset_xid(XLogReaderState *record)
+{
+	XLogRecPtr	lsn = record->EndRecPtr;
+	xl_zundo_reset_slot *xlrec = (xl_zundo_reset_slot *) XLogRecGetData(record);
+	Buffer		buf;
+	XLogRedoAction action;
+
+	action = XLogReadBufferForRedo(record, 0, &buf);
+
+	/*
+	 * Reseting the TPD slot is handled separately so only handle the page
+	 * slot here.
+	 */
+	if (action == BLK_NEEDS_REDO &&
+		xlrec->trans_slot_id <= ZHEAP_PAGE_TRANS_SLOTS)
+	{
+		Page		page;
+		ZHeapPageOpaque opaque;
+		TransInfo  *thistrans;
+		int			slot_no = xlrec->trans_slot_id;
+
+		page = BufferGetPage(buf);
+		opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+		thistrans = &opaque->transinfo[slot_no - 1];
+
+		thistrans->fxid = InvalidFullTransactionId;
+		thistrans->urec_ptr = xlrec->urec_ptr;
+
+		PageSetLSN(page, lsn);
+		MarkBufferDirty(buf);
+	}
+
+	/* replay the record for tpd buffer */
+	if (XLogRecHasBlockRef(record, 1))
+	{
+		Assert(xlrec->flags & XLU_RESET_CONTAINS_TPD_SLOT);
+		action = XLogReadTPDBuffer(record, 1);
+		if (action == BLK_NEEDS_REDO)
+		{
+			TPDPageSetTransactionSlotInfo(buf, xlrec->trans_slot_id,
+										  InvalidFullTransactionId,
+										  xlrec->urec_ptr);
+			TPDPageSetLSN(BufferGetPage(buf), lsn);
+		}
+	}
+
+	if (BufferIsValid(buf))
+		UnlockReleaseBuffer(buf);
+	UnlockReleaseTPDBuffers();
+}
+
+void
+zheap_redo(XLogReaderState *record)
+{
+	uint8		info = XLogRecGetInfo(record) & ~XLR_INFO_MASK;
+
+	switch (info & XLOG_ZHEAP_OPMASK)
+	{
+		case XLOG_ZHEAP_INSERT:
+			zheap_xlog_insert(record);
+			break;
+		case XLOG_ZHEAP_DELETE:
+			zheap_xlog_delete(record);
+			break;
+		case XLOG_ZHEAP_UPDATE:
+			zheap_xlog_update(record);
+			break;
+		case XLOG_ZHEAP_FREEZE_XACT_SLOT:
+			zheap_xlog_freeze_xact_slot(record);
+			break;
+		case XLOG_ZHEAP_INVALID_XACT_SLOT:
+			zheap_xlog_invalid_xact_slot(record);
+			break;
+		case XLOG_ZHEAP_LOCK:
+			zheap_xlog_lock(record);
+			break;
+		case XLOG_ZHEAP_MULTI_INSERT:
+			zheap_xlog_multi_insert(record);
+			break;
+		case XLOG_ZHEAP_CLEAN:
+			zheap_xlog_clean(record);
+			break;
+		default:
+			elog(PANIC, "zheap_redo: unknown op code %u", info);
+	}
+}
+
+void
+zheap2_redo(XLogReaderState *record)
+{
+	uint8		info = XLogRecGetInfo(record) & ~XLR_INFO_MASK;
+
+	switch (info & XLOG_ZHEAP_OPMASK)
+	{
+		case XLOG_ZHEAP_CONFIRM:
+			zheap_xlog_confirm(record);
+			break;
+		case XLOG_ZHEAP_UNUSED:
+			zheap_xlog_unused(record);
+			break;
+		case XLOG_ZHEAP_VISIBLE:
+			zheap_xlog_visible(record);
+			break;
+		default:
+			elog(PANIC, "zheap2_redo: unknown op code %u", info);
+	}
+}
+
+void
+zundo_redo(XLogReaderState *record)
+{
+	uint8		info = XLogRecGetInfo(record) & ~XLR_INFO_MASK;
+
+	switch (info)
+	{
+		case XLOG_ZUNDO_PAGE:
+			zheap_undo_xlog_page(record);
+			break;
+		case XLOG_ZUNDO_RESET_SLOT:
+			zheap_undo_xlog_reset_xid(record);
+			break;
+		default:
+			elog(PANIC, "zundo_redo: unknown op code %u", info);
+	}
+}
+
+
+/*
+ * Mask a zheap page before performing consistency checks on it.
+ */
+void
+zheap_mask(char *pagedata, BlockNumber blkno)
+{
+	Page		page = (Page) pagedata;
+
+	mask_page_lsn_and_checksum(page);
+
+	mask_page_hint_bits(page);
+	mask_unused_space(page);
+
+	if (PageGetSpecialSize(page) == MAXALIGN(BLCKSZ))
+	{
+		ZHeapMetaPage metap PG_USED_FOR_ASSERTS_ONLY;
+
+		metap = ZHeapPageGetMeta(page);
+		/* It's a meta-page, no need to mask further. */
+		Assert(metap->zhm_magic == ZHEAP_MAGIC);
+		Assert(metap->zhm_version == ZHEAP_VERSION);
+		return;
+	}
+
+	if (IsTPDPage(page))
+	{
+		/* It's a TPD page, no need to mask further. */
+		return;
+	}
+}
diff --git a/src/backend/access/zheap/zhio.c b/src/backend/access/zheap/zhio.c
new file mode 100644
index 0000000..a47cab1
--- /dev/null
+++ b/src/backend/access/zheap/zhio.c
@@ -0,0 +1,456 @@
+/*-------------------------------------------------------------------------
+ *
+ * zhio.c
+ *	  POSTGRES zheap access method input/output code.
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/zheap/zhio.c
+ *
+ *-------------------------------------------------------------------------
+ */
+
+#include "postgres.h"
+
+#include "access/tpd.h"
+#include "access/visibilitymap.h"
+#include "access/zheap.h"
+#include "access/zhio.h"
+#include "access/zhtup.h"
+#include "storage/bufmgr.h"
+#include "storage/freespace.h"
+#include "storage/lmgr.h"
+#include "storage/smgr.h"
+
+/*
+ * RelationGetBufferForZTuple
+ *
+ *	Returns pinned and exclusive-locked buffer of a page in given relation
+ *	with free space >= given len.
+ *
+ *	This is quite similar to RelationGetBufferForTuple except for zheap
+ *	specific handling.  If the last page where tuple needs to be inserted is a
+ *	TPD page, we skip it and directly extend the relation.  We could instead
+ *	check the previous page, but scanning relation backwards could be costly,
+ *	so we avoid it for now.  As we don't align tuples in zheap, use actual
+ *	length to find the required buffer.
+ */
+Buffer
+RelationGetBufferForZTuple(Relation relation, Size len,
+						   Buffer otherBuffer, int options,
+						   BulkInsertState bistate,
+						   Buffer *vmbuffer, Buffer *vmbuffer_other)
+{
+	bool		use_fsm = !(options & TABLE_INSERT_SKIP_FSM);
+	Buffer		buffer = InvalidBuffer;
+	Page		page;
+	Size		pageFreeSpace = 0,
+				saveFreeSpace = 0;
+	BlockNumber targetBlock,
+				otherBlock;
+	bool		needLock = false;
+
+	/* Bulk insert is not supported for updates, only inserts. */
+	Assert(otherBuffer == InvalidBuffer || !bistate);
+
+	len = SHORTALIGN(len);
+
+	/*
+	 * If we're gonna fail for oversize tuple, do it right away
+	 */
+	if (len > MaxZHeapTupleSize)
+		ereport(ERROR,
+				(errcode(ERRCODE_PROGRAM_LIMIT_EXCEEDED),
+				 errmsg("row is too big: size %zu, maximum size %zu",
+						len, MaxZHeapTupleSize)));
+
+	/* Compute desired extra freespace due to fillfactor option */
+	saveFreeSpace = RelationGetTargetPageFreeSpace(relation,
+												   HEAP_DEFAULT_FILLFACTOR);
+
+	if (otherBuffer != InvalidBuffer)
+		otherBlock = BufferGetBlockNumber(otherBuffer);
+	else
+		otherBlock = InvalidBlockNumber;	/* just to keep compiler quiet */
+
+	/*
+	 * We first try to put the tuple on the same page we last inserted a tuple
+	 * on, as cached in the BulkInsertState or relcache entry.  If that
+	 * doesn't work, we ask the Free Space Map to locate a suitable page.
+	 * Since the FSM's info might be out of date, we have to be prepared to
+	 * loop around and retry multiple times. (To insure this isn't an infinite
+	 * loop, we must update the FSM with the correct amount of free space on
+	 * each page that proves not to be suitable.)  If the FSM has no record of
+	 * a page with enough free space, we give up and extend the relation.
+	 *
+	 * When use_fsm is false, we either put the tuple onto the existing target
+	 * page or extend the relation.
+	 */
+	if (len + saveFreeSpace > MaxZHeapTupleSize)
+	{
+		/* can't fit, don't bother asking FSM */
+		targetBlock = InvalidBlockNumber;
+		use_fsm = false;
+	}
+	else if (bistate && bistate->current_buf != InvalidBuffer)
+		targetBlock = BufferGetBlockNumber(bistate->current_buf);
+	else
+		targetBlock = RelationGetTargetBlock(relation);
+
+	if (targetBlock == InvalidBlockNumber && use_fsm)
+	{
+		/*
+		 * We have no cached target page, so ask the FSM for an initial
+		 * target.
+		 */
+		targetBlock = GetPageWithFreeSpace(relation,
+										   len + saveFreeSpace);
+
+		/*
+		 * If the FSM knows nothing of the rel, try the last page before we
+		 * give up and extend.  This avoids one-tuple-per-page syndrome during
+		 * bootstrapping or in a recently-started system.
+		 */
+		if (targetBlock == InvalidBlockNumber)
+		{
+			BlockNumber nblocks = RelationGetNumberOfBlocks(relation);
+
+			if (nblocks > 0)
+				targetBlock = nblocks - 1;
+		}
+	}
+
+loop:
+	while (targetBlock != InvalidBlockNumber)
+	{
+		bool		other_buffer_locked = false;
+
+		/*
+		 * Read and exclusive-lock the target block, as well as the other
+		 * block if one was given, taking suitable care with lock ordering and
+		 * the possibility they are the same block.
+		 *
+		 * If the page-level all-visible flag is set, caller will need to
+		 * clear both that and the corresponding visibility map bit.  However,
+		 * by the time we return, we'll have x-locked the buffer, and we don't
+		 * want to do any I/O while in that state.  So we check the bit here
+		 * before taking the lock, and pin the page if it appears necessary.
+		 * Checking without the lock creates a risk of getting the wrong
+		 * answer, so we'll have to recheck after acquiring the lock.
+		 */
+		if (otherBuffer == InvalidBuffer)
+		{
+			/* easy case */
+			buffer = ReadBufferBI(relation, targetBlock, RBM_NORMAL, bistate);
+			visibilitymap_pin(relation, targetBlock, vmbuffer);
+			LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+		}
+		else if (otherBlock == targetBlock)
+		{
+			/* also easy case */
+			buffer = otherBuffer;
+			visibilitymap_pin(relation, targetBlock, vmbuffer);
+			LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+		}
+		else if (otherBlock < targetBlock)
+		{
+			/* lock other buffer first */
+			buffer = ReadBuffer(relation, targetBlock);
+			visibilitymap_pin(relation, targetBlock, vmbuffer);
+			LockBuffer(otherBuffer, BUFFER_LOCK_EXCLUSIVE);
+			LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+
+			other_buffer_locked = true;
+		}
+		else
+		{
+			/* lock target buffer first */
+			buffer = ReadBuffer(relation, targetBlock);
+			visibilitymap_pin(relation, targetBlock, vmbuffer);
+			LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+
+			/*
+			 * ZBORKED: This is my (Andres') adaption of the previously (in
+			 * code) undocumented workaround around lock-ordering issue in tpd
+			 * pages that was originally added in
+			 * https://github.com/EnterpriseDB/zheap/commit/e4d3f718991b673ca3f6b02f5562366f7bc67b6d
+			 *
+			 * Whenever we need two buffers for updating a tuple
+			 * (non-inplace), we use the rule "lock lower numbered buffer
+			 * first" to avoid deadlocks. But, in zheap this is not the
+			 * sufficient condition.  It's possible that the new buffer is a
+			 * pruned TPD buffer and some other backend is trying to use it
+			 * while holding lock on a zheap buffer with higher block number.
+			 *
+			 * To avoid deadlocking, we simply don't lock otherBuffer.  First
+			 * we will check that target block is TPD block or not, if TPD
+			 * block then we will not lock otherBuffer.
+			 *
+			 * We will never get TPD page from FSM but concurrently other
+			 * backend can get same page from FSM to use as new TPD page.  If
+			 * other backend gets same page, then that backend will make our
+			 * page as non-empty by putting TPD entry so here, we are checking
+			 * that if our page is TPD page or not, if TPD page, then directly
+			 * ignore page without checking PageIsEmpty.
+			 *
+			 * XXX: When we will not get any page from FSM, then we are
+			 * checking space in last block of relation.  It is possible that
+			 * last block of relation is empty TPD page(See ExtendTPDEntry,
+			 * there we are not removing empty TPD block from meta list to
+			 * avoid deadlock).  But we are not using empty TPD page.  If we
+			 * want, we can use that empty TPD page here by freeing empty TPD
+			 * page from meta list but will be costly.
+			 */
+			if (!IsTPDPage(BufferGetPage(buffer)))
+			{
+				LockBuffer(otherBuffer, BUFFER_LOCK_EXCLUSIVE);
+				other_buffer_locked = true;
+			}
+		}
+
+		if (targetBlock == ZHEAP_METAPAGE || IsTPDPage(BufferGetPage(buffer)))
+		{
+			/*
+			 * ZBORKED: I (Andres) had to implement this because the previous
+			 * code was plainly broken, and caused problems due to the newer
+			 * fsm_local_map() logic.  We could handle the ZHEAP_METAPAGE case
+			 * before locking (but be careful, it needs to be in the loop),
+			 * but I'm doubtful it's worth it, because we still need to update
+			 * the FSM etc.
+			 */
+			pageFreeSpace = 0;
+		}
+		else
+		{
+			/*
+			 * We now have the target page (and the other buffer, if any)
+			 * pinned and locked.  However, since our initial PageIsAllVisible
+			 * checks were performed before acquiring the lock, the results
+			 * might now be out of date, either for the selected victim
+			 * buffer, or for the other buffer passed by the caller.  In that
+			 * case, we'll need to give up our locks, go get the pin(s) we
+			 * failed to get earlier, and re-lock.  That's pretty painful, but
+			 * hopefully shouldn't happen often.
+			 *
+			 * Note that there's a small possibility that we didn't pin the
+			 * page above but still have the correct page pinned anyway,
+			 * either because we've already made a previous pass through this
+			 * loop, or because caller passed us the right page anyway.
+			 *
+			 * Note also that it's possible that by the time we get the pin
+			 * and retake the buffer locks, the visibility map bit will have
+			 * been cleared by some other backend anyway.  In that case, we'll
+			 * have done a bit of extra work for no gain, but there's no real
+			 * harm done.
+			 *
+			 * ZBORKED: Fixme: GetVisibilityMapPins use PageIsAllVisible which
+			 * is not required for zheap, so either we need to rewrite that
+			 * function or somehow avoid the usage of that call.
+			 */
+			if (otherBuffer == InvalidBuffer || targetBlock <= otherBlock)
+				GetVisibilityMapPins(relation, buffer, otherBuffer,
+									 targetBlock, otherBlock, vmbuffer,
+									 vmbuffer_other);
+			else
+				GetVisibilityMapPins(relation, otherBuffer, buffer,
+									 otherBlock, targetBlock, vmbuffer_other,
+									 vmbuffer);
+
+			/*
+			 * Now we can check to see if there's enough free space here. If
+			 * so, we're done.
+			 */
+			page = BufferGetPage(buffer);
+
+			/*
+			 * If necessary initialize page, it'll be used soon.  We could
+			 * avoid dirtying the buffer here, and rely on the caller to do so
+			 * whenever it puts a tuple onto the page, but there seems not
+			 * much benefit in doing so.
+			 */
+			if (PageIsNew(page))
+			{
+				ZheapInitPage(page, BufferGetPageSize(buffer));
+				MarkBufferDirty(buffer);
+			}
+
+			pageFreeSpace = PageGetZHeapFreeSpace(page);
+			if (len + saveFreeSpace <= pageFreeSpace)
+			{
+				/* use this page as future insert target, too */
+				RelationSetTargetBlock(relation, targetBlock);
+				return buffer;
+			}
+		}
+
+		/*
+		 * Not enough space or a tpd page, so we must give up our page locks
+		 * and pin (if any) and prepare to look elsewhere.  We don't care
+		 * which order we unlock the two buffers in, so this can be slightly
+		 * simpler than the code above.
+		 */
+		LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+		if (otherBuffer == InvalidBuffer)
+			ReleaseBuffer(buffer);
+		else if (otherBlock != targetBlock)
+		{
+			if (other_buffer_locked)
+				LockBuffer(otherBuffer, BUFFER_LOCK_UNLOCK);
+			ReleaseBuffer(buffer);
+		}
+
+		/* Without FSM, always fall out of the loop and extend */
+		if (!use_fsm)
+			break;
+
+		/*
+		 * Update FSM as to condition of this page, and ask for another page
+		 * to try.
+		 */
+		targetBlock = RecordAndGetPageWithFreeSpace(relation,
+													targetBlock,
+													pageFreeSpace,
+													len + saveFreeSpace);
+	}
+
+	/*
+	 * Have to extend the relation.
+	 *
+	 * We have to use a lock to ensure no one else is extending the rel at the
+	 * same time, else we will both try to initialize the same new page.  We
+	 * can skip locking for new or temp relations, however, since no one else
+	 * could be accessing them.
+	 */
+	needLock = !RELATION_IS_LOCAL(relation);
+
+	/*
+	 * If we need the lock but are not able to acquire it immediately, we'll
+	 * consider extending the relation by multiple blocks at a time to manage
+	 * contention on the relation extension lock.  However, this only makes
+	 * sense if we're using the FSM; otherwise, there's no point.
+	 */
+	if (needLock)
+	{
+		if (!use_fsm)
+			LockRelationForExtension(relation, ExclusiveLock);
+		else if (!ConditionalLockRelationForExtension(relation, ExclusiveLock))
+		{
+			/* Couldn't get the lock immediately; wait for it. */
+			LockRelationForExtension(relation, ExclusiveLock);
+
+			/*
+			 * Check if some other backend has extended a block for us while
+			 * we were waiting on the lock.
+			 */
+			targetBlock = GetPageWithFreeSpace(relation,
+											   len + saveFreeSpace);
+
+			/*
+			 * If some other waiter has already extended the relation, we
+			 * don't need to do so; just use the existing freespace.
+			 */
+			if (targetBlock != InvalidBlockNumber)
+			{
+				UnlockRelationForExtension(relation, ExclusiveLock);
+				goto loop;
+			}
+
+			/* Time to bulk-extend. */
+			RelationAddExtraBlocks(relation, bistate);
+		}
+	}
+
+	/*
+	 * In addition to whatever extension we performed above, we always add at
+	 * least one block to satisfy our own request.
+	 *
+	 * XXX This does a rather expensive lseek, but at the moment it is the
+	 * only way to accurately determine how many blocks are in a relation.  Is
+	 * it worth keeping an accurate file length in shared memory someplace,
+	 * rather than relying on the kernel to do it for us?
+	 */
+	buffer = ReadBufferBI(relation, P_NEW, RBM_ZERO_AND_LOCK, bistate);
+
+	/*
+	 * We need to initialize the empty new page.  Double-check that it really
+	 * is empty (this should never happen, but if it does we don't want to
+	 * risk wiping out valid data).
+	 */
+	page = BufferGetPage(buffer);
+
+	if (!PageIsNew(page))
+		elog(ERROR, "page %u of relation \"%s\" should be empty but is not",
+			 BufferGetBlockNumber(buffer),
+			 RelationGetRelationName(relation));
+
+	Assert(BufferGetBlockNumber(buffer) != ZHEAP_METAPAGE);
+	ZheapInitPage(page, BufferGetPageSize(buffer));
+	MarkBufferDirty(buffer);
+
+	/*
+	 * Release the file-extension lock; it's now OK for someone else to extend
+	 * the relation some more.
+	 */
+	if (needLock)
+		UnlockRelationForExtension(relation, ExclusiveLock);
+
+	/*
+	 * Lock the other buffer. It's guaranteed to be of a lower page number
+	 * than the new page. To conform with the deadlock prevent rules, we ought
+	 * to lock otherBuffer first, but that would give other backends a chance
+	 * to put tuples on our page. To reduce the likelihood of that, attempt to
+	 * lock the other buffer conditionally, that's very likely to work.
+	 * Otherwise we need to lock buffers in the correct order, and retry if
+	 * the space has been used in the mean time.
+	 *
+	 * Alternatively, we could acquire the lock on otherBuffer before
+	 * extending the relation, but that'd require holding the lock while
+	 * performing IO, which seems worse than an unlikely retry.
+	 */
+	if (otherBuffer != InvalidBuffer)
+	{
+		Assert(otherBuffer != buffer);
+
+		if (unlikely(!ConditionalLockBuffer(otherBuffer)))
+		{
+			LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+			LockBuffer(otherBuffer, BUFFER_LOCK_EXCLUSIVE);
+			LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+
+			/*
+			 * Because the buffer was unlocked for a while, it's possible,
+			 * although unlikely, that the page was filled. If so, just retry
+			 * from start.
+			 */
+			if (len > PageGetHeapFreeSpace(page))
+			{
+				LockBuffer(otherBuffer, BUFFER_LOCK_UNLOCK);
+				UnlockReleaseBuffer(buffer);
+
+				goto loop;
+			}
+		}
+	}
+
+	if (len > PageGetHeapFreeSpace(page))
+	{
+		/* We should not get here given the test at the top */
+		elog(PANIC, "tuple is too big: size %zu", len);
+	}
+
+	/*
+	 * Remember the new page as our target for future insertions.
+	 *
+	 * XXX should we enter the new page into the free space map immediately,
+	 * or just keep it for this backend's exclusive use in the short run
+	 * (until VACUUM sees it)?	Seems to depend on whether you expect the
+	 * current backend to make more insertions or not, which is probably a
+	 * good bet most of the time.  So for now, don't add it to FSM yet.
+	 */
+	RelationSetTargetBlock(relation, BufferGetBlockNumber(buffer));
+
+	return buffer;
+}
diff --git a/src/backend/access/zheap/zmultilocker.c b/src/backend/access/zheap/zmultilocker.c
new file mode 100644
index 0000000..8b47b30
--- /dev/null
+++ b/src/backend/access/zheap/zmultilocker.c
@@ -0,0 +1,780 @@
+/*-------------------------------------------------------------------------
+ *
+ * zmultilocker.c
+ *	  zheap multi locker code
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/zheap/zmultilocker.c
+ *
+ * NOTES
+ *	  This file contains functions for the multi locker facility of zheap.
+ *
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include "access/tpd.h"
+#include "access/xact.h"
+#include "access/zmultilocker.h"
+#include "storage/bufmgr.h"
+#include "storage/buf_internals.h"
+#include "storage/proc.h"
+#include "utils/ztqual.h"
+
+static bool IsZMultiLockListMember(List *members, ZMultiLockMember *mlmember);
+
+/*
+ * ZCurrentXactHasTupleLockMode
+ *
+ * Returns true if the current transaction has a lock in the given mode or
+ * higher on the current tuple.
+ */
+bool
+ZCurrentXactHasTupleLockMode(ZHeapTuple zhtup, UndoRecPtr urec_ptr,
+							 LockTupleMode required_mode)
+{
+	ZHeapTupleHeaderData hdr;
+	UnpackedUndoRecord *urec = NULL;
+	int			trans_slot_id = -1;
+	uint8		uur_type;
+	bool		result = false;
+	LockTupleMode current_mode;
+
+	memcpy(&hdr, zhtup->t_data, SizeofZHeapTupleHeader);
+	do
+	{
+		urec = UndoFetchRecord(urec_ptr,
+							   ItemPointerGetBlockNumber(&zhtup->t_self),
+							   ItemPointerGetOffsetNumber(&zhtup->t_self),
+							   InvalidTransactionId,
+							   NULL,
+							   ZHeapSatisfyUndoRecord);
+
+		/* If undo is discarded, we can't proceed further. */
+		if (!urec)
+			break;
+
+		/* If we encounter a different transaction, we shouldn't go ahead. */
+		if (!TransactionIdIsCurrentTransactionId(urec->uur_xid))
+			break;
+
+		uur_type = urec->uur_type;
+
+		if (uur_type == UNDO_INSERT || uur_type == UNDO_MULTI_INSERT)
+		{
+			/*
+			 * We are done, once we are at the end of current chain.  We
+			 * consider the chain has ended when we reach the root tuple.
+			 */
+			break;
+		}
+
+		trans_slot_id = UpdateTupleHeaderFromUndoRecord(urec, &hdr, NULL);
+
+		if (uur_type == UNDO_XID_LOCK_ONLY ||
+			uur_type == UNDO_XID_LOCK_FOR_UPDATE ||
+			uur_type == UNDO_XID_MULTI_LOCK_ONLY)
+			current_mode = *((LockTupleMode *) urec->uur_payload.data);
+		else if (uur_type == UNDO_UPDATE ||
+				 uur_type == UNDO_INPLACE_UPDATE)
+		{
+			if (ZHEAP_XID_IS_EXCL_LOCKED(hdr.t_infomask))
+				current_mode = LockTupleExclusive;
+			else
+				current_mode = LockTupleNoKeyExclusive;
+		}
+		else if (uur_type == UNDO_DELETE)
+			current_mode = LockTupleExclusive;
+		else
+		{
+			/* Should not reach here */
+			Assert(0);
+		}
+
+		if (current_mode >= required_mode)
+		{
+			result = true;
+			break;
+		}
+
+		if (trans_slot_id == ZHTUP_SLOT_FROZEN)
+		{
+			/*
+			 * We are done, once the undo record suggests that prior record is
+			 * already discarded.
+			 *
+			 * Note that we record the lock mode for all these cases because
+			 * the lock mode stored in undo tuple is for the current
+			 * transaction.
+			 */
+			break;
+		}
+		urec_ptr = urec->uur_blkprev;
+
+		UndoRecordRelease(urec);
+		urec = NULL;
+	} while (UndoRecPtrIsValid(urec_ptr));
+
+	if (urec)
+	{
+		UndoRecordRelease(urec);
+		urec = NULL;
+	}
+
+	return result;
+}
+
+/*
+ * ZGetMultiLockMembers - Return the list of members that have locked a
+ *		particular tuple.
+ *
+ * This function returns the list of in-progress, committed or aborted
+ * transactions.  The purpose of returning committed or aborted transactions
+ * is that some of the callers want to take some specific action for
+ * such transactions if they have updated the tuple.
+ */
+List *
+ZGetMultiLockMembers(Relation rel, ZHeapTuple zhtup, Buffer buf,
+					 bool nobuflock)
+{
+	ZHeapTupleHeaderData hdr;
+	UnpackedUndoRecord *urec = NULL;
+	UndoRecPtr	urec_ptr;
+	ZMultiLockMember *mlmember;
+	List	   *multilockmembers = NIL;
+	TransInfo  *trans_slots = NULL;
+	SubTransactionId subxid = InvalidSubTransactionId;
+	int			prev_trans_slot_id,
+				trans_slot_id;
+	uint8		uur_type;
+	int			slot_no;
+	int			total_trans_slots = 0;
+	BlockNumber tpd_blkno = InvalidBlockNumber;
+	BlockNumber blkno = ItemPointerGetBlockNumber(&zhtup->t_self);
+	OffsetNumber offnum = ItemPointerGetOffsetNumber(&zhtup->t_self);
+
+	if (nobuflock)
+	{
+		ItemId		lp;
+
+		LockBuffer(buf, BUFFER_LOCK_SHARE);
+		lp = PageGetItemId(BufferGetPage(buf), offnum);
+
+		/*
+		 * It is quite possible that once we reacquire the lock on buffer,
+		 * some other backend would have deleted the tuple and in such case,
+		 * we don't need to do anything.  However, the tuple can't be pruned
+		 * because the current snapshot must predates the transaction that
+		 * removes the tuple.
+		 */
+		Assert(!ItemIdIsDead(lp));
+		if (ItemIdIsDeleted(lp))
+		{
+			LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+			return NIL;
+		}
+	}
+
+	trans_slots = GetTransactionsSlotsForPage(rel, buf, &total_trans_slots,
+											  &tpd_blkno);
+
+	if (nobuflock)
+		LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+
+	for (slot_no = 0; slot_no < total_trans_slots; slot_no++)
+	{
+		FullTransactionId epoch_xid = trans_slots[slot_no].fxid;
+
+		/*
+		 * We need to process the undo chain only for in-progress
+		 * transactions.
+		 */
+		if (FullTransactionIdOlderThanAllUndo(epoch_xid))
+			continue;
+
+		urec_ptr = trans_slots[slot_no].urec_ptr;
+		trans_slot_id = slot_no + 1;
+		memcpy(&hdr, zhtup->t_data, SizeofZHeapTupleHeader);
+
+		/*
+		 * If the page contains TPD slots and it's not pruned, the last slot
+		 * contains the information about the corresponding TPD entry. Hence,
+		 * if current slot refers to some TPD slot, we should skip the last
+		 * slot in the page by increasing the slot index by 1.
+		 */
+		if ((trans_slot_id >= ZHEAP_PAGE_TRANS_SLOTS) &&
+			BlockNumberIsValid(tpd_blkno))
+			trans_slot_id += 1;
+
+		do
+		{
+			prev_trans_slot_id = trans_slot_id;
+			urec = UndoFetchRecord(urec_ptr,
+								   blkno,
+								   offnum,
+								   InvalidTransactionId,
+								   NULL,
+								   ZHeapSatisfyUndoRecord);
+
+			/* If undo is discarded, we can't proceed further. */
+			if (!urec)
+				break;
+
+			ZHeapTupleGetSubXid(buf, offnum, urec_ptr, &subxid);
+
+			/*
+			 * Exclude undo records inserted by my own transaction.  We
+			 * neither need to check conflicts with them nor need to wait for
+			 * them.
+			 */
+			if (TransactionIdEquals(urec->uur_xid, GetTopTransactionIdIfAny()))
+			{
+				urec_ptr = urec->uur_blkprev;
+				UndoRecordRelease(urec);
+				urec = NULL;
+				continue;
+			}
+
+			uur_type = urec->uur_type;
+
+			if (uur_type == UNDO_INSERT || uur_type == UNDO_MULTI_INSERT)
+			{
+				/*
+				 * We are done, once we are at the end of current chain.  We
+				 * consider the chain has ended when we reach the root tuple.
+				 */
+				break;
+			}
+
+			trans_slot_id =
+				UpdateTupleHeaderFromUndoRecord(urec, &hdr,
+												BufferGetPage(buf));
+
+			if (uur_type == UNDO_XID_LOCK_ONLY ||
+				uur_type == UNDO_XID_LOCK_FOR_UPDATE ||
+				uur_type == UNDO_XID_MULTI_LOCK_ONLY)
+			{
+				mlmember = (ZMultiLockMember *) palloc(sizeof(ZMultiLockMember));
+				mlmember->xid = urec->uur_xid;
+				mlmember->subxid = subxid;
+				mlmember->trans_slot_id = prev_trans_slot_id;
+				mlmember->mode = *((LockTupleMode *) urec->uur_payload.data);
+				multilockmembers = lappend(multilockmembers, mlmember);
+			}
+			else if (uur_type == UNDO_UPDATE ||
+					 uur_type == UNDO_INPLACE_UPDATE)
+			{
+				mlmember = (ZMultiLockMember *) palloc(sizeof(ZMultiLockMember));
+				mlmember->xid = urec->uur_xid;
+				mlmember->subxid = subxid;
+				mlmember->trans_slot_id = prev_trans_slot_id;
+
+				if (ZHEAP_XID_IS_EXCL_LOCKED(hdr.t_infomask))
+					mlmember->mode = LockTupleExclusive;
+				else
+					mlmember->mode = LockTupleNoKeyExclusive;
+
+				multilockmembers = lappend(multilockmembers, mlmember);
+			}
+			else if (uur_type == UNDO_DELETE)
+			{
+				mlmember = (ZMultiLockMember *) palloc(sizeof(ZMultiLockMember));
+				mlmember->xid = urec->uur_xid;
+				mlmember->subxid = subxid;
+				mlmember->trans_slot_id = prev_trans_slot_id;
+				mlmember->mode = LockTupleExclusive;
+				multilockmembers = lappend(multilockmembers, mlmember);
+			}
+			else
+			{
+				/* Should not reach here */
+				Assert(0);
+			}
+
+			if (trans_slot_id == ZHTUP_SLOT_FROZEN ||
+				trans_slot_id != prev_trans_slot_id)
+			{
+				/*
+				 * We are done, once the undo record suggests that prior
+				 * record is already discarded or the prior record belongs to
+				 * a different transaction slot chain.
+				 */
+				break;
+			}
+
+			/*
+			 * We allow to move backwards in the chain even when we
+			 * encountered undo record of committed transaction
+			 * (ZHeapTupleHasInvalidXact(undo_tup->t_data)).
+			 */
+			urec_ptr = urec->uur_blkprev;
+
+			UndoRecordRelease(urec);
+			urec = NULL;
+		} while (UndoRecPtrIsValid(urec_ptr));
+
+		if (urec)
+		{
+			UndoRecordRelease(urec);
+			urec = NULL;
+		}
+	}
+
+	/* be tidy */
+	pfree(trans_slots);
+
+	return multilockmembers;
+}
+
+/*
+ * ZMultiLockMembersWait - Wait for all the members to end.
+ *
+ * This function also applies the undo actions for aborted transactions.
+ */
+bool
+ZMultiLockMembersWait(Relation rel, List *mlmembers, ZHeapTuple zhtup,
+					  Buffer buf, TransactionId update_xact,
+					  LockTupleMode required_mode, bool nowait,
+					  XLTW_Oper oper, int *remaining, bool *upd_xact_aborted)
+{
+	bool		result = true;
+	ListCell   *lc;
+	BufferDesc *bufhdr PG_USED_FOR_ASSERTS_ONLY;
+	int			remain = 0;
+
+	bufhdr = GetBufferDescriptor(buf - 1);
+	/* buffer must be unlocked */
+	Assert(!LWLockHeldByMe(BufferDescriptorGetContentLock(bufhdr)));
+
+	*upd_xact_aborted = false;
+
+	foreach(lc, mlmembers)
+	{
+		ZMultiLockMember *mlmember = (ZMultiLockMember *) lfirst(lc);
+		TransactionId memxid = mlmember->xid;
+		SubTransactionId memsubxid = mlmember->subxid;
+		LockTupleMode memmode = mlmember->mode;
+
+		if (TransactionIdIsCurrentTransactionId(memxid))
+		{
+			remain++;
+			continue;
+		}
+
+		if (!DoLockModesConflict(HWLOCKMODE_from_locktupmode(memmode),
+								 HWLOCKMODE_from_locktupmode(required_mode)))
+		{
+			if (remaining && TransactionIdIsInProgress(memxid))
+				remain++;
+			continue;
+		}
+
+		/*
+		 * This member conflicts with our multi, so we have to sleep (or
+		 * return failure, if asked to avoid waiting.)
+		 */
+		if (memsubxid != InvalidSubTransactionId)
+		{
+			if (nowait)
+			{
+				result = ConditionalSubXactLockTableWait(memxid, memsubxid);
+				if (!result)
+					break;
+			}
+			else
+				SubXactLockTableWait(memxid, memsubxid, rel, &zhtup->t_self,
+									 oper);
+		}
+		else if (nowait)
+		{
+			result = ConditionalXactLockTableWait(memxid);
+			if (!result)
+				break;
+		}
+		else
+			XactLockTableWait(memxid, rel, &zhtup->t_self, oper);
+
+		/*
+		 * For aborted transaction, if the undo actions are not applied yet,
+		 * then apply them before modifying the page.
+		 */
+		if (TransactionIdDidAbort(memxid))
+		{
+			LockBuffer(buf, BUFFER_LOCK_SHARE);
+			zheap_exec_pending_rollback(rel, buf, mlmember->trans_slot_id,
+										memxid, NULL);
+			LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+
+			if (TransactionIdIsValid(update_xact) && memxid == update_xact)
+				*upd_xact_aborted = true;
+		}
+	}
+
+	if (remaining)
+		*remaining = remain;
+
+	return result;
+}
+
+/*
+ * ConditionalZMultiLockMembersWait
+ *		As above, but only lock if we can get the lock without blocking.
+ */
+bool
+ConditionalZMultiLockMembersWait(Relation rel, List *mlmembers,
+								 Buffer buf, TransactionId update_xact,
+								 LockTupleMode required_mode, int *remaining,
+								 bool *upd_xact_aborted)
+{
+	return ZMultiLockMembersWait(rel, mlmembers, NULL, buf, update_xact,
+								 required_mode, true, XLTW_None, remaining,
+								 upd_xact_aborted);
+}
+
+/*
+ * ZIsAnyMultiLockMemberRunning - Check if any multi lock member is running.
+ *
+ * Returns true, if any member of the multi lock is running, false otherwise.
+ *
+ * Unlike heap, we don't consider current transaction's lockers to decide
+ * if the lockers of multi lock are running. In heap, any lock taken by
+ * subtransaction is recorded separately in the multixact, so that it can
+ * detect if the subtransaction is rolled back. Now as the lock information
+ * is tracked at subtransaction level, we can't ignore the lockers for
+ * subtransactions of current top-level transaction. For zheap, rollback to
+ * subtransaction will rewind the undo and the lockers information will
+ * be automatically removed, so we don't need to track subtransaction lockers
+ * separately and hence we can ignore lockers of current top-level
+ * transaction.
+ */
+bool
+ZIsAnyMultiLockMemberRunning(Relation rel, int xwait_trans_slot,
+							 List *mlmembers, ZHeapTuple zhtup, Buffer buf,
+							 bool *pending_actions_applied)
+{
+	ListCell   *lc;
+	BufferDesc *bufhdr PG_USED_FOR_ASSERTS_ONLY;
+
+	bufhdr = GetBufferDescriptor(buf - 1);
+
+	/*
+	 * Local buffers can't be accessed by other sessions.
+	 */
+	if (BufferIsLocal(buf))
+		return false;
+
+	/* buffer must be locked by caller */
+	Assert(LWLockHeldByMe(BufferDescriptorGetContentLock(bufhdr)));
+
+	if (list_length(mlmembers) <= 0)
+	{
+		elog(DEBUG2, "ZIsRunning: no members");
+		return false;
+	}
+
+	foreach(lc, mlmembers)
+	{
+		ZMultiLockMember *mlmember = (ZMultiLockMember *) lfirst(lc);
+		TransactionId memxid = mlmember->xid;
+
+		if (TransactionIdIsInProgress(memxid))
+		{
+			elog(DEBUG2, "ZIsRunning: member %d is running", memxid);
+			return true;
+		}
+		else if (TransactionIdDidAbort(memxid))
+		{
+			bool		action_applied;
+
+			action_applied = zheap_exec_pending_rollback(rel, buf,
+														 xwait_trans_slot,
+														 memxid,
+														 NULL);
+
+			/*
+			 * If actions are applied, then set pending_actions_applied flag
+			 * so that the caller can identify that buffer lock is reacquired.
+			 */
+			if (action_applied && !*pending_actions_applied)
+				*pending_actions_applied = true;
+		}
+	}
+
+	elog(DEBUG2, "ZIsRunning: no members are running");
+
+	return false;
+}
+
+/*
+ * IsZMultiLockListMember - Returns true iff mlmember is a member of list
+ *	members.  Equality is determined by comparing all the variables of
+ *	member.
+ */
+static bool
+IsZMultiLockListMember(List *members, ZMultiLockMember *mlmember)
+{
+	ListCell   *lc;
+
+	foreach(lc, members)
+	{
+		ZMultiLockMember *lc_member = (ZMultiLockMember *) lfirst(lc);
+
+		if (lc_member->xid == mlmember->xid &&
+			lc_member->trans_slot_id == mlmember->trans_slot_id &&
+			lc_member->mode == mlmember->mode)
+			return true;
+	}
+
+	return false;
+}
+
+/*
+ * ZMultiLockMembersSame -  Returns true, iff all the members in list2 list
+ *	are present in list1 list
+ */
+bool
+ZMultiLockMembersSame(List *list1, List *list2)
+{
+	ListCell   *lc;
+
+	if (list_length(list2) > list_length(list1))
+		return false;
+
+	foreach(lc, list2)
+	{
+		ZMultiLockMember *mlmember = (ZMultiLockMember *) lfirst(lc);
+
+		if (!IsZMultiLockListMember(list1, mlmember))
+			return false;
+	}
+
+	return true;
+}
+
+/*
+ * ZGetMultiLockInfo - Helper function for compute_new_xid_infomask to
+ *	get the multi lockers information.
+ */
+void
+ZGetMultiLockInfo(uint16 old_infomask, TransactionId tup_xid,
+				  int tup_trans_slot, TransactionId add_to_xid,
+				  uint16 *new_infomask, int *new_trans_slot,
+				  LockTupleMode *mode, bool *old_tuple_has_update,
+				  LockOper lockoper)
+{
+	LockTupleMode old_mode;
+
+	old_mode = get_old_lock_mode(old_infomask);
+
+	if (tup_xid == add_to_xid)
+	{
+		if (ZHeapTupleHasMultiLockers(old_infomask))
+			*new_infomask |= ZHEAP_MULTI_LOCKERS;
+
+		/* acquire the strongest of both */
+		if (*mode < old_mode)
+			*mode = old_mode;
+	}
+	else
+	{
+		*new_infomask |= ZHEAP_MULTI_LOCKERS;
+
+		/*
+		 * Acquire the strongest of both and keep the transaction slot of the
+		 * stronger lock.
+		 */
+		if (*mode < old_mode)
+		{
+			*mode = old_mode;
+		}
+
+		/* For lockers, we want to store the updater's transaction slot. */
+		if (lockoper != ForUpdate)
+			*new_trans_slot = tup_trans_slot;
+	}
+
+	/*
+	 * We want to propagate the updaters information for lockers only provided
+	 * the tuple is already locked by others (aka it has its multi-locker bit
+	 * set).
+	 */
+	if (lockoper != ForUpdate &&
+		ZHeapTupleHasMultiLockers(*new_infomask) &&
+		IsZHeapTupleModified(old_infomask) &&
+		!ZHEAP_XID_IS_LOCKED_ONLY(old_infomask))
+	{
+		*old_tuple_has_update = true;
+
+		if (ZHeapTupleIsInPlaceUpdated(old_infomask))
+		{
+			*new_infomask |= ZHEAP_INPLACE_UPDATED;
+		}
+		else
+		{
+			Assert(ZHeapTupleIsUpdated(old_infomask));
+			*new_infomask |= ZHEAP_UPDATED;
+		}
+	}
+}
+
+/*
+ * GetLockerTransInfo - Retrieve the transaction information of single locker
+ * from undo.
+ *
+ * If the locker is already committed or too-old, we consider as if it didn't
+ * exist at all.
+ *
+ * The caller must have a lock on the buffer (buf).
+ */
+bool
+GetLockerTransInfo(Relation rel, ItemPointer tid, Buffer buf,
+				   int *trans_slot, FullTransactionId *fxid_out)
+{
+	UnpackedUndoRecord *urec = NULL;
+	UndoRecPtr	urec_ptr;
+	TransInfo  *trans_slots = NULL;
+	FullTransactionId fxid;
+	FullTransactionId oldestXidWithEpochHavingUndo;
+	int			trans_slot_id;
+	uint8		uur_type;
+	int			slot_no;
+	int			total_trans_slots = 0;
+	bool		found = false;
+	BlockNumber tpd_blkno;
+
+	oldestXidWithEpochHavingUndo = FullTransactionIdFromU64(
+															pg_atomic_read_u64(&ProcGlobal->oldestFullXidHavingUnappliedUndo));
+	trans_slots = GetTransactionsSlotsForPage(rel, buf, &total_trans_slots,
+											  &tpd_blkno);
+
+	for (slot_no = 0; slot_no < total_trans_slots; slot_no++)
+	{
+		TransactionId xid;
+
+		fxid = trans_slots[slot_no].fxid;
+		xid = XidFromFullTransactionId(fxid);
+
+		/*
+		 * We need to process the undo chain only for in-progress
+		 * transactions.
+		 */
+		if (FullTransactionIdPrecedes(fxid, oldestXidWithEpochHavingUndo) ||
+			(!TransactionIdIsInProgress(xid) && TransactionIdDidCommit(xid)))
+			continue;
+
+		urec_ptr = trans_slots[slot_no].urec_ptr;
+
+		do
+		{
+			UndoRecPtr	out_urec_ptr PG_USED_FOR_ASSERTS_ONLY;
+
+			out_urec_ptr = InvalidUndoRecPtr;
+			urec = UndoFetchRecord(urec_ptr,
+								   ItemPointerGetBlockNumber(tid),
+								   ItemPointerGetOffsetNumber(tid),
+								   InvalidTransactionId,
+								   &out_urec_ptr,
+								   ZHeapSatisfyUndoRecord);
+
+			/*
+			 * We couldn't find any undo record for the tuple corresponding to
+			 * current slot.
+			 */
+			if (urec == NULL)
+			{
+				/* Make sure we've reached the end of current undo chain. */
+				Assert(!out_urec_ptr);
+				break;
+			}
+
+			/*
+			 * If the current transaction has locked the tuple, then we don't
+			 * need to process the undo records.
+			 */
+			if (TransactionIdEquals(urec->uur_xid, GetTopTransactionIdIfAny()))
+			{
+				found = true;
+				break;
+			}
+
+			uur_type = urec->uur_type;
+
+			if (uur_type == UNDO_INSERT || uur_type == UNDO_MULTI_INSERT)
+			{
+				/*
+				 * We are done, once we are at the end of current chain.  We
+				 * consider the chain has ended when we reach the root tuple.
+				 */
+				break;
+			}
+
+			if (uur_type == UNDO_XID_LOCK_ONLY ||
+				uur_type == UNDO_XID_LOCK_FOR_UPDATE)
+			{
+				found = true;
+				break;
+			}
+
+			if (xid != urec->uur_xid)
+			{
+				/*
+				 * We are done, once the undo record suggests that prior tuple
+				 * version is modified by a different transaction.
+				 */
+				break;
+			}
+
+			urec_ptr = urec->uur_blkprev;
+
+			UndoRecordRelease(urec);
+			urec = NULL;
+		} while (UndoRecPtrIsValid(urec_ptr));
+
+		if (urec)
+		{
+			UndoRecordRelease(urec);
+			urec = NULL;
+		}
+
+		if (found)
+		{
+			/* Transaction slots in the page start from 1. */
+			trans_slot_id = slot_no + 1;
+
+			/*
+			 * If the page contains TPD slots and it's not pruned, the last
+			 * slot contains the information about the corresponding TPD
+			 * entry. Hence, if current slot refers to some TPD slot, we
+			 * should skip the last slot in the page by increasing the slot
+			 * index by 1.
+			 */
+			if ((trans_slot_id >= ZHEAP_PAGE_TRANS_SLOTS) &&
+				BlockNumberIsValid(tpd_blkno))
+				trans_slot_id += 1;
+
+			break;
+		}
+	}
+
+	/* be tidy */
+	pfree(trans_slots);
+
+	/*
+	 * If found, we return the corresponding transaction information. Else, we
+	 * return the same information as passed as arguments.
+	 */
+	if (found)
+	{
+		/* Set the value of required parameters. */
+		if (trans_slot)
+			*trans_slot = trans_slot_id;
+		if (fxid_out)
+			*fxid_out = fxid;
+	}
+
+	return found;
+}
diff --git a/src/backend/access/zheap/zpage.c b/src/backend/access/zheap/zpage.c
new file mode 100644
index 0000000..d9dcea8
--- /dev/null
+++ b/src/backend/access/zheap/zpage.c
@@ -0,0 +1,596 @@
+/*-------------------------------------------------------------------------
+ *
+ * zpage.c
+ *	  Routines to operate on a zheap page.
+ *
+ * The zheap page consists of the page header, line pointer array, tuples and
+ * transaction slots.  The line pointer array grows from top to down and
+ * tuples grow from bottom to up.  There is a fixed transaction slot array
+ * in the special space.  In the future, we want this array to be of variable
+ * length.
+ *
+ * zheap tuples are not MAXALIGN'd as PageAddItemExtended would do, but are
+ * instead aligned only on 2-byte boundaries.  This is sufficient to access
+ * the tuple header without copying the data, since there's nothing in the
+ * tuple header wider than a uint16.  The tuple data is always copied
+ * before we access it (since otherwise in-place updates would be difficut
+ * to implement).
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/zheap/zpage.c
+ *
+ *-------------------------------------------------------------------------
+ */
+
+#include "postgres.h"
+
+#include "access/tpd.h"
+#include "miscadmin.h"
+#include "utils/memdebug.h"
+#include "utils/ztqual.h"
+
+/*
+ * ZPageAddItemExtended - Add an item to a zheap page.
+ *
+ * This is similar to PageAddItemExtended except for max tuples that can be
+ * accommodated on a page and alignment for each item (Ideally, we don't need
+ * to align space between tuples as we always make the copy of tuple to
+ * support in-place updates.  However, there are places in zheap code where
+ * we access tuple header directly from page (e.g. zheap_delete, zheap_update,
+ * etc.) for which we them to be aligned at two-byte boundary). It
+ * additionally handles the itemids that are marked as unused, but still
+ * can't be reused.
+ *
+ * Callers passed a valid input_page only in case there are constructing the
+ * in-memory copy of tuples and then directly sync the page.
+ */
+OffsetNumber
+ZPageAddItemExtended(Buffer buffer,
+					 Page input_page,
+					 Item item,
+					 Size size,
+					 OffsetNumber offsetNumber,
+					 int flags,
+					 bool NoTPDBufLock)
+{
+	Page		page;
+	Size		alignedSize;
+	PageHeader	phdr;
+	int			lower;
+	int			upper;
+	ItemId		itemId;
+	OffsetNumber limit;
+	bool		needshuffle = false;
+
+	/* Either one of buffer or page could be valid. */
+	if (BufferIsValid(buffer))
+	{
+		Assert(!PageIsValid(input_page));
+		page = BufferGetPage(buffer);
+	}
+	else
+	{
+		Assert(PageIsValid(input_page));
+		page = input_page;
+	}
+
+	phdr = (PageHeader) page;
+
+	/*
+	 * Be wary about corrupted page pointers
+	 */
+	if (phdr->pd_lower < SizeOfPageHeaderData ||
+		phdr->pd_lower > phdr->pd_upper ||
+		phdr->pd_upper > phdr->pd_special ||
+		phdr->pd_special > BLCKSZ)
+		ereport(PANIC,
+				(errcode(ERRCODE_DATA_CORRUPTED),
+				 errmsg("corrupted page pointers: lower = %u, upper = %u, special = %u",
+						phdr->pd_lower, phdr->pd_upper, phdr->pd_special)));
+
+	/*
+	 * Select offsetNumber to place the new item at
+	 */
+	limit = OffsetNumberNext(PageGetMaxOffsetNumber(page));
+
+	/* was offsetNumber passed in? */
+	if (OffsetNumberIsValid(offsetNumber))
+	{
+		/* yes, check it */
+		if ((flags & PAI_OVERWRITE) != 0)
+		{
+			if (offsetNumber < limit)
+			{
+				itemId = PageGetItemId(phdr, offsetNumber);
+				if (ItemIdIsUsed(itemId) || ItemIdHasStorage(itemId))
+				{
+					elog(WARNING, "will not overwrite a used ItemId");
+					return InvalidOffsetNumber;
+				}
+			}
+		}
+		else
+		{
+			if (offsetNumber < limit)
+				needshuffle = true; /* need to move existing linp's */
+		}
+	}
+	else
+	{
+		/* offsetNumber was not passed in, so find a free slot */
+		/* if no free slot, we'll put it at limit (1st open slot) */
+		if (PageHasFreeLinePointers(phdr))
+		{
+			bool		hasPendingXact = false;
+
+			/*
+			 * Look for "recyclable" (unused) ItemId.  We check for no storage
+			 * as well, just to be paranoid --- unused items should never have
+			 * storage.
+			 */
+			for (offsetNumber = 1; offsetNumber < limit; offsetNumber++)
+			{
+				itemId = PageGetItemId(phdr, offsetNumber);
+				if (!ItemIdIsUsed(itemId) && !ItemIdHasStorage(itemId))
+				{
+					/*
+					 * We allow Unused entries to be reused only if there is
+					 * no transaction information for the entry or the
+					 * transaction is committed.
+					 */
+					if (ItemIdHasPendingXact(itemId))
+					{
+						ZHeapTupleTransInfo zinfo;
+
+						zinfo.trans_slot = ItemIdGetTransactionSlot(itemId);
+
+						/*
+						 * We can't reach here for a valid input page as the
+						 * callers passed it for the pages that wouldn't have
+						 * been pruned.
+						 */
+						Assert(!PageIsValid(input_page));
+
+						/*
+						 * Here, we are relying on the transaction information
+						 * in slot as if the corresponding slot has been
+						 * reused, then transaction information from the entry
+						 * would have been cleared.  See PageFreezeTransSlots.
+						 */
+						if (zinfo.trans_slot == ZHTUP_SLOT_FROZEN)
+							break;
+						GetTransactionSlotInfo(buffer, offsetNumber,
+											   zinfo.trans_slot, NoTPDBufLock,
+											   false, &zinfo);
+
+						/*
+						 * It is quite possible that the item is showing some
+						 * valid transaction slot, but actual slot has been
+						 * frozen. This can happen when the slot belongs to
+						 * TPD entry and the corresponding TPD entry is
+						 * pruned.
+						 */
+						if (zinfo.trans_slot == ZHTUP_SLOT_FROZEN)
+							break;
+						if (TransactionIdIsValid(zinfo.xid) &&
+							!TransactionIdDidCommit(zinfo.xid))
+						{
+							hasPendingXact = true;
+							continue;
+						}
+					}
+					break;
+				}
+			}
+			if (offsetNumber >= limit && !hasPendingXact)
+			{
+				/* the hint is wrong, so reset it */
+				PageClearHasFreeLinePointers(phdr);
+			}
+		}
+		else
+		{
+			/* don't bother searching if hint says there's no free slot */
+			offsetNumber = limit;
+		}
+	}
+
+	/* Reject placing items beyond the first unused line pointer */
+	if (offsetNumber > limit)
+	{
+		elog(WARNING, "specified item offset is too large");
+		return InvalidOffsetNumber;
+	}
+
+	/* Reject placing items beyond heap boundary, if heap */
+	if ((flags & PAI_IS_HEAP) != 0 && offsetNumber > MaxZHeapTuplesPerPage)
+	{
+		elog(WARNING, "can't put more than MaxZHeapTuplesPerPage items in a heap page");
+		return InvalidOffsetNumber;
+	}
+
+	/*
+	 * Compute new lower and upper pointers for page, see if it'll fit.
+	 *
+	 * Note: do arithmetic as signed ints, to avoid mistakes if, say, size >
+	 * pd_upper.
+	 */
+	if (offsetNumber == limit || needshuffle)
+		lower = phdr->pd_lower + sizeof(ItemIdData);
+	else
+		lower = phdr->pd_lower;
+
+	alignedSize = SHORTALIGN(size);
+
+	upper = (int) phdr->pd_upper - (int) alignedSize;
+
+	if (lower > upper)
+		return InvalidOffsetNumber;
+
+	/*
+	 * OK to insert the item.  First, shuffle the existing pointers if needed.
+	 */
+	itemId = PageGetItemId(phdr, offsetNumber);
+
+	if (needshuffle)
+		memmove(itemId + 1, itemId,
+				(limit - offsetNumber) * sizeof(ItemIdData));
+
+	/* set the item pointer */
+	ItemIdSetNormal(itemId, upper, size);
+
+	/*
+	 * Items normally contain no uninitialized bytes.  Core bufpage consumers
+	 * conform, but this is not a necessary coding rule; a new index AM could
+	 * opt to depart from it.  However, data type input functions and other
+	 * C-language functions that synthesize datums should initialize all
+	 * bytes; datumIsEqual() relies on this.  Testing here, along with the
+	 * similar check in printtup(), helps to catch such mistakes.
+	 *
+	 * Values of the "name" type retrieved via index-only scans may contain
+	 * uninitialized bytes; see comment in btrescan().  Valgrind will report
+	 * this as an error, but it is safe to ignore.
+	 */
+	VALGRIND_CHECK_MEM_IS_DEFINED(item, size);
+
+	/* copy the item's data onto the page */
+	memcpy((char *) page + upper, item, size);
+
+	/* adjust page header */
+	phdr->pd_lower = (LocationIndex) lower;
+	phdr->pd_upper = (LocationIndex) upper;
+
+	return offsetNumber;
+}
+
+/*
+ * PageGetZHeapFreeSpace
+ *		Returns the size of the free (allocatable) space on a zheap page,
+ *		reduced by the space needed for a new line pointer.
+ *
+ * This is same as PageGetHeapFreeSpace except for max tuples that can
+ * be accommodated on a page or the way unused items are dealt.
+ */
+Size
+PageGetZHeapFreeSpace(Page page)
+{
+	Size		space;
+
+	space = PageGetFreeSpace(page);
+	if (space > 0)
+	{
+		OffsetNumber offnum,
+					nline;
+
+		nline = PageGetMaxOffsetNumber(page);
+		if (nline >= MaxZHeapTuplesPerPage)
+		{
+			if (PageHasFreeLinePointers((PageHeader) page))
+			{
+				/*
+				 * Since this is just a hint, we must confirm that there is
+				 * indeed a free line pointer
+				 */
+				for (offnum = FirstOffsetNumber; offnum <= nline; offnum = OffsetNumberNext(offnum))
+				{
+					ItemId		lp = PageGetItemId(page, offnum);
+
+					/*
+					 * The unused items that have pending xact information
+					 * can't be reused.
+					 */
+					if (!ItemIdIsUsed(lp) && !ItemIdHasPendingXact(lp))
+						break;
+				}
+
+				if (offnum > nline)
+				{
+					/*
+					 * The hint is wrong, but we can't clear it here since we
+					 * don't have the ability to mark the page dirty.
+					 */
+					space = 0;
+				}
+			}
+			else
+			{
+				/*
+				 * Although the hint might be wrong, PageAddItem will believe
+				 * it anyway, so we must believe it too.
+				 */
+				space = 0;
+			}
+		}
+	}
+	return space;
+}
+
+/*
+ * RelationPutZHeapTuple - Same as RelationPutHeapTuple, but for ZHeapTuple.
+ */
+void
+RelationPutZHeapTuple(Relation relation,
+					  Buffer buffer,
+					  ZHeapTuple tuple)
+{
+	OffsetNumber offnum;
+
+	/* Add the tuple to the page.  Caller must ensure to have a TPD page lock. */
+	offnum = ZPageAddItem(buffer, NULL, (Item) tuple->t_data, tuple->t_len,
+						  InvalidOffsetNumber, false, true, false);
+
+	if (offnum == InvalidOffsetNumber)
+		elog(PANIC, "failed to add tuple to page");
+
+	/* Update tuple->t_self to the actual position where it was stored */
+	ItemPointerSet(&(tuple->t_self), BufferGetBlockNumber(buffer), offnum);
+}
+
+/*
+ * ZHeapGetUsableOffsetRanges
+ *
+ * Given a page and a set of tuples, it calculates how many tuples can fit in
+ * the page and the contiguous ranges of free offsets that can be used/reused
+ * in the same page to store those tuples.
+ */
+ZHeapFreeOffsetRanges *
+ZHeapGetUsableOffsetRanges(Buffer buffer,
+						   ZHeapTuple *tuples,
+						   int ntuples,
+						   Size saveFreeSpace)
+{
+	Page		page;
+	PageHeader	phdr;
+	int			nthispage;
+	Size		used_space;
+	Size		avail_space;
+	OffsetNumber limit,
+				offsetNumber;
+	ZHeapFreeOffsetRanges *zfree_offset_ranges;
+
+	page = BufferGetPage(buffer);
+	phdr = (PageHeader) page;
+
+	zfree_offset_ranges = (ZHeapFreeOffsetRanges *)
+		palloc0(sizeof(ZHeapFreeOffsetRanges));
+
+	zfree_offset_ranges->nranges = 0;
+	limit = OffsetNumberNext(PageGetMaxOffsetNumber(page));
+	avail_space = PageGetExactFreeSpace(page);
+	nthispage = 0;
+	used_space = 0;
+
+	if (PageHasFreeLinePointers(phdr))
+	{
+		bool		in_range = false;
+
+		/*
+		 * Look for "recyclable" (unused) ItemId.  We check for no storage as
+		 * well, just to be paranoid --- unused items should never have
+		 * storage.
+		 */
+		for (offsetNumber = 1; offsetNumber < limit; offsetNumber++)
+		{
+			ItemId		itemId = PageGetItemId(phdr, offsetNumber);
+
+			if (nthispage >= ntuples)
+			{
+				/* No more tuples to insert */
+				break;
+			}
+			if (!ItemIdIsUsed(itemId) && !ItemIdHasStorage(itemId))
+			{
+				ZHeapTuple	zheaptup = tuples[nthispage];
+				Size		needed_space = used_space + zheaptup->t_len + saveFreeSpace;
+
+				/* Check if we can fit this tuple in the page */
+				if (avail_space < needed_space)
+				{
+					/* No more space to insert tuples in this page */
+					break;
+				}
+
+				used_space += zheaptup->t_len;
+				nthispage++;
+
+				if (!in_range)
+				{
+					/* Start of a new range */
+					zfree_offset_ranges->nranges++;
+					zfree_offset_ranges->startOffset[zfree_offset_ranges->nranges - 1] = offsetNumber;
+					in_range = true;
+				}
+				zfree_offset_ranges->endOffset[zfree_offset_ranges->nranges - 1] = offsetNumber;
+			}
+			else
+			{
+				in_range = false;
+			}
+		}
+	}
+
+	/*
+	 * Now, there are no free line pointers. Check whether we can insert
+	 * another tuple in the page, then we'll insert another range starting
+	 * from limit to max required offset number. We can decide the actual end
+	 * offset for this range while inserting tuples in the buffer.
+	 */
+	if ((limit <= MaxZHeapTuplesPerPage) && (nthispage < ntuples))
+	{
+		ZHeapTuple	zheaptup = tuples[nthispage];
+		Size		needed_space = used_space + sizeof(ItemIdData) +
+		zheaptup->t_len + saveFreeSpace;
+
+		/* Check if we can fit this tuple + a new offset in the page */
+		if (avail_space >= needed_space)
+		{
+			OffsetNumber max_required_offset;
+			int			required_tuples = ntuples - nthispage;
+
+			/*
+			 * Choose minimum among MaxOffsetNumber and the maximum offsets
+			 * required for tuples.
+			 */
+			max_required_offset = Min(MaxOffsetNumber, (limit + required_tuples));
+
+			zfree_offset_ranges->nranges++;
+			zfree_offset_ranges->startOffset[zfree_offset_ranges->nranges - 1] = limit;
+			zfree_offset_ranges->endOffset[zfree_offset_ranges->nranges - 1] = max_required_offset;
+		}
+	}
+
+	return zfree_offset_ranges;
+}
+
+/*
+ * Initialize zheap page.
+ */
+void
+ZheapInitPage(Page page, Size pageSize)
+{
+	ZHeapPageOpaque opaque;
+	TransInfo  *thistrans;
+	int			i;
+
+	/*
+	 * The size of the opaque space depends on the number of transaction slots
+	 * in a page. We set it to default here.
+	 */
+	PageInit(page, pageSize, ZHEAP_PAGE_TRANS_SLOTS * sizeof(TransInfo));
+
+	opaque = (ZHeapPageOpaque) PageGetSpecialPointer(page);
+
+	for (i = 0; i < ZHEAP_PAGE_TRANS_SLOTS; i++)
+	{
+		thistrans = &opaque->transinfo[i];
+		thistrans->fxid = InvalidFullTransactionId;
+		thistrans->urec_ptr = InvalidUndoRecPtr;
+	}
+}
+
+/*
+ * ZheapInitMetaPage - Allocate and initialize the zheap metapage.
+ *
+ * If already_exists is true, we allocate a new zheap metapage else we
+ * re-initialize the existing metapage.
+ */
+void
+ZheapInitMetaPage(RelFileNode rnode, ForkNumber forkNum,
+				  char persistence, bool already_exists)
+{
+	Buffer		buf;
+	bool		use_wal;
+
+	buf = ReadBufferWithoutRelcache(SMGR_MD, rnode, forkNum,
+									already_exists ? ZHEAP_METAPAGE : P_NEW,
+									RBM_NORMAL, NULL, persistence);
+	if (BufferGetBlockNumber(buf) != ZHEAP_METAPAGE)
+		elog(ERROR, "unexpected zheap metapage block number: %u, should be %u",
+			 BufferGetBlockNumber(buf), ZHEAP_METAPAGE);
+
+	LockBuffer(buf, BUFFER_LOCK_EXCLUSIVE);
+
+	START_CRIT_SECTION();
+
+	zheap_init_meta_page(buf, InvalidBlockNumber, InvalidBlockNumber);
+	MarkBufferDirty(buf);
+
+	/*
+	 * WAL log creation of metapage if the relation is persistent, or this is
+	 * the init fork.  Init forks for unlogged relations always need to be WAL
+	 * logged.
+	 */
+	use_wal = persistence == RELPERSISTENCE_PERMANENT ||
+		forkNum == INIT_FORKNUM;
+
+	if (use_wal)
+		log_newpage_buffer(buf, true);
+
+	END_CRIT_SECTION();
+
+	UnlockReleaseBuffer(buf);
+}
+
+/*
+ * zheap_init_meta_page - Initialize the metapage.
+ */
+void
+zheap_init_meta_page(Buffer metabuf, BlockNumber first_blkno,
+					 BlockNumber last_blkno)
+{
+	ZHeapMetaPage metap;
+	Page		page;
+
+	page = BufferGetPage(metabuf);
+	PageInit(page, BufferGetPageSize(metabuf), 0);
+
+	metap = ZHeapPageGetMeta(page);
+	metap->zhm_magic = ZHEAP_MAGIC;
+	metap->zhm_version = ZHEAP_VERSION;
+	metap->zhm_first_used_tpd_page = first_blkno;
+	metap->zhm_last_used_tpd_page = last_blkno;
+
+	/*
+	 * Set pd_lower just past the end of the metadata.  This is essential,
+	 * because without doing so, metadata will be lost if xlog.c compresses
+	 * the page.
+	 */
+	((PageHeader) page)->pd_lower =
+		((char *) metap + sizeof(ZHeapMetaPageData)) - (char *) page;
+}
+
+/*
+ * zheap_gettuple
+ *
+ * Copy a raw tuple from a zheap page, forming a ZHeapTuple.
+ */
+ZHeapTuple
+zheap_gettuple(Relation relation, Buffer buffer, OffsetNumber offnum)
+{
+	Page		dp;
+	ItemId		lp;
+	Size		tuple_len;
+	ZHeapTupleHeader item;
+	ZHeapTuple	tuple;
+
+	dp = BufferGetPage(buffer);
+	lp = PageGetItemId(dp, offnum);
+
+	Assert(offnum >= FirstOffsetNumber && offnum <= PageGetMaxOffsetNumber(dp));
+	Assert(ItemIdIsNormal(lp));
+
+	tuple_len = ItemIdIsDeleted(lp) ? 0 : ItemIdGetLength(lp);
+	tuple = palloc(ZHEAPTUPLESIZE + tuple_len);
+	tuple->t_tableOid = RelationGetRelid(relation);
+	tuple->t_len = tuple_len;
+	ItemPointerSet(&tuple->t_self, BufferGetBlockNumber(buffer), offnum);
+	item = (ZHeapTupleHeader) PageGetItem(dp, lp);
+	tuple->t_data = (ZHeapTupleHeader) ((char *) tuple + ZHEAPTUPLESIZE);
+	memcpy(tuple->t_data, item, tuple_len);
+
+	return tuple;
+}
diff --git a/src/backend/access/zheap/zscan.c b/src/backend/access/zheap/zscan.c
new file mode 100644
index 0000000..c51caaa
--- /dev/null
+++ b/src/backend/access/zheap/zscan.c
@@ -0,0 +1,1543 @@
+/*-------------------------------------------------------------------------
+ *
+ * zscan.c
+ *	  Routines to scan zheap data pages.
+ *
+ * This file provides API's to scan the zheap page and get the tuples.  Zheap
+ * contains different kind of meta pages (like meta and tpd pages) which
+ * doesn't have tuples, so we need to always skip them during scan.
+ *
+ * Unlike heap, we always need to make a copy of zheap tuple before releasing
+ * the containing buffer as an in-place update can change the tuple.
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/zheap/zscan.c
+ *
+ *-------------------------------------------------------------------------
+ */
+
+#include "postgres.h"
+
+#include "access/tableam.h"
+#include "access/tpd.h"
+#include "access/visibilitymap.h"
+#include "access/zheapscan.h"
+#include "miscadmin.h"
+#include "nodes/tidbitmap.h"
+#include "pgstat.h"
+#include "storage/predicate.h"
+#include "utils/ztqual.h"
+
+/*
+ * ZBORKED: don't want to include heapam.h to avoid mistakes - the syncscan
+ * stuff should probably be moved to a different header.
+ */
+extern BlockNumber ss_get_location(Relation rel, BlockNumber relnblocks);
+extern void ss_report_location(Relation rel, BlockNumber location);
+
+/*
+ * zinitscan - same as initscan except for tuple initialization
+ */
+static void
+zinitscan(ZHeapScanDesc scan, ScanKey key, bool keep_startblock)
+{
+	ParallelBlockTableScanDesc bpscan = NULL;
+	bool		allow_strat;
+	bool		allow_sync;
+
+	/*
+	 * Determine the number of blocks we have to scan.
+	 *
+	 * It is sufficient to do this once at scan start, since any tuples added
+	 * while the scan is in progress will be invisible to my snapshot anyway.
+	 * (That is not true when using a non-MVCC snapshot.  However, we couldn't
+	 * guarantee to return tuples added after scan start anyway, since they
+	 * might go into pages we already scanned.  To guarantee consistent
+	 * results for a non-MVCC snapshot, the caller must hold some higher-level
+	 * lock that ensures the interesting tuple(s) won't change.)
+	 */
+	if (scan->rs_base.rs_parallel != NULL)
+	{
+		bpscan = (ParallelBlockTableScanDesc) scan->rs_base.rs_parallel;
+		scan->rs_nblocks = bpscan->phs_nblocks;
+	}
+	else
+		scan->rs_nblocks = RelationGetNumberOfBlocks(scan->rs_base.rs_rd);
+
+	/*
+	 * If the table is large relative to NBuffers, use a bulk-read access
+	 * strategy and enable synchronized scanning (see syncscan.c).  Although
+	 * the thresholds for these features could be different, we make them the
+	 * same so that there are only two behaviors to tune rather than four.
+	 * (However, some callers need to be able to disable one or both of these
+	 * behaviors, independently of the size of the table; also there is a GUC
+	 * variable that can disable synchronized scanning.)
+	 *
+	 * Note that heap_parallelscan_initialize has a very similar test; if you
+	 * change this, consider changing that one, too.
+	 */
+	if (!RelationUsesLocalBuffers(scan->rs_base.rs_rd) &&
+		scan->rs_nblocks > NBuffers / 4)
+	{
+		allow_strat = (scan->rs_base.rs_flags & SO_ALLOW_STRAT) != 0;
+		allow_sync = (scan->rs_base.rs_flags & SO_ALLOW_SYNC) != 0;
+	}
+	else
+		allow_strat = allow_sync = false;
+
+	if (allow_strat)
+	{
+		/* During a rescan, keep the previous strategy object. */
+		if (scan->rs_strategy == NULL)
+			scan->rs_strategy = GetAccessStrategy(BAS_BULKREAD);
+	}
+	else
+	{
+		if (scan->rs_strategy != NULL)
+			FreeAccessStrategy(scan->rs_strategy);
+		scan->rs_strategy = NULL;
+	}
+
+	if (scan->rs_base.rs_parallel != NULL)
+	{
+		/* For parallel scan, believe whatever ParallelTableScanDesc says. */
+		if (scan->rs_base.rs_parallel->phs_syncscan)
+			scan->rs_base.rs_flags |= SO_ALLOW_SYNC;
+		else
+			scan->rs_base.rs_flags &= ~SO_ALLOW_SYNC;
+	}
+	else if (keep_startblock)
+	{
+		/*
+		 * When rescanning, we want to keep the previous startblock setting,
+		 * so that rewinding a cursor doesn't generate surprising results.
+		 * Reset the active syncscan setting, though.
+		 */
+		if (allow_sync && synchronize_seqscans)
+			scan->rs_base.rs_flags |= SO_ALLOW_SYNC;
+		else
+			scan->rs_base.rs_flags &= ~SO_ALLOW_SYNC;
+	}
+	else if (allow_sync && synchronize_seqscans)
+	{
+		scan->rs_base.rs_flags |= SO_ALLOW_SYNC;
+		scan->rs_startblock = ss_get_location(scan->rs_base.rs_rd, scan->rs_nblocks);
+		/* Skip metapage */
+		if (scan->rs_startblock == ZHEAP_METAPAGE)
+			scan->rs_startblock = ZHEAP_METAPAGE + 1;
+	}
+	else
+	{
+		scan->rs_base.rs_flags &= ~SO_ALLOW_SYNC;
+		scan->rs_startblock = 0;
+	}
+
+	scan->rs_numblocks = InvalidBlockNumber;
+	scan->rs_inited = false;
+	scan->rs_cbuf = InvalidBuffer;
+	scan->rs_cblock = InvalidBlockNumber;
+
+	/* page-at-a-time fields are always invalid when not rs_inited */
+
+	/*
+	 * copy the scan key, if appropriate
+	 */
+	if (key != NULL)
+		memcpy(scan->rs_base.rs_key, key, scan->rs_base.rs_nkeys * sizeof(ScanKeyData));
+
+	/*
+	 * Currently, we only have a stats counter for sequential heap scans (but
+	 * e.g for bitmap scans the underlying bitmap index scans will be counted,
+	 * and for sample scans we update stats for tuple fetches).
+	 */
+	if (scan->rs_base.rs_flags & SO_TYPE_SEQSCAN)
+		pgstat_count_heap_scan(scan->rs_base.rs_rd);
+}
+
+/*
+ * zheap_beginscan - same as heap_beginscan except for tuple initialization
+ */
+TableScanDesc
+zheap_beginscan(Relation relation, Snapshot snapshot,
+				int nkeys, ScanKey key,
+				ParallelTableScanDesc parallel_scan,
+				uint32 flags)
+{
+	ZHeapScanDesc scan;
+
+	/*
+	 * increment relation ref count while scanning relation
+	 *
+	 * This is just to make really sure the relcache entry won't go away while
+	 * the scan has a pointer to it.  Caller should be holding the rel open
+	 * anyway, so this is redundant in all normal scenarios...
+	 */
+	RelationIncrementReferenceCount(relation);
+
+	/*
+	 * allocate and initialize scan descriptor
+	 */
+	scan = (ZHeapScanDesc) palloc(sizeof(ZHeapScanDescData));
+
+	scan->rs_base.rs_rd = relation;
+	scan->rs_base.rs_snapshot = snapshot;
+	scan->rs_base.rs_nkeys = nkeys;
+	scan->rs_base.rs_flags = flags;
+	scan->rs_base.rs_parallel = parallel_scan;
+	scan->rs_strategy = NULL;	/* set in zinitscan */
+	scan->rs_startblock = 0;	/* set in initscan */
+	scan->rs_ntuples = 0;
+
+	/*
+	 * Disable page-at-a-time mode if it's not a MVCC-safe snapshot.
+	 */
+	if (!(snapshot && IsMVCCSnapshot(snapshot)))
+		scan->rs_base.rs_flags &= ~SO_ALLOW_PAGEMODE;
+
+
+	/*
+	 * For seqscan and sample scans in a serializable transaction, acquire a
+	 * predicate lock on the entire relation. This is required not only to
+	 * lock all the matching tuples, but also to conflict with new insertions
+	 * into the table. In an indexscan, we take page locks on the index pages
+	 * covering the range specified in the scan qual, but in a heap scan there
+	 * is nothing more fine-grained to lock. A bitmap scan is a different
+	 * story, there we have already scanned the index and locked the index
+	 * pages covering the predicate. But in that case we still have to lock
+	 * any matching heap tuples. For sample scan we could optimize the locking
+	 * to be at least page-level granularity, but we'd need to add per-tuple
+	 * locking for that.
+	 */
+	if (scan->rs_base.rs_flags & (SO_TYPE_SEQSCAN | SO_TYPE_SAMPLESCAN))
+	{
+		/*
+		 * Ensure a missing snapshot is noticed reliably, even if the
+		 * isolation mode means predicate locking isn't performed (and
+		 * therefore the snapshot isn't used here).
+		 */
+		Assert(snapshot);
+		PredicateLockRelation(relation, snapshot);
+	}
+
+	scan->rs_cztup = NULL;
+
+	/*
+	 * we do this here instead of in initscan() because heap_rescan also calls
+	 * initscan() and we don't want to allocate memory again
+	 */
+	if (nkeys > 0)
+		scan->rs_base.rs_key = (ScanKey) palloc(sizeof(ScanKeyData) * nkeys);
+	else
+		scan->rs_base.rs_key = NULL;
+
+	zinitscan(scan, key, false);
+
+	return (TableScanDesc) scan;
+}
+
+void
+zheap_endscan(TableScanDesc sscan)
+{
+	ZHeapScanDesc scan = (ZHeapScanDesc) sscan;
+
+	/* Note: no locking manipulations needed */
+
+	/*
+	 * unpin scan buffers
+	 */
+	if (BufferIsValid(scan->rs_cbuf))
+		ReleaseBuffer(scan->rs_cbuf);
+
+	/*
+	 * decrement relation reference count and free scan descriptor storage
+	 */
+	RelationDecrementReferenceCount(scan->rs_base.rs_rd);
+
+	if (scan->rs_base.rs_key)
+		pfree(scan->rs_base.rs_key);
+
+	if (scan->rs_strategy != NULL)
+		FreeAccessStrategy(scan->rs_strategy);
+
+	if (scan->rs_base.rs_flags & SO_TEMP_SNAPSHOT)
+		UnregisterSnapshot(scan->rs_base.rs_snapshot);
+
+	pfree(scan);
+}
+
+/* ----------------
+ *		zheap_rescan		- similar to heap_rescan
+ * ----------------
+ */
+void
+zheap_rescan(TableScanDesc sscan, ScanKey key, bool set_params,
+			 bool allow_strat, bool allow_sync, bool allow_pagemode)
+{
+	ZHeapScanDesc scan = (ZHeapScanDesc) sscan;
+
+	if (set_params)
+	{
+		if (allow_strat)
+			scan->rs_base.rs_flags |= SO_ALLOW_STRAT;
+		else
+			scan->rs_base.rs_flags &= ~SO_ALLOW_STRAT;
+
+		if (allow_sync)
+			scan->rs_base.rs_flags |= SO_ALLOW_SYNC;
+		else
+			scan->rs_base.rs_flags &= ~SO_ALLOW_SYNC;
+
+		if (allow_pagemode && scan->rs_base.rs_snapshot &&
+			IsMVCCSnapshot(scan->rs_base.rs_snapshot))
+			scan->rs_base.rs_flags |= SO_ALLOW_PAGEMODE;
+		else
+			scan->rs_base.rs_flags &= ~SO_ALLOW_PAGEMODE;
+	}
+
+	/*
+	 * unpin scan buffers
+	 */
+	if (BufferIsValid(scan->rs_cbuf))
+		ReleaseBuffer(scan->rs_cbuf);
+
+	/*
+	 * reinitialize scan descriptor
+	 */
+	zinitscan(scan, key, true);
+}
+
+/*
+ * zheap_setscanlimits - restrict range of a zheapscan
+ *
+ * startBlk is the page to start at
+ * numBlks is number of pages to scan (InvalidBlockNumber means "all")
+ */
+void
+zheap_setscanlimits(TableScanDesc sscan, BlockNumber startBlk, BlockNumber numBlks)
+{
+	ZHeapScanDesc scan = (ZHeapScanDesc) sscan;
+
+	Assert(!scan->rs_inited);	/* else too late to change */
+	/* else rs_startblock is significant */
+	Assert(!(scan->rs_base.rs_flags & SO_ALLOW_SYNC));
+
+	/*
+	 * Check startBlk is valid (but allow case of zero blocks...). Consider
+	 * meta-page as well.
+	 */
+	Assert(startBlk == 0 || startBlk < scan->rs_nblocks ||
+		   startBlk == ZHEAP_METAPAGE + 1);
+
+	scan->rs_startblock = startBlk;
+	scan->rs_numblocks = numBlks;
+}
+
+/*
+ * zheapgetpage - Same as heapgetpage, but operate on zheap page and
+ * in page-at-a-time mode, visible tuples are stored in rs_visztuples.
+ *
+ * It returns false, if we can't scan the page (like in case of TPD page),
+ * otherwise, return true.
+ */
+bool
+zheapgetpage(TableScanDesc sscan, BlockNumber page)
+{
+	ZHeapScanDesc scan = (ZHeapScanDesc) sscan;
+	Buffer		buffer;
+	Snapshot	snapshot;
+	Page		dp;
+	int			lines;
+	int			ntup;
+	OffsetNumber lineoff;
+	ItemId		lpp;
+	bool		all_visible;
+	uint8		vmstatus;
+	Buffer		vmbuffer = InvalidBuffer;
+
+	Assert(page < scan->rs_nblocks);
+
+	/* release previous scan buffer, if any */
+	if (BufferIsValid(scan->rs_cbuf))
+	{
+		ReleaseBuffer(scan->rs_cbuf);
+		scan->rs_cbuf = InvalidBuffer;
+	}
+
+	if (page == ZHEAP_METAPAGE)
+	{
+		/* needs to be updated to keep track of scan position */
+		scan->rs_cblock = page;
+		return false;
+	}
+
+	/*
+	 * Be sure to check for interrupts at least once per page.  Checks at
+	 * higher code levels won't be able to stop a seqscan that encounters many
+	 * pages' worth of consecutive dead tuples.
+	 */
+	CHECK_FOR_INTERRUPTS();
+
+	/* read page using selected strategy */
+	buffer = ReadBufferExtended(scan->rs_base.rs_rd, MAIN_FORKNUM, page,
+								RBM_NORMAL, scan->rs_strategy);
+	scan->rs_cblock = page;
+
+	/*
+	 * We must hold share lock on the buffer content while examining tuple
+	 * visibility.  Afterwards, however, the tuples we have found to be
+	 * visible are guaranteed good as long as we hold the buffer pin.
+	 */
+	LockBuffer(buffer, BUFFER_LOCK_SHARE);
+
+	dp = BufferGetPage(buffer);
+
+	/*
+	 * Skip TPD pages. As of now, the size of special space in TPD pages is
+	 * different from other zheap pages like metapage and regular zheap page,
+	 * however, if that changes, we might need to explicitly store pagetype
+	 * flag somewhere.
+	 *
+	 * Fixme - As an exception, the size of special space for zheap page with
+	 * one transaction slot will match with TPD page's special size.
+	 */
+	if (IsTPDPage(dp))
+	{
+		UnlockReleaseBuffer(buffer);
+		return false;
+	}
+	else if (!(scan->rs_base.rs_flags & SO_ALLOW_PAGEMODE))
+	{
+		LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+		scan->rs_cbuf = buffer;
+		return true;
+	}
+
+	snapshot = scan->rs_base.rs_snapshot;
+
+	TestForOldSnapshot(snapshot, scan->rs_base.rs_rd, dp);
+	lines = PageGetMaxOffsetNumber(dp);
+	ntup = 0;
+
+	/*
+	 * If the all-visible flag indicates that all tuples on the page are
+	 * visible to everyone, we can skip the per-tuple visibility tests.
+	 *
+	 * Note: In hot standby, a tuple that's already visible to all
+	 * transactions in the master might still be invisible to a read-only
+	 * transaction in the standby. We partly handle this problem by tracking
+	 * the minimum xmin of visible tuples as the cut-off XID while marking a
+	 * page all-visible on master and WAL log that along with the visibility
+	 * map SET operation. In hot standby, we wait for (or abort) all
+	 * transactions that can potentially may not see one or more tuples on the
+	 * page. That's how index-only scans work fine in hot standby.
+	 */
+
+	vmstatus = visibilitymap_get_status(scan->rs_base.rs_rd, page, &vmbuffer);
+
+	all_visible = (vmstatus & VISIBILITYMAP_ALL_VISIBLE) &&
+		!snapshot->takenDuringRecovery;
+
+	if (BufferIsValid(vmbuffer))
+	{
+		ReleaseBuffer(vmbuffer);
+		vmbuffer = InvalidBuffer;
+	}
+
+	for (lineoff = FirstOffsetNumber, lpp = PageGetItemId(dp, lineoff);
+		 lineoff <= lines;
+		 lineoff++, lpp++)
+	{
+		if (ItemIdIsNormal(lpp) || ItemIdIsDeleted(lpp))
+		{
+			ZHeapTuple	resulttup;
+			bool		valid = false;
+			ItemPointerData tid;
+
+			ItemPointerSet(&tid, page, lineoff);
+
+			if (!all_visible)
+				valid = ZHeapTupleFetch(scan->rs_base.rs_rd, buffer,
+										lineoff, snapshot, &resulttup, NULL);
+			else if (!ItemIdIsDeleted(lpp))
+			{
+				valid = true;
+				resulttup =
+					zheap_gettuple(scan->rs_base.rs_rd, buffer, lineoff);
+			}
+
+			/*
+			 * If any prior version is visible, we pass latest visible as
+			 * true. The state of latest version of tuple is determined by the
+			 * called function.
+			 *
+			 * Note that, it's possible that tuple is updated in-place and
+			 * we're seeing some prior version of that. We handle that case in
+			 * ZHeapTupleHasSerializableConflictOut.
+			 */
+			CheckForSerializableConflictOut(valid, scan->rs_base.rs_rd, (void *) &tid,
+											buffer, snapshot);
+
+			if (valid)
+				scan->rs_visztuples[ntup++] = resulttup;
+		}
+	}
+
+	UnlockReleaseBuffer(buffer);
+
+	Assert(ntup <= MaxZHeapTuplesPerPage);
+	scan->rs_ntuples = ntup;
+
+	return true;
+}
+
+/* ----------------
+ *		zheapgettup_pagemode - fetch next zheap tuple in page-at-a-time mode
+ *
+ * Note that here we process only regular zheap pages, meta and tpd pages are
+ * skipped.
+ * ----------------
+ */
+static ZHeapTuple
+zheapgettup_pagemode(ZHeapScanDesc scan,
+					 ScanDirection dir)
+{
+	ZHeapTuple	tuple = scan->rs_cztup;
+	bool		backward = ScanDirectionIsBackward(dir);
+	BlockNumber page;
+	bool		finished;
+	bool		valid;
+	int			lines;
+	int			lineindex;
+	int			linesleft;
+	int			i = 0;
+
+	/*
+	 * calculate next starting lineindex, given scan direction
+	 */
+	if (ScanDirectionIsForward(dir))
+	{
+		if (!scan->rs_inited)
+		{
+			/*
+			 * return null immediately if relation is empty
+			 */
+			if (scan->rs_nblocks == ZHEAP_METAPAGE + 1 ||
+				scan->rs_numblocks == 0)
+			{
+				Assert(!BufferIsValid(scan->rs_cbuf));
+				tuple = NULL;
+				return tuple;
+			}
+			if (scan->rs_base.rs_parallel != NULL)
+			{
+				ParallelBlockTableScanDesc pbscan =
+				(ParallelBlockTableScanDesc) scan->rs_base.rs_parallel;
+
+				table_block_parallelscan_startblock_init(scan->rs_base.rs_rd,
+														 pbscan);
+
+				page = table_block_parallelscan_nextpage(scan->rs_base.rs_rd,
+														 pbscan);
+
+				/* Skip metapage */
+				if (page == ZHEAP_METAPAGE)
+					page = table_block_parallelscan_nextpage(scan->rs_base.rs_rd,
+															 pbscan);
+
+				/* Other processes might have already finished the scan. */
+				if (page == InvalidBlockNumber)
+				{
+					Assert(!BufferIsValid(scan->rs_cbuf));
+					tuple = NULL;
+					return tuple;
+				}
+			}
+			else
+				page = scan->rs_startblock; /* first page */
+			valid = zheapgetpage(&scan->rs_base, page);
+			if (!valid)
+				goto get_next_page;
+
+			lineindex = 0;
+			scan->rs_inited = true;
+		}
+		else
+		{
+			/* continue from previously returned page/tuple */
+			page = scan->rs_cblock; /* current page */
+			lineindex = scan->rs_cindex + 1;
+		}
+
+		lines = scan->rs_ntuples;
+		/* page and lineindex now reference the next visible tid */
+
+		linesleft = lines - lineindex;
+	}
+	else if (backward)
+	{
+		/* backward parallel scan not supported */
+		Assert(scan->rs_base.rs_parallel == NULL);
+
+		if (!scan->rs_inited)
+		{
+			/*
+			 * return null immediately if relation is empty
+			 */
+			if (scan->rs_nblocks == ZHEAP_METAPAGE + 1 ||
+				scan->rs_numblocks == 0)
+			{
+				Assert(!BufferIsValid(scan->rs_cbuf));
+				tuple = NULL;
+				return tuple;
+			}
+
+			/*
+			 * Disable reporting to syncscan logic in a backwards scan; it's
+			 * not very likely anyone else is doing the same thing at the same
+			 * time, and much more likely that we'll just bollix things for
+			 * forward scanners.
+			 */
+			scan->rs_base.rs_flags &= ~SO_ALLOW_SYNC;
+			/* start from last page of the scan */
+			if (scan->rs_startblock > ZHEAP_METAPAGE + 1)
+				page = scan->rs_startblock - 1;
+			else
+				page = scan->rs_nblocks - 1;
+			valid = zheapgetpage(&scan->rs_base, page);
+			if (!valid)
+				goto get_next_page;
+		}
+		else
+		{
+			/* continue from previously returned page/tuple */
+			page = scan->rs_cblock; /* current page */
+		}
+
+		lines = scan->rs_ntuples;
+
+		if (!scan->rs_inited)
+		{
+			lineindex = lines - 1;
+			scan->rs_inited = true;
+		}
+		else
+		{
+			lineindex = scan->rs_cindex - 1;
+		}
+		/* page and lineindex now reference the previous visible tid */
+
+		linesleft = lineindex + 1;
+	}
+	else
+	{
+		/*
+		 * In executor it seems NoMovementScanDirection is nothing but
+		 * do-nothing flag so we should not be here. The else part is still
+		 * here to keep the code as in heapgettup_pagemode.
+		 */
+		Assert(false);
+		return NULL;
+	}
+
+get_next_tuple:
+
+	/*
+	 * advance the scan until we find a qualifying tuple or run out of stuff
+	 * to scan
+	 */
+	while (linesleft > 0)
+	{
+		tuple = scan->rs_visztuples[lineindex];
+		scan->rs_cindex = lineindex;
+		return tuple;
+	}
+
+	/*
+	 * if we get here, it means we've exhausted the items on this page and
+	 * it's time to move to the next. For now we shall free all of the zheap
+	 * tuples stored in rs_visztuples. Later a better memory management is
+	 * required.
+	 */
+	for (i = 0; i < scan->rs_ntuples; i++)
+		zheap_freetuple(scan->rs_visztuples[i]);
+	scan->rs_ntuples = 0;
+
+get_next_page:
+	for (;;)
+	{
+		if (backward)
+		{
+			finished = (page == scan->rs_startblock) ||
+				(scan->rs_numblocks != InvalidBlockNumber ? --scan->rs_numblocks == 0 : false);
+			if (page == ZHEAP_METAPAGE + 1)
+				page = scan->rs_nblocks;
+			page--;
+		}
+		else if (scan->rs_base.rs_parallel != NULL)
+		{
+			ParallelBlockTableScanDesc pbscan =
+			(ParallelBlockTableScanDesc) scan->rs_base.rs_parallel;
+
+			page = table_block_parallelscan_nextpage(scan->rs_base.rs_rd,
+													 pbscan);
+			/* Skip metapage */
+			if (page == ZHEAP_METAPAGE)
+				page = table_block_parallelscan_nextpage(scan->rs_base.rs_rd,
+														 pbscan);
+			finished = (page == InvalidBlockNumber);
+		}
+		else
+		{
+			page++;
+			if (page >= scan->rs_nblocks)
+				page = 0;
+
+			if (page == ZHEAP_METAPAGE)
+			{
+				/*
+				 * Since we're skipping the metapage, we should update the
+				 * scan location if sync scan is enabled.
+				 */
+				if (scan->rs_base.rs_flags & SO_ALLOW_SYNC)
+					ss_report_location(scan->rs_base.rs_rd, page);
+				page++;
+			}
+
+			finished = (page == scan->rs_startblock) ||
+				(scan->rs_numblocks != InvalidBlockNumber ? --scan->rs_numblocks == 0 : false);
+
+			/*
+			 * Report our new scan position for synchronization purposes. We
+			 * don't do that when moving backwards, however. That would just
+			 * mess up any other forward-moving scanners.
+			 *
+			 * Note: we do this before checking for end of scan so that the
+			 * final state of the position hint is back at the start of the
+			 * rel.  That's not strictly necessary, but otherwise when you run
+			 * the same query multiple times the starting position would shift
+			 * a little bit backwards on every invocation, which is confusing.
+			 * We don't guarantee any specific ordering in general, though.
+			 */
+			if (scan->rs_base.rs_flags & SO_ALLOW_SYNC)
+				ss_report_location(scan->rs_base.rs_rd, page);
+		}
+
+		/*
+		 * return NULL if we've exhausted all the pages
+		 */
+		if (finished)
+		{
+			if (BufferIsValid(scan->rs_cbuf))
+				ReleaseBuffer(scan->rs_cbuf);
+			scan->rs_cbuf = InvalidBuffer;
+			scan->rs_cblock = InvalidBlockNumber;
+			tuple = NULL;
+			scan->rs_inited = false;
+			return tuple;
+		}
+
+		valid = zheapgetpage(&scan->rs_base, page);
+		if (!valid)
+			continue;
+
+		if (!scan->rs_inited)
+			scan->rs_inited = true;
+		lines = scan->rs_ntuples;
+		linesleft = lines;
+		if (backward)
+			lineindex = lines - 1;
+		else
+			lineindex = 0;
+
+		goto get_next_tuple;
+	}
+}
+
+/*
+ * Similar to heapgettup, but for fetching zheap tuple.
+ *
+ * Note that here we process only regular zheap pages, meta and tpd pages are
+ * skipped.
+ */
+static ZHeapTuple
+zheapgettup(ZHeapScanDesc scan,
+			ScanDirection dir)
+{
+	ZHeapTuple	tuple = scan->rs_cztup;
+	Snapshot	snapshot = scan->rs_base.rs_snapshot;
+	bool		backward = ScanDirectionIsBackward(dir);
+	BlockNumber page;
+	bool		finished;
+	bool		valid;
+	Page		dp;
+	int			lines;
+	OffsetNumber lineoff;
+	int			linesleft;
+	ItemId		lpp;
+
+	/*
+	 * calculate next starting lineoff, given scan direction
+	 */
+	if (ScanDirectionIsForward(dir))
+	{
+		if (!scan->rs_inited)
+		{
+			/*
+			 * return null immediately if relation is empty
+			 */
+			if (scan->rs_nblocks == ZHEAP_METAPAGE + 1 ||
+				scan->rs_numblocks == 0)
+			{
+				Assert(!BufferIsValid(scan->rs_cbuf));
+				return NULL;
+			}
+			if (scan->rs_base.rs_parallel != NULL)
+			{
+				ParallelBlockTableScanDesc pbscan =
+				(ParallelBlockTableScanDesc) scan->rs_base.rs_parallel;
+
+				table_block_parallelscan_startblock_init(scan->rs_base.rs_rd,
+														 pbscan);
+
+				page = table_block_parallelscan_nextpage(scan->rs_base.rs_rd,
+														 pbscan);
+
+				/* Skip metapage */
+				if (page == ZHEAP_METAPAGE)
+					page = table_block_parallelscan_nextpage(scan->rs_base.rs_rd,
+															 pbscan);
+
+				/* Other processes might have already finished the scan. */
+				if (page == InvalidBlockNumber)
+				{
+					Assert(!BufferIsValid(scan->rs_cbuf));
+					return NULL;
+				}
+			}
+			else
+				page = scan->rs_startblock; /* first page */
+			valid = zheapgetpage(&scan->rs_base, page);
+			if (!valid)
+				goto get_next_page;
+			lineoff = FirstOffsetNumber;	/* first offnum */
+			scan->rs_inited = true;
+		}
+		else
+		{
+			/* continue from previously returned page/tuple */
+			page = scan->rs_cblock; /* current page */
+			lineoff =			/* next offnum */
+				OffsetNumberNext(ItemPointerGetOffsetNumber(&(tuple->t_self)));
+		}
+
+		LockBuffer(scan->rs_cbuf, BUFFER_LOCK_SHARE);
+
+		dp = BufferGetPage(scan->rs_cbuf);
+		TestForOldSnapshot(snapshot, scan->rs_base.rs_rd, dp);
+		lines = PageGetMaxOffsetNumber(dp);
+		/* page and lineoff now reference the physically next tid */
+
+		linesleft = lines - lineoff + 1;
+	}
+	else if (backward)
+	{
+		/* backward parallel scan not supported */
+		Assert(scan->rs_base.rs_parallel == NULL);
+
+		if (!scan->rs_inited)
+		{
+			/*
+			 * return null immediately if relation is empty
+			 */
+			if (scan->rs_nblocks == ZHEAP_METAPAGE + 1 ||
+				scan->rs_numblocks == 0)
+			{
+				Assert(!BufferIsValid(scan->rs_cbuf));
+				return NULL;
+			}
+
+			/*
+			 * Disable reporting to syncscan logic in a backwards scan; it's
+			 * not very likely anyone else is doing the same thing at the same
+			 * time, and much more likely that we'll just bollix things for
+			 * forward scanners.
+			 */
+			scan->rs_base.rs_flags &= ~SO_ALLOW_SYNC;
+			/* start from last page of the scan */
+			if (scan->rs_startblock > ZHEAP_METAPAGE + 1)
+				page = scan->rs_startblock - 1;
+			else
+				page = scan->rs_nblocks - 1;
+			valid = zheapgetpage(&scan->rs_base, page);
+			if (!valid)
+				goto get_next_page;
+		}
+		else
+		{
+			/* continue from previously returned page/tuple */
+			page = scan->rs_cblock; /* current page */
+		}
+
+		LockBuffer(scan->rs_cbuf, BUFFER_LOCK_SHARE);
+
+		dp = BufferGetPage(scan->rs_cbuf);
+		TestForOldSnapshot(snapshot, scan->rs_base.rs_rd, dp);
+		lines = PageGetMaxOffsetNumber(dp);
+
+		if (!scan->rs_inited)
+		{
+			lineoff = lines;	/* final offnum */
+			scan->rs_inited = true;
+		}
+		else
+		{
+			lineoff =			/* previous offnum */
+				OffsetNumberPrev(ItemPointerGetOffsetNumber(&(tuple->t_self)));
+		}
+		/* page and lineoff now reference the physically previous tid */
+
+		linesleft = lineoff;
+	}
+	else
+	{
+		/*
+		 * In executor it seems NoMovementScanDirection is nothing but
+		 * do-nothing flag so we should not be here. The else part is still
+		 * here to keep the code as in heapgettup_pagemode.
+		 */
+		Assert(false);
+
+		return NULL;
+	}
+
+	/*
+	 * advance the scan until we find a qualifying tuple or run out of stuff
+	 * to scan
+	 */
+	lpp = PageGetItemId(dp, lineoff);
+
+get_next_tuple:
+	while (linesleft > 0)
+	{
+		if (ItemIdIsNormal(lpp))
+		{
+			ZHeapTuple	tuple;
+			bool		valid;
+
+			valid = ZHeapTupleFetch(scan->rs_base.rs_rd, scan->rs_cbuf,
+									lineoff, snapshot, &tuple, NULL);
+
+			/*
+			 * If any prior version is visible, we pass latest visible as
+			 * true. The state of latest version of tuple is determined by the
+			 * called function.
+			 *
+			 * Note that, it's possible that tuple is updated in-place and
+			 * we're seeing some prior version of that. We handle that case in
+			 * ZHeapTupleHasSerializableConflictOut.
+			 */
+			CheckForSerializableConflictOut(valid, scan->rs_base.rs_rd, (void *) &tuple->t_self,
+											scan->rs_cbuf, snapshot);
+
+			if (valid)
+			{
+				LockBuffer(scan->rs_cbuf, BUFFER_LOCK_UNLOCK);
+				return tuple;
+			}
+		}
+
+		/*
+		 * otherwise move to the next item on the page
+		 */
+		--linesleft;
+		if (backward)
+		{
+			--lpp;				/* move back in this page's ItemId array */
+			--lineoff;
+		}
+		else
+		{
+			++lpp;				/* move forward in this page's ItemId array */
+			++lineoff;
+		}
+	}
+
+	/*
+	 * if we get here, it means we've exhausted the items on this page and
+	 * it's time to move to the next.
+	 */
+	LockBuffer(scan->rs_cbuf, BUFFER_LOCK_UNLOCK);
+
+get_next_page:
+	for (;;)
+	{
+		/*
+		 * advance to next/prior page and detect end of scan
+		 */
+		if (backward)
+		{
+			finished = (page == scan->rs_startblock) ||
+				(scan->rs_numblocks != InvalidBlockNumber ? --scan->rs_numblocks == 0 : false);
+			if (page == ZHEAP_METAPAGE + 1)
+				page = scan->rs_nblocks;
+			page--;
+		}
+		else if (scan->rs_base.rs_parallel != NULL)
+		{
+			ParallelBlockTableScanDesc pbscan =
+			(ParallelBlockTableScanDesc) scan->rs_base.rs_parallel;
+
+			page = table_block_parallelscan_nextpage(scan->rs_base.rs_rd,
+													 pbscan);
+			/* Skip metapage */
+			if (page == ZHEAP_METAPAGE)
+				page = table_block_parallelscan_nextpage(scan->rs_base.rs_rd,
+														 pbscan);
+			finished = (page == InvalidBlockNumber);
+		}
+		else
+		{
+			page++;
+			if (page >= scan->rs_nblocks)
+				page = 0;
+
+			if (page == ZHEAP_METAPAGE)
+			{
+				/*
+				 * Since we're skipping the metapage, we should update the
+				 * scan location if sync scan is enabled.
+				 */
+				if (scan->rs_base.rs_flags & SO_ALLOW_SYNC)
+					ss_report_location(scan->rs_base.rs_rd, page);
+				page++;
+			}
+
+			finished = (page == scan->rs_startblock) ||
+				(scan->rs_numblocks != InvalidBlockNumber ? --scan->rs_numblocks == 0 : false);
+
+			/*
+			 * Report our new scan position for synchronization purposes. We
+			 * don't do that when moving backwards, however. That would just
+			 * mess up any other forward-moving scanners.
+			 *
+			 * Note: we do this before checking for end of scan so that the
+			 * final state of the position hint is back at the start of the
+			 * rel.  That's not strictly necessary, but otherwise when you run
+			 * the same query multiple times the starting position would shift
+			 * a little bit backwards on every invocation, which is confusing.
+			 * We don't guarantee any specific ordering in general, though.
+			 */
+			if (scan->rs_base.rs_flags & SO_ALLOW_SYNC)
+				ss_report_location(scan->rs_base.rs_rd, page);
+		}
+
+		/*
+		 * return NULL if we've exhausted all the pages
+		 */
+		if (finished)
+		{
+			if (BufferIsValid(scan->rs_cbuf))
+				ReleaseBuffer(scan->rs_cbuf);
+			scan->rs_cbuf = InvalidBuffer;
+			scan->rs_cblock = InvalidBlockNumber;
+			scan->rs_inited = false;
+			return NULL;
+		}
+
+		valid = zheapgetpage(&scan->rs_base, page);
+		if (!valid)
+			continue;
+
+		if (!scan->rs_inited)
+			scan->rs_inited = true;
+
+		LockBuffer(scan->rs_cbuf, BUFFER_LOCK_SHARE);
+
+		dp = BufferGetPage(scan->rs_cbuf);
+		TestForOldSnapshot(snapshot, scan->rs_base.rs_rd, dp);
+		lines = PageGetMaxOffsetNumber((Page) dp);
+		linesleft = lines;
+		if (backward)
+		{
+			lineoff = lines;
+			lpp = PageGetItemId(dp, lines);
+		}
+		else
+		{
+			lineoff = FirstOffsetNumber;
+			lpp = PageGetItemId(dp, FirstOffsetNumber);
+		}
+
+		goto get_next_tuple;
+	}
+}
+#ifdef ZHEAPDEBUGALL
+#define ZHEAPDEBUG_1 \
+	elog(DEBUG2, "zheap_getnextslot([%s,nkeys=%d],dir=%d) called", \
+		 RelationGetRelationName(scan->rs_rd), scan->rs_nkeys, (int) direction)
+#define ZHEAPDEBUG_2 \
+	elog(DEBUG2, "zheap_getnextslot returning EOS")
+#define ZHEAPDEBUG_3 \
+	elog(DEBUG2, "zheap_getnextslot returning tuple")
+#else
+#define ZHEAPDEBUG_1
+#define ZHEAPDEBUG_2
+#define ZHEAPDEBUG_3
+#endif							/* !defined(ZHEAPDEBUGALL) */
+
+bool
+zheap_getnextslot(TableScanDesc sscan, ScanDirection direction, TupleTableSlot *slot)
+{
+	ZHeapScanDesc scan = (ZHeapScanDesc) sscan;
+	ZHeapTuple	zhtup = NULL;
+
+	/* Skip metapage */
+	if (scan->rs_startblock == ZHEAP_METAPAGE)
+		scan->rs_startblock = ZHEAP_METAPAGE + 1;
+
+	ZHEAPDEBUG_1;				/* zheap_getnextslot( info ) */
+
+	/*
+	 * The key will be passed only for catalog table scans and catalog tables
+	 * are always a heap table!. So in case of zheap it should be set to NULL.
+	 */
+	Assert(scan->rs_base.rs_key == NULL);
+
+	if (scan->rs_base.rs_flags & SO_ALLOW_PAGEMODE)
+		zhtup = zheapgettup_pagemode(scan, direction);
+	else
+		zhtup = zheapgettup(scan, direction);
+
+	if (zhtup == NULL)
+	{
+		ZHEAPDEBUG_2;			/* zheap_getnextslot returning EOS */
+		ExecClearTuple(slot);
+		return false;
+	}
+
+	scan->rs_cztup = zhtup;
+
+	/*
+	 * if we get here it means we have a new current scan tuple, so point to
+	 * the proper return buffer and return the tuple.
+	 */
+	ZHEAPDEBUG_3;				/* zheap_getnextslot returning tuple */
+
+	pgstat_count_heap_getnext(scan->rs_base.rs_rd);
+
+	ExecStoreZHeapTuple(zhtup, slot,
+						(scan->rs_base.rs_flags & SO_ALLOW_PAGEMODE) ? false : true);
+
+	return true;
+}
+
+bool
+zheap_scan_bitmap_next_block(TableScanDesc sscan,
+							 TBMIterateResult *tbmres)
+{
+	ZHeapScanDesc scan = (ZHeapScanDesc) sscan;
+	BlockNumber page = tbmres->blockno;
+	Page		dp;
+	Buffer		buffer;
+	Snapshot	snapshot;
+	int			ntup;
+
+	scan->rs_cindex = 0;
+	scan->rs_ntuples = 0;
+
+	/*
+	 * Ignore any claimed entries past what we think is the end of the
+	 * relation.  (This is probably not necessary given that we got at least
+	 * AccessShareLock on the table before performing any of the indexscans,
+	 * but let's be safe.)
+	 */
+	if (page >= scan->rs_nblocks)
+		return false;
+
+	if (page == ZHEAP_METAPAGE)
+		return false;
+
+	scan->rs_cbuf = ReleaseAndReadBuffer(scan->rs_cbuf,
+										 scan->rs_base.rs_rd,
+										 page);
+	buffer = scan->rs_cbuf;
+	snapshot = scan->rs_base.rs_snapshot;
+
+	ntup = 0;
+
+	/*
+	 * We must hold share lock on the buffer content while examining tuple
+	 * visibility.  Afterwards, however, the tuples we have found to be
+	 * visible are guaranteed good as long as we hold the buffer pin.
+	 */
+	LockBuffer(buffer, BUFFER_LOCK_SHARE);
+	dp = (Page) BufferGetPage(buffer);
+
+	/*
+	 * Skip TPD pages. As of now, the size of special space in TPD pages is
+	 * different from other zheap pages like metapage and regular zheap page,
+	 * however, if that changes, we might need to explicitly store pagetype
+	 * flag somewhere.
+	 *
+	 * Fixme - As an exception, the size of special space for zheap page with
+	 * one transaction slot will match with TPD page's special size.
+	 */
+	if (IsTPDPage(dp))
+	{
+		UnlockReleaseBuffer(buffer);
+		return false;
+	}
+
+	/*
+	 * We need two separate strategies for lossy and non-lossy cases.
+	 */
+	if (tbmres->ntuples >= 0)
+	{
+		/*
+		 * Bitmap is non-lossy, so we just look through the offsets listed in
+		 * tbmres;
+		 */
+		int			curslot;
+
+		for (curslot = 0; curslot < tbmres->ntuples; curslot++)
+		{
+			OffsetNumber offnum = tbmres->offsets[curslot];
+			ItemPointerData tid;
+			ZHeapTuple	ztuple;
+
+			ItemPointerSet(&tid, page, offnum);
+			ztuple = zheap_search_buffer(&tid, scan->rs_base.rs_rd, buffer, snapshot, NULL);
+			if (ztuple != NULL)
+				scan->rs_visztuples[ntup++] = ztuple;
+		}
+	}
+	else
+	{
+		/*
+		 * Bitmap is lossy, so we must examine each item pointer on the page.
+		 */
+		OffsetNumber maxoff = PageGetMaxOffsetNumber(dp);
+		OffsetNumber offnum;
+
+		for (offnum = FirstOffsetNumber; offnum <= maxoff; offnum = OffsetNumberNext(offnum))
+		{
+			ItemId		lpp;
+			ZHeapTuple	resulttup;
+			bool		valid;
+			ItemPointerData tid;
+
+			lpp = PageGetItemId(dp, offnum);
+			if (!ItemIdIsNormal(lpp))
+				continue;
+
+			ItemPointerSet(&tid, page, offnum);
+
+			valid = ZHeapTupleFetch(scan->rs_base.rs_rd, buffer,
+									offnum, snapshot, &resulttup, NULL);
+
+			if (valid)
+			{
+				PredicateLockTid(scan->rs_base.rs_rd, &(resulttup->t_self), snapshot,
+								 IsSerializableXact() ?
+								 zheap_fetchinsertxid(resulttup, buffer) :
+								 InvalidTransactionId);
+			}
+
+			/*
+			 * If any prior version is visible, we pass latest visible as
+			 * true. The state of latest version of tuple is determined by the
+			 * called function.
+			 *
+			 * Note that, it's possible that tuple is updated in-place and
+			 * we're seeing some prior version of that. We handle that case in
+			 * ZHeapTupleHasSerializableConflictOut.
+			 */
+			CheckForSerializableConflictOut(valid, scan->rs_base.rs_rd, (void *) &tid,
+											buffer, snapshot);
+
+			if (valid)
+				scan->rs_visztuples[ntup++] = resulttup;
+		}
+	}
+
+	LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+
+	Assert(ntup <= MaxZHeapTuplesPerPage);
+	scan->rs_ntuples = ntup;
+	return true;
+}
+
+bool
+zheap_scan_bitmap_next_tuple(TableScanDesc sscan, TBMIterateResult *tbmres, struct TupleTableSlot *slot)
+{
+	ZHeapScanDesc scan = (ZHeapScanDesc) sscan;
+
+	if (scan->rs_cindex < 0 || scan->rs_cindex >= scan->rs_ntuples)
+		return false;
+
+	scan->rs_cztup = scan->rs_visztuples[scan->rs_cindex];
+
+	/*
+	 * Set up the result slot to point to this tuple. We don't need to keep
+	 * the pin on the buffer, since we only scan tuples in page mode.
+	 */
+	ExecStoreZHeapTuple(scan->rs_cztup, slot, true);
+
+	scan->rs_cindex++;
+
+	return true;
+}
+
+/*
+ *	zheap_search_buffer - search tuple satisfying snapshot
+ *
+ * On entry, *tid is the TID of a tuple, and buffer is the buffer holding
+ * this tuple.  We search for the first visible member satisfying the given
+ * snapshot. If one is found, we return the tuple, in addition to updating
+ * *tid. Return NULL otherwise.
+ *
+ * The caller must already have pin and (at least) share lock on the buffer;
+ * it is still pinned/locked at exit.  Also, We do not report any pgstats
+ * count; caller may do so if wanted.
+ */
+ZHeapTuple
+zheap_search_buffer(ItemPointer tid, Relation relation, Buffer buffer,
+					Snapshot snapshot, bool *all_dead)
+{
+	Page		dp = (Page) BufferGetPage(buffer);
+	ItemId		lp;
+	OffsetNumber offnum;
+	ZHeapTuple	pagetup = NULL;
+	ZHeapTuple	resulttup = NULL;
+
+	if (all_dead)
+		*all_dead = false;
+
+	Assert(ItemPointerGetBlockNumber(tid) == BufferGetBlockNumber(buffer));
+	offnum = ItemPointerGetOffsetNumber(tid);
+	/* check for bogus TID */
+	if (offnum < FirstOffsetNumber || offnum > PageGetMaxOffsetNumber(dp))
+		return NULL;
+
+	lp = PageGetItemId(dp, offnum);
+
+	/* check for unused or dead items */
+	if (!(ItemIdIsNormal(lp) || ItemIdIsDeleted(lp)))
+	{
+		if (all_dead)
+			*all_dead = true;
+		return NULL;
+	}
+
+	if (!ItemIdIsDeleted(lp))
+		pagetup = zheap_gettuple(relation, buffer, offnum);
+
+	/*
+	 * If the record is deleted, its place in the page might have been taken
+	 * by another of its kind. Try to get it from the UNDO if it is still
+	 * visible.
+	 */
+	if (ZHeapTupleFetch(relation, buffer, offnum, snapshot, &resulttup, NULL))
+	{
+		TransactionId insertxid = InvalidTransactionId;
+
+		if (IsSerializableXact())
+		{
+			if (!ItemIdIsDeleted(lp))
+			{
+				/*
+				 * To fetch the xmin (aka transaction that has inserted the
+				 * tuple), we need to use the transaction slot of the tuple in
+				 * the page instead of the tuple from undo, otherwise, it
+				 * might traverse the wrong chain.
+				 *
+				 * ZBORKED: This seems like an ugly kludge.  Can't we find
+				 * another way to make sure we DON'T traverse the wrong undo
+				 * chain?  And what does "wrong" mean here anyway?  And why
+				 * don't we have similar problems when the tuple is deleted?
+				 */
+				insertxid = zheap_fetchinsertxid(pagetup, buffer);
+			}
+			else
+				insertxid = zheap_fetchinsertxid(resulttup, buffer);
+		}
+
+		PredicateLockTid(relation, &(resulttup->t_self), snapshot, insertxid);
+	}
+
+	/*
+	 * If any prior version is visible, we pass latest visible as true. The
+	 * state of latest version of tuple is determined by the called function.
+	 *
+	 * Note that, it's possible that tuple is updated in-place and we're
+	 * seeing some prior version of that. We handle that case in
+	 * ZHeapTupleHasSerializableConflictOut.
+	 */
+	CheckForSerializableConflictOut((resulttup != NULL), relation, (void *) tid,
+									buffer, snapshot);
+
+	if (resulttup)
+	{
+		/* set the tid */
+		*tid = resulttup->t_self;
+	}
+	else
+	{
+		/*
+		 * If we can't see it, maybe no one else can either.  At caller
+		 * request, check whether tuple is dead to all transactions.
+		 *
+		 * ZBORKED: This is an ugly kludge.  We should find a way to get this
+		 * from ZHeapTupleFetch or something of that sort.
+		 */
+		if (all_dead && ZHeapTupleIsSurelyDead(pagetup, buffer, offnum))
+			*all_dead = true;
+	}
+
+	if (pagetup)
+		pfree(pagetup);
+
+	return resulttup;
+}
+
+/*
+ * zheap_fetch - Fetch a tuple based on TID.
+ *
+ *	This function is quite similar to heap_fetch with few differences like
+ *	it will always allocate the memory for tuple and do a memcpy of the tuple
+ *	instead of pointing it to disk tuple.  It is the responsibility of the
+ *	caller to free the tuple.
+ */
+bool
+zheap_fetch(Relation relation,
+			Snapshot snapshot,
+			ItemPointer tid,
+			ZHeapTuple *tuple,
+			Buffer *userbuf,
+			bool keep_buf)
+{
+	ZHeapTuple	resulttup;
+	ItemId		lp;
+	Buffer		buffer;
+	Page		page;
+	OffsetNumber offnum;
+	bool		valid;
+	ItemPointerData ctid;
+
+	/*
+	 * Fetch and pin the appropriate page of the relation.
+	 */
+	buffer = ReadBuffer(relation, ItemPointerGetBlockNumber(tid));
+
+	/*
+	 * Need share lock on buffer to examine tuple commit status.
+	 */
+	LockBuffer(buffer, BUFFER_LOCK_SHARE);
+	page = BufferGetPage(buffer);
+
+	/*
+	 * We'd better check for out-of-range offnum in case of VACUUM since the
+	 * TID was obtained. Exit if this is metapage.
+	 */
+	offnum = ItemPointerGetOffsetNumber(tid);
+	if (offnum < FirstOffsetNumber || offnum > PageGetMaxOffsetNumber(page) ||
+		BufferGetBlockNumber(buffer) == ZHEAP_METAPAGE)
+	{
+		LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+		if (keep_buf)
+			*userbuf = buffer;
+		else
+		{
+			ReleaseBuffer(buffer);
+			*userbuf = InvalidBuffer;
+		}
+		*tuple = NULL;
+		return false;
+	}
+
+	/*
+	 * get the item line pointer corresponding to the requested tid
+	 */
+	lp = PageGetItemId(page, offnum);
+
+	/*
+	 * Must check for dead and unused items.
+	 */
+	if (!ItemIdIsNormal(lp) && !ItemIdIsDeleted(lp))
+	{
+		LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+		if (keep_buf)
+			*userbuf = buffer;
+		else
+		{
+			ReleaseBuffer(buffer);
+			*userbuf = InvalidBuffer;
+		}
+		*tuple = NULL;
+		return false;
+	}
+
+	ctid = *tid;
+	valid = ZHeapTupleFetch(relation, buffer, offnum, snapshot, &resulttup,
+							&ctid);
+
+	if (valid)
+		PredicateLockTid(relation, &((resulttup)->t_self), snapshot,
+						 IsSerializableXact() ?
+						 zheap_fetchinsertxid(resulttup, buffer) :
+						 InvalidTransactionId);
+
+	/*
+	 * If any prior version is visible, we pass latest visible as true. The
+	 * state of latest version of tuple is determined by the called function.
+	 *
+	 * Note that, it's possible that tuple is updated in-place and we're
+	 * seeing some prior version of that. We handle that case in
+	 * ZHeapTupleHasSerializableConflictOut.
+	 */
+	CheckForSerializableConflictOut(valid, relation, (void *) tid,
+									buffer, snapshot);
+
+	/*
+	 * Pass back the ctid if the tuple is invisible because it was updated.
+	 * Apart from SnapshotAny, ctid must be changed only when current tuple in
+	 * not visible.
+	 */
+	if (ItemPointerIsValid(&ctid))
+	{
+		if (snapshot == SnapshotAny || !valid)
+		{
+			*tid = ctid;
+		}
+	}
+
+	LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+
+	if (valid)
+	{
+		/*
+		 * All checks passed, so return the tuple as valid. Caller is now
+		 * responsible for releasing the buffer.
+		 */
+		*userbuf = buffer;
+		*tuple = resulttup;
+
+		return true;
+	}
+
+	/* Tuple failed time qual, but maybe caller wants to see it anyway. */
+	if (keep_buf)
+		*userbuf = buffer;
+	else
+	{
+		ReleaseBuffer(buffer);
+		*userbuf = InvalidBuffer;
+	}
+
+	*tuple = NULL;
+	return false;
+}
diff --git a/src/backend/access/zheap/ztuple.c b/src/backend/access/zheap/ztuple.c
new file mode 100644
index 0000000..ac65ad7
--- /dev/null
+++ b/src/backend/access/zheap/ztuple.c
@@ -0,0 +1,1008 @@
+/*-------------------------------------------------------------------------
+ *
+ * ztuple.c
+ *	  Routines to form and deform zheap tuples.
+ *
+ * zheap implements three separate optimizations which reduce the size of
+ * zheap tuples as compared with PostgreSQL's traditional heap tuple
+ * format.
+ *
+ * First, nearly all transactional information is stored in page-level
+ * structures or in the undo log rather than on a per-tuple basis.  As
+ * a result, tuple headers can be much narrower -- just 5 bytes rather
+ * than 23.
+ *
+ * Second, we omit alignment padding between the tuple header and the
+ * tuple data.  Because we support in-place update, we can never return
+ * to the executor a pointer directly into the page; instead, every
+ * tuple must be copied -- and we can easily copy it into an aligned
+ * buffer, whether or not the source data is aligned.
+ *
+ * Third, we omit all alignment padding for pass-by-value data types.
+ * Outside of system catalogs, where it is important for the fixed-width
+ * portion of the tuple to match the format of a C "struct", this padding
+ * isn't even beneficial in the current heap, although it can't easily be
+ * removed for reasons of backward compatibility.  zheap tables can't
+ * currently be used for system catalogs, so this doesn't matter at all
+ * right now; if it matters someday, we should find a better solution
+ * than inserting unnecessary padding into user tables that may contain
+ * billions of rows.
+ *
+ * Unfortunately, zheap cannot take advantage of attcacheoff when
+ * forming and deforming tuples, because we still sometimes need to
+ * take data from a zheap table and put in the form of a heap tuple,
+ * and that code would get confused if the offset had been set according
+ * to zheap's weaker alignment rules.
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/zheap/ztuple.c
+ *
+ *-------------------------------------------------------------------------
+ */
+
+#include "postgres.h"
+
+#include "access/relation.h"
+#include "access/tpd.h"
+#include "storage/proc.h"
+#include "utils/datum.h"
+#include "utils/ztqual.h"
+
+static void tts_zheap_init(TupleTableSlot *slot);
+static void tts_zheap_release(TupleTableSlot *slot);
+static void tts_zheap_clear(TupleTableSlot *slot);
+static void tts_zheap_getsomeattrs(TupleTableSlot *slot, int natts);
+static Datum tts_zheap_getsysattr(TupleTableSlot *slot, int attnum,
+								  bool *isnull);
+static void tts_zheap_materialize(TupleTableSlot *slot);
+static void tts_zheap_copyslot(TupleTableSlot *dstslot,
+							   TupleTableSlot *srcslot);
+static HeapTuple tts_zheap_copy_heap_tuple(TupleTableSlot *slot);
+static MinimalTuple tts_zheap_copy_minimal_tuple(TupleTableSlot *slot);
+
+const TupleTableSlotOps TTSOpsZHeapTuple = {
+	.base_slot_size = sizeof(ZHeapTupleTableSlot),
+	.init = tts_zheap_init,
+	.release = tts_zheap_release,
+	.clear = tts_zheap_clear,
+	.getsomeattrs = tts_zheap_getsomeattrs,
+	.getsysattr = tts_zheap_getsysattr,
+	.materialize = tts_zheap_materialize,
+	.copyslot = tts_zheap_copyslot,
+
+	.get_heap_tuple = NULL,
+	.get_minimal_tuple = NULL,
+
+	.copy_heap_tuple = tts_zheap_copy_heap_tuple,
+	.copy_minimal_tuple = tts_zheap_copy_minimal_tuple
+};
+
+/*
+ * zheap_compute_data_size
+ *		Determine size of the data area for a zheap tuple.
+ *
+ * Even the first attribute might require alignment, because in zheap,
+ * unlike the regular heap, t_hoff is not necessarily a multiple of
+ * MAXIMUM_ALIGNOF.
+ */
+Size
+zheap_compute_data_size(TupleDesc tupleDesc, Datum *values, bool *isnull,
+						int t_hoff)
+{
+	Size		data_length = t_hoff;
+	int			i;
+	int			numberOfAttributes = tupleDesc->natts;
+
+	for (i = 0; i < numberOfAttributes; i++)
+	{
+		Datum		val;
+		Form_pg_attribute atti;
+
+		if (isnull[i])
+			continue;
+
+		val = values[i];
+		atti = TupleDescAttr(tupleDesc, i);
+
+		if (atti->attbyval)
+		{
+			/* attbyval attributes are stored unaligned in zheap. */
+			data_length += atti->attlen;
+		}
+		else if (ATT_IS_PACKABLE(atti) &&
+				 VARATT_CAN_MAKE_SHORT(DatumGetPointer(val)))
+		{
+			/*
+			 * we're anticipating converting to a short varlena header, so
+			 * adjust length and don't count any alignment
+			 */
+			data_length += VARATT_CONVERTED_SHORT_SIZE(DatumGetPointer(val));
+		}
+		else if (atti->attlen == -1 &&
+				 VARATT_IS_EXTERNAL_EXPANDED(DatumGetPointer(val)))
+		{
+			/*
+			 * we want to flatten the expanded value so that the constructed
+			 * tuple doesn't depend on it
+			 */
+			data_length = att_align_nominal(data_length, atti->attalign);
+			data_length += EOH_get_flat_size(DatumGetEOHP(val));
+		}
+		else
+		{
+			/*
+			 * We'll reach this case when storing a varlena that needs a
+			 * 4-byte header, a variable-width type that requires alignment
+			 * such as a record type, and for fixed-width types that are not
+			 * pass-by-value (e.g. aclitem).
+			 */
+			data_length = att_align_datum(data_length, atti->attalign,
+										  atti->attlen, val);
+			data_length = att_addlength_datum(data_length, atti->attlen,
+											  val);
+		}
+	}
+
+	return data_length - t_hoff;
+}
+
+/*
+ * zheap_fill_tuple
+ *		Load data portion of a tuple from values/isnull arrays.
+ *
+ * We also fill the null bitmap (if any) and set the infomask bits
+ * that reflect the tuple's data contents.  Note that zheap uses different
+ * infomask values than the regular heap, and that the alignment rules
+ * are different (see the file header comment for more details).
+ *
+ * The data area must be pre-zeroed on entry to this function.
+ */
+void
+zheap_fill_tuple(TupleDesc tupleDesc,
+				 Datum *values, bool *isnull,
+				 char *data, Size data_size,
+				 uint16 *infomask, bits8 *bit)
+{
+	bits8	   *bitP;
+	int			bitmask;
+	int			i;
+	int			numberOfAttributes = tupleDesc->natts;
+
+#ifdef USE_ASSERT_CHECKING
+	char	   *start = data;
+#endif
+
+	if (bit != NULL)
+	{
+		bitP = &bit[-1];
+		bitmask = HIGHBIT;
+	}
+	else
+	{
+		/* just to keep compiler quiet */
+		bitP = NULL;
+		bitmask = 0;
+	}
+
+	*infomask &= ~(ZHEAP_HASNULL | ZHEAP_HASVARWIDTH | ZHEAP_HASEXTERNAL);
+
+	for (i = 0; i < numberOfAttributes; i++)
+	{
+		Form_pg_attribute att = TupleDescAttr(tupleDesc, i);
+		Size		data_length;
+
+		if (bit != NULL)
+		{
+			if (bitmask != HIGHBIT)
+				bitmask <<= 1;
+			else
+			{
+				bitP += 1;
+				*bitP = 0x0;
+				bitmask = 1;
+			}
+
+			if (isnull[i])
+			{
+				*infomask |= ZHEAP_HASNULL;
+				continue;
+			}
+
+			*bitP |= bitmask;
+		}
+
+		/*
+		 * We use the att_align macros on the pointer value itself, not on an
+		 * offset.  This is a bit of a hack.
+		 */
+		if (att->attbyval)
+		{
+			/* pass-by-value */
+			memcpy(data, (char *) &values[i], att->attlen);
+			data_length = att->attlen;
+		}
+		else if (att->attlen == -1)
+		{
+			/* varlena */
+			Pointer		val = DatumGetPointer(values[i]);
+
+			*infomask |= ZHEAP_HASVARWIDTH;
+			if (VARATT_IS_EXTERNAL(val))
+			{
+				if (VARATT_IS_EXTERNAL_EXPANDED(val))
+				{
+					/*
+					 * we want to flatten the expanded value so that the
+					 * constructed tuple doesn't depend on it
+					 */
+					ExpandedObjectHeader *eoh = DatumGetEOHP(values[i]);
+
+					data = (char *) att_align_nominal(data,
+													  att->attalign);
+					data_length = EOH_get_flat_size(eoh);
+					EOH_flatten_into(eoh, data, data_length);
+				}
+				else
+				{
+					*infomask |= ZHEAP_HASEXTERNAL;
+					/* no alignment, since it's short by definition */
+					data_length = VARSIZE_EXTERNAL(val);
+					memcpy(data, val, data_length);
+				}
+			}
+			else if (VARATT_IS_SHORT(val))
+			{
+				/* no alignment for short varlenas */
+				data_length = VARSIZE_SHORT(val);
+				memcpy(data, val, data_length);
+			}
+			else if (VARLENA_ATT_IS_PACKABLE(att) &&
+					 VARATT_CAN_MAKE_SHORT(val))
+			{
+				/* convert to short varlena -- no alignment */
+				data_length = VARATT_CONVERTED_SHORT_SIZE(val);
+				SET_VARSIZE_SHORT(data, data_length);
+				memcpy(data + 1, VARDATA(val), data_length - 1);
+			}
+			else
+			{
+				/* full 4-byte header varlena */
+				data = (char *) att_align_nominal(data,
+												  att->attalign);
+				data_length = VARSIZE(val);
+				memcpy(data, val, data_length);
+			}
+		}
+		else if (att->attlen == -2)
+		{
+			/* cstring never needs alignment */
+			*infomask |= ZHEAP_HASVARWIDTH;
+			Assert(att->attalign == 'c');
+			data_length = strlen(DatumGetCString(values[i])) + 1;
+			memcpy(data, DatumGetPointer(values[i]), data_length);
+		}
+		else
+		{
+			/* fixed-length pass-by-reference */
+			data = (char *) att_align_nominal(data, att->attalign);
+			Assert(att->attlen > 0);
+			data_length = att->attlen;
+			memcpy(data, DatumGetPointer(values[i]), data_length);
+		}
+
+		data += data_length;
+	}
+
+	Assert((data - start) == data_size);
+}
+
+/*
+ * zheap_form_tuple
+ *		Construct a zheap tuple from the given values[] and isnull[] arrays.
+ *
+ * The result is allocated in the current memory context.
+ */
+ZHeapTuple
+zheap_form_tuple(TupleDesc tupleDescriptor, Datum *values, bool *isnull)
+{
+	ZHeapTuple	tuple;			/* return tuple */
+	ZHeapTupleHeader td;		/* tuple data */
+	Size		len,
+				data_len;
+	int			hoff;
+	bool		hasnull = false;
+	int			numberOfAttributes = tupleDescriptor->natts;
+	int			i;
+
+	if (numberOfAttributes > MaxTupleAttributeNumber)
+		ereport(ERROR,
+				(errcode(ERRCODE_TOO_MANY_COLUMNS),
+				 errmsg("number of columns (%d) exceeds limit (%d)",
+						numberOfAttributes, MaxTupleAttributeNumber)));
+
+	/* Check for nulls */
+	for (i = 0; i < numberOfAttributes; i++)
+	{
+		if (isnull[i])
+		{
+			hasnull = true;
+			break;
+		}
+	}
+
+	/* Compute required space.  Note that, in zheap, hoff is not aligned. */
+	len = offsetof(ZHeapTupleHeaderData, t_bits);
+	if (hasnull)
+		len += BITMAPLEN(numberOfAttributes);
+	hoff = len;
+	data_len = zheap_compute_data_size(tupleDescriptor, values, isnull, hoff);
+	len += data_len;
+
+	/* Allocate the require space as a single chunk. */
+	tuple = MemoryContextAllocExtended(CurrentMemoryContext,
+									   ZHEAPTUPLESIZE + len,
+									   MCXT_ALLOC_HUGE | MCXT_ALLOC_ZERO);
+	tuple->t_data = td = (ZHeapTupleHeader) ((char *) tuple + ZHEAPTUPLESIZE);
+
+	/*
+	 * And fill in the information.  Note we fill the Datum fields even though
+	 * this tuple may never become a Datum.  This lets HeapTupleHeaderGetDatum
+	 * identify the tuple type if needed.
+	 *
+	 * ZBORKED: The comment above is false.  Not only do we not set those
+	 * fields, but in zheap they don't even exist.  Do we just need to adjust
+	 * the comment, or is there something that actually needs to be changed
+	 * here?
+	 */
+	tuple->t_len = len;
+	ItemPointerSetInvalid(&(tuple->t_self));
+	tuple->t_tableOid = InvalidOid;
+
+	ZHeapTupleHeaderSetNatts(td, numberOfAttributes);
+	td->t_hoff = hoff;
+
+	zheap_fill_tuple(tupleDescriptor,
+					 values,
+					 isnull,
+					 (char *) td + hoff,
+					 data_len,
+					 &td->t_infomask,
+					 (hasnull ? td->t_bits : NULL));
+
+	return tuple;
+}
+
+/*
+ * zheap_deform_tuple
+ * 		Extract data from a zheap tuple into values/isnull arrays.
+ *
+ * See file header comments for an explanation of why attcacheoff is not
+ * used here.  Note that for pass-by-referenced datatypes, the pointer
+ * placed in the Datum will point into the given tuple.
+ */
+void
+zheap_deform_tuple(ZHeapTuple tuple, TupleDesc tupleDesc,
+				   Datum *values, bool *isnull, int att_count)
+{
+	ZHeapTupleHeader tup = tuple->t_data;
+	bool		hasnulls = ZHeapTupleHasNulls(tuple);
+	int			natts;			/* number of atts to extract */
+	int			attnum;
+	char	   *tp;				/* ptr to tuple data */
+	long		off;			/* offset in tuple data */
+	bits8	   *bp = tup->t_bits;	/* ptr to null bitmap in tuple */
+
+	natts = ZHeapTupleHeaderGetNatts(tup);
+
+	/*
+	 * In inheritance situations, it is possible that the given tuple actually
+	 * has more fields than the caller is expecting.  Don't run off the end of
+	 * the caller's arrays.
+	 */
+	natts = Min(natts, att_count);
+	tp = (char *) tup;
+	off = tup->t_hoff;
+
+	/* Loop over attributes one by one. */
+	for (attnum = 0; attnum < natts; attnum++)
+	{
+		Form_pg_attribute thisatt = TupleDescAttr(tupleDesc, attnum);
+
+		if (hasnulls && att_isnull(attnum, bp))
+		{
+			values[attnum] = (Datum) 0;
+			isnull[attnum] = true;
+			continue;
+		}
+
+		isnull[attnum] = false;
+
+		/*
+		 * If this is a varlena, there might be alignment padding, if it has a
+		 * 4-byte header.  Otherwise, there will only be padding if it's not
+		 * pass-by-value.
+		 */
+		if (thisatt->attlen == -1)
+			off = att_align_pointer(off, thisatt->attalign, -1,
+									tp + off);
+		else if (!thisatt->attbyval)
+			off = att_align_nominal(off, thisatt->attalign);
+
+		if (thisatt->attbyval)
+		{
+			Datum		datum;
+
+			/*
+			 * Since pass-by-value attributes are not aligned in zheap, use
+			 * memcpy to copy the value into adequately-aligned storage. Since
+			 * it's pass-by-value, a Datum must be big enough.
+			 */
+			memcpy(&datum, tp + off, thisatt->attlen);
+
+			/*
+			 * We use fetch_att to set the other uninitialized bytes in datum
+			 * field as zero.  We could achieve that by just initializing
+			 * datum with zero, but this helps us to keep the code in sync
+			 * with heap.
+			 */
+			values[attnum] = fetch_att(&datum, true, thisatt->attlen);
+		}
+		else
+			values[attnum] = PointerGetDatum((char *) (tp + off));
+
+		off = att_addlength_pointer(off, thisatt->attlen, tp + off);
+	}
+
+	/*
+	 * If tuple doesn't have all the atts indicated by tupleDesc, read the
+	 * rest as nulls or missing values as appropriate.
+	 */
+	for (; attnum < att_count; attnum++)
+		values[attnum] = getmissingattr(tupleDesc, attnum + 1, &isnull[attnum]);
+}
+
+/*
+ * zheap_freetuple
+ * 		Free memory used to store zheap tuple.
+ */
+void
+zheap_freetuple(ZHeapTuple zhtup)
+{
+	pfree(zhtup);
+}
+
+/*
+ * zheap_getsysattr
+ *		Fetch the value of a system attribute for a tuple.
+ */
+Datum
+zheap_getsysattr(ZHeapTuple zhtup, Buffer buf, int attnum,
+				 TupleDesc tupleDesc, bool *isnull)
+{
+	Datum		result;
+
+	Assert(zhtup);
+
+
+	/* Currently, no sys attribute ever reads as NULL. */
+	*isnull = false;
+
+	switch (attnum)
+	{
+		case SelfItemPointerAttributeNumber:
+			/* pass-by-reference datatype */
+			result = PointerGetDatum(&(zhtup->t_self));
+			break;
+		case MinTransactionIdAttributeNumber:
+			{
+				ZHeapTupleTransInfo zinfo;
+				bool		release_buf = false;
+				ItemPointer tid = &zhtup->t_self;
+
+				/*
+				 * For xmin we may need to fetch the information from the undo
+				 * record, so ensure we have a valid buffer.
+				 *
+				 * ZBORKED: It does not seem acceptable to call
+				 * relation_open() here. This is a very low-level function
+				 * which has no business touching the relcache.
+				 */
+				if (!BufferIsValid(buf))
+				{
+					Relation	rel = relation_open(zhtup->t_tableOid, NoLock);
+
+					buf = ReadBuffer(rel, ItemPointerGetBlockNumber(tid));
+					relation_close(rel, NoLock);
+					release_buf = true;
+				}
+
+				/*
+				 * Fixme - Need to check whether we need any handling of epoch
+				 * here.
+				 */
+				ZHeapTupleGetTransInfo(buf, ItemPointerGetOffsetNumber(tid),
+									   &zinfo);
+
+				if (!TransactionIdIsValid(zinfo.xid) ||
+					FullTransactionIdOlderThanAllUndo(zinfo.epoch_xid))
+					zinfo.xid = FrozenTransactionId;
+
+				result = TransactionIdGetDatum(zinfo.xid);
+
+				if (release_buf)
+					ReleaseBuffer(buf);
+			}
+			break;
+		case MaxTransactionIdAttributeNumber:
+		case MinCommandIdAttributeNumber:
+		case MaxCommandIdAttributeNumber:
+			ereport(ERROR,
+					(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
+					 errmsg("xmax, cmin, and cmax are not supported for zheap tuples")));
+			break;
+		case TableOidAttributeNumber:
+			result = ObjectIdGetDatum(zhtup->t_tableOid);
+			break;
+		default:
+			elog(ERROR, "invalid attnum: %d", attnum);
+			result = 0;			/* keep compiler quiet */
+			break;
+	}
+
+	return result;
+}
+
+/*
+ * zheap_attisnull
+ * 		Returns TRUE if zheap tuple attribute is not present.
+ */
+bool
+zheap_attisnull(ZHeapTuple tup, int attnum, TupleDesc tupleDesc)
+{
+	if (attnum > (int) ZHeapTupleHeaderGetNatts(tup->t_data))
+		return true;
+
+	/*
+	 * We allow a NULL tupledesc for relations not expected to have missing
+	 * values, such as catalog relations and indexes.
+	 */
+	Assert(!tupleDesc || attnum <= tupleDesc->natts);
+	if (attnum > (int) ZHeapTupleHeaderGetNatts(tup->t_data))
+	{
+		if (tupleDesc && TupleDescAttr(tupleDesc, attnum - 1)->atthasmissing)
+			return false;
+		else
+			return true;
+	}
+
+	if (attnum > 0)
+	{
+		if (ZHeapTupleNoNulls(tup))
+			return false;
+		return att_isnull(attnum - 1, tup->t_data->t_bits);
+	}
+
+	switch (attnum)
+	{
+		case TableOidAttributeNumber:
+		case SelfItemPointerAttributeNumber:
+		case MinTransactionIdAttributeNumber:
+		case MinCommandIdAttributeNumber:
+		case MaxTransactionIdAttributeNumber:
+		case MaxCommandIdAttributeNumber:
+			/* these are never null */
+			break;
+		default:
+			elog(ERROR, "invalid attnum: %d", attnum);
+	}
+
+	return false;
+}
+
+/*
+ * zheap_tuple_attr_equals
+ *		Subroutine for ZHeapDetermineModifiedColumns which returns the set of
+ *		attributes from the given att_list that are different in tup1 and tup2.
+ */
+Bitmapset *
+zheap_tuple_attr_equals(TupleDesc tupdesc, Bitmapset *att_list,
+						ZHeapTuple tup1, ZHeapTuple tup2)
+{
+	int			l_attno = 0,
+				col = -1;
+	bool		old_isnull[MaxHeapAttributeNumber],
+				new_isnull[MaxHeapAttributeNumber];
+	Datum		old_values[MaxHeapAttributeNumber],
+				new_values[MaxHeapAttributeNumber];
+	Bitmapset  *modified = NULL;
+
+	/* Find the largest attno in the given Bitmapset. */
+	while ((col = bms_next_member(att_list, col)) >= 0)
+	{
+		/* bit numbers are offset by FirstLowInvalidHeapAttributeNumber */
+		AttrNumber	attno = col + FirstLowInvalidHeapAttributeNumber;
+
+		if (attno <= InvalidAttrNumber) /* shouldn't happen */
+			elog(ERROR, "system-column update is not supported");
+
+		if (l_attno < attno)
+			l_attno = attno;
+	}
+
+	Assert(l_attno <= tupdesc->natts);
+
+	/* Deform both the old and new tuple. */
+	zheap_deform_tuple(tup1, tupdesc, old_values, old_isnull, l_attno);
+	zheap_deform_tuple(tup2, tupdesc, new_values, new_isnull, l_attno);
+
+	/* Loop through atts and add every non-equal attno to modified. */
+	col = -1;
+	while ((col = bms_next_member(att_list, col)) >= 0)
+	{
+		/* bit numbers are offset by FirstLowInvalidHeapAttributeNumber */
+		AttrNumber	attno = col + FirstLowInvalidHeapAttributeNumber;
+
+		/* If one value is NULL and other is not, they are not equal. */
+		if (old_isnull[attno - 1] != new_isnull[attno - 1])
+			modified = bms_add_member(modified, attno - FirstLowInvalidHeapAttributeNumber);
+
+		/* If both are NULL, they can be considered equal. */
+		else if (old_isnull[attno - 1])
+			continue;
+
+		else
+		{
+			Form_pg_attribute att = TupleDescAttr(tupdesc, attno - 1);
+
+			/*
+			 * We do simple binary comparison of the two datums.  This may be
+			 * overly strict because there can be multiple binary
+			 * representations for the same logical value.  But we should be
+			 * OK as long as there are no false positives.  Using a
+			 * type-specific equality operator is messy because there could be
+			 * multiple notions of equality in different operator classes;
+			 * furthermore, we cannot safely invoke user-defined functions
+			 * while holding exclusive buffer lock.
+			 */
+			if (!datumIsEqual(old_values[attno - 1], new_values[attno - 1],
+							  att->attbyval, att->attlen))
+				modified = bms_add_member(modified,
+										  attno - FirstLowInvalidHeapAttributeNumber);
+		}
+	}
+
+	return modified;
+}
+
+
+/*
+ * TupleTableSlotOps implementation for ZheapHeapTupleTableSlot.
+ */
+
+static void
+tts_zheap_init(TupleTableSlot *slot)
+{
+}
+
+static void
+tts_zheap_release(TupleTableSlot *slot)
+{
+}
+
+static void
+tts_zheap_clear(TupleTableSlot *slot)
+{
+	ZHeapTupleTableSlot *zslot = (ZHeapTupleTableSlot *) slot;
+
+	/*
+	 * Free the memory for heap tuple if allowed. A tuple coming from zheap
+	 * can never be freed. But we may have materialized a tuple from zheap.
+	 * Such a tuple can be freed.
+	 */
+	if (TTS_SHOULDFREE(slot))
+	{
+		zheap_freetuple(zslot->tuple);
+		slot->tts_flags &= ~TTS_FLAG_SHOULDFREE;
+	}
+
+	slot->tts_nvalid = 0;
+	slot->tts_flags |= TTS_FLAG_EMPTY;
+	zslot->tuple = NULL;
+	zslot->off = 0;
+}
+
+static void
+tts_zheap_getsomeattrs(TupleTableSlot *slot, int natts)
+{
+	ZHeapTupleTableSlot *zslot = (ZHeapTupleTableSlot *) slot;
+
+	Assert(!TTS_EMPTY(slot));
+	slot_deform_ztuple(slot, zslot->tuple, &zslot->off, natts);
+}
+
+static Datum
+tts_zheap_getsysattr(TupleTableSlot *slot, int attnum, bool *isnull)
+{
+	ZHeapTupleTableSlot *zslot = (ZHeapTupleTableSlot *) slot;
+
+	return zheap_getsysattr(zslot->tuple, InvalidBuffer, attnum,
+							slot->tts_tupleDescriptor, isnull);
+}
+
+/*
+ * tts_zheap_materialize
+ * 		Materialize the zheap tuple contained in the given slot into its own
+ *		memory context.
+ */
+static void
+tts_zheap_materialize(TupleTableSlot *slot)
+{
+	ZHeapTupleTableSlot *zslot = (ZHeapTupleTableSlot *) slot;
+	MemoryContext oldContext;
+
+	Assert(!TTS_EMPTY(slot));
+
+	/* If already materialized nothing to do. */
+	if (TTS_SHOULDFREE(slot))
+		return;
+
+	slot->tts_flags |= TTS_FLAG_SHOULDFREE;
+
+	oldContext = MemoryContextSwitchTo(slot->tts_mcxt);
+
+	if (zslot->tuple)
+		zslot->tuple = zheap_copytuple(zslot->tuple);
+	else
+	{
+		/*
+		 * The tuple contained in this slot is not allocated in the memory
+		 * context of the given slot (else it would have TTS_SHOULDFREE set).
+		 * Copy the tuple into the given slot's memory context.
+		 */
+		zslot->tuple = zheap_form_tuple(slot->tts_tupleDescriptor,
+										slot->tts_values,
+										slot->tts_isnull);
+	}
+	MemoryContextSwitchTo(oldContext);
+
+	/*
+	 * Have to deform from scratch, otherwise tts_values[] entries could point
+	 * into the non-materialized tuple (which might be gone when accessed).
+	 */
+	slot->tts_nvalid = 0;
+	zslot->off = 0;
+}
+
+/*
+ * tts_zheap_copyslot
+ *
+ * ZBORKED: This is extremely inefficient, because it forms a heap tuple
+ * for the source slot which we definitely can't store, and must therefore
+ * deform again -- only to turn around and build a zheap tuple again.
+ * It seems like we should instead do slot_getallattrs() on the source slot
+ * and then copy the Datum/isnull arrays.
+ */
+static void
+tts_zheap_copyslot(TupleTableSlot *dstslot, TupleTableSlot *srcslot)
+{
+	HeapTuple	tuple;
+	MemoryContext oldcontext;
+
+	oldcontext = MemoryContextSwitchTo(dstslot->tts_mcxt);
+	tuple = ExecCopySlotHeapTuple(srcslot);
+	MemoryContextSwitchTo(oldcontext);
+
+	ExecForceStoreHeapTuple(tuple, dstslot, false);
+	ExecMaterializeSlot(dstslot);
+
+	pfree(tuple);
+}
+
+/*
+ * tts_zheap_copy_heap_tuple
+ *		Return a heap tuple constructed from the contents of the slot.
+ *
+ * heap_form_tuple will always a build a new tuple, so we don't need an
+ * explicit copy step.
+ */
+static HeapTuple
+tts_zheap_copy_heap_tuple(TupleTableSlot *slot)
+{
+	HeapTuple	tuple;
+
+	Assert(!TTS_EMPTY(slot));
+	slot_getallattrs(slot);
+
+	tuple = heap_form_tuple(slot->tts_tupleDescriptor,
+							slot->tts_values, slot->tts_isnull);
+	tuple->t_self = slot->tts_tid;
+	tuple->t_tableOid = slot->tts_tableOid;
+
+	return tuple;
+}
+
+/*
+ * tts_zheap_copy_minimal_tuple
+ *		Return a minimal tuple constructed from the contents of the slot.
+ *
+ * heap_form_minimal_tuple will always a build a new tuple, so we don't
+ * need an explicit copy step.
+ */
+static MinimalTuple
+tts_zheap_copy_minimal_tuple(TupleTableSlot *slot)
+{
+	Assert(!TTS_EMPTY(slot));
+
+	slot_getallattrs(slot);
+
+	return heap_form_minimal_tuple(slot->tts_tupleDescriptor,
+								   slot->tts_values, slot->tts_isnull);
+}
+
+void
+slot_deform_ztuple(TupleTableSlot *slot, ZHeapTuple tuple,
+				   uint32 *offp, int natts)
+{
+	TupleDesc	tupleDesc = slot->tts_tupleDescriptor;
+	Datum	   *values = slot->tts_values;
+	bool	   *isnull = slot->tts_isnull;
+	ZHeapTupleHeader tup = tuple->t_data;
+	bool		hasnulls = ZHeapTupleHasNulls(tuple);
+	int			attnum;
+	char	   *tp;				/* ptr to tuple data */
+	uint32		off;			/* offset in tuple data */
+	bits8	   *bp = tup->t_bits;	/* ptr to null bitmap in tuple */
+
+	/* We can only fetch as many attributes as the tuple has. */
+	natts = Min(ZHeapTupleHeaderGetNatts(tuple->t_data), natts);
+
+	/*
+	 * Check whether the first call for this tuple, and initialize or restore
+	 * loop state.
+	 */
+	attnum = slot->tts_nvalid;
+	if (attnum == 0)
+		off = 0;				/* Start from the first attribute */
+	else
+		off = *offp;			/* Restore state from previous execution */
+
+	tp = (char *) tup + tup->t_hoff + off;
+
+	for (; attnum < natts; attnum++)
+	{
+		Form_pg_attribute thisatt = TupleDescAttr(tupleDesc, attnum);
+
+		if (hasnulls && att_isnull(attnum, bp))
+		{
+			values[attnum] = (Datum) 0;
+			isnull[attnum] = true;
+			continue;
+		}
+
+		isnull[attnum] = false;
+
+		if (thisatt->attlen == -1)
+		{
+			tp = (char *) att_align_pointer(tp, thisatt->attalign, -1,
+											tp);
+		}
+		else if (!thisatt->attbyval)
+		{
+			/* not varlena, so safe to use att_align_nominal */
+			tp = (char *) att_align_nominal(tp, thisatt->attalign);
+		}
+
+		if (thisatt->attbyval)
+		{
+			Datum		datum;
+
+			/*
+			 * Since pass-by-value attributes are not aligned in zheap, use
+			 * memcpy to copy the value into adequately-aligned storage. Since
+			 * it's pass-by-value, a Datum must be big enough.
+			 */
+			memcpy(&datum, tp, thisatt->attlen);
+
+			/*
+			 * We use fetch_att to set the other uninitialized bytes in datum
+			 * field as zero.  We could achieve that by just initializing
+			 * datum with zero, but this helps us to keep the code in sync
+			 * with heap.
+			 */
+			values[attnum] = fetch_att(&datum, true, thisatt->attlen);
+		}
+		else
+			values[attnum] = PointerGetDatum(tp);
+
+		tp = att_addlength_pointer(tp, thisatt->attlen, tp);
+	}
+
+	/*
+	 * Save state for next execution
+	 */
+	slot->tts_nvalid = attnum;
+	*offp = tp - ((char *) tup + tup->t_hoff);
+}
+
+/*
+ * ExecGetZHeapTupleFromSlot
+ *   Fetch ZHeapTuple representing the slot's content.
+ */
+ZHeapTuple
+ExecGetZHeapTupleFromSlot(TupleTableSlot *slot)
+{
+	ZHeapTupleTableSlot *zslot = (ZHeapTupleTableSlot *) slot;
+
+	if (TTS_EMPTY(slot))
+		return NULL;
+
+	/*
+	 * ZBORKED: to fix the memory management for this, the API should be like
+	 * ExecFetchSlotHeapTuple()'s.
+	 */
+	if (!TTS_IS_ZHEAP(slot))
+	{
+		slot_getallattrs(slot);
+		return zheap_form_tuple(slot->tts_tupleDescriptor,
+								slot->tts_values,
+								slot->tts_isnull);
+	}
+
+	if (!zslot->tuple)
+		slot->tts_ops->materialize(slot);
+
+	return zslot->tuple;
+}
+
+/*
+ * ExecStoreZHeapTuple
+ *		Store a physical zheap tuple into a TTSOpsZHeapTuple slot.
+ */
+TupleTableSlot *
+ExecStoreZHeapTuple(ZHeapTuple tuple, TupleTableSlot *slot, bool shouldFree)
+{
+	ZHeapTupleTableSlot *zslot = (ZHeapTupleTableSlot *) slot;
+
+	/* sanity checks */
+	Assert(slot != NULL);
+	Assert(TTS_IS_ZHEAP(slot));
+
+	/* clear slot and store new tuple */
+	tts_zheap_clear(slot);
+	zslot->tuple = tuple;
+	slot->tts_flags &= ~TTS_FLAG_EMPTY;
+	slot->tts_tid = tuple->t_self;
+
+	/* set flag if needed */
+	if (shouldFree)
+		slot->tts_flags |= TTS_FLAG_SHOULDFREE;
+
+	return slot;
+}
+
+/*
+ * zheap_copytuple
+ *		Returns a copy of an entire tuple.
+ *
+ * The ZHeapTuple struct, tuple header, and tuple data are all allocated
+ * as a single palloc() block.
+ */
+ZHeapTuple
+zheap_copytuple(ZHeapTuple tuple)
+{
+	ZHeapTuple	newTuple;
+
+	if (!ZHeapTupleIsValid(tuple) || tuple->t_data == NULL)
+		return NULL;
+
+	newTuple = (ZHeapTuple) palloc(ZHEAPTUPLESIZE + tuple->t_len);
+	newTuple->t_len = tuple->t_len;
+	newTuple->t_self = tuple->t_self;
+	newTuple->t_tableOid = tuple->t_tableOid;
+	newTuple->t_data = (ZHeapTupleHeader) ((char *) newTuple + ZHEAPTUPLESIZE);
+	memcpy((char *) newTuple->t_data, (char *) tuple->t_data, tuple->t_len);
+	return newTuple;
+}
diff --git a/src/backend/access/zheap/ztuptoaster.c b/src/backend/access/zheap/ztuptoaster.c
new file mode 100644
index 0000000..939b77d
--- /dev/null
+++ b/src/backend/access/zheap/ztuptoaster.c
@@ -0,0 +1,980 @@
+/*-------------------------------------------------------------------------
+ *
+ * ztuptoaster.c
+ *	  Support routines for external and compressed storage of
+ *	  variable size attributes.
+ *
+ *	  This file contains common functionality with tuptoaster except that
+ *	  the tuples are of zheap format and stored in zheap storage engine.
+ *	  Even if we want to keep it as a separate code for this, the common
+ *	  parts needs to be extracted.
+ *
+ *	  The benefit of storing toast data in zheap is that it avoids bloat in
+ *	  toast storage. The tuple space can be immediately reclaimed once the
+ *	  deleting transaction is committed.
+ *
+ * Copyright (c) 2000-2019, PostgreSQL Global Development Group
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/heap/ztuptoaster.c
+ *
+ *
+ * INTERFACE ROUTINES
+ *		ztoast_insert_or_update -
+ *			Try to make a given tuple fit into one page by compressing
+ *			or moving off attributes
+ *
+ *		ztoast_delete -
+ *			Reclaim toast storage when a tuple is deleted
+ *
+ *
+ *
+ *-------------------------------------------------------------------------
+ */
+
+#include "postgres.h"
+
+#include <unistd.h>
+#include <fcntl.h>
+
+#include "access/genam.h"
+#include "access/table.h"
+#include "access/tuptoaster.h"
+#include "access/xact.h"
+#include "catalog/catalog.h"
+#include "common/pg_lzcompress.h"
+#include "miscadmin.h"
+#include "utils/expandeddatum.h"
+#include "utils/fmgroids.h"
+#include "utils/rel.h"
+#include "utils/snapmgr.h"
+#include "utils/typcache.h"
+#include "access/zheap.h"
+
+static void ztoast_delete_datum(Relation rel, Datum value, bool is_speculative);
+static Datum ztoast_save_datum(Relation rel, Datum value,
+							   struct varlena *oldexternal, int options, uint32 specToken);
+
+/*
+ * ztoast_insert_or_update
+ *		Just like toast_insert_or_update but for zheap relations.
+ */
+
+ZHeapTuple
+ztoast_insert_or_update(Relation rel, ZHeapTuple newtup, ZHeapTuple oldtup,
+						int options, uint32 specToken)
+{
+	ZHeapTuple	result_tuple;
+	TupleDesc	tupleDesc;
+	int			numAttrs;
+	int			i;
+
+	bool		need_change = false;
+	bool		need_free = false;
+	bool		need_delold = false;
+	bool		has_nulls = false;
+
+	Size		maxDataLen;
+	Size		hoff;
+
+	char		toast_action[MaxHeapAttributeNumber];
+	bool		toast_isnull[MaxHeapAttributeNumber];
+	bool		toast_oldisnull[MaxHeapAttributeNumber];
+	Datum		toast_values[MaxHeapAttributeNumber];
+	Datum		toast_oldvalues[MaxHeapAttributeNumber];
+	struct varlena *toast_oldexternal[MaxHeapAttributeNumber];
+	int32		toast_sizes[MaxHeapAttributeNumber];
+	bool		toast_free[MaxHeapAttributeNumber];
+	bool		toast_delold[MaxHeapAttributeNumber];
+
+	/*
+	 * We should only ever be called for tuples of plain relations or
+	 * materialized views --- recursing on a toast rel is bad news.
+	 */
+	Assert(rel->rd_rel->relkind == RELKIND_RELATION ||
+		   rel->rd_rel->relkind == RELKIND_MATVIEW);
+
+	/*
+	 * Get the tuple descriptor and break down the tuple(s) into fields.
+	 */
+	tupleDesc = rel->rd_att;
+	numAttrs = tupleDesc->natts;
+
+	Assert(numAttrs <= MaxHeapAttributeNumber);
+	zheap_deform_tuple(newtup, tupleDesc, toast_values, toast_isnull, tupleDesc->natts);
+	if (oldtup != NULL)
+		zheap_deform_tuple(oldtup, tupleDesc, toast_oldvalues, toast_oldisnull, tupleDesc->natts);
+
+	/* ----------
+	 * Then collect information about the values given
+	 *
+	 * NOTE: toast_action[i] can have these values:
+	 *		' '		default handling
+	 *		'p'		already processed --- don't touch it
+	 *		'x'		incompressible, but OK to move off
+	 *
+	 * NOTE: toast_sizes[i] is only made valid for varlena attributes with
+	 *		toast_action[i] different from 'p'.
+	 * ----------
+	 */
+	memset(toast_action, ' ', numAttrs * sizeof(char));
+	memset(toast_oldexternal, 0, numAttrs * sizeof(struct varlena *));
+	memset(toast_free, 0, numAttrs * sizeof(bool));
+	memset(toast_delold, 0, numAttrs * sizeof(bool));
+
+	for (i = 0; i < numAttrs; i++)
+	{
+		Form_pg_attribute att = TupleDescAttr(tupleDesc, i);
+		struct varlena *old_value;
+		struct varlena *new_value;
+
+		if (oldtup != NULL)
+		{
+			/*
+			 * For UPDATE get the old and new values of this attribute
+			 */
+			old_value = (struct varlena *) DatumGetPointer(toast_oldvalues[i]);
+			new_value = (struct varlena *) DatumGetPointer(toast_values[i]);
+
+			/*
+			 * If the old value is stored on disk, check if it has changed so
+			 * we have to delete it later.
+			 */
+			if (att->attlen == -1 && !toast_oldisnull[i] &&
+				VARATT_IS_EXTERNAL_ONDISK(old_value))
+			{
+				if (toast_isnull[i] || !VARATT_IS_EXTERNAL_ONDISK(new_value) ||
+					memcmp((char *) old_value, (char *) new_value,
+						   VARSIZE_EXTERNAL(old_value)) != 0)
+				{
+					/*
+					 * The old external stored value isn't needed any more
+					 * after the update
+					 */
+					toast_delold[i] = true;
+					need_delold = true;
+				}
+				else
+				{
+					/*
+					 * This attribute isn't changed by this update so we reuse
+					 * the original reference to the old value in the new
+					 * tuple.
+					 */
+					toast_action[i] = 'p';
+					continue;
+				}
+			}
+		}
+		else
+		{
+			/*
+			 * For INSERT simply get the new value
+			 */
+			new_value = (struct varlena *) DatumGetPointer(toast_values[i]);
+		}
+
+		/*
+		 * Handle NULL attributes
+		 */
+		if (toast_isnull[i])
+		{
+			toast_action[i] = 'p';
+			has_nulls = true;
+			continue;
+		}
+
+		/*
+		 * Now look at varlena attributes
+		 */
+		if (att->attlen == -1)
+		{
+			/*
+			 * If the table's attribute says PLAIN always, force it so.
+			 */
+			if (att->attstorage == 'p')
+				toast_action[i] = 'p';
+
+			/*
+			 * We took care of UPDATE above, so any external value we find
+			 * still in the tuple must be someone else's that we cannot reuse
+			 * (this includes the case of an out-of-line in-memory datum).
+			 * Fetch it back (without decompression, unless we are forcing
+			 * PLAIN storage).  If necessary, we'll push it out as a new
+			 * external value below.
+			 */
+			if (VARATT_IS_EXTERNAL(new_value))
+			{
+				toast_oldexternal[i] = new_value;
+				if (att->attstorage == 'p')
+					new_value = heap_tuple_untoast_attr(new_value);
+				else
+					new_value = heap_tuple_fetch_attr(new_value);
+				toast_values[i] = PointerGetDatum(new_value);
+				toast_free[i] = true;
+				need_change = true;
+				need_free = true;
+			}
+
+			/*
+			 * Remember the size of this attribute
+			 */
+			toast_sizes[i] = VARSIZE_ANY(new_value);
+		}
+		else
+		{
+			/*
+			 * Not a varlena attribute, plain storage always
+			 */
+			toast_action[i] = 'p';
+		}
+	}
+
+	/* ----------
+	 * Compress and/or save external until data fits into target length
+	 *
+	 *	1: Inline compress attributes with attstorage 'x', and store very
+	 *	   large attributes with attstorage 'x' or 'e' external immediately
+	 *	2: Store attributes with attstorage 'x' or 'e' external
+	 *	3: Inline compress attributes with attstorage 'm'
+	 *	4: Store attributes with attstorage 'm' external
+	 * ----------
+	 */
+
+	/* compute header overhead --- this should match heap_form_tuple() */
+	hoff = SizeofZHeapTupleHeader;
+	if (has_nulls)
+		hoff += BITMAPLEN(numAttrs);
+
+	/* now convert to a limit on the tuple data size */
+	maxDataLen = RelationGetToastTupleTarget(rel, TOAST_TUPLE_TARGET) - hoff;
+
+	/*
+	 * Look for attributes with attstorage 'x' to compress.  Also find large
+	 * attributes with attstorage 'x' or 'e', and store them external.
+	 */
+	while (zheap_compute_data_size(tupleDesc,
+								   toast_values, toast_isnull, hoff) > maxDataLen)
+	{
+		int			biggest_attno = -1;
+		int32		biggest_size = MAXALIGN(TOAST_POINTER_SIZE);
+		Datum		old_value;
+		Datum		new_value;
+
+		/*
+		 * Search for the biggest yet unprocessed internal attribute
+		 */
+		for (i = 0; i < numAttrs; i++)
+		{
+			Form_pg_attribute att = TupleDescAttr(tupleDesc, i);
+
+			if (toast_action[i] != ' ')
+				continue;
+			if (VARATT_IS_EXTERNAL(DatumGetPointer(toast_values[i])))
+				continue;		/* can't happen, toast_action would be 'p' */
+			if (VARATT_IS_COMPRESSED(DatumGetPointer(toast_values[i])))
+				continue;
+			if (att->attstorage != 'x' && att->attstorage != 'e')
+				continue;
+			if (toast_sizes[i] > biggest_size)
+			{
+				biggest_attno = i;
+				biggest_size = toast_sizes[i];
+			}
+		}
+
+		if (biggest_attno < 0)
+			break;
+
+		/*
+		 * Attempt to compress it inline, if it has attstorage 'x'
+		 */
+		i = biggest_attno;
+		if (TupleDescAttr(tupleDesc, i)->attstorage == 'x')
+		{
+			old_value = toast_values[i];
+			new_value = toast_compress_datum(old_value);
+
+			if (DatumGetPointer(new_value) != NULL)
+			{
+				/* successful compression */
+				if (toast_free[i])
+					pfree(DatumGetPointer(old_value));
+				toast_values[i] = new_value;
+				toast_free[i] = true;
+				toast_sizes[i] = VARSIZE(DatumGetPointer(toast_values[i]));
+				need_change = true;
+				need_free = true;
+			}
+			else
+			{
+				/* incompressible, ignore on subsequent compression passes */
+				toast_action[i] = 'x';
+			}
+		}
+		else
+		{
+			/* has attstorage 'e', ignore on subsequent compression passes */
+			toast_action[i] = 'x';
+		}
+
+		/*
+		 * If this value is by itself more than maxDataLen (after compression
+		 * if any), push it out to the toast table immediately, if possible.
+		 * This avoids uselessly compressing other fields in the common case
+		 * where we have one long field and several short ones.
+		 *
+		 * XXX maybe the threshold should be less than maxDataLen?
+		 */
+		if (toast_sizes[i] > maxDataLen &&
+			rel->rd_rel->reltoastrelid != InvalidOid)
+		{
+			old_value = toast_values[i];
+			toast_action[i] = 'p';
+			toast_values[i] = ztoast_save_datum(rel, toast_values[i],
+												toast_oldexternal[i], options,
+												specToken);
+			if (toast_free[i])
+				pfree(DatumGetPointer(old_value));
+			toast_free[i] = true;
+			need_change = true;
+			need_free = true;
+		}
+	}
+
+	/*
+	 * Second we look for attributes of attstorage 'x' or 'e' that are still
+	 * inline.  But skip this if there's no toast table to push them to.
+	 */
+	while (zheap_compute_data_size(tupleDesc,
+								   toast_values, toast_isnull, hoff) > maxDataLen &&
+		   rel->rd_rel->reltoastrelid != InvalidOid)
+	{
+		int			biggest_attno = -1;
+		int32		biggest_size = MAXALIGN(TOAST_POINTER_SIZE);
+		Datum		old_value;
+
+		/*------
+		 * Search for the biggest yet inlined attribute with
+		 * attstorage equals 'x' or 'e'
+		 *------
+		 */
+		for (i = 0; i < numAttrs; i++)
+		{
+			Form_pg_attribute att = TupleDescAttr(tupleDesc, i);
+
+			if (toast_action[i] == 'p')
+				continue;
+			if (VARATT_IS_EXTERNAL(DatumGetPointer(toast_values[i])))
+				continue;		/* can't happen, toast_action would be 'p' */
+			if (att->attstorage != 'x' && att->attstorage != 'e')
+				continue;
+			if (toast_sizes[i] > biggest_size)
+			{
+				biggest_attno = i;
+				biggest_size = toast_sizes[i];
+			}
+		}
+
+		if (biggest_attno < 0)
+			break;
+
+		/*
+		 * Store this external
+		 */
+		i = biggest_attno;
+		old_value = toast_values[i];
+		toast_action[i] = 'p';
+		toast_values[i] = ztoast_save_datum(rel, toast_values[i],
+											toast_oldexternal[i], options,
+											specToken);
+		if (toast_free[i])
+			pfree(DatumGetPointer(old_value));
+		toast_free[i] = true;
+
+		need_change = true;
+		need_free = true;
+	}
+
+	/*
+	 * Round 3 - this time we take attributes with storage 'm' into
+	 * compression
+	 */
+	while (zheap_compute_data_size(tupleDesc,
+								   toast_values, toast_isnull, hoff) > maxDataLen)
+	{
+		int			biggest_attno = -1;
+		int32		biggest_size = MAXALIGN(TOAST_POINTER_SIZE);
+		Datum		old_value;
+		Datum		new_value;
+
+		/*
+		 * Search for the biggest yet uncompressed internal attribute
+		 */
+		for (i = 0; i < numAttrs; i++)
+		{
+			if (toast_action[i] != ' ')
+				continue;
+			if (VARATT_IS_EXTERNAL(DatumGetPointer(toast_values[i])))
+				continue;		/* can't happen, toast_action would be 'p' */
+			if (VARATT_IS_COMPRESSED(DatumGetPointer(toast_values[i])))
+				continue;
+			if (TupleDescAttr(tupleDesc, i)->attstorage != 'm')
+				continue;
+			if (toast_sizes[i] > biggest_size)
+			{
+				biggest_attno = i;
+				biggest_size = toast_sizes[i];
+			}
+		}
+
+		if (biggest_attno < 0)
+			break;
+
+		/*
+		 * Attempt to compress it inline
+		 */
+		i = biggest_attno;
+		old_value = toast_values[i];
+		new_value = toast_compress_datum(old_value);
+
+		if (DatumGetPointer(new_value) != NULL)
+		{
+			/* successful compression */
+			if (toast_free[i])
+				pfree(DatumGetPointer(old_value));
+			toast_values[i] = new_value;
+			toast_free[i] = true;
+			toast_sizes[i] = VARSIZE(DatumGetPointer(toast_values[i]));
+			need_change = true;
+			need_free = true;
+		}
+		else
+		{
+			/* incompressible, ignore on subsequent compression passes */
+			toast_action[i] = 'x';
+		}
+	}
+
+	/*
+	 * Finally we store attributes of type 'm' externally.  At this point we
+	 * increase the target tuple size, so that 'm' attributes aren't stored
+	 * externally unless really necessary.
+	 */
+	maxDataLen = TOAST_TUPLE_TARGET_MAIN - hoff;
+
+	while (zheap_compute_data_size(tupleDesc,
+								   toast_values, toast_isnull, hoff) > maxDataLen &&
+		   rel->rd_rel->reltoastrelid != InvalidOid)
+	{
+		int			biggest_attno = -1;
+		int32		biggest_size = MAXALIGN(TOAST_POINTER_SIZE);
+		Datum		old_value;
+
+		/*--------
+		 * Search for the biggest yet inlined attribute with
+		 * attstorage = 'm'
+		 *--------
+		 */
+		for (i = 0; i < numAttrs; i++)
+		{
+			if (toast_action[i] == 'p')
+				continue;
+			if (VARATT_IS_EXTERNAL(DatumGetPointer(toast_values[i])))
+				continue;		/* can't happen, toast_action would be 'p' */
+			if (TupleDescAttr(tupleDesc, i)->attstorage != 'm')
+				continue;
+			if (toast_sizes[i] > biggest_size)
+			{
+				biggest_attno = i;
+				biggest_size = toast_sizes[i];
+			}
+		}
+
+		if (biggest_attno < 0)
+			break;
+
+		/*
+		 * Store this external
+		 */
+		i = biggest_attno;
+		old_value = toast_values[i];
+		toast_action[i] = 'p';
+		toast_values[i] = ztoast_save_datum(rel, toast_values[i],
+											toast_oldexternal[i], options,
+											specToken);
+		if (toast_free[i])
+			pfree(DatumGetPointer(old_value));
+		toast_free[i] = true;
+
+		need_change = true;
+		need_free = true;
+	}
+
+	/*
+	 * In the case we toasted any values, we need to build a new heap tuple
+	 * with the changed values.
+	 */
+	if (need_change)
+	{
+		ZHeapTupleHeader olddata = newtup->t_data;
+		ZHeapTupleHeader new_data;
+		int32		new_header_len;
+		int32		new_data_len;
+		int32		new_tuple_len;
+
+		/*
+		 * Calculate the new size of the tuple.
+		 *
+		 * Note: we used to assume here that the old tuple's t_hoff must equal
+		 * the new_header_len value, but that was incorrect.  The old tuple
+		 * might have a smaller-than-current natts, if there's been an ALTER
+		 * TABLE ADD COLUMN since it was stored; and that would lead to a
+		 * different conclusion about the size of the null bitmap, or even
+		 * whether there needs to be one at all.
+		 */
+		new_header_len = SizeofZHeapTupleHeader;
+		if (has_nulls)
+			new_header_len += BITMAPLEN(numAttrs);
+		new_data_len = zheap_compute_data_size(tupleDesc,
+											   toast_values, toast_isnull, hoff);
+		new_tuple_len = new_header_len + new_data_len;
+
+		/*
+		 * Allocate and zero the space needed, and fill ZHeapTupleData fields.
+		 */
+		result_tuple = (ZHeapTuple) palloc0(ZHEAPTUPLESIZE + new_tuple_len);
+		result_tuple->t_len = new_tuple_len;
+		result_tuple->t_self = newtup->t_self;
+		result_tuple->t_tableOid = newtup->t_tableOid;
+		new_data = (ZHeapTupleHeader) ((char *) result_tuple + ZHEAPTUPLESIZE);
+		result_tuple->t_data = new_data;
+
+		/*
+		 * Copy the existing tuple header, but adjust natts and t_hoff.
+		 */
+		memcpy(new_data, olddata, SizeofZHeapTupleHeader);
+		ZHeapTupleHeaderSetNatts(new_data, numAttrs);
+		new_data->t_hoff = new_header_len;
+
+		/* Copy over the data, and fill the null bitmap if needed */
+		zheap_fill_tuple(tupleDesc,
+						 toast_values,
+						 toast_isnull,
+						 (char *) new_data + new_header_len,
+						 new_data_len,
+						 &(new_data->t_infomask),
+						 has_nulls ? new_data->t_bits : NULL);
+	}
+	else
+		result_tuple = newtup;
+
+	/*
+	 * Free allocated temp values
+	 */
+	if (need_free)
+		for (i = 0; i < numAttrs; i++)
+			if (toast_free[i])
+				pfree(DatumGetPointer(toast_values[i]));
+
+	/*
+	 * Delete external values from the old tuple
+	 */
+	if (need_delold)
+		for (i = 0; i < numAttrs; i++)
+			if (toast_delold[i])
+				ztoast_delete_datum(rel, toast_oldvalues[i], false);
+
+	return result_tuple;
+}
+
+/*
+ * ztoast_save_datum
+ *		Just like toast_save_datum but for zheap relations.
+ */
+static Datum
+ztoast_save_datum(Relation rel, Datum value,
+				  struct varlena *oldexternal, int options, uint32 specToken)
+{
+	Relation	toastrel;
+	Relation   *toastidxs;
+	ZHeapTuple	toasttup;
+	TupleDesc	toasttupDesc;
+	Datum		t_values[3];
+	bool		t_isnull[3];
+	CommandId	mycid = GetCurrentCommandId(true);
+	struct varlena *result;
+	struct varatt_external toast_pointer;
+	union
+	{
+		struct varlena hdr;
+		/* this is to make the union big enough for a chunk: */
+		char		data[TOAST_MAX_CHUNK_SIZE + VARHDRSZ];
+		/* ensure union is aligned well enough: */
+		int32		align_it;
+	}			chunk_data;
+	int32		chunk_size;
+	int32		chunk_seq = 0;
+	char	   *data_p;
+	int32		data_todo;
+	Pointer		dval = DatumGetPointer(value);
+	int			num_indexes;
+	int			validIndex;
+
+	Assert(!VARATT_IS_EXTERNAL(value));
+
+	/*
+	 * Open the toast relation and its indexes.  We can use the index to check
+	 * uniqueness of the OID we assign to the toasted item, even though it has
+	 * additional columns besides OID.
+	 */
+	toastrel = heap_open(rel->rd_rel->reltoastrelid, RowExclusiveLock);
+	toasttupDesc = toastrel->rd_att;
+
+	/* The toast table of zheap table should also be of zheap type */
+	Assert(RelationStorageIsZHeap(toastrel));
+
+	/* Open all the toast indexes and look for the valid one */
+	validIndex = toast_open_indexes(toastrel,
+									RowExclusiveLock,
+									&toastidxs,
+									&num_indexes);
+
+	/*
+	 * Get the data pointer and length, and compute va_rawsize and va_extsize.
+	 *
+	 * va_rawsize is the size of the equivalent fully uncompressed datum, so
+	 * we have to adjust for short headers.
+	 *
+	 * va_extsize is the actual size of the data payload in the toast records.
+	 */
+	if (VARATT_IS_SHORT(dval))
+	{
+		data_p = VARDATA_SHORT(dval);
+		data_todo = VARSIZE_SHORT(dval) - VARHDRSZ_SHORT;
+		toast_pointer.va_rawsize = data_todo + VARHDRSZ;	/* as if not short */
+		toast_pointer.va_extsize = data_todo;
+	}
+	else if (VARATT_IS_COMPRESSED(dval))
+	{
+		data_p = VARDATA(dval);
+		data_todo = VARSIZE(dval) - VARHDRSZ;
+		/* rawsize in a compressed datum is just the size of the payload */
+		toast_pointer.va_rawsize = VARRAWSIZE_4B_C(dval) + VARHDRSZ;
+		toast_pointer.va_extsize = data_todo;
+		/* Assert that the numbers look like it's compressed */
+		Assert(VARATT_EXTERNAL_IS_COMPRESSED(toast_pointer));
+	}
+	else
+	{
+		data_p = VARDATA(dval);
+		data_todo = VARSIZE(dval) - VARHDRSZ;
+		toast_pointer.va_rawsize = VARSIZE(dval);
+		toast_pointer.va_extsize = data_todo;
+	}
+
+	/*
+	 * Insert the correct table OID into the result TOAST pointer.
+	 *
+	 * Normally this is the actual OID of the target toast table, but during
+	 * table-rewriting operations such as CLUSTER, we have to insert the OID
+	 * of the table's real permanent toast table instead.  rd_toastoid is set
+	 * if we have to substitute such an OID.
+	 */
+	if (OidIsValid(rel->rd_toastoid))
+		toast_pointer.va_toastrelid = rel->rd_toastoid;
+	else
+		toast_pointer.va_toastrelid = RelationGetRelid(toastrel);
+
+	/*
+	 * Choose an OID to use as the value ID for this toast value.
+	 *
+	 * Normally we just choose an unused OID within the toast table.  But
+	 * during table-rewriting operations where we are preserving an existing
+	 * toast table OID, we want to preserve toast value OIDs too.  So, if
+	 * rd_toastoid is set and we had a prior external value from that same
+	 * toast table, re-use its value ID.  If we didn't have a prior external
+	 * value (which is a corner case, but possible if the table's attstorage
+	 * options have been changed), we have to pick a value ID that doesn't
+	 * conflict with either new or existing toast value OIDs.
+	 */
+	if (!OidIsValid(rel->rd_toastoid))
+	{
+		/* normal case: just choose an unused OID */
+		toast_pointer.va_valueid =
+			GetNewOidWithIndex(toastrel,
+							   RelationGetRelid(toastidxs[validIndex]),
+							   (AttrNumber) 1);
+	}
+	else
+	{
+		/* rewrite case: check to see if value was in old toast table */
+		toast_pointer.va_valueid = InvalidOid;
+		if (oldexternal != NULL)
+		{
+			struct varatt_external old_toast_pointer;
+
+			Assert(VARATT_IS_EXTERNAL_ONDISK(oldexternal));
+			/* Must copy to access aligned fields */
+			VARATT_EXTERNAL_GET_POINTER(old_toast_pointer, oldexternal);
+			if (old_toast_pointer.va_toastrelid == rel->rd_toastoid)
+			{
+				/* This value came from the old toast table; reuse its OID */
+				toast_pointer.va_valueid = old_toast_pointer.va_valueid;
+
+				/*
+				 * There is a corner case here: the table rewrite might have
+				 * to copy both live and recently-dead versions of a row, and
+				 * those versions could easily reference the same toast value.
+				 * When we copy the second or later version of such a row,
+				 * reusing the OID will mean we select an OID that's already
+				 * in the new toast table.  Check for that, and if so, just
+				 * fall through without writing the data again.
+				 *
+				 * While annoying and ugly-looking, this is a good thing
+				 * because it ensures that we wind up with only one copy of
+				 * the toast value when there is only one copy in the old
+				 * toast table.  Before we detected this case, we'd have made
+				 * multiple copies, wasting space; and what's worse, the
+				 * copies belonging to already-deleted heap tuples would not
+				 * be reclaimed by VACUUM.
+				 */
+				if (toastrel_valueid_exists(toastrel,
+											toast_pointer.va_valueid))
+				{
+					/* Match, so short-circuit the data storage loop below */
+					data_todo = 0;
+				}
+			}
+		}
+		if (toast_pointer.va_valueid == InvalidOid)
+		{
+			/*
+			 * new value; must choose an OID that doesn't conflict in either
+			 * old or new toast table
+			 */
+			do
+			{
+				toast_pointer.va_valueid =
+					GetNewOidWithIndex(toastrel,
+									   RelationGetRelid(toastidxs[validIndex]),
+									   (AttrNumber) 1);
+			} while (toastid_valueid_exists(rel->rd_toastoid,
+											toast_pointer.va_valueid));
+		}
+	}
+
+	/*
+	 * Initialize constant parts of the tuple data
+	 */
+	t_values[0] = ObjectIdGetDatum(toast_pointer.va_valueid);
+	t_values[2] = PointerGetDatum(&chunk_data);
+	t_isnull[0] = false;
+	t_isnull[1] = false;
+	t_isnull[2] = false;
+
+	/*
+	 * Split up the item into chunks
+	 */
+	while (data_todo > 0)
+	{
+		int			i;
+
+		CHECK_FOR_INTERRUPTS();
+
+		/*
+		 * Calculate the size of this chunk
+		 */
+		chunk_size = Min(TOAST_MAX_CHUNK_SIZE, data_todo);
+
+		/*
+		 * Build a tuple and store it
+		 */
+		t_values[1] = Int32GetDatum(chunk_seq++);
+		SET_VARSIZE(&chunk_data, chunk_size + VARHDRSZ);
+		memcpy(VARDATA(&chunk_data), data_p, chunk_size);
+		toasttup = zheap_form_tuple(toasttupDesc, t_values, t_isnull);
+
+		zheap_insert(toastrel, toasttup, mycid, options, NULL, specToken);
+
+		/*
+		 * Create the index entry.  We cheat a little here by not using
+		 * FormIndexDatum: this relies on the knowledge that the index columns
+		 * are the same as the initial columns of the table for all the
+		 * indexes.  We also cheat by not providing an IndexInfo: this is okay
+		 * for now because btree doesn't need one, but we might have to be
+		 * more honest someday.
+		 *
+		 * Note also that there had better not be any user-created index on
+		 * the TOAST table, since we don't bother to update anything else.
+		 */
+		for (i = 0; i < num_indexes; i++)
+		{
+			/* Only index relations marked as ready can be updated */
+			if (toastidxs[i]->rd_index->indisready)
+				index_insert(toastidxs[i], t_values, t_isnull,
+							 &(toasttup->t_self),
+							 toastrel,
+							 toastidxs[i]->rd_index->indisunique ?
+							 UNIQUE_CHECK_YES : UNIQUE_CHECK_NO,
+							 NULL);
+		}
+
+		/*
+		 * Free memory
+		 */
+		zheap_freetuple(toasttup);
+
+		/*
+		 * Move on to next chunk
+		 */
+		data_todo -= chunk_size;
+		data_p += chunk_size;
+	}
+
+	/*
+	 * Done - close toast relation and its indexes
+	 */
+	toast_close_indexes(toastidxs, num_indexes, RowExclusiveLock);
+	heap_close(toastrel, RowExclusiveLock);
+
+	/*
+	 * Create the TOAST pointer value that we'll return
+	 */
+	result = (struct varlena *) palloc(TOAST_POINTER_SIZE);
+	SET_VARTAG_EXTERNAL(result, VARTAG_ONDISK);
+	memcpy(VARDATA_EXTERNAL(result), &toast_pointer, sizeof(toast_pointer));
+
+	return PointerGetDatum(result);
+}
+
+/*
+ * ztoast_delete_datum
+ * Just like toast_delete_datum but for zheap relations.
+ */
+static void
+ztoast_delete_datum(Relation rel, Datum value, bool is_speculative)
+{
+	struct varlena *attr = (struct varlena *) DatumGetPointer(value);
+	struct varatt_external toast_pointer;
+	Relation	toastrel;
+	Relation   *toastidxs;
+	ScanKeyData toastkey;
+	SysScanDesc toastscan;
+	int			num_indexes;
+	int			validIndex;
+	SnapshotData SnapshotToast;
+	TupleTableSlot *slot;
+
+	if (!VARATT_IS_EXTERNAL_ONDISK(attr))
+		return;
+
+	/* Must copy to access aligned fields */
+	VARATT_EXTERNAL_GET_POINTER(toast_pointer, attr);
+
+	/*
+	 * Open the toast relation and its indexes
+	 */
+	toastrel = heap_open(toast_pointer.va_toastrelid, RowExclusiveLock);
+
+	/* The toast table of zheap table should also be of zheap type */
+	Assert(RelationStorageIsZHeap(toastrel));
+
+	/* Fetch valid relation used for process */
+	validIndex = toast_open_indexes(toastrel,
+									RowExclusiveLock,
+									&toastidxs,
+									&num_indexes);
+
+	/*
+	 * Setup a scan key to find chunks with matching va_valueid
+	 */
+	ScanKeyInit(&toastkey,
+				(AttrNumber) 1,
+				BTEqualStrategyNumber, F_OIDEQ,
+				ObjectIdGetDatum(toast_pointer.va_valueid));
+
+	/*
+	 * Find all the chunks.  (We don't actually care whether we see them in
+	 * sequence or not, but since we've already locked the index we might as
+	 * well use systable_beginscan_ordered.)
+	 */
+	init_toast_snapshot(&SnapshotToast);
+	toastscan = systable_beginscan_ordered(toastrel, toastidxs[validIndex],
+										   &SnapshotToast, 1, &toastkey);
+	while ((slot = systable_getnext_ordered_slot(toastscan, ForwardScanDirection)) != NULL)
+	{
+		ZHeapTuple	ztuple = ExecGetZHeapTupleFromSlot(slot);
+
+		/*
+		 * Have a chunk, delete it
+		 */
+		if (!is_speculative)
+			simple_zheap_delete(toastrel, &ztuple->t_self, &SnapshotToast);
+		else
+			zheap_abort_speculative(toastrel, &ztuple->t_self);
+	}
+
+	/*
+	 * End scan and close relations
+	 */
+	systable_endscan_ordered(toastscan);
+	toast_close_indexes(toastidxs, num_indexes, RowExclusiveLock);
+	heap_close(toastrel, RowExclusiveLock);
+}
+
+/*
+ * ztoast_delete
+ *		Cascaded delete toast-entries on DELETE
+ */
+void
+ztoast_delete(Relation rel, ZHeapTuple oldtup, bool is_speculative)
+{
+	TupleDesc	tupleDesc;
+	int			numAttrs;
+	int			i;
+	Datum		toast_values[MaxHeapAttributeNumber];
+	bool		toast_isnull[MaxHeapAttributeNumber];
+
+	/*
+	 * We should only ever be called for tuples of plain relations or
+	 * materialized views --- recursing on a toast rel is bad news.
+	 */
+	Assert(rel->rd_rel->relkind == RELKIND_RELATION ||
+		   rel->rd_rel->relkind == RELKIND_MATVIEW);
+
+	/*
+	 * Get the tuple descriptor and break down the tuple into fields.
+	 *
+	 * NOTE: it's debatable whether to use heap_deform_tuple() here or just
+	 * heap_getattr() only the varlena columns.  The latter could win if there
+	 * are few varlena columns and many non-varlena ones. However,
+	 * heap_deform_tuple costs only O(N) while the heap_getattr way would cost
+	 * O(N^2) if there are many varlena columns, so it seems better to err on
+	 * the side of linear cost.  (We won't even be here unless there's at
+	 * least one varlena column, by the way.)
+	 */
+	tupleDesc = rel->rd_att;
+	numAttrs = tupleDesc->natts;
+
+	Assert(numAttrs <= MaxHeapAttributeNumber);
+	zheap_deform_tuple(oldtup, tupleDesc, toast_values, toast_isnull, tupleDesc->natts);
+
+	/*
+	 * Check for external stored attributes and delete them from the secondary
+	 * relation.
+	 */
+	for (i = 0; i < numAttrs; i++)
+	{
+		if (TupleDescAttr(tupleDesc, i)->attlen == -1)
+		{
+			Datum		value = toast_values[i];
+
+			if (toast_isnull[i])
+				continue;
+			else if (VARATT_IS_EXTERNAL_ONDISK(PointerGetDatum(value)))
+				ztoast_delete_datum(rel, value, is_speculative);
+		}
+	}
+}
diff --git a/src/backend/access/zheap/zundo.c b/src/backend/access/zheap/zundo.c
new file mode 100644
index 0000000..6ffe294
--- /dev/null
+++ b/src/backend/access/zheap/zundo.c
@@ -0,0 +1,1397 @@
+/*-------------------------------------------------------------------------
+ *
+ * zundo.c
+ *	  Routines to process undo records.
+ *
+ * Each operation in zheap generates an undo record which later can be used
+ * for visibility and or rollback purpose.  This file provides set of API's
+ * that can be used to process undo records.
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/access/zheap/zundo.c
+ *
+ *-------------------------------------------------------------------------
+ */
+
+#include "postgres.h"
+
+#include "access/table.h"
+#include "access/tpd.h"
+#include "access/undorecord.h"
+#include "access/undorequest.h"
+#include "access/visibilitymap.h"
+#include "access/xact.h"
+#include "access/zheapam_xlog.h"
+#include "access/zheapscan.h"
+#include "miscadmin.h"
+#include "utils/syscache.h"
+#include "utils/ztqual.h"
+#include "access/relation.h"
+
+static ZHeapTupleHeader RestoreTupleFromUndoRecord(UnpackedUndoRecord *urec,
+												   Page page, ZHeapTupleHeader page_tup_hdr);
+static void RestoreXactFromUndoRecord(UnpackedUndoRecord *urec, Buffer buffer,
+									  ZHeapTupleHeader zhtup,
+									  bool tpd_offset_map,
+									  bool *is_tpd_map_updated);
+static int	TransSlotFromUndoRecord(UnpackedUndoRecord *urec,
+									ZHeapTupleHeader hdr, Page page);
+static void log_zheap_undo_actions(ZHeapUndoActionWALInfo *wal_info);
+
+/*
+ * Per-undorecord callback from UndoFetchRecord to check whether
+ * an undorecord satisfies the given conditions.
+ */
+bool
+ZHeapSatisfyUndoRecord(UnpackedUndoRecord *urec, BlockNumber blkno,
+					   OffsetNumber offset, TransactionId xid)
+{
+	Assert(urec != NULL);
+	Assert(blkno != InvalidBlockNumber);
+
+	if ((urec->uur_block != blkno ||
+		 (TransactionIdIsValid(xid) && !TransactionIdEquals(xid, urec->uur_xid))))
+		return false;
+
+	switch (urec->uur_type)
+	{
+		case UNDO_MULTI_INSERT:
+			{
+				OffsetNumber start_offset;
+				OffsetNumber end_offset;
+
+				start_offset = ((OffsetNumber *) urec->uur_payload.data)[0];
+				end_offset = ((OffsetNumber *) urec->uur_payload.data)[1];
+
+				if (offset >= start_offset && offset <= end_offset)
+					return true;
+			}
+			break;
+		case UNDO_ITEMID_UNUSED:
+			{
+				/*
+				 * We don't expect to check the visibility of any unused item,
+				 * but the undo record of same can be present in chain which
+				 * we need to ignore.
+				 */
+			}
+			break;
+		default:
+			{
+				Assert(offset != InvalidOffsetNumber);
+				if (urec->uur_offset == offset)
+					return true;
+			}
+			break;
+	}
+
+	return false;
+}
+
+/*
+ * UpdateTupleHeaderFromUndoRecord
+ *
+ * Update the caller-supplied tuple header using the information from the
+ * undo record supplied by the caller.
+ */
+int
+UpdateTupleHeaderFromUndoRecord(UnpackedUndoRecord *urec, ZHeapTupleHeader hdr,
+								Page page)
+{
+	if (urec->uur_type == UNDO_INSERT)
+	{
+		/*
+		 * We need to deal with undo of root tuple only for a special case
+		 * where during non-inplace update operation, we propagate the lockers
+		 * information to the freshly inserted tuple. But, we've to make sure
+		 * the inserted tuple is locked only.
+		 */
+		Assert(ZHEAP_XID_IS_LOCKED_ONLY(hdr->t_infomask));
+
+		/*
+		 * Ensure to clear the visibility related information from the tuple.
+		 * This is required for the cases where the passed in tuple has lock
+		 * only flags set on it.
+		 */
+		hdr->t_infomask &= ~ZHEAP_VIS_STATUS_MASK;
+	}
+	else
+	{
+		/*
+		 * Any other record type we encounter should contain either a complete
+		 * tuple (UNDO_DELETE, UNDO_UPDATE, UNDO_INPLACE_UPDATE) or at least a
+		 * ZHeapTupleHeader (UNDO_XID_LOCK_ONLY, UNDO_XID_LOCK_FOR_UPDATE,
+		 * UNDO_XID_MULTI_LOCK_ONLY).
+		 */
+		Assert(urec->uur_tuple.len >= SizeofZHeapTupleHeader);
+		memcpy(hdr, urec->uur_tuple.data, SizeofZHeapTupleHeader);
+	}
+
+	return TransSlotFromUndoRecord(urec, hdr, page);
+}
+
+/*
+ * Extract transaction slot information from an undo record.
+ *
+ * 'hdr' must be the tuple header which UpdateTupleHeaderFromUndoRecord
+ * reconstructed.  For an inserted record it could instead be the tuple taken
+ * from the page itself.
+ */
+static int
+TransSlotFromUndoRecord(UnpackedUndoRecord *urec, ZHeapTupleHeader hdr,
+						Page page)
+{
+	int			trans_slot_id;
+
+	if ((urec->uur_info & UREC_INFO_PAYLOAD_CONTAINS_SLOT) == 0)
+	{
+		/*
+		 * There is no slot information in the payload, so just extract it
+		 * from the tuple itself.
+		 */
+		trans_slot_id = ZHeapTupleHeaderGetXactSlot(hdr);
+	}
+	else
+	{
+		int			offset;
+
+		/*
+		 * Figure out where in the payload the transaction slot information is
+		 * stored.  Some undo record types store a lock mode or CTID prior to
+		 * the transaction slot information.
+		 */
+		switch (urec->uur_type)
+		{
+			case UNDO_XID_LOCK_ONLY:
+			case UNDO_XID_LOCK_FOR_UPDATE:
+			case UNDO_XID_MULTI_LOCK_ONLY:
+				offset = sizeof(LockTupleMode);
+				break;
+			case UNDO_UPDATE:
+				offset = sizeof(ItemPointerData);
+				break;
+			case UNDO_INSERT:
+			case UNDO_INPLACE_UPDATE:
+			case UNDO_DELETE:
+				offset = 0;
+				break;
+			default:
+				elog(ERROR, "unsupported undo record type");
+		}
+
+		/*
+		 * The undo records are stored without alignment, so we use memcpy to
+		 * avoid unaligned access. We could optimize it for the cases where
+		 * undo data is separately allocated (aka when a particular undo
+		 * record is split across multiple buffers), but those are not common
+		 * cases, so it doesn't seem worth the effort.
+		 */
+		memcpy(&trans_slot_id, urec->uur_payload.data + offset, sizeof(int));
+	}
+
+	/*
+	 * If the undo tuple is pointing to the last slot of the page and the page
+	 * has TPD slots that means the last slot information must move to the
+	 * first slot of the TPD page so change the slot number as per that.
+	 */
+	if (page && trans_slot_id == ZHEAP_PAGE_TRANS_SLOTS &&
+		ZHeapPageHasTPDSlot((PageHeader) page))
+		trans_slot_id = ZHEAP_PAGE_TRANS_SLOTS + 1;
+
+	return trans_slot_id;
+}
+
+/*
+ * ValidateTuplesXact - Check if the tuple is modified by priorXmax.
+ *
+ *	We need to traverse the undo chain of tuple to see if any of its
+ *	prior version is modified by priorXmax.
+ *
+ *  nobuflock indicates whether caller has lock on the buffer 'buf'.
+ */
+bool
+ValidateTuplesXact(Relation relation, ZHeapTuple tuple, Snapshot snapshot,
+				   Buffer buf, TransactionId priorXmax, bool nobuflock)
+{
+	ZHeapTuple	visible_tuple;
+	ZHeapTupleHeaderData hdr;
+	ItemPointer tid = &(tuple->t_self);
+	OffsetNumber offnum = ItemPointerGetOffsetNumber(tid);
+	bool		valid = false;
+	ZHeapTupleTransInfo zinfo;
+
+	/*
+	 * As we are going to access special space in the page to retrieve the
+	 * transaction information share lock on buffer is required.
+	 */
+	if (nobuflock)
+		LockBuffer(buf, BUFFER_LOCK_SHARE);
+
+	/* XXX. This is a waste; we really only need the tuple header. */
+	ZHeapTupleFetch(relation, buf, offnum, snapshot, &visible_tuple, NULL);
+
+	if (visible_tuple == NULL)
+	{
+		/*
+		 * If the tuple is already removed by Rollbacks/pruning, then we don't
+		 * need to proceed further.
+		 */
+		if (nobuflock)
+			LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+		return false;
+	}
+
+	/*
+	 * We've to call ZHeapTupleGetTransInfo to fetch the xact info of the
+	 * tuple since the tuple can be marked with invalid xact flag.
+	 */
+	ZHeapTupleGetTransInfo(buf, offnum, &zinfo);
+
+	/*
+	 * Current xid on tuple must not precede oldestXidHavingUndo as it will be
+	 * greater than priorXmax which was not visible to our snapshot.
+	 */
+	Assert(zinfo.trans_slot != ZHTUP_SLOT_FROZEN);
+
+	if (TransactionIdEquals(zinfo.xid, priorXmax))
+	{
+		valid = true;
+		pfree(visible_tuple);
+		goto tuple_is_valid;
+	}
+
+	memcpy(&hdr, visible_tuple->t_data, SizeofZHeapTupleHeader);
+	pfree(visible_tuple);
+
+	/*
+	 * Current xid on tuple must not precede RecentGlobalXmin as it will be
+	 * greater than priorXmax which was not visible to our snapshot.
+	 */
+	Assert(TransactionIdIsValid(zinfo.xid) &&
+		   !TransactionIdPrecedes(zinfo.xid, RecentGlobalXmin));
+
+	zinfo.xid = InvalidTransactionId;
+
+	do
+	{
+		UnpackedUndoRecord *urec;
+		int			prev_trans_slot_id = zinfo.trans_slot;
+
+		Assert(prev_trans_slot_id != ZHTUP_SLOT_FROZEN);
+
+		urec = UndoFetchRecord(zinfo.urec_ptr,
+							   ItemPointerGetBlockNumber(tid),
+							   ItemPointerGetOffsetNumber(tid),
+							   zinfo.xid,
+							   NULL,
+							   ZHeapSatisfyUndoRecord);
+
+		/*
+		 * As we still hold a snapshot to which priorXmax is not visible,
+		 * neither the transaction slot on tuple can be marked as frozen nor
+		 * the corresponding undo be discarded.
+		 */
+		Assert(urec != NULL);
+
+		if (TransactionIdEquals(urec->uur_xid, priorXmax))
+		{
+			valid = true;
+			UndoRecordRelease(urec);
+			break;
+		}
+
+		zinfo.trans_slot = UpdateTupleHeaderFromUndoRecord(urec, &hdr,
+														   BufferGetPage(buf));
+
+		Assert(!TransactionIdPrecedes(urec->uur_prevxid, RecentGlobalXmin));
+
+		zinfo.xid = urec->uur_prevxid;
+		zinfo.urec_ptr = urec->uur_blkprev;
+		UndoRecordRelease(urec);
+
+		/*
+		 * Change the undo chain if the undo tuple is stamped with the
+		 * different transaction slot.
+		 */
+		if (prev_trans_slot_id != zinfo.trans_slot)
+			ZHeapUpdateTransactionSlotInfo(zinfo.trans_slot, buf,
+										   ItemPointerGetOffsetNumber(tid),
+										   &zinfo);
+
+		/*
+		 * If the tuple has invalid xact flag, we may have to fetch the
+		 * correct xact info from other slot.
+		 */
+		if (ZHeapTupleHasInvalidXact(hdr.t_infomask))
+			FetchTransInfoFromUndo(BufferGetBlockNumber(buf), offnum,
+								   zinfo.xid, &zinfo, NULL);
+	} while (UndoRecPtrIsValid(zinfo.urec_ptr));
+
+tuple_is_valid:
+	if (nobuflock)
+		LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+
+	return valid;
+}
+
+/*
+ * zheap_exec_pending_rollback - apply any pending rollback on the input buffer
+ *
+ * trans_slot_id  - If a valid slot number is passed then it will apply
+ * the undo actions for that slot unless already applied, otherwise it
+ * traverses all the transaction slots of the current page including tpd
+ * slots and applies any pending aborts on the page.  If the input
+ * trans_slot_id is valid then the caller must have a buffer lock on the input
+ * buffer.
+ * xid - Transaction id for which pending actions need to be applied.  If
+ * the given slot contains different xid, then we can consider that
+ * actions are already applied and the slot has been reused by a
+ * different transaction.
+ *
+ * It expects the caller has an exclusive lock on the relation. It also returns
+ * the corresponding TPD block number in case it has rolled back any
+ * transactions from the corresponding TPD page, if any.
+ */
+bool
+zheap_exec_pending_rollback(Relation rel, Buffer buf, int trans_slot_id,
+							TransactionId xid, BlockNumber *tpd_blkno)
+{
+	int			slot_no;
+	int			total_trans_slots = 0;
+	TransInfo  *trans_slots = NULL;
+	bool		any_tpd_slot_rolled_back = false;
+
+	/*
+	 * If the caller has passed a valid slot then only apply undo actions for
+	 * xid in that slot.
+	 */
+	if (trans_slot_id != InvalidXactSlotId)
+	{
+		Page		page;
+		PageHeader	phdr;
+		TransInfo	slotinfo;
+		ZHeapTupleTransInfo zinfo;
+
+		page = BufferGetPage(buf);
+		phdr = (PageHeader) page;
+
+		/*
+		 * If the caller reacquired the lock before calling this function,
+		 * rollback could have been performed by some other backend or the
+		 * undo-worker.  In that case, the TPD entry can be pruned away.
+		 */
+		if (trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS &&
+			!ZHeapPageHasTPDSlot(phdr))
+			return false;
+
+		GetTransactionSlotInfo(buf, InvalidOffsetNumber, trans_slot_id,
+							   true, true, &zinfo);
+		/* Undo actions already applied for the transaction so nothing to do. */
+		if (xid != zinfo.xid)
+			return false;
+
+		slotinfo.fxid = zinfo.epoch_xid;
+		slotinfo.urec_ptr = zinfo.urec_ptr;
+		total_trans_slots = 1;
+		trans_slots = &slotinfo;
+
+		/* Release buffer lock before applying undo actions. */
+		LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+	}
+	else
+	{
+		Assert(tpd_blkno != NULL);
+
+		/*
+		 * Fetch all the transaction information from the page and its
+		 * corresponding TPD page.
+		 */
+		LockBuffer(buf, BUFFER_LOCK_SHARE);
+		trans_slots = GetTransactionsSlotsForPage(rel, buf, &total_trans_slots,
+												  tpd_blkno);
+		LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+	}
+
+	for (slot_no = 0; slot_no < total_trans_slots; slot_no++)
+	{
+		FullTransactionId fxid = trans_slots[slot_no].fxid;
+		UndoRecPtr	urec_ptr = trans_slots[slot_no].urec_ptr;
+
+		xid = XidFromFullTransactionId(fxid);
+
+		/*
+		 * There shouldn't be any other in-progress transaction as we hold an
+		 * exclusive lock on the relation.
+		 */
+		Assert(TransactionIdIsCurrentTransactionId(xid) ||
+			   !TransactionIdIsInProgress(xid));
+
+		/* If the transaction is aborted, apply undo actions */
+		if (TransactionIdIsValid(xid) && TransactionIdDidAbort(xid))
+		{
+			/* Remember if we've rolled back a transaction from a TPD-slot. */
+			if (tpd_blkno != NULL && (slot_no >= ZHEAP_PAGE_TRANS_SLOTS - 1) &&
+				BlockNumberIsValid(*tpd_blkno))
+				any_tpd_slot_rolled_back = true;
+
+			process_and_execute_undo_actions_page(urec_ptr, rel, buf,
+												  fxid, slot_no);
+		}
+	}
+
+	/*
+	 * If we've not rolled back anything from TPD slot, there is no need set
+	 * the TPD buffer.
+	 */
+	if (tpd_blkno != NULL && !any_tpd_slot_rolled_back)
+		*tpd_blkno = InvalidBlockNumber;
+
+	/* Reacquire the lock if we have released it. */
+	if (trans_slot_id != InvalidXactSlotId)
+		LockBuffer(buf, BUFFER_LOCK_EXCLUSIVE);
+	else
+		pfree(trans_slots);
+	return true;
+}
+
+/*
+ * process_and_execute_undo_actions_page
+ *
+ * Collect all the undo for the input buffer and execute.  Here, we don't know
+ * the to_urecptr and we can not collect from undo meta data also like we do in
+ * execute_undo_actions, because we might be applying undo of some old
+ * transaction and may be from different undo log as well.
+ *
+ * from_urecptr - undo record pointer from where to start applying the undo.
+ * rel			- relation descriptor for which undo to be applied.
+ * buffer		- buffer for which unto to be processed.
+ * epoch		- epoch of the xid passed.
+ * xid			- aborted transaction id whose effects needs to be reverted.
+ * slot_no		- transaction slot number of xid.
+ */
+void
+process_and_execute_undo_actions_page(UndoRecPtr from_urecptr, Relation rel,
+									  Buffer buffer,
+									  FullTransactionId fxid, int slot_no)
+{
+	UndoRecPtr	urec_ptr = from_urecptr;
+	UndoRecInfo *urp_array;
+	Page		page;
+	bool		actions_applied = false;
+	int			nrecords;
+	int			undo_apply_size = maintenance_work_mem * 1024L;
+	int			i;
+
+	/*
+	 * Fetch the multiple undo records which can fit into uur_segment; sort
+	 * them in order of block number then apply them together page-wise.
+	 * Repeat the process until we reach to the to_urecptr.
+	 */
+	do
+	{
+		if (!UndoRecPtrIsValid(urec_ptr))
+			break;
+
+		urp_array = UndoBulkFetchRecord(&urec_ptr, InvalidUndoRecPtr,
+										undo_apply_size, &nrecords, true);
+		if (nrecords == 0)
+			break;
+
+		/* Apply the last set of the actions. */
+		execute_undo_actions_page(urp_array, 0, nrecords - 1, rel->rd_id,
+								  fxid, BufferGetBlockNumber(buffer),
+								  UndoRecPtrIsValid(urec_ptr) ? false : true);
+
+		/* Free all undo records. */
+		for (i = 0; i < nrecords; i++)
+			UndoRecordRelease(urp_array[i].uur);
+
+		pfree(urp_array);
+	} while (true);
+
+	/*
+	 * Clear the transaction id from the slot.  We expect that if the undo
+	 * actions are applied by execute_undo_actions_page then it would have
+	 * cleared the xid, otherwise we will clear it here.
+	 */
+	if (!actions_applied)
+	{
+		int			slot_no;
+
+		LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+		page = BufferGetPage(buffer);
+		slot_no = PageGetTransactionSlotId(rel, buffer, fxid, &urec_ptr,
+										   true, false, NULL);
+
+		/*
+		 * If someone has already cleared the transaction info, then we don't
+		 * need to do anything.
+		 */
+		if (slot_no != InvalidXactSlotId)
+		{
+			START_CRIT_SECTION();
+
+			/* Clear the epoch and xid from the slot. */
+			PageSetTransactionSlotInfo(buffer, slot_no,
+									   InvalidFullTransactionId, urec_ptr);
+			MarkBufferDirty(buffer);
+
+			/* XLOG stuff */
+			if (RelationNeedsWAL(rel))
+			{
+				XLogRecPtr	recptr;
+				xl_zundo_reset_slot xlrec;
+
+				xlrec.flags = 0;
+				xlrec.urec_ptr = urec_ptr;
+				xlrec.trans_slot_id = slot_no;
+
+				XLogBeginInsert();
+
+				XLogRegisterData((char *) &xlrec, SizeOfZUndoResetSlot);
+				XLogRegisterBuffer(0, buffer, REGBUF_STANDARD);
+
+				/* Register tpd buffer if the slot belongs to tpd page. */
+				if (slot_no > ZHEAP_PAGE_TRANS_SLOTS)
+				{
+					xlrec.flags |= XLU_RESET_CONTAINS_TPD_SLOT;
+					RegisterTPDBuffer(page, 1);
+				}
+
+				recptr = XLogInsert(RM_ZUNDO_ID, XLOG_ZUNDO_RESET_SLOT);
+
+				PageSetLSN(page, recptr);
+				if (xlrec.flags & XLU_RESET_CONTAINS_TPD_SLOT)
+					TPDPageSetLSN(page, recptr);
+			}
+
+			END_CRIT_SECTION();
+		}
+
+		LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+		UnlockReleaseTPDBuffers();
+	}
+}
+
+/*
+ * undo_action_insert - perform the undo action for insert
+ *
+ *	This will mark the tuple as dead so that the future access to it can't see
+ *	this tuple.  We mark it as unused if there is no other index pointing to
+ *	it, otherwise mark it as dead.
+ */
+static inline void
+undo_action_insert(Relation rel, Page page, OffsetNumber off,
+				   TransactionId xid)
+{
+	ItemId		lp;
+	bool		relhasindex;
+
+	/*
+	 * This will mark the tuple as dead so that the future access to it can't
+	 * see this tuple.  We mark it as unused if there is no other index
+	 * pointing to it, otherwise mark it as dead.
+	 */
+	relhasindex = RelationGetForm(rel)->relhasindex;
+	lp = PageGetItemId(page, off);
+	if (relhasindex)
+	{
+		ItemIdSetDead(lp);
+	}
+	else
+	{
+		ItemIdSetUnused(lp);
+		/* Set hint bit for ZPageAddItem */
+		PageSetHasFreeLinePointers(page);
+	}
+
+	ZPageSetPrunable(page, xid);
+}
+
+/*
+ * zheap_undo_actions - Execute the undo actions for a zheap page
+ *
+ *	urp_array - array of undo records (along with their location) for which undo
+ *				action needs to be applied.
+ *	first_idx - index in the urp_array of the first undo action to be applied
+ *	last_idx  - index in the urp_array of the first undo action to be applied
+ *	reloid	- OID of relation on which undo actions needs to be applied.
+ *	blkno	- block number on which undo actions needs to be applied.
+ *	blk_chain_complete - indicates whether the undo chain for block is
+ *						 complete.
+ *
+ *	returns true, if successfully applied the undo actions, otherwise, false.
+ */
+bool
+zheap_undo_actions(UndoRecInfo *urp_array, int first_idx, int last_idx,
+				   Oid reloid, FullTransactionId full_xid, BlockNumber blkno,
+				   bool blk_chain_complete)
+{
+	Relation	rel;
+	Buffer		buffer;
+	Buffer		vmbuffer = InvalidBuffer;
+	Page		page;
+	UndoRecPtr	slot_urec_ptr;
+	UndoRecPtr	prev_urec_ptr,
+				block_prev_urp;
+	UndoRecPtr	first_urp;
+	bool		need_init = false;
+	bool		tpd_page_locked = false;
+	bool		is_tpd_map_updated = false;
+	char	   *tpd_offset_map = NULL;
+	int			i;
+	int			slot_no = 0;
+	int			tpd_map_size = 0;
+	uint32		epoch = EpochFromFullTransactionId(full_xid);
+	TransactionId xid = XidFromFullTransactionId(full_xid);
+
+	/*
+	 * FIXME: If reloid is not valid then we have nothing to do. In future, we
+	 * might want to do it differently for transactions that perform both DDL
+	 * and DML operations.
+	 */
+	if (!OidIsValid(reloid))
+	{
+		elog(LOG, "ignoring undo for invalid reloid");
+		return false;
+	}
+
+	/*
+	 * We always try to lock the relation.  If the relation is already gone,
+	 * then we can skip processing the undo actions.
+	 */
+	rel = try_relation_open(reloid, RowExclusiveLock);
+	if (rel == NULL)
+	{
+		elog(LOG, "relation is already dropped.");
+		return false;
+	}
+
+	if (RelationGetNumberOfBlocks(rel) <= blkno)
+	{
+		/*
+		 * This is possible if the underlying relation is truncated just
+		 * before taking the relation lock above.
+		 */
+		relation_close(rel, RowExclusiveLock);
+		return false;
+	}
+
+	buffer = ReadBuffer(rel, blkno);
+
+	/*
+	 * If there is a undo action of type UNDO_ITEMID_UNUSED then might need to
+	 * clear visibility_map. Since we cannot call visibilitymap_pin or
+	 * visibilitymap_status within a critical section it shall be called here
+	 * and let it be before taking the buffer lock on page.
+	 */
+	for (i = first_idx; i <= last_idx; i++)
+	{
+		UndoRecInfo *urec_info = (UndoRecInfo *) urp_array + i;
+		UnpackedUndoRecord *uur = urec_info->uur;
+
+		if (uur->uur_type == UNDO_ITEMID_UNUSED)
+		{
+			visibilitymap_pin(rel, blkno, &vmbuffer);
+			break;
+		}
+	}
+
+	LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+	page = BufferGetPage(buffer);
+
+	/*
+	 * Identify the slot number for this transaction.
+	 *
+	 * Here, we will always take a lock on the tpd_page, if there is a tpd
+	 * slot on the page.  This is required because sometimes we only come to
+	 * know that we need to update the tpd page after applying the undo
+	 * record. Now, the case where this can happen is when during DO operation
+	 * the slot of previous updater is a non-TPD slot, but by the time we came
+	 * for rollback it became a TPD slot which means this information won't be
+	 * even recorded in undo.
+	 */
+	slot_no = PageGetTransactionSlotId(rel, buffer, full_xid,
+									   &slot_urec_ptr, true, true,
+									   &tpd_page_locked);
+
+	/*
+	 * If undo action has been already applied for this page then skip the
+	 * process altogether.  If we didn't find a slot corresponding to xid, we
+	 * consider the transaction is already rolled back.
+	 *
+	 * The logno of slot's undo record pointer must be same as the logno of
+	 * undo record to be applied.
+	 */
+	prev_urec_ptr = urp_array[last_idx].uur->uur_blkprev;
+	first_urp = urp_array[first_idx].urp;
+
+	if (slot_no == InvalidXactSlotId ||
+		(UndoRecPtrGetLogNo(slot_urec_ptr) != UndoRecPtrGetLogNo(first_urp)) ||
+		(UndoRecPtrGetLogNo(slot_urec_ptr) ==
+		 UndoRecPtrGetLogNo(prev_urec_ptr) && slot_urec_ptr <= prev_urec_ptr))
+	{
+		UnlockReleaseBuffer(buffer);
+		UnlockReleaseTPDBuffers();
+
+		/* Close the relation. */
+		relation_close(rel, RowExclusiveLock);
+
+		return false;
+	}
+
+	/*
+	 * We might need to update the TPD offset map while applying undo actions,
+	 * so get the size of the TPD offset map and allocate the memory to fetch
+	 * that outside the critical section.  It is quite possible that the TPD
+	 * entry is already pruned by this time, in which case, we will mark the
+	 * slot as frozen.
+	 *
+	 * XXX It would have been better if we fetch the tpd map only when
+	 * required, but that won't be possible in all cases.  Sometimes we will
+	 * come to know only during processing particular undo record. Now, we can
+	 * process the undo records partially outside critical section such that
+	 * we know whether we need TPD map or not, but that seems to be overkill.
+	 */
+	if (tpd_page_locked)
+	{
+		tpd_map_size = TPDPageGetOffsetMapSize(buffer);
+		if (tpd_map_size > 0)
+			tpd_offset_map = palloc(tpd_map_size);
+	}
+
+	START_CRIT_SECTION();
+
+	/* Set the already applied undo ptr. */
+	block_prev_urp = slot_urec_ptr;
+
+	for (i = first_idx; i <= last_idx; i++)
+	{
+		UndoRecInfo *urec_info = (UndoRecInfo *) urp_array + i;
+		UnpackedUndoRecord *uur = urec_info->uur;
+
+		/* Skip already applied undo. */
+		if (block_prev_urp < urec_info->urp)
+			continue;
+
+		Assert(block_prev_urp == urec_info->urp);
+		block_prev_urp = uur->uur_blkprev;
+
+		elog(DEBUG1, "Rollback undo record: "
+			 "TransSlot: %d, Epoch: %d, TransactionId: %d, urec: " UndoRecPtrFormat ", "
+			 "prev_urec: " UndoRecPtrFormat ", block: %d, offset: %d, undo_op: %d, "
+			 "xid_tup: %d, reloid: %d",
+			 slot_no, epoch, xid, slot_urec_ptr,
+			 uur->uur_blkprev, uur->uur_block,
+			 uur->uur_offset, uur->uur_type,
+			 uur->uur_prevxid, uur->uur_reloid);
+
+		switch (uur->uur_type)
+		{
+			case UNDO_INSERT:
+				{
+					int			i,
+								nline;
+					ItemId		lp;
+					uint32		specToken = 0;
+
+					/* Copy the entire tuple from undo. */
+					lp = PageGetItemId(page, uur->uur_offset);
+
+					/*
+					 * If a dead item is found, ensure that it is from
+					 * speculative abort case only.
+					 */
+					if (ItemIdIsDead(lp))
+					{
+						/* Fetch if this is a speculative insert case */
+						specToken = *(uint32 *) uur->uur_payload.data;
+
+						if (specToken)
+						{
+							ItemIdSetDead(lp);
+							break;
+						}
+					}
+
+					undo_action_insert(rel, page, uur->uur_offset, xid);
+
+					nline = PageGetMaxOffsetNumber(page);
+					need_init = true;
+					for (i = FirstOffsetNumber; i <= nline; i++)
+					{
+						lp = PageGetItemId(page, i);
+						if (ItemIdIsUsed(lp) || ItemIdHasPendingXact(lp))
+						{
+							need_init = false;
+							break;
+						}
+					}
+				}
+				break;
+			case UNDO_MULTI_INSERT:
+				{
+					OffsetNumber start_offset;
+					OffsetNumber end_offset;
+					OffsetNumber iter_offset;
+					int			i,
+								nline;
+					ItemId		lp;
+
+					start_offset = ((OffsetNumber *) uur->uur_payload.data)[0];
+					end_offset = ((OffsetNumber *) uur->uur_payload.data)[1];
+
+					for (iter_offset = start_offset;
+						 iter_offset <= end_offset;
+						 iter_offset++)
+					{
+						undo_action_insert(rel, page, iter_offset, xid);
+					}
+
+					nline = PageGetMaxOffsetNumber(page);
+					need_init = true;
+					for (i = FirstOffsetNumber; i <= nline; i++)
+					{
+						lp = PageGetItemId(page, i);
+						if (ItemIdIsUsed(lp) || ItemIdHasPendingXact(lp))
+						{
+							need_init = false;
+							break;
+						}
+					}
+				}
+				break;
+			case UNDO_DELETE:
+			case UNDO_UPDATE:
+			case UNDO_INPLACE_UPDATE:
+			case UNDO_XID_LOCK_FOR_UPDATE:
+				{
+					ZHeapTupleHeader zhtup;
+					ZHeapTupleHeaderData old_tup;
+
+					zhtup = RestoreTupleFromUndoRecord(uur, page, &old_tup);
+					RestoreXactFromUndoRecord(uur, buffer, zhtup, tpd_offset_map,
+											  &is_tpd_map_updated);
+
+					/*
+					 * We always need to retain the strongest locker
+					 * information on the tuple (as part of infomask and
+					 * infomask2), if there are multiple lockers on a tuple.
+					 * This is because the conflict detection mechanism works
+					 * based on strongest locker.  See
+					 * zheap_update/zheap_delete.  We have allowed to override
+					 * the transaction slot information with whatever is
+					 * present in undo as we have taken care during DO
+					 * operation that it contains previous strongest locker
+					 * information.  See compute_new_xid_infomask.
+					 */
+					if (ZHeapTupleHasMultiLockers(old_tup.t_infomask))
+					{
+						zhtup->t_infomask |= ZHEAP_MULTI_LOCKERS;
+						zhtup->t_infomask &= ~(zhtup->t_infomask &
+											   ZHEAP_LOCK_MASK);
+						zhtup->t_infomask |= old_tup.t_infomask &
+							ZHEAP_LOCK_MASK;
+
+						/*
+						 * If the tuple originally has INVALID_XACT_SLOT set,
+						 * then we need to retain it as that must be the
+						 * information of strongest locker.
+						 */
+						if (ZHeapTupleHasInvalidXact(old_tup.t_infomask))
+							zhtup->t_infomask |= ZHEAP_INVALID_XACT_SLOT;
+					}
+				}
+				break;
+			case UNDO_XID_LOCK_ONLY:
+				{
+					ZHeapTupleHeader zhtup;
+					ZHeapTupleHeaderData old_tup;
+
+					zhtup = RestoreTupleFromUndoRecord(uur, page, &old_tup);
+
+					/* Let's do some sanity checks. */
+					if (!ZHeapTupleHasMultiLockers(old_tup.t_infomask))
+					{
+						int			prev_trans_slot PG_USED_FOR_ASSERTS_ONLY;
+						ZHeapTupleTransInfo zinfo PG_USED_FOR_ASSERTS_ONLY;
+
+						GetTransactionSlotInfo(buffer,
+											   uur->uur_offset,
+											   ZHeapTupleHeaderGetXactSlot(&old_tup),
+											   false,
+											   false,
+											   &zinfo);
+
+						/*
+						 * If the previous version of the tuple points to a
+						 * TPD slot then we need to update the slot in the
+						 * offset map of the TPD entry.  But, only if we still
+						 * have a valid TPD entry for the page otherwise the
+						 * old tuple version must be all visible and we can
+						 * mark the slot as frozen.
+						 */
+						if (uur->uur_info & UREC_INFO_PAYLOAD_CONTAINS_SLOT)
+						{
+							prev_trans_slot =
+								*(int *) ((char *) uur->uur_payload.data +
+										  sizeof(LockTupleMode));
+
+							/*
+							 * For a non multi locker case, the slot in undo
+							 * (hence on tuple) must be either a frozen slot
+							 * or the previous slot.
+							 */
+							Assert(zinfo.trans_slot == ZHTUP_SLOT_FROZEN ||
+								   zinfo.trans_slot == prev_trans_slot);
+						}
+						else
+						{
+							/*
+							 * For a non multi locker case, the slot in undo
+							 * (hence on tuple) must be either a frozen slot
+							 * or the previous slot. It is quite possible that
+							 * previous slot may moved in TPD. Generally, we
+							 * always set the multi-locker bit on the tuple
+							 * whenever the tuple slot is not frozen. But, if
+							 * the tuple is inserted/modified by the same
+							 * transaction that later takes a lock on it, we
+							 * keep the transaction slot as it is. See
+							 * compute_new_xid_infomask for details.
+							 */
+							prev_trans_slot =
+								ZHeapTupleHeaderGetXactSlot(zhtup);
+							Assert(zinfo.trans_slot == ZHTUP_SLOT_FROZEN ||
+								   zinfo.trans_slot == prev_trans_slot ||
+								   (ZHeapPageHasTPDSlot((PageHeader) page) &&
+									zinfo.trans_slot == prev_trans_slot + 1));
+						}
+					}
+				}
+				break;
+			case UNDO_XID_MULTI_LOCK_ONLY:
+				break;
+			case UNDO_ITEMID_UNUSED:
+				{
+					int			item_count,
+								i;
+					OffsetNumber *unused;
+
+					unused = ((OffsetNumber *) uur->uur_payload.data);
+					item_count = (uur->uur_payload.len / sizeof(OffsetNumber));
+
+					/*
+					 * We need to preserve all the unused items in zheap so
+					 * that they can't be reused till the corresponding index
+					 * entries are removed.  So, marking them dead is a
+					 * sufficient indication for the index to remove the entry
+					 * in index.
+					 */
+					for (i = 0; i < item_count; i++)
+					{
+						ItemId		itemid;
+
+						itemid = PageGetItemId(page, unused[i]);
+						ItemIdSetDead(itemid);
+					}
+
+					/* clear visibility map */
+					Assert(BufferIsValid(vmbuffer));
+					visibilitymap_clear(rel, blkno, vmbuffer,
+										VISIBILITYMAP_VALID_BITS);
+
+				}
+				break;
+			default:
+				elog(ERROR, "unsupported undo record type");
+		}
+	}
+
+	/*
+	 * If the undo chain for the block is complete then set the xid in the
+	 * slot as InvalidTransactionId.  But, rewind the slot urec_ptr to the
+	 * previous urec_ptr in the slot.  This is to make sure if any transaction
+	 * reuse the transaction slot and rollback then put back the previous
+	 * transaction's urec_ptr.
+	 */
+	if (blk_chain_complete)
+		full_xid = InvalidFullTransactionId;
+
+	PageSetTransactionSlotInfo(buffer, slot_no, full_xid, prev_urec_ptr);
+
+	MarkBufferDirty(buffer);
+
+	if (RelationNeedsWAL(rel))
+	{
+		ZHeapUndoActionWALInfo wal_info;
+
+		wal_info.buffer = buffer;
+		wal_info.vmbuffer = vmbuffer;
+		wal_info.prev_urecptr = prev_urec_ptr;
+		wal_info.slot_id = slot_no;
+		wal_info.tpd_page_locked = tpd_page_locked;
+		wal_info.tpd_offset_map = tpd_offset_map;
+		wal_info.is_tpd_map_updated = is_tpd_map_updated;
+		wal_info.tpd_map_size = tpd_map_size;
+		wal_info.fxid = full_xid;
+		wal_info.need_init = need_init;
+		log_zheap_undo_actions(&wal_info);
+	}
+
+	/*
+	 * During rollback, if all the itemids are marked as unused, we need to
+	 * initialize the page, so that the next insertion can see the page as
+	 * initialized.  This serves two purposes (a) On next insertion, we can
+	 * safely set the XLOG_ZHEAP_INIT_PAGE flag in WAL (OTOH, if we don't
+	 * initialize the page here and set the flag, wal consistency checker can
+	 * complain), (b) we don't accumulate the dead space in the page.
+	 *
+	 * Note that we initialize the page after writing WAL because the TPD
+	 * routines use last slot in page to determine TPD block number.
+	 */
+	if (need_init)
+		ZheapInitPage(page, (Size) BLCKSZ);
+
+	END_CRIT_SECTION();
+
+	/* Free TPD offset map memory. */
+	if (tpd_offset_map)
+		pfree(tpd_offset_map);
+
+	/*
+	 * Release any remaining pin on visibility map page.
+	 */
+	if (BufferIsValid(vmbuffer))
+		ReleaseBuffer(vmbuffer);
+
+	UnlockReleaseBuffer(buffer);
+	UnlockReleaseTPDBuffers();
+
+	/* Close the relation. */
+	relation_close(rel, RowExclusiveLock);
+
+	return true;
+}
+
+ /*
+  * log_zheap_undo_actions Perform XLogInsert for zheap_undo_actions.
+  *
+  * We are logging the complete page for undo actions, so we don't need to
+  * record the data for individual operations.  We can optimize it by
+  * recording the data for individual operations, but again if there are
+  * multiple operations, then it might be better to log the complete page. So
+  * we can have some threshold above which we always log the complete page.
+  */
+static void
+log_zheap_undo_actions(ZHeapUndoActionWALInfo *wal_info)
+{
+	XLogRecPtr	recptr;
+	uint8		flags = 0;
+	Page		page = BufferGetPage(wal_info->buffer);
+
+	if (wal_info->slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+		flags |= XLU_PAGE_CONTAINS_TPD_SLOT;
+	if (BufferIsValid(wal_info->vmbuffer))
+		flags |= XLU_PAGE_CLEAR_VISIBILITY_MAP;
+	if (wal_info->is_tpd_map_updated)
+	{
+		/* TPD page must be locked. */
+		Assert(wal_info->tpd_page_locked);
+		/* tpd_offset_map must be non-null. */
+		Assert(wal_info->tpd_offset_map);
+		flags |= XLU_CONTAINS_TPD_OFFSET_MAP;
+	}
+	if (wal_info->need_init)
+		flags |= XLU_INIT_PAGE;
+
+	XLogBeginInsert();
+
+	XLogRegisterData((char *) &flags, sizeof(uint8));
+	XLogRegisterBuffer(0, wal_info->buffer, REGBUF_FORCE_IMAGE | REGBUF_STANDARD);
+
+	/* Log the TPD details, if the transaction slot belongs to TPD. */
+	if (flags & XLU_PAGE_CONTAINS_TPD_SLOT)
+	{
+		xl_zundo_page xlrec;
+
+		xlrec.urec_ptr = wal_info->prev_urecptr;
+		xlrec.fxid = wal_info->fxid;
+		xlrec.trans_slot_id = wal_info->slot_id;
+		XLogRegisterData((char *) &xlrec, SizeOfZUndoPage);
+	}
+
+	/*
+	 * Log the TPD offset map if we have modified it.
+	 *
+	 * XXX Another option could be that we track all the offset map entries of
+	 * TPD which got modified while applying the undo and only log those
+	 * information into the WAL.
+	 */
+	if (wal_info->is_tpd_map_updated)
+	{
+		/* Fetch the TPD offset map and write into the WAL record. */
+		TPDPageGetOffsetMap(wal_info->buffer, wal_info->tpd_offset_map, wal_info->tpd_map_size);
+		XLogRegisterData((char *) wal_info->tpd_offset_map, wal_info->tpd_map_size);
+	}
+
+	if (flags & XLU_PAGE_CONTAINS_TPD_SLOT ||
+		flags & XLU_CONTAINS_TPD_OFFSET_MAP)
+	{
+		RegisterTPDBuffer(page, 1);
+	}
+
+	recptr = XLogInsert(RM_ZUNDO_ID, XLOG_ZUNDO_PAGE);
+
+	PageSetLSN(page, recptr);
+	if (flags & XLU_PAGE_CONTAINS_TPD_SLOT ||
+		flags & XLU_CONTAINS_TPD_OFFSET_MAP)
+		TPDPageSetLSN(page, recptr);
+}
+
+/*
+ * RestoreTupleFromUndoRecord - restore tuple from undorecord in page
+ *
+ * It also returns the old page tuple header to the caller.
+ */
+static ZHeapTupleHeader
+RestoreTupleFromUndoRecord(UnpackedUndoRecord *urec, Page page,
+						   ZHeapTupleHeader page_tup_hdr)
+{
+	ItemId		lp;
+	ZHeapTupleHeader zhtup;
+
+	lp = PageGetItemId(page, urec->uur_offset);
+	Assert(ItemIdIsNormal(lp));
+	zhtup = (ZHeapTupleHeader) PageGetItem(page, lp);
+
+	memcpy(page_tup_hdr, zhtup, SizeofZHeapTupleHeader);
+
+	switch (urec->uur_type)
+	{
+		case UNDO_XID_LOCK_ONLY:
+
+			/*
+			 * Override the tuple header values with values retrieved from
+			 * undo record except when there are multiple lockers.  In such
+			 * cases, we want to retain the strongest locker information
+			 * present in infomask and infomask2.
+			 */
+			if (!ZHeapTupleHasMultiLockers(page_tup_hdr->t_infomask))
+			{
+				ZHeapTupleHeader undo_tup_hdr;
+
+				undo_tup_hdr = (ZHeapTupleHeader) urec->uur_tuple.data;
+
+				/*
+				 * For locked tuples, undo tuple data is always same as prior
+				 * tuple's data as we don't modify it. Only override the tuple
+				 * header values with values fetched from undo record.
+				 */
+				zhtup->t_infomask2 = undo_tup_hdr->t_infomask2;
+				zhtup->t_infomask = undo_tup_hdr->t_infomask;
+				zhtup->t_hoff = undo_tup_hdr->t_hoff;
+			}
+			break;
+		case UNDO_XID_LOCK_FOR_UPDATE:
+			{
+				ZHeapTupleHeader undo_tup_hdr;
+
+				undo_tup_hdr = (ZHeapTupleHeader) urec->uur_tuple.data;
+
+				/*
+				 * For locked tuples, undo tuple data is always same as prior
+				 * tuple's data as we don't modify it. Only override the tuple
+				 * header values with values fetched from undo record.
+				 */
+				zhtup->t_infomask2 = undo_tup_hdr->t_infomask2;
+				zhtup->t_infomask = undo_tup_hdr->t_infomask;
+				zhtup->t_hoff = undo_tup_hdr->t_hoff;
+			}
+			break;
+		case UNDO_DELETE:
+		case UNDO_UPDATE:
+		case UNDO_INPLACE_UPDATE:
+			{
+				uint32		undo_tup_len = urec->uur_tuple.len;
+
+				/* change the item id length */
+				ItemIdChangeLen(lp, undo_tup_len);
+
+				/* restore data bytes */
+				memcpy(zhtup, urec->uur_tuple.data, undo_tup_len);
+			}
+			break;
+		case UNDO_INSERT:
+		case UNDO_MULTI_INSERT:
+		case UNDO_XID_MULTI_LOCK_ONLY:
+			elog(ERROR, "invalid undo record type for restoring tuple");
+			break;
+		default:
+			elog(ERROR, "unsupported undo record type");
+	}
+
+	return zhtup;
+}
+
+/*
+ * RestoreXactFromUndoRecord - restore xact related information on the tuple
+ *
+ * It checks whether we can mark the tuple as frozen based on certain
+ * conditions. It also sets the invalid xact flag on the tuple when previous
+ * xid from the undo record doesn't match with the slot xid.
+ *
+ * is_tpd_map_updated - true if tpd map is updated; false otherwise.
+ */
+static void
+RestoreXactFromUndoRecord(UnpackedUndoRecord *urec, Buffer buffer,
+						  ZHeapTupleHeader zhtup,
+						  bool tpd_offset_map,
+						  bool *is_tpd_map_updated)
+{
+	int			tup_trans_slot;
+	bool		update_tpd_map = false;
+	Page		page = BufferGetPage(buffer);
+	ZHeapTupleTransInfo zinfo;
+
+	/* Fetch transaction slot on tuple formed from undo record. */
+	tup_trans_slot = ZHeapTupleHeaderGetXactSlot(zhtup);
+
+	if (urec->uur_info & UREC_INFO_PAYLOAD_CONTAINS_SLOT)
+	{
+		if (tpd_offset_map)
+		{
+			/* Fetch TPD slot from the undo. */
+			if (urec->uur_type == UNDO_UPDATE)
+			{
+				tup_trans_slot =
+					*(int *) ((char *) urec->uur_payload.data +
+							  sizeof(ItemPointerData));
+			}
+			else if (urec->uur_type == UNDO_XID_LOCK_FOR_UPDATE)
+			{
+				tup_trans_slot =
+					*(int *) ((char *) urec->uur_payload.data +
+							  sizeof(LockTupleMode));
+			}
+			else
+			{
+				tup_trans_slot = *(int *) urec->uur_payload.data;
+			}
+
+			/*
+			 * If the previous transaction slot points to a TPD slot then we
+			 * need to update the slot in the offset map of the TPD entry.
+			 */
+			update_tpd_map = true;
+
+			GetTransactionSlotInfo(buffer, InvalidOffsetNumber, tup_trans_slot,
+								   false, true, &zinfo);
+
+			/* The old TPD slot can be frozen by now. */
+			Assert(zinfo.trans_slot == tup_trans_slot ||
+				   zinfo.trans_slot == ZHTUP_SLOT_FROZEN);
+
+			tup_trans_slot = zinfo.trans_slot;
+		}
+		else
+		{
+			/*
+			 * If we don't have a valid TPD entry for the page, the old tuple
+			 * version must be all visible and we can mark the slot as frozen.
+			 */
+			tup_trans_slot = ZHTUP_SLOT_FROZEN;
+		}
+	}
+	else if (tup_trans_slot == ZHEAP_PAGE_TRANS_SLOTS &&
+			 ZHeapPageHasTPDSlot((PageHeader) page))
+	{
+		if (tpd_offset_map)
+		{
+			/*
+			 * This is the case where during DO operation the previous updater
+			 * belongs to a non-TPD slot whereas now the same slot has become
+			 * a TPD slot. In such cases, we need to update offset-map.
+			 */
+			update_tpd_map = true;
+
+			GetTransactionSlotInfo(buffer, InvalidOffsetNumber, tup_trans_slot,
+								   false, true, &zinfo);
+
+			/* The old slot can be frozen by now or moved to a TPD slot. */
+			Assert(zinfo.trans_slot == tup_trans_slot + 1 ||
+				   zinfo.trans_slot == ZHTUP_SLOT_FROZEN);
+
+			tup_trans_slot = zinfo.trans_slot;
+		}
+		else
+		{
+			/*
+			 * If the previous slot is in tpd but tpd is pruned away then set
+			 * the slot as frozen.
+			 */
+			tup_trans_slot = ZHTUP_SLOT_FROZEN;
+		}
+	}
+	else
+	{
+		if (TransactionIdEquals(urec->uur_prevxid, FrozenTransactionId))
+		{
+			/*
+			 * If the previous xid is frozen, then we can safely mark the
+			 * tuple as frozen.
+			 */
+			tup_trans_slot = ZHTUP_SLOT_FROZEN;
+		}
+		else
+		{
+			GetTransactionSlotInfo(buffer, urec->uur_offset, tup_trans_slot,
+								   false, false, &zinfo);
+
+			/* The old slot can be frozen by now. */
+			Assert(zinfo.trans_slot == tup_trans_slot ||
+				   zinfo.trans_slot == ZHTUP_SLOT_FROZEN);
+
+			/* But, it can't be a TPD slot. */
+			Assert((zinfo.trans_slot < ZHEAP_PAGE_TRANS_SLOTS) ||
+				   (zinfo.trans_slot == ZHEAP_PAGE_TRANS_SLOTS &&
+					!ZHeapPageHasTPDSlot((PageHeader) page)));
+
+			tup_trans_slot = zinfo.trans_slot;
+		}
+	}
+
+	/*
+	 * If the previous version of the tuple points to a TPD slot then we need
+	 * to update the slot in the offset map of the TPD entry.
+	 */
+	if (update_tpd_map)
+	{
+		/* It should be a TPD slot. */
+		Assert(tup_trans_slot == ZHTUP_SLOT_FROZEN ||
+			   tup_trans_slot > ZHEAP_PAGE_TRANS_SLOTS);
+
+		TPDPageSetOffsetMapSlot(buffer,
+								tup_trans_slot,
+								urec->uur_offset);
+
+		/* Here, we updated TPD offset map, so need to log. */
+		if (is_tpd_map_updated)
+			*is_tpd_map_updated = true;
+	}
+
+	if (tup_trans_slot == ZHTUP_SLOT_FROZEN)
+		ZHeapTupleHeaderSetXactSlot(zhtup, ZHTUP_SLOT_FROZEN);
+	else if (urec->uur_prevxid != zinfo.xid)
+	{
+		/*
+		 * If the transaction slot to which tuple point got reused by this
+		 * time, then we need to mark the tuple with a special flag.  See
+		 * comments atop PageFreezeTransSlots.
+		 */
+		zhtup->t_infomask |= ZHEAP_INVALID_XACT_SLOT;
+	}
+}
diff --git a/src/backend/access/zheap/zvacuumlazy.c b/src/backend/access/zheap/zvacuumlazy.c
new file mode 100644
index 0000000..ec5baad
--- /dev/null
+++ b/src/backend/access/zheap/zvacuumlazy.c
@@ -0,0 +1,1555 @@
+/*-------------------------------------------------------------------------
+ *
+ * zvacuumlazy.c
+ *	  Concurrent ("lazy") vacuuming.
+ *
+ *
+ * The lazy vacuum in zheap uses two-passes to clean up the dead tuples in
+ * heap and index.  It reclaims all the dead items in heap in the first pass
+ * and write undo record for such items, then clean the indexes in second
+ * pass.  The undo is written, so that if there is any error while cleaning
+ * indexes, we can rollback the operation and mark the entries in as dead.
+ *
+ * The vacuum progress checker also uses only two phases - the vacuuming heap
+ * and the vacuuming index. The scanning heap phase is not used because it is
+ * not a separate pass in zheap but a part of the first pass.
+ *
+ * The other important aspect that is ensured in this system is that we don't
+ * item ids that are marked as unused to be reused till the transaction that
+ * has marked them unused is committed.
+ *
+ * The dead tuple tracking works in the same way as in heap.  See lazyvacuum.c.
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ *
+ * IDENTIFICATION
+ *	  src/backend/commands/zvacuumlazy.c
+ *
+ *-------------------------------------------------------------------------
+ */
+#include "postgres.h"
+
+#include <math.h>
+
+#include "access/genam.h"
+#include "access/multixact.h"
+#include "access/tpd.h"
+#include "access/vacuumblk.h"
+#include "access/visibilitymap.h"
+#include "access/xact.h"
+#include "access/zhtup.h"
+#include "utils/ztqual.h"
+#include "access/zheapam_xlog.h"
+#include "commands/dbcommands.h"
+#include "commands/progress.h"
+#include "commands/vacuum.h"
+#include "miscadmin.h"
+#include "pgstat.h"
+#include "portability/instr_time.h"
+#include "postmaster/autovacuum.h"
+#include "storage/bufmgr.h"
+#include "storage/freespace.h"
+#include "storage/lmgr.h"
+#include "storage/procarray.h"
+#include "utils/lsyscache.h"
+#include "utils/memutils.h"
+#include "utils/pg_rusage.h"
+
+/*
+ * Before we consider skipping a page that's marked as clean in
+ * visibility map, we must've seen at least this many clean pages.
+ */
+#define SKIP_PAGES_THRESHOLD	((BlockNumber) 32)
+
+/* A few variables that don't seem worth passing around as parameters */
+static int	elevel = -1;
+static TransactionId OldestXmin;
+static BufferAccessStrategy vac_strategy;
+
+/*
+ * Guesstimate the number of dead tuples per page.  This is used to
+ * provide an upper limit to memory allocated when vacuuming small
+ * tables.
+ */
+#define LAZY_ALLOC_TUPLES		MaxZHeapTuplesPerPage
+
+/* non-export function prototypes */
+static int	lazy_vacuum_zpage(Relation onerel, BlockNumber blkno, Buffer buffer,
+							  int tupindex, LVRelStats *vacrelstats, Buffer *vmbuffer);
+static int	lazy_vacuum_zpage_with_undo(Relation onerel, BlockNumber blkno, Buffer buffer,
+										int tupindex, LVRelStats *vacrelstats,
+										Buffer *vmbuffer,
+										TransactionId *global_visibility_cutoff_xid);
+static void
+			lazy_space_zalloc(LVRelStats *vacrelstats, BlockNumber relblocks);
+static void lazy_scan_zheap(Relation onerel, VacuumParams *params, LVRelStats *vacrelstats,
+							Relation *Irel, int nindexes,
+							BufferAccessStrategy vac_strategy, bool aggressive);
+static bool zheap_page_is_all_visible(Relation rel, Buffer buf,
+									  TransactionId *visibility_cutoff_xid);
+
+/*
+ *	lazy_vacuum_zpage() -- free dead tuples on a page
+ *					 and repair its fragmentation.
+ *
+ * Caller must hold pin and buffer exclusive lock on the buffer.
+ *
+ * tupindex is the index in vacrelstats->dead_tuples of the first dead
+ * tuple for this page.  We assume the rest follow sequentially.
+ * The return value is the first tupindex after the tuples of this page.
+ */
+static int
+lazy_vacuum_zpage(Relation onerel, BlockNumber blkno, Buffer buffer,
+				  int tupindex, LVRelStats *vacrelstats, Buffer *vmbuffer)
+{
+	Page		page = BufferGetPage(buffer);
+	Page		tmppage;
+	OffsetNumber unused[MaxOffsetNumber];
+	int			uncnt = 0;
+	TransactionId visibility_cutoff_xid;
+	bool		pruned = false;
+
+	/*
+	 * Lock the TPD page before starting critical section.  We might need to
+	 * access it during page repair fragmentation.
+	 */
+	if (ZHeapPageHasTPDSlot((PageHeader) page))
+		TPDPageLock(onerel, buffer);
+
+	/*
+	 * We prepare the temporary copy of the page so that during page repair
+	 * fragmentation we can use it to copy the actual tuples. See comments
+	 * atop zheap_page_prune_guts.
+	 */
+	tmppage = PageGetTempPageCopy(page);
+
+	/* Report the number of blocks vacuumed. */
+	pgstat_progress_update_param(PROGRESS_VACUUM_HEAP_BLKS_VACUUMED, blkno - 1);
+
+	START_CRIT_SECTION();
+
+	for (; tupindex < vacrelstats->num_dead_tuples; tupindex++)
+	{
+		BlockNumber tblk;
+		OffsetNumber toff;
+		ItemId		itemid;
+
+		tblk = ItemPointerGetBlockNumber(&vacrelstats->dead_tuples[tupindex]);
+		if (tblk != blkno)
+			break;				/* past end of tuples for this block */
+		toff = ItemPointerGetOffsetNumber(&vacrelstats->dead_tuples[tupindex]);
+		itemid = PageGetItemId(page, toff);
+		ItemIdSetUnused(itemid);
+		unused[uncnt++] = toff;
+	}
+
+	ZPageRepairFragmentation(buffer, tmppage, InvalidOffsetNumber, 0, false,
+							 &pruned, false);
+
+	/*
+	 * Mark buffer dirty before we write WAL.
+	 */
+	MarkBufferDirty(buffer);
+
+	/* XLOG stuff */
+	if (RelationNeedsWAL(onerel))
+	{
+		XLogRecPtr	recptr;
+
+		recptr = log_zheap_clean(onerel, buffer, InvalidOffsetNumber, 0,
+								 NULL, 0, NULL, 0,
+								 unused, uncnt,
+								 vacrelstats->latestRemovedXid, pruned);
+		PageSetLSN(page, recptr);
+	}
+
+	END_CRIT_SECTION();
+
+	/* be tidy */
+	pfree(tmppage);
+	UnlockReleaseTPDBuffers();
+
+	/*
+	 * Now that we have removed the dead tuples from the page, once again
+	 * check if the page has become all-visible.  The page is already marked
+	 * dirty, exclusively locked.
+	 */
+	if (zheap_page_is_all_visible(onerel, buffer, &visibility_cutoff_xid))
+	{
+		uint8		vm_status = visibilitymap_get_status(onerel, blkno, vmbuffer);
+		uint8		flags = 0;
+
+		/* Set the VM all-visible bit to flag, if needed */
+		if ((vm_status & VISIBILITYMAP_ALL_VISIBLE) == 0)
+			flags |= VISIBILITYMAP_ALL_VISIBLE;
+
+		Assert(BufferIsValid(*vmbuffer));
+		if (flags != 0)
+			visibilitymap_set(onerel, blkno, buffer, InvalidXLogRecPtr,
+							  *vmbuffer, visibility_cutoff_xid, flags);
+	}
+
+	return tupindex;
+}
+
+/*
+ *	lazy_vacuum_zpage_with_undo() -- free dead tuples on a page
+ *					 and repair its fragmentation.
+ *
+ * Caller must hold pin and buffer exclusive lock on the buffer.
+ */
+static int
+lazy_vacuum_zpage_with_undo(Relation onerel, BlockNumber blkno, Buffer buffer,
+							int tupindex, LVRelStats *vacrelstats,
+							Buffer *vmbuffer,
+							TransactionId *global_visibility_cutoff_xid)
+{
+	TransactionId visibility_cutoff_xid;
+	FullTransactionId fxid = GetTopFullTransactionId();
+	TransactionId xid = XidFromFullTransactionId(fxid);
+	Page		page = BufferGetPage(buffer);
+	Page		tmppage;
+	UnpackedUndoRecord undorecord;
+	OffsetNumber unused[MaxOffsetNumber];
+	UndoRecPtr	urecptr,
+				prev_urecptr;
+	int			i,
+				uncnt = 0;
+	int			trans_slot_id;
+	XLogRecPtr	RedoRecPtr;
+	bool		doPageWrites;
+	bool		lock_reacquired;
+	bool		pruned = false;
+	UndoRecordInsertContext	context;
+
+	for (; tupindex < vacrelstats->num_dead_tuples; tupindex++)
+	{
+		BlockNumber tblk PG_USED_FOR_ASSERTS_ONLY;
+		OffsetNumber toff;
+
+		tblk = ItemPointerGetBlockNumber(&vacrelstats->dead_tuples[tupindex]);
+
+		/*
+		 * We should never pass the end of tuples for this block as we clean
+		 * the tuples in the current block before moving to next block.
+		 */
+		Assert(tblk == blkno);
+
+		toff = ItemPointerGetOffsetNumber(&vacrelstats->dead_tuples[tupindex]);
+		unused[uncnt++] = toff;
+	}
+
+	if (uncnt <= 0)
+		return tupindex;
+
+reacquire_slot:
+
+	/*
+	 * The transaction information of tuple needs to be set in transaction
+	 * slot, so needs to reserve the slot before proceeding with the actual
+	 * operation.  It will be costly to wait for getting the slot, but we do
+	 * that by releasing the buffer lock.
+	 */
+	trans_slot_id = PageReserveTransactionSlot(onerel,
+											   buffer,
+											   PageGetMaxOffsetNumber(page),
+											   fxid,
+											   &prev_urecptr,
+											   &lock_reacquired,
+											   false,
+											   InvalidBuffer,
+											   NULL);
+	if (lock_reacquired)
+		goto reacquire_slot;
+
+	if (trans_slot_id == InvalidXactSlotId)
+	{
+		LockBuffer(buffer, BUFFER_LOCK_UNLOCK);
+
+		pgstat_report_wait_start(PG_WAIT_PAGE_TRANS_SLOT);
+		pg_usleep(10000L);		/* 10 ms */
+		pgstat_report_wait_end();
+
+		LockBuffer(buffer, BUFFER_LOCK_EXCLUSIVE);
+		goto reacquire_slot;
+	}
+
+	/* prepare an undo record */
+	undorecord.uur_rmid = RM_ZHEAP_ID;
+	undorecord.uur_type = UNDO_ITEMID_UNUSED;
+	undorecord.uur_info = 0;
+	undorecord.uur_reloid = onerel->rd_id;
+	undorecord.uur_prevxid = xid;
+	undorecord.uur_xid = xid;
+	undorecord.uur_cid = InvalidCommandId;
+	undorecord.uur_fork = MAIN_FORKNUM;
+	undorecord.uur_blkprev = prev_urecptr;
+	undorecord.uur_block = blkno;
+	undorecord.uur_offset = 0;
+	undorecord.uur_tuple.len = 0;
+	undorecord.uur_payload.len = uncnt * sizeof(OffsetNumber);
+	undorecord.uur_payload.data = (char *) palloc(uncnt * sizeof(OffsetNumber));
+
+	/*
+	 * XXX Unlike other undo records, we don't set the TPD slot number in undo
+	 * record as this record is just skipped during processing of undo.
+	 */
+	BeginUndoRecordInsert(&context, UNDO_PERMANENT, 1, NULL);
+	urecptr = PrepareUndoInsert(&context, &undorecord,
+								InvalidFullTransactionId);
+
+	/*
+	 * Lock the TPD page before starting critical section.  We might need to
+	 * access it during page repair fragmentation.  Note that if the
+	 * transaction slot belongs to TPD entry, then the TPD page must be locked
+	 * during slot reservation.
+	 */
+	if (trans_slot_id <= ZHEAP_PAGE_TRANS_SLOTS &&
+		ZHeapPageHasTPDSlot((PageHeader) page))
+		TPDPageLock(onerel, buffer);
+
+	/*
+	 * We prepare the temporary copy of the page so that during page repair
+	 * fragmentation we can use it to copy the actual tuples. See comments
+	 * atop zheap_page_prune_guts.
+	 */
+	tmppage = PageGetTempPageCopy(page);
+
+
+	/* Report the number of blocks vacuumed. */
+	pgstat_progress_update_param(PROGRESS_VACUUM_HEAP_BLKS_VACUUMED, blkno - 1);
+
+	START_CRIT_SECTION();
+
+	memcpy(undorecord.uur_payload.data, unused, uncnt * sizeof(OffsetNumber));
+	InsertPreparedUndo(&context);
+
+	/*
+	 * We're sending the undo record for debugging purpose. So, just send the
+	 * last one.
+	 */
+	if (trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+	{
+		PageSetUNDO(undorecord,
+					buffer,
+					trans_slot_id,
+					true,
+					fxid,
+					urecptr,
+					unused,
+					uncnt);
+	}
+	else
+	{
+		PageSetUNDO(undorecord,
+					buffer,
+					trans_slot_id,
+					true,
+					fxid,
+					urecptr,
+					NULL,
+					0);
+	}
+
+	for (i = 0; i < uncnt; i++)
+	{
+		ItemId		itemid;
+
+		itemid = PageGetItemId(page, unused[i]);
+		ItemIdSetUnusedExtended(itemid, trans_slot_id);
+	}
+
+	ZPageRepairFragmentation(buffer, tmppage, InvalidOffsetNumber, 0, false,
+							 &pruned, true);
+
+	/*
+	 * Mark buffer dirty before we write WAL.
+	 */
+	MarkBufferDirty(buffer);
+
+	/* XLOG stuff */
+	if (RelationNeedsWAL(onerel))
+	{
+		xl_zheap_unused xl_rec;
+		xl_undo_header xlundohdr;
+		XLogRecPtr	recptr;
+
+		/*
+		 * Store the information required to generate undo record during
+		 * replay.
+		 */
+		xlundohdr.reloid = undorecord.uur_reloid;
+		xlundohdr.urec_ptr = urecptr;
+		xlundohdr.blkprev = prev_urecptr;
+
+		xl_rec.latestRemovedXid = vacrelstats->latestRemovedXid;
+		xl_rec.nunused = uncnt;
+		xl_rec.trans_slot_id = trans_slot_id;
+		xl_rec.flags = 0;
+		if (pruned)
+			xl_rec.flags |= XLZ_UNUSED_ALLOW_PRUNING;
+
+prepare_xlog:
+
+		GetFullPageWriteInfo(&RedoRecPtr, &doPageWrites);
+
+		XLogBeginInsert();
+		XLogRegisterData((char *) &xlundohdr, SizeOfUndoHeader);
+		XLogRegisterData((char *) &xl_rec, SizeOfZHeapUnused);
+
+		XLogRegisterData((char *) unused, uncnt * sizeof(OffsetNumber));
+		XLogRegisterBuffer(0, buffer, REGBUF_STANDARD);
+		if (trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+			(void) RegisterTPDBuffer(page, 1);
+
+		RegisterUndoLogBuffers(&context, 2);
+
+		recptr = XLogInsertExtended(RM_ZHEAP2_ID, XLOG_ZHEAP_UNUSED, RedoRecPtr,
+									doPageWrites);
+		if (recptr == InvalidXLogRecPtr)
+		{
+			ResetRegisteredTPDBuffers();
+			goto prepare_xlog;
+		}
+
+		PageSetLSN(page, recptr);
+		if (trans_slot_id > ZHEAP_PAGE_TRANS_SLOTS)
+			TPDPageSetLSN(page, recptr);
+		UndoLogBuffersSetLSN(&context, recptr);
+	}
+
+	END_CRIT_SECTION();
+
+	FinishUndoRecordInsert(&context);
+	UnlockReleaseTPDBuffers();
+
+	/* be tidy */
+	pfree(tmppage);
+
+	/*
+	 * Now that we have removed the dead tuples from the page, once again
+	 * check if the page has become potentially all-visible.  The page is
+	 * already marked dirty, exclusively locked.  We can't mark the page as
+	 * all-visible here because we have yet to remove index entries
+	 * corresponding dead tuples.  So, we mark them potentially all-visible
+	 * and later after removing index entries, if still the bit is set, we
+	 * mark them as all-visible.
+	 */
+	if (zheap_page_is_all_visible(onerel, buffer, &visibility_cutoff_xid))
+	{
+		uint8		vm_status = visibilitymap_get_status(onerel, blkno, vmbuffer);
+		uint8		flags = 0;
+
+		/* Set the VM to become potentially all-visible, if needed */
+		if ((vm_status & VISIBILITYMAP_POTENTIAL_ALL_VISIBLE) == 0)
+			flags |= VISIBILITYMAP_POTENTIAL_ALL_VISIBLE;
+
+		if (TransactionIdFollows(visibility_cutoff_xid,
+								 *global_visibility_cutoff_xid))
+			*global_visibility_cutoff_xid = visibility_cutoff_xid;
+
+		Assert(BufferIsValid(*vmbuffer));
+		if (flags != 0)
+			visibilitymap_set(onerel, blkno, buffer, InvalidXLogRecPtr,
+							  *vmbuffer, InvalidTransactionId, flags);
+	}
+
+	return tupindex;
+}
+
+/*
+ *	MarkPagesAsAllVisible() -- Mark all the pages corresponding to dead tuples
+ *		as all-visible.
+ *
+ * We mark the page as all-visible, if it is already marked as potential
+ * all-visible.
+ */
+static void
+MarkPagesAsAllVisible(Relation rel, LVRelStats *vacrelstats,
+					  TransactionId visibility_cutoff_xid)
+{
+	int			idx = 0;
+
+	for (; idx < vacrelstats->num_dead_tuples; idx++)
+	{
+		BlockNumber tblk;
+		BlockNumber prev_tblk = InvalidBlockNumber;
+		Buffer		vmbuffer = InvalidBuffer;
+		Buffer		buf = InvalidBuffer;
+		uint8		vm_status;
+
+		tblk = ItemPointerGetBlockNumber(&vacrelstats->dead_tuples[idx]);
+		buf = ReadBufferExtended(rel, MAIN_FORKNUM, tblk,
+								 RBM_NORMAL, NULL);
+
+		/* Avoid processing same block again and again. */
+		if (tblk == prev_tblk)
+			continue;
+
+		visibilitymap_pin(rel, tblk, &vmbuffer);
+		vm_status = visibilitymap_get_status(rel, tblk, &vmbuffer);
+
+		/* Set the VM all-visible bit, if needed */
+		if ((vm_status & VISIBILITYMAP_ALL_VISIBLE) == 0 &&
+			(vm_status & VISIBILITYMAP_POTENTIAL_ALL_VISIBLE))
+		{
+			visibilitymap_clear(rel, tblk, vmbuffer,
+								VISIBILITYMAP_VALID_BITS);
+
+			Assert(BufferIsValid(buf));
+			LockBuffer(buf, BUFFER_LOCK_SHARE);
+
+			visibilitymap_set(rel, tblk, buf, InvalidXLogRecPtr, vmbuffer,
+							  visibility_cutoff_xid, VISIBILITYMAP_ALL_VISIBLE);
+
+			LockBuffer(buf, BUFFER_LOCK_UNLOCK);
+		}
+
+		if (BufferIsValid(vmbuffer))
+		{
+			ReleaseBuffer(vmbuffer);
+			vmbuffer = InvalidBuffer;
+		}
+
+		if (BufferIsValid(buf))
+		{
+			ReleaseBuffer(buf);
+			buf = InvalidBuffer;
+		}
+
+		prev_tblk = tblk;
+	}
+}
+
+/*
+ *	lazy_scan_zheap() -- scan an open heap relation
+ *
+ *		This routine prunes each page in the zheap, which will among other
+ *		things truncate dead tuples to dead line pointers, truncate recently
+ *		dead tuples to deleted line pointers and defragment the page
+ *		(see zheap_page_prune).  It also builds lists of dead tuples and pages
+ *		with free space, calculates statistics on the number of live tuples in
+ *		the zheap.  It then reclaim all dead line pointers and write undo for
+ *		each of them, so that if there is any error later, we can rollback the
+ *		operation.  When done, or when we run low on space for dead-tuple
+ *		TIDs, invoke vacuuming of indexes.
+ *
+ *		We also need to ensure that the heap-TIDs won't get reused till the
+ *		transaction that has performed this vacuum is committed.  To achieve
+ *		that, we need to store transaction slot information in the line
+ *		pointers that are marked unused in the first-pass of heap.
+ *
+ *		If there are no indexes then we can reclaim line pointers without
+ *		writing any undo;
+ */
+static void
+lazy_scan_zheap(Relation onerel, VacuumParams *params, LVRelStats *vacrelstats,
+				Relation *Irel, int nindexes,
+				BufferAccessStrategy vac_strategy, bool aggressive)
+{
+	BlockNumber nblocks,
+				blkno;
+	ZHeapTupleData tuple;
+	char	   *relname;
+	BlockNumber empty_pages,
+				vacuumed_pages,
+				next_fsm_block_to_vacuum;
+	double		num_tuples,
+				tups_vacuumed,
+				nkeep,
+				nunused;
+	IndexBulkDeleteResult **indstats;
+	StringInfoData infobuf;
+	int			i;
+	int			tupindex = 0;
+	PGRUsage	ru0;
+	BlockNumber next_unskippable_block;
+	bool		skipping_blocks;
+	Buffer		vmbuffer = InvalidBuffer;
+	TransactionId visibility_cutoff_xid = InvalidTransactionId;
+	const int	initprog_index[] = {
+		PROGRESS_VACUUM_PHASE,
+		PROGRESS_VACUUM_TOTAL_HEAP_BLKS,
+		PROGRESS_VACUUM_MAX_DEAD_TUPLES
+	};
+	int64		initprog_val[3];
+
+
+	pg_rusage_init(&ru0);
+
+	relname = RelationGetRelationName(onerel);
+	if (aggressive)
+		ereport(elevel,
+				(errmsg("aggressively vacuuming \"%s.%s\"",
+						get_namespace_name(RelationGetNamespace(onerel)),
+						relname)));
+	else
+		ereport(elevel,
+				(errmsg("vacuuming \"%s.%s\"",
+						get_namespace_name(RelationGetNamespace(onerel)),
+						relname)));
+
+	empty_pages = vacuumed_pages = 0;
+	next_fsm_block_to_vacuum = (BlockNumber) 0;
+	num_tuples = tups_vacuumed = nkeep = nunused = 0;
+
+	indstats = (IndexBulkDeleteResult **)
+		palloc0(nindexes * sizeof(IndexBulkDeleteResult *));
+
+	nblocks = RelationGetNumberOfBlocks(onerel);
+	vacrelstats->rel_pages = nblocks;
+	vacrelstats->scanned_pages = 0;
+	vacrelstats->tupcount_pages = 0;
+	vacrelstats->nonempty_pages = 0;
+	vacrelstats->latestRemovedXid = InvalidTransactionId;
+
+	lazy_space_zalloc(vacrelstats, nblocks);
+
+	/*
+	 * Report that we are vacuuming heap and advertise the total number of
+	 * blocks and max dead tuples. The metapage is also considered in nblocks,
+	 * subtract by one to get total pages.
+	 */
+	initprog_val[0] = PROGRESS_VACUUM_PHASE_VACUUM_HEAP;
+	initprog_val[1] = nblocks - 1;
+	initprog_val[2] = vacrelstats->max_dead_tuples;
+	pgstat_progress_update_multi_param(3, initprog_index, initprog_val);
+
+	next_unskippable_block = ZHEAP_METAPAGE + 1;
+	if (!aggressive)
+	{
+
+		Assert((params->options & VACOPT_DISABLE_PAGE_SKIPPING) == 0);
+		while (next_unskippable_block < nblocks)
+		{
+			uint8		vmstatus;
+
+			vmstatus = visibilitymap_get_status(onerel, next_unskippable_block,
+												&vmbuffer);
+
+			if ((vmstatus & VISIBILITYMAP_ALL_VISIBLE) == 0)
+				break;
+
+			vacuum_delay_point();
+			next_unskippable_block++;
+		}
+	}
+
+	if (next_unskippable_block >= SKIP_PAGES_THRESHOLD)
+		skipping_blocks = true;
+	else
+		skipping_blocks = false;
+
+	for (blkno = ZHEAP_METAPAGE + 1; blkno < nblocks; blkno++)
+	{
+		Buffer		buf;
+		Page		page;
+		TransactionId xid;
+		OffsetNumber offnum,
+					maxoff;
+		Size		freespace;
+		bool		tupgone,
+					hastup;
+		bool		all_visible_according_to_vm = false;
+		bool		all_visible;
+		bool		has_dead_tuples;
+
+		/* Report the number of blocks scanned. */
+		pgstat_progress_update_param(PROGRESS_VACUUM_HEAP_BLKS_SCANNED, blkno - 1);
+
+		if (blkno == next_unskippable_block)
+		{
+			/* Time to advance next_unskippable_block */
+			next_unskippable_block++;
+			if (!aggressive)
+			{
+				while (next_unskippable_block < nblocks)
+				{
+					uint8		vmskipflags;
+
+					vmskipflags = visibilitymap_get_status(onerel,
+														   next_unskippable_block,
+														   &vmbuffer);
+					if ((vmskipflags & VISIBILITYMAP_ALL_VISIBLE) == 0)
+						break;
+
+					vacuum_delay_point();
+					next_unskippable_block++;
+				}
+			}
+
+			/*
+			 * We know we can't skip the current block.  But set up
+			 * skipping_blocks to do the right thing at the following blocks.
+			 */
+			if (next_unskippable_block - blkno > SKIP_PAGES_THRESHOLD)
+				skipping_blocks = true;
+			else
+				skipping_blocks = false;
+		}
+		else
+		{
+			/*
+			 * The current block is potentially skippable; if we've seen a
+			 * long enough run of skippable blocks to justify skipping it.
+			 */
+			if (skipping_blocks)
+				continue;
+			all_visible_according_to_vm = true;
+		}
+
+		vacuum_delay_point();
+
+		/*
+		 * If we are close to overrunning the available space for dead-tuple
+		 * TIDs, pause and do a cycle of vacuuming before we tackle this page.
+		 */
+		if ((vacrelstats->max_dead_tuples - vacrelstats->num_dead_tuples) < MaxZHeapTuplesPerPage &&
+			vacrelstats->num_dead_tuples > 0)
+		{
+			/*
+			 * Before beginning index vacuuming, we release any pin we may
+			 * hold on the visibility map page.  This isn't necessary for
+			 * correctness, but we do it anyway to avoid holding the pin
+			 * across a lengthy, unrelated operation.
+			 */
+			if (BufferIsValid(vmbuffer))
+			{
+				ReleaseBuffer(vmbuffer);
+				vmbuffer = InvalidBuffer;
+			}
+
+			/* Report that we are now vacuuming indexes. */
+			pgstat_progress_update_param(PROGRESS_VACUUM_PHASE,
+										 PROGRESS_VACUUM_PHASE_VACUUM_INDEX);
+
+			/*
+			 * Remove index entries.  Unlike, heap we don't need to log
+			 * special cleanup info which includes latest latestRemovedXid for
+			 * standby. This is because we have covered all the dead tuples in
+			 * the first pass itself and we don't need another pass on heap
+			 * after index.
+			 */
+			for (i = 0; i < nindexes; i++)
+				lazy_vacuum_index(Irel[i],
+								  &indstats[i],
+								  vacrelstats,
+								  vac_strategy,
+								  elevel);
+
+			pgstat_progress_update_param(PROGRESS_VACUUM_NUM_INDEX_VACUUMS,
+										 vacrelstats->num_index_scans + 1);
+
+			/*
+			 * XXX - The cutoff xid used here is the highest xmin of all the
+			 * heap pages scanned.  This can lead to more query cancellations
+			 * on standby.  However, alternative is that we track cutoff_xid
+			 * for each page in first-pass of vacuum and then use it after
+			 * removing index entries.  We didn't pursue the alternative
+			 * because it would require more work memory which means it can
+			 * lead to more index passes.
+			 */
+			MarkPagesAsAllVisible(onerel, vacrelstats, visibility_cutoff_xid);
+
+			/*
+			 * Forget the now-vacuumed tuples, and press on, but be careful
+			 * not to reset latestRemovedXid since we want that value to be
+			 * valid.
+			 */
+			tupindex = 0;
+			vacrelstats->num_dead_tuples = 0;
+			vacrelstats->num_index_scans++;
+
+			/*
+			 * Vacuum the Free Space Map to make newly-freed space visible on
+			 * upper-level FSM pages.  Note we have not yet processed blkno.
+			 */
+			FreeSpaceMapVacuumRange(onerel, next_fsm_block_to_vacuum, blkno);
+			next_fsm_block_to_vacuum = blkno;
+
+			/* Report that we are once again vacuuming the heap. */
+			pgstat_progress_update_param(PROGRESS_VACUUM_PHASE,
+										 PROGRESS_VACUUM_PHASE_VACUUM_HEAP);
+		}
+
+		/*
+		 * Pin the visibility map page in case we need to mark the page
+		 * all-visible.  In most cases this will be very cheap, because we'll
+		 * already have the correct page pinned anyway.  However, it's
+		 * possible that (a) next_unskippable_block is covered by a different
+		 * VM page than the current block or (b) we released our pin and did a
+		 * cycle of index vacuuming.
+		 *
+		 */
+		visibilitymap_pin(onerel, blkno, &vmbuffer);
+
+		buf = ReadBufferExtended(onerel, MAIN_FORKNUM, blkno,
+								 RBM_NORMAL, vac_strategy);
+		LockBuffer(buf, BUFFER_LOCK_EXCLUSIVE);
+
+		vacrelstats->scanned_pages++;
+		vacrelstats->tupcount_pages++;
+
+		page = BufferGetPage(buf);
+
+		if (PageIsNew(page))
+		{
+			/*
+			 * An all-zeros page could be left over if a backend extends the
+			 * relation but crashes before initializing the page, or when
+			 * bulk-extending the relation (which creates a number of empty
+			 * pages at the tail end of the relation, but enters them into the
+			 * FSM)Reclaim such pages for use.  See the similar code in
+			 * lazy_scan_heap to know why we have used relation extension
+			 * lock.
+			 */
+			Size		freespace = 0;
+
+			empty_pages++;
+
+			/*
+			 * Perform checking of FSM after releasing lock, the fsm is
+			 * approximate, after all.
+			 */
+			UnlockReleaseBuffer(buf);
+
+			if (GetRecordedFreeSpace(onerel, blkno) == 0)
+				freespace = BufferGetPageSize(buf) - SizeOfPageHeaderData;
+
+			if (freespace > 0)
+			{
+				RecordPageWithFreeSpace(onerel, blkno, freespace);
+				elog(DEBUG1, "relation \"%s\" page %u is uninitialized and not in fsm, fixing",
+					 relname, blkno);
+			}
+			continue;
+		}
+
+		/*
+		 * Skip TPD pages.  This needs to be checked before PageIsEmpty as TPD
+		 * pages can also be empty, but we don't want to deal with it like a
+		 * heap page.
+		 */
+
+		/*
+		 * Prune the TPD pages and if all the entries are removed, then record
+		 * it in FSM, so that it can be reused as a zheap page.
+		 */
+		if (IsTPDPage(page))
+		{
+			TPDPagePrune(onerel, buf, vac_strategy, InvalidOffsetNumber, 0,
+						 true, NULL, NULL);
+
+			/*
+			 * Remember the location of the last page with non-removable
+			 * tuples.
+			 */
+			if (!PageIsNew(page))
+				vacrelstats->nonempty_pages = blkno + 1;
+
+			UnlockReleaseBuffer(buf);
+			continue;
+		}
+
+		if (PageIsEmpty(page))
+		{
+			uint8		vmstatus;
+
+			empty_pages++;
+			freespace = PageGetZHeapFreeSpace(page);
+
+			vmstatus = visibilitymap_get_status(onerel,
+												blkno,
+												&vmbuffer);
+			if ((vmstatus & VISIBILITYMAP_ALL_VISIBLE) == 0)
+			{
+				START_CRIT_SECTION();
+
+				/* mark buffer dirty before writing a WAL record */
+				MarkBufferDirty(buf);
+
+				/*
+				 * It's possible that another backend has extended the heap,
+				 * initialized the page, and then failed to WAL-log the page
+				 * due to an ERROR.  Since heap extension is not WAL-logged,
+				 * recovery might try to replay our record setting the page
+				 * all-visible and find that the page isn't initialized, which
+				 * will cause a PANIC.  To prevent that, check whether the
+				 * page has been previously WAL-logged, and if not, do that
+				 * now.
+				 */
+				if (RelationNeedsWAL(onerel) &&
+					PageGetLSN(page) == InvalidXLogRecPtr)
+					log_newpage_buffer(buf, true);
+
+				visibilitymap_set(onerel, blkno, buf, InvalidXLogRecPtr,
+								  vmbuffer, InvalidTransactionId,
+								  VISIBILITYMAP_ALL_VISIBLE);
+
+				END_CRIT_SECTION();
+			}
+
+			UnlockReleaseBuffer(buf);
+			RecordPageWithFreeSpace(onerel, blkno, freespace);
+			continue;
+		}
+
+		/*
+		 * We count tuples removed by the pruning step as removed by VACUUM.
+		 */
+		tups_vacuumed += zheap_page_prune_guts(onerel, buf, OldestXmin,
+											   InvalidOffsetNumber, 0, false,
+											   false,
+											   &vacrelstats->latestRemovedXid,
+											   NULL);
+
+		/* Now scan the page to collect vacuumable items. */
+		hastup = false;
+		freespace = 0;
+		maxoff = PageGetMaxOffsetNumber(page);
+		all_visible = true;
+		has_dead_tuples = false;
+
+		for (offnum = FirstOffsetNumber;
+			 offnum <= maxoff;
+			 offnum = OffsetNumberNext(offnum))
+		{
+			ItemId		itemid;
+
+			itemid = PageGetItemId(page, offnum);
+
+			/* Unused items require no processing, but we count 'em */
+			if (!ItemIdIsUsed(itemid))
+			{
+				nunused += 1;
+				continue;
+			}
+
+			/* Deleted items mustn't be touched */
+			if (ItemIdIsDeleted(itemid))
+			{
+				hastup = true;	/* this page cannot be truncated */
+				all_visible = false;
+				continue;
+			}
+
+			ItemPointerSet(&(tuple.t_self), blkno, offnum);
+
+			/*
+			 * DEAD item pointers are to be vacuumed normally; but we don't
+			 * count them in tups_vacuumed, else we'd be double-counting (at
+			 * least in the common case where zheap_page_prune_guts() just
+			 * freed up a tuple).
+			 */
+			if (ItemIdIsDead(itemid))
+			{
+				all_visible = false;
+				lazy_record_dead_tuple(vacrelstats, &(tuple.t_self));
+				continue;
+			}
+
+			Assert(ItemIdIsNormal(itemid));
+
+			tuple.t_data = (ZHeapTupleHeader) PageGetItem(page, itemid);
+			tuple.t_len = ItemIdGetLength(itemid);
+			tuple.t_tableOid = RelationGetRelid(onerel);
+
+			tupgone = false;
+
+			switch (ZHeapTupleSatisfiesOldestXmin(&tuple, OldestXmin, buf,
+												  false, NULL, &xid, NULL))
+			{
+				case ZHEAPTUPLE_DEAD:
+
+					/*
+					 * Ordinarily, DEAD tuples would have been removed by
+					 * zheap_page_prune_guts(), but it's possible that the
+					 * tuple state changed since heap_page_prune() looked. In
+					 * particular an INSERT_IN_PROGRESS tuple could have
+					 * changed to DEAD if the inserter aborted.  So this
+					 * cannot be considered an error condition.
+					 */
+					tupgone = true; /* we can delete the tuple */
+					all_visible = false;
+					break;
+				case ZHEAPTUPLE_LIVE:
+					if (all_visible)
+					{
+						if (!TransactionIdPrecedes(xid, OldestXmin))
+						{
+							all_visible = false;
+							break;
+						}
+					}
+
+					/* Track newest xmin on page. */
+					if (TransactionIdFollows(xid, visibility_cutoff_xid))
+						visibility_cutoff_xid = xid;
+					break;
+				case ZHEAPTUPLE_RECENTLY_DEAD:
+
+					/*
+					 * If tuple is recently deleted then we must not remove it
+					 * from relation.
+					 */
+					nkeep += 1;
+					all_visible = false;
+					break;
+				case ZHEAPTUPLE_INSERT_IN_PROGRESS:
+				case ZHEAPTUPLE_DELETE_IN_PROGRESS:
+					/* This is an expected case during concurrent vacuum */
+					all_visible = false;
+					break;
+				case ZHEAPTUPLE_ABORT_IN_PROGRESS:
+
+					/*
+					 * We can simply skip the tuple if it has
+					 * inserted/operated by some aborted transaction and its
+					 * rollback is still pending. It'll be taken care of by
+					 * future vacuum calls.
+					 */
+					all_visible = false;
+					break;
+				default:
+					elog(ERROR, "unexpected ZHeapTupleSatisfiesOldestXmin result");
+					break;
+			}
+
+			if (tupgone)
+			{
+				lazy_record_dead_tuple(vacrelstats, &(tuple.t_self));
+				ZHeapTupleHeaderAdvanceLatestRemovedXid(tuple.t_data, xid,
+														&vacrelstats->latestRemovedXid);
+				tups_vacuumed += 1;
+				has_dead_tuples = true;
+			}
+			else
+			{
+				num_tuples += 1;
+				hastup = true;
+			}
+		}						/* scan along page */
+
+		/*
+		 * If there are no indexes then we can vacuum the page right now
+		 * instead of doing a second scan.
+		 */
+		if (vacrelstats->num_dead_tuples > 0)
+		{
+			if (nindexes == 0)
+			{
+				/* Remove tuples from zheap */
+				tupindex = lazy_vacuum_zpage(onerel, blkno, buf, tupindex,
+											 vacrelstats, &vmbuffer);
+				has_dead_tuples = false;
+
+				/*
+				 * Forget the now-vacuumed tuples, and press on, but be
+				 * careful not to reset latestRemovedXid since we want that
+				 * value to be valid.
+				 */
+				vacrelstats->num_dead_tuples = 0;
+				tupindex = 0;
+				vacuumed_pages++;
+
+				/*
+				 * Periodically do incremental FSM vacuuming to make
+				 * newly-freed space visible on upper FSM pages.  Note:
+				 * although we've cleaned the current block, we haven't yet
+				 * updated its FSM entry (that happens further down), so
+				 * passing end == blkno is correct.
+				 */
+				if (blkno - next_fsm_block_to_vacuum >= VACUUM_FSM_EVERY_PAGES)
+				{
+					FreeSpaceMapVacuumRange(onerel, next_fsm_block_to_vacuum,
+											blkno);
+					next_fsm_block_to_vacuum = blkno;
+				}
+			}
+			else
+			{
+				Assert(nindexes > 0);
+
+				/* Remove tuples from zheap and write the undo for it. */
+				tupindex = lazy_vacuum_zpage_with_undo(onerel, blkno, buf,
+													   tupindex, vacrelstats,
+													   &vmbuffer,
+													   &visibility_cutoff_xid);
+			}
+		}
+
+		/* Now that we are done with the page, get its available space */
+		freespace = PageGetZHeapFreeSpace(page);
+
+		/* mark page all-visible, if appropriate */
+		if (all_visible && !all_visible_according_to_vm)
+		{
+			uint8		flags = VISIBILITYMAP_ALL_VISIBLE;
+
+			visibilitymap_set(onerel, blkno, buf, InvalidXLogRecPtr,
+							  vmbuffer, visibility_cutoff_xid, flags);
+		}
+		else if (has_dead_tuples && all_visible_according_to_vm)
+		{
+			visibilitymap_clear(onerel, blkno, vmbuffer,
+								VISIBILITYMAP_VALID_BITS);
+		}
+
+		UnlockReleaseBuffer(buf);
+
+		/* Remember the location of the last page with non-removable tuples */
+		if (hastup)
+			vacrelstats->nonempty_pages = blkno + 1;
+
+		/* We're done with this page, so remember its free space as-is. */
+		if (freespace)
+			RecordPageWithFreeSpace(onerel, blkno, freespace);
+	}
+
+	/* Report that everything is scanned and vacuumed. */
+	pgstat_progress_update_param(PROGRESS_VACUUM_HEAP_BLKS_SCANNED, blkno - 1);
+	pgstat_progress_update_param(PROGRESS_VACUUM_HEAP_BLKS_VACUUMED, blkno - 1);
+
+	/* save stats for use later */
+	vacrelstats->tuples_deleted = tups_vacuumed;
+	vacrelstats->new_dead_tuples = nkeep;
+
+	/*
+	 * Now we can compute the new value for pg_class.reltuples.  To compensate
+	 * for metapage pass one less than the actual nblocks.
+	 */
+	vacrelstats->new_rel_tuples = vac_estimate_reltuples(onerel,
+														 nblocks - 1,
+														 vacrelstats->tupcount_pages,
+														 num_tuples);
+
+	/*
+	 * Release any remaining pin on visibility map page.
+	 */
+	if (BufferIsValid(vmbuffer))
+	{
+		ReleaseBuffer(vmbuffer);
+		vmbuffer = InvalidBuffer;
+	}
+
+	if (vacrelstats->num_dead_tuples > 0)
+	{
+		/* Report that we are now vacuuming indexes. */
+		pgstat_progress_update_param(PROGRESS_VACUUM_PHASE,
+									 PROGRESS_VACUUM_PHASE_VACUUM_INDEX);
+
+		/*
+		 * Remove index entries.  Unlike, heap we don't need to log special
+		 * cleanup info which includes latest latestRemovedXid for standby.
+		 * This is because we have covered all the dead tuples in the first
+		 * pass itself and we don't need another pass on heap after index.
+		 */
+		for (i = 0; i < nindexes; i++)
+			lazy_vacuum_index(Irel[i],
+							  &indstats[i],
+							  vacrelstats,
+							  vac_strategy,
+							  elevel);
+
+		pgstat_progress_update_param(PROGRESS_VACUUM_NUM_INDEX_VACUUMS,
+									 vacrelstats->num_index_scans + 1);
+
+		/*
+		 * XXX - The cutoff xid used here is the highest xmin of all the heap
+		 * pages scanned.  This can lead to more query cancellations on
+		 * standby.  However, alternative is that we track cutoff_xid for each
+		 * page in first-pass of vacuum and then use it after removing index
+		 * entries.  We didn't pursue the alternative because it would require
+		 * more work memory which means it can lead to more index passes.
+		 */
+		MarkPagesAsAllVisible(onerel, vacrelstats, visibility_cutoff_xid);
+
+		vacrelstats->num_index_scans++;
+
+		/*
+		 * Vacuum the Free Space Map to make newly-freed space visible on
+		 * upper-level FSM pages.
+		 */
+		FreeSpaceMapVacuumRange(onerel, next_fsm_block_to_vacuum, blkno);
+		next_fsm_block_to_vacuum = blkno;
+	}
+
+	/*
+	 * Vacuum the remainder of the Free Space Map.  We must do this whether or
+	 * not there were indexes.
+	 */
+	if (blkno > next_fsm_block_to_vacuum)
+		FreeSpaceMapVacuumRange(onerel, next_fsm_block_to_vacuum, blkno);
+
+	/* Report that we're cleaning up. */
+	pgstat_progress_update_param(PROGRESS_VACUUM_PHASE,
+								 PROGRESS_VACUUM_PHASE_INDEX_CLEANUP);
+
+	/* Do post-vacuum cleanup and statistics update for each index */
+	for (i = 0; i < nindexes; i++)
+		lazy_cleanup_index(Irel[i], indstats[i], vacrelstats, vac_strategy,
+						   elevel);
+
+	/*
+	 * This is pretty messy, but we split it up so that we can skip emitting
+	 * individual parts of the message when not applicable.
+	 */
+	initStringInfo(&infobuf);
+	appendStringInfo(&infobuf,
+					 _("%.0f dead row versions cannot be removed yet, oldest xmin: %u\n"),
+					 nkeep, OldestXmin);
+	appendStringInfo(&infobuf, _("There were %.0f unused item pointers.\n"),
+					 nunused);
+	appendStringInfo(&infobuf, ngettext("%u page is entirely empty.\n",
+										"%u pages are entirely empty.\n",
+										empty_pages),
+					 empty_pages);
+	appendStringInfo(&infobuf, _("%s."), pg_rusage_show(&ru0));
+
+	ereport(elevel,
+			(errmsg("\"%s\": found %.0f removable, %.0f nonremovable row versions in %u out of %u pages",
+					RelationGetRelationName(onerel),
+					tups_vacuumed, num_tuples,
+					vacrelstats->scanned_pages, nblocks),
+			 errdetail_internal("%s", infobuf.data)));
+	pfree(infobuf.data);
+}
+
+/*
+ *	lazy_vacuum_zheap_rel() -- perform LAZY VACUUM for one zheap relation
+ */
+void
+lazy_vacuum_zheap_rel(Relation onerel, VacuumParams *params,
+					  BufferAccessStrategy bstrategy)
+{
+	LVRelStats *vacrelstats;
+	Relation   *Irel;
+	int			nindexes;
+	PGRUsage	ru0;
+	TimestampTz starttime = 0;
+	long		secs;
+	int			usecs;
+	double		read_rate,
+				write_rate;
+	bool		aggressive = false; /* should we scan all unfrozen pages? */
+	BlockNumber new_rel_pages;
+	double		new_rel_tuples;
+	double		new_live_tuples;
+
+	Assert(params != NULL);
+
+	/*
+	 * For zheap, since vacuum process also reserves transaction slot in page,
+	 * other backend can't ignore this while calculating
+	 * OldestXmin/RecentXmin.  See GetSnapshotData for details.
+	 */
+	LWLockAcquire(ProcArrayLock, LW_EXCLUSIVE);
+	MyPgXact->vacuumFlags &= ~PROC_IN_VACUUM;
+	LWLockRelease(ProcArrayLock);
+
+	/* measure elapsed time iff autovacuum logging requires it */
+	if (IsAutoVacuumWorkerProcess() && params->log_min_duration >= 0)
+	{
+		pg_rusage_init(&ru0);
+		starttime = GetCurrentTimestamp();
+	}
+
+	if (params->options & VACOPT_VERBOSE)
+		elevel = INFO;
+	else
+		elevel = DEBUG2;
+
+	pgstat_progress_start_command(PROGRESS_COMMAND_VACUUM,
+								  RelationGetRelid(onerel));
+
+	vac_strategy = bstrategy;
+
+	/*
+	 * We can't ignore processes running lazy vacuum on zheap relations
+	 * because like other backends operating on zheap, lazy vacuum also
+	 * reserves a transaction slot in the page for pruning purpose.
+	 */
+	OldestXmin = GetOldestXmin(onerel, PROCARRAY_FLAGS_DEFAULT);
+
+	Assert(TransactionIdIsNormal(OldestXmin));
+
+	/*
+	 * We request an aggressive scan if DISABLE_PAGE_SKIPPING was specified.
+	 */
+	if (params->options & VACOPT_DISABLE_PAGE_SKIPPING)
+		aggressive = true;
+
+	vacrelstats = (LVRelStats *) palloc0(sizeof(LVRelStats));
+
+	vacrelstats->old_rel_pages = onerel->rd_rel->relpages;
+	vacrelstats->old_live_tuples = onerel->rd_rel->reltuples;
+	vacrelstats->num_index_scans = 0;
+	vacrelstats->pages_removed = 0;
+	vacrelstats->lock_waiter_detected = false;
+
+	/* Open all indexes of the relation */
+	vac_open_indexes(onerel, RowExclusiveLock, &nindexes, &Irel);
+	vacrelstats->useindex = (nindexes > 0 &&
+							 params->index_cleanup == VACOPT_TERNARY_ENABLED);
+
+	/* Do the vacuuming */
+	lazy_scan_zheap(onerel, params, vacrelstats, Irel, nindexes,
+					vac_strategy, aggressive);
+
+	/* Done with indexes */
+	vac_close_indexes(nindexes, Irel, NoLock);
+
+	/*
+	 * Optionally truncate the relation.
+	 */
+	if (should_attempt_truncation(params, vacrelstats))
+		lazy_truncate_heap(onerel, vacrelstats, vac_strategy, elevel);
+
+	/* Report that we are now doing final cleanup. */
+	pgstat_progress_update_param(PROGRESS_VACUUM_PHASE,
+								 PROGRESS_VACUUM_PHASE_FINAL_CLEANUP);
+
+	/*
+	 * Update statistics in pg_class.
+	 *
+	 * A corner case here is that if we scanned no pages at all because every
+	 * page is all-visible, we should not update relpages/reltuples, because
+	 * we have no new information to contribute.  In particular this keeps us
+	 * from replacing relpages=reltuples=0 (which means "unknown tuple
+	 * density") with nonzero relpages and reltuples=0 (which means "zero
+	 * tuple density") unless there's some actual evidence for the latter.
+	 *
+	 * We can use either tupcount_pages or scanned_pages for the check
+	 * described above as both the values should be same.  However, we use
+	 * earlier so as to be consistent with heap.
+	 *
+	 * Fixme: We do need to update relallvisible as in heap once we start
+	 * using visibilitymap or something equivalent to it.
+	 *
+	 * relfrozenxid/relminmxid are invalid as we don't perform freeze
+	 * operation in zheap.
+	 */
+	new_rel_pages = vacrelstats->rel_pages;
+	new_rel_tuples = vacrelstats->new_rel_tuples;
+	if (vacrelstats->tupcount_pages == 0 && new_rel_pages > 0)
+	{
+		new_rel_pages = vacrelstats->old_rel_pages;
+		new_rel_tuples = vacrelstats->old_live_tuples;
+	}
+
+	vac_update_relstats(onerel,
+						new_rel_pages,
+						new_rel_tuples,
+						new_rel_pages,
+						nindexes > 0,
+						InvalidTransactionId,
+						InvalidMultiXactId,
+						false);
+
+	/* report results to the stats collector, too */
+	new_live_tuples = new_rel_tuples - vacrelstats->new_dead_tuples;
+	if (new_live_tuples < 0)
+		new_live_tuples = 0;	/* just in case */
+
+	pgstat_report_vacuum(RelationGetRelid(onerel),
+						 onerel->rd_rel->relisshared,
+						 new_live_tuples,
+						 vacrelstats->new_dead_tuples);
+
+	pgstat_progress_end_command();
+
+	/* and log the action if appropriate */
+	if (IsAutoVacuumWorkerProcess() && params->log_min_duration >= 0)
+	{
+		TimestampTz endtime = GetCurrentTimestamp();
+
+		if (params->log_min_duration == 0 ||
+			TimestampDifferenceExceeds(starttime, endtime,
+									   params->log_min_duration))
+		{
+			StringInfoData buf;
+			char	   *msgfmt;
+
+			TimestampDifference(starttime, endtime, &secs, &usecs);
+
+			read_rate = 0;
+			write_rate = 0;
+			if ((secs > 0) || (usecs > 0))
+			{
+				read_rate = (double) BLCKSZ * VacuumPageMiss / (1024 * 1024) /
+					(secs + usecs / 1000000.0);
+				write_rate = (double) BLCKSZ * VacuumPageDirty / (1024 * 1024) /
+					(secs + usecs / 1000000.0);
+			}
+
+			/*
+			 * This is pretty messy, but we split it up so that we can skip
+			 * emitting individual parts of the message when not applicable.
+			 */
+			initStringInfo(&buf);
+			if (aggressive)
+				msgfmt = _("automatic aggressive vacuum of table \"%s.%s.%s\": index scans: %d\n");
+			else
+				msgfmt = _("automatic vacuum of table \"%s.%s.%s\": index scans: %d\n");
+			appendStringInfo(&buf, msgfmt,
+							 get_database_name(MyDatabaseId),
+							 get_namespace_name(RelationGetNamespace(onerel)),
+							 RelationGetRelationName(onerel),
+							 vacrelstats->num_index_scans);
+			appendStringInfo(&buf, _("pages: %u removed, %u remain\n"),
+							 vacrelstats->pages_removed,
+							 vacrelstats->rel_pages);
+			appendStringInfo(&buf,
+							 _("tuples: %.0f removed, %.0f remain, %.0f are dead but not yet removable, oldest xmin: %u\n"),
+							 vacrelstats->tuples_deleted,
+							 vacrelstats->new_rel_tuples,
+							 vacrelstats->new_dead_tuples,
+							 OldestXmin);
+			appendStringInfo(&buf,
+							 _("buffer usage: %d hits, %d misses, %d dirtied\n"),
+							 VacuumPageHit,
+							 VacuumPageMiss,
+							 VacuumPageDirty);
+			appendStringInfo(&buf, _("avg read rate: %.3f MB/s, avg write rate: %.3f MB/s\n"),
+							 read_rate, write_rate);
+			appendStringInfo(&buf, _("system usage: %s"), pg_rusage_show(&ru0));
+
+			ereport(LOG,
+					(errmsg_internal("%s", buf.data)));
+			pfree(buf.data);
+		}
+	}
+}
+
+/*
+ * lazy_space_zalloc - space allocation decisions for lazy vacuum
+ *
+ * See the comments at the head of this file for rationale.
+ */
+static void
+lazy_space_zalloc(LVRelStats *vacrelstats, BlockNumber relblocks)
+{
+	long		maxtuples;
+	int			vac_work_mem = IsAutoVacuumWorkerProcess() &&
+	autovacuum_work_mem != -1 ?
+	autovacuum_work_mem : maintenance_work_mem;
+
+	if (vacrelstats->useindex)
+	{
+		maxtuples = (vac_work_mem * 1024L) / sizeof(ItemPointerData);
+		maxtuples = Min(maxtuples, INT_MAX);
+		maxtuples = Min(maxtuples, MaxAllocSize / sizeof(ItemPointerData));
+
+		/* curious coding here to ensure the multiplication can't overflow */
+		if ((BlockNumber) (maxtuples / LAZY_ALLOC_TUPLES) > relblocks)
+			maxtuples = relblocks * LAZY_ALLOC_TUPLES;
+
+		/* stay sane if small maintenance_work_mem */
+		maxtuples = Max(maxtuples, MaxZHeapTuplesPerPage);
+	}
+	else
+	{
+		maxtuples = MaxZHeapTuplesPerPage;
+	}
+
+	vacrelstats->num_dead_tuples = 0;
+	vacrelstats->max_dead_tuples = (int) maxtuples;
+	vacrelstats->dead_tuples = (ItemPointer)
+		palloc(maxtuples * sizeof(ItemPointerData));
+}
+
+/*
+ * Check if every tuple in the given page is visible to all current and future
+ * transactions. Also return the visibility_cutoff_xid which is the highest
+ * xmin amongst the visible tuples.
+ */
+static bool
+zheap_page_is_all_visible(Relation rel, Buffer buf,
+						  TransactionId *visibility_cutoff_xid)
+{
+	Page		page = BufferGetPage(buf);
+	BlockNumber blockno = BufferGetBlockNumber(buf);
+	OffsetNumber offnum,
+				maxoff;
+	bool		all_visible = true;
+
+	*visibility_cutoff_xid = InvalidTransactionId;
+
+	/*
+	 * This is a stripped down version of the line pointer scan in
+	 * lazy_scan_zheap(). So if you change anything here, also check that
+	 * code.
+	 */
+	maxoff = PageGetMaxOffsetNumber(page);
+	for (offnum = FirstOffsetNumber;
+		 offnum <= maxoff && all_visible;
+		 offnum = OffsetNumberNext(offnum))
+	{
+		ItemId		itemid;
+		TransactionId xid;
+		ZHeapTupleData tuple;
+
+		itemid = PageGetItemId(page, offnum);
+
+		/* Unused or redirect line pointers are of no interest */
+		if (!ItemIdIsUsed(itemid) || ItemIdIsRedirected(itemid))
+			continue;
+
+		ItemPointerSet(&(tuple.t_self), blockno, offnum);
+
+		/*
+		 * Dead line pointers can have index pointers pointing to them. So
+		 * they can't be treated as visible
+		 */
+		if (ItemIdIsDead(itemid))
+		{
+			all_visible = false;
+			break;
+		}
+
+		Assert(ItemIdIsNormal(itemid));
+
+		tuple.t_data = (ZHeapTupleHeader) PageGetItem(page, itemid);
+		tuple.t_len = ItemIdGetLength(itemid);
+		tuple.t_tableOid = RelationGetRelid(rel);
+
+		switch (ZHeapTupleSatisfiesOldestXmin(&tuple, OldestXmin, buf,
+											  false, NULL, &xid, NULL))
+		{
+			case ZHEAPTUPLE_LIVE:
+				{
+					/*
+					 * The inserter definitely committed. But is it old enough
+					 * that everyone sees it as committed?
+					 */
+					if (!TransactionIdPrecedes(xid, OldestXmin))
+					{
+						all_visible = false;
+						break;
+					}
+
+					/* Track newest xmin on page. */
+					if (TransactionIdFollows(xid, *visibility_cutoff_xid))
+						*visibility_cutoff_xid = xid;
+				}
+				break;
+
+			case ZHEAPTUPLE_DEAD:
+			case ZHEAPTUPLE_RECENTLY_DEAD:
+			case ZHEAPTUPLE_INSERT_IN_PROGRESS:
+			case ZHEAPTUPLE_DELETE_IN_PROGRESS:
+			case ZHEAPTUPLE_ABORT_IN_PROGRESS:
+				{
+					all_visible = false;
+					break;
+				}
+			default:
+				elog(ERROR, "unexpected ZHeapTupleSatisfiesOldestXmin result");
+				break;
+		}
+	}							/* scan along page */
+
+	return all_visible;
+}
diff --git a/src/backend/catalog/storage.c b/src/backend/catalog/storage.c
index 3cc886f..7d9b868 100644
--- a/src/backend/catalog/storage.c
+++ b/src/backend/catalog/storage.c
@@ -26,6 +26,8 @@
 #include "access/xlog.h"
 #include "access/xloginsert.h"
 #include "access/xlogutils.h"
+#include "access/tableam.h"
+#include "access/zheap.h"
 #include "catalog/storage.h"
 #include "catalog/storage_xlog.h"
 #include "storage/freespace.h"
diff --git a/src/backend/commands/tablecmds.c b/src/backend/commands/tablecmds.c
index c610be2..5fc3a7c 100644
--- a/src/backend/commands/tablecmds.c
+++ b/src/backend/commands/tablecmds.c
@@ -21,6 +21,7 @@
 #include "access/reloptions.h"
 #include "access/relscan.h"
 #include "access/tableam.h"
+#include "access/tpd.h"
 #include "access/sysattr.h"
 #include "access/tableam.h"
 #include "access/tupconvert.h"
diff --git a/src/backend/commands/tablespace.c b/src/backend/commands/tablespace.c
index 17c28b2..15e011b 100644
--- a/src/backend/commands/tablespace.c
+++ b/src/backend/commands/tablespace.c
@@ -512,6 +512,20 @@ DropTableSpace(DropTableSpaceStmt *stmt)
 						tablespacename)));
 
 	/*
+	 * Drop the undo logs in this tablespace.  This will fail (without
+	 * dropping anything) if there are undo logs that we can't afford to drop
+	 * because they contain non-discarded data or a transaction is in
+	 * progress.  Since we hold TablespaceCreateLock, no other session will be
+	 * able to attach to an undo log in this tablespace (or any tablespace
+	 * except default) concurrently.
+	 */
+	if (!DropUndoLogsInTablespace(tablespaceoid))
+		ereport(ERROR,
+				(errcode(ERRCODE_OBJECT_NOT_IN_PREREQUISITE_STATE),
+				 errmsg("tablespace \"%s\" cannot be dropped because it contains non-empty undo logs",
+						tablespacename)));
+
+	/*
 	 * Try to remove the physical infrastructure.
 	 */
 	if (!destroy_tablespace_directories(tablespaceoid, false))
@@ -1540,6 +1554,14 @@ tblspc_redo(XLogReaderState *record)
 					 errmsg("tablespace cannot be dropped because it contains non-empty undo logs")));
 		LWLockRelease(TablespaceCreateLock);
 
+		/* This shouldn't be able to fail in recovery. */
+		LWLockAcquire(TablespaceCreateLock, LW_EXCLUSIVE);
+		if (!DropUndoLogsInTablespace(xlrec->ts_id))
+			ereport(ERROR,
+					(errcode(ERRCODE_OBJECT_NOT_IN_PREREQUISITE_STATE),
+					 errmsg("tablespace cannot be dropped because it contains non-empty undo logs")));
+		LWLockRelease(TablespaceCreateLock);
+
 		/*
 		 * If we issued a WAL record for a drop tablespace it implies that
 		 * there were no files in it at all when the DROP was done. That means
diff --git a/src/backend/commands/vacuum.c b/src/backend/commands/vacuum.c
index e7b379d..e4705d1 100644
--- a/src/backend/commands/vacuum.c
+++ b/src/backend/commands/vacuum.c
@@ -1461,6 +1461,7 @@ vac_truncate_clog(TransactionId frozenXID,
 				  MultiXactId lastSaneMinMulti)
 {
 	TransactionId nextXID = ReadNewTransactionId();
+	TransactionId oldestXidHavingUndo;
 	Relation	relation;
 	TableScanDesc scan;
 	HeapTuple	tuple;
@@ -1555,6 +1556,16 @@ vac_truncate_clog(TransactionId frozenXID,
 		return;
 
 	/*
+	 * We can't truncate the clog for transactions that still have undo.  The
+	 * oldestXidHavingUndo will be only valid for zheap storage engine, so it
+	 * won't impact any other storage engine.
+	 */
+	oldestXidHavingUndo = GetXidFromEpochXid(
+											 pg_atomic_read_u64(&ProcGlobal->oldestFullXidHavingUnappliedUndo));
+	if (TransactionIdIsValid(oldestXidHavingUndo))
+		frozenXID = Min(frozenXID, oldestXidHavingUndo);
+
+	/*
 	 * Advance the oldest value for commit timestamps before truncating, so
 	 * that if a user requests a timestamp for a transaction we're truncating
 	 * away right after this point, they get NULL instead of an ugly "file not
diff --git a/src/backend/executor/execIndexing.c b/src/backend/executor/execIndexing.c
index 40bd804..8797c74 100644
--- a/src/backend/executor/execIndexing.c
+++ b/src/backend/executor/execIndexing.c
@@ -92,7 +92,7 @@
  * To avoid the livelock, one of the backends must back out first, and then
  * wait, while the other one waits without backing out.  It doesn't matter
  * which one backs out, so we employ an arbitrary rule that the transaction
- * with the higher XID backs out.
+ * with the higher top XID backs out.
  *
  *
  * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
@@ -108,6 +108,7 @@
 
 #include "access/genam.h"
 #include "access/relscan.h"
+#include "access/subtrans.h"
 #include "access/tableam.h"
 #include "access/xact.h"
 #include "catalog/index.h"
@@ -730,7 +731,8 @@ retry:
 
 	while (index_getnext_slot(index_scan, ForwardScanDirection, existing_slot))
 	{
-		TransactionId xwait;
+		TransactionId xwait,
+					xid;
 		XLTW_Oper	reason_wait;
 		Datum		existing_values[INDEX_MAX_KEYS];
 		bool		existing_isnull[INDEX_MAX_KEYS];
@@ -782,18 +784,31 @@ retry:
 		xwait = TransactionIdIsValid(DirtySnapshot.xmin) ?
 			DirtySnapshot.xmin : DirtySnapshot.xmax;
 
+		/*
+		 * When a speculative insertion conflict is detected among two
+		 * in-progress transactions, one of the backends must back out first,
+		 * and then wait, while the other one waits without backing out.  It
+		 * doesn't matter which one backs out, so we employ an arbitrary rule
+		 * that the transaction with the higher top XID backs out. (See notes
+		 * in file header)
+		 */
+		xid = GetTopTransactionId();
+
 		if (TransactionIdIsValid(xwait) &&
 			(waitMode == CEOUC_WAIT ||
 			 (waitMode == CEOUC_LIVELOCK_PREVENTING_WAIT &&
 			  DirtySnapshot.speculativeToken &&
-			  TransactionIdPrecedes(GetCurrentTransactionId(), xwait))))
+			  TransactionIdPrecedes(xid, SubTransGetTopmostTransaction(xwait)))))
 		{
 			reason_wait = indexInfo->ii_ExclusionOps ?
 				XLTW_RecheckExclusionConstr : XLTW_InsertIndex;
 			index_endscan(index_scan);
 			if (DirtySnapshot.speculativeToken)
-				SpeculativeInsertionWait(DirtySnapshot.xmin,
+				SpeculativeInsertionWait(SubTransGetTopmostTransaction(DirtySnapshot.xmin),
 										 DirtySnapshot.speculativeToken);
+			else if (DirtySnapshot.subxid != InvalidSubTransactionId)
+				SubXactLockTableWait(xwait, DirtySnapshot.subxid, heap,
+									 &existing_slot->tts_tid, reason_wait);
 			else
 				XactLockTableWait(xwait, heap,
 								  &existing_slot->tts_tid, reason_wait);
diff --git a/src/backend/executor/execTuples.c b/src/backend/executor/execTuples.c
index 5ee2a46..ebcf634 100644
--- a/src/backend/executor/execTuples.c
+++ b/src/backend/executor/execTuples.c
@@ -985,7 +985,10 @@ slot_deform_heap_tuple(TupleTableSlot *slot, HeapTuple tuple, uint32 *offp,
 		slot->tts_flags &= ~TTS_FLAG_SLOW;
 }
 
-
+/*
+ * TupleTableSlotOps for each of TupleTableSlotTypes. These are used to
+ * identify the type of slot.
+ */
 const TupleTableSlotOps TTSOpsVirtual = {
 	.base_slot_size = sizeof(VirtualTupleTableSlot),
 	.init = tts_virtual_init,
@@ -1057,7 +1060,6 @@ const TupleTableSlotOps TTSOpsBufferHeapTuple = {
 	.copy_minimal_tuple = tts_buffer_heap_copy_minimal_tuple
 };
 
-
 /* ----------------------------------------------------------------
  *				  tuple table create/delete functions
  * ----------------------------------------------------------------
diff --git a/src/backend/executor/nodeModifyTable.c b/src/backend/executor/nodeModifyTable.c
index d8b695d..38d5600 100644
--- a/src/backend/executor/nodeModifyTable.c
+++ b/src/backend/executor/nodeModifyTable.c
@@ -540,8 +540,14 @@ ExecInsert(ModifyTableState *mtstate,
 			 * insertion lock".  Others can use that to wait for us to decide
 			 * if we're going to go ahead with the insertion, instead of
 			 * waiting for the whole transaction to complete.
+			 *
+			 * In this case, we use top transaction id to create the
+			 * speculative lock tag to make it generic across different
+			 * storage engine.  When encountering a conflict, we should use
+			 * SubTransGetTopmostTransaction() to determine the xid on which
+			 * we should wait.
 			 */
-			specToken = SpeculativeInsertionLockAcquire(GetCurrentTransactionId());
+			specToken = SpeculativeInsertionLockAcquire(GetTopTransactionId());
 
 			/* insert the tuple, with the speculative token */
 			table_tuple_insert_speculative(resultRelationDesc, slot,
@@ -562,11 +568,11 @@ ExecInsert(ModifyTableState *mtstate,
 			/*
 			 * Wake up anyone waiting for our decision.  They will re-check
 			 * the tuple, see that it's no longer speculative, and wait on our
-			 * XID as if this was a regularly inserted tuple all along.  Or if
-			 * we killed the tuple, they will see it's dead, and proceed as if
-			 * the tuple never existed.
+			 * top XID as if this was a regularly inserted tuple all along. Or
+			 * if we killed the tuple, they will see it's dead, and proceed as
+			 * if the tuple never existed.
 			 */
-			SpeculativeInsertionLockRelease(GetCurrentTransactionId());
+			SpeculativeInsertionLockRelease(GetTopTransactionId());
 
 			/*
 			 * If there was a conflict, start from the beginning.  We'll do
@@ -836,7 +842,7 @@ ldelete:;
 											  estate->es_snapshot,
 											  inputslot, estate->es_output_cid,
 											  LockTupleExclusive, LockWaitBlock,
-											  TUPLE_LOCK_FLAG_FIND_LAST_VERSION,
+											  TUPLE_LOCK_FLAG_FIND_LAST_VERSION | TUPLE_LOCK_FLAG_WEIRD,
 											  &tmfd);
 
 					switch (result)
@@ -1378,7 +1384,7 @@ lreplace:;
 											  estate->es_snapshot,
 											  inputslot, estate->es_output_cid,
 											  lockmode, LockWaitBlock,
-											  TUPLE_LOCK_FLAG_FIND_LAST_VERSION,
+											  TUPLE_LOCK_FLAG_FIND_LAST_VERSION | TUPLE_LOCK_FLAG_WEIRD,
 											  &tmfd);
 
 					switch (result)
@@ -1526,7 +1532,7 @@ ExecOnConflictUpdate(ModifyTableState *mtstate,
 	test = table_tuple_lock(relation, conflictTid,
 							estate->es_snapshot,
 							existing, estate->es_output_cid,
-							lockmode, LockWaitBlock, 0,
+							lockmode, LockWaitBlock, TUPLE_LOCK_FLAG_WEIRD,
 							&tmfd);
 	switch (test)
 	{
@@ -1569,6 +1575,16 @@ ExecOnConflictUpdate(ModifyTableState *mtstate,
 			break;
 
 		case TM_SelfModified:
+#ifdef ZBORKED
+
+			/*
+			 * ZHEAP accepts this, but this isn't ok from a layering POV (and
+			 * I'm doubtful about the correctness). See 1e9d17cc240.
+			 *
+			 * Unlike heap, we expect TM_SelfModified in the same scenario as
+			 * the new tuple could have been in-place updated.
+			 */
+#endif
 
 			/*
 			 * This state should never be reached. As a dirty snapshot is used
diff --git a/src/backend/lib/binaryheap.c b/src/backend/lib/binaryheap.c
index 5f7454d..6a41f2b 100644
--- a/src/backend/lib/binaryheap.c
+++ b/src/backend/lib/binaryheap.c
@@ -194,61 +194,12 @@ binaryheap_first(binaryheap *heap)
 }
 
 /*
- * binaryheap_remove_first
- *
- * Removes the first (root, topmost) node in the heap and returns a
- * pointer to it after rebalancing the heap. The caller must ensure
- * that this routine is not used on an empty heap. O(log n) worst
- * case.
- */
-Datum
-binaryheap_remove_first(binaryheap *heap)
-{
-	Assert(!binaryheap_empty(heap) && heap->bh_has_heap_property);
-
-	if (heap->bh_size == 1)
-	{
-		heap->bh_size--;
-		return heap->bh_nodes[0];
-	}
-
-	/*
-	 * Swap the root and last nodes, decrease the size of the heap (i.e.
-	 * remove the former root node) and sift the new root node down to its
-	 * correct position.
-	 */
-	swap_nodes(heap, 0, heap->bh_size - 1);
-	heap->bh_size--;
-	sift_down(heap, 0);
-
-	return heap->bh_nodes[heap->bh_size];
-}
-
-/*
- * binaryheap_replace_first
- *
- * Replace the topmost element of a non-empty heap, preserving the heap
- * property.  O(1) in the best case, or O(log n) if it must fall back to
- * sifting the new node down.
- */
-void
-binaryheap_replace_first(binaryheap *heap, Datum d)
-{
-	Assert(!binaryheap_empty(heap) && heap->bh_has_heap_property);
-
-	heap->bh_nodes[0] = d;
-
-	if (heap->bh_size > 1)
-		sift_down(heap, 0);
-}
-
-/*
  * binaryheap_nth
  *
  * Returns a pointer to the nth (0-based) node in the heap without modifying
- * the heap in O(1).  The caller must ensure that this routine is not used on
- * an empty heap and is not called with n greater than or equal to the heap
- * size.
+ * the heap. The caller must ensure that this routine is not used on an empty
+ * heap and is not called with n greater than or equal to the heap size. Always
+ * O(1).
  */
 Datum
 binaryheap_nth(binaryheap *heap, int n)
@@ -263,7 +214,7 @@ binaryheap_nth(binaryheap *heap, int n)
  *
  * Removes the nth node (0-based) in the heap and returns a
  * pointer to it after rebalancing the heap. The caller must ensure
- * that this routine is not used on an empty heap.  O(log n) worst
+ * that this routine is not used on an empty heap. O(log n) worst
  * case.
  */
 Datum
@@ -289,11 +240,11 @@ binaryheap_remove_nth(binaryheap *heap, int n)
 /*
  * binaryheap_remove_nth_unordered
  *
- * Removes the nth node (0-based) in the heap and returns a pointer to it in
- * O(1) without preserving the heap property.  This is a convenience routine
- * to remove elements quickly.  To obtain a valid heap, one must call
- * binaryheap_build() afterwards.  The caller must ensure that this routine is
- * not used on an empty heap.
+ * Removes the nth node (0-based) in the heap and returns a pointer
+ * to it in O(1) without preserving the heap property. This is a
+ * convenience to remove elements quickly. To obtain a valid heap,
+ * one must call binaryheap_build() afterwards. The caller must ensure
+ * that this routine is not used on an empty heap.
  */
 Datum
 binaryheap_remove_nth_unordered(binaryheap *heap, int n)
@@ -316,6 +267,55 @@ binaryheap_remove_nth_unordered(binaryheap *heap, int n)
 }
 
 /*
+ * binaryheap_remove_first
+ *
+ * Removes the first (root, topmost) node in the heap and returns a
+ * pointer to it after rebalancing the heap. The caller must ensure
+ * that this routine is not used on an empty heap. O(log n) worst
+ * case.
+ */
+Datum
+binaryheap_remove_first(binaryheap *heap)
+{
+	Assert(!binaryheap_empty(heap) && heap->bh_has_heap_property);
+
+	if (heap->bh_size == 1)
+	{
+		heap->bh_size--;
+		return heap->bh_nodes[0];
+	}
+
+	/*
+	 * Swap the root and last nodes, decrease the size of the heap (i.e.
+	 * remove the former root node) and sift the new root node down to its
+	 * correct position.
+	 */
+	swap_nodes(heap, 0, heap->bh_size - 1);
+	heap->bh_size--;
+	sift_down(heap, 0);
+
+	return heap->bh_nodes[heap->bh_size];
+}
+
+/*
+ * binaryheap_replace_first
+ *
+ * Replace the topmost element of a non-empty heap, preserving the heap
+ * property.  O(1) in the best case, or O(log n) if it must fall back to
+ * sifting the new node down.
+ */
+void
+binaryheap_replace_first(binaryheap *heap, Datum d)
+{
+	Assert(!binaryheap_empty(heap) && heap->bh_has_heap_property);
+
+	heap->bh_nodes[0] = d;
+
+	if (heap->bh_size > 1)
+		sift_down(heap, 0);
+}
+
+/*
  * Swap the contents of two nodes.
  */
 static inline void
diff --git a/src/backend/lib/stringinfo.c b/src/backend/lib/stringinfo.c
index 99c83c1..a091e18 100644
--- a/src/backend/lib/stringinfo.c
+++ b/src/backend/lib/stringinfo.c
@@ -249,6 +249,38 @@ appendBinaryStringInfoNT(StringInfo str, const char *data, int datalen)
 	str->len += datalen;
 }
 
+/* appendBinaryStringInfoNoExtend
+ *
+ * Append arbitrary binary data to a StringInfo.
+ *
+ * Returns false, if more space is required to append the string, true
+ * otherwise.
+ *
+ * This can be used in critical section.
+ */
+bool
+appendBinaryStringInfoNoExtend(StringInfo str, const char *data, int datalen)
+{
+	Assert(str != NULL);
+
+	/* fail, if more space is required */
+	if (datalen > str->maxlen)
+		return false;
+
+	/* OK, append the data */
+	memcpy(str->data + str->len, data, datalen);
+	str->len += datalen;
+
+	/*
+	 * Keep a trailing null in place, even though it's probably useless for
+	 * binary data.  (Some callers are dealing with text but call this because
+	 * their input isn't null-terminated.)
+	 */
+	str->data[str->len] = '\0';
+
+	return true;
+}
+
 /*
  * enlargeStringInfo
  *
diff --git a/src/backend/nodes/tidbitmap.c b/src/backend/nodes/tidbitmap.c
index bf53459..fe03a87 100644
--- a/src/backend/nodes/tidbitmap.c
+++ b/src/backend/nodes/tidbitmap.c
@@ -41,6 +41,7 @@
 #include <limits.h>
 
 #include "access/htup_details.h"
+#include "access/zheap.h"
 #include "nodes/bitmapset.h"
 #include "nodes/tidbitmap.h"
 #include "storage/lwlock.h"
@@ -53,7 +54,7 @@
  * the per-page bitmaps variable size.  We just legislate that the size
  * is this:
  */
-#define MAX_TUPLES_PER_PAGE  MaxHeapTuplesPerPage
+#define MAX_TUPLES_PER_PAGE  Max(MaxHeapTuplesPerPage, MaxZHeapTuplesPerPage)
 
 /*
  * When we have to switch over to lossy storage, we use a data structure
diff --git a/src/backend/optimizer/util/plancat.c b/src/backend/optimizer/util/plancat.c
index 6ea625a..f126a98 100644
--- a/src/backend/optimizer/util/plancat.c
+++ b/src/backend/optimizer/util/plancat.c
@@ -976,10 +976,6 @@ estimate_rel_size(Relation rel, int32 *attr_widths,
 				*allvisfrac = 0;
 				break;
 			}
-			/* coerce values in pg_class to more desirable types */
-			relpages = (BlockNumber) rel->rd_rel->relpages;
-			reltuples = (double) rel->rd_rel->reltuples;
-			relallvisible = (BlockNumber) rel->rd_rel->relallvisible;
 
 			/*
 			 * Discount the metapage while estimating the number of tuples.
diff --git a/src/backend/postmaster/pgstat.c b/src/backend/postmaster/pgstat.c
index 4c906f6..9678f0c 100644
--- a/src/backend/postmaster/pgstat.c
+++ b/src/backend/postmaster/pgstat.c
@@ -228,9 +228,12 @@ typedef struct TwoPhasePgStatRecord
 {
 	PgStat_Counter tuples_inserted; /* tuples inserted in xact */
 	PgStat_Counter tuples_updated;	/* tuples updated in xact */
+	PgStat_Counter tuples_inplace_updated;	/* tuples inplace updated in xact */
 	PgStat_Counter tuples_deleted;	/* tuples deleted in xact */
 	PgStat_Counter inserted_pre_trunc;	/* tuples inserted prior to truncate */
 	PgStat_Counter updated_pre_trunc;	/* tuples updated prior to truncate */
+	PgStat_Counter inplace_pre_trunc;	/* tuples inplace updated prior to
+										 * truncate */
 	PgStat_Counter deleted_pre_trunc;	/* tuples deleted prior to truncate */
 	Oid			t_id;			/* table's OID */
 	bool		t_shared;		/* is it a shared catalog? */
@@ -1461,7 +1464,8 @@ pgstat_report_analyze(Relation rel,
 		for (trans = rel->pgstat_info->trans; trans; trans = trans->upper)
 		{
 			livetuples -= trans->tuples_inserted - trans->tuples_deleted;
-			deadtuples -= trans->tuples_updated + trans->tuples_deleted;
+			deadtuples -= (trans->tuples_updated - trans->tuples_inplace_updated)
+				+ trans->tuples_deleted;
 		}
 		/* count stuff inserted by already-aborted subxacts, too */
 		deadtuples -= rel->pgstat_info->t_counts.t_delta_dead_tuples;
@@ -1963,6 +1967,30 @@ pgstat_count_heap_insert(Relation rel, PgStat_Counter n)
 }
 
 /*
+ * pgstat_count_zheap_update - count a inplace ztuple update
+ */
+void
+pgstat_count_zheap_update(Relation rel)
+{
+	PgStat_TableStatus *pgstat_info = rel->pgstat_info;
+
+	if (pgstat_info != NULL)
+	{
+		/* We have to log the effect at the proper transactional level */
+		int			nest_level = GetCurrentTransactionNestLevel();
+
+		if (pgstat_info->trans == NULL ||
+			pgstat_info->trans->nest_level != nest_level)
+			add_tabstat_xact_level(pgstat_info, nest_level);
+
+		/* increase, similar to pgstat_count_heap_update */
+		pgstat_info->trans->tuples_updated++;
+
+		pgstat_info->trans->tuples_inplace_updated++;
+	}
+}
+
+/*
  * pgstat_count_heap_update - count a tuple update
  */
 void
@@ -2023,6 +2051,7 @@ pgstat_truncate_save_counters(PgStat_TableXactStatus *trans)
 	{
 		trans->inserted_pre_trunc = trans->tuples_inserted;
 		trans->updated_pre_trunc = trans->tuples_updated;
+		trans->inplace_pre_trunc = trans->tuples_inplace_updated;
 		trans->deleted_pre_trunc = trans->tuples_deleted;
 		trans->truncated = true;
 	}
@@ -2038,6 +2067,7 @@ pgstat_truncate_restore_counters(PgStat_TableXactStatus *trans)
 	{
 		trans->tuples_inserted = trans->inserted_pre_trunc;
 		trans->tuples_updated = trans->updated_pre_trunc;
+		trans->tuples_inplace_updated = trans->inplace_pre_trunc;
 		trans->tuples_deleted = trans->deleted_pre_trunc;
 	}
 }
@@ -2062,6 +2092,7 @@ pgstat_count_truncate(Relation rel)
 		pgstat_truncate_save_counters(pgstat_info->trans);
 		pgstat_info->trans->tuples_inserted = 0;
 		pgstat_info->trans->tuples_updated = 0;
+		pgstat_info->trans->tuples_inplace_updated = 0;
 		pgstat_info->trans->tuples_deleted = 0;
 	}
 }
@@ -2134,6 +2165,7 @@ AtEOXact_PgStat(bool isCommit, bool parallel)
 			/* count attempted actions regardless of commit/abort */
 			tabstat->t_counts.t_tuples_inserted += trans->tuples_inserted;
 			tabstat->t_counts.t_tuples_updated += trans->tuples_updated;
+			tabstat->t_counts.t_tuples_inplace_updated += trans->tuples_inplace_updated;
 			tabstat->t_counts.t_tuples_deleted += trans->tuples_deleted;
 			if (isCommit)
 			{
@@ -2149,7 +2181,7 @@ AtEOXact_PgStat(bool isCommit, bool parallel)
 					trans->tuples_inserted - trans->tuples_deleted;
 				/* update and delete each create a dead tuple */
 				tabstat->t_counts.t_delta_dead_tuples +=
-					trans->tuples_updated + trans->tuples_deleted;
+					(trans->tuples_updated - trans->tuples_inplace_updated) + trans->tuples_deleted;
 				/* insert, update, delete each count as one change event */
 				tabstat->t_counts.t_changed_tuples +=
 					trans->tuples_inserted + trans->tuples_updated +
@@ -2159,7 +2191,7 @@ AtEOXact_PgStat(bool isCommit, bool parallel)
 			{
 				/* inserted tuples are dead, deleted tuples are unaffected */
 				tabstat->t_counts.t_delta_dead_tuples +=
-					trans->tuples_inserted + trans->tuples_updated;
+					trans->tuples_inserted + (trans->tuples_updated - trans->tuples_inplace_updated);
 				/* an aborted xact generates no changed_tuple events */
 			}
 			tabstat->trans = NULL;
@@ -2215,12 +2247,14 @@ AtEOSubXact_PgStat(bool isCommit, int nestDepth)
 						/* replace upper xact stats with ours */
 						trans->upper->tuples_inserted = trans->tuples_inserted;
 						trans->upper->tuples_updated = trans->tuples_updated;
+						trans->upper->tuples_inplace_updated = trans->tuples_inplace_updated;
 						trans->upper->tuples_deleted = trans->tuples_deleted;
 					}
 					else
 					{
 						trans->upper->tuples_inserted += trans->tuples_inserted;
 						trans->upper->tuples_updated += trans->tuples_updated;
+						trans->upper->tuples_inplace_updated += trans->tuples_inplace_updated;
 						trans->upper->tuples_deleted += trans->tuples_deleted;
 					}
 					tabstat->trans = trans->upper;
@@ -2256,10 +2290,11 @@ AtEOSubXact_PgStat(bool isCommit, int nestDepth)
 				/* count attempted actions regardless of commit/abort */
 				tabstat->t_counts.t_tuples_inserted += trans->tuples_inserted;
 				tabstat->t_counts.t_tuples_updated += trans->tuples_updated;
+				tabstat->t_counts.t_tuples_inplace_updated += trans->tuples_inplace_updated;
 				tabstat->t_counts.t_tuples_deleted += trans->tuples_deleted;
 				/* inserted tuples are dead, deleted tuples are unaffected */
 				tabstat->t_counts.t_delta_dead_tuples +=
-					trans->tuples_inserted + trans->tuples_updated;
+					trans->tuples_inserted + (trans->tuples_updated - trans->tuples_inplace_updated);
 				tabstat->trans = trans->upper;
 				pfree(trans);
 			}
@@ -2304,6 +2339,7 @@ AtPrepare_PgStat(void)
 			record.inserted_pre_trunc = trans->inserted_pre_trunc;
 			record.updated_pre_trunc = trans->updated_pre_trunc;
 			record.deleted_pre_trunc = trans->deleted_pre_trunc;
+			record.inplace_pre_trunc = trans->inplace_pre_trunc;
 			record.t_id = tabstat->t_id;
 			record.t_shared = tabstat->t_shared;
 			record.t_truncated = trans->truncated;
@@ -2371,6 +2407,7 @@ pgstat_twophase_postcommit(TransactionId xid, uint16 info,
 	/* Same math as in AtEOXact_PgStat, commit case */
 	pgstat_info->t_counts.t_tuples_inserted += rec->tuples_inserted;
 	pgstat_info->t_counts.t_tuples_updated += rec->tuples_updated;
+	pgstat_info->t_counts.t_tuples_inplace_updated += rec->tuples_inplace_updated;
 	pgstat_info->t_counts.t_tuples_deleted += rec->tuples_deleted;
 	pgstat_info->t_counts.t_truncated = rec->t_truncated;
 	if (rec->t_truncated)
@@ -2382,7 +2419,7 @@ pgstat_twophase_postcommit(TransactionId xid, uint16 info,
 	pgstat_info->t_counts.t_delta_live_tuples +=
 		rec->tuples_inserted - rec->tuples_deleted;
 	pgstat_info->t_counts.t_delta_dead_tuples +=
-		rec->tuples_updated + rec->tuples_deleted;
+		(rec->tuples_updated - rec->tuples_inplace_updated) + rec->tuples_deleted;
 	pgstat_info->t_counts.t_changed_tuples +=
 		rec->tuples_inserted + rec->tuples_updated +
 		rec->tuples_deleted;
@@ -2409,13 +2446,14 @@ pgstat_twophase_postabort(TransactionId xid, uint16 info,
 	{
 		rec->tuples_inserted = rec->inserted_pre_trunc;
 		rec->tuples_updated = rec->updated_pre_trunc;
+		rec->tuples_inplace_updated = rec->inplace_pre_trunc;
 		rec->tuples_deleted = rec->deleted_pre_trunc;
 	}
 	pgstat_info->t_counts.t_tuples_inserted += rec->tuples_inserted;
 	pgstat_info->t_counts.t_tuples_updated += rec->tuples_updated;
 	pgstat_info->t_counts.t_tuples_deleted += rec->tuples_deleted;
 	pgstat_info->t_counts.t_delta_dead_tuples +=
-		rec->tuples_inserted + rec->tuples_updated;
+		rec->tuples_inserted + (rec->tuples_updated - rec->tuples_inplace_updated);
 }
 
 
@@ -3539,6 +3577,9 @@ pgstat_get_wait_event_type(uint32 wait_event_info)
 		case PG_WAIT_IO:
 			event_type = "IO";
 			break;
+		case PG_WAIT_PAGE_TRANS_SLOT:
+			event_type = "TransSlot";
+			break;
 		default:
 			event_type = "???";
 			break;
@@ -3616,6 +3657,9 @@ pgstat_get_wait_event(uint32 wait_event_info)
 				event_name = pgstat_get_wait_io(w);
 				break;
 			}
+		case PG_WAIT_PAGE_TRANS_SLOT:
+			event_name = "TransSlot";
+			break;
 		default:
 			event_name = "unknown wait event";
 			break;
@@ -5981,6 +6025,7 @@ pgstat_recv_tabstat(PgStat_MsgTabstat *msg, int len)
 			tabentry->tuples_updated = tabmsg->t_counts.t_tuples_updated;
 			tabentry->tuples_deleted = tabmsg->t_counts.t_tuples_deleted;
 			tabentry->tuples_hot_updated = tabmsg->t_counts.t_tuples_hot_updated;
+			tabentry->tuples_inplace_updated = tabmsg->t_counts.t_tuples_inplace_updated;
 			tabentry->n_live_tuples = tabmsg->t_counts.t_delta_live_tuples;
 			tabentry->n_dead_tuples = tabmsg->t_counts.t_delta_dead_tuples;
 			tabentry->changes_since_analyze = tabmsg->t_counts.t_changed_tuples;
@@ -6008,6 +6053,7 @@ pgstat_recv_tabstat(PgStat_MsgTabstat *msg, int len)
 			tabentry->tuples_updated += tabmsg->t_counts.t_tuples_updated;
 			tabentry->tuples_deleted += tabmsg->t_counts.t_tuples_deleted;
 			tabentry->tuples_hot_updated += tabmsg->t_counts.t_tuples_hot_updated;
+			tabentry->tuples_inplace_updated += tabmsg->t_counts.t_tuples_inplace_updated;
 			/* If table was truncated, first reset the live/dead counters */
 			if (tabmsg->t_counts.t_truncated)
 			{
diff --git a/src/backend/postmaster/postmaster.c b/src/backend/postmaster/postmaster.c
index 6521efa..7b0da97 100644
--- a/src/backend/postmaster/postmaster.c
+++ b/src/backend/postmaster/postmaster.c
@@ -250,6 +250,8 @@ bool		restart_after_crash = true;
 
 bool		enable_undo_launcher = true;
 
+bool		disable_undo_launcher;
+
 /* PIDs of special child processes; 0 when not running */
 static pid_t StartupPID = 0,
 			BgWriterPID = 0,
diff --git a/src/backend/replication/logical/decode.c b/src/backend/replication/logical/decode.c
index 272edcb..2ce480c 100644
--- a/src/backend/replication/logical/decode.c
+++ b/src/backend/replication/logical/decode.c
@@ -160,6 +160,22 @@ LogicalDecodingProcessRecord(LogicalDecodingContext *ctx, XLogReaderState *recor
 			ReorderBufferProcessXid(ctx->reorder, XLogRecGetXid(record),
 									buf.origptr);
 			break;
+		case RM_ZHEAP_ID:
+			/* Logical decoding is not yet implemented for zheap. */
+			Assert(0);
+			break;
+		case RM_ZHEAP2_ID:
+			/* Logical decoding is not yet implemented for zheap. */
+			Assert(0);
+			break;
+		case RM_ZUNDO_ID:
+			/* Logical decoding is not yet implemented for zheap. */
+			Assert(0);
+			break;
+		case RM_TPD_ID:
+			/* Logical decoding is not yet implemented for TPD. */
+			Assert(0);
+			break;			
 		case RM_NEXT_ID:
 			elog(ERROR, "unexpected RM_NEXT_ID rmgr_id: %u", (RmgrIds) XLogRecGetRmid(buf.record));
 	}
diff --git a/src/backend/storage/lmgr/lmgr.c b/src/backend/storage/lmgr/lmgr.c
index f838b0f..a58bd4b 100644
--- a/src/backend/storage/lmgr/lmgr.c
+++ b/src/backend/storage/lmgr/lmgr.c
@@ -725,6 +725,143 @@ ConditionalXactLockTableWait(TransactionId xid)
 }
 
 /*
+ *		SubXactLockTableInsert
+ *
+ * Insert a lock showing that the current subtransaction is running ---
+ * this is done when a subtransaction performs the operation.  The lock can
+ * then be used to wait for the subtransaction to finish.
+ */
+void
+SubXactLockTableInsert(SubTransactionId subxid)
+{
+	LOCKTAG		tag;
+	TransactionId xid;
+	ResourceOwner currentOwner;
+
+	/* Acquire lock only if we doesn't already hold that lock. */
+	if (HasCurrentSubTransactionLock())
+		return;
+
+	xid = GetTopTransactionId();
+
+	/*
+	 * Acquire lock on the transaction XID.  (We assume this cannot block.) We
+	 * have to ensure that the lock is assigned to the transaction's own
+	 * ResourceOwner.
+	 */
+	currentOwner = CurrentResourceOwner;
+	CurrentResourceOwner = GetCurrentTransactionResOwner();
+
+	SET_LOCKTAG_SUBTRANSACTION(tag, xid, subxid);
+	(void) LockAcquire(&tag, ExclusiveLock, false, false);
+
+	CurrentResourceOwner = currentOwner;
+
+	SetCurrentSubTransactionLocked();
+}
+
+/*
+ *		SubXactLockTableDelete
+ *
+ * Delete the lock showing that the given subtransaction is running.
+ * (This is never used for main transaction IDs; those locks are only
+ * released implicitly at transaction end.  But we do use it for
+ * subtransactions in zheap.)
+ */
+void
+SubXactLockTableDelete(SubTransactionId subxid)
+{
+	LOCKTAG		tag;
+	TransactionId xid = GetTopTransactionId();
+
+	SET_LOCKTAG_SUBTRANSACTION(tag, xid, subxid);
+
+	LockRelease(&tag, ExclusiveLock, false);
+}
+
+/*
+ *		SubXactLockTableWait
+ *
+ * Wait for the specified subtransaction to commit or abort.  Here, instead of
+ * waiting on xid, we wait on xid + subTransactionId.  Whenever any concurrent
+ * transaction finds conflict then it will create a lock tag by (slot xid +
+ * subtransaction id from the undo) and wait on that.
+ *
+ * Unlike XactLockTableWait, we don't need to wait for topmost transaction to
+ * finish as we release the lock only when the transaction (committed/aborted)
+ * is recorded in clog.  This has some overhead in terms of maintianing unique
+ * xid locks for subtransactions during commit, but that shouldn't be much as
+ * we release the locks immediately after transaction is recorded in clog.
+ * This function is designed for zheap where we don't have xids assigned for
+ * subtransaction, so we can't really figure out if the subtransaction is
+ * still in progress.
+ */
+void
+SubXactLockTableWait(TransactionId xid, SubTransactionId subxid, Relation rel,
+					 ItemPointer ctid, XLTW_Oper oper)
+{
+	LOCKTAG		tag;
+	XactLockTableWaitInfo info;
+	ErrorContextCallback callback;
+
+	/*
+	 * If an operation is specified, set up our verbose error context
+	 * callback.
+	 */
+	if (oper != XLTW_None)
+	{
+		Assert(RelationIsValid(rel));
+		Assert(ItemPointerIsValid(ctid));
+
+		info.rel = rel;
+		info.ctid = ctid;
+		info.oper = oper;
+
+		callback.callback = XactLockTableWaitErrorCb;
+		callback.arg = &info;
+		callback.previous = error_context_stack;
+		error_context_stack = &callback;
+	}
+
+	Assert(TransactionIdIsValid(xid));
+	Assert(!TransactionIdEquals(xid, GetTopTransactionIdIfAny()));
+	Assert(subxid != InvalidSubTransactionId);
+
+	SET_LOCKTAG_SUBTRANSACTION(tag, xid, subxid);
+
+	(void) LockAcquire(&tag, ShareLock, false, false);
+
+	LockRelease(&tag, ShareLock, false);
+
+	if (oper != XLTW_None)
+		error_context_stack = callback.previous;
+}
+
+/*
+ *		ConditionalSubXactLockTableWait
+ *
+ * As above, but only lock if we can get the lock without blocking.
+ * Returns true if the lock was acquired.
+ */
+bool
+ConditionalSubXactLockTableWait(TransactionId xid, SubTransactionId subxid)
+{
+	LOCKTAG		tag;
+
+	Assert(TransactionIdIsValid(xid));
+	Assert(!TransactionIdEquals(xid, GetTopTransactionIdIfAny()));
+
+	SET_LOCKTAG_SUBTRANSACTION(tag, xid, subxid);
+
+	if (LockAcquire(&tag, ShareLock, false, true) == LOCKACQUIRE_NOT_AVAIL)
+		return false;
+
+	LockRelease(&tag, ShareLock, false);
+
+	return true;
+}
+
+/*
  *		SpeculativeInsertionLockAcquire
  *
  * Insert a lock showing that the given transaction ID is inserting a tuple,
@@ -772,6 +909,17 @@ SpeculativeInsertionLockRelease(TransactionId xid)
 }
 
 /*
+ *		GetSpeculativeInsertionToken
+ *
+ * Return the value of speculative insertion token.
+ */
+uint32
+GetSpeculativeInsertionToken(void)
+{
+	return speculativeInsertionToken;
+}
+
+/*
  *		SpeculativeInsertionWait
  *
  * Wait for the specified transaction to finish or abort the insertion of a
diff --git a/src/backend/storage/lmgr/lock.c b/src/backend/storage/lmgr/lock.c
index 1b7053c..18b4e5e 100644
--- a/src/backend/storage/lmgr/lock.c
+++ b/src/backend/storage/lmgr/lock.c
@@ -32,12 +32,14 @@
 #include <signal.h>
 #include <unistd.h>
 
+#include "access/multixact.h"
 #include "access/transam.h"
 #include "access/twophase.h"
 #include "access/twophase_rmgr.h"
 #include "access/xact.h"
 #include "access/xlog.h"
 #include "miscadmin.h"
+#include "nodes/lockoptions.h"
 #include "pg_trace.h"
 #include "pgstat.h"
 #include "storage/proc.h"
@@ -118,6 +120,31 @@ static const char *const lock_mode_names[] =
 	"AccessExclusiveLock"
 };
 
+const struct LockExtraInfo
+			tupleLockExtraInfo[MaxLockTupleMode + 1] =
+{
+	{							/* LockTupleKeyShare */
+		AccessShareLock,
+		MultiXactStatusForKeyShare,
+		-1						/* KeyShare does not allow updating tuples */
+	},
+	{							/* LockTupleShare */
+		RowShareLock,
+		MultiXactStatusForShare,
+		-1						/* Share does not allow updating tuples */
+	},
+	{							/* LockTupleNoKeyExclusive */
+		ExclusiveLock,
+		MultiXactStatusForNoKeyUpdate,
+		MultiXactStatusNoKeyUpdate
+	},
+	{							/* LockTupleExclusive */
+		AccessExclusiveLock,
+		MultiXactStatusForUpdate,
+		MultiXactStatusUpdate
+	}
+};
+
 #ifndef LOCK_DEBUG
 static bool Dummy_trace = false;
 #endif
@@ -4494,3 +4521,12 @@ LockWaiterCount(const LOCKTAG *locktag)
 
 	return waiters;
 }
+
+/*
+ * Get the heavy-weight lock mode from lock tuple mode.
+ */
+LOCKMODE
+GetHWLockModeFromMode(LockTupleMode mode)
+{
+	return tupleLockExtraInfo[mode].hwlock;
+}
diff --git a/src/backend/storage/lmgr/predicate.c b/src/backend/storage/lmgr/predicate.c
index 2d70942..286f6d9 100644
--- a/src/backend/storage/lmgr/predicate.c
+++ b/src/backend/storage/lmgr/predicate.c
@@ -212,6 +212,7 @@
 #include "storage/procarray.h"
 #include "utils/rel.h"
 #include "utils/snapmgr.h"
+#include "utils/ztqual.h"
 
 /* Uncomment the next line to test the graceful degradation code. */
 /* #define TEST_OLDSERXID */
@@ -479,7 +480,6 @@ static void SetNewSxactGlobalXmin(void);
 static void ClearOldPredicateLocks(void);
 static void ReleaseOneSerializableXact(SERIALIZABLEXACT *sxact, bool partial,
 									   bool summarize);
-static bool XidIsConcurrent(TransactionId xid);
 static void CheckTargetForConflictsIn(PREDICATELOCKTARGETTAG *targettag);
 static void FlagRWConflict(SERIALIZABLEXACT *reader, SERIALIZABLEXACT *writer);
 static void OnConflict_CheckForSerializationFailure(const SERIALIZABLEXACT *reader,
@@ -1069,6 +1069,12 @@ CheckPointPredicate(void)
 
 /*------------------------------------------------------------------------*/
 
+bool
+IsSerializableXact()
+{
+	return (MySerializableXact != InvalidSerializableXact);
+}
+
 /*
  * InitPredicateLocks -- Initialize the predicate locking data structures.
  *
@@ -2545,11 +2551,10 @@ PredicateLockPage(Relation relation, BlockNumber blkno, Snapshot snapshot)
  * Skip if this is a temporary table.
  */
 void
-PredicateLockTuple(Relation relation, HeapTuple tuple, Snapshot snapshot)
+PredicateLockTid(Relation relation, ItemPointer tid, Snapshot snapshot,
+				 TransactionId targetxmin)
 {
 	PREDICATELOCKTARGETTAG tag;
-	ItemPointer tid;
-	TransactionId targetxmin;
 
 	if (!SerializationNeededForRead(relation, snapshot))
 		return;
@@ -2561,8 +2566,6 @@ PredicateLockTuple(Relation relation, HeapTuple tuple, Snapshot snapshot)
 	{
 		TransactionId myxid;
 
-		targetxmin = HeapTupleHeaderGetXmin(tuple->t_data);
-
 		myxid = GetTopTransactionIdIfAny();
 		if (TransactionIdIsValid(myxid))
 		{
@@ -2591,7 +2594,6 @@ PredicateLockTuple(Relation relation, HeapTuple tuple, Snapshot snapshot)
 	if (PredicateLockExists(&tag))
 		return;
 
-	tid = &(tuple->t_self);
 	SET_PREDICATELOCKTARGETTAG_TUPLE(tag,
 									 relation->rd_node.dbNode,
 									 relation->rd_id,
@@ -4010,7 +4012,7 @@ ReleaseOneSerializableXact(SERIALIZABLEXACT *sxact, bool partial,
  * that to this function to save the overhead of checking the snapshot's
  * subxip array.
  */
-static bool
+bool
 XidIsConcurrent(TransactionId xid)
 {
 	Snapshot	snap;
@@ -4055,14 +4057,13 @@ XidIsConcurrent(TransactionId xid)
  */
 void
 CheckForSerializableConflictOut(bool visible, Relation relation,
-								HeapTuple tuple, Buffer buffer,
+								void *stup, Buffer buffer,
 								Snapshot snapshot)
 {
 	TransactionId xid;
 	SERIALIZABLEXIDTAG sxidtag;
 	SERIALIZABLEXID *sxid;
 	SERIALIZABLEXACT *sxact;
-	HTSV_Result htsvResult;
 
 	if (!SerializationNeededForRead(relation, snapshot))
 		return;
@@ -4077,65 +4078,17 @@ CheckForSerializableConflictOut(bool visible, Relation relation,
 				 errhint("The transaction might succeed if retried.")));
 	}
 
-	/*
-	 * Check to see whether the tuple has been written to by a concurrent
-	 * transaction, either to create it not visible to us, or to delete it
-	 * while it is visible to us.  The "visible" bool indicates whether the
-	 * tuple is visible to us, while HeapTupleSatisfiesVacuum checks what else
-	 * is going on with it.
-	 */
-	htsvResult = HeapTupleSatisfiesVacuum(tuple, TransactionXmin, buffer);
-	switch (htsvResult)
+	if (RelationStorageIsZHeap(relation))
 	{
-		case HEAPTUPLE_LIVE:
-			if (visible)
-				return;
-			xid = HeapTupleHeaderGetXmin(tuple->t_data);
-			break;
-		case HEAPTUPLE_RECENTLY_DEAD:
-			if (!visible)
-				return;
-			xid = HeapTupleHeaderGetUpdateXid(tuple->t_data);
-			break;
-		case HEAPTUPLE_DELETE_IN_PROGRESS:
-			xid = HeapTupleHeaderGetUpdateXid(tuple->t_data);
-			break;
-		case HEAPTUPLE_INSERT_IN_PROGRESS:
-			xid = HeapTupleHeaderGetXmin(tuple->t_data);
-			break;
-		case HEAPTUPLE_DEAD:
+		if (!ZHeapTupleHasSerializableConflictOut(visible, relation,
+												  (ItemPointer) stup, buffer, &xid))
+			return;
+	}
+	else
+	{
+		if (!HeapTupleHasSerializableConflictOut(visible, (HeapTuple) stup, buffer, &xid))
 			return;
-		default:
-
-			/*
-			 * The only way to get to this default clause is if a new value is
-			 * added to the enum type without adding it to this switch
-			 * statement.  That's a bug, so elog.
-			 */
-			elog(ERROR, "unrecognized return value from HeapTupleSatisfiesVacuum: %u", htsvResult);
-
-			/*
-			 * In spite of having all enum values covered and calling elog on
-			 * this default, some compilers think this is a code path which
-			 * allows xid to be used below without initialization. Silence
-			 * that warning.
-			 */
-			xid = InvalidTransactionId;
 	}
-	Assert(TransactionIdIsValid(xid));
-	Assert(TransactionIdFollowsOrEquals(xid, TransactionXmin));
-
-	/*
-	 * Find top level xid.  Bail out if xid is too early to be a conflict, or
-	 * if it's our own xid.
-	 */
-	if (TransactionIdEquals(xid, GetTopTransactionIdIfAny()))
-		return;
-	xid = SubTransGetTopmostTransaction(xid);
-	if (TransactionIdPrecedes(xid, TransactionXmin))
-		return;
-	if (TransactionIdEquals(xid, GetTopTransactionIdIfAny()))
-		return;
 
 	/*
 	 * Find sxact or summarized info for the top level xid.
@@ -4439,7 +4392,7 @@ CheckTargetForConflictsIn(PREDICATELOCKTARGETTAG *targettag)
  * tuple itself.
  */
 void
-CheckForSerializableConflictIn(Relation relation, HeapTuple tuple,
+CheckForSerializableConflictIn(Relation relation, ItemPointer tid,
 							   Buffer buffer)
 {
 	PREDICATELOCKTARGETTAG targettag;
@@ -4470,13 +4423,13 @@ CheckForSerializableConflictIn(Relation relation, HeapTuple tuple,
 	 * It is not possible to take and hold a lock across the checks for all
 	 * granularities because each target could be in a separate partition.
 	 */
-	if (tuple != NULL)
+	if (ItemPointerIsValid(tid))
 	{
 		SET_PREDICATELOCKTARGETTAG_TUPLE(targettag,
 										 relation->rd_node.dbNode,
 										 relation->rd_id,
-										 ItemPointerGetBlockNumber(&(tuple->t_self)),
-										 ItemPointerGetOffsetNumber(&(tuple->t_self)));
+										 ItemPointerGetBlockNumber(tid),
+										 ItemPointerGetOffsetNumber(tid));
 		CheckTargetForConflictsIn(&targettag);
 	}
 
diff --git a/src/backend/storage/page/bufpage.c b/src/backend/storage/page/bufpage.c
index f5133c7..30e6e34 100644
--- a/src/backend/storage/page/bufpage.c
+++ b/src/backend/storage/page/bufpage.c
@@ -18,6 +18,8 @@
 #include "access/itup.h"
 #include "access/xlog.h"
 #include "pgstat.h"
+#include "access/zhtup.h"
+#include "access/zheap.h"
 #include "storage/checksum.h"
 #include "utils/memdebug.h"
 #include "utils/memutils.h"
@@ -136,7 +138,8 @@ PageIsVerified(Page page, BlockNumber blkno)
 		 * the block can still reveal problems, which is why we offer the
 		 * checksum option.
 		 */
-		if ((p->pd_flags & ~PD_VALID_FLAG_BITS) == 0 &&
+		if (((p->pd_flags & ~PD_VALID_FLAG_BITS) == 0 ||
+			 (p->pd_flags & ~PD_ZHEAP_VALID_FLAG_BITS) == 0) &&
 			p->pd_lower <= p->pd_upper &&
 			p->pd_upper <= p->pd_special &&
 			p->pd_special <= BLCKSZ &&
@@ -445,17 +448,6 @@ PageRestoreTempPage(Page tempPage, Page oldPage)
 	pfree(tempPage);
 }
 
-/*
- * sorting support for PageRepairFragmentation and PageIndexMultiDelete
- */
-typedef struct itemIdSortData
-{
-	uint16		offsetindex;	/* linp array index */
-	int16		itemoff;		/* page offset of item data */
-	uint16		alignedlen;		/* MAXALIGN(item data len) */
-} itemIdSortData;
-typedef itemIdSortData *itemIdSort;
-
 static int
 itemoffcompare(const void *itemidp1, const void *itemidp2)
 {
@@ -468,7 +460,7 @@ itemoffcompare(const void *itemidp1, const void *itemidp2)
  * After removing or marking some line pointers unused, move the tuples to
  * remove the gaps caused by the removed items.
  */
-static void
+void
 compactify_tuples(itemIdSort itemidbase, int nitems, Page page)
 {
 	PageHeader	phdr = (PageHeader) page;
diff --git a/src/backend/storage/smgr/README b/src/backend/storage/smgr/README
index e1cfc6c..b48920d 100644
--- a/src/backend/storage/smgr/README
+++ b/src/backend/storage/smgr/README
@@ -10,16 +10,14 @@ memory, but these were never supported in any externally released Postgres,
 nor in any version of PostgreSQL.)  The "magnetic disk" manager is itself
 seriously misnamed, because actually it supports any kind of device for
 which the operating system provides standard filesystem operations; which
-these days is pretty much everything of interest.  However, we retain the
-notion of a storage manager switch in case anyone ever wants to reintroduce
-other kinds of storage managers.  Removing the switch layer would save
-nothing noticeable anyway, since storage-access operations are surely far
-more expensive than one extra layer of C function calls.
+these days is pretty much everything of interest.  However, we retained the
+notion of a storage manager switch and it turned out to be useful for plugging
+in a new storage manager to support buffered undo logs.
 
 In Berkeley Postgres each relation was tagged with the ID of the storage
-manager to use for it.  This is gone.  It would be probably more reasonable
-to associate storage managers with tablespaces, should we ever re-introduce
-multiple storage managers into the system catalogs.
+manager to use for it.  This is gone.  While earlier PostgreSQL releases were
+hard coded to use md.c unconditionally, PostgreSQL 12 routes IO for the undo
+pseudo-database to undo_file.c.
 
 The files in this directory, and their contents, are
 
@@ -31,7 +29,16 @@ The files in this directory, and their contents, are
     md.c	The "magnetic disk" storage manager, which is really just
 		an interface to the kernel's filesystem operations.
 
+    undo_file.c The undo log storage manager.  This supports
+		buffer-pool based access to the contents of undo log
+		segment files.  It supports a limited subset of the
+		smgr interface: it can only read and write blocks of
+		existing files.
+
 Note that md.c in turn relies on src/backend/storage/file/fd.c.
+undo_file.c also uses fd.c to read and write blocks, but it expects
+src/backend/access/undo/undolog.c to manage the files holding those
+blocks.
 
 
 Relation Forks
diff --git a/src/backend/storage/smgr/smgr.c b/src/backend/storage/smgr/smgr.c
index 93df85c..bfe4e9b 100644
--- a/src/backend/storage/smgr/smgr.c
+++ b/src/backend/storage/smgr/smgr.c
@@ -22,6 +22,7 @@
 #include "storage/bufmgr.h"
 #include "storage/ipc.h"
 #include "storage/md.h"
+#include "storage/undofile.h"
 #include "storage/smgr.h"
 #include "storage/undofile.h"
 #include "utils/hsearch.h"
diff --git a/src/backend/tcop/utility.c b/src/backend/tcop/utility.c
index 7f6f0b6..2a316be 100644
--- a/src/backend/tcop/utility.c
+++ b/src/backend/tcop/utility.c
@@ -1027,7 +1027,7 @@ ProcessUtilitySlow(ParseState *pstate,
 
 							/*
 							 * parse and validate reloptions for the toast
-							 * table
+							 * table.
 							 */
 							toast_options = transformRelOptions((Datum) 0,
 																((CreateStmt *) stmt)->options,
diff --git a/src/backend/utils/adt/lockfuncs.c b/src/backend/utils/adt/lockfuncs.c
index ffd1970..9a91a3c 100644
--- a/src/backend/utils/adt/lockfuncs.c
+++ b/src/backend/utils/adt/lockfuncs.c
@@ -29,9 +29,11 @@ const char *const LockTagTypeNames[] = {
 	"page",
 	"tuple",
 	"transactionid",
+	"subtransactionid",
 	"virtualxid",
 	"speculative token",
 	"object",
+	"undoaction",
 	"userlock",
 	"advisory"
 };
diff --git a/src/backend/utils/adt/pgstatfuncs.c b/src/backend/utils/adt/pgstatfuncs.c
index 05240bf..3964a51 100644
--- a/src/backend/utils/adt/pgstatfuncs.c
+++ b/src/backend/utils/adt/pgstatfuncs.c
@@ -16,6 +16,7 @@
 
 #include "access/htup_details.h"
 #include "access/xlog.h"
+#include "access/table.h"
 #include "catalog/pg_authid.h"
 #include "catalog/pg_type.h"
 #include "common/ip.h"
@@ -29,6 +30,7 @@
 #include "utils/acl.h"
 #include "utils/builtins.h"
 #include "utils/inet.h"
+#include "utils/rel.h"
 #include "utils/timestamp.h"
 
 #define UINT32_ACCESS_ONCE(var)		 ((uint32)(*((volatile uint32 *)&(var))))
@@ -138,12 +140,36 @@ pg_stat_get_tuples_hot_updated(PG_FUNCTION_ARGS)
 	Oid			relid = PG_GETARG_OID(0);
 	int64		result;
 	PgStat_StatTabEntry *tabentry;
+	Relation	rel = table_open(relid, AccessShareLock);
 
-	if ((tabentry = pgstat_fetch_stat_tabentry(relid)) == NULL)
+	/*
+	 * Counter tuples_hot_updated stores number of hot updates for heap table
+	 * and the number of inplace updates for zheap table.
+	 */
+	if ((tabentry = pgstat_fetch_stat_tabentry(relid)) == NULL ||
+		RelationStorageIsZHeap(rel))
 		result = 0;
 	else
 		result = (int64) (tabentry->tuples_hot_updated);
 
+	table_close(rel, AccessShareLock);
+
+	PG_RETURN_INT64(result);
+}
+
+
+Datum
+pg_stat_get_tuples_inplace_updated(PG_FUNCTION_ARGS)
+{
+	Oid			relid = PG_GETARG_OID(0);
+	int64		result;
+	PgStat_StatTabEntry *tabentry;
+
+	if ((tabentry = pgstat_fetch_stat_tabentry(relid)) == NULL)
+		result = 0;
+	else
+		result = (int64) (tabentry->tuples_inplace_updated);
+
 	PG_RETURN_INT64(result);
 }
 
@@ -1773,12 +1799,43 @@ pg_stat_get_xact_tuples_hot_updated(PG_FUNCTION_ARGS)
 	Oid			relid = PG_GETARG_OID(0);
 	int64		result;
 	PgStat_TableStatus *tabentry;
+	Relation	rel = table_open(relid, AccessShareLock);
 
-	if ((tabentry = find_tabstat_entry(relid)) == NULL)
+	/*
+	 * Counter t_tuples_hot_updated stores number of hot updates for heap
+	 * table and the number of inplace updates for zheap table.
+	 */
+	if ((tabentry = find_tabstat_entry(relid)) == NULL ||
+		RelationStorageIsZHeap(rel))
 		result = 0;
 	else
 		result = (int64) (tabentry->t_counts.t_tuples_hot_updated);
 
+	table_close(rel, AccessShareLock);
+
+	PG_RETURN_INT64(result);
+}
+
+Datum
+pg_stat_get_xact_tuples_inplace_updated(PG_FUNCTION_ARGS)
+{
+	Oid			relid = PG_GETARG_OID(0);
+	int64		result;
+	PgStat_TableStatus *tabentry;
+	Relation	rel = table_open(relid, AccessShareLock);
+
+	/*
+	 * Counter t_tuples_hot_updated stores number of hot updates for heap
+	 * table and the number of inplace updates for zheap table.
+	 */
+	if ((tabentry = find_tabstat_entry(relid)) == NULL ||
+		!RelationStorageIsZHeap(rel))
+		result = 0;
+	else
+		result = (int64) (tabentry->t_counts.t_tuples_hot_updated);
+
+	table_close(rel, AccessShareLock);
+
 	PG_RETURN_INT64(result);
 }
 
diff --git a/src/backend/utils/error/elog.c b/src/backend/utils/error/elog.c
index c665269..233ca6c 100644
--- a/src/backend/utils/error/elog.c
+++ b/src/backend/utils/error/elog.c
@@ -1871,7 +1871,6 @@ GetErrorContextStack(void)
 	return edata->context;
 }
 
-
 /*
  * Initialization of error output file
  */
@@ -1955,7 +1954,6 @@ set_syslog_parameters(const char *ident, int facility)
 	}
 }
 
-
 /*
  * Write a message line to syslog
  */
diff --git a/src/backend/utils/init/postinit.c b/src/backend/utils/init/postinit.c
index ede9c51..cbd2374 100644
--- a/src/backend/utils/init/postinit.c
+++ b/src/backend/utils/init/postinit.c
@@ -455,6 +455,20 @@ InitCommunication(void)
 	}
 }
 
+/*
+ * Check whether the dbid exist or not.
+ */
+bool
+dbid_exists(Oid dboid)
+{
+	bool		result = false;
+
+	Assert(IsTransactionState());
+	result = (GetDatabaseTupleByOid(dboid) != NULL);
+
+	return result;
+}
+
 
 /*
  * pg_split_opts -- split a string of options and append it to an argv array
@@ -1086,20 +1100,6 @@ InitPostgres(const char *in_dbname, Oid dboid, const char *username,
 }
 
 /*
- * Check whether the dbid exist or not.
- */
-bool
-dbid_exists(Oid dboid)
-{
-	bool		result = false;
-
-	Assert(IsTransactionState());
-	result = (GetDatabaseTupleByOid(dboid) != NULL);
-
-	return result;
-}
-
-/*
  * Process any command-line switches and any additional GUC variable
  * settings passed in the startup packet.
  */
diff --git a/src/backend/utils/misc/guc.c b/src/backend/utils/misc/guc.c
index 8b4aa0c..d84a0ca 100644
--- a/src/backend/utils/misc/guc.c
+++ b/src/backend/utils/misc/guc.c
@@ -2936,6 +2936,16 @@ static struct config_int ConfigureNamesInt[] =
 		5000, 1, INT_MAX,
 		NULL, NULL, NULL
 	},
+	{
+		{"rollback_overflow_size", PGC_USERSET, RESOURCES_MEM,
+			gettext_noop("Rollbacks greater than this size are done lazily"),
+			NULL,
+			GUC_UNIT_MB
+		},
+		&rollback_overflow_size,
+		64, 0, MAX_KILOBYTES,
+		NULL, NULL, NULL
+	},
 
 	{
 		{"wal_segment_size", PGC_INTERNAL, PRESET_OPTIONS,
@@ -3724,6 +3734,17 @@ static struct config_string ConfigureNamesString[] =
 	},
 
 	{
+		{"undo_tablespaces", PGC_USERSET, CLIENT_CONN_STATEMENT,
+			gettext_noop("Sets the tablespace(s) to use for undo logs."),
+			NULL,
+			GUC_LIST_INPUT | GUC_LIST_QUOTE
+		},
+		&undo_tablespaces,
+		"",
+		check_undo_tablespaces, assign_undo_tablespaces, NULL
+	},
+
+	{
 		{"dynamic_library_path", PGC_SUSET, CLIENT_CONN_OTHER,
 			gettext_noop("Sets the path for dynamically loadable modules."),
 			gettext_noop("If a dynamically loadable module needs to be opened and "
diff --git a/src/backend/utils/misc/pg_controldata.c b/src/backend/utils/misc/pg_controldata.c
index b429218..b3399fc 100644
--- a/src/backend/utils/misc/pg_controldata.c
+++ b/src/backend/utils/misc/pg_controldata.c
@@ -79,8 +79,8 @@ pg_control_system(PG_FUNCTION_ARGS)
 Datum
 pg_control_checkpoint(PG_FUNCTION_ARGS)
 {
-	Datum		values[19];
-	bool		nulls[19];
+	Datum		values[20];
+	bool		nulls[20];
 	TupleDesc	tupdesc;
 	HeapTuple	htup;
 	ControlFileData *ControlFile;
@@ -92,7 +92,7 @@ pg_control_checkpoint(PG_FUNCTION_ARGS)
 	 * Construct a tuple descriptor for the result row.  This must match this
 	 * function's pg_proc entry!
 	 */
-	tupdesc = CreateTemplateTupleDesc(18);
+	tupdesc = CreateTemplateTupleDesc(19);
 	TupleDescInitEntry(tupdesc, (AttrNumber) 1, "checkpoint_lsn",
 					   LSNOID, -1, 0);
 	TupleDescInitEntry(tupdesc, (AttrNumber) 2, "redo_lsn",
@@ -129,6 +129,8 @@ pg_control_checkpoint(PG_FUNCTION_ARGS)
 					   XIDOID, -1, 0);
 	TupleDescInitEntry(tupdesc, (AttrNumber) 18, "checkpoint_time",
 					   TIMESTAMPTZOID, -1, 0);
+	TupleDescInitEntry(tupdesc, (AttrNumber) 19, "oldest_xid_with_epoch_having_undo",
+					   INT8OID, -1, 0);
 	tupdesc = BlessTupleDesc(tupdesc);
 
 	/* Read the control file. */
@@ -203,6 +205,9 @@ pg_control_checkpoint(PG_FUNCTION_ARGS)
 									 time_t_to_timestamptz(ControlFile->checkPointCopy.time));
 	nulls[17] = false;
 
+	values[18] = Int64GetDatum(U64FromFullTransactionId(ControlFile->checkPointCopy.oldestFullXidHavingUnappliedUndo));
+	nulls[18] = false;
+
 	htup = heap_form_tuple(tupdesc, values, nulls);
 
 	PG_RETURN_DATUM(HeapTupleGetDatum(htup));
diff --git a/src/backend/utils/misc/postgresql.conf.sample b/src/backend/utils/misc/postgresql.conf.sample
index e86507c..61e07fd 100644
--- a/src/backend/utils/misc/postgresql.conf.sample
+++ b/src/backend/utils/misc/postgresql.conf.sample
@@ -758,4 +758,10 @@
 # CUSTOMIZED OPTIONS
 #------------------------------------------------------------------------------
 
+# If often there are large transactions requiring rollbacks, then we can push
+# them to undo-workers for better performance. The size specifeid by the
+# parameter below, determines the minimum size of the rollback requests to be
+# sent to the undo-worker.
+#
+#rollback_overflow_size = 64
 # Add settings for extensions here
diff --git a/src/bin/pg_controldata/pg_controldata.c b/src/bin/pg_controldata/pg_controldata.c
index 390ea0a..ee77367 100644
--- a/src/bin/pg_controldata/pg_controldata.c
+++ b/src/bin/pg_controldata/pg_controldata.c
@@ -272,6 +272,8 @@ main(int argc, char *argv[])
 		   ControlFile->checkPointCopy.oldestCommitTsXid);
 	printf(_("Latest checkpoint's newestCommitTsXid:%u\n"),
 		   ControlFile->checkPointCopy.newestCommitTsXid);
+	printf(_("Latest checkpoint's oldestFullXidHavingUnappliedUndo:" UINT64_FORMAT "\n"),
+		   U64FromFullTransactionId(ControlFile->checkPointCopy.oldestFullXidHavingUnappliedUndo));
 	printf(_("Time of latest checkpoint:            %s\n"),
 		   ckpttime_str);
 	printf(_("Fake LSN counter for unlogged rels:   %X/%X\n"),
@@ -325,6 +327,8 @@ main(int argc, char *argv[])
 		   ControlFile->toast_max_chunk_size);
 	printf(_("Size of a large-object chunk:         %u\n"),
 		   ControlFile->loblksize);
+	printf(_("Transaction slots per zheap page:     %u\n"),
+		   ControlFile->zheap_page_trans_slots);
 	/* This is no longer configurable, but users may still expect to see it: */
 	printf(_("Date/time type storage:               %s\n"),
 		   _("64-bit integers"));
diff --git a/src/bin/pg_resetwal/pg_resetwal.c b/src/bin/pg_resetwal/pg_resetwal.c
index ad96fe7..cc3ec46 100644
--- a/src/bin/pg_resetwal/pg_resetwal.c
+++ b/src/bin/pg_resetwal/pg_resetwal.c
@@ -58,6 +58,11 @@
 #include "pg_getopt.h"
 #include "getopt_long.h"
 
+#ifndef WIN32
+#define pg_mv_file		rename
+#else
+#define pg_mv_file		pgrename
+#endif
 
 static ControlFileData ControlFile; /* pg_control values */
 static XLogSegNo newXlogSegNo;	/* new XLOG segment # */
@@ -86,6 +91,7 @@ static void FindEndOfXLOG(void);
 static void KillExistingXLOG(void);
 static void KillExistingArchiveStatus(void);
 static void WriteEmptyXLOG(void);
+static bool FindLatestUndoCheckPointFile(char *latest_undo_checkpoint_file);
 static void usage(void);
 
 
@@ -116,6 +122,9 @@ main(int argc, char *argv[])
 	char	   *DataDir = NULL;
 	char	   *log_fname = NULL;
 	int			fd;
+	char		latest_undo_checkpoint_file[MAXPGPATH];
+	char		new_undo_checkpoint_file[MAXPGPATH];
+	bool		found = false;
 
 	pg_logging_init(argv[0]);
 	set_pglocale_pgservice(argv[0], PG_TEXTDOMAIN("pg_resetwal"));
@@ -446,6 +455,7 @@ main(int argc, char *argv[])
 		if (ControlFile.checkPointCopy.oldestXid < FirstNormalTransactionId)
 			ControlFile.checkPointCopy.oldestXid += FirstNormalTransactionId;
 		ControlFile.checkPointCopy.oldestXidDB = InvalidOid;
+		ControlFile.checkPointCopy.oldestFullXidHavingUnappliedUndo = InvalidFullTransactionId;
 	}
 
 	if (set_oldest_commit_ts_xid != 0)
@@ -513,6 +523,25 @@ main(int argc, char *argv[])
 	 */
 	AdjustRedoLocation(DataDir);
 	RewriteControlFile();
+
+	/*
+	 * Find the newest undo checkpoint file under pg_undo directory and rename
+	 * it as per the latest checkpoint redo location in control file.
+	 */
+	found = FindLatestUndoCheckPointFile(latest_undo_checkpoint_file);
+	if (!found)
+		fprintf(stderr, _("Could not find the latest undo checkpoint file.\n"));
+
+	snprintf(new_undo_checkpoint_file, sizeof(new_undo_checkpoint_file),
+			 "pg_undo/%016" INT64_MODIFIER "X", ControlFile.checkPointCopy.redo);
+
+	if (pg_mv_file(latest_undo_checkpoint_file, new_undo_checkpoint_file) != 0)
+	{
+		fprintf(stderr, _("Unable to rename %s to %s.\n"), latest_undo_checkpoint_file,
+				new_undo_checkpoint_file);
+		exit(1);
+	}
+
 	KillExistingXLOG();
 	KillExistingArchiveStatus();
 	WriteEmptyXLOG();
@@ -704,6 +733,7 @@ GuessControlValues(void)
 	ControlFile.checkPointCopy.oldestMultiDB = InvalidOid;
 	ControlFile.checkPointCopy.time = (pg_time_t) time(NULL);
 	ControlFile.checkPointCopy.oldestActiveXid = InvalidTransactionId;
+	ControlFile.checkPointCopy.oldestFullXidHavingUnappliedUndo = InvalidFullTransactionId;
 
 	ControlFile.state = DB_SHUTDOWNED;
 	ControlFile.time = (pg_time_t) time(NULL);
@@ -788,6 +818,8 @@ PrintControlValues(bool guessed)
 		   ControlFile.checkPointCopy.oldestCommitTsXid);
 	printf(_("Latest checkpoint's newestCommitTsXid:%u\n"),
 		   ControlFile.checkPointCopy.newestCommitTsXid);
+	printf(_("Latest checkpoint's oldestFullXidHavingUnappliedUndo:" UINT64_FORMAT "\n"),
+		   U64FromFullTransactionId(ControlFile.checkPointCopy.oldestFullXidHavingUnappliedUndo));
 	printf(_("Maximum data alignment:               %u\n"),
 		   ControlFile.maxAlign);
 	/* we don't print floatFormat since can't say much useful about it */
@@ -864,6 +896,8 @@ PrintNewControlValues(void)
 			   ControlFile.checkPointCopy.oldestXid);
 		printf(_("OldestXID's DB:                       %u\n"),
 			   ControlFile.checkPointCopy.oldestXidDB);
+		printf(_("OldestFullXidHavingUnappliedUndo:" UINT64_FORMAT "\n"),
+			   U64FromFullTransactionId(ControlFile.checkPointCopy.oldestFullXidHavingUnappliedUndo));
 	}
 
 	if (set_xid_epoch != -1)
@@ -1287,6 +1321,55 @@ WriteEmptyXLOG(void)
 	close(fd);
 }
 
+/*
+ * Find the latest modified undo checkpoint file under pg_undo directory and
+ * delete all other files.
+ */
+static bool
+FindLatestUndoCheckPointFile(char *latest_undo_checkpoint_file)
+{
+	char	  **filenames;
+	char	  **filename;
+	char		latest[UNDO_CHECKPOINT_FILENAME_LENGTH + 1];
+	bool		result = false;
+
+	memset(latest, 0, sizeof(latest));
+
+	/* Copy all the files from pg_undo directory into filenames */
+	filenames = pgfnames("pg_undo");
+
+	/*
+	 * Start reading each file under pg_undo to identify the latest modified
+	 * file and remove the older files that are not required.
+	 */
+	for (filename = filenames; *filename; filename++)
+	{
+		if (!(strlen(*filename) == UNDO_CHECKPOINT_FILENAME_LENGTH))
+			continue;
+
+		if (UndoCheckPointFilenamePrecedes(latest, *filename))
+		{
+			if (latest[0] != '\0')
+			{
+				snprintf(latest_undo_checkpoint_file, MAXPGPATH, "pg_undo/%s",
+						 latest);
+				if (unlink(latest_undo_checkpoint_file) != 0)
+					fprintf(stderr, _("could not unlink file \"%s\": %s\n"),
+							*filename, strerror(errno));
+			}
+			memcpy(latest, *filename, UNDO_CHECKPOINT_FILENAME_LENGTH);
+			latest[UNDO_CHECKPOINT_FILENAME_LENGTH] = '\0';
+			result = true;
+		}
+	}
+
+	if (result)
+		snprintf(latest_undo_checkpoint_file, MAXPGPATH, "pg_undo/%s", latest);
+
+	pgfnames_cleanup(filenames);
+
+	return result;
+}
 
 static void
 usage(void)
diff --git a/src/bin/pg_upgrade/pg_upgrade.c b/src/bin/pg_upgrade/pg_upgrade.c
index 09b786f..058f59b 100644
--- a/src/bin/pg_upgrade/pg_upgrade.c
+++ b/src/bin/pg_upgrade/pg_upgrade.c
@@ -472,6 +472,15 @@ copy_xact_xlog_xid(void)
 					  GET_MAJOR_VERSION(new_cluster.major_version) < 1000 ?
 					  "pg_clog" : "pg_xact");
 
+	/* copy old undo checkpoint files to new data dir */
+	copy_subdir_files("pg_undo", "pg_undo");
+
+	/*
+	 * copy old undo logs to new data dir assuming that the undo logs exist in
+	 * default location i.e. 'base/undo'.
+	 */
+	copy_subdir_files("base/undo", "base/undo");
+
 	/* set the next transaction id and epoch of the new cluster */
 	prep_status("Setting next transaction ID and epoch for new cluster");
 	exec_prog(UTILITY_LOG_FILE, NULL, true, true,
diff --git a/src/bin/pg_waldump/rmgrdesc.c b/src/bin/pg_waldump/rmgrdesc.c
index 976f80e..11efc60 100644
--- a/src/bin/pg_waldump/rmgrdesc.c
+++ b/src/bin/pg_waldump/rmgrdesc.c
@@ -20,10 +20,12 @@
 #include "access/nbtxlog.h"
 #include "access/rmgr.h"
 #include "access/spgxlog.h"
+#include "access/tpd_xlog.h"
 #include "access/undoaction_xlog.h"
 #include "access/undolog_xlog.h"
 #include "access/xact.h"
 #include "access/xlog_internal.h"
+#include "access/zheapam_xlog.h"
 #include "catalog/storage_xlog.h"
 #include "commands/dbcommands_xlog.h"
 #include "commands/sequence.h"
diff --git a/src/bin/pgbench/t/001_pgbench_with_server.pl b/src/bin/pgbench/t/001_pgbench_with_server.pl
index 5a2fdb9..772aa72 100644
--- a/src/bin/pgbench/t/001_pgbench_with_server.pl
+++ b/src/bin/pgbench/t/001_pgbench_with_server.pl
@@ -909,6 +909,72 @@ pgbench(
 check_pgbench_logs($bdir, '001_pgbench_log_3', 1, 10, 10,
 	qr{^\d \d{1,2} \d+ \d \d+ \d+$});
 
+# Modifying the default_table_access_method to zheap from heap
+$node->append_conf('postgresql.conf', "default_table_access_method = 'zheap'\n");
+$node->restart;
+
+# Test to verify non-inplace updates and rollback in zheap
+$node->safe_psql('postgres', 'DROP TABLE pgbench_tellers CASCADE; ');
+$node->safe_psql('postgres', 'DROP TABLE pgbench_branches CASCADE; ');
+$node->safe_psql('postgres', 'DROP TABLE pgbench_accounts CASCADE; ');
+$node->safe_psql('postgres', 'CREATE TABLE pgbench_accounts (aid integer,aidp integer,bid integer,abalance integer); ');
+$node->safe_psql('postgres', 'CREATE TABLE pgbench_branches (bid integer,bidp integer,	bbalance integer); ');
+$node->safe_psql('postgres', 'CREATE TABLE pgbench_tellers (tid integer,tidp integer,	bid integer,tbalance integer); ');
+$node->safe_psql('postgres', 'CREATE INDEX pgbench_accounts_pkey ON pgbench_accounts USING BTREE (aid);');
+$node->safe_psql('postgres', 'CREATE INDEX pgbench_branches_pkey ON pgbench_branches USING BTREE (bid);');
+$node->safe_psql('postgres', 'CREATE INDEX pgbench_tellers_pkey ON pgbench_tellers USING BTREE (tid);');
+$node->safe_psql('postgres', 'CREATE INDEX pgbench_accounts_pkey1 ON pgbench_accounts USING BTREE (aidp);');
+$node->safe_psql('postgres', 'CREATE INDEX pgbench_branches_pkey1 ON pgbench_branches USING BTREE (bidp);');
+$node->safe_psql('postgres', 'CREATE INDEX pgbench_tellers_pkey1 ON pgbench_tellers USING BTREE (tidp);');
+$node->safe_psql('postgres', 'INSERT INTO pgbench_accounts SELECT g,g,1,0 FROM generate_series(1, 5000000) g;');
+$node->safe_psql('postgres', 'INSERT INTO pgbench_branches SELECT g,g,0 FROM generate_series(1,5000)g;');
+$node->safe_psql('postgres', 'INSERT INTO pgbench_tellers SELECT g,g,1,0 FROM generate_series(1,50000)g;');
+
+pgbench(
+	"-T 60 -c32 -j32 -M prepared",
+	0,
+	[
+			qr{type: multiple scripts},
+			qr{mode: prepared},
+			qr{script 1: .*/001_pgbench_custom_script_zheap_1},
+			qr{weight: 1},
+			qr{script 2: .*/001_pgbench_custom_script_zheap_2},
+			qr{weight: 5}
+	],
+	[qr{starting vacuum...end.}],
+	'zheap pgbench custom scripts',
+	{
+		'001_pgbench_custom_script_zheap_1@1' => q{-- custom_script
+		\set aid random(1, 5000000)
+		\set bid random(1, 5000)
+		\set tid random(1, 50000)
+		\set delta random(1, 5000000)
+		\set deltb random(1, 5000)
+		\set deltt random(1, 50000)
+		BEGIN;
+		UPDATE pgbench_accounts SET aid = :delta WHERE aidp = :aid;
+		SELECT abalance FROM pgbench_accounts WHERE aidp = :aid;
+		UPDATE pgbench_tellers SET tid = :deltt WHERE tidp = :tid;
+		UPDATE pgbench_branches SET bid = :deltb WHERE bidp = :bid;
+		INSERT INTO pgbench_history (tid, bid, aid, delta, mtime) VALUES (:tid, :bid, :aid, :delta, CURRENT_TIMESTAMP);
+		SELECT * from pgbench_tellers FOR KEY SHARE;
+		END;
+},
+		'001_pgbench_custom_script_zheap_2@5' => q{-- custom_script_rb
+		\set aid random(1, 50000000)
+		\set bid random(1, 500)
+		\set tid random(1, 5000)
+		\set delta random(1, 50000)
+		BEGIN;
+		UPDATE pgbench_accounts SET abalance = abalance + :delta WHERE aid = :aid;
+		SELECT abalance FROM pgbench_accounts WHERE aid = :aid;
+		UPDATE pgbench_tellers SET tbalance = tbalance + :delta WHERE tid = :tid;
+		UPDATE pgbench_branches SET bbalance = bbalance + :delta WHERE bid = :bid;
+		SELECT * from pgbench_branches FOR KEY SHARE;
+		rollback;
+}
+	});
+
 # done
 $node->stop;
 done_testing();
diff --git a/src/include/access/genam.h b/src/include/access/genam.h
index 8c053be..d90c017 100644
--- a/src/include/access/genam.h
+++ b/src/include/access/genam.h
@@ -212,6 +212,7 @@ extern SysScanDesc systable_beginscan_ordered(Relation heapRelation,
 											  int nkeys, ScanKey key);
 extern HeapTuple systable_getnext_ordered(SysScanDesc sysscan,
 										  ScanDirection direction);
+extern struct TupleTableSlot *systable_getnext_ordered_slot(SysScanDesc sysscan, ScanDirection direction);
 extern void systable_endscan_ordered(SysScanDesc sysscan);
 
 #endif							/* GENAM_H */
diff --git a/src/include/access/hash_xlog.h b/src/include/access/hash_xlog.h
index 53b682c..6b6374c 100644
--- a/src/include/access/hash_xlog.h
+++ b/src/include/access/hash_xlog.h
@@ -260,17 +260,24 @@ typedef struct xl_hash_init_bitmap_page
  *
  * Backup Blk 0: bucket page
  * Backup Blk 1: meta page
+ *
+ * In Hot Standby, we need to scan the entire relation to verify whether any
+ * hash delete index item conflicts with any standby query. For that, we need to
+ * know the relation type which is stored in xlog record.
  */
+#define	XLOG_HASH_VACUUM_RELATION_STORAGE_ZHEAP	0x0001
+
 typedef struct xl_hash_vacuum_one_page
 {
 	TransactionId latestRemovedXid;
 	int			ntuples;
+	uint8		flags;			/* See XLOG_HASH_VACUUM_* flags for details */
 
 	/* TARGET OFFSET NUMBERS FOLLOW AT THE END */
 } xl_hash_vacuum_one_page;
 
 #define SizeOfHashVacuumOnePage \
-	(offsetof(xl_hash_vacuum_one_page, ntuples) + sizeof(int))
+	(offsetof(xl_hash_vacuum_one_page, flags) + sizeof(uint8))
 
 extern void hash_redo(XLogReaderState *record);
 extern void hash_desc(StringInfo buf, XLogReaderState *record);
diff --git a/src/include/access/heapam.h b/src/include/access/heapam.h
index 858bcb6..5958274 100644
--- a/src/include/access/heapam.h
+++ b/src/include/access/heapam.h
@@ -206,6 +206,9 @@ extern void HeapTupleSetHintBits(HeapTupleHeader tuple, Buffer buffer,
 extern bool HeapTupleHeaderIsOnlyLocked(HeapTupleHeader tuple);
 extern bool XidInMVCCSnapshot(TransactionId xid, Snapshot snapshot);
 extern bool HeapTupleIsSurelyDead(HeapTuple htup, TransactionId OldestXmin);
+extern bool HeapTupleHasSerializableConflictOut(bool visible,
+												HeapTuple htup, Buffer buffer,
+												TransactionId *xid);
 
 /*
  * To avoid leaking too much knowledge about reorderbuffer implementation
diff --git a/src/include/access/htup_details.h b/src/include/access/htup_details.h
index 27f963e..6a5ceea 100644
--- a/src/include/access/htup_details.h
+++ b/src/include/access/htup_details.h
@@ -815,5 +815,6 @@ extern MinimalTuple minimal_tuple_from_heap_tuple(HeapTuple htup);
 extern size_t varsize_any(void *p);
 extern HeapTuple heap_expand_tuple(HeapTuple sourceTuple, TupleDesc tupleDesc);
 extern MinimalTuple minimal_expand_tuple(HeapTuple sourceTuple, TupleDesc tupleDesc);
+extern Datum getmissingattr(TupleDesc tupleDesc, int attnum, bool *isnull);
 
 #endif							/* HTUP_DETAILS_H */
diff --git a/src/include/access/relscan.h b/src/include/access/relscan.h
index 2bde2c2..c7f2ab7 100644
--- a/src/include/access/relscan.h
+++ b/src/include/access/relscan.h
@@ -91,6 +91,15 @@ typedef struct IndexFetchTableData
 	Relation	rel;
 } IndexFetchTableData;
 
+
+typedef struct IndexFetchZHeapData
+{
+	IndexFetchTableData xs_base;
+
+	Buffer		xs_cbuf;		/* current heap buffer in scan, if any */
+	/* NB: if xs_cbuf is not InvalidBuffer, we hold a pin on that buffer */
+}			IndexFetchZHeapData;
+
 /*
  * We use the same IndexScanDescData structure for both amgettuple-based
  * and amgetbitmap-based index scans.  Some fields are only relevant in
diff --git a/src/include/access/rewritezheap.h b/src/include/access/rewritezheap.h
new file mode 100644
index 0000000..2525671
--- /dev/null
+++ b/src/include/access/rewritezheap.h
@@ -0,0 +1,32 @@
+/*-------------------------------------------------------------------------
+ *
+ * rewritezheap.h
+ *	  Declarations for zheap rewrite support functions
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994-5, Regents of the University of California
+ *
+ * src/include/access/rewritezheap.h
+ *
+ *-------------------------------------------------------------------------
+ */
+#ifndef REWRITE_ZHEAP_H
+#define REWRITE_ZHEAP_H
+
+#include "access/zhtup.h"
+#include "utils/relcache.h"
+
+/* struct definition is private to rewritezheap.c */
+typedef struct RewriteZheapStateData *RewriteZheapState;
+
+extern RewriteZheapState begin_zheap_rewrite(Relation OldHeap, Relation NewHeap,
+											 TransactionId OldestXmin, TransactionId FreezeXid,
+											 MultiXactId MultiXactCutoff, bool use_wal);
+extern void end_zheap_rewrite(RewriteZheapState state);
+extern void reform_and_rewrite_ztuple(TupleDesc oldTupDesc,
+									  TupleDesc newTupDesc, Datum *values, bool *isnull,
+									  RewriteZheapState rwstate);
+extern void rewrite_zheap_tuple(RewriteZheapState state,
+								ZHeapTuple newTuple);
+
+#endif							/* REWRITE_ZHEAP_H */
diff --git a/src/include/access/rmgrlist.h b/src/include/access/rmgrlist.h
index 6da5930..173afa0 100644
--- a/src/include/access/rmgrlist.h
+++ b/src/include/access/rmgrlist.h
@@ -49,3 +49,7 @@ PG_RMGR(RM_GENERIC_ID, "Generic", generic_redo, generic_desc, generic_identify,
 PG_RMGR(RM_LOGICALMSG_ID, "LogicalMessage", logicalmsg_redo, logicalmsg_desc, logicalmsg_identify, NULL, NULL, NULL, NULL, NULL, NULL)
 PG_RMGR(RM_UNDOLOG_ID, "UndoLog", undolog_redo, undolog_desc, undolog_identify, NULL, NULL, NULL, NULL, NULL, NULL)
 PG_RMGR(RM_UNDOACTION_ID, "UndoAction", undoaction_redo, undoaction_desc, undoaction_identify, NULL, NULL, NULL, NULL, NULL, NULL)
+PG_RMGR(RM_ZHEAP_ID, "Zheap", zheap_redo, zheap_desc, zheap_identify, NULL, NULL, zheap_mask, zheap_undo_actions, NULL)
+PG_RMGR(RM_ZHEAP2_ID, "Zheap2", zheap2_redo, zheap2_desc, zheap2_identify, NULL, NULL, zheap_mask, NULL, NULL)
+PG_RMGR(RM_ZUNDO_ID, "ZUndo", zundo_redo, zundo_desc, zundo_identify, NULL, NULL, NULL, NULL, NULL)
+PG_RMGR(RM_TPD_ID, "TPD", tpd_redo, tpd_desc, tpd_identify, NULL, NULL, zheap_mask, NULL, NULL)
diff --git a/src/include/access/tableam.h b/src/include/access/tableam.h
index c2b0481..0c60c1d 100644
--- a/src/include/access/tableam.h
+++ b/src/include/access/tableam.h
@@ -19,6 +19,7 @@
 
 #include "access/relscan.h"
 #include "access/sdir.h"
+#include "storage/bufmgr.h"
 #include "utils/guc.h"
 #include "utils/rel.h"
 #include "utils/snapshot.h"
@@ -117,6 +118,10 @@ typedef enum TM_Result
  * tuple); otherwise cmax is zero.  (We make this restriction because
  * HeapTupleHeaderGetCmax doesn't work for tuples outdated in other
  * transactions.)
+ *
+ * in_place_updated_or_locked indicates whether the tuple is updated or locked.
+ * We need to re-verify the tuple even if it is just marked as locked, because
+ * previously someone could have updated it in place.
  */
 typedef struct TM_FailureData
 {
@@ -124,6 +129,7 @@ typedef struct TM_FailureData
 	TransactionId xmax;
 	CommandId	cmax;
 	bool		traversed;
+	bool		in_place_updated_or_locked;
 } TM_FailureData;
 
 /* "options" flag bits for table_tuple_insert */
@@ -1751,4 +1757,20 @@ extern const TableAmRoutine *GetHeapamTableAmRoutine(void);
 extern bool check_default_table_access_method(char **newval, void **extra,
 											  GucSource source);
 
+/* ----------------------------------------------------------------------------
+ * Functions common to heap and zheap
+ * ----------------------------------------------------------------------------
+ */
+typedef struct BulkInsertStateData *BulkInsertState;
+
+extern bool heap_acquire_tuplock(Relation relation, ItemPointer tid,
+								 LockTupleMode mode, LockWaitPolicy wait_policy,
+								 bool *have_tuple_lock);
+extern void GetVisibilityMapPins(Relation relation, Buffer buffer1,
+								 Buffer buffer2, BlockNumber block1, BlockNumber block2,
+								 Buffer *vmbuffer1, Buffer *vmbuffer2);
+extern void RelationAddExtraBlocks(Relation relation, BulkInsertState bistate);
+extern Buffer ReadBufferBI(Relation relation, BlockNumber targetBlock,
+						   ReadBufferMode mode, BulkInsertState bistate);
+
 #endif							/* TABLEAM_H */
diff --git a/src/include/access/tpd.h b/src/include/access/tpd.h
new file mode 100644
index 0000000..304931a
--- /dev/null
+++ b/src/include/access/tpd.h
@@ -0,0 +1,148 @@
+/*-------------------------------------------------------------------------
+ *
+ * tpd.h
+ *	  POSTGRES TPD definitions.
+ *
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * src/include/access/tpd.h
+ *
+ *-------------------------------------------------------------------------
+ */
+#ifndef TPD_H
+#define TPD_H
+
+#include "postgres.h"
+
+#include "access/xlogutils.h"
+#include "access/zheap.h"
+#include "storage/block.h"
+#include "utils/rel.h"
+
+/* TPD page information */
+typedef struct TPDPageOpaqueData
+{
+	BlockNumber tpd_prevblkno;
+	BlockNumber tpd_nextblkno;
+	FullTransactionId tpd_latest_fxid;
+} TPDPageOpaqueData;
+
+typedef TPDPageOpaqueData *TPDPageOpaque;
+
+#define SizeofTPDPageOpaque (offsetof(TPDPageOpaqueData, tpd_latest_fxid) + sizeof(FullTransactionId))
+
+/*
+ * IsTPDPage
+ * 		returns true iff page is TPD page.
+ */
+#define IsTPDPage(page) \
+	(PageGetSpecialSize(page) == MAXALIGN(sizeof(TPDPageOpaqueData)))
+
+/* TPD entry information */
+#define INITIAL_TRANS_SLOTS_IN_TPD_ENTRY	8
+/*
+ * Number of item to transaction slot mapping entries in addition to max
+ * itemid's in heap page.  This is required to support newer inserts on the
+ * page, otherwise, we might immediately need to allocate a new bigger TPD
+ * entry.
+ */
+#define ADDITIONAL_MAP_ELEM_IN_TPD_ENTRY	8
+
+typedef struct TPDEntryHeaderData
+{
+	BlockNumber blkno;			/* Heap block number to which this TPD entry
+								 * belongs. */
+	uint16		tpe_num_map_entries;
+	uint16		tpe_num_slots;
+	uint16		tpe_flags;
+} TPDEntryHeaderData;
+
+typedef TPDEntryHeaderData *TPDEntryHeader;
+
+#define SizeofTPDEntryHeader (offsetof(TPDEntryHeaderData, tpe_flags) + sizeof(uint16))
+
+#define	TPE_ONE_BYTE	0x0001
+#define	TPE_FOUR_BYTE	0x0002
+#define	TPE_DELETED		0x0004
+
+#define	OFFSET_MASK	0x3FFFFF
+
+#define TPDEntryIsDeleted(tpd_e_hdr) \
+( \
+	(tpd_e_hdr.tpe_flags & TPE_DELETED) != 0 \
+)
+
+/* Maximum size of one TPD entry. */
+#define MaxTPDEntrySize \
+	((int) (BLCKSZ - SizeOfPageHeaderData - SizeofTPDPageOpaque - sizeof(ItemIdData)))
+
+/*
+ * MaxTPDTuplesPerPage is an upper bound on the number of tuples that can
+ * fit on one zheap page.
+ */
+#define MaxTPDTuplesPerPage	\
+	((int) ((BLCKSZ - SizeOfPageHeaderData - SizeofTPDPageOpaque) / \
+			(SizeofTPDEntryHeader  + sizeof(ItemIdData))))
+
+extern OffsetNumber TPDPageAddEntry(Page tpdpage, char *tpd_entry, Size size,
+									OffsetNumber offset);
+extern void SetTPDLocation(Buffer heapbuffer, Buffer tpdbuffer, uint16 offset);
+extern void ClearTPDLocation(Buffer heapbuf);
+extern void TPDInitPage(Page page, Size pageSize);
+extern bool TPDFreePage(Relation rel, Buffer buf, BufferAccessStrategy bstrategy);
+extern void ReleaseLastTPDBufferByTPDBlock(BlockNumber tpdblk);
+extern int	TPDAllocateAndReserveTransSlot(Relation relation, Buffer buf,
+										   OffsetNumber offnum, UndoRecPtr *urec_ptr,
+										   bool extend_if_required);
+extern TransInfo *TPDPageGetTransactionSlots(Relation relation, Buffer heapbuf,
+											 OffsetNumber offnum, bool keepTPDBufLock,
+											 bool checkOffset, int *num_map_entries,
+											 int *num_trans_slots, int *tpd_buf_id,
+											 bool *tpd_e_pruned, bool *alloc_bigger_map,
+											 bool clean_tpd_loc);
+extern int	TPDPageReserveTransSlot(Relation relation, Buffer heapbuf,
+									OffsetNumber offset, UndoRecPtr *urec_ptr,
+									bool *lock_reacquired,
+									bool always_extend, Buffer other_buf);
+extern int	TPDPageGetSlotIfExists(Relation relation, Buffer heapbuf, OffsetNumber offnum,
+								   FullTransactionId fxid, UndoRecPtr *urec_ptr,
+								   bool keepTPDBufLock, bool checkOffset);
+extern int	TPDPageGetTransactionSlotInfo(Buffer heapbuf, int trans_slot,
+										  OffsetNumber offset, uint32 *epoch, TransactionId *xid,
+										  UndoRecPtr *urec_ptr, bool NoTPDBufLock, bool keepTPDBufLock);
+extern void TPDPageSetTransactionSlotInfo(Buffer heapbuf, int trans_slot_id,
+										  FullTransactionId fxid, UndoRecPtr urec_ptr);
+extern void TPDPageSetUndo(Buffer heapbuf, int trans_slot_id,
+						   bool set_tpd_map_slot, FullTransactionId xid,
+						   UndoRecPtr urec_ptr, OffsetNumber *usedoff, int ucnt);
+extern void TPDPageSetOffsetMapSlot(Buffer heapbuf, int trans_slot_id,
+									OffsetNumber offset);
+extern void TPDPageGetOffsetMap(Buffer heapbuf, char *tpd_entry_data,
+								int map_size);
+extern int	TPDPageGetOffsetMapSize(Buffer heapbuf);
+extern void TPDPageSetOffsetMap(Buffer heapbuf, char *tpd_offset_map);
+extern bool TPDPageLock(Relation relation, Buffer heapbuf);
+extern void GetTPDBlockAndOffset(Page heap_page, BlockNumber *tpd_blk,
+								 OffsetNumber *tpd_item_off);
+extern XLogRedoAction XLogReadTPDBuffer(XLogReaderState *record,
+										uint8 block_id);
+extern uint8 RegisterTPDBuffer(Page heappage, uint8 block_id);
+extern void TPDPageSetLSN(Page heappage, XLogRecPtr recptr);
+extern void UnlockReleaseTPDBuffers(void);
+extern Size PageGetTPDFreeSpace(Page page);
+extern void ResetRegisteredTPDBuffers(void);
+
+/* interfaces exposed via prunetpd.c */
+extern int	TPDPagePrune(Relation rel, Buffer tpdbuf, BufferAccessStrategy strategy,
+						 OffsetNumber target_offnum, Size space_required, bool can_free,
+						 bool *update_tpd_inplace, bool *tpd_e_pruned);
+extern void TPDPagePruneExecute(Buffer tpdbuf, OffsetNumber *nowunused,
+								int nunused);
+extern void TPDPageRepairFragmentation(Page page, Page tmppage,
+									   OffsetNumber target_offnum, Size space_required);
+
+/* Reset globals related to TPD buffers. */
+extern void ResetTPDBuffers(void);
+#endif							/* TPD_H */
diff --git a/src/include/access/tpd_xlog.h b/src/include/access/tpd_xlog.h
new file mode 100644
index 0000000..81a54c5
--- /dev/null
+++ b/src/include/access/tpd_xlog.h
@@ -0,0 +1,81 @@
+/*-------------------------------------------------------------------------
+ *
+ * tpd_xlog.h
+ *	  POSTGRES tpd XLOG definitions.
+ *
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * src/include/access/tpd_xlog.h
+ *
+ *-------------------------------------------------------------------------
+ */
+#ifndef TPD_XLOG_H
+#define TPD_XLOG_H
+
+#include "postgres.h"
+
+#include "access/xlogreader.h"
+#include "lib/stringinfo.h"
+#include "storage/off.h"
+
+/*
+ * WAL record definitions for tpd.c's WAL operations
+ */
+#define XLOG_ALLOCATE_TPD_ENTRY			0x00
+#define XLOG_TPD_CLEAN					0x10
+#define XLOG_TPD_CLEAR_LOCATION			0x20
+#define XLOG_INPLACE_UPDATE_TPD_ENTRY	0x30
+#define XLOG_TPD_FREE_PAGE				0x40
+#define	XLOG_TPD_CLEAN_ALL_ENTRIES		0x50
+
+#define	XLOG_TPD_OPMASK				0x70
+
+/*
+ * When we insert 1st tpd entry on new page during reserve slot, we can (and
+ * we do) restore entire page in redo.
+ */
+#define XLOG_TPD_INIT_PAGE				0x80
+
+#define XLOG_OLD_TPD_BUF_EQ_LAST_TPD_BUF	0x01
+
+/* This is what we need to know about tpd entry allocation */
+typedef struct xl_tpd_allocate_entry
+{
+	/* tpd entry related info */
+	BlockNumber prevblk;
+	BlockNumber nextblk;
+	OffsetNumber offnum;		/* inserted entry's offset */
+
+	uint8		flags;
+	/* TPD entry data in backup block 0 */
+} xl_tpd_allocate_entry;
+
+#define SizeOfTPDAllocateEntry	(offsetof(xl_tpd_allocate_entry, flags) + sizeof(uint8))
+
+/* This is what we need to know about tpd entry cleanup */
+#define XL_TPD_CONTAINS_OFFSET			(1<<0)
+
+typedef struct xl_tpd_clean
+{
+	uint8		flags;
+} xl_tpd_clean;
+
+#define SizeOfTPDClean	(offsetof(xl_tpd_clean, flags) + sizeof(uint8))
+
+/* This is what we need to know about tpd free page */
+
+typedef struct xl_tpd_free_page
+{
+	BlockNumber prevblkno;
+	BlockNumber nextblkno;
+} xl_tpd_free_page;
+
+#define SizeOfTPDFreePage	(offsetof(xl_tpd_free_page, nextblkno) + sizeof(BlockNumber))
+
+extern void tpd_redo(XLogReaderState *record);
+extern void tpd_desc(StringInfo buf, XLogReaderState *record);
+extern const char *tpd_identify(uint8 info);
+
+#endif							/* TPD_XLOG_H */
diff --git a/src/include/access/transam.h b/src/include/access/transam.h
index e68e743..343a580 100644
--- a/src/include/access/transam.h
+++ b/src/include/access/transam.h
@@ -116,6 +116,14 @@ FullTransactionIdAdvance(FullTransactionId *dest)
 	(AssertMacro(TransactionIdIsNormal(id1) && TransactionIdIsNormal(id2)), \
 	(int32) ((id1) - (id2)) > 0)
 
+/* Extract xid from a value comprised of epoch and xid  */
+#define GetXidFromEpochXid(epochxid)			\
+	((uint32) (epochxid) & 0XFFFFFFFF)
+
+/* Extract epoch from a value comprised of epoch and xid  */
+#define GetEpochFromEpochXid(epochxid)			\
+	((uint32) ((epochxid) >> 32))
+
 /* ----------
  *		Object ID (OID) zero is InvalidOid.
  *
@@ -235,6 +243,9 @@ extern XLogRecPtr TransactionIdGetCommitLSN(TransactionId xid);
 /* in transam/varsup.c */
 extern FullTransactionId GetNewTransactionId(bool isSubXact);
 extern void AdvanceNextFullTransactionIdPastXid(TransactionId xid);
+
+/* ZBORKED: eliminate */
+extern uint32 GetEpochForXid(TransactionId xid);
 extern FullTransactionId ReadNextFullTransactionId(void);
 extern void SetTransactionIdLimit(TransactionId oldest_datfrozenxid,
 								  Oid oldest_datoid);
diff --git a/src/include/access/tuptoaster.h b/src/include/access/tuptoaster.h
index f0aea24..1f24dbc 100644
--- a/src/include/access/tuptoaster.h
+++ b/src/include/access/tuptoaster.h
@@ -16,6 +16,7 @@
 #include "access/htup_details.h"
 #include "storage/lockdefs.h"
 #include "utils/relcache.h"
+#include "utils/snapshot.h"
 
 /*
  * This enables de-toasting of index entries.  Needed until VACUUM is
@@ -236,4 +237,14 @@ extern Size toast_datum_size(Datum value);
  */
 extern Oid	toast_get_valid_index(Oid toastoid, LOCKMODE lock);
 
+extern int	toast_open_indexes(Relation toastrel,
+							   LOCKMODE lock,
+							   Relation **toastidxs,
+							   int *num_indexes);
+extern bool toastrel_valueid_exists(Relation toastrel, Oid valueid);
+extern bool toastid_valueid_exists(Oid toastrelid, Oid valueid);
+extern void toast_close_indexes(Relation *toastidxs, int num_indexes,
+								LOCKMODE lock);
+extern void init_toast_snapshot(Snapshot toast_snapshot);
+
 #endif							/* TUPTOASTER_H */
diff --git a/src/include/access/undorecord.h b/src/include/access/undorecord.h
index 6a2c5cc..3c78f74 100644
--- a/src/include/access/undorecord.h
+++ b/src/include/access/undorecord.h
@@ -21,6 +21,19 @@
 #include "storage/buf.h"
 #include "storage/off.h"
 
+typedef enum undorectype
+{
+	UNDO_INSERT,
+	UNDO_MULTI_INSERT,
+	UNDO_DELETE,
+	UNDO_INPLACE_UPDATE,
+	UNDO_UPDATE,
+	UNDO_XID_LOCK_ONLY,
+	UNDO_XID_LOCK_FOR_UPDATE,
+	UNDO_XID_MULTI_LOCK_ONLY,
+	UNDO_ITEMID_UNUSED
+} undorectype;
+
 /*
  * The below common information will be stored in the first undo record of the page.
  * Every subsequent undo record will not store this information, if required this information
@@ -63,6 +76,8 @@ typedef struct UndoCompressionInfo
 #define UREC_INFO_BLOCK						0x080
 #define UREC_INFO_LOGSWITCH					0x100
 #define UREC_INFO_PAYLOAD					0x200
+#define UREC_INFO_PAYLOAD_CONTAINS_SLOT		0x400
+#define UREC_INFO_PAYLOAD_CONTAINS_SUBXACT	0x800
 
 #define UREC_INFO_PAGE_COMMON  (UREC_INFO_RMID | UREC_INFO_RELOID | UREC_INFO_XID | UREC_INFO_CID)
 
diff --git a/src/include/access/vacuumblk.h b/src/include/access/vacuumblk.h
new file mode 100644
index 0000000..64a4110
--- /dev/null
+++ b/src/include/access/vacuumblk.h
@@ -0,0 +1,32 @@
+/*-------------------------------------------------------------------------
+ *
+ * vacuumblk.h
+ *	  header file for postgres block level vacuum routines
+ *
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * src/include/commands/vacuumblk.h
+ *
+ *-------------------------------------------------------------------------
+ */
+#ifndef VACUUMBLK_H
+#define VACUUMBLK_H
+
+#include "commands/vacuum.h"
+#include "storage/buf.h"
+
+extern void lazy_vacuum_index(Relation indrel, IndexBulkDeleteResult **stats,
+							  LVRelStats *vacrelstats,
+							  BufferAccessStrategy vac_strategy, int elevel);
+extern void lazy_cleanup_index(Relation indrel, IndexBulkDeleteResult *stats,
+							   LVRelStats *vacrelstats,
+							   BufferAccessStrategy vac_strategy, int elevel);
+extern bool should_attempt_truncation(VacuumParams *params, LVRelStats *vacrelstats);
+extern void lazy_truncate_heap(Relation onerel, LVRelStats *vacrelstats,
+							   BufferAccessStrategy vac_strategy, int elevel);
+extern void lazy_record_dead_tuple(LVRelStats *vacrelstats,
+								   ItemPointer itemptr);
+
+#endif							/* VACUUMBLK_H */
diff --git a/src/include/access/visibilitymap.h b/src/include/access/visibilitymap.h
index 2d88043..dd02a89 100644
--- a/src/include/access/visibilitymap.h
+++ b/src/include/access/visibilitymap.h
@@ -25,6 +25,8 @@
 /* Flags for bit map */
 #define VISIBILITYMAP_ALL_VISIBLE	0x01
 #define VISIBILITYMAP_ALL_FROZEN	0x02
+/* Used for zheap two-phase vacuum */
+#define VISIBILITYMAP_POTENTIAL_ALL_VISIBLE 0x02
 #define VISIBILITYMAP_VALID_BITS	0x03	/* OR of all valid visibilitymap
 											 * flags bits */
 
diff --git a/src/include/access/xact.h b/src/include/access/xact.h
index 6bcdc80..45640a4 100644
--- a/src/include/access/xact.h
+++ b/src/include/access/xact.h
@@ -16,12 +16,14 @@
 
 #include "access/undolog.h"
 #include "access/transam.h"
+#include "access/undolog.h"
 #include "access/xlogreader.h"
 #include "lib/stringinfo.h"
 #include "nodes/pg_list.h"
 #include "storage/relfilenode.h"
 #include "storage/sinval.h"
 #include "utils/datetime.h"
+#include "utils/resowner.h"
 
 /*
  * Maximum size of Global Transaction ID (including '\0').
@@ -359,14 +361,18 @@ extern TransactionId GetTopTransactionIdIfAny(void);
 extern TransactionId GetCurrentTransactionId(void);
 extern TransactionId GetCurrentTransactionIdIfAny(void);
 extern TransactionId GetStableLatestTransactionId(void);
+extern void SetCurrentSubTransactionLocked(void);
+extern bool HasCurrentSubTransactionLock(void);
 extern SubTransactionId GetCurrentSubTransactionId(void);
 extern FullTransactionId GetTopFullTransactionId(void);
 extern FullTransactionId GetTopFullTransactionIdIfAny(void);
 extern FullTransactionId GetCurrentFullTransactionId(void);
 extern FullTransactionId GetCurrentFullTransactionIdIfAny(void);
+extern ResourceOwner GetCurrentTransactionResOwner(void);
 extern void MarkCurrentTransactionIdLoggedIfAny(void);
 extern bool SubTransactionIsActive(SubTransactionId subxid);
 extern CommandId GetCurrentCommandId(bool used);
+extern bool GetCurrentCommandIdUsed(void);
 extern void SetParallelStartTimestamps(TimestampTz xact_ts, TimestampTz stmt_ts);
 extern TimestampTz GetCurrentTransactionStartTimestamp(void);
 extern TimestampTz GetCurrentStatementStartTimestamp(void);
@@ -438,6 +444,11 @@ extern bool PerformUndoActions(FullTransactionId fxid, Oid dbid,
 extern void SetCurrentUndoLocation(UndoRecPtr urec_ptr,
 				UndoLogCategory category);
 
+extern void ApplyUndoActions(void);
+extern void SetUndoActionsInfo(void);
+extern void ResetUndoActionsInfo(void);
+extern bool CanPerformUndoActions(void);
+
 /* xactdesc.c */
 extern void xact_desc(StringInfo buf, XLogReaderState *record);
 extern const char *xact_identify(uint8 info);
@@ -449,5 +460,6 @@ extern void ParseAbortRecord(uint8 info, xl_xact_abort *xlrec, xl_xact_parsed_ab
 extern void EnterParallelMode(void);
 extern void ExitParallelMode(void);
 extern bool IsInParallelMode(void);
+extern bool XidIsConcurrent(TransactionId xid);
 
 #endif							/* XACT_H */
diff --git a/src/include/access/xlog.h b/src/include/access/xlog.h
index d519252..093d72d 100644
--- a/src/include/access/xlog.h
+++ b/src/include/access/xlog.h
@@ -258,6 +258,7 @@ struct XLogRecData;
 
 extern XLogRecPtr XLogInsertRecord(struct XLogRecData *rdata,
 								   XLogRecPtr fpw_lsn,
+								   XLogRecPtr OldRedoRecPtr,
 								   uint8 flags);
 extern void XLogFlush(XLogRecPtr RecPtr);
 extern bool XLogBackgroundFlush(void);
diff --git a/src/include/access/xloginsert.h b/src/include/access/xloginsert.h
index 22b388c..c695eaf 100644
--- a/src/include/access/xloginsert.h
+++ b/src/include/access/xloginsert.h
@@ -44,6 +44,8 @@
 extern void XLogBeginInsert(void);
 extern void XLogSetRecordFlags(uint8 flags);
 extern XLogRecPtr XLogInsert(RmgrId rmid, uint8 info);
+extern XLogRecPtr XLogInsertExtended(RmgrId rmid, uint8 info,
+									 XLogRecPtr RedoRecPtr, bool doPageWrites);
 extern void XLogEnsureRecordSpace(int nbuffers, int ndatas);
 extern void XLogRegisterData(char *data, int len);
 extern void XLogRegisterBuffer(uint8 block_id, Buffer buffer, uint8 flags);
diff --git a/src/include/access/xlogreader.h b/src/include/access/xlogreader.h
index a12c94c..475bff6 100644
--- a/src/include/access/xlogreader.h
+++ b/src/include/access/xlogreader.h
@@ -233,6 +233,7 @@ extern bool DecodeXLogRecord(XLogReaderState *state, XLogRecord *record,
 #define XLogRecGetInfo(decoder) ((decoder)->decoded_record->xl_info)
 #define XLogRecGetRmid(decoder) ((decoder)->decoded_record->xl_rmid)
 #define XLogRecGetXid(decoder) ((decoder)->decoded_record->xl_xid)
+extern FullTransactionId XLogRecGetFullXid(XLogReaderState *record);
 #define XLogRecGetOrigin(decoder) ((decoder)->record_origin)
 #define XLogRecGetData(decoder) ((decoder)->main_data)
 #define XLogRecGetDataLen(decoder) ((decoder)->main_data_len)
diff --git a/src/include/access/xlogrecord.h b/src/include/access/xlogrecord.h
index 9375e54..08584fc 100644
--- a/src/include/access/xlogrecord.h
+++ b/src/include/access/xlogrecord.h
@@ -13,6 +13,7 @@
 
 #include "access/rmgr.h"
 #include "access/xlogdefs.h"
+#include "access/transam.h"
 #include "port/pg_crc32c.h"
 #include "storage/block.h"
 #include "storage/relfilenode.h"
diff --git a/src/include/access/xlogutils.h b/src/include/access/xlogutils.h
index 4db68f1..72e685d 100644
--- a/src/include/access/xlogutils.h
+++ b/src/include/access/xlogutils.h
@@ -36,6 +36,14 @@ typedef enum
 extern XLogRedoAction XLogReadBufferForRedo(XLogReaderState *record,
 											uint8 buffer_id, Buffer *buf);
 extern Buffer XLogInitBufferForRedo(XLogReaderState *record, uint8 block_id);
+extern XLogRedoAction XLogReadBufferForRedoBlock(XLogReaderState *record,
+												 SmgrId smgrid,
+												 RelFileNode rnode,
+												 ForkNumber forknum,
+												 BlockNumber blockno,
+												 ReadBufferMode mode,
+												 bool get_cleanup_lock,
+												 Buffer *buf);
 extern XLogRedoAction XLogReadBufferForRedoExtended(XLogReaderState *record,
 													uint8 buffer_id,
 													ReadBufferMode mode, bool get_cleanup_lock,
@@ -50,14 +58,6 @@ extern bool XLogFindBlockId(XLogReaderState *record,
 							BlockNumber blockno,
 							uint8 *block_id);
 
-extern XLogRedoAction XLogReadBufferForRedoBlock(XLogReaderState *record,
-												 RelFileNode rnode,
-												 ForkNumber forknum,
-												 BlockNumber blockno,
-												 ReadBufferMode mode,
-												 bool get_cleanup_lock,
-												 Buffer *buf);
-
 extern Relation CreateFakeRelcacheEntry(RelFileNode rnode);
 extern void FreeFakeRelcacheEntry(Relation fakerel);
 
diff --git a/src/include/access/zheap.h b/src/include/access/zheap.h
new file mode 100644
index 0000000..1fc7906
--- /dev/null
+++ b/src/include/access/zheap.h
@@ -0,0 +1,355 @@
+/*-------------------------------------------------------------------------
+ *
+ * zheap.h
+ *	  POSTGRES zheap header definitions.
+ *
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * src/include/access/zheap.h
+ *
+ *-------------------------------------------------------------------------
+ */
+#ifndef ZHEAP_H
+#define ZHEAP_H
+
+#include "postgres.h"
+
+#include "access/hio.h"
+#include "access/tableam.h"
+#include "access/undoaccess.h"
+#include "access/undorequest.h"
+#include "access/zhtup.h"
+#include "storage/smgr.h"
+#include "utils/rel.h"
+#include "utils/snapshot.h"
+
+/*
+ * Threshold for the number of blocks till which non-inplace updates due to
+ * reuse of transaction slot or use of TPD slots are allowed.  The performance
+ * testing on various sizes of tables indicate that threshold of 200 is good
+ * enough to keep the contention on transaction slots under control.
+ */
+#define		NUM_BLOCKS_FOR_NON_INPLACE_UPDATES 200
+
+/*
+ * Additional bits used from page header for zheap specific pages.
+ * See PageHeaderData.  We have considered to store these special flags
+ * in zheap specific pages, but the pages have different structures for
+ * special space which makes it inconvenient to store these flags.
+ */
+#define PD_PAGE_HAS_TPD_SLOT				0x0008
+
+#define PD_ZHEAP_VALID_FLAG_BITS	0x000F	/* OR of all valid pd_flags bits */
+
+#define ZHeapPageHasTPDSlot(phdr) \
+( \
+  ((phdr)->pd_flags & PD_PAGE_HAS_TPD_SLOT) != 0 \
+)
+
+/*
+ * We need TransactionId and undo pointer to retrieve the undo information
+ * for a particular transaction.
+ */
+typedef struct TransInfo
+{
+	FullTransactionId fxid;
+	UndoRecPtr	urec_ptr;
+} TransInfo;
+
+typedef struct ZHeapPageOpaqueData
+{
+	TransInfo	transinfo[1];
+} ZHeapPageOpaqueData;
+
+typedef ZHeapPageOpaqueData *ZHeapPageOpaque;
+
+#define SizeOfZHeapPageOpaqueData (ZHEAP_PAGE_TRANS_SLOTS \
+										 * sizeof(TransInfo))
+typedef struct ZHeapMetaPageData
+{
+	uint32		zhm_magic;		/* magic number for zheap tables */
+	uint32		zhm_version;	/* version ID */
+	uint32		zhm_first_used_tpd_page;
+	uint32		zhm_last_used_tpd_page;
+} ZHeapMetaPageData;
+
+typedef ZHeapMetaPageData *ZHeapMetaPage;
+
+#define ZHEAP_METAPAGE 0		/* metapage is always block 0 */
+#define ZHEAP_MAGIC            0xA056
+#define ZHEAP_VERSION  1
+
+#define ZHeapPageGetMeta(page) \
+		((ZHeapMetaPage) PageGetContents(page))
+
+/* "options" flag bits for heap_insert */
+#define ZHEAP_INSERT_SKIP_WAL	TABLE_INSERT_SKIP_WAL
+#define ZHEAP_INSERT_SKIP_FSM	TABLE_INSERT_SKIP_FSM
+#define ZHEAP_INSERT_FROZEN		TABLE_INSERT_FROZEN
+#define ZHEAP_INSERT_NO_LOGICAL	TABLE_INSERT_NO_LOGICAL
+#define ZHEAP_INSERT_SPECULATIVE 0x0010
+
+/*
+ * Given a page, it stores contiguous ranges of free offsets that can be
+ * used/reused in the same page. This is used in zheap_multi_insert to decide
+ * the number of undo records needs to be prepared before entering into critical
+ * section.
+ */
+typedef struct ZHeapFreeOffsetRanges
+{
+	OffsetNumber startOffset[MaxOffsetNumber];
+	OffsetNumber endOffset[MaxOffsetNumber];
+	int			nranges;
+} ZHeapFreeOffsetRanges;
+
+/* This is used to prepare undo records. */
+typedef struct ZHeapPrepareUndoInfo
+{
+	Oid			reloid;
+	BlockNumber blkno;
+	OffsetNumber offnum;
+	UndoRecPtr	prev_urecptr;
+	FullTransactionId fxid;
+	CommandId	cid;
+	UndoPersistence undo_persistence;
+	UndoRecordInsertContext	context;
+} ZHeapPrepareUndoInfo;
+
+/* This is used to prepare update undo records. */
+typedef struct ZHeapPrepareUpdateUndoInfo
+{
+	ZHeapPrepareUndoInfo *gen_info;
+	UnpackedUndoRecord *old_undorec;
+	UnpackedUndoRecord *new_undorec;
+	ItemPointerData *recovery_tid;
+	uint64		new_block;
+	UndoRecPtr	new_prev_urecptr;
+	TransactionId prevxid;
+	OffsetNumber new_offset;
+	int			new_trans_slot_id;
+	int			tup_trans_slot_id;
+	bool		inplace_update;
+	bool		same_buf;
+	bool		hasSubXactLock;
+} ZHeapPrepareUpdateUndoInfo;
+
+/* This is used to prepare lock undo records. */
+typedef struct ZHeapPrepareLockUndoInfo
+{
+	ZHeapPrepareUndoInfo *gen_info;
+	LockTupleMode mode;
+	char	   *tup_hdr;
+	int			tup_trans_slot;
+	TransactionId tup_xid;
+	uint16		new_infomask;
+	bool		IsLockForUpdate;
+	bool		hasSubXactLock;
+} ZHeapPrepareLockUndoInfo;
+
+/* This is used to write WAL. */
+typedef struct ZHeapWALInfo
+{
+	Buffer		buffer;
+	ZHeapTuple	ztuple;
+	UndoRecPtr	urecptr;		/* current undo record pointer */
+	UndoRecPtr	prev_urecptr;	/* previous undo record pointer */
+	int			prior_trans_slot_id;	/* trans slot prior to the operation */
+	int			new_trans_slot_id;	/* trans slot of the current operation */
+	bool		all_visible_cleared;
+	UnpackedUndoRecord *undorecord;
+	UndoRecordInsertContext	*context;
+} ZHeapWALInfo;
+
+/* This is used to write WAL during multi insert */
+typedef struct ZHeapMultiInsertWALInfo
+{
+	ZHeapWALInfo *gen_walinfo;	/* generic WAL info */
+	Relation	relation;
+	ZHeapTuple *ztuples;		/* array of all zheap tuples inserted */
+	ZHeapFreeOffsetRanges *zfree_offsets;	/* unused offset ranges in current
+											 * page */
+	int			curpage_ntuples;	/* tuples inserted in current page */
+	int			ntuples;		/* total number of tuples inserted */
+	int			ndone;			/* tuples processed */
+} ZHeapMultiInsertWALInfo;
+
+/* This is used to write WAL for undo actions */
+typedef struct ZHeapUndoActionWALInfo
+{
+	char	   *tpd_offset_map;
+	UndoRecPtr	prev_urecptr;
+	FullTransactionId fxid;
+	Buffer		buffer;
+	Buffer		vmbuffer;
+	int			slot_id;
+	int			tpd_map_size;
+	bool		tpd_page_locked;
+	bool		is_tpd_map_updated;
+	bool		need_init;
+} ZHeapUndoActionWALInfo;
+
+extern void zheap_insert(Relation relation, ZHeapTuple tup, CommandId cid,
+						 int options, BulkInsertState bistate, uint32 specToken);
+extern void simple_zheap_delete(Relation relation, ItemPointer tid, Snapshot snapshot);
+extern TM_Result zheap_delete(Relation relation, ItemPointer tid,
+							  CommandId cid, Snapshot crosscheck, Snapshot snapshot,
+							  bool wait, TM_FailureData *tmfd, bool changingPart);
+extern TM_Result zheap_update(Relation relation, ItemPointer otid, ZHeapTuple newtup,
+							  CommandId cid, Snapshot crosscheck, Snapshot snapshot, bool wait,
+							  TM_FailureData *tmfd, LockTupleMode *lockmode);
+extern TM_Result zheap_lock_tuple(Relation relation, ItemPointer tid,
+								  CommandId cid, LockTupleMode mode, LockWaitPolicy wait_policy,
+								  bool follow_updates, bool eval, Snapshot snapshot,
+								  ZHeapTuple tuple, Buffer *buffer, TM_FailureData *tmfd);
+extern void zheap_finish_speculative(Relation relation, ItemPointer tid);
+extern void zheap_abort_speculative(Relation relation, ItemPointer tid);
+extern int	PageReserveTransactionSlot(Relation relation, Buffer buf,
+									   OffsetNumber offset,
+									   FullTransactionId xid, UndoRecPtr *ureptr,
+									   bool *lock_reacquired,
+									   bool extend_if_required,
+									   Buffer other_buf,
+									   bool *slot_reused_or_TPD_slot);
+extern void MultiPageReserveTransSlot(Relation relation,
+									  Buffer oldbuf, Buffer newbuf,
+									  OffsetNumber oldbuf_offnum,
+									  OffsetNumber newbuf_offnum,
+									  FullTransactionId fxid,
+									  UndoRecPtr *oldbuf_prev_urecptr,
+									  UndoRecPtr *newbuf_prev_urecptr,
+									  int *oldbuf_trans_slot_id,
+									  int *newbuf_trans_slot_id,
+									  bool *lock_reacquired);
+extern int	PageGetTransactionSlotId(Relation rel, Buffer buf,
+									 FullTransactionId fxid, UndoRecPtr *urec_ptr,
+									 bool keepTPDBufLock, bool locktpd,
+									 bool *tpd_page_locked);
+extern void PageGetTransactionSlotInfo(Buffer buf, int slot_no,
+									   uint32 *epoch, TransactionId *xid,
+									   UndoRecPtr *urec_ptr,
+									   bool keepTPDBufLock);
+extern TransInfo *GetTransactionsSlotsForPage(Relation rel, Buffer buf,
+											  int *total_trans_slots,
+											  BlockNumber *tpd_blkno);
+
+struct TupleTableSlot;
+extern void zheap_multi_insert(Relation relation, struct TupleTableSlot **slots,
+							   int ntuples, CommandId cid, int options,
+							   BulkInsertState bistate);
+extern void zheap_get_latest_tid(TableScanDesc sscan,
+								 ItemPointer tid);
+extern XLogRecPtr log_zheap_visible(RelFileNode rnode, Buffer heap_buffer,
+									Buffer vm_buf, TransactionId cutoff_xid, uint8 flags);
+extern void PageSetTransactionSlotInfo(Buffer buf, int trans_slot_id,
+									   FullTransactionId fxid, UndoRecPtr urec_ptr);
+extern void PageSetUNDO(UnpackedUndoRecord undorecord, Buffer buffer,
+						int trans_slot_id, bool set_tpd_map_slot,
+						FullTransactionId fxid, UndoRecPtr urecptr, OffsetNumber *usedoff,
+						int ucnt);
+extern void ZHeapTupleHeaderAdvanceLatestRemovedXid(ZHeapTupleHeader tuple,
+													TransactionId xid, TransactionId *latestRemovedXid);
+extern void zheap_freeze_or_invalidate_tuples(Buffer buf, int nSlots, int *slots,
+											  bool isFrozen, bool TPDSlot);
+extern bool PageFreezeTransSlots(Relation relation, Buffer buf,
+								 bool *lock_reacquired, TransInfo *transinfo,
+								 int num_slots, Buffer other_buf);
+extern TransactionId zheap_fetchinsertxid(ZHeapTuple zhtup, Buffer buffer);
+extern void copy_zrelation_data(Relation srcRel, SMgrRelation dst);
+extern TransactionId zheap_compute_xid_horizon_for_tuples(Relation rel,
+														  ItemPointerData *tids, int nitems);
+extern UndoRecPtr zheap_prepare_undoinsert(ZHeapPrepareUndoInfo *zh_undo_info,
+										   uint32 specToken, bool specIns,
+										   UnpackedUndoRecord *undorecord,
+										   XLogReaderState *xlog_record);
+extern UndoRecPtr zheap_prepare_undodelete(ZHeapPrepareUndoInfo *zhUndoInfo, ZHeapTuple zhtup,
+										   TransactionId tup_xid, int tup_trans_slot_id,
+										   SubTransactionId subxid, UnpackedUndoRecord *undorecord,
+										   XLogReaderState *xlog_record);
+extern UndoRecPtr zheap_prepare_undoupdate(ZHeapPrepareUpdateUndoInfo *zh_up_undo_info, ZHeapTuple zhtup,
+										   XLogReaderState *xlog_record, UndoRecPtr *new_urecptr);
+extern UndoRecPtr zheap_prepare_undolock(ZHeapPrepareLockUndoInfo *zh_undo_info,
+										 UnpackedUndoRecord *undorecord,
+										 XLogReaderState *xlog_record);
+extern UndoRecPtr zheap_prepare_undo_multi_insert(ZHeapPrepareUndoInfo *zh_undo_info,
+									int nranges, UnpackedUndoRecord **uur_ptr,
+									XLogReaderState *xlog_record);
+
+/* Pruning related API's (prunezheap.c) */
+extern bool zheap_page_prune_opt(Relation relation, Buffer buffer,
+								 OffsetNumber offnum, Size space_required);
+extern int	zheap_page_prune_guts(Relation relation, Buffer buffer,
+								  TransactionId OldestXmin, OffsetNumber target_offnum,
+								  Size space_required, bool report_stats, bool force_prune,
+								  TransactionId *latestRemovedXid, bool *pruned);
+extern void zheap_page_prune_execute(Buffer buffer, OffsetNumber target_offnum,
+									 OffsetNumber *deleted, int ndeleted,
+									 OffsetNumber *nowdead, int ndead,
+									 OffsetNumber *nowunused, int nunused);
+extern XLogRecPtr log_zheap_clean(Relation reln, Buffer buffer,
+								  OffsetNumber target_offnum, Size space_required,
+								  OffsetNumber *nowdeleted, int ndeleted,
+								  OffsetNumber *nowdead, int ndead,
+								  OffsetNumber *nowunused, int nunused,
+								  TransactionId latestRemovedXid, bool pruned);
+extern void ZPageRepairFragmentation(Buffer buffer, Page tmppage, OffsetNumber target_offnum,
+									 Size space_required, bool NoTPDBufLock, bool *pruned,
+									 bool unused_set);
+extern void compactify_ztuples(itemIdSort itemidbase, int nitems, Page page,
+							   Page tmppage);
+
+/* Page related API's (zpage.c). */
+#define ZPageAddItem(buffer, input_page, item, size, offsetNumber, overwrite, is_heap, NoTPDBufLock) \
+	ZPageAddItemExtended(buffer, input_page, item, size, offsetNumber, \
+						 ((overwrite) ? PAI_OVERWRITE : 0) | \
+						 ((is_heap) ? PAI_IS_HEAP : 0), \
+						 NoTPDBufLock)
+
+extern OffsetNumber ZPageAddItemExtended(Buffer buffer, Page input_page,
+										 Item item, Size size, OffsetNumber offsetNumber,
+										 int flags, bool NoTPDBufLock);
+extern Size PageGetZHeapFreeSpace(Page page);
+extern void RelationPutZHeapTuple(Relation relation, Buffer buffer,
+								  ZHeapTuple tuple);
+extern ZHeapFreeOffsetRanges *ZHeapGetUsableOffsetRanges(Buffer buffer,
+														 ZHeapTuple *tuples, int ntuples, Size saveFreeSpace);
+extern void ZheapInitPage(Page page, Size pageSize);
+extern void zheap_init_meta_page(Buffer metabuf, BlockNumber first_blkno,
+								 BlockNumber last_blkno);
+extern void ZheapInitMetaPage(RelFileNode rnode, ForkNumber forkNum,
+							  char persistence, bool already_exists);
+extern ZHeapTuple zheap_gettuple(Relation relation, Buffer buffer,
+								 OffsetNumber offnum);
+
+/* Zheap and undo record interaction related API's (zundo.c) */
+extern bool ZHeapSatisfyUndoRecord(UnpackedUndoRecord *uurec, BlockNumber blkno,
+								   OffsetNumber offset, TransactionId xid);
+extern int	UpdateTupleHeaderFromUndoRecord(UnpackedUndoRecord *urec,
+											ZHeapTupleHeader hdr, Page page);
+extern bool ValidateTuplesXact(Relation relation, ZHeapTuple tuple,
+							   Snapshot snapshot, Buffer buf,
+							   TransactionId priorXmax, bool nobuflock);
+extern bool zheap_exec_pending_rollback(Relation rel, Buffer buffer,
+										int slot_no, TransactionId xwait, BlockNumber *tpd_blkno);
+extern void process_and_execute_undo_actions_page(UndoRecPtr from_urecptr,
+												  Relation rel, Buffer buffer,
+												  FullTransactionId fxid, int slot_no);
+
+/* in zheap/zvacuumlazy.c */
+struct VacuumParams;
+extern void lazy_vacuum_zheap_rel(Relation onerel, struct VacuumParams *params,
+								  BufferAccessStrategy bstrategy);
+
+/* in zheap/zundo.c */
+extern bool zheap_undo_actions(UndoRecInfo *urp_array, int first_idx, int last_idx,
+							   Oid reloid, FullTransactionId full_xid, BlockNumber blkno,
+							   bool blk_chain_complete);
+
+/* in zheap/ztuptoaster.c */
+extern ZHeapTuple ztoast_insert_or_update(Relation rel,
+										  ZHeapTuple newtup, ZHeapTuple oldtup,
+										  int options, uint32 specToken);
+extern void ztoast_delete(Relation rel, ZHeapTuple oldtup, bool is_speculative);
+
+#endif							/* ZHEAP_H */
diff --git a/src/include/access/zheapam_xlog.h b/src/include/access/zheapam_xlog.h
new file mode 100644
index 0000000..508e04c
--- /dev/null
+++ b/src/include/access/zheapam_xlog.h
@@ -0,0 +1,366 @@
+/*-------------------------------------------------------------------------
+ *
+ * zheapam_xlog.h
+ *	  POSTGRES zheap access XLOG definitions.
+ *
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * src/include/access/zheapam_xlog.h
+ *
+ *-------------------------------------------------------------------------
+ */
+#ifndef ZHEAP_XLOG_H
+#define ZHEAP_XLOG_H
+
+#include "postgres.h"
+
+#include "access/hio.h"
+#include "access/xlogreader.h"
+#include "access/undoaccess.h"
+#include "access/zhtup.h"
+#include "storage/freespace.h"
+#include "utils/rel.h"
+#include "utils/snapshot.h"
+
+/*
+ * WAL record definitions for zheapam.c's WAL operations
+ *
+ * XLOG allows to store some information in high 4 bits of log
+ * record xl_info field.  We use 3 for opcode and one for init bit.
+ */
+#define XLOG_ZHEAP_INSERT				0x00
+#define XLOG_ZHEAP_DELETE				0x10
+#define XLOG_ZHEAP_UPDATE				0x20
+#define XLOG_ZHEAP_MULTI_INSERT			0x30
+#define XLOG_ZHEAP_FREEZE_XACT_SLOT		0x40
+#define XLOG_ZHEAP_INVALID_XACT_SLOT	0x50
+#define XLOG_ZHEAP_LOCK					0x60
+#define XLOG_ZHEAP_CLEAN				0x70
+
+#define	XLOG_ZHEAP_OPMASK				0x70
+
+/*
+ * When we insert 1st item on new page in INSERT, NON-INPLACE-UPDATE,
+ * or MULTI_INSERT, we can (and we do) restore entire page in redo
+ */
+#define XLOG_ZHEAP_INIT_PAGE		0x80
+
+/*
+ * We ran out of opcodes, so zheapam.c now has a second RmgrId.  These opcodes
+ * are associated with RM_ZHEAP2_ID, but are not logically different from
+ * the ones above associated with RM_ZHEAP_ID.  XLOG_ZHEAP_OPMASK applies to
+ * these, too.
+ */
+#define XLOG_ZHEAP_CONFIRM		0x00
+#define XLOG_ZHEAP_UNUSED		0x10
+#define XLOG_ZHEAP_VISIBLE		0x20
+
+/*
+ * All that we need to regenerate the meta-data page
+ */
+typedef struct xl_zheap_metadata
+{
+	uint32		first_used_tpd_page;
+	uint32		last_used_tpd_page;
+} xl_zheap_metadata;
+
+#define SizeOfMetaData	(offsetof(xl_zheap_metadata, last_used_tpd_page) + sizeof(uint32))
+
+/* common undo record related info */
+typedef struct xl_undo_header
+{
+	Oid			reloid;			/* relation OID */
+	uint64		blkprev;		/* byte offset of previous undo for block */
+	UndoRecPtr	urec_ptr;		/* undo location for undo tuple */
+} xl_undo_header;
+
+#define SizeOfUndoHeader	(offsetof(xl_undo_header, urec_ptr) + sizeof(UndoRecPtr))
+
+/*
+ * xl_zheap_insert/xl_zheap_multi_insert flag values, 8 bits are available.
+ */
+#define XLZ_INSERT_ALL_VISIBLE_CLEARED			(1<<0)
+#define XLZ_INSERT_LAST_IN_MULTI				(1<<1)
+#define XLZ_INSERT_IS_SPECULATIVE				(1<<2)
+#define XLZ_INSERT_CONTAINS_NEW_TUPLE			(1<<3)
+#define XLZ_INSERT_CONTAINS_TPD_SLOT			(1<<4)
+#define XLZ_INSERT_IS_FROZEN					(1<<5)
+
+/*
+ * NOTE: t_hoff could be recomputed, but we may as well store it because
+ * it will come for free due to alignment considerations.
+ */
+typedef struct xl_zheap_header
+{
+	uint16		t_infomask2;
+	uint16		t_infomask;
+	uint8		t_hoff;
+} xl_zheap_header;
+
+#define SizeOfZHeapHeader	(offsetof(xl_zheap_header, t_hoff) + sizeof(uint8))
+
+/* This is what we need to know about insert */
+typedef struct xl_zheap_insert
+{
+	/* heap record related info */
+	OffsetNumber offnum;		/* inserted tuple's offset */
+	uint8		flags;
+
+	/* xl_zheap_header & TUPLE DATA in backup block 0 */
+} xl_zheap_insert;
+
+#define SizeOfZHeapInsert	(offsetof(xl_zheap_insert, flags) + sizeof(uint8))
+
+/*
+ * xl_zheap_delete flag values, 8 bits are available.
+ */
+/* PD_ALL_VISIBLE was cleared */
+#define XLZ_DELETE_ALL_VISIBLE_CLEARED			(1<<0)
+/* undo tuple is present in xlog record? */
+#define XLZ_HAS_DELETE_UNDOTUPLE				(1<<1)
+#define XLZ_DELETE_CONTAINS_TPD_SLOT			(1<<2)
+#define XLZ_DELETE_CONTAINS_SUBXACT				(1<<3)
+#define XLZ_DELETE_IS_PARTITION_MOVE			(1<<4)
+
+/* This is what we need to know about delete */
+typedef struct xl_zheap_delete
+{
+	/* info related to undo record */
+	TransactionId prevxid;		/* transaction id that has modified the tuple
+								 * written in undo record for delete operation */
+
+	/* zheap related info */
+	OffsetNumber offnum;		/* deleted tuple's offset */
+	uint16		infomask;		/* lock mode */
+	uint16		trans_slot_id;	/* transaction slot id */
+	uint8		flags;
+} xl_zheap_delete;
+
+#define SizeOfZHeapDelete	(offsetof(xl_zheap_delete, flags) + sizeof(uint8))
+
+/*
+ * xl_zheap_update flag values, 8 bits are available.
+ */
+/* PD_ALL_VISIBLE was cleared */
+#define XLZ_UPDATE_OLD_ALL_VISIBLE_CLEARED		(1<<0)
+/* PD_ALL_VISIBLE was cleared in the 2nd page */
+#define XLZ_UPDATE_NEW_ALL_VISIBLE_CLEARED		(1<<1)
+#define XLZ_UPDATE_PREFIX_FROM_OLD				(1<<2)
+#define XLZ_UPDATE_SUFFIX_FROM_OLD				(1<<3)
+#define	XLZ_NON_INPLACE_UPDATE					(1<<4)
+#define	XLZ_HAS_UPDATE_UNDOTUPLE				(1<<5)
+#define	XLZ_UPDATE_OLD_CONTAINS_TPD_SLOT		(1<<6)
+#define	XLZ_UPDATE_NEW_CONTAINS_TPD_SLOT		(1<<7)
+#define XLZ_UPDATE_CONTAINS_SUBXACT				(1<<8)
+
+/*
+ * This is what we need to know about update|inplace_update
+ *
+ * Backup blk 0: new page
+ *
+ * If XLOG_ZHEAP_PREFIX_FROM_OLD or XLOG_ZHEAP_SUFFIX_FROM_OLD flags are set,
+ * the prefix and/or suffix come first, as one or two uint16s.
+ *
+ * After that, xl_zheap_header and new tuple data follow.  The new tuple
+ * data doesn't include the prefix and suffix, which are copied from the
+ * old tuple on replay.
+ *
+ * Backup blk 1: old page, if different. (no data, just a reference to the blk)
+ */
+typedef struct xl_zheap_update
+{
+	/* info related to undo record */
+	TransactionId prevxid;		/* transaction id that has modified the tuple
+								 * written in undo record for delete operation */
+	/* zheap related info */
+	OffsetNumber old_offnum;	/* old tuple's offset */
+	uint16		old_infomask;	/* infomask bits to set on old tuple */
+	uint16		old_trans_slot_id;	/* old tuple's transaction slot id */
+	uint16		flags;
+	OffsetNumber new_offnum;	/* new tuple's offset */
+} xl_zheap_update;
+
+#define SizeOfZHeapUpdate	(offsetof(xl_zheap_update, new_offnum) + sizeof(OffsetNumber))
+
+/* This is what we need to know for freezing transaction slots */
+typedef struct xl_zheap_freeze_xact_slot
+{
+	TransactionId lastestFrozenXid; /* latest frozen xid */
+	uint16		nFrozen;		/* number of transaction slots to freeze */
+} xl_zheap_freeze_xact_slot;
+
+#define SizeOfZHeapFreezeXactSlot	(offsetof(xl_zheap_freeze_xact_slot, nFrozen) + sizeof(uint16))
+
+/*
+ * xl_zheap_lock flag values, 8 bits are available.
+ */
+#define XLZ_LOCK_TRANS_SLOT_FOR_UREC		(1<<0)
+#define XLZ_LOCK_CONTAINS_TPD_SLOT			(1<<1)
+#define XLZ_LOCK_CONTAINS_SUBXACT			(1<<2)
+#define XLZ_LOCK_FOR_UPDATE					(1<<3)
+
+/* This is what we need to know about zheap lock tuple. */
+typedef struct xl_zheap_lock
+{
+	/* info related to undo record */
+	TransactionId prev_xid;
+	/* zheap related info */
+	OffsetNumber offnum;		/* locked tuple's offset */
+	uint16		infomask;		/* lock mode */
+	uint16		trans_slot_id;	/* transaction slot id */
+	uint8		flags;
+} xl_zheap_lock;
+
+#define SizeOfZHeapLock    (offsetof(xl_zheap_lock, flags) + sizeof(uint8))
+
+/*
+ * This is what we need to know about a multi-insert.
+ *
+ * The main data of the record consists of this xl_zheap_multi_insert header,
+ * 'offset ranges' and tpd transaction slot number.
+ *
+ * In block 0's data portion, there is an xl_multi_insert_ztuple struct,
+ * followed by the tuple data for each tuple. There is padding to align
+ * each xl_zheap_multi_insert struct.
+ */
+typedef struct xl_zheap_multi_insert
+{
+	/* zheap record related info */
+	uint8		flags;
+	uint16		ntuples;
+} xl_zheap_multi_insert;
+
+#define SizeOfZHeapMultiInsert	(offsetof(xl_zheap_multi_insert, ntuples) + sizeof(uint16))
+
+typedef struct xl_multi_insert_ztuple
+{
+	uint16		datalen;		/* size of tuple data that follows */
+	uint16		t_infomask2;
+	uint16		t_infomask;
+	uint8		t_hoff;
+	/* TUPLE DATA FOLLOWS AT END OF STRUCT */
+} xl_multi_insert_ztuple;
+
+#define SizeOfMultiInsertZTuple	(offsetof(xl_multi_insert_ztuple, t_hoff) + sizeof(uint8))
+
+/*
+ * This is what we need to know about vacuum page cleanup/redirect
+ *
+ * The array of OffsetNumbers following the fixed part of the record contains:
+ * for each redirected item: the item offset, then the offset redirected to
+ * for each now-dead item: the item offset for each now-unused item: the item offset
+ * The total number of OffsetNumbers is therefore 2*nredirected+ndead+nunused.
+ * Note that nunused is not explicitly stored, but may be found by reference to the
+ * total record length.
+ */
+#define XLZ_CLEAN_CONTAINS_OFFSET			(1<<0)
+#define XLZ_CLEAN_ALLOW_PRUNING				(1<<1)
+
+typedef struct xl_zheap_clean
+{
+
+	TransactionId latestRemovedXid;
+	uint16		ndeleted;
+	uint16		ndead;
+	uint8		flags;
+	/* OFFSET NUMBERS are in the block reference 0 */
+} xl_zheap_clean;
+
+#define SizeOfZHeapClean (offsetof(xl_zheap_clean, flags) + sizeof(uint8))
+
+#define XLZ_UNUSED_ALLOW_PRUNING				(1<<0)
+
+typedef struct xl_zheap_unused
+{
+
+	TransactionId latestRemovedXid;
+	uint16		nunused;
+	uint16		trans_slot_id;
+	uint8		flags;
+	/* OFFSET NUMBERS are in the block reference 0 */
+} xl_zheap_unused;
+
+#define SizeOfZHeapUnused (offsetof(xl_zheap_unused, flags) + sizeof(uint8))
+
+/* This is what we need to know about confirmation of speculative insertion */
+/*
+ * xl_zheap_confirm flag values, 8 bits are available.
+ */
+/* speculative insertion is successful */
+#define XLZ_SPEC_INSERT_SUCCESS			(1<<0)
+/* speculative insertion failed */
+#define XLZ_SPEC_INSERT_FAILED				(1<<1)
+typedef struct xl_zheap_confirm
+{
+	OffsetNumber offnum;		/* confirmed tuple's offset on page */
+	uint8		flags;
+	uint16		trans_slot_id;
+} xl_zheap_confirm;
+
+#define SizeOfZHeapConfirm	(offsetof(xl_zheap_confirm, trans_slot_id) + sizeof(uint16))
+
+/*
+ * This is what we need to know about setting a visibility map bit
+ */
+typedef struct xl_zheap_visible
+{
+	TransactionId cutoff_xid;
+	BlockNumber heapBlk;
+	uint8		flags;
+} xl_zheap_visible;
+
+#define SizeOfZHeapVisible (offsetof(xl_zheap_visible, flags) + sizeof(uint8))
+
+/*
+ * WAL record definitions for zundo.c's WAL operations
+ */
+#define XLOG_ZUNDO_PAGE				0x00
+#define XLOG_ZUNDO_RESET_SLOT		0x10
+
+/*
+ * xl_undoaction_page flag values, 8 bits are available.
+ */
+#define XLU_PAGE_CONTAINS_TPD_SLOT			(1<<0)
+#define XLU_PAGE_CLEAR_VISIBILITY_MAP		(1<<1)
+#define XLU_CONTAINS_TPD_OFFSET_MAP			(1<<2)
+#define XLU_INIT_PAGE						(1<<3)
+
+/* This is what we need to know about delete */
+typedef struct xl_zundo_page
+{
+	UndoRecPtr	urec_ptr;
+	FullTransactionId fxid;
+	int			trans_slot_id;	/* transaction slot id */
+} xl_zundo_page;
+
+#define SizeOfZUndoPage	(offsetof(xl_zundo_page, trans_slot_id) + sizeof(int))
+
+/*
+ * xl_undoaction_reset_slot flag values, 8 bits are available.
+ */
+#define XLU_RESET_CONTAINS_TPD_SLOT			(1<<0)
+
+/* This is what we need to know about delete */
+typedef struct xl_zundo_reset_slot
+{
+	UndoRecPtr	urec_ptr;
+	int			trans_slot_id;	/* transaction slot id */
+	uint8		flags;
+} xl_zundo_reset_slot;
+
+#define SizeOfZUndoResetSlot	(offsetof(xl_zundo_reset_slot, flags) + sizeof(uint8))
+
+extern void zheap_redo(XLogReaderState *record);
+extern void zheap_desc(StringInfo buf, XLogReaderState *record);
+extern const char *zheap_identify(uint8 info);
+extern void zheap2_redo(XLogReaderState *record);
+extern void zheap_mask(char *pagedata, BlockNumber blkno);
+extern void zheap2_desc(StringInfo buf, XLogReaderState *record);
+extern const char *zheap2_identify(uint8 info);
+extern void zundo_redo(XLogReaderState *record);
+extern void zundo_desc(StringInfo buf, XLogReaderState *record);
+extern const char *zundo_identify(uint8 info);
+
+#endif							/* ZHEAP_XLOG_H */
diff --git a/src/include/access/zheapscan.h b/src/include/access/zheapscan.h
new file mode 100644
index 0000000..ce328d1
--- /dev/null
+++ b/src/include/access/zheapscan.h
@@ -0,0 +1,74 @@
+/*-------------------------------------------------------------------------
+ *
+ * zheapscan.h
+ *	  POSTGRES table scan definitions
+ *
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * src/include/access/zheapscan.h
+ *
+ *-------------------------------------------------------------------------
+ */
+
+#ifndef ZHEAPSCAN_H
+#define ZHEAPSCAN_H
+
+#include "access/relscan.h"
+#include "access/skey.h"
+#include "access/zheap.h"
+
+typedef struct ZHeapScanDescData
+{
+	/* scan parameters */
+	TableScanDescData rs_base;	/* */
+
+	/* state set up at initscan time */
+	BlockNumber rs_nblocks;		/* total number of blocks in rel */
+	BlockNumber rs_startblock;	/* block # to start at */
+	BlockNumber rs_numblocks;	/* max number of blocks to scan */
+	/* rs_numblocks is usually InvalidBlockNumber, meaning "scan whole rel" */
+
+	/* scan current state */
+	bool		rs_inited;		/* false = scan not initialized yet */
+	BlockNumber rs_cblock;		/* current block # in scan, if any */
+	Buffer		rs_cbuf;		/* current buffer in scan, if any */
+
+
+	/* rs_numblocks is usually InvalidBlockNumber, meaning "scan whole rel" */
+	BufferAccessStrategy rs_strategy;	/* access strategy for reads */
+
+	ZHeapTuple	rs_cztup;		/* current tuple in scan, if any */
+
+	int			rs_cindex;		/* current tuple's index in visztuples */
+	int			rs_ntuples;		/* number of visible tuples on page */
+
+	ZHeapTuple	rs_visztuples[MaxZHeapTuplesPerPage];
+} ZHeapScanDescData;
+
+typedef struct ZHeapScanDescData *ZHeapScanDesc;
+
+extern TableScanDesc zheap_beginscan(Relation relation, Snapshot snapshot,
+									 int nkeys, ScanKey key, ParallelTableScanDesc parallel_scan,
+									 uint32 flags);
+extern void zheap_endscan(TableScanDesc sscan);
+extern void zheap_rescan(TableScanDesc scan, ScanKey key, bool set_params,
+						 bool allow_strat, bool allow_sync, bool allow_pagemode);
+extern void zheap_setscanlimits(TableScanDesc scan, BlockNumber startBlk,
+								BlockNumber endBlk);
+extern bool zheapgetpage(TableScanDesc scan, BlockNumber page);
+extern bool zheap_getnextslot(TableScanDesc scan, ScanDirection direction,
+							  struct TupleTableSlot *slot);
+
+struct TBMIterateResult;
+extern bool zheap_scan_bitmap_next_block(TableScanDesc sscan, struct TBMIterateResult *tbmres);
+extern bool zheap_scan_bitmap_next_tuple(TableScanDesc sscan, struct TBMIterateResult *tbmres, struct TupleTableSlot *slot);
+
+extern ZHeapTuple zheap_search_buffer(ItemPointer tid, Relation relation,
+									  Buffer buffer, Snapshot snapshot, bool *all_dead);
+extern bool zheap_fetch(Relation relation, Snapshot snapshot,
+						ItemPointer tid, ZHeapTuple *tuple, Buffer *userbuf,
+						bool keep_buf);
+
+#endif							/* ZHEAPSCAN_H */
diff --git a/src/include/access/zhio.h b/src/include/access/zhio.h
new file mode 100644
index 0000000..ae0017b
--- /dev/null
+++ b/src/include/access/zhio.h
@@ -0,0 +1,26 @@
+/*-------------------------------------------------------------------------
+ *
+ * hio.h
+ *	  POSTGRES zheap access method input/output definitions.
+ *
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * src/include/access/zhio.h
+ *
+ *-------------------------------------------------------------------------
+ */
+#ifndef ZHIO_H
+#define ZHIO_H
+
+#include "utils/relcache.h"
+#include "storage/buf.h"
+
+
+extern Buffer RelationGetBufferForZTuple(Relation relation, Size len,
+										 Buffer otherBuffer, int options,
+										 BulkInsertState bistate,
+										 Buffer *vmbuffer, Buffer *vmbuffer_other);
+
+#endif							/* ZHIO_H */
diff --git a/src/include/access/zhtup.h b/src/include/access/zhtup.h
new file mode 100644
index 0000000..c4ffb55
--- /dev/null
+++ b/src/include/access/zhtup.h
@@ -0,0 +1,331 @@
+/*-------------------------------------------------------------------------
+ *
+ * zhtup.h
+ *	  POSTGRES zheap tuple header definitions.
+ *
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * src/include/access/zhtup.h
+ *
+ *-------------------------------------------------------------------------
+ */
+#ifndef ZHTUP_H
+#define ZHTUP_H
+
+#include "access/tupdesc.h"
+#include "access/tupmacs.h"
+#include "access/transam.h"
+#include "access/undolog.h"
+#include "access/undorecord.h"
+#include "executor/tuptable.h"
+#include "nodes/lockoptions.h"
+#include "storage/bufpage.h"
+#include "storage/buf.h"
+#include "storage/itemptr.h"
+
+/* valid values for transaction slot is between 0 and ZHEAP_PAGE_TRANS_SLOTS */
+#define InvalidXactSlotId	(-1)
+/* we use frozen slot to indicate that the tuple is all visible now */
+#define	ZHTUP_SLOT_FROZEN	0x000
+
+typedef struct ZMultiLockMember
+{
+	TransactionId xid;
+	SubTransactionId subxid;
+	int			trans_slot_id;
+	LockTupleMode mode;
+} ZMultiLockMember;
+
+ /*
+  * Possible lock modes for a tuple.
+  */
+typedef enum LockOper
+{
+	/* SELECT FOR 'KEY SHARE/SHARE/NO KEY UPDATE/UPDATE' */
+	LockOnly,
+	/* Via EvalPlanQual where after locking we will update it */
+	LockForUpdate,
+	/* Update/Delete */
+	ForUpdate
+} LockOper;
+
+/*
+ * Heap tuple header.  To avoid wasting space, the fields should be
+ * laid out in such a way as to avoid structure padding.
+ *
+ * Following the fixed header fields, the nulls bitmap is stored (beginning
+ * at t_bits).  The bitmap is *not* stored if t_infomask shows that there
+ * are no nulls in the tuple.  If an OID field is present (as indicated by
+ * t_infomask), then it is stored just before the user data, which begins at
+ * the offset shown by t_hoff.  Note that t_hoff must be a multiple of
+ * MAXALIGN.
+ */
+
+typedef struct ZHeapTupleHeaderData
+{
+	uint16		t_infomask2;	/* number of attributes + translot info +
+								 * various flags */
+
+	uint16		t_infomask;		/* various flag bits, see below */
+
+	uint8		t_hoff;			/* sizeof header incl. bitmap, padding */
+
+	/* ^ - 5 bytes - ^ */
+
+	bits8		t_bits[FLEXIBLE_ARRAY_MEMBER];	/* bitmap of NULLs */
+
+	/* MORE DATA FOLLOWS AT END OF STRUCT */
+} ZHeapTupleHeaderData;
+
+typedef ZHeapTupleHeaderData *ZHeapTupleHeader;
+
+#define SizeofZHeapTupleHeader offsetof(ZHeapTupleHeaderData, t_bits)
+
+typedef struct ZHeapTupleData
+{
+	uint32		t_len;			/* length of *t_data */
+	ItemPointerData t_self;		/* SelfItemPointer */
+	Oid			t_tableOid;		/* table the tuple came from */
+	ZHeapTupleHeader t_data;	/* -> tuple header and data */
+} ZHeapTupleData;
+
+typedef ZHeapTupleData *ZHeapTuple;
+
+#define ZHEAPTUPLESIZE	MAXALIGN(sizeof(ZHeapTupleData))
+
+/*
+ * Accessor macros to be used with ZHeapTuple pointers.
+ */
+#define ZHeapTupleIsValid(tuple) PointerIsValid(tuple)
+
+/*
+ * information stored in t_infomask:
+ */
+#define ZHEAP_HASNULL			0x0001	/* has null attribute(s) */
+#define ZHEAP_HASVARWIDTH		0x0002	/* has variable-width attribute(s) */
+#define ZHEAP_HASEXTERNAL		0x0004	/* has external stored attribute(s) */
+/* unused bits */
+#define	ZHEAP_DELETED			0x0010	/* tuple deleted */
+#define	ZHEAP_INPLACE_UPDATED	0x0020	/* tuple is updated inplace */
+#define	ZHEAP_UPDATED			0x0040	/* tuple is not updated inplace */
+#define ZHEAP_XID_LOCK_ONLY		0x0080	/* xid, if valid, is only a locker */
+
+#define ZHEAP_XID_KEYSHR_LOCK	0x0100	/* xid is a key-shared locker */
+#define ZHEAP_XID_NOKEY_EXCL_LOCK	0x0200	/* xid is a nokey-exclusive locker */
+ /* xid is a shared locker */
+#define ZHEAP_XID_SHR_LOCK	(ZHEAP_XID_NOKEY_EXCL_LOCK | ZHEAP_XID_KEYSHR_LOCK)
+#define ZHEAP_XID_EXCL_LOCK		0x0400	/* tuple was updated and key cols
+										 * modified, or tuple deleted */
+#define ZHEAP_MULTI_LOCKERS		0x0800	/* tuple was locked by multiple
+										 * lockers */
+#define ZHEAP_INVALID_XACT_SLOT	0x1000	/* transaction slot on tuple got
+										 * reused */
+#define ZHEAP_SPECULATIVE_INSERT	0x2000	/* tuple insertion is a
+											 * speculative insertion and can
+											 * be taken back */
+
+#define ZHEAP_MOVED		(ZHEAP_DELETED | ZHEAP_UPDATED) /* moved tuple to
+														 * another partition */
+#define ZHEAP_LOCK_MASK		(ZHEAP_XID_KEYSHR_LOCK | ZHEAP_XID_NOKEY_EXCL_LOCK | \
+							 ZHEAP_XID_SHR_LOCK | ZHEAP_XID_EXCL_LOCK)
+
+#define ZHEAP_VIS_STATUS_MASK	0x1FF0	/* mask for visibility bits (5 ~ 13
+										 * bits) */
+
+/*
+ * Use these to test whether a particular lock is applied to a tuple
+ */
+#define ZHEAP_XID_IS_KEYSHR_LOCKED(infomask) \
+	(((infomask) & ZHEAP_LOCK_MASK) == ZHEAP_XID_KEYSHR_LOCK)
+#define ZHEAP_XID_IS_NOKEY_EXCL_LOCKED(infomask) \
+	(((infomask) & ZHEAP_LOCK_MASK) == ZHEAP_XID_NOKEY_EXCL_LOCK)
+#define ZHEAP_XID_IS_SHR_LOCKED(infomask) \
+	(((infomask) & ZHEAP_LOCK_MASK) == ZHEAP_XID_SHR_LOCK)
+#define ZHEAP_XID_IS_EXCL_LOCKED(infomask) \
+	(((infomask) & ZHEAP_LOCK_MASK) == ZHEAP_XID_EXCL_LOCK)
+
+/*
+ * information stored in t_infomask2:
+ */
+#define ZHEAP_NATTS_MASK			0x07FF	/* 11 bits for number of
+											 * attributes */
+#define ZHEAP_XACT_SLOT				0xF800	/* 5 bits (12, 13, 14, 15 and 16)
+											 * for transaction slot */
+#define	ZHEAP_XACT_SLOT_SHIFT		0x000B	/* 11 - mask to retrieve
+											 * transaction slot */
+
+#define ZHeapTupleHasExternal(tuple) \
+		(((tuple)->t_data->t_infomask & ZHEAP_HASEXTERNAL) != 0)
+
+#define ZHEAP_XID_IS_LOCKED_ONLY(infomask) \
+( \
+	((infomask) & ZHEAP_XID_LOCK_ONLY) != 0 \
+)
+
+#define ZHeapTupleHasMultiLockers(infomask) \
+( \
+	((infomask) & ZHEAP_MULTI_LOCKERS) != 0 \
+)
+
+#define ZHeapTupleIsInPlaceUpdated(infomask) \
+( \
+  (infomask & ZHEAP_INPLACE_UPDATED) != 0 \
+)
+
+#define ZHeapTupleIsUpdated(infomask) \
+( \
+  (infomask & ZHEAP_UPDATED) != 0 \
+)
+
+#define ZHeapTupleIsMoved(infomask) \
+( \
+  (infomask & ZHEAP_MOVED) == ZHEAP_MOVED \
+)
+
+#define ZHeapTupleHasInvalidXact(infomask) \
+( \
+	(infomask & ZHEAP_INVALID_XACT_SLOT) != 0 \
+)
+
+#define ZHeapTupleHeaderIsSpeculative(tup) \
+( \
+	(tup->t_infomask & ZHEAP_SPECULATIVE_INSERT) \
+)
+
+#define ZHeapTupleHeaderGetNatts(tup) \
+( \
+	((tup)->t_infomask2 & ZHEAP_NATTS_MASK) \
+)
+
+#define ZHeapTupleHeaderSetNatts(tup, natts) \
+( \
+	(tup)->t_infomask2 = ((tup)->t_infomask2 & ~ZHEAP_NATTS_MASK) | (natts) \
+)
+
+#define ZHeapTupleHeaderGetXactSlot(tup) \
+( \
+	(((tup)->t_infomask2 & ZHEAP_XACT_SLOT) >> ZHEAP_XACT_SLOT_SHIFT) \
+)
+
+static inline
+void
+ZHeapTupleHeaderSetXactSlot(ZHeapTupleHeader tup, int slotno)
+{
+	/*
+	 * The slots that belongs to TPD entry always point to last slot on the
+	 * page.
+	 */
+	if (slotno > ZHEAP_PAGE_TRANS_SLOTS)
+		slotno = ZHEAP_PAGE_TRANS_SLOTS;
+
+	(tup)->t_infomask2 = ((tup)->t_infomask2 & ~ZHEAP_XACT_SLOT) |
+		(slotno << ZHEAP_XACT_SLOT_SHIFT);
+}
+
+#define ZHeapTupleHeaderSetMovedPartitions(tup) \
+( \
+	(tup)->t_infomask |= ZHEAP_MOVED \
+)
+
+/*
+ * Accessor macros to be used with ZHeapTuple pointers.
+ */
+
+#define ZHeapTupleHasNulls(tuple) \
+		(((tuple)->t_data->t_infomask & ZHEAP_HASNULL) != 0)
+
+#define ZHeapTupleNoNulls(tuple) \
+		(!((tuple)->t_data->t_infomask & ZHEAP_HASNULL))
+
+#define ZHeapTupleHasVarWidth(tuple) \
+		(((tuple)->t_data->t_infomask & ZHEAP_HASVARWIDTH) != 0)
+
+#define ZHeapTupleDeleted(tup_data) \
+		((tup_data->t_infomask & (ZHEAP_DELETED | ZHEAP_UPDATED)) != 0)
+
+#define IsZHeapTupleModified(t_infomask) \
+( \
+	((t_infomask & ZHEAP_DELETED || \
+	 t_infomask & ZHEAP_UPDATED || \
+	 t_infomask & ZHEAP_INPLACE_UPDATED || \
+	 t_infomask & ZHEAP_XID_LOCK_ONLY) != 0) \
+)
+
+extern Size zheap_compute_data_size(TupleDesc tupleDesc, Datum *values,
+									bool *isnull, int t_hoff);
+extern void zheap_fill_tuple(TupleDesc tupleDesc,
+							 Datum *values, bool *isnull,
+							 char *data, Size data_size,
+							 uint16 *infomask, bits8 *bit);
+extern ZHeapTuple zheap_form_tuple(TupleDesc tupleDescriptor,
+								   Datum *values, bool *isnull);
+extern void zheap_deform_tuple(ZHeapTuple tuple, TupleDesc tupleDesc,
+							   Datum *values, bool *isnull, int atts_count);
+extern void zheap_freetuple(ZHeapTuple zhtup);
+extern Datum zheap_getsysattr(ZHeapTuple zhtup, Buffer buf, int attnum,
+							  TupleDesc tupleDesc, bool *isnull);
+extern bool zheap_attisnull(ZHeapTuple tup, int attnum, TupleDesc tupleDesc);
+extern Bitmapset *zheap_tuple_attr_equals(TupleDesc tupdesc, Bitmapset *att_list,
+										  ZHeapTuple tup1, ZHeapTuple tup2);
+
+/* Tuple table slot related API's that are specific zheap tuples. */
+typedef struct ZHeapTupleTableSlot
+{
+	TupleTableSlot base;
+	ZHeapTuple	tuple;			/* physical tuple */
+	ZHeapTupleData tupdata;
+	uint32		off;			/* saved state for slot_deform_tuple */
+} ZHeapTupleTableSlot;
+
+struct TupleTableSlot;
+extern void slot_deform_ztuple(struct TupleTableSlot *slot, ZHeapTuple tuple,
+							   uint32 *offp, int natts);
+extern ZHeapTuple ExecGetZHeapTupleFromSlot(struct TupleTableSlot *slot);
+extern struct TupleTableSlot *ExecStoreZHeapTuple(ZHeapTuple tuple,
+												  struct TupleTableSlot *slot, bool shouldFree);
+extern PGDLLIMPORT const TupleTableSlotOps TTSOpsZHeapTuple;
+#define TTS_IS_ZHEAP(slot) ((slot)->tts_ops == &TTSOpsZHeapTuple)
+
+extern ZHeapTuple zheap_copytuple(ZHeapTuple tuple);
+
+struct ZHeapTupleTransInfo;
+
+/* Zheap transaction information related API's */
+extern CommandId ZHeapTupleGetCid(ZHeapTuple zhtup, Buffer buf,
+								  UndoRecPtr urec_ptr, int trans_slot_id);
+extern void GetTransactionSlotInfo(Buffer buf, OffsetNumber offset,
+								   int trans_slot_id,
+								   bool NoTPDBufLock, bool TPDSlot,
+								   struct ZHeapTupleTransInfo *zinfo);
+extern void ZHeapTupleGetSubXid(Buffer buf, OffsetNumber offnum,
+								UndoRecPtr urec_ptr, SubTransactionId *subxid);
+extern void ZHeapTupleGetSpecToken(ZHeapTuple zhtup, Buffer buf,
+								   UndoRecPtr urec_ptr, uint32 *specToken);
+
+/* Page related API's. */
+
+/*
+ * MaxZHeapTupFixedSize - Fixed size for tuple, this is computed based
+ * on data alignment.
+ */
+#define MaxZHeapTupFixedSize \
+			(SizeofZHeapTupleHeader  + sizeof(ItemIdData))
+
+
+/* MaxZHeapPageFixedSpace - Maximum fixed size for page */
+#define MaxZHeapPageFixedSpace \
+	(BLCKSZ - SizeOfPageHeaderData - SizeOfZHeapPageOpaqueData)
+/*
+ * MaxZHeapTuplesPerPage is an upper bound on the number of tuples that can
+ * fit on one zheap page.
+ */
+#define MaxZHeapTuplesPerPage	\
+	((int) ((MaxZHeapPageFixedSpace) / \
+			(MaxZHeapTupFixedSize)))
+
+#define MaxZHeapTupleSize  (BLCKSZ - MAXALIGN(SizeOfPageHeaderData + SizeOfZHeapPageOpaqueData + sizeof(ItemIdData)))
+#define MinZHeapTupleSize  MAXALIGN(SizeofZHeapTupleHeader)
+
+#endif							/* ZHTUP_H */
diff --git a/src/include/access/zmultilocker.h b/src/include/access/zmultilocker.h
new file mode 100644
index 0000000..8bebb5d
--- /dev/null
+++ b/src/include/access/zmultilocker.h
@@ -0,0 +1,90 @@
+/*-------------------------------------------------------------------------
+ *
+ * zmultilocker.h
+ *	  POSTGRES zheap multi locker function definitions.
+ *
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * src/include/access/zmultilocker.h
+ *
+ *-------------------------------------------------------------------------
+ */
+#ifndef ZMULTILOCKER_H
+#define ZMULTILOCKER_H
+
+#include "postgres.h"
+
+#include "access/zhtup.h"
+#include "storage/lmgr.h"
+#include "utils/rel.h"
+
+/* Get the LOCKMODE for a given LockTupleMode */
+#define HWLOCKMODE_from_locktupmode(lockmode) \
+				(GetHWLockModeFromMode(lockmode))
+
+extern bool ZCurrentXactHasTupleLockMode(ZHeapTuple zhtup,
+										 UndoRecPtr urec_ptr, LockTupleMode required_mode);
+extern List *ZGetMultiLockMembers(Relation rel, ZHeapTuple zhtup, Buffer buf,
+								  bool nobuflock);
+extern bool ZMultiLockMembersWait(Relation rel, List *mlmembers,
+								  ZHeapTuple zhtup, Buffer buf, TransactionId update_xact,
+								  LockTupleMode required_mode, bool nowait, XLTW_Oper oper,
+								  int *remaining, bool *upd_xact_aborted);
+extern bool ConditionalZMultiLockMembersWait(Relation rel, List *mlmembers,
+											 Buffer buf, TransactionId update_xact,
+											 LockTupleMode required_mode, int *remaining,
+											 bool *upd_xact_aborted);
+extern bool ZIsAnyMultiLockMemberRunning(Relation rel, int xwait_trans_slot,
+										 List *mlmembers, ZHeapTuple zhtup,
+										 Buffer buf, bool *pending_actions_applied);
+extern bool ZMultiLockMembersSame(List *old_members, List *new_members);
+extern void ZGetMultiLockInfo(uint16 old_infomask, TransactionId tup_xid,
+							  int tup_trans_slot, TransactionId add_to_xid,
+							  uint16 *new_infomask, int *new_trans_slot,
+							  LockTupleMode *mode, bool *old_tuple_has_update,
+							  LockOper lockoper);
+extern bool GetLockerTransInfo(Relation rel, ItemPointer tid, Buffer buf,
+							   int *trans_slot, FullTransactionId *fxid_out);
+
+static inline LockTupleMode
+get_old_lock_mode(uint16 infomask)
+{
+	LockTupleMode old_lock_mode;
+
+	/*
+	 * Normally, if the tuple is not marked as locked only, it should not
+	 * contain any locker information. But, during rollback of
+	 * (in-)update/delete, we retain the multilocker information. See
+	 * execute_undo_actions_page for details.
+	 */
+	if (ZHEAP_XID_IS_LOCKED_ONLY(infomask) || !IsZHeapTupleModified(infomask))
+	{
+		if (ZHEAP_XID_IS_KEYSHR_LOCKED(infomask))
+			old_lock_mode = LockTupleKeyShare;
+		else if (ZHEAP_XID_IS_SHR_LOCKED(infomask))
+			old_lock_mode = LockTupleShare;
+		else if (ZHEAP_XID_IS_NOKEY_EXCL_LOCKED(infomask))
+			old_lock_mode = LockTupleNoKeyExclusive;
+		else if (ZHEAP_XID_IS_EXCL_LOCKED(infomask))
+			old_lock_mode = LockTupleExclusive;
+		else
+		{
+			/* LOCK_ONLY can't be present alone */
+			pg_unreachable();
+		}
+	}
+	else
+	{
+		/* it's an update, but which kind? */
+		if (infomask & ZHEAP_XID_EXCL_LOCK)
+			old_lock_mode = LockTupleExclusive;
+		else
+			old_lock_mode = LockTupleNoKeyExclusive;
+	}
+
+	return old_lock_mode;
+}
+
+#endif							/* ZMULTILOCKER_H */
diff --git a/src/include/catalog/pg_am.dat b/src/include/catalog/pg_am.dat
index 393b41d..cbe20cc 100644
--- a/src/include/catalog/pg_am.dat
+++ b/src/include/catalog/pg_am.dat
@@ -33,5 +33,9 @@
 { oid => '3580', oid_symbol => 'BRIN_AM_OID',
   descr => 'block range index (BRIN) access method',
   amname => 'brin', amhandler => 'brinhandler', amtype => 'i' },
+{ oid => '8193', oid_symbol => 'ZHEAP_TABLE_AM_OID',
+  descr => 'zheap table access method',
+  amname => 'zheap', amhandler => 'zheap_tableam_handler', amtype => 't' },
+
 
 ]
diff --git a/src/include/catalog/pg_control.h b/src/include/catalog/pg_control.h
index babcc6b..0537dd2 100644
--- a/src/include/catalog/pg_control.h
+++ b/src/include/catalog/pg_control.h
@@ -231,6 +231,18 @@ typedef struct ControlFileData
 	uint32		data_checksum_version;
 
 	/*
+	 * Number of transaction slots per zheap page
+	 *
+	 * FIXME: We've added this parameter in control file only to check whether
+	 * cluster and server have been configured with the same value. The value
+	 * of this option can be checked with bin/pg_controldata. To avoid catalog
+	 * changes, we've not added this parameter in pg_control_init. This is a
+	 * temporary parameter required for performance testing of zheap. In
+	 * future, it'll be removed.
+	 */
+	uint32		zheap_page_trans_slots;
+
+	/*
 	 * Random nonce, used in authentication requests that need to proceed
 	 * based on values that are cluster-unique, like a SASL exchange that
 	 * failed at an early stage.
diff --git a/src/include/catalog/pg_proc.dat b/src/include/catalog/pg_proc.dat
index de475cb..25dffa4 100644
--- a/src/include/catalog/pg_proc.dat
+++ b/src/include/catalog/pg_proc.dat
@@ -873,6 +873,10 @@
   proname => 'heap_tableam_handler', provolatile => 'v',
   prorettype => 'table_am_handler', proargtypes => 'internal',
   prosrc => 'heap_tableam_handler' },
+{ oid => '8192', oid_symbol => 'ZHEAP_TABLE_AM_HANDLER_OID',
+  descr => 'row-oriented, undo based, heap table access method handler',
+  proname => 'zheap_tableam_handler', provolatile => 'v', prorettype => 'table_am_handler',
+  proargtypes => 'internal', prosrc => 'zheap_tableam_handler' },
 
 # Index access method handlers
 { oid => '330', descr => 'btree index access method handler',
@@ -10582,6 +10586,15 @@
   proname => 'pg_relation_is_publishable', provolatile => 's',
   prorettype => 'bool', proargtypes => 'regclass',
   prosrc => 'pg_relation_is_publishable' },
+{ oid => '6122', descr => 'statistics: number of inplace updates performed',
+  proname => 'pg_stat_get_tuples_inplace_updated', provolatile => 's', proparallel => 'r',
+  prorettype => 'int8', proargtypes => 'oid',
+  prosrc => 'pg_stat_get_tuples_inplace_updated' },
+{ oid => '6123',
+  descr => 'statistics: number of inplace updates performed in current transaction',
+  proname => 'pg_stat_get_xact_tuples_inplace_updated', provolatile => 'v',
+  proparallel => 'r', prorettype => 'int8', proargtypes => 'oid',
+  prosrc => 'pg_stat_get_xact_tuples_inplace_updated' },
 
 # rls
 { oid => '3298',
@@ -10613,9 +10626,9 @@
   descr => 'pg_controldata checkpoint state information as a function',
   proname => 'pg_control_checkpoint', provolatile => 'v',
   prorettype => 'record', proargtypes => '',
-  proallargtypes => '{pg_lsn,pg_lsn,text,int4,int4,bool,text,oid,xid,xid,xid,oid,xid,xid,oid,xid,xid,timestamptz}',
-  proargmodes => '{o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o}',
-  proargnames => '{checkpoint_lsn,redo_lsn,redo_wal_file,timeline_id,prev_timeline_id,full_page_writes,next_xid,next_oid,next_multixact_id,next_multi_offset,oldest_xid,oldest_xid_dbid,oldest_active_xid,oldest_multi_xid,oldest_multi_dbid,oldest_commit_ts_xid,newest_commit_ts_xid,checkpoint_time}',
+  proallargtypes => '{pg_lsn,pg_lsn,text,int4,int4,bool,text,oid,xid,xid,xid,oid,xid,xid,oid,xid,xid,timestamptz,int8}',
+  proargmodes => '{o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o}',
+  proargnames => '{checkpoint_lsn,redo_lsn,redo_wal_file,timeline_id,prev_timeline_id,full_page_writes,next_xid,next_oid,next_multixact_id,next_multi_offset,oldest_xid,oldest_xid_dbid,oldest_active_xid,oldest_multi_xid,oldest_multi_dbid,oldest_commit_ts_xid,newest_commit_ts_xid,checkpoint_time,oldest_xid_with_epoch_having_undo}',
   prosrc => 'pg_control_checkpoint' },
 
 { oid => '3443',
diff --git a/src/include/commands/vacuum.h b/src/include/commands/vacuum.h
index 128f7ae..880988a 100644
--- a/src/include/commands/vacuum.h
+++ b/src/include/commands/vacuum.h
@@ -14,6 +14,7 @@
 #ifndef VACUUM_H
 #define VACUUM_H
 
+#include "access/amapi.h"
 #include "access/htup.h"
 #include "catalog/pg_class.h"
 #include "catalog/pg_statistic.h"
@@ -23,6 +24,14 @@
 #include "storage/lock.h"
 #include "utils/relcache.h"
 
+/*
+ * When a table has no indexes, vacuum the FSM after every 8GB, approximately
+ * (it won't be exact because we only vacuum FSM after processing a heap/zheap
+ * page that has some removable tuples).  When there are indexes, this is
+ * ignored, and we vacuum FSM after each index/heap cleaning pass.
+ */
+#define VACUUM_FSM_EVERY_PAGES \
+	((BlockNumber) (((uint64) 8 * 1024 * 1024 * 1024) / BLCKSZ))
 
 /*----------
  * ANALYZE builds one of these structs for each attribute (column) that is
@@ -186,6 +195,34 @@ typedef struct VacuumParams
 									 * default value depends on reloptions */
 } VacuumParams;
 
+typedef struct LVRelStats
+{
+	/* useindex = true means two-pass strategy; false means one-pass */
+	bool		useindex;
+	/* Overall statistics about rel */
+	BlockNumber old_rel_pages;	/* previous value of pg_class.relpages */
+	BlockNumber rel_pages;		/* total number of pages */
+	BlockNumber scanned_pages;	/* number of pages we examined */
+	BlockNumber pinskipped_pages;	/* # of pages we skipped due to a pin */
+	BlockNumber frozenskipped_pages;	/* # of frozen pages we skipped */
+	BlockNumber tupcount_pages; /* pages whose tuples we counted */
+	double		old_live_tuples;	/* previous value of pg_class.reltuples */
+	double		new_rel_tuples; /* new estimated total # of tuples */
+	double		new_live_tuples;	/* new estimated total # of live tuples */
+	double		new_dead_tuples;	/* new estimated total # of dead tuples */
+	BlockNumber pages_removed;
+	double		tuples_deleted;
+	BlockNumber nonempty_pages; /* actually, last nonempty page + 1 */
+	/* List of TIDs of tuples we intend to delete */
+	/* NB: this list is ordered by TID address */
+	int			num_dead_tuples;	/* current # of entries */
+	int			max_dead_tuples;	/* # slots allocated in array */
+	ItemPointer dead_tuples;	/* array of ItemPointerData */
+	int			num_index_scans;
+	TransactionId latestRemovedXid;
+	bool		lock_waiter_detected;
+} LVRelStats;
+
 /* GUC parameters */
 extern PGDLLIMPORT int default_statistics_target;	/* PGDLLIMPORT for PostGIS */
 extern int	vacuum_freeze_min_age;
diff --git a/src/include/executor/tuptable.h b/src/include/executor/tuptable.h
index 203b1ab..2340f2d 100644
--- a/src/include/executor/tuptable.h
+++ b/src/include/executor/tuptable.h
@@ -230,7 +230,6 @@ extern PGDLLIMPORT const TupleTableSlotOps TTSOpsBufferHeapTuple;
 #define TTS_IS_MINIMALTUPLE(slot) ((slot)->tts_ops == &TTSOpsMinimalTuple)
 #define TTS_IS_BUFFERTUPLE(slot) ((slot)->tts_ops == &TTSOpsBufferHeapTuple)
 
-
 /*
  * Tuple table slot implementations.
  */
diff --git a/src/include/lib/stringinfo.h b/src/include/lib/stringinfo.h
index c484277..24e8433 100644
--- a/src/include/lib/stringinfo.h
+++ b/src/include/lib/stringinfo.h
@@ -152,6 +152,14 @@ extern void appendBinaryStringInfoNT(StringInfo str,
 									 const char *data, int datalen);
 
 /*------------------------
+ * appendBinaryStringInfo
+ * Append arbitrary binary data to a StringInfo, fail if more space
+ * is required.
+ */
+extern bool appendBinaryStringInfoNoExtend(StringInfo str,
+										   const char *data, int datalen);
+
+/*------------------------
  * enlargeStringInfo
  * Make sure a StringInfo's buffer can hold at least 'needed' more bytes.
  */
diff --git a/src/include/miscadmin.h b/src/include/miscadmin.h
index 388dc97..fc27ffc 100644
--- a/src/include/miscadmin.h
+++ b/src/include/miscadmin.h
@@ -170,6 +170,8 @@ extern PGDLLIMPORT struct Latch *MyLatch;
 extern int32 MyCancelKey;
 extern int	MyPMChildSlot;
 
+extern bool applying_subxact_undo;
+
 extern char OutputFileName[];
 extern PGDLLIMPORT char my_exec_path[];
 extern char pkglib_path[];
@@ -424,6 +426,7 @@ extern AuxProcType MyAuxProcType;
  *****************************************************************************/
 
 /* in utils/init/postinit.c */
+extern bool dbid_exists(Oid dboid);
 extern void pg_split_opts(char **argv, int *argcp, const char *optstr);
 extern void InitializeMaxBackends(void);
 extern void InitPostgres(const char *in_dbname, Oid dboid, const char *username,
diff --git a/src/include/nodes/lockoptions.h b/src/include/nodes/lockoptions.h
index 8e8ccff..4bbc6e3 100644
--- a/src/include/nodes/lockoptions.h
+++ b/src/include/nodes/lockoptions.h
@@ -43,6 +43,8 @@ typedef enum LockWaitPolicy
 	LockWaitError
 } LockWaitPolicy;
 
+#define MaxLockTupleMode	LockTupleExclusive
+
 /*
  * Possible lock modes for a tuple.
  */
@@ -58,4 +60,11 @@ typedef enum LockTupleMode
 	LockTupleExclusive
 } LockTupleMode;
 
+/*  ZBORKED: Why is the eval flag needed, and what's it's actual documentation? */
+/*  Because surely */
+/*   *	eval - indicates whether the tuple will be evaluated to see if it still */
+/*   *	matches the qualification. */
+/*  isn't very descriptive. */
+#define TUPLE_LOCK_FLAG_WEIRD					(1 << 2)
+
 #endif							/* LOCKOPTIONS_H */
diff --git a/src/include/pg_config.h.in b/src/include/pg_config.h.in
index 512213a..1c5d5d7 100644
--- a/src/include/pg_config.h.in
+++ b/src/include/pg_config.h.in
@@ -993,6 +993,10 @@
    */
 #undef XLOG_BLCKSZ
 
+/* transaction slots per zheap page. By default, it is set to 4. Changing
+   ZHEAP_PAGE_TRANS_SLOTS requires an initdb. */
+#undef ZHEAP_PAGE_TRANS_SLOTS
+
 
 
 /* Number of bits in a file offset, on hosts where this is settable. */
diff --git a/src/include/pgstat.h b/src/include/pgstat.h
index f9dc0bb..b1afc95 100644
--- a/src/include/pgstat.h
+++ b/src/include/pgstat.h
@@ -89,7 +89,7 @@ typedef int64 PgStat_Counter;
  * the index AM, while tuples_fetched is the number of tuples successfully
  * fetched by heap_fetch under the control of simple indexscans for this index.
  *
- * tuples_inserted/updated/deleted/hot_updated count attempted actions,
+ * tuples_inserted/updated/deleted/hot_updated/inplace_updated count attempted actions,
  * regardless of whether the transaction committed.  delta_live_tuples,
  * delta_dead_tuples, and changed_tuples are set depending on commit or abort.
  * Note that delta_live_tuples and delta_dead_tuples can be negative!
@@ -104,6 +104,7 @@ typedef struct PgStat_TableCounts
 
 	PgStat_Counter t_tuples_inserted;
 	PgStat_Counter t_tuples_updated;
+	PgStat_Counter t_tuples_inplace_updated;
 	PgStat_Counter t_tuples_deleted;
 	PgStat_Counter t_tuples_hot_updated;
 	bool		t_truncated;
@@ -166,12 +167,16 @@ typedef struct PgStat_TableStatus
 typedef struct PgStat_TableXactStatus
 {
 	PgStat_Counter tuples_inserted; /* tuples inserted in (sub)xact */
-	PgStat_Counter tuples_updated;	/* tuples updated in (sub)xact */
+	PgStat_Counter tuples_updated;	/* tuples non-inplace updated in (sub)xact */
+	PgStat_Counter tuples_inplace_updated;	/* tuples inplace updated in
+											 * (sub)xact */
 	PgStat_Counter tuples_deleted;	/* tuples deleted in (sub)xact */
 	bool		truncated;		/* relation truncated in this (sub)xact */
 	PgStat_Counter inserted_pre_trunc;	/* tuples inserted prior to truncate */
 	PgStat_Counter updated_pre_trunc;	/* tuples updated prior to truncate */
 	PgStat_Counter deleted_pre_trunc;	/* tuples deleted prior to truncate */
+	PgStat_Counter inplace_pre_trunc;	/* tuples inplace updated prior to
+										 * truncate */
 	int			nest_level;		/* subtransaction nest level */
 	/* links to other structs for same relation: */
 	struct PgStat_TableXactStatus *upper;	/* next higher subxact if any */
@@ -641,7 +646,9 @@ typedef struct PgStat_StatTabEntry
 
 	PgStat_Counter tuples_inserted;
 	PgStat_Counter tuples_updated;
+	PgStat_Counter tuples_inplace_updated;
 	PgStat_Counter tuples_deleted;
+
 	PgStat_Counter tuples_hot_updated;
 
 	PgStat_Counter n_live_tuples;
@@ -761,6 +768,8 @@ typedef enum BackendState
 #define PG_WAIT_IPC					0x08000000U
 #define PG_WAIT_TIMEOUT				0x09000000U
 #define PG_WAIT_IO					0x0A000000U
+#define PG_WAIT_PAGE_TRANS_SLOT		0x0B000000U
+#define PG_WAIT_ROLLBACK_HT			0x0C000000U
 
 /* ----------
  * Wait Events - Activity
@@ -1409,6 +1418,7 @@ pgstat_report_wait_end(void)
 
 extern void pgstat_count_heap_insert(Relation rel, PgStat_Counter n);
 extern void pgstat_count_heap_update(Relation rel, bool hot);
+extern void pgstat_count_zheap_update(Relation rel);
 extern void pgstat_count_heap_delete(Relation rel);
 extern void pgstat_count_truncate(Relation rel);
 extern void pgstat_update_heap_dead_tuples(Relation rel, int delta);
diff --git a/src/include/postgres.h b/src/include/postgres.h
index 057a341..c756951 100644
--- a/src/include/postgres.h
+++ b/src/include/postgres.h
@@ -348,6 +348,13 @@ typedef struct
 #define VARDATA_ANY(PTR) \
 	 (VARATT_IS_1B(PTR) ? VARDATA_1B(PTR) : VARDATA_4B(PTR))
 
+/* Does att's datatype allow packing into the 1-byte-header varlena format? */
+#define ATT_IS_PACKABLE(att) \
+	((att)->attlen == -1 && (att)->attstorage != 'p')
+
+/* Use this if it's already known varlena */
+#define VARLENA_ATT_IS_PACKABLE(att) \
+	((att)->attstorage != 'p')
 
 /* ----------------------------------------------------------------
  *				Section 2:	Datum type + support macros
diff --git a/src/include/storage/bufpage.h b/src/include/storage/bufpage.h
index 93d108c..c2040d6 100644
--- a/src/include/storage/bufpage.h
+++ b/src/include/storage/bufpage.h
@@ -16,6 +16,7 @@
 
 #include "access/xlogdefs.h"
 #include "storage/block.h"
+#include "storage/buf.h"
 #include "storage/item.h"
 #include "storage/off.h"
 
@@ -166,6 +167,12 @@ typedef struct PageHeaderData
 typedef PageHeaderData *PageHeader;
 
 /*
+ * We cannot include storage/procarray.h here, otherwise it creates cyclic
+ * dependency. So declaring TransactionIdIsInProgress again.
+ */
+extern bool TransactionIdIsInProgress(TransactionId xid);
+
+/*
  * pd_flags contains the following flag bits.  Undefined bits are initialized
  * to zero and may be used in the future.
  *
@@ -199,6 +206,18 @@ typedef PageHeaderData *PageHeader;
 #define PG_PAGE_LAYOUT_VERSION		4
 #define PG_DATA_CHECKSUM_VERSION	1
 
+/*
+ * sorting support for PageRepairFragmentation and PageIndexMultiDelete
+ */
+typedef struct itemIdSortData
+{
+	uint16		offsetindex;	/* linp array index */
+	int16		itemoff;		/* page offset of item data */
+	uint16		alignedlen;		/* MAXALIGN(item data len) */
+} itemIdSortData;
+typedef itemIdSortData *itemIdSort;
+
+
 /* ----------------------------------------------------------------
  *						page support macros
  * ----------------------------------------------------------------
@@ -442,6 +461,20 @@ do { \
 #define PageClearPrunable(page) \
 	(((PageHeader) (page))->pd_prune_xid = InvalidTransactionId)
 
+#define ZPageIsPrunable(page) \
+( \
+	TransactionIdIsValid(((PageHeader) (page))->pd_prune_xid) && \
+	!TransactionIdIsInProgress(((PageHeader) (page))->pd_prune_xid) \
+)
+#define ZPageSetPrunable(page, xid) \
+do { \
+	Assert(TransactionIdIsNormal(xid)); \
+	if (!TransactionIdIsValid(((PageHeader) (page))->pd_prune_xid) || \
+		TransactionIdIsInProgress(((PageHeader) (page))->pd_prune_xid) || \
+		TransactionIdPrecedes(xid, ((PageHeader) (page))->pd_prune_xid)) \
+		((PageHeader) (page))->pd_prune_xid = (xid); \
+} while (0)
+#define ZPageClearPrunable(page) PageClearPrunable(page)
 
 /* ----------------------------------------------------------------
  *		extern declarations
@@ -466,6 +499,7 @@ extern Page PageGetTempPage(Page page);
 extern Page PageGetTempPageCopy(Page page);
 extern Page PageGetTempPageCopySpecial(Page page);
 extern void PageRestoreTempPage(Page tempPage, Page oldPage);
+extern void compactify_tuples(itemIdSort itemidbase, int nitems, Page page);
 extern void PageRepairFragmentation(Page page);
 extern Size PageGetFreeSpace(Page page);
 extern Size PageGetFreeSpaceForMultipleTuples(Page page, int ntups);
diff --git a/src/include/storage/itemid.h b/src/include/storage/itemid.h
index ad232fb..004763e 100644
--- a/src/include/storage/itemid.h
+++ b/src/include/storage/itemid.h
@@ -41,6 +41,20 @@ typedef ItemIdData *ItemId;
 #define LP_DEAD			3		/* dead, may or may not have storage */
 
 /*
+ * Flags used in zheap.  These flags are used in a line pointer of a deleted
+ * item that has no actual storage.  These help in fetching the tuple from
+ * undo when required.
+ */
+#define ITEMID_DELETED	0x0001	/* Item is deleted */
+#define	ITEMID_XACT_INVALID	0x0002	/* transaction slot on tuple got reused */
+#define	ITEMID_XACT_PENDING	0x0003	/* transaction that has marked item as
+									 * unused is pending */
+#define VISIBILTY_MASK	0x007F	/* 7 bits (1..7) for visibility mask */
+#define XACT_SLOT		0x7F80	/* 8 bits (8..15) of offset for transaction
+								 * slot */
+#define XACT_SLOT_MASK	0x0007	/* 7 - mask to retrieve transaction slot */
+
+/*
  * Item offsets and lengths are represented by these types when
  * they're not actually stored in an ItemIdData.
  */
@@ -114,6 +128,13 @@ typedef uint16 ItemLength;
 	((itemId)->lp_flags == LP_DEAD)
 
 /*
+ * ItemIdIsDeleted
+ *		True iff item identifier is in state REDIRECT.
+ */
+#define ItemIdIsDeleted(itemId) \
+	((itemId)->lp_flags == LP_REDIRECT)
+
+/*
  * ItemIdHasStorage
  *		True iff item identifier has associated storage.
  */
@@ -145,6 +166,20 @@ typedef uint16 ItemLength;
 )
 
 /*
+ * ItemIdChangeLen
+ *		Change the length of itemid.
+ */
+#define ItemIdChangeLen(itemId, len) \
+	(itemId)->lp_len = (len)
+
+/*
+ * ItemIdChangeOff
+ * 		Change the Offset of itemid.
+ */
+#define ItemIdChangeOff(itemId, off) \
+	(itemId)->lp_off = (off)
+
+/*
  * ItemIdSetRedirect
  *		Set the item identifier to be REDIRECT, with the specified link.
  *		Beware of multiple evaluations of itemId!
@@ -157,6 +192,97 @@ typedef uint16 ItemLength;
 )
 
 /*
+ * ItemIdSetUnusedExtended
+ *		Set the item identifier to be UNUSED, with transaction slot
+ *		information.  The most significant 8 bits in offset are used to store
+ *		transaction slot information.  Such an item doesn't have any storage.
+ *		We don't allow such an item to be reused till the transaction that has
+ *		marked it as UNUSED is committed. Beware of multiple evaluations of
+ *		itemId!
+ */
+static inline
+void
+ItemIdSetUnusedExtended(ItemId itemId, int trans_slot)
+{
+	/*
+	 * The slots that belongs to TPD entry always point to last slot on the
+	 * page.
+	 */
+	if (trans_slot > ZHEAP_PAGE_TRANS_SLOTS)
+		trans_slot = ZHEAP_PAGE_TRANS_SLOTS;
+	itemId->lp_flags = LP_UNUSED;
+	itemId->lp_off = (itemId->lp_off & ~VISIBILTY_MASK) | ITEMID_XACT_PENDING;
+	itemId->lp_off = (itemId->lp_off & ~XACT_SLOT) | trans_slot << XACT_SLOT_MASK;
+	itemId->lp_len = 0;
+}
+
+/*
+ * ItemIdSetDeadExtended
+ *		Set the item identifier to be DEAD, with transaction slot
+ *		information.  The most significant 8 bits in offset are used to store
+ *		transaction slot information.  Such an item doesn't have any storage.
+ *		We do this to identify this happened in speculative abort case.
+ *		Beware of multiple evaluations of itemId!
+ */
+
+static inline
+void
+ItemIdSetDeadExtended(ItemId itemId, int trans_slot)
+{
+	/*
+	 * The slots that belongs to TPD entry always point to last slot on the
+	 * page.
+	 */
+	if (trans_slot > ZHEAP_PAGE_TRANS_SLOTS)
+		trans_slot = ZHEAP_PAGE_TRANS_SLOTS;
+	itemId->lp_flags = LP_DEAD;
+	itemId->lp_off = (itemId->lp_off & ~VISIBILTY_MASK) | ITEMID_XACT_PENDING;
+	itemId->lp_off = (itemId->lp_off & ~XACT_SLOT) | trans_slot << XACT_SLOT_MASK;
+	itemId->lp_len = 0;
+}
+
+/*
+ * ItemIdSetDeleted
+ *		Set the item identifier to be Deleted, with the specified visibility
+ *		info and transaction slot info.  The most significant 8 bits are used
+ *		to store transaction slot information and the lower 7 bits are used to
+ *		store visibility info.  Such an item has no storage.
+ *		Beware of multiple evaluations of itemId!
+ */
+#define ItemIdSetDeleted(itemId, trans_slot, vis_info) \
+( \
+	(itemId)->lp_flags = LP_REDIRECT, \
+	(itemId)->lp_off = ((itemId)->lp_off & ~VISIBILTY_MASK) | (vis_info), \
+	(itemId)->lp_off = ((itemId)->lp_off & ~XACT_SLOT) | (trans_slot) << XACT_SLOT_MASK, \
+	(itemId)->lp_len = 0 \
+)
+
+#define ItemIdSetInvalidXact(itemId) \
+	((itemId)->lp_off = ((itemId)->lp_off & ~VISIBILTY_MASK) | ITEMID_XACT_INVALID)
+
+#define ItemIdResetInvalidXact(itemId) \
+	((itemId)->lp_off = ((itemId)->lp_off & ~VISIBILTY_MASK) & ~(ITEMID_XACT_INVALID))
+
+/*
+ * ItemIdGetTransactionSlot
+ *	In a REDIRECT pointer, lp_off contains the transaction slot information in
+ *	most significant 8 bits.
+ */
+#define ItemIdGetTransactionSlot(itemId) \
+   (((itemId)->lp_off & XACT_SLOT) >> XACT_SLOT_MASK)
+
+/*
+ * ItemIdGetVisibilityInfo
+ *	In a REDIRECT pointer, lp_off contains the visibility information in
+ *	least significant 7 bits.
+ */
+#define ItemIdGetVisibilityInfo(itemId) \
+   ((itemId)->lp_off & VISIBILTY_MASK)
+
+#define ItemIdHasPendingXact(itemId) \
+   (((itemId)->lp_off & VISIBILTY_MASK) & ITEMID_XACT_PENDING)
+
+/*
  * ItemIdSetDead
  *		Set the item identifier to be DEAD, with no storage.
  *		Beware of multiple evaluations of itemId!
diff --git a/src/include/storage/lmgr.h b/src/include/storage/lmgr.h
index 099e18f..b00caed 100644
--- a/src/include/storage/lmgr.h
+++ b/src/include/storage/lmgr.h
@@ -81,9 +81,21 @@ extern bool ConditionalXactLockTableWait(TransactionId xid);
 extern void WaitForLockers(LOCKTAG heaplocktag, LOCKMODE lockmode, bool progress);
 extern void WaitForLockersMultiple(List *locktags, LOCKMODE lockmode, bool progress);
 
+/*
+ * Lock a subtranasction (used to wait for a subtransaction to finish).  This
+ * is used for zheap, but is generic enough to be used elsewhere.
+ */
+extern void SubXactLockTableInsert(SubTransactionId subxid);
+extern void SubXactLockTableDelete(SubTransactionId subxid);
+extern void SubXactLockTableWait(TransactionId xid, SubTransactionId subxid,
+								 Relation rel, ItemPointer ctid, XLTW_Oper oper);
+extern bool ConditionalSubXactLockTableWait(TransactionId xid,
+											SubTransactionId subxid);
+
 /* Lock an XID for tuple insertion (used to wait for an insertion to finish) */
 extern uint32 SpeculativeInsertionLockAcquire(TransactionId xid);
 extern void SpeculativeInsertionLockRelease(TransactionId xid);
+extern uint32 GetSpeculativeInsertionToken(void);
 extern void SpeculativeInsertionWait(TransactionId xid, uint32 token);
 
 /* Lock a general object (other than a relation) of the current database */
diff --git a/src/include/storage/lock.h b/src/include/storage/lock.h
index 986bb64..898a0a5 100644
--- a/src/include/storage/lock.h
+++ b/src/include/storage/lock.h
@@ -18,6 +18,7 @@
 #error "lock.h may not be included from frontend code"
 #endif
 
+#include "nodes/lockoptions.h"
 #include "storage/lockdefs.h"
 #include "storage/backendid.h"
 #include "storage/lwlock.h"
@@ -143,8 +144,25 @@ typedef enum LockTagType
 	LOCKTAG_TUPLE,				/* one physical tuple */
 	LOCKTAG_TRANSACTION,		/* transaction (for waiting for xact done) */
 	LOCKTAG_VIRTUALTRANSACTION, /* virtual transaction (ditto) */
+	/* ID info for a virtual transaction is its VirtualTransactionId */
+	LOCKTAG_SUBTRANSACTION,		/* virtual transaction (ditto) */
+
+	/*
+	 * ID info for a sub transaction is its top transaction id +
+	 * subTransactionId
+	 */
 	LOCKTAG_SPECULATIVE_TOKEN,	/* speculative insertion Xid and token */
 	LOCKTAG_OBJECT,				/* non-relation database object */
+	/* ID info for an object is DB OID + CLASS OID + OBJECT OID + SUBID */
+
+	/* ID info for an transaction undoaction is transaction id */
+	LOCKTAG_TRANSACTION_UNDOACTION, /* transaction (waiting for undoaction) */
+
+	/*
+	 * Note: object ID has same representation as in pg_depend and
+	 * pg_description, but notice that we are constraining SUBID to 16 bits.
+	 * Also, we use DB OID = 0 for shared objects such as tablespaces.
+	 */
 	LOCKTAG_USERLOCK,			/* reserved for old contrib/userlock code */
 	LOCKTAG_ADVISORY			/* advisory user locks */
 } LockTagType;
@@ -231,6 +249,14 @@ typedef struct LOCKTAG
 	 (locktag).locktag_type = LOCKTAG_VIRTUALTRANSACTION, \
 	 (locktag).locktag_lockmethodid = DEFAULT_LOCKMETHOD)
 
+#define SET_LOCKTAG_SUBTRANSACTION(locktag,xid,subxid) \
+	((locktag).locktag_field1 = (xid), \
+	 (locktag).locktag_field2 = (subxid), \
+	 (locktag).locktag_field3 = 0, \
+	 (locktag).locktag_field4 = 0, \
+	 (locktag).locktag_type = LOCKTAG_SUBTRANSACTION, \
+	 (locktag).locktag_lockmethodid = DEFAULT_LOCKMETHOD)
+
 /*
  * ID info for a speculative insert is TRANSACTION info +
  * its speculative insert counter.
@@ -243,6 +269,14 @@ typedef struct LOCKTAG
 	 (locktag).locktag_type = LOCKTAG_SPECULATIVE_TOKEN, \
 	 (locktag).locktag_lockmethodid = DEFAULT_LOCKMETHOD)
 
+#define SET_LOCKTAG_TRANSACTION_UNDOACTION(locktag,xid) \
+	((locktag).locktag_field1 = (xid), \
+	 (locktag).locktag_field2 = 0, \
+	 (locktag).locktag_field3 = 0, \
+	 (locktag).locktag_field4 = 0, \
+	 (locktag).locktag_type = LOCKTAG_TRANSACTION_UNDOACTION, \
+	 (locktag).locktag_lockmethodid = DEFAULT_LOCKMETHOD)
+
 /*
  * ID info for an object is DB OID + CLASS OID + OBJECT OID + SUBID
  *
@@ -267,6 +301,13 @@ typedef struct LOCKTAG
 	 (locktag).locktag_lockmethodid = USER_LOCKMETHOD)
 
 
+struct LockExtraInfo
+{
+	LOCKMODE	hwlock;
+	int			lockstatus;
+	int			updstatus;
+};
+
 /*
  * Per-locked-object lock information:
  *
@@ -583,6 +624,10 @@ extern void RememberSimpleDeadLock(PGPROC *proc1,
 extern void InitDeadLockChecking(void);
 
 extern int	LockWaiterCount(const LOCKTAG *locktag);
+extern LOCKMODE GetHWLockModeFromMode(LockTupleMode mode);
+
+#define UnlockTupleTuplock(rel, tup, mode) \
+	UnlockTuple((rel), (tup), GetHWLockModeFromMode(mode))
 
 #ifdef LOCK_DEBUG
 extern void DumpLocks(PGPROC *proc);
diff --git a/src/include/storage/predicate.h b/src/include/storage/predicate.h
index 376245e..4570482 100644
--- a/src/include/storage/predicate.h
+++ b/src/include/storage/predicate.h
@@ -57,16 +57,17 @@ extern void SetSerializableTransactionSnapshot(Snapshot snapshot,
 extern void RegisterPredicateLockingXid(TransactionId xid);
 extern void PredicateLockRelation(Relation relation, Snapshot snapshot);
 extern void PredicateLockPage(Relation relation, BlockNumber blkno, Snapshot snapshot);
-extern void PredicateLockTuple(Relation relation, HeapTuple tuple, Snapshot snapshot);
+extern void PredicateLockTid(Relation relation, ItemPointer, Snapshot snapshot,
+							 TransactionId targetxmin);
 extern void PredicateLockPageSplit(Relation relation, BlockNumber oldblkno, BlockNumber newblkno);
 extern void PredicateLockPageCombine(Relation relation, BlockNumber oldblkno, BlockNumber newblkno);
 extern void TransferPredicateLocksToHeapRelation(Relation relation);
 extern void ReleasePredicateLocks(bool isCommit, bool isReadOnlySafe);
 
 /* conflict detection (may also trigger rollback) */
-extern void CheckForSerializableConflictOut(bool valid, Relation relation, HeapTuple tuple,
+extern void CheckForSerializableConflictOut(bool valid, Relation relation, void *stup,
 											Buffer buffer, Snapshot snapshot);
-extern void CheckForSerializableConflictIn(Relation relation, HeapTuple tuple, Buffer buffer);
+extern void CheckForSerializableConflictIn(Relation relation, ItemPointer tid, Buffer buffer);
 extern void CheckTableForSerializableConflictIn(Relation relation);
 
 /* final rollback checking */
@@ -79,6 +80,8 @@ extern void PredicateLockTwoPhaseFinish(TransactionId xid, bool isCommit);
 extern void predicatelock_twophase_recover(TransactionId xid, uint16 info,
 										   void *recdata, uint32 len);
 
+extern bool IsSerializableXact(void);
+
 /* parallel query support */
 extern SerializableXactHandle ShareSerializableXact(void);
 extern void AttachSerializableXact(SerializableXactHandle handle);
diff --git a/src/include/storage/proc.h b/src/include/storage/proc.h
index bcee3e1..5abb7f1 100644
--- a/src/include/storage/proc.h
+++ b/src/include/storage/proc.h
@@ -338,4 +338,12 @@ extern PGPROC *AuxiliaryPidGetProc(int pid);
 extern void BecomeLockGroupLeader(void);
 extern bool BecomeLockGroupMember(PGPROC *leader, int pid);
 
+static inline bool
+FullTransactionIdOlderThanAllUndo(FullTransactionId full_xid)
+{
+	uint64		cutoff = pg_atomic_read_u64(&ProcGlobal->oldestFullXidHavingUnappliedUndo);
+
+	return U64FromFullTransactionId(full_xid) < cutoff;
+}
+
 #endif							/* PROC_H */
diff --git a/src/include/storage/smgr.h b/src/include/storage/smgr.h
index 0fd3b75..d5b7375 100644
--- a/src/include/storage/smgr.h
+++ b/src/include/storage/smgr.h
@@ -107,6 +107,7 @@ extern void smgrwriteback(SMgrRelation reln, ForkNumber forknum,
 extern BlockNumber smgrnblocks(SMgrRelation reln, ForkNumber forknum);
 extern void smgrtruncate(SMgrRelation reln, ForkNumber forknum,
 						 BlockNumber nblocks);
+extern void smgrrequestsync(RelFileNode rnode, ForkNumber forknum, int segno);
 extern void smgrimmedsync(SMgrRelation reln, ForkNumber forknum);
 extern void AtEOXact_SMgr(void);
 
diff --git a/src/include/utils/elog.h b/src/include/utils/elog.h
index 0b227ab..fece39f 100644
--- a/src/include/utils/elog.h
+++ b/src/include/utils/elog.h
@@ -197,6 +197,10 @@ extern int	internalerrquery(const char *query);
 
 extern int	err_out_to_client(bool out_to_client);
 
+extern int	err_out_to_client(bool out_to_client);
+
+extern int	err_out_to_client(bool out_to_client);
+
 extern int	err_generic_string(int field, const char *str);
 
 extern int	geterrcode(void);
diff --git a/src/include/utils/rel.h b/src/include/utils/rel.h
index d35b4a5..7bdc179 100644
--- a/src/include/utils/rel.h
+++ b/src/include/utils/rel.h
@@ -19,6 +19,7 @@
 #include "catalog/pg_class.h"
 #include "catalog/pg_index.h"
 #include "catalog/pg_publication.h"
+#include "catalog/pg_am_d.h"
 #include "fmgr.h"
 #include "nodes/bitmapset.h"
 #include "rewrite/prs2lock.h"
@@ -270,6 +271,7 @@ typedef struct StdRdOptions
 	int			parallel_workers;	/* max number of parallel workers */
 	bool		vacuum_index_cleanup;	/* enables index vacuuming and cleanup */
 	bool		vacuum_truncate;	/* enables vacuum to truncate a relation */
+	int			relstorage_offset;	/* see RELSTORAGE_xxx constants below */
 } StdRdOptions;
 
 #define HEAP_MIN_FILLFACTOR			10
@@ -325,6 +327,17 @@ typedef struct StdRdOptions
 	((relation)->rd_options ? \
 	 ((StdRdOptions *) (relation)->rd_options)->parallel_workers : (defaultpw))
 
+/*
+ * RelationStorageIsZHeap
+ *  TRUE if relation stored in a zheap format
+ */
+#define RelationStorageIsZHeap(relation) \
+	(relation &&	\
+	((relation)->rd_rel->relkind == RELKIND_RELATION ||	\
+	 (relation)->rd_rel->relkind == RELKIND_MATVIEW ||	\
+	 (relation)->rd_rel->relkind == RELKIND_PARTITIONED_TABLE ||	\
+	 (relation)->rd_rel->relkind == RELKIND_TOASTVALUE) &&	\
+	 (relation)->rd_rel->relam == ZHEAP_TABLE_AM_OID) \
 
 /*
  * ViewOptions
diff --git a/src/include/utils/snapshot.h b/src/include/utils/snapshot.h
index c00f1fe..b7cfc26 100644
--- a/src/include/utils/snapshot.h
+++ b/src/include/utils/snapshot.h
@@ -158,6 +158,13 @@ typedef struct SnapshotData
 	TransactionId xmax;			/* all XID >= xmax are invisible to me */
 
 	/*
+	 * This if for the new type of locks for sub-transactions for zheap. This
+	 * is filled in ZHeapTupleSatisfiesDirty, if the tuple is modified by a
+	 * sub-transaction.  This allows us to wait on subtransactions.
+	 */
+	SubTransactionId subxid;
+
+	/*
 	 * For normal MVCC snapshot this contains the all xact IDs that are in
 	 * progress, unless the snapshot was taken during recovery in which case
 	 * it's empty. For historic MVCC snapshots, the meaning is inverted, i.e.
diff --git a/src/include/utils/ztqual.h b/src/include/utils/ztqual.h
new file mode 100644
index 0000000..3523488
--- /dev/null
+++ b/src/include/utils/ztqual.h
@@ -0,0 +1,78 @@
+/*-------------------------------------------------------------------------
+ *
+ * ztqual.h
+ *	  POSTGRES "time qualification" definitions, ie, ztuple visibility rules.
+ *
+ *
+ * Portions Copyright (c) 1996-2019, PostgreSQL Global Development Group
+ * Portions Copyright (c) 1994, Regents of the University of California
+ *
+ * src/include/utils/ztqual.h
+ *
+ *-------------------------------------------------------------------------
+ */
+#ifndef ZTQUAL_H
+#define ZTQUAL_H
+
+#include "access/xlogdefs.h"
+#include "access/zheap.h"
+
+typedef struct ZHeapTupleTransInfo
+{
+	int			trans_slot;
+	FullTransactionId epoch_xid;
+	TransactionId xid;
+	CommandId	cid;
+	UndoRecPtr	urec_ptr;
+} ZHeapTupleTransInfo;
+
+/* Result codes for ZHeapTupleSatisfiesOldestXmin */
+typedef enum
+{
+	ZHEAPTUPLE_DEAD,			/* tuple is dead and deletable */
+	ZHEAPTUPLE_LIVE,			/* tuple is live (committed, no deleter) */
+	ZHEAPTUPLE_RECENTLY_DEAD,	/* tuple is dead, but not deletable yet */
+	ZHEAPTUPLE_INSERT_IN_PROGRESS,	/* inserting xact is still in progress */
+	ZHEAPTUPLE_DELETE_IN_PROGRESS,	/* deleting xact is still in progress */
+	ZHEAPTUPLE_ABORT_IN_PROGRESS	/* rollback is still pending */
+} ZHTSV_Result;
+
+extern void FetchTransInfoFromUndo(BlockNumber blocknum, OffsetNumber offnum,
+								   TransactionId xid, ZHeapTupleTransInfo *zinfo,
+								   ItemPointer new_ctid);
+extern void ZHeapUpdateTransactionSlotInfo(int trans_slot, Buffer buffer,
+										   OffsetNumber offnum,
+										   ZHeapTupleTransInfo *zinfo);
+extern void ZHeapTupleGetTransInfo(Buffer buf, OffsetNumber offnum,
+								   ZHeapTupleTransInfo *zinfo);
+extern TransactionId ZHeapTupleGetTransXID(ZHeapTuple zhtup, Buffer buf,
+										   bool nobuflock);
+
+/* Fetch CTID information stored in undo */
+extern void ZHeapPageGetNewCtid(Buffer buffer, ItemPointer ctid,
+								ZHeapTupleTransInfo *zinfo);
+
+/* These are the "satisfies" test routines for the zheap. */
+extern TM_Result ZHeapTupleSatisfiesUpdate(Relation rel, ItemPointer tid,
+										   ZHeapTuple zhtup, CommandId curcid, Buffer buffer,
+										   ItemPointer ctid, ZHeapTupleTransInfo *zinfo,
+										   SubTransactionId *subxid, TransactionId *single_locker_xid,
+										   int *single_locker_trans_slot, bool lock_allowed,
+										   Snapshot snapshot, bool *in_place_updated_or_locked);
+extern bool ZHeapTupleIsSurelyDead(ZHeapTuple zhtup, Buffer buffer,
+								   OffsetNumber offnum);
+extern ZHTSV_Result ZHeapTupleSatisfiesOldestXmin(ZHeapTuple zhtup,
+												  TransactionId OldestXmin,
+												  Buffer buffer, bool resolve_abort_in_progress,
+												  ZHeapTuple *preabort_tuple,
+												  TransactionId *xid, SubTransactionId *subxid);
+
+extern bool ZHeapTupleFetch(Relation rel, Buffer buffer, OffsetNumber offnum,
+							Snapshot snapshot, ZHeapTuple *visible_tuple,
+							ItemPointer new_ctid);
+
+extern bool ZHeapTupleHasSerializableConflictOut(bool visible, Relation relation,
+												 ItemPointer tid, Buffer buffer,
+												 TransactionId *xid);
+
+#endif							/* ZTQUAL_H */
diff --git a/src/pl/plperl/expected/plperl_transaction.out b/src/pl/plperl/expected/plperl_transaction.out
index 7ca0ef3..3a3c250 100644
--- a/src/pl/plperl/expected/plperl_transaction.out
+++ b/src/pl/plperl/expected/plperl_transaction.out
@@ -12,7 +12,7 @@ foreach my $i (0..9) {
 }
 $$;
 CALL transaction_test1();
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
  0 | 
@@ -35,7 +35,7 @@ foreach my $i (0..9) {
     }
 }
 $$;
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
  0 | 
@@ -63,7 +63,7 @@ $$;
 SELECT transaction_test2();
 ERROR:  invalid transaction termination at line 5.
 CONTEXT:  PL/Perl function "transaction_test2"
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
 (0 rows)
@@ -78,7 +78,7 @@ $$;
 SELECT transaction_test3();
 ERROR:  invalid transaction termination at line 5. at line 2.
 CONTEXT:  PL/Perl function "transaction_test3"
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
 (0 rows)
@@ -105,7 +105,7 @@ while (defined($row = spi_fetchrow($sth))) {
     spi_commit();
 }
 $$;
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
  0 | 
@@ -133,11 +133,11 @@ while (defined($row = spi_fetchrow($sth))) {
 $$;
 ERROR:  division by zero at line 5.
 CONTEXT:  PL/Perl anonymous code block
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
   a  | b 
 -----+---
-  -6 | 
  -12 | 
+  -6 | 
 (2 rows)
 
 SELECT * FROM pg_cursors;
@@ -155,7 +155,7 @@ while (defined($row = spi_fetchrow($sth))) {
     spi_rollback();
 }
 $$;
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
 (0 rows)
@@ -179,7 +179,7 @@ while (defined($row = spi_fetchrow($sth))) {
     }
 }
 $$;
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
  0 | 
diff --git a/src/pl/plperl/expected/plperl_trigger.out b/src/pl/plperl/expected/plperl_trigger.out
index d4879e2..0eb3a27 100644
--- a/src/pl/plperl/expected/plperl_trigger.out
+++ b/src/pl/plperl/expected/plperl_trigger.out
@@ -244,7 +244,7 @@ INSERT INTO trigger_test (i, v, foo) VALUES (2,'second line', '("(2)")');
 INSERT INTO trigger_test (i, v, foo) VALUES (3,'third line', '("(3)")');
 INSERT INTO trigger_test (i, v, foo) VALUES (4,'immortal', '("(4)")');
 INSERT INTO trigger_test (i, v) VALUES (101,'bad id');
-SELECT * FROM trigger_test;
+SELECT * FROM trigger_test ORDER BY i;
  i |                v                 |   foo   
 ---+----------------------------------+---------
  1 | first line(modified by trigger)  | ("(2)")
@@ -255,7 +255,7 @@ SELECT * FROM trigger_test;
 
 UPDATE trigger_test SET i = 5 where i=3;
 UPDATE trigger_test SET i = 100 where i=1;
-SELECT * FROM trigger_test;
+SELECT * FROM trigger_test ORDER BY i;
  i |                          v                           |   foo   
 ---+------------------------------------------------------+---------
  1 | first line(modified by trigger)                      | ("(2)")
@@ -282,15 +282,15 @@ $$ LANGUAGE plperl;
 CREATE TRIGGER "test_trigger_recurse" BEFORE INSERT ON trigger_test
 FOR EACH ROW EXECUTE PROCEDURE "trigger_recurse"();
 INSERT INTO trigger_test (i, v) values (10000, 'top');
-SELECT * FROM trigger_test;
+SELECT * FROM trigger_test ORDER BY i;
    i   |                          v                           |   foo   
 -------+------------------------------------------------------+---------
      1 | first line(modified by trigger)                      | ("(2)")
      2 | second line(modified by trigger)                     | ("(3)")
      4 | immortal                                             | ("(4)")
      5 | third line(modified by trigger)(modified by trigger) | ("(5)")
- 20000 | child                                                | 
  10000 | top                                                  | 
+ 20000 | child                                                | 
 (6 rows)
 
 CREATE OR REPLACE FUNCTION immortal() RETURNS trigger AS $$
@@ -306,7 +306,7 @@ $$ LANGUAGE plperl;
 CREATE TRIGGER "immortal_trig" BEFORE DELETE ON trigger_test
 FOR EACH ROW EXECUTE PROCEDURE immortal('immortal');
 DELETE FROM trigger_test;
-SELECT * FROM trigger_test;
+SELECT * FROM trigger_test ORDER BY i;
  i |    v     |   foo   
 ---+----------+---------
  4 | immortal | ("(4)")
diff --git a/src/pl/plperl/sql/plperl_transaction.sql b/src/pl/plperl/sql/plperl_transaction.sql
index 0a60799..95a9dae 100644
--- a/src/pl/plperl/sql/plperl_transaction.sql
+++ b/src/pl/plperl/sql/plperl_transaction.sql
@@ -16,7 +16,7 @@ $$;
 
 CALL transaction_test1();
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 
 TRUNCATE test1;
@@ -34,7 +34,7 @@ foreach my $i (0..9) {
 }
 $$;
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 
 TRUNCATE test1;
@@ -56,7 +56,7 @@ $$;
 
 SELECT transaction_test2();
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 
 -- also not allowed if procedure is called from a function
@@ -69,7 +69,7 @@ $$;
 
 SELECT transaction_test3();
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 
 -- DO block inside function
@@ -98,7 +98,7 @@ while (defined($row = spi_fetchrow($sth))) {
 }
 $$;
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 -- check that this doesn't leak a holdable portal
 SELECT * FROM pg_cursors;
@@ -116,7 +116,7 @@ while (defined($row = spi_fetchrow($sth))) {
 }
 $$;
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 SELECT * FROM pg_cursors;
 
@@ -133,7 +133,7 @@ while (defined($row = spi_fetchrow($sth))) {
 }
 $$;
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 SELECT * FROM pg_cursors;
 
@@ -154,7 +154,7 @@ while (defined($row = spi_fetchrow($sth))) {
 }
 $$;
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 SELECT * FROM pg_cursors;
 
diff --git a/src/pl/plperl/sql/plperl_trigger.sql b/src/pl/plperl/sql/plperl_trigger.sql
index 4adddeb..a05b028 100644
--- a/src/pl/plperl/sql/plperl_trigger.sql
+++ b/src/pl/plperl/sql/plperl_trigger.sql
@@ -134,13 +134,13 @@ INSERT INTO trigger_test (i, v, foo) VALUES (4,'immortal', '("(4)")');
 
 INSERT INTO trigger_test (i, v) VALUES (101,'bad id');
 
-SELECT * FROM trigger_test;
+SELECT * FROM trigger_test ORDER BY i;
 
 UPDATE trigger_test SET i = 5 where i=3;
 
 UPDATE trigger_test SET i = 100 where i=1;
 
-SELECT * FROM trigger_test;
+SELECT * FROM trigger_test ORDER BY i;
 
 DROP TRIGGER "test_valid_id_trig" ON trigger_test;
 
@@ -164,7 +164,7 @@ FOR EACH ROW EXECUTE PROCEDURE "trigger_recurse"();
 
 INSERT INTO trigger_test (i, v) values (10000, 'top');
 
-SELECT * FROM trigger_test;
+SELECT * FROM trigger_test ORDER BY i;
 
 CREATE OR REPLACE FUNCTION immortal() RETURNS trigger AS $$
     if ($_TD->{old}{v} eq $_TD->{args}[0])
@@ -182,7 +182,7 @@ FOR EACH ROW EXECUTE PROCEDURE immortal('immortal');
 
 DELETE FROM trigger_test;
 
-SELECT * FROM trigger_test;
+SELECT * FROM trigger_test ORDER BY i;
 
 CREATE FUNCTION direct_trigger() RETURNS trigger AS $$
     return;
diff --git a/src/pl/plpython/expected/plpython_transaction.out b/src/pl/plpython/expected/plpython_transaction.out
index 1415299..1fbd452 100644
--- a/src/pl/plpython/expected/plpython_transaction.out
+++ b/src/pl/plpython/expected/plpython_transaction.out
@@ -10,7 +10,7 @@ for i in range(0, 10):
         plpy.rollback()
 $$;
 CALL transaction_test1();
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
  0 | 
@@ -31,7 +31,7 @@ for i in range(0, 10):
     else:
         plpy.rollback()
 $$;
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
  0 | 
@@ -57,7 +57,7 @@ $$;
 SELECT transaction_test2();
 ERROR:  invalid transaction termination
 CONTEXT:  PL/Python function "transaction_test2"
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
 (0 rows)
@@ -75,7 +75,7 @@ CONTEXT:  Traceback (most recent call last):
   PL/Python function "transaction_test3", line 2, in <module>
     plpy.execute("CALL transaction_test1()")
 PL/Python function "transaction_test3"
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
 (0 rows)
@@ -111,7 +111,7 @@ for row in plpy.cursor("SELECT * FROM test2 ORDER BY x"):
     plpy.execute("INSERT INTO test1 (a) VALUES (%s)" % row['x'])
     plpy.commit()
 $$;
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
  0 | 
@@ -139,11 +139,11 @@ CONTEXT:  Traceback (most recent call last):
   PL/Python anonymous code block, line 3, in <module>
     plpy.execute("INSERT INTO test1 (a) VALUES (12/(%s-2))" % row['x'])
 PL/Python anonymous code block
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
   a  | b 
 -----+---
-  -6 | 
  -12 | 
+  -6 | 
 (2 rows)
 
 SELECT * FROM pg_cursors;
@@ -158,7 +158,7 @@ for row in plpy.cursor("SELECT * FROM test2 ORDER BY x"):
     plpy.execute("INSERT INTO test1 (a) VALUES (%s)" % row['x'])
     plpy.rollback()
 $$;
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
 (0 rows)
@@ -178,7 +178,7 @@ for row in plpy.cursor("SELECT * FROM test2 ORDER BY x"):
     else:
         plpy.rollback()
 $$;
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
  0 | 
diff --git a/src/pl/plpython/sql/plpython_transaction.sql b/src/pl/plpython/sql/plpython_transaction.sql
index 33b37e5..d866877 100644
--- a/src/pl/plpython/sql/plpython_transaction.sql
+++ b/src/pl/plpython/sql/plpython_transaction.sql
@@ -14,7 +14,7 @@ $$;
 
 CALL transaction_test1();
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 
 TRUNCATE test1;
@@ -30,7 +30,7 @@ for i in range(0, 10):
         plpy.rollback()
 $$;
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 
 TRUNCATE test1;
@@ -50,7 +50,7 @@ $$;
 
 SELECT transaction_test2();
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 
 -- also not allowed if procedure is called from a function
@@ -63,7 +63,7 @@ $$;
 
 SELECT transaction_test3();
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 
 -- DO block inside function
@@ -97,7 +97,7 @@ for row in plpy.cursor("SELECT * FROM test2 ORDER BY x"):
     plpy.commit()
 $$;
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 -- check that this doesn't leak a holdable portal
 SELECT * FROM pg_cursors;
@@ -112,7 +112,7 @@ for row in plpy.cursor("SELECT * FROM test2 ORDER BY x"):
     plpy.commit()
 $$;
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 SELECT * FROM pg_cursors;
 
@@ -126,7 +126,7 @@ for row in plpy.cursor("SELECT * FROM test2 ORDER BY x"):
     plpy.rollback()
 $$;
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 SELECT * FROM pg_cursors;
 
@@ -143,7 +143,7 @@ for row in plpy.cursor("SELECT * FROM test2 ORDER BY x"):
         plpy.rollback()
 $$;
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 SELECT * FROM pg_cursors;
 
diff --git a/src/pl/tcl/expected/pltcl_transaction.out b/src/pl/tcl/expected/pltcl_transaction.out
index 007204b..e0c8180 100644
--- a/src/pl/tcl/expected/pltcl_transaction.out
+++ b/src/pl/tcl/expected/pltcl_transaction.out
@@ -14,7 +14,7 @@ for {set i 0} {$i < 10} {incr i} {
 }
 $$;
 CALL transaction_test1();
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
  0 | 
@@ -41,7 +41,7 @@ return 1
 $$;
 SELECT transaction_test2();
 ERROR:  invalid transaction termination
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
 (0 rows)
@@ -55,7 +55,7 @@ return 1
 $$;
 SELECT transaction_test3();
 ERROR:  invalid transaction termination
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
 (0 rows)
@@ -74,7 +74,7 @@ spi_exec -array row "SELECT * FROM test2 ORDER BY x" {
 $$;
 CALL transaction_test4a();
 ERROR:  cannot commit while a subtransaction is active
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
 (0 rows)
@@ -91,7 +91,7 @@ spi_exec -array row "SELECT * FROM test2 ORDER BY x" {
 $$;
 CALL transaction_test4b();
 ERROR:  cannot roll back while a subtransaction is active
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
  a | b 
 ---+---
 (0 rows)
diff --git a/src/pl/tcl/expected/pltcl_trigger.out b/src/pl/tcl/expected/pltcl_trigger.out
index 008ea19..160a661 100644
--- a/src/pl/tcl/expected/pltcl_trigger.out
+++ b/src/pl/tcl/expected/pltcl_trigger.out
@@ -446,7 +446,7 @@ insert into T_pkey2 values (1, 'key1-3', 'test key');
 insert into T_pkey2 values (2, 'key2-1', 'test key');
 insert into T_pkey2 values (2, 'key2-2', 'test key');
 insert into T_pkey2 values (2, 'key2-3', 'test key');
-select * from T_pkey1;
+select * from T_pkey1 order by 1, 2;
  key1 |         key2         |                   txt                    
 ------+----------------------+------------------------------------------
     1 | key1-1               | test key                                
@@ -458,7 +458,7 @@ select * from T_pkey1;
 (6 rows)
 
 -- key2 in T_pkey2 should have upper case only
-select * from T_pkey2;
+select * from T_pkey2 order by 1, 2;
  key1 |         key2         |                   txt                    
 ------+----------------------+------------------------------------------
     1 | KEY1-1               | test key                                
@@ -485,7 +485,7 @@ insert into T_dta2 values ('trec 3', 1, 'KEY1-3');
 -- Must fail due to unknown key in T_pkey2
 insert into T_dta2 values ('trec 4', 1, 'KEY1-4');
 ERROR:  key for t_dta2 not in t_pkey2
-select * from T_dta1;
+select * from T_dta1 order by 1, 2;
     tkey    | ref1 |         ref2         
 ------------+------+----------------------
  trec 1     |    1 | key1-1              
@@ -493,7 +493,7 @@ select * from T_dta1;
  trec 3     |    1 | key1-3              
 (3 rows)
 
-select * from T_dta2;
+select * from T_dta2 order by 1, 2;
     tkey    | ref1 |         ref2         
 ------------+------+----------------------
  trec 1     |    1 | KEY1-1              
@@ -513,27 +513,27 @@ NOTICE:  updated 1 entries in T_dta2 for new key in T_pkey2
 delete from T_pkey2 where key1 = 2 and key2 = 'KEY2-2';
 delete from T_pkey2 where key1 = 1 and key2 = 'KEY1-2';
 NOTICE:  deleted 1 entries from T_dta2
-select * from T_pkey1;
+select * from T_pkey1 order by 1, 2;
  key1 |         key2         |                   txt                    
 ------+----------------------+------------------------------------------
     1 | key1-1               | test key                                
     1 | key1-2               | test key                                
     1 | key1-3               | test key                                
-    2 | key2-3               | test key                                
     1 | KEY1-3               | should work                             
+    2 | key2-3               | test key                                
     2 | key2-9               | test key                                
 (6 rows)
 
-select * from T_pkey2;
+select * from T_pkey2 order by 1, 2;
  key1 |         key2         |                   txt                    
 ------+----------------------+------------------------------------------
     1 | KEY1-3               | test key                                
+    1 | KEY1-9               | test key                                
     2 | KEY2-3               | test key                                
     2 | KEY2-9               | test key                                
-    1 | KEY1-9               | test key                                
 (4 rows)
 
-select * from T_dta1;
+select * from T_dta1 order by 1, 2;
     tkey    | ref1 |         ref2         
 ------------+------+----------------------
  trec 1     |    1 | key1-1              
@@ -541,11 +541,11 @@ select * from T_dta1;
  trec 3     |    1 | key1-3              
 (3 rows)
 
-select * from T_dta2;
+select * from T_dta2 order by 1, 2;
     tkey    | ref1 |         ref2         
 ------------+------+----------------------
- trec 3     |    1 | KEY1-3              
  trec 1     |    1 | KEY1-9              
+ trec 3     |    1 | KEY1-3              
 (2 rows)
 
 select tcl_avg(key1) from T_pkey1;
@@ -881,7 +881,7 @@ FOR EACH ROW EXECUTE PROCEDURE generated_test_func1();
 TRUNCATE trigger_test_generated;
 INSERT INTO trigger_test_generated (i) VALUES (1);
 ERROR:  cannot set generated column "j"
-SELECT * FROM trigger_test_generated;
+SELECT * FROM trigger_test_generated order by 1, 2;
  i | j 
 ---+---
 (0 rows)
diff --git a/src/pl/tcl/sql/pltcl_transaction.sql b/src/pl/tcl/sql/pltcl_transaction.sql
index c752faf..c1ce9b1 100644
--- a/src/pl/tcl/sql/pltcl_transaction.sql
+++ b/src/pl/tcl/sql/pltcl_transaction.sql
@@ -19,7 +19,7 @@ $$;
 
 CALL transaction_test1();
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 
 TRUNCATE test1;
@@ -41,7 +41,7 @@ $$;
 
 SELECT transaction_test2();
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 
 -- also not allowed if procedure is called from a function
@@ -54,7 +54,7 @@ $$;
 
 SELECT transaction_test3();
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 
 -- commit inside cursor loop
@@ -74,7 +74,7 @@ $$;
 
 CALL transaction_test4a();
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 
 -- rollback inside cursor loop
@@ -91,7 +91,7 @@ $$;
 
 CALL transaction_test4b();
 
-SELECT * FROM test1;
+SELECT * FROM test1 ORDER BY 1, 2;
 
 
 DROP TABLE test1;
diff --git a/src/pl/tcl/sql/pltcl_trigger.sql b/src/pl/tcl/sql/pltcl_trigger.sql
index 2db75a3..032a829 100644
--- a/src/pl/tcl/sql/pltcl_trigger.sql
+++ b/src/pl/tcl/sql/pltcl_trigger.sql
@@ -482,10 +482,10 @@ insert into T_pkey2 values (2, 'key2-1', 'test key');
 insert into T_pkey2 values (2, 'key2-2', 'test key');
 insert into T_pkey2 values (2, 'key2-3', 'test key');
 
-select * from T_pkey1;
+select * from T_pkey1 order by 1, 2;
 
 -- key2 in T_pkey2 should have upper case only
-select * from T_pkey2;
+select * from T_pkey2 order by 1, 2;
 
 insert into T_pkey1 values (1, 'KEY1-3', 'should work');
 
@@ -506,9 +506,9 @@ insert into T_dta2 values ('trec 3', 1, 'KEY1-3');
 -- Must fail due to unknown key in T_pkey2
 insert into T_dta2 values ('trec 4', 1, 'KEY1-4');
 
-select * from T_dta1;
+select * from T_dta1 order by 1, 2;
 
-select * from T_dta2;
+select * from T_dta2 order by 1, 2;
 
 update T_pkey1 set key2 = 'key2-9' where key1 = 2 and key2 = 'key2-1';
 update T_pkey1 set key2 = 'key1-9' where key1 = 1 and key2 = 'key1-1';
@@ -520,10 +520,10 @@ update T_pkey2 set key2 = 'KEY1-9' where key1 = 1 and key2 = 'KEY1-1';
 delete from T_pkey2 where key1 = 2 and key2 = 'KEY2-2';
 delete from T_pkey2 where key1 = 1 and key2 = 'KEY1-2';
 
-select * from T_pkey1;
-select * from T_pkey2;
-select * from T_dta1;
-select * from T_dta2;
+select * from T_pkey1 order by 1, 2;
+select * from T_pkey2 order by 1, 2;
+select * from T_dta1 order by 1, 2;
+select * from T_dta2 order by 1, 2;
 
 select tcl_avg(key1) from T_pkey1;
 select tcl_sum(key1) from T_pkey1;
@@ -600,4 +600,4 @@ FOR EACH ROW EXECUTE PROCEDURE generated_test_func1();
 
 TRUNCATE trigger_test_generated;
 INSERT INTO trigger_test_generated (i) VALUES (1);
-SELECT * FROM trigger_test_generated;
+SELECT * FROM trigger_test_generated order by 1, 2;
diff --git a/src/test/isolation/expected/alter-table-3_1.out b/src/test/isolation/expected/alter-table-3_1.out
new file mode 100644
index 0000000..7458dea
--- /dev/null
+++ b/src/test/isolation/expected/alter-table-3_1.out
@@ -0,0 +1,697 @@
+Parsed test spec with 2 sessions
+
+starting permutation: s1a s1b s1c s1d s2a s2b s2c s2d
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s1b s1c s2a s1d s2b s2c s2d
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2a: BEGIN;
+step s1d: COMMIT;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s1b s1c s2a s2b s1d s2c s2d
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1d: COMMIT;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s1b s1c s2a s2b s2c s1d s2d
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s1b s2a s1c s1d s2b s2c s2d
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2a: BEGIN;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s1b s2a s1c s2b s1d s2c s2d
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2a: BEGIN;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1d: COMMIT;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s1b s2a s1c s2b s2c s1d s2d
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2a: BEGIN;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s1b s2a s2b s1c s1d s2c s2d
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s1b s2a s2b s1c s2c s1d s2d
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s1b s2a s2b s2c s1c s1d s2d
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s2a s1b s1c s1d s2b s2c s2d
+step s1a: BEGIN;
+step s2a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s2a s1b s1c s2b s1d s2c s2d
+step s1a: BEGIN;
+step s2a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1d: COMMIT;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s2a s1b s1c s2b s2c s1d s2d
+step s1a: BEGIN;
+step s2a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s2a s1b s2b s1c s1d s2c s2d
+step s1a: BEGIN;
+step s2a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s2a s1b s2b s1c s2c s1d s2d
+step s1a: BEGIN;
+step s2a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s2a s1b s2b s2c s1c s1d s2d
+step s1a: BEGIN;
+step s2a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s2a s2b s1b s1c s1d s2c s2d
+step s1a: BEGIN;
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s2a s2b s1b s1c s2c s1d s2d
+step s1a: BEGIN;
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s2a s2b s1b s2c s1c s1d s2d
+step s1a: BEGIN;
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s1a s2a s2b s2c s1b s1c s1d s2d
+step s1a: BEGIN;
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2d: COMMIT;
+
+starting permutation: s1a s2a s2b s2c s1b s1c s2d s1d
+step s1a: BEGIN;
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2d: COMMIT; <waiting ...>
+step s1d: COMMIT;
+step s2d: <... completed>
+
+starting permutation: s1a s2a s2b s2c s1b s2d s1c s1d
+step s1a: BEGIN;
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2d: COMMIT; <waiting ...>
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2d: <... completed>
+
+starting permutation: s1a s2a s2b s2c s2d s1b s1c s1d
+step s1a: BEGIN;
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+
+starting permutation: s2a s1a s1b s1c s1d s2b s2c s2d
+step s2a: BEGIN;
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s2a s1a s1b s1c s2b s1d s2c s2d
+step s2a: BEGIN;
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1d: COMMIT;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s2a s1a s1b s1c s2b s2c s1d s2d
+step s2a: BEGIN;
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s2a s1a s1b s2b s1c s1d s2c s2d
+step s2a: BEGIN;
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s2a s1a s1b s2b s1c s2c s1d s2d
+step s2a: BEGIN;
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s2a s1a s1b s2b s2c s1c s1d s2d
+step s2a: BEGIN;
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s2a s1a s2b s1b s1c s1d s2c s2d
+step s2a: BEGIN;
+step s1a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s2a s1a s2b s1b s1c s2c s1d s2d
+step s2a: BEGIN;
+step s1a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s2a s1a s2b s1b s2c s1c s1d s2d
+step s2a: BEGIN;
+step s1a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s2a s1a s2b s2c s1b s1c s1d s2d
+step s2a: BEGIN;
+step s1a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2d: COMMIT;
+
+starting permutation: s2a s1a s2b s2c s1b s1c s2d s1d
+step s2a: BEGIN;
+step s1a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2d: COMMIT; <waiting ...>
+step s1d: COMMIT;
+step s2d: <... completed>
+
+starting permutation: s2a s1a s2b s2c s1b s2d s1c s1d
+step s2a: BEGIN;
+step s1a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2d: COMMIT; <waiting ...>
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2d: <... completed>
+
+starting permutation: s2a s1a s2b s2c s2d s1b s1c s1d
+step s2a: BEGIN;
+step s1a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+
+starting permutation: s2a s2b s1a s1b s1c s1d s2c s2d
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s2a s2b s1a s1b s1c s2c s1d s2d
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s2a s2b s1a s1b s2c s1c s1d s2d
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2c: INSERT INTO a VALUES (0); <waiting ...>
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2c: <... completed>
+error in steps s1d s2c: ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+
+starting permutation: s2a s2b s1a s2c s1b s1c s1d s2d
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1a: BEGIN;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2d: COMMIT;
+
+starting permutation: s2a s2b s1a s2c s1b s1c s2d s1d
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1a: BEGIN;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2d: COMMIT; <waiting ...>
+step s1d: COMMIT;
+step s2d: <... completed>
+
+starting permutation: s2a s2b s1a s2c s1b s2d s1c s1d
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1a: BEGIN;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2d: COMMIT; <waiting ...>
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2d: <... completed>
+
+starting permutation: s2a s2b s1a s2c s2d s1b s1c s1d
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s1a: BEGIN;
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+
+starting permutation: s2a s2b s2c s1a s1b s1c s1d s2d
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2d: COMMIT;
+
+starting permutation: s2a s2b s2c s1a s1b s1c s2d s1d
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s2d: COMMIT; <waiting ...>
+step s1d: COMMIT;
+step s2d: <... completed>
+
+starting permutation: s2a s2b s2c s1a s1b s2d s1c s1d
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s2d: COMMIT; <waiting ...>
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+step s2d: <... completed>
+
+starting permutation: s2a s2b s2c s1a s2d s1b s1c s1d
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s1a: BEGIN;
+step s2d: COMMIT;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
+
+starting permutation: s2a s2b s2c s2d s1a s1b s1c s1d
+step s2a: BEGIN;
+step s2b: SELECT * FROM a WHERE i = 1 LIMIT 1 FOR UPDATE;
+i              
+
+1              
+step s2c: INSERT INTO a VALUES (0);
+ERROR:  duplicate key value violates unique constraint "a_pkey"
+step s2d: COMMIT;
+step s1a: BEGIN;
+step s1b: ALTER TABLE a DISABLE TRIGGER t;
+step s1c: ALTER TABLE a ENABLE TRIGGER t;
+step s1d: COMMIT;
diff --git a/src/test/isolation/expected/deleted_item_id.out b/src/test/isolation/expected/deleted_item_id.out
new file mode 100644
index 0000000..2238464
--- /dev/null
+++ b/src/test/isolation/expected/deleted_item_id.out
@@ -0,0 +1,10 @@
+Parsed test spec with 3 sessions
+
+starting permutation: w1 w2 t3 v3 c1 c2
+step w1: UPDATE a SET i = 5 WHERE i = 1;
+step w2: UPDATE a SET i = 5 WHERE i >= 1; <waiting ...>
+step t3: DELETE FROM a WHERE i = 2;
+step v3: VACUUM;
+step c1: COMMIT;
+step w2: <... completed>
+step c2: COMMIT;
diff --git a/src/test/isolation/expected/eval-plan-qual.out b/src/test/isolation/expected/eval-plan-qual.out
index 5bf6ec1..3ec2288 100644
--- a/src/test/isolation/expected/eval-plan-qual.out
+++ b/src/test/isolation/expected/eval-plan-qual.out
@@ -352,26 +352,26 @@ checking       600
 savings        2334           
 
 starting permutation: readp1 writep1 readp2 c1 c2
-step readp1: SELECT tableoid::regclass, ctid, * FROM p WHERE b IN (0, 1) AND c = 0 FOR UPDATE;
-tableoid       ctid           a              b              c              
-
-c1             (0,1)          0              0              0              
-c1             (0,4)          0              1              0              
-c2             (0,1)          1              0              0              
-c2             (0,4)          1              1              0              
-c3             (0,1)          2              0              0              
-c3             (0,4)          2              1              0              
+step readp1: SELECT tableoid::regclass, * FROM p WHERE b IN (0, 1) AND c = 0 FOR UPDATE;
+tableoid       a              b              c              
+
+c1             0              0              0              
+c1             0              1              0              
+c2             1              0              0              
+c2             1              1              0              
+c3             2              0              0              
+c3             2              1              0              
 step writep1: UPDATE p SET b = -1 WHERE a = 1 AND b = 1 AND c = 0;
-step readp2: SELECT tableoid::regclass, ctid, * FROM p WHERE b IN (0, 1) AND c = 0 FOR UPDATE; <waiting ...>
+step readp2: SELECT tableoid::regclass, * FROM p WHERE b IN (0, 1) AND c = 0 FOR UPDATE; <waiting ...>
 step c1: COMMIT;
 step readp2: <... completed>
-tableoid       ctid           a              b              c              
+tableoid       a              b              c              
 
-c1             (0,1)          0              0              0              
-c1             (0,4)          0              1              0              
-c2             (0,1)          1              0              0              
-c3             (0,1)          2              0              0              
-c3             (0,4)          2              1              0              
+c1             0              0              0              
+c1             0              1              0              
+c2             1              0              0              
+c3             2              0              0              
+c3             2              1              0              
 step c2: COMMIT;
 
 starting permutation: writep2 returningp1 c1 c2
diff --git a/src/test/isolation/expected/eval-plan-qual_1.out b/src/test/isolation/expected/eval-plan-qual_1.out
new file mode 100644
index 0000000..43442c0
--- /dev/null
+++ b/src/test/isolation/expected/eval-plan-qual_1.out
@@ -0,0 +1,285 @@
+Parsed test spec with 3 sessions
+
+starting permutation: wx1 wx2 c1 c2 read
+step wx1: UPDATE accounts SET balance = balance - 200 WHERE accountid = 'checking';
+step wx2: UPDATE accounts SET balance = balance + 450 WHERE accountid = 'checking'; <waiting ...>
+step c1: COMMIT;
+step wx2: <... completed>
+step c2: COMMIT;
+step read: SELECT * FROM accounts ORDER BY accountid;
+accountid      balance        
+
+checking       850            
+savings        600            
+
+starting permutation: wy1 wy2 c1 c2 read
+step wy1: UPDATE accounts SET balance = balance + 500 WHERE accountid = 'checking';
+step wy2: UPDATE accounts SET balance = balance + 1000 WHERE accountid = 'checking' AND balance < 1000; <waiting ...>
+step c1: COMMIT;
+step wy2: <... completed>
+step c2: COMMIT;
+step read: SELECT * FROM accounts ORDER BY accountid;
+accountid      balance        
+
+checking       1100           
+savings        600            
+
+starting permutation: upsert1 upsert2 c1 c2 read
+step upsert1: 
+	WITH upsert AS
+	  (UPDATE accounts SET balance = balance + 500
+	   WHERE accountid = 'savings'
+	   RETURNING accountid)
+	INSERT INTO accounts SELECT 'savings', 500
+	  WHERE NOT EXISTS (SELECT 1 FROM upsert);
+
+step upsert2: 
+	WITH upsert AS
+	  (UPDATE accounts SET balance = balance + 1234
+	   WHERE accountid = 'savings'
+	   RETURNING accountid)
+	INSERT INTO accounts SELECT 'savings', 1234
+	  WHERE NOT EXISTS (SELECT 1 FROM upsert);
+ <waiting ...>
+step c1: COMMIT;
+step upsert2: <... completed>
+step c2: COMMIT;
+step read: SELECT * FROM accounts ORDER BY accountid;
+accountid      balance        
+
+checking       600            
+savings        2334           
+
+starting permutation: readp1 writep1 readp2 c1 c2
+step readp1: SELECT tableoid::regclass, ctid, * FROM p WHERE b IN (0, 1) AND c = 0 FOR UPDATE;
+tableoid       ctid           a              b              c              
+
+c1             (1,1)          0              0              0              
+c1             (1,4)          0              1              0              
+c2             (1,1)          1              0              0              
+c2             (1,4)          1              1              0              
+c3             (1,1)          2              0              0              
+c3             (1,4)          2              1              0              
+step writep1: UPDATE p SET b = -1 WHERE a = 1 AND b = 1 AND c = 0;
+step readp2: SELECT tableoid::regclass, ctid, * FROM p WHERE b IN (0, 1) AND c = 0 FOR UPDATE; <waiting ...>
+step c1: COMMIT;
+step readp2: <... completed>
+tableoid       ctid           a              b              c              
+
+c1             (1,1)          0              0              0              
+c1             (1,4)          0              1              0              
+c2             (1,1)          1              0              0              
+c3             (1,1)          2              0              0              
+c3             (1,4)          2              1              0              
+step c2: COMMIT;
+
+starting permutation: writep2 returningp1 c1 c2
+step writep2: UPDATE p SET b = -b WHERE a = 1 AND c = 0;
+step returningp1: 
+	WITH u AS ( UPDATE p SET b = b WHERE a > 0 RETURNING * )
+	  SELECT * FROM u;
+ <waiting ...>
+step c1: COMMIT;
+step returningp1: <... completed>
+a              b              c              
+
+1              0              0              
+1              0              1              
+1              0              2              
+1              -1             0              
+1              1              1              
+1              1              2              
+1              -2             0              
+1              2              1              
+1              2              2              
+1              -3             0              
+2              0              0              
+2              0              1              
+2              0              2              
+2              1              0              
+2              1              1              
+2              1              2              
+2              2              0              
+2              2              1              
+2              2              2              
+2              3              0              
+step c2: COMMIT;
+
+starting permutation: wx2 partiallock c2 c1 read
+step wx2: UPDATE accounts SET balance = balance + 450 WHERE accountid = 'checking';
+step partiallock: 
+	SELECT * FROM accounts a1, accounts a2
+	  WHERE a1.accountid = a2.accountid
+	  FOR UPDATE OF a1;
+ <waiting ...>
+step c2: COMMIT;
+step partiallock: <... completed>
+accountid      balance        accountid      balance        
+
+checking       1050           checking       600            
+savings        600            savings        600            
+step c1: COMMIT;
+step read: SELECT * FROM accounts ORDER BY accountid;
+accountid      balance        
+
+checking       1050           
+savings        600            
+
+starting permutation: wx2 lockwithvalues c2 c1 read
+step wx2: UPDATE accounts SET balance = balance + 450 WHERE accountid = 'checking';
+step lockwithvalues: 
+	SELECT * FROM accounts a1, (values('checking'),('savings')) v(id)
+	  WHERE a1.accountid = v.id
+	  FOR UPDATE OF a1;
+ <waiting ...>
+step c2: COMMIT;
+step lockwithvalues: <... completed>
+accountid      balance        id             
+
+checking       1050           checking       
+savings        600            savings        
+step c1: COMMIT;
+step read: SELECT * FROM accounts ORDER BY accountid;
+accountid      balance        
+
+checking       1050           
+savings        600            
+
+starting permutation: wx2_ext partiallock_ext c2 c1 read_ext
+step wx2_ext: UPDATE accounts_ext SET balance = balance + 450;
+step partiallock_ext: 
+	SELECT * FROM accounts_ext a1, accounts_ext a2
+	  WHERE a1.accountid = a2.accountid
+	  FOR UPDATE OF a1;
+ <waiting ...>
+step c2: COMMIT;
+step partiallock_ext: <... completed>
+accountid      balance        other          newcol         newcol2        accountid      balance        other          newcol         newcol2        
+
+checking       1050           other          42                            checking       600            other          42                            
+savings        1150                          42                            savings        700                           42                            
+step c1: COMMIT;
+step read_ext: SELECT * FROM accounts_ext ORDER BY accountid;
+accountid      balance        other          newcol         newcol2        
+
+checking       1050           other          42                            
+savings        1150                          42                            
+
+starting permutation: updateforss readforss c1 c2
+step updateforss: 
+	UPDATE table_a SET value = 'newTableAValue' WHERE id = 1;
+	UPDATE table_b SET value = 'newTableBValue' WHERE id = 1;
+
+step readforss: 
+	SELECT ta.id AS ta_id, ta.value AS ta_value,
+		(SELECT ROW(tb.id, tb.value)
+		 FROM table_b tb WHERE ta.id = tb.id) AS tb_row
+	FROM table_a ta
+	WHERE ta.id = 1 FOR UPDATE OF ta;
+ <waiting ...>
+step c1: COMMIT;
+step readforss: <... completed>
+ta_id          ta_value       tb_row         
+
+1              newTableAValue (1,tableBValue)
+step c2: COMMIT;
+
+starting permutation: updateforcip updateforcip2 c1 c2 read_a
+step updateforcip: 
+	UPDATE table_a SET value = NULL WHERE id = 1;
+
+step updateforcip2: 
+	UPDATE table_a SET value = COALESCE(value, (SELECT text 'newValue')) WHERE id = 1;
+ <waiting ...>
+step c1: COMMIT;
+step updateforcip2: <... completed>
+step c2: COMMIT;
+step read_a: SELECT * FROM table_a ORDER BY id;
+id             value          
+
+1              newValue       
+
+starting permutation: updateforcip updateforcip3 c1 c2 read_a
+step updateforcip: 
+	UPDATE table_a SET value = NULL WHERE id = 1;
+
+step updateforcip3: 
+	WITH d(val) AS (SELECT text 'newValue' FROM generate_series(1,1))
+	UPDATE table_a SET value = COALESCE(value, (SELECT val FROM d)) WHERE id = 1;
+ <waiting ...>
+step c1: COMMIT;
+step updateforcip3: <... completed>
+step c2: COMMIT;
+step read_a: SELECT * FROM table_a ORDER BY id;
+id             value          
+
+1              newValue       
+
+starting permutation: wrtwcte readwcte c1 c2
+step wrtwcte: UPDATE table_a SET value = 'tableAValue2' WHERE id = 1;
+step readwcte: 
+	WITH
+	    cte1 AS (
+	      SELECT id FROM table_b WHERE value = 'tableBValue'
+	    ),
+	    cte2 AS (
+	      SELECT * FROM table_a
+	      WHERE id = (SELECT id FROM cte1)
+	      FOR UPDATE
+	    )
+	SELECT * FROM cte2;
+ <waiting ...>
+step c1: COMMIT;
+step c2: COMMIT;
+step readwcte: <... completed>
+id             value          
+
+1              tableAValue2   
+
+starting permutation: wrjt selectjoinforupdate c2 c1
+step wrjt: UPDATE jointest SET data = 42 WHERE id = 7;
+step selectjoinforupdate: 
+	set enable_nestloop to 0;
+	set enable_hashjoin to 0;
+	set enable_seqscan to 0;
+	explain (costs off)
+	select * from jointest a join jointest b on a.id=b.id for update;
+	select * from jointest a join jointest b on a.id=b.id for update;
+ <waiting ...>
+step c2: COMMIT;
+step selectjoinforupdate: <... completed>
+QUERY PLAN     
+
+LockRows       
+  ->  Merge Join
+        Merge Cond: (a.id = b.id)
+        ->  Index Scan using jointest_id_idx on jointest a
+        ->  Index Scan using jointest_id_idx on jointest b
+id             data           id             data           
+
+1              0              1              0              
+2              0              2              0              
+3              0              3              0              
+4              0              4              0              
+5              0              5              0              
+6              0              6              0              
+7              42             7              42             
+8              0              8              0              
+9              0              9              0              
+10             0              10             0              
+step c1: COMMIT;
+
+starting permutation: wrtwcte multireadwcte c1 c2
+step wrtwcte: UPDATE table_a SET value = 'tableAValue2' WHERE id = 1;
+step multireadwcte: 
+	WITH updated AS (
+	  UPDATE table_a SET value = 'tableAValue3' WHERE id = 1 RETURNING id
+	)
+	SELECT (SELECT id FROM updated) AS subid, * FROM updated;
+ <waiting ...>
+step c1: COMMIT;
+step c2: COMMIT;
+step multireadwcte: <... completed>
+subid          id             
+
+1              1              
diff --git a/src/test/isolation/expected/inherit-temp.out b/src/test/isolation/expected/inherit-temp.out
index edfc8f9..67f5108 100644
--- a/src/test/isolation/expected/inherit-temp.out
+++ b/src/test/isolation/expected/inherit-temp.out
@@ -4,26 +4,26 @@ starting permutation: s1_insert_p s1_insert_c s2_insert_c s1_select_p s1_select_
 step s1_insert_p: INSERT INTO inh_parent VALUES (1), (2);
 step s1_insert_c: INSERT INTO inh_temp_child_s1 VALUES (3), (4);
 step s2_insert_c: INSERT INTO inh_temp_child_s2 VALUES (5), (6);
-step s1_select_p: SELECT a FROM inh_parent;
+step s1_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
 1              
 2              
 3              
 4              
-step s1_select_c: SELECT a FROM inh_temp_child_s1;
+step s1_select_c: SELECT a FROM inh_temp_child_s1 ORDER BY a;
 a              
 
 3              
 4              
-step s2_select_p: SELECT a FROM inh_parent;
+step s2_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
 1              
 2              
 5              
 6              
-step s2_select_c: SELECT a FROM inh_temp_child_s2;
+step s2_select_c: SELECT a FROM inh_temp_child_s2 ORDER BY a;
 a              
 
 5              
@@ -35,26 +35,26 @@ step s1_insert_c: INSERT INTO inh_temp_child_s1 VALUES (3), (4);
 step s2_insert_c: INSERT INTO inh_temp_child_s2 VALUES (5), (6);
 step s1_update_p: UPDATE inh_parent SET a = 11 WHERE a = 1;
 step s1_update_c: UPDATE inh_parent SET a = 13 WHERE a IN (3, 5);
-step s1_select_p: SELECT a FROM inh_parent;
+step s1_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
 2              
-11             
 4              
+11             
 13             
-step s1_select_c: SELECT a FROM inh_temp_child_s1;
+step s1_select_c: SELECT a FROM inh_temp_child_s1 ORDER BY a;
 a              
 
 4              
 13             
-step s2_select_p: SELECT a FROM inh_parent;
+step s2_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
 2              
-11             
 5              
 6              
-step s2_select_c: SELECT a FROM inh_temp_child_s2;
+11             
+step s2_select_c: SELECT a FROM inh_temp_child_s2 ORDER BY a;
 a              
 
 5              
@@ -65,26 +65,26 @@ step s1_insert_p: INSERT INTO inh_parent VALUES (1), (2);
 step s1_insert_c: INSERT INTO inh_temp_child_s1 VALUES (3), (4);
 step s2_insert_c: INSERT INTO inh_temp_child_s2 VALUES (5), (6);
 step s2_update_c: UPDATE inh_parent SET a = 15 WHERE a IN (3, 5);
-step s1_select_p: SELECT a FROM inh_parent;
+step s1_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
 1              
 2              
 3              
 4              
-step s1_select_c: SELECT a FROM inh_temp_child_s1;
+step s1_select_c: SELECT a FROM inh_temp_child_s1 ORDER BY a;
 a              
 
 3              
 4              
-step s2_select_p: SELECT a FROM inh_parent;
+step s2_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
 1              
 2              
 6              
 15             
-step s2_select_c: SELECT a FROM inh_temp_child_s2;
+step s2_select_c: SELECT a FROM inh_temp_child_s2 ORDER BY a;
 a              
 
 6              
@@ -96,22 +96,22 @@ step s1_insert_c: INSERT INTO inh_temp_child_s1 VALUES (3), (4);
 step s2_insert_c: INSERT INTO inh_temp_child_s2 VALUES (5), (6);
 step s1_delete_p: DELETE FROM inh_parent WHERE a = 2;
 step s1_delete_c: DELETE FROM inh_parent WHERE a IN (4, 6);
-step s1_select_p: SELECT a FROM inh_parent;
+step s1_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
 1              
 3              
-step s1_select_c: SELECT a FROM inh_temp_child_s1;
+step s1_select_c: SELECT a FROM inh_temp_child_s1 ORDER BY a;
 a              
 
 3              
-step s2_select_p: SELECT a FROM inh_parent;
+step s2_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
 1              
 5              
 6              
-step s2_select_c: SELECT a FROM inh_temp_child_s2;
+step s2_select_c: SELECT a FROM inh_temp_child_s2 ORDER BY a;
 a              
 
 5              
@@ -122,25 +122,25 @@ step s1_insert_p: INSERT INTO inh_parent VALUES (1), (2);
 step s1_insert_c: INSERT INTO inh_temp_child_s1 VALUES (3), (4);
 step s2_insert_c: INSERT INTO inh_temp_child_s2 VALUES (5), (6);
 step s2_delete_c: DELETE FROM inh_parent WHERE a IN (4, 6);
-step s1_select_p: SELECT a FROM inh_parent;
+step s1_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
 1              
 2              
 3              
 4              
-step s1_select_c: SELECT a FROM inh_temp_child_s1;
+step s1_select_c: SELECT a FROM inh_temp_child_s1 ORDER BY a;
 a              
 
 3              
 4              
-step s2_select_p: SELECT a FROM inh_parent;
+step s2_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
 1              
 2              
 5              
-step s2_select_c: SELECT a FROM inh_temp_child_s2;
+step s2_select_c: SELECT a FROM inh_temp_child_s2 ORDER BY a;
 a              
 
 5              
@@ -150,18 +150,18 @@ step s1_insert_p: INSERT INTO inh_parent VALUES (1), (2);
 step s1_insert_c: INSERT INTO inh_temp_child_s1 VALUES (3), (4);
 step s2_insert_c: INSERT INTO inh_temp_child_s2 VALUES (5), (6);
 step s1_truncate_p: TRUNCATE inh_parent;
-step s1_select_p: SELECT a FROM inh_parent;
+step s1_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
-step s1_select_c: SELECT a FROM inh_temp_child_s1;
+step s1_select_c: SELECT a FROM inh_temp_child_s1 ORDER BY a;
 a              
 
-step s2_select_p: SELECT a FROM inh_parent;
+step s2_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
 5              
 6              
-step s2_select_c: SELECT a FROM inh_temp_child_s2;
+step s2_select_c: SELECT a FROM inh_temp_child_s2 ORDER BY a;
 a              
 
 5              
@@ -172,20 +172,20 @@ step s1_insert_p: INSERT INTO inh_parent VALUES (1), (2);
 step s1_insert_c: INSERT INTO inh_temp_child_s1 VALUES (3), (4);
 step s2_insert_c: INSERT INTO inh_temp_child_s2 VALUES (5), (6);
 step s2_truncate_p: TRUNCATE inh_parent;
-step s1_select_p: SELECT a FROM inh_parent;
+step s1_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
 3              
 4              
-step s1_select_c: SELECT a FROM inh_temp_child_s1;
+step s1_select_c: SELECT a FROM inh_temp_child_s1 ORDER BY a;
 a              
 
 3              
 4              
-step s2_select_p: SELECT a FROM inh_parent;
+step s2_select_p: SELECT a FROM inh_parent ORDER BY a;
 a              
 
-step s2_select_c: SELECT a FROM inh_temp_child_s2;
+step s2_select_c: SELECT a FROM inh_temp_child_s2 ORDER BY a;
 a              
 
 
@@ -195,7 +195,7 @@ step s1_insert_c: INSERT INTO inh_temp_child_s1 VALUES (3), (4);
 step s2_insert_c: INSERT INTO inh_temp_child_s2 VALUES (5), (6);
 step s1_begin: BEGIN;
 step s1_truncate_p: TRUNCATE inh_parent;
-step s2_select_p: SELECT a FROM inh_parent; <waiting ...>
+step s2_select_p: SELECT a FROM inh_parent ORDER BY a; <waiting ...>
 step s1_commit: COMMIT;
 step s2_select_p: <... completed>
 a              
@@ -209,7 +209,7 @@ step s1_insert_c: INSERT INTO inh_temp_child_s1 VALUES (3), (4);
 step s2_insert_c: INSERT INTO inh_temp_child_s2 VALUES (5), (6);
 step s1_begin: BEGIN;
 step s1_truncate_p: TRUNCATE inh_parent;
-step s2_select_c: SELECT a FROM inh_temp_child_s2;
+step s2_select_c: SELECT a FROM inh_temp_child_s2 ORDER BY a;
 a              
 
 5              
diff --git a/src/test/isolation/expected/multiple-row-versions_1.out b/src/test/isolation/expected/multiple-row-versions_1.out
new file mode 100644
index 0000000..f4f140c
--- /dev/null
+++ b/src/test/isolation/expected/multiple-row-versions_1.out
@@ -0,0 +1,25 @@
+Parsed test spec with 4 sessions
+
+starting permutation: rx1 wx2 c2 wx3 ry3 wy4 rz4 c4 c3 wz1 c1
+step rx1: SELECT * FROM t WHERE id = 1000000;
+id             txt            
+
+1000000                       
+step wx2: UPDATE t SET txt = 'b' WHERE id = 1000000;
+step c2: COMMIT;
+step wx3: UPDATE t SET txt = 'c' WHERE id = 1000000;
+step ry3: SELECT * FROM t WHERE id = 500000;
+id             txt            
+
+500000                        
+step wy4: UPDATE t SET txt = 'd' WHERE id = 500000;
+step rz4: SELECT * FROM t WHERE id = 1;
+id             txt            
+
+1                             
+step c4: COMMIT;
+step c3: COMMIT;
+ERROR:  could not serialize access due to read/write dependencies among transactions
+step wz1: UPDATE t SET txt = 'a' WHERE id = 1;
+ERROR:  could not serialize access due to read/write dependencies among transactions
+step c1: COMMIT;
diff --git a/src/test/isolation/expected/tpd_offset_map_updation.out b/src/test/isolation/expected/tpd_offset_map_updation.out
new file mode 100644
index 0000000..95b7b1f
--- /dev/null
+++ b/src/test/isolation/expected/tpd_offset_map_updation.out
@@ -0,0 +1,20 @@
+Parsed test spec with 4 sessions
+
+starting permutation: s1a s1b s2b s2a s2b s3a s3b s4a s4b s2c s1c s1d s3d s4c
+step s1a: BEGIN;
+step s1b: INSERT INTO t VALUES (1001);
+step s2b: UPDATE t SET b = b + 1 WHERE a = 1;
+step s2a: BEGIN;
+step s2b: UPDATE t SET b = b + 1 WHERE a = 1;
+step s3a: BEGIN;
+step s3b: UPDATE t SET b = b + 1 WHERE a = 2;
+step s4a: BEGIN;
+step s4b: UPDATE t SET b = b + 1 WHERE a = 3;
+step s2c: ROLLBACK;
+step s1c: SELECT * FROM t WHERE a = 1;
+a              b              
+
+1              2              
+step s1d: END;
+step s3d: END;
+step s4c: END;
diff --git a/src/test/isolation/expected/vacuum-reltuples_1.out b/src/test/isolation/expected/vacuum-reltuples_1.out
new file mode 100644
index 0000000..afabdfc
--- /dev/null
+++ b/src/test/isolation/expected/vacuum-reltuples_1.out
@@ -0,0 +1,59 @@
+Parsed test spec with 2 sessions
+
+starting permutation: modify vac stats
+step modify: 
+    insert into smalltbl select max(id)+1 from smalltbl;
+
+step vac: 
+    vacuum smalltbl;
+
+step stats: 
+    select relpages, reltuples from pg_class
+     where oid='smalltbl'::regclass;
+
+relpages       reltuples      
+
+2              21             
+
+starting permutation: modify open fetch1 vac close stats
+step modify: 
+    insert into smalltbl select max(id)+1 from smalltbl;
+
+step open: 
+    begin;
+    declare c1 cursor for select 1 as dummy from smalltbl;
+
+step fetch1: 
+    fetch next from c1;
+
+dummy          
+
+1              
+step vac: 
+    vacuum smalltbl;
+
+step close: 
+    commit;
+
+step stats: 
+    select relpages, reltuples from pg_class
+     where oid='smalltbl'::regclass;
+
+relpages       reltuples      
+
+2              21             
+
+starting permutation: modify vac stats
+step modify: 
+    insert into smalltbl select max(id)+1 from smalltbl;
+
+step vac: 
+    vacuum smalltbl;
+
+step stats: 
+    select relpages, reltuples from pg_class
+     where oid='smalltbl'::regclass;
+
+relpages       reltuples      
+
+2              21             
diff --git a/src/test/isolation/expected/zheap_mvcc.out b/src/test/isolation/expected/zheap_mvcc.out
new file mode 100644
index 0000000..5253cb4
--- /dev/null
+++ b/src/test/isolation/expected/zheap_mvcc.out
@@ -0,0 +1,164 @@
+Parsed test spec with 3 sessions
+
+starting permutation: r1 w2 r2 r1 c2 r1 c1 r1 c3
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+step w2: UPDATE animals SET counter = counter + 1 WHERE name = 'cat';
+step r2: SELECT * FROM animals;
+name           counter        
+
+cat            2              
+dog            1              
+monkey         1              
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+step c2: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            2              
+dog            1              
+monkey         1              
+step c1: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            2              
+dog            1              
+monkey         1              
+step c3: COMMIT;
+
+starting permutation: r1 w2 r2 r1 c2 r1 w3 r3 r1 c3 r1 c1 r1
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+step w2: UPDATE animals SET counter = counter + 1 WHERE name = 'cat';
+step r2: SELECT * FROM animals;
+name           counter        
+
+cat            2              
+dog            1              
+monkey         1              
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+step c2: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            2              
+dog            1              
+monkey         1              
+step w3: UPDATE animals SET counter = counter + 1 WHERE name = 'cat';
+step r3: SELECT * FROM animals;
+name           counter        
+
+cat            3              
+dog            1              
+monkey         1              
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            2              
+dog            1              
+monkey         1              
+step c3: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            3              
+dog            1              
+monkey         1              
+step c1: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            3              
+dog            1              
+monkey         1              
+
+starting permutation: r1 d2 r2 r1 c2 r1 c1 r1 c3
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+step d2: DELETE FROM animals WHERE name = 'dog';
+step r2: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+monkey         1              
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+step c2: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+monkey         1              
+step c1: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+monkey         1              
+step c3: COMMIT;
+
+starting permutation: r1 i3 r3 r1 c3 r1 c1 r1 c2
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+step i3: INSERT INTO animals VALUES ('kangaroo', 1);
+step r3: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+kangaroo       1              
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+step c3: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+kangaroo       1              
+step c1: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+kangaroo       1              
+step c2: COMMIT;
diff --git a/src/test/isolation/expected/zheap_non-inplace-update.out b/src/test/isolation/expected/zheap_non-inplace-update.out
new file mode 100644
index 0000000..5bd0066
--- /dev/null
+++ b/src/test/isolation/expected/zheap_non-inplace-update.out
@@ -0,0 +1,73 @@
+Parsed test spec with 3 sessions
+
+starting permutation: r1 w2 r2 r1 c2 r1 c1 r1 c3
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+step w2: UPDATE animals SET counter = counter + 1 WHERE name = 'cat';
+step r2: SELECT * FROM animals;
+name           counter        
+
+dog            1              
+monkey         1              
+cat            2              
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+step c2: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+dog            1              
+monkey         1              
+cat            2              
+step c1: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+dog            1              
+monkey         1              
+cat            2              
+step c3: COMMIT;
+
+starting permutation: r1 w3 r3 r1 c3 r1 c1 r1 c2
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+step w3: UPDATE animals SET name = 'cat1' WHERE name = 'cat';
+step r3: SELECT * FROM animals;
+name           counter        
+
+cat1           1              
+dog            1              
+monkey         1              
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            1              
+monkey         1              
+step c3: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat1           1              
+dog            1              
+monkey         1              
+step c1: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat1           1              
+dog            1              
+monkey         1              
+step c2: COMMIT;
diff --git a/src/test/isolation/expected/zheap_tidscan.out b/src/test/isolation/expected/zheap_tidscan.out
new file mode 100644
index 0000000..987c1c7
--- /dev/null
+++ b/src/test/isolation/expected/zheap_tidscan.out
@@ -0,0 +1,16 @@
+Parsed test spec with 2 sessions
+
+starting permutation: s1u s2f s2u s1c s2c s2s
+step s1u: UPDATE tidscan SET a = a + 1;
+step s2f: DECLARE c CURSOR FOR SELECT a FROM tidscan; FETCH FIRST FROM c;
+a              
+
+1              
+step s2u: UPDATE tidscan SET a = a + 2, v = 'session2' WHERE CURRENT  OF c; <waiting ...>
+step s1c: COMMIT;
+step s2u: <... completed>
+step s2c: COMMIT;
+step s2s: SELECT * from tidscan ORDER BY a;
+a              v              
+
+4              session2       
diff --git a/src/test/isolation/expected/zheap_tpd.out b/src/test/isolation/expected/zheap_tpd.out
new file mode 100644
index 0000000..f7abb80
--- /dev/null
+++ b/src/test/isolation/expected/zheap_tpd.out
@@ -0,0 +1,128 @@
+Parsed test spec with 5 sessions
+
+starting permutation: i1 i2 i3 i4 i5 c5 r5 c4 r4 c2 r2 c3 r3 c1 r1
+step i1: INSERT INTO ANIMALS VALUES ('cow', 11);
+step i2: INSERT INTO ANIMALS VALUES ('lion', 22);
+step i3: INSERT INTO ANIMALS VALUES ('panther', 33);
+step i4: INSERT INTO ANIMALS VALUES ('giraffe', 44);
+step i5: INSERT INTO ANIMALS VALUES('tiger', 55);
+step c5: COMMIT;
+step r5: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            10             
+monkey         100            
+tiger          55             
+step c4: COMMIT;
+step r4: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            10             
+monkey         100            
+giraffe        44             
+tiger          55             
+step c2: COMMIT;
+step r2: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            10             
+monkey         100            
+lion           22             
+giraffe        44             
+tiger          55             
+step c3: COMMIT;
+step r3: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            10             
+monkey         100            
+lion           22             
+panther        33             
+giraffe        44             
+tiger          55             
+step c1: COMMIT;
+step r1: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+dog            10             
+monkey         100            
+cow            11             
+lion           22             
+panther        33             
+giraffe        44             
+tiger          55             
+
+starting permutation: i1 i2 i3 i4 i5 w5 c5 r5 w2 d2 r2 w3 c3 r3 c1 c4
+step i1: INSERT INTO ANIMALS VALUES ('cow', 11);
+step i2: INSERT INTO ANIMALS VALUES ('lion', 22);
+step i3: INSERT INTO ANIMALS VALUES ('panther', 33);
+step i4: INSERT INTO ANIMALS VALUES ('giraffe', 44);
+step i5: INSERT INTO ANIMALS VALUES('tiger', 55);
+step w5: UPDATE animals SET counter = counter + 5 WHERE name = 'cat';
+step c5: COMMIT;
+step r5: SELECT * FROM animals;
+name           counter        
+
+cat            6              
+dog            10             
+monkey         100            
+tiger          55             
+step w2: UPDATE animals SET counter = counter + 2 WHERE name = 'cat';
+step d2: ROLLBACK;
+step r2: SELECT * FROM animals;
+name           counter        
+
+cat            6              
+dog            10             
+monkey         100            
+tiger          55             
+step w3: UPDATE animals SET counter = counter + 3 WHERE name = 'cat';
+step c3: COMMIT;
+step r3: SELECT * FROM animals;
+name           counter        
+
+cat            9              
+dog            10             
+monkey         100            
+panther        33             
+tiger          55             
+step c1: COMMIT;
+step c4: COMMIT;
+
+starting permutation: i1 i2 i3 i4 i5 t5 c5 r5 t2 d2 r2 t3 c3 r3 c1 c4
+step i1: INSERT INTO ANIMALS VALUES ('cow', 11);
+step i2: INSERT INTO ANIMALS VALUES ('lion', 22);
+step i3: INSERT INTO ANIMALS VALUES ('panther', 33);
+step i4: INSERT INTO ANIMALS VALUES ('giraffe', 44);
+step i5: INSERT INTO ANIMALS VALUES('tiger', 55);
+step t5: DELETE FROM ANIMALS WHERE name = 'dog';
+step c5: COMMIT;
+step r5: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+monkey         100            
+tiger          55             
+step t2: DELETE FROM ANIMALS WHERE name = 'lion';
+step d2: ROLLBACK;
+step r2: SELECT * FROM animals;
+name           counter        
+
+cat            1              
+monkey         100            
+tiger          55             
+step t3: DELETE FROM ANIMALS WHERE counter < 3;
+step c3: COMMIT;
+step r3: SELECT * FROM animals;
+name           counter        
+
+monkey         100            
+panther        33             
+tiger          55             
+step c1: COMMIT;
+step c4: COMMIT;
diff --git a/src/test/isolation/isolation_schedule b/src/test/isolation/isolation_schedule
index 74b5077..cbb4c84 100644
--- a/src/test/isolation/isolation_schedule
+++ b/src/test/isolation/isolation_schedule
@@ -1,3 +1,7 @@
+test: zheap_mvcc
+test: zheap_non-inplace-update
+test: zheap_tpd
+test: zheap_tidscan
 test: read-only-anomaly
 test: read-only-anomaly-2
 test: read-only-anomaly-3
@@ -85,3 +89,5 @@ test: plpgsql-toast
 test: truncate-conflict
 test: serializable-parallel
 test: serializable-parallel-2
+test: tpd_offset_map_updation
+test: deleted_item_id
diff --git a/src/test/isolation/specs/deleted_item_id.spec b/src/test/isolation/specs/deleted_item_id.spec
new file mode 100644
index 0000000..3fae07f
--- /dev/null
+++ b/src/test/isolation/specs/deleted_item_id.spec
@@ -0,0 +1,28 @@
+#Test case to verify concurrently deleted itemId for update
+
+setup
+{
+	CREATE TABLE a (i int);
+	INSERT INTO a VALUES (1), (2);
+}
+
+teardown
+{
+	DROP TABLE a;
+}
+
+session "s1"
+setup       { BEGIN; }
+step "w1"   { UPDATE a SET i = 5 WHERE i = 1; }
+step "c1"   { COMMIT; }
+
+session "s2"
+setup       { BEGIN; }
+step "w2"   { UPDATE a SET i = 5 WHERE i >= 1; }
+step "c2"   { COMMIT; }
+
+session "s3"
+step "t3"   { DELETE FROM a WHERE i = 2; }
+step "v3"   { VACUUM; }
+
+permutation "w1" "w2" "t3" "v3" "c1" "c2"
diff --git a/src/test/isolation/specs/eval-plan-qual.spec b/src/test/isolation/specs/eval-plan-qual.spec
index f35a64e..44406d7 100644
--- a/src/test/isolation/specs/eval-plan-qual.spec
+++ b/src/test/isolation/specs/eval-plan-qual.spec
@@ -83,7 +83,7 @@ step "upsert1"	{
 # when the first updated tuple was in a non-first child table.
 # writep2/returningp1 tests a memory allocation issue
 
-step "readp1"	{ SELECT tableoid::regclass, ctid, * FROM p WHERE b IN (0, 1) AND c = 0 FOR UPDATE; }
+step "readp1"	{ SELECT tableoid::regclass, * FROM p WHERE b IN (0, 1) AND c = 0 FOR UPDATE; }
 step "writep1"	{ UPDATE p SET b = -1 WHERE a = 1 AND b = 1 AND c = 0; }
 step "writep2"	{ UPDATE p SET b = -b WHERE a = 1 AND c = 0; }
 step "c1"	{ COMMIT; }
@@ -181,7 +181,7 @@ step "upsert2"	{
 	  WHERE NOT EXISTS (SELECT 1 FROM upsert);
 }
 step "wx2_ext"	{ UPDATE accounts_ext SET balance = balance + 450; }
-step "readp2"	{ SELECT tableoid::regclass, ctid, * FROM p WHERE b IN (0, 1) AND c = 0 FOR UPDATE; }
+step "readp2"	{ SELECT tableoid::regclass, * FROM p WHERE b IN (0, 1) AND c = 0 FOR UPDATE; }
 step "returningp1" {
 	WITH u AS ( UPDATE p SET b = b WHERE a > 0 RETURNING * )
 	  SELECT * FROM u;
diff --git a/src/test/isolation/specs/inherit-temp.spec b/src/test/isolation/specs/inherit-temp.spec
index 5cd251d..d6dbe06 100644
--- a/src/test/isolation/specs/inherit-temp.spec
+++ b/src/test/isolation/specs/inherit-temp.spec
@@ -26,8 +26,8 @@ setup
 }
 step "s1_begin" { BEGIN; }
 step "s1_truncate_p" { TRUNCATE inh_parent; }
-step "s1_select_p" { SELECT a FROM inh_parent; }
-step "s1_select_c" { SELECT a FROM inh_temp_child_s1; }
+step "s1_select_p" { SELECT a FROM inh_parent ORDER BY a; }
+step "s1_select_c" { SELECT a FROM inh_temp_child_s1 ORDER BY a; }
 step "s1_insert_p" { INSERT INTO inh_parent VALUES (1), (2); }
 step "s1_insert_c" { INSERT INTO inh_temp_child_s1 VALUES (3), (4); }
 step "s1_update_p" { UPDATE inh_parent SET a = 11 WHERE a = 1; }
@@ -47,8 +47,8 @@ setup
   CREATE TEMPORARY TABLE inh_temp_child_s2 () INHERITS (inh_parent);
 }
 step "s2_truncate_p" { TRUNCATE inh_parent; }
-step "s2_select_p" { SELECT a FROM inh_parent; }
-step "s2_select_c" { SELECT a FROM inh_temp_child_s2; }
+step "s2_select_p" { SELECT a FROM inh_parent ORDER BY a; }
+step "s2_select_c" { SELECT a FROM inh_temp_child_s2 ORDER BY a; }
 step "s2_insert_c" { INSERT INTO inh_temp_child_s2 VALUES (5), (6); }
 step "s2_update_c" { UPDATE inh_parent SET a = 15 WHERE a IN (3, 5); }
 step "s2_delete_c" { DELETE FROM inh_parent WHERE a IN (4, 6); }
diff --git a/src/test/isolation/specs/tpd_offset_map_updation.spec b/src/test/isolation/specs/tpd_offset_map_updation.spec
new file mode 100644
index 0000000..da77f02
--- /dev/null
+++ b/src/test/isolation/specs/tpd_offset_map_updation.spec
@@ -0,0 +1,38 @@
+# If the previous transaction slot points to a TPD slot then we need to update
+# the slot in the offset map of the TPD entry
+#
+
+setup
+{
+	CREATE TABLE t (a int, b int);
+	INSERT INTO t SELECT g,g FROM generate_series(1,1000)g;
+}
+
+teardown
+{
+	DROP TABLE t;
+}
+
+session "s1"
+step "s1a" { BEGIN; }
+step "s1b" { INSERT INTO t VALUES (1001); }
+step "s1c" { SELECT * FROM t WHERE a = 1; }
+step "s1d" { END; }
+
+session "s2"
+step "s2a" { BEGIN; }
+step "s2b" { UPDATE t SET b = b + 1 WHERE a = 1; }
+step "s2c" { ROLLBACK; }
+
+session "s3"
+step "s3a" { BEGIN; }
+step "s3b" { UPDATE t SET b = b + 1 WHERE a = 2; }
+step "s3d" { END; }
+
+session "s4"
+step "s4a" { BEGIN; }
+step "s4b" { UPDATE t SET b = b + 1 WHERE a = 3; }
+step "s4c" { END; }
+
+permutation "s1a" "s1b" "s2b"  "s2a" "s2b" "s3a" "s3b" "s4a" "s4b" "s2c" "s1c"
+"s1d" "s3d" "s4c"
diff --git a/src/test/isolation/specs/vacuum-reltuples.spec b/src/test/isolation/specs/vacuum-reltuples.spec
index 6d9fa01..a1c008a 100644
--- a/src/test/isolation/specs/vacuum-reltuples.spec
+++ b/src/test/isolation/specs/vacuum-reltuples.spec
@@ -5,6 +5,9 @@
 # Expected result in second permutation is 20 tuples rather than 21 as
 # for the others, because vacuum should leave the previous result
 # (from before the insert) in place.
+# In zheap, the result should be 21 since we don't have to take cleanup
+# lock for vaccuming the relation. Hence, the vacuum command won't skip
+# the buffer even when another backend holds a pin on the same.
 
 setup {
     create table smalltbl
diff --git a/src/test/isolation/specs/zheap_mvcc.spec b/src/test/isolation/specs/zheap_mvcc.spec
new file mode 100644
index 0000000..db88ab6
--- /dev/null
+++ b/src/test/isolation/specs/zheap_mvcc.spec
@@ -0,0 +1,45 @@
+# Simple tests that show the behavior of snapshots working correctly.
+
+setup
+{
+ CREATE TABLE animals (name text, counter int) USING zheap;
+ INSERT INTO animals VALUES ('cat', 1), ('dog', 1), ('monkey', 1);
+}
+
+teardown
+{
+ DROP TABLE animals;
+}
+
+session "s1"
+setup		{ BEGIN; }
+step "r1"	{ SELECT * FROM animals; }
+step "c1"	{ COMMIT; }
+
+session "s2"
+setup       { BEGIN; }
+step "w2"	{ UPDATE animals SET counter = counter + 1 WHERE name = 'cat'; }
+step "r2"	{ SELECT * FROM animals; }
+step "d2"	{ DELETE FROM animals WHERE name = 'dog'; }
+step "c2"	{ COMMIT; }
+
+session "s3"
+setup       { BEGIN; }
+step "w3"	{ UPDATE animals SET counter = counter + 1 WHERE name = 'cat'; }
+step "r3"	{ SELECT * FROM animals; }
+step "i3"	{ INSERT INTO animals VALUES ('kangaroo', 1); }
+step "c3"	{ COMMIT; }
+
+# s1 sees previous version of "cat" tuple until the new version is committed
+# but s2 sees its own uncommitted data
+permutation "r1" "w2" "r2" "r1" "c2" "r1" "c1" "r1"  "c3"
+
+# same thing, but with a two link update chain; again s2 and s3 see their
+# own uncommitted data but s1 sees it only after s2 and s3 commit.
+permutation "r1" "w2" "r2" "r1" "c2" "r1" "w3" "r3" "r1" "c3" "r1" "c1" "r1"
+
+# s1 doesn't see a row as deleted until s2 commits, but s2 does
+permutation "r1" "d2" "r2" "r1" "c2" "r1" "c1" "r1" "c3"
+
+# same again, but this time it's an insert
+permutation "r1" "i3" "r3" "r1" "c3" "r1" "c1" "r1" "c2"
diff --git a/src/test/isolation/specs/zheap_non-inplace-update.spec b/src/test/isolation/specs/zheap_non-inplace-update.spec
new file mode 100644
index 0000000..c5cee85
--- /dev/null
+++ b/src/test/isolation/specs/zheap_non-inplace-update.spec
@@ -0,0 +1,40 @@
+# Simple tests that show the behavior of snapshots working correctly
+# for non-inplace-updates.
+
+setup
+{
+ CREATE TABLE animals (name text, counter int) USING zheap;
+ CREATE INDEX idx_animals_counter ON animals USING BTREE(counter);
+ INSERT INTO animals VALUES ('cat', 1), ('dog', 1), ('monkey', 1);
+}
+
+teardown
+{
+ DROP TABLE animals;
+}
+
+session "s1"
+setup		{ BEGIN; }
+step "r1"	{ SELECT * FROM animals; }
+step "c1"	{ COMMIT; }
+
+# index key update
+session "s2"
+setup       { BEGIN; }
+step "w2"	{ UPDATE animals SET counter = counter + 1 WHERE name = 'cat'; }
+step "r2"	{ SELECT * FROM animals; }
+step "c2"	{ COMMIT; }
+
+# tuple size increase
+session "s3"
+setup       { BEGIN; }
+step "w3"	{ UPDATE animals SET name = 'cat1' WHERE name = 'cat'; }
+step "r3"	{ SELECT * FROM animals; }
+step "c3"	{ COMMIT; }
+
+# s1 sees previous version of "cat" tuple until the new version is committed
+# but s2 sees its own uncommitted data
+permutation "r1" "w2" "r2" "r1" "c2" "r1" "c1" "r1"  "c3"
+
+# same thing, but for tuple size increase
+permutation "r1" "w3" "r3" "r1" "c3" "r1" "c1" "r1"  "c2"
diff --git a/src/test/isolation/specs/zheap_tidscan.spec b/src/test/isolation/specs/zheap_tidscan.spec
new file mode 100644
index 0000000..f07de7f
--- /dev/null
+++ b/src/test/isolation/specs/zheap_tidscan.spec
@@ -0,0 +1,26 @@
+# Scenarios that test sanity of zheap_get_latest_tid() function
+
+setup
+{
+  CREATE TABLE tidscan (a int PRIMARY KEY, v varchar) USING zheap;
+  INSERT INTO tidscan VALUES (1, NULL);
+}
+
+teardown
+{
+  DROP TABLE tidscan;
+}
+
+session "s1"
+setup		{ BEGIN; }
+step "s1u"	{ UPDATE tidscan SET a = a + 1; }
+step "s1c"	{ COMMIT; }
+
+session "s2"
+setup		{ BEGIN; }
+step "s2f"	{ DECLARE c CURSOR FOR SELECT a FROM tidscan; FETCH FIRST FROM c; }
+step "s2u"	{ UPDATE tidscan SET a = a + 2, v = 'session2' WHERE CURRENT  OF c; }
+step "s2c"	{ COMMIT; }
+step "s2s"	{ SELECT * from tidscan ORDER BY a; }
+
+permutation "s1u" "s2f" "s2u" "s1c" "s2c" "s2s"
diff --git a/src/test/isolation/specs/zheap_tpd.spec b/src/test/isolation/specs/zheap_tpd.spec
new file mode 100644
index 0000000..96be779
--- /dev/null
+++ b/src/test/isolation/specs/zheap_tpd.spec
@@ -0,0 +1,63 @@
+# Simple tests that show the working of zheap correctly with TPD.
+setup
+{
+ CREATE TABLE animals (name text, counter int) USING zheap;
+ INSERT INTO animals VALUES ('cat', 1), ('dog', 10), ('monkey', 100);
+}
+
+teardown
+{
+ DROP TABLE animals;
+}
+
+session "s1"
+setup		{ BEGIN; }
+step "r1"	{ SELECT * FROM animals; }
+step "i1"	{ INSERT INTO ANIMALS VALUES ('cow', 11); }
+step "t1"	{ DELETE FROM ANIMALS WHERE name = 'dog'; }
+step "c1"	{ COMMIT; }
+
+# insert and index key update
+session "s2"
+setup       { BEGIN; }
+step "w2"	{ UPDATE animals SET counter = counter + 2 WHERE name = 'cat'; }
+step "i2"	{ INSERT INTO ANIMALS VALUES ('lion', 22); }
+step "r2"	{ SELECT * FROM animals; }
+step "t2"	{ DELETE FROM ANIMALS WHERE name = 'lion'; }
+step "c2"	{ COMMIT; }
+step "d2"	{ ROLLBACK; }
+
+# tuple size increase
+session "s3"
+setup       { BEGIN; }
+step "i3"	{ INSERT INTO ANIMALS VALUES ('panther', 33); }
+step "w3"	{ UPDATE animals SET counter = counter + 3 WHERE name = 'cat'; }
+step "t3"	{ DELETE FROM ANIMALS WHERE counter < 3; }
+step "r3"	{ SELECT * FROM animals; }
+step "c3"	{ COMMIT; }
+
+# index key update
+session "s4"
+setup       { BEGIN; }
+step "i4"	{ INSERT INTO ANIMALS VALUES ('giraffe', 44); }
+step "w4"	{ UPDATE animals SET counter = counter + 4 WHERE name = 'cat'; }
+step "r4"	{ SELECT * FROM animals; }
+step "c4"	{ COMMIT; }
+
+# insert and index key update
+session "s5"
+setup       { BEGIN; }
+step "i5"	{ INSERT INTO ANIMALS VALUES('tiger', 55); }
+step "w5"	{ UPDATE animals SET counter = counter + 5 WHERE name = 'cat'; }
+step "r5"	{ SELECT * FROM animals; }
+step "t5"	{ DELETE FROM ANIMALS WHERE name = 'dog'; }
+step "c5"	{ COMMIT; }
+
+# check if the insertions are handled with TPD pages
+permutation "i1" "i2" "i3" "i4" "i5" "c5" "r5" "c4" "r4" "c2" "r2" "c3" "r3" "c1" "r1"
+
+# check if the updates with rollback are handled are with TPD pages
+permutation "i1" "i2" "i3" "i4" "i5" "w5" "c5" "r5" "w2" "d2" "r2" "w3" "c3" "r3" "c1" "c4"
+
+# check for the correct handling of deletes with rollback with TPD pages
+permutation "i1" "i2" "i3" "i4" "i5" "t5" "c5" "r5" "t2" "d2" "r2" "t3" "c3" "r3" "c1" "c4"
diff --git a/src/test/modules/Makefile b/src/test/modules/Makefile
index 60d6d7b..bc002d6 100644
--- a/src/test/modules/Makefile
+++ b/src/test/modules/Makefile
@@ -19,6 +19,7 @@ SUBDIRS = \
 		  test_rbtree \
 		  test_rls_hooks \
 		  test_shm_mq \
+		  test_alter_tablespace_zheap \
 		  unsafe_tests \
 		  worker_spi
 
diff --git a/src/test/modules/test_alter_tablespace_zheap/Makefile b/src/test/modules/test_alter_tablespace_zheap/Makefile
new file mode 100644
index 0000000..f5cfdb7
--- /dev/null
+++ b/src/test/modules/test_alter_tablespace_zheap/Makefile
@@ -0,0 +1,24 @@
+# src/test/modules/test_alter_tablespace_zheap/Makefile
+
+EXTRA_INSTALL=contrib/pageinspect
+
+REGRESS = alter_tablespace_zheap
+REGRESS_OPTS = --temp-config=$(top_srcdir)/src/test/modules/test_alter_tablespace_zheap/atz.conf
+
+ifdef USE_PGXS
+PG_CONFIG = pg_config
+PGXS := $(shell $(PG_CONFIG) --pgxs)
+include $(PGXS)
+else
+subdir = src/test/modules/test_alter_tablespace_zheap
+top_builddir = ../../../..
+include $(top_builddir)/src/Makefile.global
+include $(top_srcdir)/contrib/contrib-global.mk
+endif
+
+check: tablespace-setup temp-install
+
+.PHONY: tablespace-setup
+tablespace-setup:
+	rm -fr ./testtablespace
+	mkdir ./testtablespace
diff --git a/src/test/modules/test_alter_tablespace_zheap/atz.conf b/src/test/modules/test_alter_tablespace_zheap/atz.conf
new file mode 100644
index 0000000..44d5c29
--- /dev/null
+++ b/src/test/modules/test_alter_tablespace_zheap/atz.conf
@@ -0,0 +1,6 @@
+# We've to create all the tables in zheap storage format. Also, we have to
+# perform the undo actions while performing alter table set tablespace command
+# by the backend itself.
+default_table_access_method = 'zheap'
+disable_undo_launcher = true
+rollback_overflow_size = 0
diff --git a/src/test/modules/test_alter_tablespace_zheap/expected/.gitignore b/src/test/modules/test_alter_tablespace_zheap/expected/.gitignore
new file mode 100644
index 0000000..1bb8bf6
--- /dev/null
+++ b/src/test/modules/test_alter_tablespace_zheap/expected/.gitignore
@@ -0,0 +1 @@
+# empty
diff --git a/src/test/modules/test_alter_tablespace_zheap/input/alter_tablespace_zheap.source b/src/test/modules/test_alter_tablespace_zheap/input/alter_tablespace_zheap.source
new file mode 100644
index 0000000..8bef217
--- /dev/null
+++ b/src/test/modules/test_alter_tablespace_zheap/input/alter_tablespace_zheap.source
@@ -0,0 +1,31 @@
+create tablespace regress_ts location '@testtablespace@';
+
+create table t1(a int);
+insert into t1 select generate_series(1,10);
+
+-- Rollback some transactions for which undo actions must be performed before
+-- modifying the tablespace.
+begin;update t1 set a=a+10 where a=1;rollback;
+begin;update t1 set a=a+10 where a=2;rollback;
+begin;update t1 set a=a+10 where a=3;rollback;
+begin;update t1 set a=a+10 where a=4;rollback;
+
+alter table t1 set tablespace regress_ts;
+
+-- Now, check the table definition
+\d+ t1;
+
+-- Check whether rollback has been performed.
+select a from t1;
+
+create extension pageinspect;
+
+-- There can be at most one slot which has a valid xid - xid of the transaction
+-- that inserted the tuples.
+select count(*) <= 1 from zheap_page_slots(get_raw_page('t1', 1)) where xid != 0;
+
+drop extension pageinspect;
+drop table t1;
+
+-- check that we can drop tablespaces (because there is nothing in them)
+drop tablespace regress_ts;
diff --git a/src/test/modules/test_alter_tablespace_zheap/output/alter_tablespace_zheap.source b/src/test/modules/test_alter_tablespace_zheap/output/alter_tablespace_zheap.source
new file mode 100644
index 0000000..c0f570f
--- /dev/null
+++ b/src/test/modules/test_alter_tablespace_zheap/output/alter_tablespace_zheap.source
@@ -0,0 +1,47 @@
+create tablespace regress_ts location '@testtablespace@';
+create table t1(a int);
+insert into t1 select generate_series(1,10);
+-- Rollback some transactions for which undo actions must be performed before
+-- modifying the tablespace.
+begin;update t1 set a=a+10 where a=1;rollback;
+begin;update t1 set a=a+10 where a=2;rollback;
+begin;update t1 set a=a+10 where a=3;rollback;
+begin;update t1 set a=a+10 where a=4;rollback;
+alter table t1 set tablespace regress_ts;
+-- Now, check the table definition
+\d+ t1;
+                                    Table "public.t1"
+ Column |  Type   | Collation | Nullable | Default | Storage | Stats target | Description 
+--------+---------+-----------+----------+---------+---------+--------------+-------------
+ a      | integer |           |          |         | plain   |              | 
+Tablespace: "regress_ts"
+
+-- Check whether rollback has been performed.
+select a from t1;
+ a  
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+(10 rows)
+
+create extension pageinspect;
+-- There can be at most one slot which has a valid xid - xid of the transaction
+-- that inserted the tuples.
+select count(*) <= 1 from zheap_page_slots(get_raw_page('t1', 1)) where xid != 0;
+ ?column? 
+----------
+ t
+(1 row)
+
+drop extension pageinspect;
+drop table t1;
+-- check that we can drop tablespaces (because there is nothing in them)
+drop tablespace regress_ts;
diff --git a/src/test/modules/test_alter_tablespace_zheap/sql/.gitignore b/src/test/modules/test_alter_tablespace_zheap/sql/.gitignore
new file mode 100644
index 0000000..9297299
--- /dev/null
+++ b/src/test/modules/test_alter_tablespace_zheap/sql/.gitignore
@@ -0,0 +1,2 @@
+# empty
+alter_tablespace_zheap.sql
diff --git a/src/test/regress/expected/arrays.out b/src/test/regress/expected/arrays.out
index c730563..d4bf6f0 100644
--- a/src/test/regress/expected/arrays.out
+++ b/src/test/regress/expected/arrays.out
@@ -105,11 +105,11 @@ UPDATE arrtest
 UPDATE arrtest
   SET c[2:2] = '{"new_word"}'
   WHERE array_dims(c) is not null;
-SELECT a,b,c FROM arrtest;
+SELECT a,b,c FROM arrtest ORDER BY a;
        a       |           b           |         c         
 ---------------+-----------------------+-------------------
- {16,25,3,4,5} | {{{113,142},{1,147}}} | {}
  {}            | {3,4}                 | {foo,new_word}
+ {16,25,3,4,5} | {{{113,142},{1,147}}} | {}
  {16,25,23}    | {{3,4},{4,5}}         | {foobar,new_word}
 (3 rows)
 
@@ -117,44 +117,44 @@ SELECT a[1:3],
           b[1:1][1:2][1:2],
           c[1:2],
           d[1:1][2:2]
-   FROM arrtest;
+   FROM arrtest ORDER BY a;
      a      |           b           |         c         |    d     
 ------------+-----------------------+-------------------+----------
- {16,25,3}  | {{{113,142},{1,147}}} | {}                | {}
  {}         | {}                    | {foo,new_word}    | {}
+ {16,25,3}  | {{{113,142},{1,147}}} | {}                | {}
  {16,25,23} | {}                    | {foobar,new_word} | {{elt2}}
 (3 rows)
 
 SELECT b[1:1][2][2],
        d[1:1][2]
-   FROM arrtest;
+   FROM arrtest ORDER BY b, d;
            b           |       d       
 -----------------------+---------------
- {{{113,142},{1,147}}} | {}
  {}                    | {}
  {}                    | {{elt1,elt2}}
+ {{{113,142},{1,147}}} | {}
 (3 rows)
 
 INSERT INTO arrtest(a) VALUES('{1,null,3}');
-SELECT a FROM arrtest;
+SELECT a FROM arrtest ORDER BY a;
        a       
 ---------------
- {16,25,3,4,5}
  {}
- {16,25,23}
  {1,NULL,3}
+ {16,25,3,4,5}
+ {16,25,23}
 (4 rows)
 
 UPDATE arrtest SET a[4] = NULL WHERE a[2] IS NULL;
-SELECT a FROM arrtest WHERE a[2] IS NULL;
+SELECT a FROM arrtest WHERE a[2] IS NULL ORDER BY a;
         a        
 -----------------
- [4:4]={NULL}
  {1,NULL,3,NULL}
+ [4:4]={NULL}
 (2 rows)
 
 DELETE FROM arrtest WHERE a[2] IS NULL AND b IS NULL;
-SELECT a,b,c FROM arrtest;
+SELECT a,b,c FROM arrtest ORDER BY a,b,c;
        a       |           b           |         c         
 ---------------+-----------------------+-------------------
  {16,25,3,4,5} | {{{113,142},{1,147}}} | {}
@@ -263,7 +263,7 @@ SELECT a[:], b[:] FROM arrtest_s;
 -- updates
 UPDATE arrtest_s SET a[:3] = '{11, 12, 13}', b[:2][:2] = '{{11,12}, {14,15}}'
   WHERE array_lower(a,1) = 1;
-SELECT * FROM arrtest_s;
+SELECT * FROM arrtest_s ORDER BY 1;
          a         |                  b                   
 -------------------+--------------------------------------
  [0:4]={1,2,3,4,5} | [0:2][0:2]={{1,2,3},{4,5,6},{7,8,9}}
@@ -271,7 +271,7 @@ SELECT * FROM arrtest_s;
 (2 rows)
 
 UPDATE arrtest_s SET a[3:] = '{23, 24, 25}', b[2:][2:] = '{{25,26}, {28,29}}';
-SELECT * FROM arrtest_s;
+SELECT * FROM arrtest_s ORDER BY 1;
           a          |                   b                   
 ---------------------+---------------------------------------
  [0:4]={1,2,3,23,24} | [0:2][0:2]={{1,2,3},{4,5,6},{7,8,25}}
@@ -279,7 +279,7 @@ SELECT * FROM arrtest_s;
 (2 rows)
 
 UPDATE arrtest_s SET a[:] = '{11, 12, 13, 14, 15}';
-SELECT * FROM arrtest_s;
+SELECT * FROM arrtest_s ORDER BY 1;
            a            |                   b                   
 ------------------------+---------------------------------------
  [0:4]={11,12,13,14,15} | [0:2][0:2]={{1,2,3},{4,5,6},{7,8,25}}
diff --git a/src/test/regress/expected/box.out b/src/test/regress/expected/box.out
index 4d0f169..4c32183 100644
--- a/src/test/regress/expected/box.out
+++ b/src/test/regress/expected/box.out
@@ -253,6 +253,7 @@ INSERT INTO box_temp
 		   ('(-infinity,0)(0,infinity)'),
 		   ('(-infinity,-infinity)(infinity,infinity)');
 SET enable_seqscan = false;
+SET enable_bitmapscan = false;
 SELECT * FROM box_temp WHERE f1 << '(10,20),(30,40)';
              f1             
 ----------------------------
diff --git a/src/test/regress/expected/case.out b/src/test/regress/expected/case.out
index c0c8acf..1488b51 100644
--- a/src/test/regress/expected/case.out
+++ b/src/test/regress/expected/case.out
@@ -269,25 +269,25 @@ SELECT '' AS "Two", *
 UPDATE CASE_TBL
   SET i = CASE WHEN i >= 3 THEN (- i)
                 ELSE (2 * i) END;
-SELECT * FROM CASE_TBL;
+SELECT * FROM CASE_TBL ORDER BY i;
  i  |   f   
 ----+-------
+ -4 |      
+ -3 | -30.3
   2 |  10.1
   4 |  20.2
- -3 | -30.3
- -4 |      
 (4 rows)
 
 UPDATE CASE_TBL
   SET i = CASE WHEN i >= 2 THEN (2 * i)
                 ELSE (3 * i) END;
-SELECT * FROM CASE_TBL;
+SELECT * FROM CASE_TBL ORDER BY i;
   i  |   f   
 -----+-------
+ -12 |      
+  -9 | -30.3
    4 |  10.1
    8 |  20.2
-  -9 | -30.3
- -12 |      
 (4 rows)
 
 UPDATE CASE_TBL
@@ -295,13 +295,13 @@ UPDATE CASE_TBL
                 ELSE (3 * j) END
   FROM CASE2_TBL b
   WHERE j = -CASE_TBL.i;
-SELECT * FROM CASE_TBL;
+SELECT * FROM CASE_TBL ORDER BY i;
   i  |   f   
 -----+-------
-   8 |  20.2
-  -9 | -30.3
  -12 |      
+  -9 | -30.3
   -8 |  10.1
+   8 |  20.2
 (4 rows)
 
 --
diff --git a/src/test/regress/expected/combocid_1.out b/src/test/regress/expected/combocid_1.out
new file mode 100644
index 0000000..a2fb460
--- /dev/null
+++ b/src/test/regress/expected/combocid_1.out
@@ -0,0 +1,117 @@
+--
+-- Tests for some likely failure cases with combo cmin/cmax mechanism
+--
+CREATE TEMP TABLE combocidtest (foobar int);
+BEGIN;
+-- a few dummy ops to push up the CommandId counter
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest VALUES (1);
+INSERT INTO combocidtest VALUES (2);
+SELECT ctid,cmin,* FROM combocidtest;
+ERROR:  xmax, cmin, and cmax are not supported for zheap tuples
+SAVEPOINT s1;
+ERROR:  current transaction is aborted, commands ignored until end of transaction block
+UPDATE combocidtest SET foobar = foobar + 10;
+ERROR:  current transaction is aborted, commands ignored until end of transaction block
+-- here we should see only updated tuples
+SELECT ctid,cmin,* FROM combocidtest;
+ERROR:  current transaction is aborted, commands ignored until end of transaction block
+ROLLBACK TO s1;
+ERROR:  savepoint "s1" does not exist
+-- now we should see old tuples, but with combo CIDs starting at 0
+SELECT ctid,cmin,* FROM combocidtest;
+ERROR:  current transaction is aborted, commands ignored until end of transaction block
+COMMIT;
+-- combo data is not there anymore, but should still see tuples
+SELECT ctid,cmin,* FROM combocidtest;
+ ctid | cmin | foobar 
+------+------+--------
+(0 rows)
+
+-- Test combo cids with portals
+BEGIN;
+INSERT INTO combocidtest VALUES (333);
+DECLARE c CURSOR FOR SELECT ctid,cmin,* FROM combocidtest;
+DELETE FROM combocidtest;
+FETCH ALL FROM c;
+ERROR:  xmax, cmin, and cmax are not supported for zheap tuples
+ROLLBACK;
+SELECT ctid,cmin,* FROM combocidtest;
+ ctid | cmin | foobar 
+------+------+--------
+(0 rows)
+
+-- check behavior with locked tuples
+BEGIN;
+-- a few dummy ops to push up the CommandId counter
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest SELECT 1 LIMIT 0;
+INSERT INTO combocidtest VALUES (444);
+SELECT ctid,cmin,* FROM combocidtest;
+ERROR:  xmax, cmin, and cmax are not supported for zheap tuples
+SAVEPOINT s1;
+ERROR:  current transaction is aborted, commands ignored until end of transaction block
+-- this doesn't affect cmin
+SELECT ctid,cmin,* FROM combocidtest FOR UPDATE;
+ERROR:  current transaction is aborted, commands ignored until end of transaction block
+SELECT ctid,cmin,* FROM combocidtest;
+ERROR:  current transaction is aborted, commands ignored until end of transaction block
+-- but this does
+UPDATE combocidtest SET foobar = foobar + 10;
+ERROR:  current transaction is aborted, commands ignored until end of transaction block
+SELECT ctid,cmin,* FROM combocidtest;
+ERROR:  current transaction is aborted, commands ignored until end of transaction block
+ROLLBACK TO s1;
+ERROR:  savepoint "s1" does not exist
+SELECT ctid,cmin,* FROM combocidtest;
+ERROR:  current transaction is aborted, commands ignored until end of transaction block
+COMMIT;
+SELECT ctid,cmin,* FROM combocidtest;
+ ctid | cmin | foobar 
+------+------+--------
+(0 rows)
+
+-- test for bug reported in
+-- CABRT9RC81YUf1=jsmWopcKJEro=VoeG2ou6sPwyOUTx_qteRsg@mail.gmail.com
+CREATE TABLE IF NOT EXISTS testcase(
+	id int PRIMARY KEY,
+	balance numeric
+);
+INSERT INTO testcase VALUES (1, 0);
+BEGIN;
+SELECT * FROM testcase WHERE testcase.id = 1 FOR UPDATE;
+ id | balance 
+----+---------
+  1 |       0
+(1 row)
+
+UPDATE testcase SET balance = balance + 400 WHERE id=1;
+SAVEPOINT subxact;
+UPDATE testcase SET balance = balance - 100 WHERE id=1;
+ROLLBACK TO SAVEPOINT subxact;
+-- should return one tuple
+SELECT * FROM testcase WHERE id = 1 FOR UPDATE;
+ id | balance 
+----+---------
+  1 |     400
+(1 row)
+
+ROLLBACK;
+DROP TABLE testcase;
diff --git a/src/test/regress/expected/copy2_1.out b/src/test/regress/expected/copy2_1.out
new file mode 100644
index 0000000..3bbb7bd
--- /dev/null
+++ b/src/test/regress/expected/copy2_1.out
@@ -0,0 +1,616 @@
+CREATE TEMP TABLE x (
+	a serial,
+	b int,
+	c text not null default 'stuff',
+	d text,
+	e text
+) ;
+CREATE FUNCTION fn_x_before () RETURNS TRIGGER AS '
+  BEGIN
+		NEW.e := ''before trigger fired''::text;
+		return NEW;
+	END;
+' LANGUAGE plpgsql;
+CREATE FUNCTION fn_x_after () RETURNS TRIGGER AS '
+  BEGIN
+		UPDATE x set e=''after trigger fired'' where c=''stuff'';
+		return NULL;
+	END;
+' LANGUAGE plpgsql;
+CREATE TRIGGER trg_x_after AFTER INSERT ON x
+FOR EACH ROW EXECUTE PROCEDURE fn_x_after();
+CREATE TRIGGER trg_x_before BEFORE INSERT ON x
+FOR EACH ROW EXECUTE PROCEDURE fn_x_before();
+COPY x (a, b, c, d, e) from stdin;
+COPY x (b, d) from stdin;
+COPY x (b, d) from stdin;
+COPY x (a, b, c, d, e) from stdin;
+-- non-existent column in column list: should fail
+COPY x (xyz) from stdin;
+ERROR:  column "xyz" of relation "x" does not exist
+-- too many columns in column list: should fail
+COPY x (a, b, c, d, e, d, c) from stdin;
+ERROR:  column "d" specified more than once
+-- missing data: should fail
+COPY x from stdin;
+ERROR:  invalid input syntax for type integer: ""
+CONTEXT:  COPY x, line 1, column a: ""
+COPY x from stdin;
+ERROR:  missing data for column "e"
+CONTEXT:  COPY x, line 1: "2000	230	23	23"
+COPY x from stdin;
+ERROR:  missing data for column "e"
+CONTEXT:  COPY x, line 1: "2001	231	\N	\N"
+-- extra data: should fail
+COPY x from stdin;
+ERROR:  extra data after last expected column
+CONTEXT:  COPY x, line 1: "2002	232	40	50	60	70	80"
+-- various COPY options: delimiters, oids, NULL string, encoding
+COPY x (b, c, d, e) from stdin delimiter ',' null 'x';
+COPY x from stdin WITH DELIMITER AS ';' NULL AS '';
+COPY x from stdin WITH DELIMITER AS ':' NULL AS E'\\X' ENCODING 'sql_ascii';
+COPY x TO stdout WHERE a = 1;
+ERROR:  WHERE clause not allowed with COPY TO
+LINE 1: COPY x TO stdout WHERE a = 1;
+                         ^
+COPY x from stdin WHERE a = 50004;
+COPY x from stdin WHERE a > 60003;
+COPY x from stdin WHERE f > 60003;
+ERROR:  column "f" does not exist
+LINE 1: COPY x from stdin WHERE f > 60003;
+                                ^
+COPY x from stdin WHERE a = max(x.b);
+ERROR:  aggregate functions are not allowed in COPY FROM WHERE conditions
+LINE 1: COPY x from stdin WHERE a = max(x.b);
+                                    ^
+COPY x from stdin WHERE a IN (SELECT 1 FROM x);
+ERROR:  cannot use subquery in COPY FROM WHERE condition
+LINE 1: COPY x from stdin WHERE a IN (SELECT 1 FROM x);
+                                  ^
+COPY x from stdin WHERE a IN (generate_series(1,5));
+ERROR:  set-returning functions are not allowed in COPY FROM WHERE conditions
+LINE 1: COPY x from stdin WHERE a IN (generate_series(1,5));
+                                      ^
+COPY x from stdin WHERE a = row_number() over(b);
+ERROR:  window functions are not allowed in COPY FROM WHERE conditions
+LINE 1: COPY x from stdin WHERE a = row_number() over(b);
+                                    ^
+-- check results of copy in
+SELECT * FROM x;
+   a   | b  |     c      |   d    |          e           
+-------+----+------------+--------+----------------------
+  9999 |    | \N         | NN     | before trigger fired
+ 10000 | 21 | 31         | 41     | before trigger fired
+     1 |  1 | stuff      | test_1 | after trigger fired
+     2 |  2 | stuff      | test_2 | after trigger fired
+     3 |  3 | stuff      | test_3 | after trigger fired
+     4 |  4 | stuff      | test_4 | after trigger fired
+     5 |  5 | stuff      | test_5 | after trigger fired
+ 10001 | 22 | 32         | 42     | before trigger fired
+ 10002 | 23 | 33         | 43     | before trigger fired
+ 10003 | 24 | 34         | 44     | before trigger fired
+ 10004 | 25 | 35         | 45     | before trigger fired
+ 10005 | 26 | 36         | 46     | before trigger fired
+     6 |    | 45         | 80     | before trigger fired
+     7 |    | x          | \x     | before trigger fired
+     8 |    | ,          | \,     | before trigger fired
+  3000 |    | c          |        | before trigger fired
+  4000 |    | C          |        | before trigger fired
+  4001 |  1 | empty      |        | before trigger fired
+  4002 |  2 | null       |        | before trigger fired
+  4003 |  3 | Backslash  | \      | before trigger fired
+  4004 |  4 | BackslashX | \X     | before trigger fired
+  4005 |  5 | N          | N      | before trigger fired
+  4006 |  6 | BackslashN | \N     | before trigger fired
+  4007 |  7 | XX         | XX     | before trigger fired
+  4008 |  8 | Delimiter  | :      | before trigger fired
+ 50004 | 25 | 35         | 45     | before trigger fired
+ 60004 | 25 | 35         | 45     | before trigger fired
+ 60005 | 26 | 36         | 46     | before trigger fired
+(28 rows)
+
+-- check copy out
+COPY x TO stdout;
+9999	\N	\\N	NN	before trigger fired
+10000	21	31	41	before trigger fired
+1	1	stuff	test_1	after trigger fired
+2	2	stuff	test_2	after trigger fired
+3	3	stuff	test_3	after trigger fired
+4	4	stuff	test_4	after trigger fired
+5	5	stuff	test_5	after trigger fired
+10001	22	32	42	before trigger fired
+10002	23	33	43	before trigger fired
+10003	24	34	44	before trigger fired
+10004	25	35	45	before trigger fired
+10005	26	36	46	before trigger fired
+6	\N	45	80	before trigger fired
+7	\N	x	\\x	before trigger fired
+8	\N	,	\\,	before trigger fired
+3000	\N	c	\N	before trigger fired
+4000	\N	C	\N	before trigger fired
+4001	1	empty		before trigger fired
+4002	2	null	\N	before trigger fired
+4003	3	Backslash	\\	before trigger fired
+4004	4	BackslashX	\\X	before trigger fired
+4005	5	N	N	before trigger fired
+4006	6	BackslashN	\\N	before trigger fired
+4007	7	XX	XX	before trigger fired
+4008	8	Delimiter	:	before trigger fired
+50004	25	35	45	before trigger fired
+60004	25	35	45	before trigger fired
+60005	26	36	46	before trigger fired
+COPY x (c, e) TO stdout;
+\\N	before trigger fired
+31	before trigger fired
+stuff	after trigger fired
+stuff	after trigger fired
+stuff	after trigger fired
+stuff	after trigger fired
+stuff	after trigger fired
+32	before trigger fired
+33	before trigger fired
+34	before trigger fired
+35	before trigger fired
+36	before trigger fired
+45	before trigger fired
+x	before trigger fired
+,	before trigger fired
+c	before trigger fired
+C	before trigger fired
+empty	before trigger fired
+null	before trigger fired
+Backslash	before trigger fired
+BackslashX	before trigger fired
+N	before trigger fired
+BackslashN	before trigger fired
+XX	before trigger fired
+Delimiter	before trigger fired
+35	before trigger fired
+35	before trigger fired
+36	before trigger fired
+COPY x (b, e) TO stdout WITH NULL 'I''m null';
+I'm null	before trigger fired
+21	before trigger fired
+1	after trigger fired
+2	after trigger fired
+3	after trigger fired
+4	after trigger fired
+5	after trigger fired
+22	before trigger fired
+23	before trigger fired
+24	before trigger fired
+25	before trigger fired
+26	before trigger fired
+I'm null	before trigger fired
+I'm null	before trigger fired
+I'm null	before trigger fired
+I'm null	before trigger fired
+I'm null	before trigger fired
+1	before trigger fired
+2	before trigger fired
+3	before trigger fired
+4	before trigger fired
+5	before trigger fired
+6	before trigger fired
+7	before trigger fired
+8	before trigger fired
+25	before trigger fired
+25	before trigger fired
+26	before trigger fired
+CREATE TEMP TABLE y (
+	col1 text,
+	col2 text
+);
+INSERT INTO y VALUES ('Jackson, Sam', E'\\h');
+INSERT INTO y VALUES ('It is "perfect".',E'\t');
+INSERT INTO y VALUES ('', NULL);
+COPY y TO stdout WITH CSV;
+"Jackson, Sam",\h
+"It is ""perfect"".",	
+"",
+COPY y TO stdout WITH CSV QUOTE '''' DELIMITER '|';
+Jackson, Sam|\h
+It is "perfect".|	
+''|
+COPY y TO stdout WITH CSV FORCE QUOTE col2 ESCAPE E'\\' ENCODING 'sql_ascii';
+"Jackson, Sam","\\h"
+"It is \"perfect\".","	"
+"",
+COPY y TO stdout WITH CSV FORCE QUOTE *;
+"Jackson, Sam","\h"
+"It is ""perfect"".","	"
+"",
+-- Repeat above tests with new 9.0 option syntax
+COPY y TO stdout (FORMAT CSV);
+"Jackson, Sam",\h
+"It is ""perfect"".",	
+"",
+COPY y TO stdout (FORMAT CSV, QUOTE '''', DELIMITER '|');
+Jackson, Sam|\h
+It is "perfect".|	
+''|
+COPY y TO stdout (FORMAT CSV, FORCE_QUOTE (col2), ESCAPE E'\\');
+"Jackson, Sam","\\h"
+"It is \"perfect\".","	"
+"",
+COPY y TO stdout (FORMAT CSV, FORCE_QUOTE *);
+"Jackson, Sam","\h"
+"It is ""perfect"".","	"
+"",
+\copy y TO stdout (FORMAT CSV)
+"Jackson, Sam",\h
+"It is ""perfect"".",	
+"",
+\copy y TO stdout (FORMAT CSV, QUOTE '''', DELIMITER '|')
+Jackson, Sam|\h
+It is "perfect".|	
+''|
+\copy y TO stdout (FORMAT CSV, FORCE_QUOTE (col2), ESCAPE E'\\')
+"Jackson, Sam","\\h"
+"It is \"perfect\".","	"
+"",
+\copy y TO stdout (FORMAT CSV, FORCE_QUOTE *)
+"Jackson, Sam","\h"
+"It is ""perfect"".","	"
+"",
+--test that we read consecutive LFs properly
+CREATE TEMP TABLE testnl (a int, b text, c int);
+COPY testnl FROM stdin CSV;
+-- test end of copy marker
+CREATE TEMP TABLE testeoc (a text);
+COPY testeoc FROM stdin CSV;
+COPY testeoc TO stdout CSV;
+a\.
+\.b
+c\.d
+"\."
+-- test handling of nonstandard null marker that violates escaping rules
+CREATE TEMP TABLE testnull(a int, b text);
+INSERT INTO testnull VALUES (1, E'\\0'), (NULL, NULL);
+COPY testnull TO stdout WITH NULL AS E'\\0';
+1	\\0
+\0	\0
+COPY testnull FROM stdin WITH NULL AS E'\\0';
+SELECT * FROM testnull;
+ a  | b  
+----+----
+  1 | \0
+    | 
+ 42 | \0
+    | 
+(4 rows)
+
+BEGIN;
+CREATE TABLE vistest (LIKE testeoc);
+COPY vistest FROM stdin CSV;
+COMMIT;
+SELECT * FROM vistest;
+ a  
+----
+ a0
+ b
+(2 rows)
+
+BEGIN;
+TRUNCATE vistest;
+COPY vistest FROM stdin CSV;
+SELECT * FROM vistest;
+ a  
+----
+ a1
+ b
+(2 rows)
+
+SAVEPOINT s1;
+TRUNCATE vistest;
+COPY vistest FROM stdin CSV;
+SELECT * FROM vistest;
+ a  
+----
+ d1
+ e
+(2 rows)
+
+COMMIT;
+SELECT * FROM vistest;
+ a  
+----
+ d1
+ e
+(2 rows)
+
+BEGIN;
+TRUNCATE vistest;
+COPY vistest FROM stdin CSV FREEZE;
+SELECT * FROM vistest;
+ a  
+----
+ a2
+ b
+(2 rows)
+
+SAVEPOINT s1;
+TRUNCATE vistest;
+COPY vistest FROM stdin CSV FREEZE;
+SELECT * FROM vistest;
+ a  
+----
+ d2
+ e
+(2 rows)
+
+COMMIT;
+SELECT * FROM vistest;
+ a  
+----
+ d2
+ e
+(2 rows)
+
+BEGIN;
+TRUNCATE vistest;
+COPY vistest FROM stdin CSV FREEZE;
+SELECT * FROM vistest;
+ a 
+---
+ x
+ y
+(2 rows)
+
+COMMIT;
+TRUNCATE vistest;
+COPY vistest FROM stdin CSV FREEZE;
+ERROR:  cannot perform COPY FREEZE because the table was not created or truncated in the current subtransaction
+BEGIN;
+TRUNCATE vistest;
+SAVEPOINT s1;
+COPY vistest FROM stdin CSV FREEZE;
+ERROR:  cannot perform COPY FREEZE because the table was not created or truncated in the current subtransaction
+COMMIT;
+BEGIN;
+INSERT INTO vistest VALUES ('z');
+SAVEPOINT s1;
+TRUNCATE vistest;
+ROLLBACK TO SAVEPOINT s1;
+COPY vistest FROM stdin CSV FREEZE;
+ERROR:  cannot perform COPY FREEZE because the table was not created or truncated in the current subtransaction
+COMMIT;
+CREATE FUNCTION truncate_in_subxact() RETURNS VOID AS
+$$
+BEGIN
+	TRUNCATE vistest;
+EXCEPTION
+  WHEN OTHERS THEN
+	INSERT INTO vistest VALUES ('subxact failure');
+END;
+$$ language plpgsql;
+BEGIN;
+INSERT INTO vistest VALUES ('z');
+SELECT truncate_in_subxact();
+ truncate_in_subxact 
+---------------------
+ 
+(1 row)
+
+COPY vistest FROM stdin CSV FREEZE;
+SELECT * FROM vistest;
+ a  
+----
+ d4
+ e
+(2 rows)
+
+COMMIT;
+SELECT * FROM vistest;
+ a  
+----
+ d4
+ e
+(2 rows)
+
+-- Test FORCE_NOT_NULL and FORCE_NULL options
+CREATE TEMP TABLE forcetest (
+    a INT NOT NULL,
+    b TEXT NOT NULL,
+    c TEXT,
+    d TEXT,
+    e TEXT
+);
+\pset null NULL
+-- should succeed with no effect ("b" remains an empty string, "c" remains NULL)
+BEGIN;
+COPY forcetest (a, b, c) FROM STDIN WITH (FORMAT csv, FORCE_NOT_NULL(b), FORCE_NULL(c));
+COMMIT;
+SELECT b, c FROM forcetest WHERE a = 1;
+ b |  c   
+---+------
+   | NULL
+(1 row)
+
+-- should succeed, FORCE_NULL and FORCE_NOT_NULL can be both specified
+BEGIN;
+COPY forcetest (a, b, c, d) FROM STDIN WITH (FORMAT csv, FORCE_NOT_NULL(c,d), FORCE_NULL(c,d));
+COMMIT;
+SELECT c, d FROM forcetest WHERE a = 2;
+ c |  d   
+---+------
+   | NULL
+(1 row)
+
+-- should fail with not-null constraint violation
+BEGIN;
+COPY forcetest (a, b, c) FROM STDIN WITH (FORMAT csv, FORCE_NULL(b), FORCE_NOT_NULL(c));
+ERROR:  null value in column "b" violates not-null constraint
+DETAIL:  Failing row contains (3, null, , null, null).
+CONTEXT:  COPY forcetest, line 1: "3,,"""
+ROLLBACK;
+-- should fail with "not referenced by COPY" error
+BEGIN;
+COPY forcetest (d, e) FROM STDIN WITH (FORMAT csv, FORCE_NOT_NULL(b));
+ERROR:  FORCE_NOT_NULL column "b" not referenced by COPY
+ROLLBACK;
+-- should fail with "not referenced by COPY" error
+BEGIN;
+COPY forcetest (d, e) FROM STDIN WITH (FORMAT csv, FORCE_NULL(b));
+ERROR:  FORCE_NULL column "b" not referenced by COPY
+ROLLBACK;
+\pset null ''
+-- test case with whole-row Var in a check constraint
+create table check_con_tbl (f1 int);
+create function check_con_function(check_con_tbl) returns bool as $$
+begin
+  raise notice 'input = %', row_to_json($1);
+  return $1.f1 > 0;
+end $$ language plpgsql immutable;
+alter table check_con_tbl add check (check_con_function(check_con_tbl.*));
+\d+ check_con_tbl
+                               Table "public.check_con_tbl"
+ Column |  Type   | Collation | Nullable | Default | Storage | Stats target | Description 
+--------+---------+-----------+----------+---------+---------+--------------+-------------
+ f1     | integer |           |          |         | plain   |              | 
+Check constraints:
+    "check_con_tbl_check" CHECK (check_con_function(check_con_tbl.*))
+
+copy check_con_tbl from stdin;
+NOTICE:  input = {"f1":1}
+NOTICE:  input = {"f1":null}
+copy check_con_tbl from stdin;
+NOTICE:  input = {"f1":0}
+ERROR:  new row for relation "check_con_tbl" violates check constraint "check_con_tbl_check"
+DETAIL:  Failing row contains (0).
+CONTEXT:  COPY check_con_tbl, line 1: "0"
+select * from check_con_tbl;
+ f1 
+----
+  1
+   
+(2 rows)
+
+-- test with RLS enabled.
+CREATE ROLE regress_rls_copy_user;
+CREATE ROLE regress_rls_copy_user_colperms;
+CREATE TABLE rls_t1 (a int, b int, c int);
+COPY rls_t1 (a, b, c) from stdin;
+CREATE POLICY p1 ON rls_t1 FOR SELECT USING (a % 2 = 0);
+ALTER TABLE rls_t1 ENABLE ROW LEVEL SECURITY;
+ALTER TABLE rls_t1 FORCE ROW LEVEL SECURITY;
+GRANT SELECT ON TABLE rls_t1 TO regress_rls_copy_user;
+GRANT SELECT (a, b) ON TABLE rls_t1 TO regress_rls_copy_user_colperms;
+-- all columns
+COPY rls_t1 TO stdout;
+1	4	1
+2	3	2
+3	2	3
+4	1	4
+COPY rls_t1 (a, b, c) TO stdout;
+1	4	1
+2	3	2
+3	2	3
+4	1	4
+-- subset of columns
+COPY rls_t1 (a) TO stdout;
+1
+2
+3
+4
+COPY rls_t1 (a, b) TO stdout;
+1	4
+2	3
+3	2
+4	1
+-- column reordering
+COPY rls_t1 (b, a) TO stdout;
+4	1
+3	2
+2	3
+1	4
+SET SESSION AUTHORIZATION regress_rls_copy_user;
+-- all columns
+COPY rls_t1 TO stdout;
+2	3	2
+4	1	4
+COPY rls_t1 (a, b, c) TO stdout;
+2	3	2
+4	1	4
+-- subset of columns
+COPY rls_t1 (a) TO stdout;
+2
+4
+COPY rls_t1 (a, b) TO stdout;
+2	3
+4	1
+-- column reordering
+COPY rls_t1 (b, a) TO stdout;
+3	2
+1	4
+RESET SESSION AUTHORIZATION;
+SET SESSION AUTHORIZATION regress_rls_copy_user_colperms;
+-- attempt all columns (should fail)
+COPY rls_t1 TO stdout;
+ERROR:  permission denied for table rls_t1
+COPY rls_t1 (a, b, c) TO stdout;
+ERROR:  permission denied for table rls_t1
+-- try to copy column with no privileges (should fail)
+COPY rls_t1 (c) TO stdout;
+ERROR:  permission denied for table rls_t1
+-- subset of columns (should succeed)
+COPY rls_t1 (a) TO stdout;
+2
+4
+COPY rls_t1 (a, b) TO stdout;
+2	3
+4	1
+RESET SESSION AUTHORIZATION;
+-- test with INSTEAD OF INSERT trigger on a view
+CREATE TABLE instead_of_insert_tbl(id serial, name text);
+CREATE VIEW instead_of_insert_tbl_view AS SELECT ''::text AS str;
+COPY instead_of_insert_tbl_view FROM stdin; -- fail
+ERROR:  cannot copy to view "instead_of_insert_tbl_view"
+HINT:  To enable copying to a view, provide an INSTEAD OF INSERT trigger.
+CREATE FUNCTION fun_instead_of_insert_tbl() RETURNS trigger AS $$
+BEGIN
+  INSERT INTO instead_of_insert_tbl (name) VALUES (NEW.str);
+  RETURN NULL;
+END;
+$$ LANGUAGE plpgsql;
+CREATE TRIGGER trig_instead_of_insert_tbl_view
+  INSTEAD OF INSERT ON instead_of_insert_tbl_view
+  FOR EACH ROW EXECUTE PROCEDURE fun_instead_of_insert_tbl();
+COPY instead_of_insert_tbl_view FROM stdin;
+SELECT * FROM instead_of_insert_tbl;
+ id | name  
+----+-------
+  1 | test1
+(1 row)
+
+-- Test of COPY optimization with view using INSTEAD OF INSERT
+-- trigger when relation is created in the same transaction as
+-- when COPY is executed.
+BEGIN;
+CREATE VIEW instead_of_insert_tbl_view_2 as select ''::text as str;
+CREATE TRIGGER trig_instead_of_insert_tbl_view_2
+  INSTEAD OF INSERT ON instead_of_insert_tbl_view_2
+  FOR EACH ROW EXECUTE PROCEDURE fun_instead_of_insert_tbl();
+COPY instead_of_insert_tbl_view_2 FROM stdin;
+SELECT * FROM instead_of_insert_tbl;
+ id | name  
+----+-------
+  1 | test1
+  2 | test1
+(2 rows)
+
+COMMIT;
+-- clean up
+DROP TABLE forcetest;
+DROP TABLE vistest;
+DROP FUNCTION truncate_in_subxact();
+DROP TABLE x, y;
+DROP TABLE rls_t1 CASCADE;
+DROP ROLE regress_rls_copy_user;
+DROP ROLE regress_rls_copy_user_colperms;
+DROP FUNCTION fn_x_before();
+DROP FUNCTION fn_x_after();
+DROP TABLE instead_of_insert_tbl;
+DROP VIEW instead_of_insert_tbl_view;
+DROP VIEW instead_of_insert_tbl_view_2;
+DROP FUNCTION fun_instead_of_insert_tbl();
diff --git a/src/test/regress/expected/create_am.out b/src/test/regress/expected/create_am.out
index 84da403..b997de3 100644
--- a/src/test/regress/expected/create_am.out
+++ b/src/test/regress/expected/create_am.out
@@ -126,11 +126,12 @@ ERROR:  function int4in(internal) does not exist
 CREATE ACCESS METHOD bogus TYPE TABLE HANDLER bthandler;
 ERROR:  function bthandler must return type table_am_handler
 SELECT amname, amhandler, amtype FROM pg_am where amtype = 't' ORDER BY 1, 2;
- amname |      amhandler       | amtype 
---------+----------------------+--------
- heap   | heap_tableam_handler | t
- heap2  | heap_tableam_handler | t
-(2 rows)
+ amname |       amhandler       | amtype 
+--------+-----------------------+--------
+ heap   | heap_tableam_handler  | t
+ heap2  | heap_tableam_handler  | t
+ zheap  | zheap_tableam_handler | t
+(3 rows)
 
 -- First create tables employing the new AM using USING
 -- plain CREATE TABLE
diff --git a/src/test/regress/expected/float4.out b/src/test/regress/expected/float4.out
index 901abb1..577b532 100644
--- a/src/test/regress/expected/float4.out
+++ b/src/test/regress/expected/float4.out
@@ -263,14 +263,14 @@ SELECT '' AS five, f.f1, @f.f1 AS abs_f1 FROM FLOAT4_TBL f;
 UPDATE FLOAT4_TBL
    SET f1 = FLOAT4_TBL.f1 * '-1'
    WHERE FLOAT4_TBL.f1 > '0.0';
-SELECT '' AS five, * FROM FLOAT4_TBL;
+SELECT '' AS five, * FROM FLOAT4_TBL ORDER BY f1 DESC;
  five |       f1       
 ------+----------------
       |              0
+      | -1.2345679e-20
       |         -34.84
       |        -1004.3
       | -1.2345679e+20
-      | -1.2345679e-20
 (5 rows)
 
 -- test edge-case coercions to integer
diff --git a/src/test/regress/expected/float4_1.out b/src/test/regress/expected/float4_1.out
new file mode 100644
index 0000000..bdc37e9
--- /dev/null
+++ b/src/test/regress/expected/float4_1.out
@@ -0,0 +1,259 @@
+--
+-- FLOAT4
+--
+CREATE TABLE FLOAT4_TBL (f1  float4);
+INSERT INTO FLOAT4_TBL(f1) VALUES ('    0.0');
+INSERT INTO FLOAT4_TBL(f1) VALUES ('1004.30   ');
+INSERT INTO FLOAT4_TBL(f1) VALUES ('     -34.84    ');
+INSERT INTO FLOAT4_TBL(f1) VALUES ('1.2345678901234e+20');
+INSERT INTO FLOAT4_TBL(f1) VALUES ('1.2345678901234e-20');
+-- test for over and under flow
+INSERT INTO FLOAT4_TBL(f1) VALUES ('10e70');
+ERROR:  value out of range: overflow
+LINE 1: INSERT INTO FLOAT4_TBL(f1) VALUES ('10e70');
+                                           ^
+INSERT INTO FLOAT4_TBL(f1) VALUES ('-10e70');
+ERROR:  value out of range: overflow
+LINE 1: INSERT INTO FLOAT4_TBL(f1) VALUES ('-10e70');
+                                           ^
+INSERT INTO FLOAT4_TBL(f1) VALUES ('10e-70');
+ERROR:  value out of range: underflow
+LINE 1: INSERT INTO FLOAT4_TBL(f1) VALUES ('10e-70');
+                                           ^
+INSERT INTO FLOAT4_TBL(f1) VALUES ('-10e-70');
+ERROR:  value out of range: underflow
+LINE 1: INSERT INTO FLOAT4_TBL(f1) VALUES ('-10e-70');
+                                           ^
+-- bad input
+INSERT INTO FLOAT4_TBL(f1) VALUES ('');
+ERROR:  invalid input syntax for type real: ""
+LINE 1: INSERT INTO FLOAT4_TBL(f1) VALUES ('');
+                                           ^
+INSERT INTO FLOAT4_TBL(f1) VALUES ('       ');
+ERROR:  invalid input syntax for type real: "       "
+LINE 1: INSERT INTO FLOAT4_TBL(f1) VALUES ('       ');
+                                           ^
+INSERT INTO FLOAT4_TBL(f1) VALUES ('xyz');
+ERROR:  invalid input syntax for type real: "xyz"
+LINE 1: INSERT INTO FLOAT4_TBL(f1) VALUES ('xyz');
+                                           ^
+INSERT INTO FLOAT4_TBL(f1) VALUES ('5.0.0');
+ERROR:  invalid input syntax for type real: "5.0.0"
+LINE 1: INSERT INTO FLOAT4_TBL(f1) VALUES ('5.0.0');
+                                           ^
+INSERT INTO FLOAT4_TBL(f1) VALUES ('5 . 0');
+ERROR:  invalid input syntax for type real: "5 . 0"
+LINE 1: INSERT INTO FLOAT4_TBL(f1) VALUES ('5 . 0');
+                                           ^
+INSERT INTO FLOAT4_TBL(f1) VALUES ('5.   0');
+ERROR:  invalid input syntax for type real: "5.   0"
+LINE 1: INSERT INTO FLOAT4_TBL(f1) VALUES ('5.   0');
+                                           ^
+INSERT INTO FLOAT4_TBL(f1) VALUES ('     - 3.0');
+ERROR:  invalid input syntax for type real: "     - 3.0"
+LINE 1: INSERT INTO FLOAT4_TBL(f1) VALUES ('     - 3.0');
+                                           ^
+INSERT INTO FLOAT4_TBL(f1) VALUES ('123            5');
+ERROR:  invalid input syntax for type real: "123            5"
+LINE 1: INSERT INTO FLOAT4_TBL(f1) VALUES ('123            5');
+                                           ^
+-- special inputs
+SELECT 'NaN'::float4;
+ float4 
+--------
+    NaN
+(1 row)
+
+SELECT 'nan'::float4;
+ float4 
+--------
+    NaN
+(1 row)
+
+SELECT '   NAN  '::float4;
+ float4 
+--------
+    NaN
+(1 row)
+
+SELECT 'infinity'::float4;
+  float4  
+----------
+ Infinity
+(1 row)
+
+SELECT '          -INFINiTY   '::float4;
+  float4   
+-----------
+ -Infinity
+(1 row)
+
+-- bad special inputs
+SELECT 'N A N'::float4;
+ERROR:  invalid input syntax for type real: "N A N"
+LINE 1: SELECT 'N A N'::float4;
+               ^
+SELECT 'NaN x'::float4;
+ERROR:  invalid input syntax for type real: "NaN x"
+LINE 1: SELECT 'NaN x'::float4;
+               ^
+SELECT ' INFINITY    x'::float4;
+ERROR:  invalid input syntax for type real: " INFINITY    x"
+LINE 1: SELECT ' INFINITY    x'::float4;
+               ^
+SELECT 'Infinity'::float4 + 100.0;
+ ?column? 
+----------
+ Infinity
+(1 row)
+
+SELECT 'Infinity'::float4 / 'Infinity'::float4;
+ ?column? 
+----------
+      NaN
+(1 row)
+
+SELECT 'nan'::float4 / 'nan'::float4;
+ ?column? 
+----------
+      NaN
+(1 row)
+
+SELECT 'nan'::numeric::float4;
+ float4 
+--------
+    NaN
+(1 row)
+
+SELECT '' AS five, * FROM FLOAT4_TBL;
+ five |     f1      
+------+-------------
+      |           0
+      |      1004.3
+      |      -34.84
+      | 1.23457e+20
+      | 1.23457e-20
+(5 rows)
+
+SELECT '' AS four, f.* FROM FLOAT4_TBL f WHERE f.f1 <> '1004.3';
+ four |     f1      
+------+-------------
+      |           0
+      |      -34.84
+      | 1.23457e+20
+      | 1.23457e-20
+(4 rows)
+
+SELECT '' AS one, f.* FROM FLOAT4_TBL f WHERE f.f1 = '1004.3';
+ one |   f1   
+-----+--------
+     | 1004.3
+(1 row)
+
+SELECT '' AS three, f.* FROM FLOAT4_TBL f WHERE '1004.3' > f.f1;
+ three |     f1      
+-------+-------------
+       |           0
+       |      -34.84
+       | 1.23457e-20
+(3 rows)
+
+SELECT '' AS three, f.* FROM FLOAT4_TBL f WHERE  f.f1 < '1004.3';
+ three |     f1      
+-------+-------------
+       |           0
+       |      -34.84
+       | 1.23457e-20
+(3 rows)
+
+SELECT '' AS four, f.* FROM FLOAT4_TBL f WHERE '1004.3' >= f.f1;
+ four |     f1      
+------+-------------
+      |           0
+      |      1004.3
+      |      -34.84
+      | 1.23457e-20
+(4 rows)
+
+SELECT '' AS four, f.* FROM FLOAT4_TBL f WHERE  f.f1 <= '1004.3';
+ four |     f1      
+------+-------------
+      |           0
+      |      1004.3
+      |      -34.84
+      | 1.23457e-20
+(4 rows)
+
+SELECT '' AS three, f.f1, f.f1 * '-10' AS x FROM FLOAT4_TBL f
+   WHERE f.f1 > '0.0';
+ three |     f1      |      x       
+-------+-------------+--------------
+       |      1004.3 |       -10043
+       | 1.23457e+20 | -1.23457e+21
+       | 1.23457e-20 | -1.23457e-19
+(3 rows)
+
+SELECT '' AS three, f.f1, f.f1 + '-10' AS x FROM FLOAT4_TBL f
+   WHERE f.f1 > '0.0';
+ three |     f1      |      x      
+-------+-------------+-------------
+       |      1004.3 |       994.3
+       | 1.23457e+20 | 1.23457e+20
+       | 1.23457e-20 |         -10
+(3 rows)
+
+SELECT '' AS three, f.f1, f.f1 / '-10' AS x FROM FLOAT4_TBL f
+   WHERE f.f1 > '0.0';
+ three |     f1      |      x       
+-------+-------------+--------------
+       |      1004.3 |      -100.43
+       | 1.23457e+20 | -1.23457e+19
+       | 1.23457e-20 | -1.23457e-21
+(3 rows)
+
+SELECT '' AS three, f.f1, f.f1 - '-10' AS x FROM FLOAT4_TBL f
+   WHERE f.f1 > '0.0';
+ three |     f1      |      x      
+-------+-------------+-------------
+       |      1004.3 |      1014.3
+       | 1.23457e+20 | 1.23457e+20
+       | 1.23457e-20 |          10
+(3 rows)
+
+-- test divide by zero
+SELECT '' AS bad, f.f1 / '0.0' from FLOAT4_TBL f;
+ERROR:  division by zero
+SELECT '' AS five, * FROM FLOAT4_TBL;
+ five |     f1      
+------+-------------
+      |           0
+      |      1004.3
+      |      -34.84
+      | 1.23457e+20
+      | 1.23457e-20
+(5 rows)
+
+-- test the unary float4abs operator
+SELECT '' AS five, f.f1, @f.f1 AS abs_f1 FROM FLOAT4_TBL f;
+ five |     f1      |   abs_f1    
+------+-------------+-------------
+      |           0 |           0
+      |      1004.3 |      1004.3
+      |      -34.84 |       34.84
+      | 1.23457e+20 | 1.23457e+20
+      | 1.23457e-20 | 1.23457e-20
+(5 rows)
+
+UPDATE FLOAT4_TBL
+   SET f1 = FLOAT4_TBL.f1 * '-1'
+   WHERE FLOAT4_TBL.f1 > '0.0';
+SELECT '' AS five, * FROM FLOAT4_TBL;
+ five |      f1      
+------+--------------
+      |            0
+      |      -1004.3
+      |       -34.84
+      | -1.23457e+20
+      | -1.23457e-20
+(5 rows)
+
diff --git a/src/test/regress/expected/float8.out b/src/test/regress/expected/float8.out
index aaef20b..b1b0c23 100644
--- a/src/test/regress/expected/float8.out
+++ b/src/test/regress/expected/float8.out
@@ -444,14 +444,14 @@ SELECT '' AS bad, exp(f.f1) from FLOAT8_TBL f;
 ERROR:  value out of range: underflow
 SELECT '' AS bad, f.f1 / '0.0' from FLOAT8_TBL f;
 ERROR:  division by zero
-SELECT '' AS five, * FROM FLOAT8_TBL;
+SELECT '' AS five, * FROM FLOAT8_TBL ORDER BY f1 DESC;
  five |          f1           
 ------+-----------------------
       |                     0
+      | -1.2345678901234e-200
       |                -34.84
       |               -1004.3
       | -1.2345678901234e+200
-      | -1.2345678901234e-200
 (5 rows)
 
 -- hyperbolic functions
diff --git a/src/test/regress/expected/float8_1.out b/src/test/regress/expected/float8_1.out
new file mode 100644
index 0000000..0926b75
--- /dev/null
+++ b/src/test/regress/expected/float8_1.out
@@ -0,0 +1,586 @@
+--
+-- FLOAT8
+--
+CREATE TABLE FLOAT8_TBL(f1 float8);
+INSERT INTO FLOAT8_TBL(f1) VALUES ('    0.0   ');
+INSERT INTO FLOAT8_TBL(f1) VALUES ('1004.30  ');
+INSERT INTO FLOAT8_TBL(f1) VALUES ('   -34.84');
+INSERT INTO FLOAT8_TBL(f1) VALUES ('1.2345678901234e+200');
+INSERT INTO FLOAT8_TBL(f1) VALUES ('1.2345678901234e-200');
+-- test for underflow and overflow handling
+SELECT '10e400'::float8;
+ERROR:  "10e400" is out of range for type double precision
+LINE 1: SELECT '10e400'::float8;
+               ^
+SELECT '-10e400'::float8;
+ERROR:  "-10e400" is out of range for type double precision
+LINE 1: SELECT '-10e400'::float8;
+               ^
+SELECT '10e-400'::float8;
+ERROR:  "10e-400" is out of range for type double precision
+LINE 1: SELECT '10e-400'::float8;
+               ^
+SELECT '-10e-400'::float8;
+ERROR:  "-10e-400" is out of range for type double precision
+LINE 1: SELECT '-10e-400'::float8;
+               ^
+-- bad input
+INSERT INTO FLOAT8_TBL(f1) VALUES ('');
+ERROR:  invalid input syntax for type double precision: ""
+LINE 1: INSERT INTO FLOAT8_TBL(f1) VALUES ('');
+                                           ^
+INSERT INTO FLOAT8_TBL(f1) VALUES ('     ');
+ERROR:  invalid input syntax for type double precision: "     "
+LINE 1: INSERT INTO FLOAT8_TBL(f1) VALUES ('     ');
+                                           ^
+INSERT INTO FLOAT8_TBL(f1) VALUES ('xyz');
+ERROR:  invalid input syntax for type double precision: "xyz"
+LINE 1: INSERT INTO FLOAT8_TBL(f1) VALUES ('xyz');
+                                           ^
+INSERT INTO FLOAT8_TBL(f1) VALUES ('5.0.0');
+ERROR:  invalid input syntax for type double precision: "5.0.0"
+LINE 1: INSERT INTO FLOAT8_TBL(f1) VALUES ('5.0.0');
+                                           ^
+INSERT INTO FLOAT8_TBL(f1) VALUES ('5 . 0');
+ERROR:  invalid input syntax for type double precision: "5 . 0"
+LINE 1: INSERT INTO FLOAT8_TBL(f1) VALUES ('5 . 0');
+                                           ^
+INSERT INTO FLOAT8_TBL(f1) VALUES ('5.   0');
+ERROR:  invalid input syntax for type double precision: "5.   0"
+LINE 1: INSERT INTO FLOAT8_TBL(f1) VALUES ('5.   0');
+                                           ^
+INSERT INTO FLOAT8_TBL(f1) VALUES ('    - 3');
+ERROR:  invalid input syntax for type double precision: "    - 3"
+LINE 1: INSERT INTO FLOAT8_TBL(f1) VALUES ('    - 3');
+                                           ^
+INSERT INTO FLOAT8_TBL(f1) VALUES ('123           5');
+ERROR:  invalid input syntax for type double precision: "123           5"
+LINE 1: INSERT INTO FLOAT8_TBL(f1) VALUES ('123           5');
+                                           ^
+-- special inputs
+SELECT 'NaN'::float8;
+ float8 
+--------
+    NaN
+(1 row)
+
+SELECT 'nan'::float8;
+ float8 
+--------
+    NaN
+(1 row)
+
+SELECT '   NAN  '::float8;
+ float8 
+--------
+    NaN
+(1 row)
+
+SELECT 'infinity'::float8;
+  float8  
+----------
+ Infinity
+(1 row)
+
+SELECT '          -INFINiTY   '::float8;
+  float8   
+-----------
+ -Infinity
+(1 row)
+
+-- bad special inputs
+SELECT 'N A N'::float8;
+ERROR:  invalid input syntax for type double precision: "N A N"
+LINE 1: SELECT 'N A N'::float8;
+               ^
+SELECT 'NaN x'::float8;
+ERROR:  invalid input syntax for type double precision: "NaN x"
+LINE 1: SELECT 'NaN x'::float8;
+               ^
+SELECT ' INFINITY    x'::float8;
+ERROR:  invalid input syntax for type double precision: " INFINITY    x"
+LINE 1: SELECT ' INFINITY    x'::float8;
+               ^
+SELECT 'Infinity'::float8 + 100.0;
+ ?column? 
+----------
+ Infinity
+(1 row)
+
+SELECT 'Infinity'::float8 / 'Infinity'::float8;
+ ?column? 
+----------
+      NaN
+(1 row)
+
+SELECT 'nan'::float8 / 'nan'::float8;
+ ?column? 
+----------
+      NaN
+(1 row)
+
+SELECT 'nan'::numeric::float8;
+ float8 
+--------
+    NaN
+(1 row)
+
+SELECT '' AS five, * FROM FLOAT8_TBL;
+ five |          f1          
+------+----------------------
+      |                    0
+      |               1004.3
+      |               -34.84
+      | 1.2345678901234e+200
+      | 1.2345678901234e-200
+(5 rows)
+
+SELECT '' AS four, f.* FROM FLOAT8_TBL f WHERE f.f1 <> '1004.3';
+ four |          f1          
+------+----------------------
+      |                    0
+      |               -34.84
+      | 1.2345678901234e+200
+      | 1.2345678901234e-200
+(4 rows)
+
+SELECT '' AS one, f.* FROM FLOAT8_TBL f WHERE f.f1 = '1004.3';
+ one |   f1   
+-----+--------
+     | 1004.3
+(1 row)
+
+SELECT '' AS three, f.* FROM FLOAT8_TBL f WHERE '1004.3' > f.f1;
+ three |          f1          
+-------+----------------------
+       |                    0
+       |               -34.84
+       | 1.2345678901234e-200
+(3 rows)
+
+SELECT '' AS three, f.* FROM FLOAT8_TBL f WHERE  f.f1 < '1004.3';
+ three |          f1          
+-------+----------------------
+       |                    0
+       |               -34.84
+       | 1.2345678901234e-200
+(3 rows)
+
+SELECT '' AS four, f.* FROM FLOAT8_TBL f WHERE '1004.3' >= f.f1;
+ four |          f1          
+------+----------------------
+      |                    0
+      |               1004.3
+      |               -34.84
+      | 1.2345678901234e-200
+(4 rows)
+
+SELECT '' AS four, f.* FROM FLOAT8_TBL f WHERE  f.f1 <= '1004.3';
+ four |          f1          
+------+----------------------
+      |                    0
+      |               1004.3
+      |               -34.84
+      | 1.2345678901234e-200
+(4 rows)
+
+SELECT '' AS three, f.f1, f.f1 * '-10' AS x
+   FROM FLOAT8_TBL f
+   WHERE f.f1 > '0.0';
+ three |          f1          |           x           
+-------+----------------------+-----------------------
+       |               1004.3 |                -10043
+       | 1.2345678901234e+200 | -1.2345678901234e+201
+       | 1.2345678901234e-200 | -1.2345678901234e-199
+(3 rows)
+
+SELECT '' AS three, f.f1, f.f1 + '-10' AS x
+   FROM FLOAT8_TBL f
+   WHERE f.f1 > '0.0';
+ three |          f1          |          x           
+-------+----------------------+----------------------
+       |               1004.3 |                994.3
+       | 1.2345678901234e+200 | 1.2345678901234e+200
+       | 1.2345678901234e-200 |                  -10
+(3 rows)
+
+SELECT '' AS three, f.f1, f.f1 / '-10' AS x
+   FROM FLOAT8_TBL f
+   WHERE f.f1 > '0.0';
+ three |          f1          |           x           
+-------+----------------------+-----------------------
+       |               1004.3 |               -100.43
+       | 1.2345678901234e+200 | -1.2345678901234e+199
+       | 1.2345678901234e-200 | -1.2345678901234e-201
+(3 rows)
+
+SELECT '' AS three, f.f1, f.f1 - '-10' AS x
+   FROM FLOAT8_TBL f
+   WHERE f.f1 > '0.0';
+ three |          f1          |          x           
+-------+----------------------+----------------------
+       |               1004.3 |               1014.3
+       | 1.2345678901234e+200 | 1.2345678901234e+200
+       | 1.2345678901234e-200 |                   10
+(3 rows)
+
+SELECT '' AS one, f.f1 ^ '2.0' AS square_f1
+   FROM FLOAT8_TBL f where f.f1 = '1004.3';
+ one | square_f1  
+-----+------------
+     | 1008618.49
+(1 row)
+
+-- absolute value
+SELECT '' AS five, f.f1, @f.f1 AS abs_f1
+   FROM FLOAT8_TBL f;
+ five |          f1          |        abs_f1        
+------+----------------------+----------------------
+      |                    0 |                    0
+      |               1004.3 |               1004.3
+      |               -34.84 |                34.84
+      | 1.2345678901234e+200 | 1.2345678901234e+200
+      | 1.2345678901234e-200 | 1.2345678901234e-200
+(5 rows)
+
+-- truncate
+SELECT '' AS five, f.f1, trunc(f.f1) AS trunc_f1
+   FROM FLOAT8_TBL f;
+ five |          f1          |       trunc_f1       
+------+----------------------+----------------------
+      |                    0 |                    0
+      |               1004.3 |                 1004
+      |               -34.84 |                  -34
+      | 1.2345678901234e+200 | 1.2345678901234e+200
+      | 1.2345678901234e-200 |                    0
+(5 rows)
+
+-- round
+SELECT '' AS five, f.f1, round(f.f1) AS round_f1
+   FROM FLOAT8_TBL f;
+ five |          f1          |       round_f1       
+------+----------------------+----------------------
+      |                    0 |                    0
+      |               1004.3 |                 1004
+      |               -34.84 |                  -35
+      | 1.2345678901234e+200 | 1.2345678901234e+200
+      | 1.2345678901234e-200 |                    0
+(5 rows)
+
+-- ceil / ceiling
+select ceil(f1) as ceil_f1 from float8_tbl f;
+       ceil_f1        
+----------------------
+                    0
+                 1005
+                  -34
+ 1.2345678901234e+200
+                    1
+(5 rows)
+
+select ceiling(f1) as ceiling_f1 from float8_tbl f;
+      ceiling_f1      
+----------------------
+                    0
+                 1005
+                  -34
+ 1.2345678901234e+200
+                    1
+(5 rows)
+
+-- floor
+select floor(f1) as floor_f1 from float8_tbl f;
+       floor_f1       
+----------------------
+                    0
+                 1004
+                  -35
+ 1.2345678901234e+200
+                    0
+(5 rows)
+
+-- sign
+select sign(f1) as sign_f1 from float8_tbl f;
+ sign_f1 
+---------
+       0
+       1
+      -1
+       1
+       1
+(5 rows)
+
+-- square root
+SELECT sqrt(float8 '64') AS eight;
+ eight 
+-------
+     8
+(1 row)
+
+SELECT |/ float8 '64' AS eight;
+ eight 
+-------
+     8
+(1 row)
+
+SELECT '' AS three, f.f1, |/f.f1 AS sqrt_f1
+   FROM FLOAT8_TBL f
+   WHERE f.f1 > '0.0';
+ three |          f1          |        sqrt_f1        
+-------+----------------------+-----------------------
+       |               1004.3 |      31.6906926399535
+       | 1.2345678901234e+200 | 1.11111110611109e+100
+       | 1.2345678901234e-200 | 1.11111110611109e-100
+(3 rows)
+
+-- power
+SELECT power(float8 '144', float8 '0.5');
+ power 
+-------
+    12
+(1 row)
+
+SELECT power(float8 'NaN', float8 '0.5');
+ power 
+-------
+   NaN
+(1 row)
+
+SELECT power(float8 '144', float8 'NaN');
+ power 
+-------
+   NaN
+(1 row)
+
+SELECT power(float8 'NaN', float8 'NaN');
+ power 
+-------
+   NaN
+(1 row)
+
+SELECT power(float8 '-1', float8 'NaN');
+ power 
+-------
+   NaN
+(1 row)
+
+SELECT power(float8 '1', float8 'NaN');
+ power 
+-------
+     1
+(1 row)
+
+SELECT power(float8 'NaN', float8 '0');
+ power 
+-------
+     1
+(1 row)
+
+-- take exp of ln(f.f1)
+SELECT '' AS three, f.f1, exp(ln(f.f1)) AS exp_ln_f1
+   FROM FLOAT8_TBL f
+   WHERE f.f1 > '0.0';
+ three |          f1          |       exp_ln_f1       
+-------+----------------------+-----------------------
+       |               1004.3 |                1004.3
+       | 1.2345678901234e+200 | 1.23456789012338e+200
+       | 1.2345678901234e-200 | 1.23456789012339e-200
+(3 rows)
+
+-- cube root
+SELECT ||/ float8 '27' AS three;
+ three 
+-------
+     3
+(1 row)
+
+SELECT '' AS five, f.f1, ||/f.f1 AS cbrt_f1 FROM FLOAT8_TBL f;
+ five |          f1          |       cbrt_f1        
+------+----------------------+----------------------
+      |                    0 |                    0
+      |               1004.3 |      10.014312837827
+      |               -34.84 |    -3.26607421344208
+      | 1.2345678901234e+200 | 4.97933859234765e+66
+      | 1.2345678901234e-200 |  2.3112042409018e-67
+(5 rows)
+
+SELECT '' AS five, * FROM FLOAT8_TBL;
+ five |          f1          
+------+----------------------
+      |                    0
+      |               1004.3
+      |               -34.84
+      | 1.2345678901234e+200
+      | 1.2345678901234e-200
+(5 rows)
+
+UPDATE FLOAT8_TBL
+   SET f1 = FLOAT8_TBL.f1 * '-1'
+   WHERE FLOAT8_TBL.f1 > '0.0';
+SELECT '' AS bad, f.f1 * '1e200' from FLOAT8_TBL f;
+ERROR:  value out of range: overflow
+SELECT '' AS bad, f.f1 ^ '1e200' from FLOAT8_TBL f;
+ERROR:  value out of range: overflow
+SELECT 0 ^ 0 + 0 ^ 1 + 0 ^ 0.0 + 0 ^ 0.5;
+ ?column? 
+----------
+        2
+(1 row)
+
+SELECT '' AS bad, ln(f.f1) from FLOAT8_TBL f where f.f1 = '0.0' ;
+ERROR:  cannot take logarithm of zero
+SELECT '' AS bad, ln(f.f1) from FLOAT8_TBL f where f.f1 < '0.0' ;
+ERROR:  cannot take logarithm of a negative number
+SELECT '' AS bad, exp(f.f1) from FLOAT8_TBL f;
+ERROR:  value out of range: underflow
+SELECT '' AS bad, f.f1 / '0.0' from FLOAT8_TBL f;
+ERROR:  division by zero
+SELECT '' AS five, * FROM FLOAT8_TBL;
+ five |          f1           
+------+-----------------------
+      |                     0
+      |               -1004.3
+      |                -34.84
+      | -1.2345678901234e+200
+      | -1.2345678901234e-200
+(5 rows)
+
+-- test for over- and underflow
+INSERT INTO FLOAT8_TBL(f1) VALUES ('10e400');
+ERROR:  "10e400" is out of range for type double precision
+LINE 1: INSERT INTO FLOAT8_TBL(f1) VALUES ('10e400');
+                                           ^
+INSERT INTO FLOAT8_TBL(f1) VALUES ('-10e400');
+ERROR:  "-10e400" is out of range for type double precision
+LINE 1: INSERT INTO FLOAT8_TBL(f1) VALUES ('-10e400');
+                                           ^
+INSERT INTO FLOAT8_TBL(f1) VALUES ('10e-400');
+ERROR:  "10e-400" is out of range for type double precision
+LINE 1: INSERT INTO FLOAT8_TBL(f1) VALUES ('10e-400');
+                                           ^
+INSERT INTO FLOAT8_TBL(f1) VALUES ('-10e-400');
+ERROR:  "-10e-400" is out of range for type double precision
+LINE 1: INSERT INTO FLOAT8_TBL(f1) VALUES ('-10e-400');
+                                           ^
+-- maintain external table consistency across platforms
+-- delete all values and reinsert well-behaved ones
+DELETE FROM FLOAT8_TBL;
+INSERT INTO FLOAT8_TBL(f1) VALUES ('0.0');
+INSERT INTO FLOAT8_TBL(f1) VALUES ('-34.84');
+INSERT INTO FLOAT8_TBL(f1) VALUES ('-1004.30');
+INSERT INTO FLOAT8_TBL(f1) VALUES ('-1.2345678901234e+200');
+INSERT INTO FLOAT8_TBL(f1) VALUES ('-1.2345678901234e-200');
+SELECT '' AS five, * FROM FLOAT8_TBL;
+ five |          f1           
+------+-----------------------
+      |                     0
+      |                -34.84
+      |               -1004.3
+      | -1.2345678901234e+200
+      | -1.2345678901234e-200
+(5 rows)
+
+-- test exact cases for trigonometric functions in degrees
+SET extra_float_digits = 3;
+SELECT x,
+       sind(x),
+       sind(x) IN (-1,-0.5,0,0.5,1) AS sind_exact
+FROM (VALUES (0), (30), (90), (150), (180),
+      (210), (270), (330), (360)) AS t(x);
+  x  | sind | sind_exact 
+-----+------+------------
+   0 |    0 | t
+  30 |  0.5 | t
+  90 |    1 | t
+ 150 |  0.5 | t
+ 180 |    0 | t
+ 210 | -0.5 | t
+ 270 |   -1 | t
+ 330 | -0.5 | t
+ 360 |    0 | t
+(9 rows)
+
+SELECT x,
+       cosd(x),
+       cosd(x) IN (-1,-0.5,0,0.5,1) AS cosd_exact
+FROM (VALUES (0), (60), (90), (120), (180),
+      (240), (270), (300), (360)) AS t(x);
+  x  | cosd | cosd_exact 
+-----+------+------------
+   0 |    1 | t
+  60 |  0.5 | t
+  90 |    0 | t
+ 120 | -0.5 | t
+ 180 |   -1 | t
+ 240 | -0.5 | t
+ 270 |    0 | t
+ 300 |  0.5 | t
+ 360 |    1 | t
+(9 rows)
+
+SELECT x,
+       tand(x),
+       tand(x) IN ('-Infinity'::float8,-1,0,
+                   1,'Infinity'::float8) AS tand_exact,
+       cotd(x),
+       cotd(x) IN ('-Infinity'::float8,-1,0,
+                   1,'Infinity'::float8) AS cotd_exact
+FROM (VALUES (0), (45), (90), (135), (180),
+      (225), (270), (315), (360)) AS t(x);
+  x  |   tand    | tand_exact |   cotd    | cotd_exact 
+-----+-----------+------------+-----------+------------
+   0 |         0 | t          |  Infinity | t
+  45 |         1 | t          |         1 | t
+  90 |  Infinity | t          |         0 | t
+ 135 |        -1 | t          |        -1 | t
+ 180 |         0 | t          | -Infinity | t
+ 225 |         1 | t          |         1 | t
+ 270 | -Infinity | t          |         0 | t
+ 315 |        -1 | t          |        -1 | t
+ 360 |         0 | t          |  Infinity | t
+(9 rows)
+
+SELECT x,
+       asind(x),
+       asind(x) IN (-90,-30,0,30,90) AS asind_exact,
+       acosd(x),
+       acosd(x) IN (0,60,90,120,180) AS acosd_exact
+FROM (VALUES (-1), (-0.5), (0), (0.5), (1)) AS t(x);
+  x   | asind | asind_exact | acosd | acosd_exact 
+------+-------+-------------+-------+-------------
+   -1 |   -90 | t           |   180 | t
+ -0.5 |   -30 | t           |   120 | t
+    0 |     0 | t           |    90 | t
+  0.5 |    30 | t           |    60 | t
+    1 |    90 | t           |     0 | t
+(5 rows)
+
+SELECT x,
+       atand(x),
+       atand(x) IN (-90,-45,0,45,90) AS atand_exact
+FROM (VALUES ('-Infinity'::float8), (-1), (0), (1),
+      ('Infinity'::float8)) AS t(x);
+     x     | atand | atand_exact 
+-----------+-------+-------------
+ -Infinity |   -90 | t
+        -1 |   -45 | t
+         0 |     0 | t
+         1 |    45 | t
+  Infinity |    90 | t
+(5 rows)
+
+SELECT x, y,
+       atan2d(y, x),
+       atan2d(y, x) IN (-90,0,90,180) AS atan2d_exact
+FROM (SELECT 10*cosd(a), 10*sind(a)
+      FROM generate_series(0, 360, 90) AS t(a)) AS t(x,y);
+  x  |  y  | atan2d | atan2d_exact 
+-----+-----+--------+--------------
+  10 |   0 |      0 | t
+   0 |  10 |     90 | t
+ -10 |   0 |    180 | t
+   0 | -10 |    -90 | t
+  10 |   0 |      0 | t
+(5 rows)
+
+RESET extra_float_digits;
diff --git a/src/test/regress/expected/foreign_key.out b/src/test/regress/expected/foreign_key.out
index 58f6058..ba95838 100644
--- a/src/test/regress/expected/foreign_key.out
+++ b/src/test/regress/expected/foreign_key.out
@@ -46,12 +46,12 @@ SELECT * FROM FKTABLE;
 -- Update a row from PK TABLE
 UPDATE PKTABLE SET ptest1=1 WHERE ptest1=2;
 -- Check FKTABLE for update of matched row
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2;
  ftest1 | ftest2 
 --------+--------
+      1 |      3
       3 |      4
         |      1
-      1 |      3
 (3 rows)
 
 DROP TABLE FKTABLE;
@@ -107,7 +107,7 @@ SELECT * FROM FKTABLE;
 -- Delete a row from PK TABLE
 DELETE FROM PKTABLE WHERE ptest1=1 and ptest2=2;
 -- Check FKTABLE for removal of matched row
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
  ftest1 | ftest2 | ftest3 
 --------+--------+--------
       1 |      3 |      5
@@ -120,7 +120,7 @@ SELECT * FROM FKTABLE;
 -- Delete another row from PK TABLE
 DELETE FROM PKTABLE WHERE ptest1=5 and ptest2=10;
 -- Check FKTABLE (should be no change)
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
  ftest1 | ftest2 | ftest3 
 --------+--------+--------
       1 |      3 |      5
@@ -133,7 +133,7 @@ SELECT * FROM FKTABLE;
 -- Update a row from PK TABLE
 UPDATE PKTABLE SET ptest1=1 WHERE ptest1=2;
 -- Check FKTABLE for update of matched row
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
  ftest1 | ftest2 | ftest3 
 --------+--------+--------
       1 |      3 |      5
@@ -161,14 +161,14 @@ SELECT * FROM PKTABLE;
       1 |      4 | Test2
 (4 rows)
 
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
  ftest1 | ftest2 | ftest3 
 --------+--------+--------
+      1 |      3 |      5
       3 |      6 |     12
         |        |      0
         |        |      4
         |        |      8
-      1 |      3 |      5
 (5 rows)
 
 DROP TABLE PKTABLE CASCADE;
@@ -222,40 +222,40 @@ SELECT * FROM FKTABLE;
 -- Delete a row from PK TABLE
 DELETE FROM PKTABLE WHERE ptest1=1 and ptest2=2;
 -- Check FKTABLE to check for removal
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
  ftest1 | ftest2 | ftest3 
 --------+--------+--------
+     -1 |     -2 |      4
       1 |      3 |      5
       2 |      4 |      8
       3 |      6 |     12
         |        |      0
-     -1 |     -2 |      4
 (5 rows)
 
 -- Delete another row from PK TABLE
 DELETE FROM PKTABLE WHERE ptest1=5 and ptest2=10;
 -- Check FKTABLE (should be no change)
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
  ftest1 | ftest2 | ftest3 
 --------+--------+--------
+     -1 |     -2 |      4
       1 |      3 |      5
       2 |      4 |      8
       3 |      6 |     12
         |        |      0
-     -1 |     -2 |      4
 (5 rows)
 
 -- Update a row from PK TABLE
 UPDATE PKTABLE SET ptest1=1 WHERE ptest1=2;
 -- Check FKTABLE for update of matched row
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
  ftest1 | ftest2 | ftest3 
 --------+--------+--------
+     -1 |     -2 |      4
+     -1 |     -2 |      8
       1 |      3 |      5
       3 |      6 |     12
         |        |      0
-     -1 |     -2 |      4
-     -1 |     -2 |      8
 (5 rows)
 
 -- this should fail for lack of CASCADE
@@ -477,34 +477,34 @@ UPDATE PKTABLE set ptest2=5 where ptest2=2;
 -- Try to update something that should not cascade
 UPDATE PKTABLE set ptest1=1 WHERE ptest2=3;
 -- Show PKTABLE and FKTABLE
-SELECT * from PKTABLE;
+SELECT * from PKTABLE ORDER BY ptest1, ptest2, ptest3;
  ptest1 | ptest2 | ptest3 | ptest4 
 --------+--------+--------+--------
-      2 |      4 |      5 | test4
-      1 |      5 |      3 | test1
       1 |      3 |      3 | test2
       1 |      3 |      4 | test3
+      1 |      5 |      3 | test1
+      2 |      4 |      5 | test4
 (4 rows)
 
-SELECT * from FKTABLE;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3;
  ftest1 | ftest2 | ftest3 | ftest4 
 --------+--------+--------+--------
-        |      2 |      3 |      2
+      1 |      5 |      3 |      1
       2 |        |      3 |      3
+        |      2 |      3 |      2
         |      2 |      7 |      4
         |      3 |      4 |      5
-      1 |      5 |      3 |      1
 (5 rows)
 
 -- Try to delete something that should cascade
 DELETE FROM PKTABLE where ptest1=1 and ptest2=5 and ptest3=3;
 -- Show PKTABLE and FKTABLE
-SELECT * from PKTABLE;
+SELECT * from PKTABLE ORDER BY ptest1, ptest2, ptest3;
  ptest1 | ptest2 | ptest3 | ptest4 
 --------+--------+--------+--------
-      2 |      4 |      5 | test4
       1 |      3 |      3 | test2
       1 |      3 |      4 | test3
+      2 |      4 |      5 | test4
 (3 rows)
 
 SELECT * from FKTABLE;
@@ -584,12 +584,12 @@ SELECT * from PKTABLE;
       1 |      2 |      3 | test2
 (4 rows)
 
-SELECT * from FKTABLE;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3, ftest4;
  ftest1 | ftest2 | ftest3 | ftest4 
 --------+--------+--------+--------
       2 |      3 |      4 |      1
-        |      2 |      3 |      2
       2 |        |      3 |      3
+        |      2 |      3 |      2
         |      2 |      7 |      4
         |      3 |      4 |      5
         |        |        |      1
@@ -606,15 +606,15 @@ SELECT * from PKTABLE;
       1 |      2 |      3 | test2
 (3 rows)
 
-SELECT * from FKTABLE;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3, ftest4;
  ftest1 | ftest2 | ftest3 | ftest4 
 --------+--------+--------+--------
-        |      2 |      3 |      2
+      0 |        |        |      1
       2 |        |      3 |      3
+        |      2 |      3 |      2
         |      2 |      7 |      4
         |      3 |      4 |      5
         |        |        |      1
-      0 |        |        |      1
 (6 rows)
 
 -- Try to delete something that should not set default
@@ -627,15 +627,15 @@ SELECT * from PKTABLE;
       1 |      2 |      3 | test2
 (2 rows)
 
-SELECT * from FKTABLE;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3, ftest4;
  ftest1 | ftest2 | ftest3 | ftest4 
 --------+--------+--------+--------
-        |      2 |      3 |      2
+      0 |        |        |      1
       2 |        |      3 |      3
+        |      2 |      3 |      2
         |      2 |      7 |      4
         |      3 |      4 |      5
         |        |        |      1
-      0 |        |        |      1
 (6 rows)
 
 DROP TABLE FKTABLE;
@@ -696,16 +696,16 @@ SELECT * from PKTABLE;
       1 |      2 |      3 | test2
 (5 rows)
 
-SELECT * from FKTABLE;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3, ftest4;
  ftest1 | ftest2 | ftest3 | ftest4 
 --------+--------+--------+--------
+      0 |     -1 |     -2 |      1
+      0 |     -1 |     -2 |      1
       2 |      3 |      4 |      1
-        |      2 |      3 |      2
       2 |        |      3 |      3
+        |      2 |      3 |      2
         |      2 |      7 |      4
         |      3 |      4 |      5
-      0 |     -1 |     -2 |      1
-      0 |     -1 |     -2 |      1
 (7 rows)
 
 -- Try to delete something that should set null
@@ -720,15 +720,15 @@ SELECT * from PKTABLE;
       1 |      2 |      3 | test2
 (4 rows)
 
-SELECT * from FKTABLE;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3, ftest4;
  ftest1 | ftest2 | ftest3 | ftest4 
 --------+--------+--------+--------
-        |      2 |      3 |      2
+      0 |     -1 |     -2 |      1
+      0 |     -1 |     -2 |      1
       2 |        |      3 |      3
+        |      2 |      3 |      2
         |      2 |      7 |      4
         |      3 |      4 |      5
-      0 |     -1 |     -2 |      1
-      0 |     -1 |     -2 |      1
         |        |        |      1
 (7 rows)
 
@@ -743,15 +743,15 @@ SELECT * from PKTABLE;
       1 |      2 |      3 | test2
 (3 rows)
 
-SELECT * from FKTABLE;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3, ftest4;
  ftest1 | ftest2 | ftest3 | ftest4 
 --------+--------+--------+--------
-        |      2 |      3 |      2
+      0 |     -1 |     -2 |      1
+      0 |     -1 |     -2 |      1
       2 |        |      3 |      3
+        |      2 |      3 |      2
         |      2 |      7 |      4
         |      3 |      4 |      5
-      0 |     -1 |     -2 |      1
-      0 |     -1 |     -2 |      1
         |        |        |      1
 (7 rows)
 
@@ -1292,21 +1292,21 @@ SELECT * FROM tasks;
 -- could fail with only 2 changes to make, if row was already updated
 BEGIN;
 UPDATE tasks set id=id WHERE id=2;
-SELECT * FROM tasks;
+SELECT * FROM tasks ORDER BY id;
  id | owner | worker | checked_by 
 ----+-------+--------+------------
   1 |     1 |        |           
-  3 |       |        |           
   2 |     2 |      2 |           
+  3 |       |        |           
 (3 rows)
 
 DELETE FROM users WHERE id = 2;
-SELECT * FROM tasks;
+SELECT * FROM tasks ORDER BY id;
  id | owner | worker | checked_by 
 ----+-------+--------+------------
   1 |     1 |        |           
-  3 |       |        |           
   2 |       |        |           
+  3 |       |        |           
 (3 rows)
 
 COMMIT;
diff --git a/src/test/regress/expected/fsm_1.out b/src/test/regress/expected/fsm_1.out
new file mode 100644
index 0000000..ba2a29c
--- /dev/null
+++ b/src/test/regress/expected/fsm_1.out
@@ -0,0 +1,73 @@
+--
+-- Free Space Map test
+--
+SELECT current_setting('block_size')::integer AS blocksize,
+current_setting('block_size')::integer / 8 AS strsize
+\gset
+CREATE TABLE fsm_check_size (num int, str text);
+-- Fill 3 blocks with one record each
+ALTER TABLE fsm_check_size SET (fillfactor=15);
+INSERT INTO fsm_check_size SELECT i, rpad('', :strsize, 'a')
+FROM generate_series(1,3) i;
+-- There should be no FSM
+VACUUM fsm_check_size;
+SELECT pg_relation_size('fsm_check_size', 'main') / :blocksize AS heap_nblocks,
+pg_relation_size('fsm_check_size', 'fsm') / :blocksize AS fsm_nblocks;
+ heap_nblocks | fsm_nblocks 
+--------------+-------------
+            4 |           0
+(1 row)
+
+-- The following operations are for testing the functionality of the local
+-- in-memory map. In particular, we want to be able to insert into some
+-- other block than the one at the end of the heap, without using a FSM.
+-- Fill most of the last block
+ALTER TABLE fsm_check_size SET (fillfactor=100);
+INSERT INTO fsm_check_size SELECT i, rpad('', :strsize, 'a')
+FROM generate_series(101,105) i;
+-- Make sure records can go into any block but the last one
+ALTER TABLE fsm_check_size SET (fillfactor=30);
+-- Insert large record and make sure it does not cause the relation to extend
+INSERT INTO fsm_check_size VALUES (111, rpad('', :strsize, 'a'));
+VACUUM fsm_check_size;
+SELECT pg_relation_size('fsm_check_size', 'main') / :blocksize AS heap_nblocks,
+pg_relation_size('fsm_check_size', 'fsm') / :blocksize AS fsm_nblocks;
+ heap_nblocks | fsm_nblocks 
+--------------+-------------
+            4 |           0
+(1 row)
+
+-- Extend table with enough blocks to exceed the FSM threshold
+DO $$
+DECLARE curtid tid;
+num int;
+BEGIN
+num = 11;
+  LOOP
+    INSERT INTO fsm_check_size VALUES (num, 'b') RETURNING ctid INTO curtid;
+    EXIT WHEN curtid >= tid '(4, 0)';
+    num = num + 1;
+  END LOOP;
+END;
+$$;
+VACUUM fsm_check_size;
+SELECT pg_relation_size('fsm_check_size', 'fsm') / :blocksize AS fsm_nblocks;
+ fsm_nblocks 
+-------------
+           3
+(1 row)
+
+-- Add long random string to extend TOAST table to 1 block
+INSERT INTO fsm_check_size
+VALUES(0, (SELECT string_agg(md5(chr(i)), '')
+		   FROM generate_series(1, :blocksize / 100) i));
+VACUUM fsm_check_size;
+SELECT pg_relation_size(reltoastrelid, 'main') / :blocksize AS toast_nblocks,
+pg_relation_size(reltoastrelid, 'fsm') / :blocksize AS toast_fsm_nblocks
+FROM pg_class WHERE relname = 'fsm_check_size';
+ toast_nblocks | toast_fsm_nblocks 
+---------------+-------------------
+             2 |                 0
+(1 row)
+
+DROP TABLE fsm_check_size;
diff --git a/src/test/regress/expected/generated.out b/src/test/regress/expected/generated.out
index f62c93f..2bc71ee 100644
--- a/src/test/regress/expected/generated.out
+++ b/src/test/regress/expected/generated.out
@@ -129,11 +129,11 @@ SELECT a, b FROM gtest1 WHERE b = 4 ORDER BY a;
 -- test that overflow error happens on write
 INSERT INTO gtest1 VALUES (2000000000);
 ERROR:  integer out of range
-SELECT * FROM gtest1;
+SELECT * FROM gtest1 ORDER BY a, b;
  a | b 
 ---+---
- 2 | 4
  1 | 2
+ 2 | 4
 (2 rows)
 
 DELETE FROM gtest1 WHERE a = 2000000000;
diff --git a/src/test/regress/expected/identity.out b/src/test/regress/expected/identity.out
index 2286519..b64965e 100644
--- a/src/test/regress/expected/identity.out
+++ b/src/test/regress/expected/identity.out
@@ -145,25 +145,25 @@ SELECT * FROM itest2;
 -- UPDATE tests
 UPDATE itest1 SET a = 101 WHERE a = 1;
 UPDATE itest1 SET a = DEFAULT WHERE a = 2;
-SELECT * FROM itest1;
+SELECT * FROM itest1 ORDER BY a;
   a  |  b  
 -----+-----
-  10 | xyz
    3 | xyz
- 101 | 
    4 | 
+  10 | xyz
+ 101 | 
 (4 rows)
 
 UPDATE itest2 SET a = 101 WHERE a = 1;
 ERROR:  column "a" can only be updated to DEFAULT
 DETAIL:  Column "a" is an identity column defined as GENERATED ALWAYS.
 UPDATE itest2 SET a = DEFAULT WHERE a = 2;
-SELECT * FROM itest2;
+SELECT * FROM itest2 ORDER BY a;
  a  |  b  
 ----+-----
   1 | 
- 10 | xyz
   3 | 
+ 10 | xyz
 (3 rows)
 
 -- COPY tests
diff --git a/src/test/regress/expected/indirect_toast.out b/src/test/regress/expected/indirect_toast.out
index b05173c..90c0dd0 100644
--- a/src/test/regress/expected/indirect_toast.out
+++ b/src/test/regress/expected/indirect_toast.out
@@ -24,52 +24,58 @@ UPDATE indtoasttest SET cnt = cnt +1 RETURNING substring(indtoasttest::text, 1,
 (4 rows)
 
 -- modification without modifying assigned value
-UPDATE indtoasttest SET cnt = cnt +1, f1 = f1 RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1, f1 = f1 RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
                                                                                                 substring                                                                                                 
 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- (two-compressed,2,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012
- (two-toasted,2,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345
  ("one-compressed,one-null",2,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
  ("one-toasted,one-null",2,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
+ (two-compressed,2,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012
+ (two-toasted,2,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345
 (4 rows)
 
 -- modification modifying, but effectively not changing
-UPDATE indtoasttest SET cnt = cnt +1, f1 = f1||'' RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1, f1 = f1||'' RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
                                                                                                 substring                                                                                                 
 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- (two-compressed,3,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012
- (two-toasted,3,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345
  ("one-compressed,one-null",3,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
  ("one-toasted,one-null",3,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
+ (two-compressed,3,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012
+ (two-toasted,3,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345
 (4 rows)
 
-UPDATE indtoasttest SET cnt = cnt +1, f1 = '-'||f1||'-' RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1, f1 = '-'||f1||'-' RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
                                                                                                 substring                                                                                                 
 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- (two-compressed,4,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901
- (two-toasted,4,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234
  ("one-compressed,one-null",4,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
  ("one-toasted,one-null",4,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
+ (two-compressed,4,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901
+ (two-toasted,4,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234
 (4 rows)
 
-SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest;
+SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest ORDER BY 1;
                                                                                                 substring                                                                                                 
 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- (two-compressed,4,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901
- (two-toasted,4,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234
  ("one-compressed,one-null",4,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
  ("one-toasted,one-null",4,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
+ (two-compressed,4,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901
+ (two-toasted,4,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234
 (4 rows)
 
 -- check we didn't screw with main/toast tuple visibility
 VACUUM FREEZE indtoasttest;
-SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest;
+SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest ORDER BY 1;
                                                                                                 substring                                                                                                 
 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- (two-compressed,4,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901
- (two-toasted,4,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234
  ("one-compressed,one-null",4,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
  ("one-toasted,one-null",4,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
+ (two-compressed,4,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901
+ (two-toasted,4,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234
 (4 rows)
 
 -- now create a trigger that forces all Datums to be indirect ones
@@ -86,65 +92,73 @@ CREATE TRIGGER indtoasttest_update_indirect
         FOR EACH ROW
         EXECUTE PROCEDURE update_using_indirect();
 -- modification without changing varlenas
-UPDATE indtoasttest SET cnt = cnt +1 RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1 RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
                                                                                                 substring                                                                                                 
 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- (two-compressed,5,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901
- (two-toasted,5,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234
  ("one-compressed,one-null",5,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
  ("one-toasted,one-null",5,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
+ (two-compressed,5,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901
+ (two-toasted,5,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234
 (4 rows)
 
 -- modification without modifying assigned value
-UPDATE indtoasttest SET cnt = cnt +1, f1 = f1 RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1, f1 = f1 RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
                                                                                                 substring                                                                                                 
 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- (two-compressed,6,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901
- (two-toasted,6,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234
  ("one-compressed,one-null",6,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
  ("one-toasted,one-null",6,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
+ (two-compressed,6,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901
+ (two-toasted,6,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234
 (4 rows)
 
 -- modification modifying, but effectively not changing
-UPDATE indtoasttest SET cnt = cnt +1, f1 = f1||'' RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1, f1 = f1||'' RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
                                                                                                 substring                                                                                                 
 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- (two-compressed,7,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901
- (two-toasted,7,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234
  ("one-compressed,one-null",7,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
  ("one-toasted,one-null",7,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
+ (two-compressed,7,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901
+ (two-toasted,7,-1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234
 (4 rows)
 
-UPDATE indtoasttest SET cnt = cnt +1, f1 = '-'||f1||'-' RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1, f1 = '-'||f1||'-' RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
                                                                                                 substring                                                                                                 
 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- (two-compressed,8,--123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
- (two-toasted,8,--123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
  ("one-compressed,one-null",8,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
  ("one-toasted,one-null",8,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
+ (two-compressed,8,--123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
+ (two-toasted,8,--123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
 (4 rows)
 
 INSERT INTO indtoasttest(descr, f1, f2) VALUES('one-toasted,one-null, via indirect', repeat('1234567890',30000), NULL);
-SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest;
+SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest ORDER BY 1;
                                                                                                 substring                                                                                                 
 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- (two-compressed,8,--123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
- (two-toasted,8,--123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
  ("one-compressed,one-null",8,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
  ("one-toasted,one-null",8,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
  ("one-toasted,one-null, via indirect",0,1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
+ (two-compressed,8,--123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
+ (two-toasted,8,--123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
 (5 rows)
 
 -- check we didn't screw with main/toast tuple visibility
 VACUUM FREEZE indtoasttest;
-SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest;
+SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest ORDER BY 1;
                                                                                                 substring                                                                                                 
 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- (two-compressed,8,--123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
- (two-toasted,8,--123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
  ("one-compressed,one-null",8,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
  ("one-toasted,one-null",8,,12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
  ("one-toasted,one-null, via indirect",0,1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
+ (two-compressed,8,--123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890
+ (two-toasted,8,--123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123
 (5 rows)
 
 DROP TABLE indtoasttest;
diff --git a/src/test/regress/expected/inherit.out b/src/test/regress/expected/inherit.out
index c6abcfc..c9ec9fe 100644
--- a/src/test/regress/expected/inherit.out
+++ b/src/test/regress/expected/inherit.out
@@ -154,7 +154,7 @@ UPDATE ONLY a SET aa='zzzzz' WHERE aa='aaaaa';
 UPDATE b SET aa='zzz' WHERE aa='aaa';
 UPDATE ONLY b SET aa='zzz' WHERE aa='aaa';
 UPDATE a SET aa='zzzzzz' WHERE aa LIKE 'aaa%';
-SELECT relname, a.* FROM a, pg_class where a.tableoid = pg_class.oid;
+SELECT relname, a.* FROM a, pg_class where a.tableoid = pg_class.oid order by relname, aa;
  relname |    aa    
 ---------+----------
  a       | zzzz
@@ -228,7 +228,7 @@ SELECT relname, d.* FROM d, pg_class where d.tableoid = pg_class.oid;
  d       | dddddddd |    |    | 
 (6 rows)
 
-SELECT relname, a.* FROM ONLY a, pg_class where a.tableoid = pg_class.oid;
+SELECT relname, a.* FROM ONLY a, pg_class where a.tableoid = pg_class.oid order by relname, aa;
  relname |   aa   
 ---------+--------
  a       | zzzz
@@ -273,7 +273,7 @@ SELECT relname, d.* FROM ONLY d, pg_class where d.tableoid = pg_class.oid;
 (6 rows)
 
 UPDATE b SET aa='new';
-SELECT relname, a.* FROM a, pg_class where a.tableoid = pg_class.oid;
+SELECT relname, a.* FROM a, pg_class where a.tableoid = pg_class.oid order by relname, aa;
  relname |    aa    
 ---------+----------
  a       | zzzz
@@ -347,7 +347,7 @@ SELECT relname, d.* FROM d, pg_class where d.tableoid = pg_class.oid;
  d       | new |    |    | 
 (6 rows)
 
-SELECT relname, a.* FROM ONLY a, pg_class where a.tableoid = pg_class.oid;
+SELECT relname, a.* FROM ONLY a, pg_class where a.tableoid = pg_class.oid order by relname, aa;
  relname |   aa   
 ---------+--------
  a       | zzzz
diff --git a/src/test/regress/expected/insert_conflict.out b/src/test/regress/expected/insert_conflict.out
index 1338b2b..bfb9435 100644
--- a/src/test/regress/expected/insert_conflict.out
+++ b/src/test/regress/expected/insert_conflict.out
@@ -528,7 +528,7 @@ insert into cities values ('Las Vegas', 2.583E+5, 2174) on conflict do nothing;
 insert into capitals values ('Sacramento', 4664.E+5, 30, 'CA') on conflict (name) do update set population = excluded.population;
 -- Wrong "Sacramento", so do nothing:
 insert into capitals values ('Sacramento', 50, 2267, 'NE') on conflict (name) do nothing;
-select * from capitals;
+select * from capitals order by name;
     name    | population | altitude | state 
 ------------+------------+----------+-------
  Madison    |     191300 |      845 | WI
@@ -536,50 +536,50 @@ select * from capitals;
 (2 rows)
 
 insert into cities values ('Las Vegas', 5.83E+5, 2001) on conflict (name) do update set population = excluded.population, altitude = excluded.altitude;
-select tableoid::regclass, * from cities;
+select tableoid::regclass, * from cities order by name;
  tableoid |     name      | population | altitude 
 ----------+---------------+------------+----------
- cities   | San Francisco |     724000 |       63
- cities   | Mariposa      |       1200 |     1953
  cities   | Las Vegas     |     583000 |     2001
  capitals | Madison       |     191300 |      845
+ cities   | Mariposa      |       1200 |     1953
  capitals | Sacramento    |  466400000 |       30
+ cities   | San Francisco |     724000 |       63
 (5 rows)
 
 insert into capitals values ('Las Vegas', 5.83E+5, 2222, 'NV') on conflict (name) do update set population = excluded.population;
 -- Capitals will contain new capital, Las Vegas:
-select * from capitals;
+select * from capitals order by name;
     name    | population | altitude | state 
 ------------+------------+----------+-------
+ Las Vegas  |     583000 |     2222 | NV
  Madison    |     191300 |      845 | WI
  Sacramento |  466400000 |       30 | CA
- Las Vegas  |     583000 |     2222 | NV
 (3 rows)
 
 -- Cities contains two instances of "Las Vegas", since unique constraints don't
 -- work across inheritance:
-select tableoid::regclass, * from cities;
+select tableoid::regclass, * from cities order by name;
  tableoid |     name      | population | altitude 
 ----------+---------------+------------+----------
- cities   | San Francisco |     724000 |       63
- cities   | Mariposa      |       1200 |     1953
  cities   | Las Vegas     |     583000 |     2001
+ capitals | Las Vegas     |     583000 |     2222
  capitals | Madison       |     191300 |      845
+ cities   | Mariposa      |       1200 |     1953
  capitals | Sacramento    |  466400000 |       30
- capitals | Las Vegas     |     583000 |     2222
+ cities   | San Francisco |     724000 |       63
 (6 rows)
 
 -- This only affects "cities" version of "Las Vegas":
 insert into cities values ('Las Vegas', 5.86E+5, 2223) on conflict (name) do update set population = excluded.population, altitude = excluded.altitude;
-select tableoid::regclass, * from cities;
+select tableoid::regclass, * from cities order by name;
  tableoid |     name      | population | altitude 
 ----------+---------------+------------+----------
- cities   | San Francisco |     724000 |       63
- cities   | Mariposa      |       1200 |     1953
  cities   | Las Vegas     |     586000 |     2223
+ capitals | Las Vegas     |     583000 |     2222
  capitals | Madison       |     191300 |      845
+ cities   | Mariposa      |       1200 |     1953
  capitals | Sacramento    |  466400000 |       30
- capitals | Las Vegas     |     583000 |     2222
+ cities   | San Francisco |     724000 |       63
 (6 rows)
 
 -- clean up
diff --git a/src/test/regress/expected/partition_aggregate_1.out b/src/test/regress/expected/partition_aggregate_1.out
new file mode 100644
index 0000000..b296575
--- /dev/null
+++ b/src/test/regress/expected/partition_aggregate_1.out
@@ -0,0 +1,1507 @@
+--
+-- PARTITION_AGGREGATE
+-- Test partitionwise aggregation on partitioned tables
+--
+-- Enable partitionwise aggregate, which by default is disabled.
+SET enable_partitionwise_aggregate TO true;
+-- Enable partitionwise join, which by default is disabled.
+SET enable_partitionwise_join TO true;
+-- Disable parallel plans.
+SET max_parallel_workers_per_gather TO 0;
+--
+-- Tests for list partitioned tables.
+--
+CREATE TABLE pagg_tab (a int, b int, c text, d int) PARTITION BY LIST(c);
+CREATE TABLE pagg_tab_p1 PARTITION OF pagg_tab FOR VALUES IN ('0000', '0001', '0002', '0003');
+CREATE TABLE pagg_tab_p2 PARTITION OF pagg_tab FOR VALUES IN ('0004', '0005', '0006', '0007');
+CREATE TABLE pagg_tab_p3 PARTITION OF pagg_tab FOR VALUES IN ('0008', '0009', '0010', '0011');
+INSERT INTO pagg_tab SELECT i % 20, i % 30, to_char(i % 12, 'FM0000'), i % 30 FROM generate_series(0, 2999) i;
+ANALYZE pagg_tab;
+-- When GROUP BY clause matches; full aggregation is performed for each partition.
+EXPLAIN (COSTS OFF)
+SELECT c, sum(a), avg(b), count(*), min(a), max(b) FROM pagg_tab GROUP BY c HAVING avg(d) < 15 ORDER BY 1, 2, 3;
+                              QUERY PLAN                               
+-----------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_p1.c, (sum(pagg_tab_p1.a)), (avg(pagg_tab_p1.b))
+   ->  Append
+         ->  HashAggregate
+               Group Key: pagg_tab_p1.c
+               Filter: (avg(pagg_tab_p1.d) < '15'::numeric)
+               ->  Seq Scan on pagg_tab_p1
+         ->  HashAggregate
+               Group Key: pagg_tab_p2.c
+               Filter: (avg(pagg_tab_p2.d) < '15'::numeric)
+               ->  Seq Scan on pagg_tab_p2
+         ->  HashAggregate
+               Group Key: pagg_tab_p3.c
+               Filter: (avg(pagg_tab_p3.d) < '15'::numeric)
+               ->  Seq Scan on pagg_tab_p3
+(15 rows)
+
+SELECT c, sum(a), avg(b), count(*), min(a), max(b) FROM pagg_tab GROUP BY c HAVING avg(d) < 15 ORDER BY 1, 2, 3;
+  c   | sum  |         avg         | count | min | max 
+------+------+---------------------+-------+-----+-----
+ 0000 | 2000 | 12.0000000000000000 |   250 |   0 |  24
+ 0001 | 2250 | 13.0000000000000000 |   250 |   1 |  25
+ 0002 | 2500 | 14.0000000000000000 |   250 |   2 |  26
+ 0006 | 2500 | 12.0000000000000000 |   250 |   2 |  24
+ 0007 | 2750 | 13.0000000000000000 |   250 |   3 |  25
+ 0008 | 2000 | 14.0000000000000000 |   250 |   0 |  26
+(6 rows)
+
+-- When GROUP BY clause does not match; partial aggregation is performed for each partition.
+EXPLAIN (COSTS OFF)
+SELECT a, sum(b), avg(b), count(*), min(a), max(b) FROM pagg_tab GROUP BY a HAVING avg(d) < 15 ORDER BY 1, 2, 3;
+                              QUERY PLAN                               
+-----------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_p1.a, (sum(pagg_tab_p1.b)), (avg(pagg_tab_p1.b))
+   ->  Finalize HashAggregate
+         Group Key: pagg_tab_p1.a
+         Filter: (avg(pagg_tab_p1.d) < '15'::numeric)
+         ->  Append
+               ->  Partial HashAggregate
+                     Group Key: pagg_tab_p1.a
+                     ->  Seq Scan on pagg_tab_p1
+               ->  Partial HashAggregate
+                     Group Key: pagg_tab_p2.a
+                     ->  Seq Scan on pagg_tab_p2
+               ->  Partial HashAggregate
+                     Group Key: pagg_tab_p3.a
+                     ->  Seq Scan on pagg_tab_p3
+(15 rows)
+
+SELECT a, sum(b), avg(b), count(*), min(a), max(b) FROM pagg_tab GROUP BY a HAVING avg(d) < 15 ORDER BY 1, 2, 3;
+ a  | sum  |         avg         | count | min | max 
+----+------+---------------------+-------+-----+-----
+  0 | 1500 | 10.0000000000000000 |   150 |   0 |  20
+  1 | 1650 | 11.0000000000000000 |   150 |   1 |  21
+  2 | 1800 | 12.0000000000000000 |   150 |   2 |  22
+  3 | 1950 | 13.0000000000000000 |   150 |   3 |  23
+  4 | 2100 | 14.0000000000000000 |   150 |   4 |  24
+ 10 | 1500 | 10.0000000000000000 |   150 |  10 |  20
+ 11 | 1650 | 11.0000000000000000 |   150 |  11 |  21
+ 12 | 1800 | 12.0000000000000000 |   150 |  12 |  22
+ 13 | 1950 | 13.0000000000000000 |   150 |  13 |  23
+ 14 | 2100 | 14.0000000000000000 |   150 |  14 |  24
+(10 rows)
+
+-- Check with multiple columns in GROUP BY
+EXPLAIN (COSTS OFF)
+SELECT a, c, count(*) FROM pagg_tab GROUP BY a, c;
+                   QUERY PLAN                    
+-------------------------------------------------
+ Append
+   ->  HashAggregate
+         Group Key: pagg_tab_p1.a, pagg_tab_p1.c
+         ->  Seq Scan on pagg_tab_p1
+   ->  HashAggregate
+         Group Key: pagg_tab_p2.a, pagg_tab_p2.c
+         ->  Seq Scan on pagg_tab_p2
+   ->  HashAggregate
+         Group Key: pagg_tab_p3.a, pagg_tab_p3.c
+         ->  Seq Scan on pagg_tab_p3
+(10 rows)
+
+-- Check with multiple columns in GROUP BY, order in GROUP BY is reversed
+EXPLAIN (COSTS OFF)
+SELECT a, c, count(*) FROM pagg_tab GROUP BY c, a;
+                   QUERY PLAN                    
+-------------------------------------------------
+ Append
+   ->  HashAggregate
+         Group Key: pagg_tab_p1.c, pagg_tab_p1.a
+         ->  Seq Scan on pagg_tab_p1
+   ->  HashAggregate
+         Group Key: pagg_tab_p2.c, pagg_tab_p2.a
+         ->  Seq Scan on pagg_tab_p2
+   ->  HashAggregate
+         Group Key: pagg_tab_p3.c, pagg_tab_p3.a
+         ->  Seq Scan on pagg_tab_p3
+(10 rows)
+
+-- Check with multiple columns in GROUP BY, order in target-list is reversed
+EXPLAIN (COSTS OFF)
+SELECT c, a, count(*) FROM pagg_tab GROUP BY a, c;
+                   QUERY PLAN                    
+-------------------------------------------------
+ Append
+   ->  HashAggregate
+         Group Key: pagg_tab_p1.a, pagg_tab_p1.c
+         ->  Seq Scan on pagg_tab_p1
+   ->  HashAggregate
+         Group Key: pagg_tab_p2.a, pagg_tab_p2.c
+         ->  Seq Scan on pagg_tab_p2
+   ->  HashAggregate
+         Group Key: pagg_tab_p3.a, pagg_tab_p3.c
+         ->  Seq Scan on pagg_tab_p3
+(10 rows)
+
+-- Test when input relation for grouping is dummy
+EXPLAIN (COSTS OFF)
+SELECT c, sum(a) FROM pagg_tab WHERE 1 = 2 GROUP BY c;
+           QUERY PLAN           
+--------------------------------
+ HashAggregate
+   Group Key: c
+   ->  Result
+         One-Time Filter: false
+(4 rows)
+
+SELECT c, sum(a) FROM pagg_tab WHERE 1 = 2 GROUP BY c;
+ c | sum 
+---+-----
+(0 rows)
+
+EXPLAIN (COSTS OFF)
+SELECT c, sum(a) FROM pagg_tab WHERE c = 'x' GROUP BY c;
+           QUERY PLAN           
+--------------------------------
+ GroupAggregate
+   Group Key: c
+   ->  Result
+         One-Time Filter: false
+(4 rows)
+
+SELECT c, sum(a) FROM pagg_tab WHERE c = 'x' GROUP BY c;
+ c | sum 
+---+-----
+(0 rows)
+
+-- Test GroupAggregate paths by disabling hash aggregates.
+SET enable_hashagg TO false;
+-- When GROUP BY clause matches full aggregation is performed for each partition.
+EXPLAIN (COSTS OFF)
+SELECT c, sum(a), avg(b), count(*) FROM pagg_tab GROUP BY 1 HAVING avg(d) < 15 ORDER BY 1, 2, 3;
+                              QUERY PLAN                               
+-----------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_p1.c, (sum(pagg_tab_p1.a)), (avg(pagg_tab_p1.b))
+   ->  Append
+         ->  GroupAggregate
+               Group Key: pagg_tab_p1.c
+               Filter: (avg(pagg_tab_p1.d) < '15'::numeric)
+               ->  Sort
+                     Sort Key: pagg_tab_p1.c
+                     ->  Seq Scan on pagg_tab_p1
+         ->  GroupAggregate
+               Group Key: pagg_tab_p2.c
+               Filter: (avg(pagg_tab_p2.d) < '15'::numeric)
+               ->  Sort
+                     Sort Key: pagg_tab_p2.c
+                     ->  Seq Scan on pagg_tab_p2
+         ->  GroupAggregate
+               Group Key: pagg_tab_p3.c
+               Filter: (avg(pagg_tab_p3.d) < '15'::numeric)
+               ->  Sort
+                     Sort Key: pagg_tab_p3.c
+                     ->  Seq Scan on pagg_tab_p3
+(21 rows)
+
+SELECT c, sum(a), avg(b), count(*) FROM pagg_tab GROUP BY 1 HAVING avg(d) < 15 ORDER BY 1, 2, 3;
+  c   | sum  |         avg         | count 
+------+------+---------------------+-------
+ 0000 | 2000 | 12.0000000000000000 |   250
+ 0001 | 2250 | 13.0000000000000000 |   250
+ 0002 | 2500 | 14.0000000000000000 |   250
+ 0006 | 2500 | 12.0000000000000000 |   250
+ 0007 | 2750 | 13.0000000000000000 |   250
+ 0008 | 2000 | 14.0000000000000000 |   250
+(6 rows)
+
+-- When GROUP BY clause does not match; partial aggregation is performed for each partition.
+EXPLAIN (COSTS OFF)
+SELECT a, sum(b), avg(b), count(*) FROM pagg_tab GROUP BY 1 HAVING avg(d) < 15 ORDER BY 1, 2, 3;
+                              QUERY PLAN                               
+-----------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_p1.a, (sum(pagg_tab_p1.b)), (avg(pagg_tab_p1.b))
+   ->  Finalize GroupAggregate
+         Group Key: pagg_tab_p1.a
+         Filter: (avg(pagg_tab_p1.d) < '15'::numeric)
+         ->  Merge Append
+               Sort Key: pagg_tab_p1.a
+               ->  Partial GroupAggregate
+                     Group Key: pagg_tab_p1.a
+                     ->  Sort
+                           Sort Key: pagg_tab_p1.a
+                           ->  Seq Scan on pagg_tab_p1
+               ->  Partial GroupAggregate
+                     Group Key: pagg_tab_p2.a
+                     ->  Sort
+                           Sort Key: pagg_tab_p2.a
+                           ->  Seq Scan on pagg_tab_p2
+               ->  Partial GroupAggregate
+                     Group Key: pagg_tab_p3.a
+                     ->  Sort
+                           Sort Key: pagg_tab_p3.a
+                           ->  Seq Scan on pagg_tab_p3
+(22 rows)
+
+SELECT a, sum(b), avg(b), count(*) FROM pagg_tab GROUP BY 1 HAVING avg(d) < 15 ORDER BY 1, 2, 3;
+ a  | sum  |         avg         | count 
+----+------+---------------------+-------
+  0 | 1500 | 10.0000000000000000 |   150
+  1 | 1650 | 11.0000000000000000 |   150
+  2 | 1800 | 12.0000000000000000 |   150
+  3 | 1950 | 13.0000000000000000 |   150
+  4 | 2100 | 14.0000000000000000 |   150
+ 10 | 1500 | 10.0000000000000000 |   150
+ 11 | 1650 | 11.0000000000000000 |   150
+ 12 | 1800 | 12.0000000000000000 |   150
+ 13 | 1950 | 13.0000000000000000 |   150
+ 14 | 2100 | 14.0000000000000000 |   150
+(10 rows)
+
+-- Test partitionwise grouping without any aggregates
+EXPLAIN (COSTS OFF)
+SELECT c FROM pagg_tab GROUP BY c ORDER BY 1;
+                QUERY PLAN                 
+-------------------------------------------
+ Merge Append
+   Sort Key: pagg_tab_p1.c
+   ->  Group
+         Group Key: pagg_tab_p1.c
+         ->  Sort
+               Sort Key: pagg_tab_p1.c
+               ->  Seq Scan on pagg_tab_p1
+   ->  Group
+         Group Key: pagg_tab_p2.c
+         ->  Sort
+               Sort Key: pagg_tab_p2.c
+               ->  Seq Scan on pagg_tab_p2
+   ->  Group
+         Group Key: pagg_tab_p3.c
+         ->  Sort
+               Sort Key: pagg_tab_p3.c
+               ->  Seq Scan on pagg_tab_p3
+(17 rows)
+
+SELECT c FROM pagg_tab GROUP BY c ORDER BY 1;
+  c   
+------
+ 0000
+ 0001
+ 0002
+ 0003
+ 0004
+ 0005
+ 0006
+ 0007
+ 0008
+ 0009
+ 0010
+ 0011
+(12 rows)
+
+EXPLAIN (COSTS OFF)
+SELECT a FROM pagg_tab WHERE a < 3 GROUP BY a ORDER BY 1;
+                   QUERY PLAN                    
+-------------------------------------------------
+ Group
+   Group Key: pagg_tab_p1.a
+   ->  Merge Append
+         Sort Key: pagg_tab_p1.a
+         ->  Group
+               Group Key: pagg_tab_p1.a
+               ->  Sort
+                     Sort Key: pagg_tab_p1.a
+                     ->  Seq Scan on pagg_tab_p1
+                           Filter: (a < 3)
+         ->  Group
+               Group Key: pagg_tab_p2.a
+               ->  Sort
+                     Sort Key: pagg_tab_p2.a
+                     ->  Seq Scan on pagg_tab_p2
+                           Filter: (a < 3)
+         ->  Group
+               Group Key: pagg_tab_p3.a
+               ->  Sort
+                     Sort Key: pagg_tab_p3.a
+                     ->  Seq Scan on pagg_tab_p3
+                           Filter: (a < 3)
+(22 rows)
+
+SELECT a FROM pagg_tab WHERE a < 3 GROUP BY a ORDER BY 1;
+ a 
+---
+ 0
+ 1
+ 2
+(3 rows)
+
+RESET enable_hashagg;
+-- ROLLUP, partitionwise aggregation does not apply
+EXPLAIN (COSTS OFF)
+SELECT c, sum(a) FROM pagg_tab GROUP BY rollup(c) ORDER BY 1, 2;
+                   QUERY PLAN                    
+-------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_p1.c, (sum(pagg_tab_p1.a))
+   ->  MixedAggregate
+         Hash Key: pagg_tab_p1.c
+         Group Key: ()
+         ->  Append
+               ->  Seq Scan on pagg_tab_p1
+               ->  Seq Scan on pagg_tab_p2
+               ->  Seq Scan on pagg_tab_p3
+(9 rows)
+
+-- ORDERED SET within the aggregate.
+-- Full aggregation; since all the rows that belong to the same group come
+-- from the same partition, having an ORDER BY within the aggregate doesn't
+-- make any difference.
+EXPLAIN (COSTS OFF)
+SELECT c, sum(b order by a) FROM pagg_tab GROUP BY c ORDER BY 1, 2;
+                               QUERY PLAN                               
+------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_p1.c, (sum(pagg_tab_p1.b ORDER BY pagg_tab_p1.a))
+   ->  Append
+         ->  GroupAggregate
+               Group Key: pagg_tab_p1.c
+               ->  Sort
+                     Sort Key: pagg_tab_p1.c
+                     ->  Seq Scan on pagg_tab_p1
+         ->  GroupAggregate
+               Group Key: pagg_tab_p2.c
+               ->  Sort
+                     Sort Key: pagg_tab_p2.c
+                     ->  Seq Scan on pagg_tab_p2
+         ->  GroupAggregate
+               Group Key: pagg_tab_p3.c
+               ->  Sort
+                     Sort Key: pagg_tab_p3.c
+                     ->  Seq Scan on pagg_tab_p3
+(18 rows)
+
+-- Since GROUP BY clause does not match with PARTITION KEY; we need to do
+-- partial aggregation. However, ORDERED SET are not partial safe and thus
+-- partitionwise aggregation plan is not generated.
+EXPLAIN (COSTS OFF)
+SELECT a, sum(b order by a) FROM pagg_tab GROUP BY a ORDER BY 1, 2;
+                               QUERY PLAN                               
+------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_p1.a, (sum(pagg_tab_p1.b ORDER BY pagg_tab_p1.a))
+   ->  GroupAggregate
+         Group Key: pagg_tab_p1.a
+         ->  Sort
+               Sort Key: pagg_tab_p1.a
+               ->  Append
+                     ->  Seq Scan on pagg_tab_p1
+                     ->  Seq Scan on pagg_tab_p2
+                     ->  Seq Scan on pagg_tab_p3
+(10 rows)
+
+-- JOIN query
+CREATE TABLE pagg_tab1(x int, y int) PARTITION BY RANGE(x);
+CREATE TABLE pagg_tab1_p1 PARTITION OF pagg_tab1 FOR VALUES FROM (0) TO (10);
+CREATE TABLE pagg_tab1_p2 PARTITION OF pagg_tab1 FOR VALUES FROM (10) TO (20);
+CREATE TABLE pagg_tab1_p3 PARTITION OF pagg_tab1 FOR VALUES FROM (20) TO (30);
+CREATE TABLE pagg_tab2(x int, y int) PARTITION BY RANGE(y);
+CREATE TABLE pagg_tab2_p1 PARTITION OF pagg_tab2 FOR VALUES FROM (0) TO (10);
+CREATE TABLE pagg_tab2_p2 PARTITION OF pagg_tab2 FOR VALUES FROM (10) TO (20);
+CREATE TABLE pagg_tab2_p3 PARTITION OF pagg_tab2 FOR VALUES FROM (20) TO (30);
+INSERT INTO pagg_tab1 SELECT i % 30, i % 20 FROM generate_series(0, 299, 2) i;
+INSERT INTO pagg_tab2 SELECT i % 20, i % 30 FROM generate_series(0, 299, 3) i;
+ANALYZE pagg_tab1;
+ANALYZE pagg_tab2;
+-- When GROUP BY clause matches; full aggregation is performed for each partition.
+EXPLAIN (COSTS OFF)
+SELECT t1.x, sum(t1.y), count(*) FROM pagg_tab1 t1, pagg_tab2 t2 WHERE t1.x = t2.y GROUP BY t1.x ORDER BY 1, 2, 3;
+                         QUERY PLAN                          
+-------------------------------------------------------------
+ Sort
+   Sort Key: t1.x, (sum(t1.y)), (count(*))
+   ->  Append
+         ->  HashAggregate
+               Group Key: t1.x
+               ->  Hash Join
+                     Hash Cond: (t1.x = t2.y)
+                     ->  Seq Scan on pagg_tab1_p1 t1
+                     ->  Hash
+                           ->  Seq Scan on pagg_tab2_p1 t2
+         ->  HashAggregate
+               Group Key: t1_1.x
+               ->  Hash Join
+                     Hash Cond: (t1_1.x = t2_1.y)
+                     ->  Seq Scan on pagg_tab1_p2 t1_1
+                     ->  Hash
+                           ->  Seq Scan on pagg_tab2_p2 t2_1
+         ->  HashAggregate
+               Group Key: t1_2.x
+               ->  Hash Join
+                     Hash Cond: (t2_2.y = t1_2.x)
+                     ->  Seq Scan on pagg_tab2_p3 t2_2
+                     ->  Hash
+                           ->  Seq Scan on pagg_tab1_p3 t1_2
+(24 rows)
+
+SELECT t1.x, sum(t1.y), count(*) FROM pagg_tab1 t1, pagg_tab2 t2 WHERE t1.x = t2.y GROUP BY t1.x ORDER BY 1, 2, 3;
+ x  | sum  | count 
+----+------+-------
+  0 |  500 |   100
+  6 | 1100 |   100
+ 12 |  700 |   100
+ 18 | 1300 |   100
+ 24 |  900 |   100
+(5 rows)
+
+-- Check with whole-row reference; partitionwise aggregation does not apply
+EXPLAIN (COSTS OFF)
+SELECT t1.x, sum(t1.y), count(t1) FROM pagg_tab1 t1, pagg_tab2 t2 WHERE t1.x = t2.y GROUP BY t1.x ORDER BY 1, 2, 3;
+                         QUERY PLAN                          
+-------------------------------------------------------------
+ Sort
+   Sort Key: t1.x, (sum(t1.y)), (count(((t1.*)::pagg_tab1)))
+   ->  HashAggregate
+         Group Key: t1.x
+         ->  Hash Join
+               Hash Cond: (t1.x = t2.y)
+               ->  Append
+                     ->  Seq Scan on pagg_tab1_p1 t1
+                     ->  Seq Scan on pagg_tab1_p2 t1_1
+                     ->  Seq Scan on pagg_tab1_p3 t1_2
+               ->  Hash
+                     ->  Append
+                           ->  Seq Scan on pagg_tab2_p1 t2
+                           ->  Seq Scan on pagg_tab2_p2 t2_1
+                           ->  Seq Scan on pagg_tab2_p3 t2_2
+(15 rows)
+
+SELECT t1.x, sum(t1.y), count(t1) FROM pagg_tab1 t1, pagg_tab2 t2 WHERE t1.x = t2.y GROUP BY t1.x ORDER BY 1, 2, 3;
+ x  | sum  | count 
+----+------+-------
+  0 |  500 |   100
+  6 | 1100 |   100
+ 12 |  700 |   100
+ 18 | 1300 |   100
+ 24 |  900 |   100
+(5 rows)
+
+-- GROUP BY having other matching key
+EXPLAIN (COSTS OFF)
+SELECT t2.y, sum(t1.y), count(*) FROM pagg_tab1 t1, pagg_tab2 t2 WHERE t1.x = t2.y GROUP BY t2.y ORDER BY 1, 2, 3;
+                         QUERY PLAN                          
+-------------------------------------------------------------
+ Sort
+   Sort Key: t2.y, (sum(t1.y)), (count(*))
+   ->  Append
+         ->  HashAggregate
+               Group Key: t2.y
+               ->  Hash Join
+                     Hash Cond: (t1.x = t2.y)
+                     ->  Seq Scan on pagg_tab1_p1 t1
+                     ->  Hash
+                           ->  Seq Scan on pagg_tab2_p1 t2
+         ->  HashAggregate
+               Group Key: t2_1.y
+               ->  Hash Join
+                     Hash Cond: (t1_1.x = t2_1.y)
+                     ->  Seq Scan on pagg_tab1_p2 t1_1
+                     ->  Hash
+                           ->  Seq Scan on pagg_tab2_p2 t2_1
+         ->  HashAggregate
+               Group Key: t2_2.y
+               ->  Hash Join
+                     Hash Cond: (t2_2.y = t1_2.x)
+                     ->  Seq Scan on pagg_tab2_p3 t2_2
+                     ->  Hash
+                           ->  Seq Scan on pagg_tab1_p3 t1_2
+(24 rows)
+
+-- When GROUP BY clause does not match; partial aggregation is performed for each partition.
+-- Also test GroupAggregate paths by disabling hash aggregates.
+SET enable_hashagg TO false;
+EXPLAIN (COSTS OFF)
+SELECT t1.y, sum(t1.x), count(*) FROM pagg_tab1 t1, pagg_tab2 t2 WHERE t1.x = t2.y GROUP BY t1.y HAVING avg(t1.x) > 10 ORDER BY 1, 2, 3;
+                               QUERY PLAN                                
+-------------------------------------------------------------------------
+ Sort
+   Sort Key: t1.y, (sum(t1.x)), (count(*))
+   ->  Finalize GroupAggregate
+         Group Key: t1.y
+         Filter: (avg(t1.x) > '10'::numeric)
+         ->  Merge Append
+               Sort Key: t1.y
+               ->  Partial GroupAggregate
+                     Group Key: t1.y
+                     ->  Sort
+                           Sort Key: t1.y
+                           ->  Hash Join
+                                 Hash Cond: (t1.x = t2.y)
+                                 ->  Seq Scan on pagg_tab1_p1 t1
+                                 ->  Hash
+                                       ->  Seq Scan on pagg_tab2_p1 t2
+               ->  Partial GroupAggregate
+                     Group Key: t1_1.y
+                     ->  Sort
+                           Sort Key: t1_1.y
+                           ->  Hash Join
+                                 Hash Cond: (t1_1.x = t2_1.y)
+                                 ->  Seq Scan on pagg_tab1_p2 t1_1
+                                 ->  Hash
+                                       ->  Seq Scan on pagg_tab2_p2 t2_1
+               ->  Partial GroupAggregate
+                     Group Key: t1_2.y
+                     ->  Sort
+                           Sort Key: t1_2.y
+                           ->  Hash Join
+                                 Hash Cond: (t2_2.y = t1_2.x)
+                                 ->  Seq Scan on pagg_tab2_p3 t2_2
+                                 ->  Hash
+                                       ->  Seq Scan on pagg_tab1_p3 t1_2
+(34 rows)
+
+SELECT t1.y, sum(t1.x), count(*) FROM pagg_tab1 t1, pagg_tab2 t2 WHERE t1.x = t2.y GROUP BY t1.y HAVING avg(t1.x) > 10 ORDER BY 1, 2, 3;
+ y  | sum  | count 
+----+------+-------
+  2 |  600 |    50
+  4 | 1200 |    50
+  8 |  900 |    50
+ 12 |  600 |    50
+ 14 | 1200 |    50
+ 18 |  900 |    50
+(6 rows)
+
+RESET enable_hashagg;
+-- Check with LEFT/RIGHT/FULL OUTER JOINs which produces NULL values for
+-- aggregation
+-- LEFT JOIN, should produce partial partitionwise aggregation plan as
+-- GROUP BY is on nullable column
+EXPLAIN (COSTS OFF)
+SELECT b.y, sum(a.y) FROM pagg_tab1 a LEFT JOIN pagg_tab2 b ON a.x = b.y GROUP BY b.y ORDER BY 1 NULLS LAST;
+                            QUERY PLAN                            
+------------------------------------------------------------------
+ Finalize GroupAggregate
+   Group Key: b.y
+   ->  Sort
+         Sort Key: b.y
+         ->  Append
+               ->  Partial HashAggregate
+                     Group Key: b.y
+                     ->  Hash Left Join
+                           Hash Cond: (a.x = b.y)
+                           ->  Seq Scan on pagg_tab1_p1 a
+                           ->  Hash
+                                 ->  Seq Scan on pagg_tab2_p1 b
+               ->  Partial HashAggregate
+                     Group Key: b_1.y
+                     ->  Hash Left Join
+                           Hash Cond: (a_1.x = b_1.y)
+                           ->  Seq Scan on pagg_tab1_p2 a_1
+                           ->  Hash
+                                 ->  Seq Scan on pagg_tab2_p2 b_1
+               ->  Partial HashAggregate
+                     Group Key: b_2.y
+                     ->  Hash Right Join
+                           Hash Cond: (b_2.y = a_2.x)
+                           ->  Seq Scan on pagg_tab2_p3 b_2
+                           ->  Hash
+                                 ->  Seq Scan on pagg_tab1_p3 a_2
+(26 rows)
+
+SELECT b.y, sum(a.y) FROM pagg_tab1 a LEFT JOIN pagg_tab2 b ON a.x = b.y GROUP BY b.y ORDER BY 1 NULLS LAST;
+ y  | sum  
+----+------
+  0 |  500
+  6 | 1100
+ 12 |  700
+ 18 | 1300
+ 24 |  900
+    |  900
+(6 rows)
+
+-- RIGHT JOIN, should produce full partitionwise aggregation plan as
+-- GROUP BY is on non-nullable column
+EXPLAIN (COSTS OFF)
+SELECT b.y, sum(a.y) FROM pagg_tab1 a RIGHT JOIN pagg_tab2 b ON a.x = b.y GROUP BY b.y ORDER BY 1 NULLS LAST;
+                         QUERY PLAN                         
+------------------------------------------------------------
+ Sort
+   Sort Key: b.y
+   ->  Append
+         ->  HashAggregate
+               Group Key: b.y
+               ->  Hash Right Join
+                     Hash Cond: (a.x = b.y)
+                     ->  Seq Scan on pagg_tab1_p1 a
+                     ->  Hash
+                           ->  Seq Scan on pagg_tab2_p1 b
+         ->  HashAggregate
+               Group Key: b_1.y
+               ->  Hash Right Join
+                     Hash Cond: (a_1.x = b_1.y)
+                     ->  Seq Scan on pagg_tab1_p2 a_1
+                     ->  Hash
+                           ->  Seq Scan on pagg_tab2_p2 b_1
+         ->  HashAggregate
+               Group Key: b_2.y
+               ->  Hash Left Join
+                     Hash Cond: (b_2.y = a_2.x)
+                     ->  Seq Scan on pagg_tab2_p3 b_2
+                     ->  Hash
+                           ->  Seq Scan on pagg_tab1_p3 a_2
+(24 rows)
+
+SELECT b.y, sum(a.y) FROM pagg_tab1 a RIGHT JOIN pagg_tab2 b ON a.x = b.y GROUP BY b.y ORDER BY 1 NULLS LAST;
+ y  | sum  
+----+------
+  0 |  500
+  3 |     
+  6 | 1100
+  9 |     
+ 12 |  700
+ 15 |     
+ 18 | 1300
+ 21 |     
+ 24 |  900
+ 27 |     
+(10 rows)
+
+-- FULL JOIN, should produce partial partitionwise aggregation plan as
+-- GROUP BY is on nullable column
+EXPLAIN (COSTS OFF)
+SELECT a.x, sum(b.x) FROM pagg_tab1 a FULL OUTER JOIN pagg_tab2 b ON a.x = b.y GROUP BY a.x ORDER BY 1 NULLS LAST;
+                            QUERY PLAN                            
+------------------------------------------------------------------
+ Finalize GroupAggregate
+   Group Key: a.x
+   ->  Sort
+         Sort Key: a.x
+         ->  Append
+               ->  Partial HashAggregate
+                     Group Key: a.x
+                     ->  Hash Full Join
+                           Hash Cond: (a.x = b.y)
+                           ->  Seq Scan on pagg_tab1_p1 a
+                           ->  Hash
+                                 ->  Seq Scan on pagg_tab2_p1 b
+               ->  Partial HashAggregate
+                     Group Key: a_1.x
+                     ->  Hash Full Join
+                           Hash Cond: (a_1.x = b_1.y)
+                           ->  Seq Scan on pagg_tab1_p2 a_1
+                           ->  Hash
+                                 ->  Seq Scan on pagg_tab2_p2 b_1
+               ->  Partial HashAggregate
+                     Group Key: a_2.x
+                     ->  Hash Full Join
+                           Hash Cond: (b_2.y = a_2.x)
+                           ->  Seq Scan on pagg_tab2_p3 b_2
+                           ->  Hash
+                                 ->  Seq Scan on pagg_tab1_p3 a_2
+(26 rows)
+
+SELECT a.x, sum(b.x) FROM pagg_tab1 a FULL OUTER JOIN pagg_tab2 b ON a.x = b.y GROUP BY a.x ORDER BY 1 NULLS LAST;
+ x  | sum  
+----+------
+  0 |  500
+  2 |     
+  4 |     
+  6 | 1100
+  8 |     
+ 10 |     
+ 12 |  700
+ 14 |     
+ 16 |     
+ 18 | 1300
+ 20 |     
+ 22 |     
+ 24 |  900
+ 26 |     
+ 28 |     
+    |  500
+(16 rows)
+
+-- LEFT JOIN, with dummy relation on right side, ideally
+-- should produce full partitionwise aggregation plan as GROUP BY is on
+-- non-nullable columns.
+-- But right now we are unable to do partitionwise join in this case.
+EXPLAIN (COSTS OFF)
+SELECT a.x, b.y, count(*) FROM (SELECT * FROM pagg_tab1 WHERE x < 20) a LEFT JOIN (SELECT * FROM pagg_tab2 WHERE y > 10) b ON a.x = b.y WHERE a.x > 5 or b.y < 20  GROUP BY a.x, b.y ORDER BY 1, 2;
+                              QUERY PLAN                               
+-----------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab1_p1.x, pagg_tab2_p2.y
+   ->  HashAggregate
+         Group Key: pagg_tab1_p1.x, pagg_tab2_p2.y
+         ->  Hash Left Join
+               Hash Cond: (pagg_tab1_p1.x = pagg_tab2_p2.y)
+               Filter: ((pagg_tab1_p1.x > 5) OR (pagg_tab2_p2.y < 20))
+               ->  Append
+                     ->  Seq Scan on pagg_tab1_p1
+                           Filter: (x < 20)
+                     ->  Seq Scan on pagg_tab1_p2
+                           Filter: (x < 20)
+               ->  Hash
+                     ->  Append
+                           ->  Seq Scan on pagg_tab2_p2
+                                 Filter: (y > 10)
+                           ->  Seq Scan on pagg_tab2_p3
+                                 Filter: (y > 10)
+(18 rows)
+
+SELECT a.x, b.y, count(*) FROM (SELECT * FROM pagg_tab1 WHERE x < 20) a LEFT JOIN (SELECT * FROM pagg_tab2 WHERE y > 10) b ON a.x = b.y WHERE a.x > 5 or b.y < 20  GROUP BY a.x, b.y ORDER BY 1, 2;
+ x  | y  | count 
+----+----+-------
+  6 |    |    10
+  8 |    |    10
+ 10 |    |    10
+ 12 | 12 |   100
+ 14 |    |    10
+ 16 |    |    10
+ 18 | 18 |   100
+(7 rows)
+
+-- FULL JOIN, with dummy relations on both sides, ideally
+-- should produce partial partitionwise aggregation plan as GROUP BY is on
+-- nullable columns.
+-- But right now we are unable to do partitionwise join in this case.
+EXPLAIN (COSTS OFF)
+SELECT a.x, b.y, count(*) FROM (SELECT * FROM pagg_tab1 WHERE x < 20) a FULL JOIN (SELECT * FROM pagg_tab2 WHERE y > 10) b ON a.x = b.y WHERE a.x > 5 or b.y < 20  GROUP BY a.x, b.y ORDER BY 1, 2;
+                              QUERY PLAN                               
+-----------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab1_p1.x, pagg_tab2_p2.y
+   ->  HashAggregate
+         Group Key: pagg_tab1_p1.x, pagg_tab2_p2.y
+         ->  Hash Full Join
+               Hash Cond: (pagg_tab1_p1.x = pagg_tab2_p2.y)
+               Filter: ((pagg_tab1_p1.x > 5) OR (pagg_tab2_p2.y < 20))
+               ->  Append
+                     ->  Seq Scan on pagg_tab1_p1
+                           Filter: (x < 20)
+                     ->  Seq Scan on pagg_tab1_p2
+                           Filter: (x < 20)
+               ->  Hash
+                     ->  Append
+                           ->  Seq Scan on pagg_tab2_p2
+                                 Filter: (y > 10)
+                           ->  Seq Scan on pagg_tab2_p3
+                                 Filter: (y > 10)
+(18 rows)
+
+SELECT a.x, b.y, count(*) FROM (SELECT * FROM pagg_tab1 WHERE x < 20) a FULL JOIN (SELECT * FROM pagg_tab2 WHERE y > 10) b ON a.x = b.y WHERE a.x > 5 or b.y < 20 GROUP BY a.x, b.y ORDER BY 1, 2;
+ x  | y  | count 
+----+----+-------
+  6 |    |    10
+  8 |    |    10
+ 10 |    |    10
+ 12 | 12 |   100
+ 14 |    |    10
+ 16 |    |    10
+ 18 | 18 |   100
+    | 15 |    10
+(8 rows)
+
+-- Empty join relation because of empty outer side, no partitionwise agg plan
+EXPLAIN (COSTS OFF)
+SELECT a.x, a.y, count(*) FROM (SELECT * FROM pagg_tab1 WHERE x = 1 AND x = 2) a LEFT JOIN pagg_tab2 b ON a.x = b.y GROUP BY a.x, a.y ORDER BY 1, 2;
+              QUERY PLAN               
+---------------------------------------
+ GroupAggregate
+   Group Key: pagg_tab1.x, pagg_tab1.y
+   ->  Sort
+         Sort Key: pagg_tab1.y
+         ->  Result
+               One-Time Filter: false
+(6 rows)
+
+SELECT a.x, a.y, count(*) FROM (SELECT * FROM pagg_tab1 WHERE x = 1 AND x = 2) a LEFT JOIN pagg_tab2 b ON a.x = b.y GROUP BY a.x, a.y ORDER BY 1, 2;
+ x | y | count 
+---+---+-------
+(0 rows)
+
+-- Partition by multiple columns
+CREATE TABLE pagg_tab_m (a int, b int, c int) PARTITION BY RANGE(a, ((a+b)/2));
+CREATE TABLE pagg_tab_m_p1 PARTITION OF pagg_tab_m FOR VALUES FROM (0, 0) TO (10, 10);
+CREATE TABLE pagg_tab_m_p2 PARTITION OF pagg_tab_m FOR VALUES FROM (10, 10) TO (20, 20);
+CREATE TABLE pagg_tab_m_p3 PARTITION OF pagg_tab_m FOR VALUES FROM (20, 20) TO (30, 30);
+INSERT INTO pagg_tab_m SELECT i % 30, i % 40, i % 50 FROM generate_series(0, 2999) i;
+ANALYZE pagg_tab_m;
+-- Partial aggregation as GROUP BY clause does not match with PARTITION KEY
+EXPLAIN (COSTS OFF)
+SELECT a, sum(b), avg(c), count(*) FROM pagg_tab_m GROUP BY a HAVING avg(c) < 22 ORDER BY 1, 2, 3;
+                                 QUERY PLAN                                  
+-----------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_m_p1.a, (sum(pagg_tab_m_p1.b)), (avg(pagg_tab_m_p1.c))
+   ->  Finalize HashAggregate
+         Group Key: pagg_tab_m_p1.a
+         Filter: (avg(pagg_tab_m_p1.c) < '22'::numeric)
+         ->  Append
+               ->  Partial HashAggregate
+                     Group Key: pagg_tab_m_p1.a
+                     ->  Seq Scan on pagg_tab_m_p1
+               ->  Partial HashAggregate
+                     Group Key: pagg_tab_m_p2.a
+                     ->  Seq Scan on pagg_tab_m_p2
+               ->  Partial HashAggregate
+                     Group Key: pagg_tab_m_p3.a
+                     ->  Seq Scan on pagg_tab_m_p3
+(15 rows)
+
+SELECT a, sum(b), avg(c), count(*) FROM pagg_tab_m GROUP BY a HAVING avg(c) < 22 ORDER BY 1, 2, 3;
+ a  | sum  |         avg         | count 
+----+------+---------------------+-------
+  0 | 1500 | 20.0000000000000000 |   100
+  1 | 1600 | 21.0000000000000000 |   100
+ 10 | 1500 | 20.0000000000000000 |   100
+ 11 | 1600 | 21.0000000000000000 |   100
+ 20 | 1500 | 20.0000000000000000 |   100
+ 21 | 1600 | 21.0000000000000000 |   100
+(6 rows)
+
+-- Full aggregation as GROUP BY clause matches with PARTITION KEY
+EXPLAIN (COSTS OFF)
+SELECT a, sum(b), avg(c), count(*) FROM pagg_tab_m GROUP BY a, (a+b)/2 HAVING sum(b) < 50 ORDER BY 1, 2, 3;
+                                     QUERY PLAN                                      
+-------------------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_m_p1.a, (sum(pagg_tab_m_p1.b)), (avg(pagg_tab_m_p1.c))
+   ->  Append
+         ->  HashAggregate
+               Group Key: pagg_tab_m_p1.a, ((pagg_tab_m_p1.a + pagg_tab_m_p1.b) / 2)
+               Filter: (sum(pagg_tab_m_p1.b) < 50)
+               ->  Seq Scan on pagg_tab_m_p1
+         ->  HashAggregate
+               Group Key: pagg_tab_m_p2.a, ((pagg_tab_m_p2.a + pagg_tab_m_p2.b) / 2)
+               Filter: (sum(pagg_tab_m_p2.b) < 50)
+               ->  Seq Scan on pagg_tab_m_p2
+         ->  HashAggregate
+               Group Key: pagg_tab_m_p3.a, ((pagg_tab_m_p3.a + pagg_tab_m_p3.b) / 2)
+               Filter: (sum(pagg_tab_m_p3.b) < 50)
+               ->  Seq Scan on pagg_tab_m_p3
+(15 rows)
+
+SELECT a, sum(b), avg(c), count(*) FROM pagg_tab_m GROUP BY a, (a+b)/2 HAVING sum(b) < 50 ORDER BY 1, 2, 3;
+ a  | sum |         avg         | count 
+----+-----+---------------------+-------
+  0 |   0 | 20.0000000000000000 |    25
+  1 |  25 | 21.0000000000000000 |    25
+ 10 |   0 | 20.0000000000000000 |    25
+ 11 |  25 | 21.0000000000000000 |    25
+ 20 |   0 | 20.0000000000000000 |    25
+ 21 |  25 | 21.0000000000000000 |    25
+(6 rows)
+
+-- Full aggregation as PARTITION KEY is part of GROUP BY clause
+EXPLAIN (COSTS OFF)
+SELECT a, c, sum(b), avg(c), count(*) FROM pagg_tab_m GROUP BY (a+b)/2, 2, 1 HAVING sum(b) = 50 AND avg(c) > 25 ORDER BY 1, 2, 3;
+                                              QUERY PLAN                                              
+------------------------------------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_m_p1.a, pagg_tab_m_p1.c, (sum(pagg_tab_m_p1.b))
+   ->  Append
+         ->  HashAggregate
+               Group Key: ((pagg_tab_m_p1.a + pagg_tab_m_p1.b) / 2), pagg_tab_m_p1.c, pagg_tab_m_p1.a
+               Filter: ((sum(pagg_tab_m_p1.b) = 50) AND (avg(pagg_tab_m_p1.c) > '25'::numeric))
+               ->  Seq Scan on pagg_tab_m_p1
+         ->  HashAggregate
+               Group Key: ((pagg_tab_m_p2.a + pagg_tab_m_p2.b) / 2), pagg_tab_m_p2.c, pagg_tab_m_p2.a
+               Filter: ((sum(pagg_tab_m_p2.b) = 50) AND (avg(pagg_tab_m_p2.c) > '25'::numeric))
+               ->  Seq Scan on pagg_tab_m_p2
+         ->  HashAggregate
+               Group Key: ((pagg_tab_m_p3.a + pagg_tab_m_p3.b) / 2), pagg_tab_m_p3.c, pagg_tab_m_p3.a
+               Filter: ((sum(pagg_tab_m_p3.b) = 50) AND (avg(pagg_tab_m_p3.c) > '25'::numeric))
+               ->  Seq Scan on pagg_tab_m_p3
+(15 rows)
+
+SELECT a, c, sum(b), avg(c), count(*) FROM pagg_tab_m GROUP BY (a+b)/2, 2, 1 HAVING sum(b) = 50 AND avg(c) > 25 ORDER BY 1, 2, 3;
+ a  | c  | sum |         avg         | count 
+----+----+-----+---------------------+-------
+  0 | 30 |  50 | 30.0000000000000000 |     5
+  0 | 40 |  50 | 40.0000000000000000 |     5
+ 10 | 30 |  50 | 30.0000000000000000 |     5
+ 10 | 40 |  50 | 40.0000000000000000 |     5
+ 20 | 30 |  50 | 30.0000000000000000 |     5
+ 20 | 40 |  50 | 40.0000000000000000 |     5
+(6 rows)
+
+-- Test with multi-level partitioning scheme
+CREATE TABLE pagg_tab_ml (a int, b int, c text) PARTITION BY RANGE(a);
+CREATE TABLE pagg_tab_ml_p1 PARTITION OF pagg_tab_ml FOR VALUES FROM (0) TO (10);
+CREATE TABLE pagg_tab_ml_p2 PARTITION OF pagg_tab_ml FOR VALUES FROM (10) TO (20) PARTITION BY LIST (c);
+CREATE TABLE pagg_tab_ml_p2_s1 PARTITION OF pagg_tab_ml_p2 FOR VALUES IN ('0000', '0001');
+CREATE TABLE pagg_tab_ml_p2_s2 PARTITION OF pagg_tab_ml_p2 FOR VALUES IN ('0002', '0003');
+-- This level of partitioning has different column positions than the parent
+CREATE TABLE pagg_tab_ml_p3(b int, c text, a int) PARTITION BY RANGE (b);
+CREATE TABLE pagg_tab_ml_p3_s1(c text, a int, b int);
+CREATE TABLE pagg_tab_ml_p3_s2 PARTITION OF pagg_tab_ml_p3 FOR VALUES FROM (5) TO (10);
+ALTER TABLE pagg_tab_ml_p3 ATTACH PARTITION pagg_tab_ml_p3_s1 FOR VALUES FROM (0) TO (5);
+ALTER TABLE pagg_tab_ml ATTACH PARTITION pagg_tab_ml_p3 FOR VALUES FROM (20) TO (30);
+INSERT INTO pagg_tab_ml SELECT i % 30, i % 10, to_char(i % 4, 'FM0000') FROM generate_series(0, 29999) i;
+ANALYZE pagg_tab_ml;
+-- For Parallel Append
+SET max_parallel_workers_per_gather TO 2;
+-- Full aggregation at level 1 as GROUP BY clause matches with PARTITION KEY
+-- for level 1 only. For subpartitions, GROUP BY clause does not match with
+-- PARTITION KEY, but still we do not see a partial aggregation as array_agg()
+-- is not partial agg safe.
+EXPLAIN (COSTS OFF)
+SELECT a, sum(b), array_agg(distinct c), count(*) FROM pagg_tab_ml GROUP BY a HAVING avg(b) < 3 ORDER BY 1, 2, 3;
+                                          QUERY PLAN                                           
+-----------------------------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_ml_p1.a, (sum(pagg_tab_ml_p1.b)), (array_agg(DISTINCT pagg_tab_ml_p1.c))
+   ->  Append
+         ->  GroupAggregate
+               Group Key: pagg_tab_ml_p1.a
+               Filter: (avg(pagg_tab_ml_p1.b) < '3'::numeric)
+               ->  Sort
+                     Sort Key: pagg_tab_ml_p1.a
+                     ->  Seq Scan on pagg_tab_ml_p1
+         ->  GroupAggregate
+               Group Key: pagg_tab_ml_p2_s1.a
+               Filter: (avg(pagg_tab_ml_p2_s1.b) < '3'::numeric)
+               ->  Sort
+                     Sort Key: pagg_tab_ml_p2_s1.a
+                     ->  Append
+                           ->  Seq Scan on pagg_tab_ml_p2_s1
+                           ->  Seq Scan on pagg_tab_ml_p2_s2
+         ->  GroupAggregate
+               Group Key: pagg_tab_ml_p3_s1.a
+               Filter: (avg(pagg_tab_ml_p3_s1.b) < '3'::numeric)
+               ->  Sort
+                     Sort Key: pagg_tab_ml_p3_s1.a
+                     ->  Append
+                           ->  Seq Scan on pagg_tab_ml_p3_s1
+                           ->  Seq Scan on pagg_tab_ml_p3_s2
+(25 rows)
+
+SELECT a, sum(b), array_agg(distinct c), count(*) FROM pagg_tab_ml GROUP BY a HAVING avg(b) < 3 ORDER BY 1, 2, 3;
+ a  | sum  |  array_agg  | count 
+----+------+-------------+-------
+  0 |    0 | {0000,0002} |  1000
+  1 | 1000 | {0001,0003} |  1000
+  2 | 2000 | {0000,0002} |  1000
+ 10 |    0 | {0000,0002} |  1000
+ 11 | 1000 | {0001,0003} |  1000
+ 12 | 2000 | {0000,0002} |  1000
+ 20 |    0 | {0000,0002} |  1000
+ 21 | 1000 | {0001,0003} |  1000
+ 22 | 2000 | {0000,0002} |  1000
+(9 rows)
+
+-- Without ORDER BY clause, to test Gather at top-most path
+EXPLAIN (COSTS OFF)
+SELECT a, sum(b), array_agg(distinct c), count(*) FROM pagg_tab_ml GROUP BY a HAVING avg(b) < 3;
+                        QUERY PLAN                         
+-----------------------------------------------------------
+ Append
+   ->  GroupAggregate
+         Group Key: pagg_tab_ml_p1.a
+         Filter: (avg(pagg_tab_ml_p1.b) < '3'::numeric)
+         ->  Sort
+               Sort Key: pagg_tab_ml_p1.a
+               ->  Seq Scan on pagg_tab_ml_p1
+   ->  GroupAggregate
+         Group Key: pagg_tab_ml_p2_s1.a
+         Filter: (avg(pagg_tab_ml_p2_s1.b) < '3'::numeric)
+         ->  Sort
+               Sort Key: pagg_tab_ml_p2_s1.a
+               ->  Append
+                     ->  Seq Scan on pagg_tab_ml_p2_s1
+                     ->  Seq Scan on pagg_tab_ml_p2_s2
+   ->  GroupAggregate
+         Group Key: pagg_tab_ml_p3_s1.a
+         Filter: (avg(pagg_tab_ml_p3_s1.b) < '3'::numeric)
+         ->  Sort
+               Sort Key: pagg_tab_ml_p3_s1.a
+               ->  Append
+                     ->  Seq Scan on pagg_tab_ml_p3_s1
+                     ->  Seq Scan on pagg_tab_ml_p3_s2
+(23 rows)
+
+-- Full aggregation at level 1 as GROUP BY clause matches with PARTITION KEY
+-- for level 1 only. For subpartitions, GROUP BY clause does not match with
+-- PARTITION KEY, thus we will have a partial aggregation for them.
+EXPLAIN (COSTS OFF)
+SELECT a, sum(b), count(*) FROM pagg_tab_ml GROUP BY a HAVING avg(b) < 3 ORDER BY 1, 2, 3;
+                            QUERY PLAN                             
+-------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_ml_p1.a, (sum(pagg_tab_ml_p1.b)), (count(*))
+   ->  Append
+         ->  HashAggregate
+               Group Key: pagg_tab_ml_p1.a
+               Filter: (avg(pagg_tab_ml_p1.b) < '3'::numeric)
+               ->  Seq Scan on pagg_tab_ml_p1
+         ->  Finalize GroupAggregate
+               Group Key: pagg_tab_ml_p2_s1.a
+               Filter: (avg(pagg_tab_ml_p2_s1.b) < '3'::numeric)
+               ->  Sort
+                     Sort Key: pagg_tab_ml_p2_s1.a
+                     ->  Append
+                           ->  Partial HashAggregate
+                                 Group Key: pagg_tab_ml_p2_s1.a
+                                 ->  Seq Scan on pagg_tab_ml_p2_s1
+                           ->  Partial HashAggregate
+                                 Group Key: pagg_tab_ml_p2_s2.a
+                                 ->  Seq Scan on pagg_tab_ml_p2_s2
+         ->  Finalize GroupAggregate
+               Group Key: pagg_tab_ml_p3_s1.a
+               Filter: (avg(pagg_tab_ml_p3_s1.b) < '3'::numeric)
+               ->  Sort
+                     Sort Key: pagg_tab_ml_p3_s1.a
+                     ->  Append
+                           ->  Partial HashAggregate
+                                 Group Key: pagg_tab_ml_p3_s1.a
+                                 ->  Seq Scan on pagg_tab_ml_p3_s1
+                           ->  Partial HashAggregate
+                                 Group Key: pagg_tab_ml_p3_s2.a
+                                 ->  Seq Scan on pagg_tab_ml_p3_s2
+(31 rows)
+
+SELECT a, sum(b), count(*) FROM pagg_tab_ml GROUP BY a HAVING avg(b) < 3 ORDER BY 1, 2, 3;
+ a  | sum  | count 
+----+------+-------
+  0 |    0 |  1000
+  1 | 1000 |  1000
+  2 | 2000 |  1000
+ 10 |    0 |  1000
+ 11 | 1000 |  1000
+ 12 | 2000 |  1000
+ 20 |    0 |  1000
+ 21 | 1000 |  1000
+ 22 | 2000 |  1000
+(9 rows)
+
+-- Partial aggregation at all levels as GROUP BY clause does not match with
+-- PARTITION KEY
+EXPLAIN (COSTS OFF)
+SELECT b, sum(a), count(*) FROM pagg_tab_ml GROUP BY b ORDER BY 1, 2, 3;
+                            QUERY PLAN                             
+-------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_ml_p1.b, (sum(pagg_tab_ml_p1.a)), (count(*))
+   ->  Finalize GroupAggregate
+         Group Key: pagg_tab_ml_p1.b
+         ->  Sort
+               Sort Key: pagg_tab_ml_p1.b
+               ->  Append
+                     ->  Partial HashAggregate
+                           Group Key: pagg_tab_ml_p1.b
+                           ->  Seq Scan on pagg_tab_ml_p1
+                     ->  Partial HashAggregate
+                           Group Key: pagg_tab_ml_p2_s1.b
+                           ->  Seq Scan on pagg_tab_ml_p2_s1
+                     ->  Partial HashAggregate
+                           Group Key: pagg_tab_ml_p2_s2.b
+                           ->  Seq Scan on pagg_tab_ml_p2_s2
+                     ->  Partial HashAggregate
+                           Group Key: pagg_tab_ml_p3_s1.b
+                           ->  Seq Scan on pagg_tab_ml_p3_s1
+                     ->  Partial HashAggregate
+                           Group Key: pagg_tab_ml_p3_s2.b
+                           ->  Seq Scan on pagg_tab_ml_p3_s2
+(22 rows)
+
+SELECT b, sum(a), count(*) FROM pagg_tab_ml GROUP BY b HAVING avg(a) < 15 ORDER BY 1, 2, 3;
+ b |  sum  | count 
+---+-------+-------
+ 0 | 30000 |  3000
+ 1 | 33000 |  3000
+ 2 | 36000 |  3000
+ 3 | 39000 |  3000
+ 4 | 42000 |  3000
+(5 rows)
+
+-- Full aggregation at all levels as GROUP BY clause matches with PARTITION KEY
+EXPLAIN (COSTS OFF)
+SELECT a, sum(b), count(*) FROM pagg_tab_ml GROUP BY a, b, c HAVING avg(b) > 7 ORDER BY 1, 2, 3;
+                                       QUERY PLAN                                       
+----------------------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_ml_p1.a, (sum(pagg_tab_ml_p1.b)), (count(*))
+   ->  Append
+         ->  HashAggregate
+               Group Key: pagg_tab_ml_p1.a, pagg_tab_ml_p1.b, pagg_tab_ml_p1.c
+               Filter: (avg(pagg_tab_ml_p1.b) > '7'::numeric)
+               ->  Seq Scan on pagg_tab_ml_p1
+         ->  HashAggregate
+               Group Key: pagg_tab_ml_p2_s1.a, pagg_tab_ml_p2_s1.b, pagg_tab_ml_p2_s1.c
+               Filter: (avg(pagg_tab_ml_p2_s1.b) > '7'::numeric)
+               ->  Seq Scan on pagg_tab_ml_p2_s1
+         ->  HashAggregate
+               Group Key: pagg_tab_ml_p2_s2.a, pagg_tab_ml_p2_s2.b, pagg_tab_ml_p2_s2.c
+               Filter: (avg(pagg_tab_ml_p2_s2.b) > '7'::numeric)
+               ->  Seq Scan on pagg_tab_ml_p2_s2
+         ->  HashAggregate
+               Group Key: pagg_tab_ml_p3_s1.a, pagg_tab_ml_p3_s1.b, pagg_tab_ml_p3_s1.c
+               Filter: (avg(pagg_tab_ml_p3_s1.b) > '7'::numeric)
+               ->  Seq Scan on pagg_tab_ml_p3_s1
+         ->  HashAggregate
+               Group Key: pagg_tab_ml_p3_s2.a, pagg_tab_ml_p3_s2.b, pagg_tab_ml_p3_s2.c
+               Filter: (avg(pagg_tab_ml_p3_s2.b) > '7'::numeric)
+               ->  Seq Scan on pagg_tab_ml_p3_s2
+(23 rows)
+
+SELECT a, sum(b), count(*) FROM pagg_tab_ml GROUP BY a, b, c HAVING avg(b) > 7 ORDER BY 1, 2, 3;
+ a  | sum  | count 
+----+------+-------
+  8 | 4000 |   500
+  8 | 4000 |   500
+  9 | 4500 |   500
+  9 | 4500 |   500
+ 18 | 4000 |   500
+ 18 | 4000 |   500
+ 19 | 4500 |   500
+ 19 | 4500 |   500
+ 28 | 4000 |   500
+ 28 | 4000 |   500
+ 29 | 4500 |   500
+ 29 | 4500 |   500
+(12 rows)
+
+-- Parallelism within partitionwise aggregates
+SET min_parallel_table_scan_size TO '8kB';
+SET parallel_setup_cost TO 0;
+-- Full aggregation at level 1 as GROUP BY clause matches with PARTITION KEY
+-- for level 1 only. For subpartitions, GROUP BY clause does not match with
+-- PARTITION KEY, thus we will have a partial aggregation for them.
+EXPLAIN (COSTS OFF)
+SELECT a, sum(b), count(*) FROM pagg_tab_ml GROUP BY a HAVING avg(b) < 3 ORDER BY 1, 2, 3;
+                                    QUERY PLAN                                    
+----------------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_ml_p1.a, (sum(pagg_tab_ml_p1.b)), (count(*))
+   ->  Append
+         ->  Finalize GroupAggregate
+               Group Key: pagg_tab_ml_p1.a
+               Filter: (avg(pagg_tab_ml_p1.b) < '3'::numeric)
+               ->  Gather Merge
+                     Workers Planned: 2
+                     ->  Sort
+                           Sort Key: pagg_tab_ml_p1.a
+                           ->  Partial HashAggregate
+                                 Group Key: pagg_tab_ml_p1.a
+                                 ->  Parallel Seq Scan on pagg_tab_ml_p1
+         ->  Finalize GroupAggregate
+               Group Key: pagg_tab_ml_p2_s1.a
+               Filter: (avg(pagg_tab_ml_p2_s1.b) < '3'::numeric)
+               ->  Gather Merge
+                     Workers Planned: 2
+                     ->  Sort
+                           Sort Key: pagg_tab_ml_p2_s1.a
+                           ->  Parallel Append
+                                 ->  Partial HashAggregate
+                                       Group Key: pagg_tab_ml_p2_s1.a
+                                       ->  Parallel Seq Scan on pagg_tab_ml_p2_s1
+                                 ->  Partial HashAggregate
+                                       Group Key: pagg_tab_ml_p2_s2.a
+                                       ->  Parallel Seq Scan on pagg_tab_ml_p2_s2
+         ->  Finalize GroupAggregate
+               Group Key: pagg_tab_ml_p3_s1.a
+               Filter: (avg(pagg_tab_ml_p3_s1.b) < '3'::numeric)
+               ->  Gather Merge
+                     Workers Planned: 2
+                     ->  Sort
+                           Sort Key: pagg_tab_ml_p3_s1.a
+                           ->  Parallel Append
+                                 ->  Partial HashAggregate
+                                       Group Key: pagg_tab_ml_p3_s1.a
+                                       ->  Parallel Seq Scan on pagg_tab_ml_p3_s1
+                                 ->  Partial HashAggregate
+                                       Group Key: pagg_tab_ml_p3_s2.a
+                                       ->  Parallel Seq Scan on pagg_tab_ml_p3_s2
+(41 rows)
+
+SELECT a, sum(b), count(*) FROM pagg_tab_ml GROUP BY a HAVING avg(b) < 3 ORDER BY 1, 2, 3;
+ a  | sum  | count 
+----+------+-------
+  0 |    0 |  1000
+  1 | 1000 |  1000
+  2 | 2000 |  1000
+ 10 |    0 |  1000
+ 11 | 1000 |  1000
+ 12 | 2000 |  1000
+ 20 |    0 |  1000
+ 21 | 1000 |  1000
+ 22 | 2000 |  1000
+(9 rows)
+
+-- Partial aggregation at all levels as GROUP BY clause does not match with
+-- PARTITION KEY
+EXPLAIN (COSTS OFF)
+SELECT b, sum(a), count(*) FROM pagg_tab_ml GROUP BY b ORDER BY 1, 2, 3;
+                                 QUERY PLAN                                 
+----------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_ml_p1.b, (sum(pagg_tab_ml_p1.a)), (count(*))
+   ->  Finalize GroupAggregate
+         Group Key: pagg_tab_ml_p1.b
+         ->  Gather Merge
+               Workers Planned: 2
+               ->  Sort
+                     Sort Key: pagg_tab_ml_p1.b
+                     ->  Parallel Append
+                           ->  Partial HashAggregate
+                                 Group Key: pagg_tab_ml_p1.b
+                                 ->  Parallel Seq Scan on pagg_tab_ml_p1
+                           ->  Partial HashAggregate
+                                 Group Key: pagg_tab_ml_p2_s1.b
+                                 ->  Parallel Seq Scan on pagg_tab_ml_p2_s1
+                           ->  Partial HashAggregate
+                                 Group Key: pagg_tab_ml_p2_s2.b
+                                 ->  Parallel Seq Scan on pagg_tab_ml_p2_s2
+                           ->  Partial HashAggregate
+                                 Group Key: pagg_tab_ml_p3_s1.b
+                                 ->  Parallel Seq Scan on pagg_tab_ml_p3_s1
+                           ->  Partial HashAggregate
+                                 Group Key: pagg_tab_ml_p3_s2.b
+                                 ->  Parallel Seq Scan on pagg_tab_ml_p3_s2
+(24 rows)
+
+SELECT b, sum(a), count(*) FROM pagg_tab_ml GROUP BY b HAVING avg(a) < 15 ORDER BY 1, 2, 3;
+ b |  sum  | count 
+---+-------+-------
+ 0 | 30000 |  3000
+ 1 | 33000 |  3000
+ 2 | 36000 |  3000
+ 3 | 39000 |  3000
+ 4 | 42000 |  3000
+(5 rows)
+
+-- Full aggregation at all levels as GROUP BY clause matches with PARTITION KEY
+EXPLAIN (COSTS OFF)
+SELECT a, sum(b), count(*) FROM pagg_tab_ml GROUP BY a, b, c HAVING avg(b) > 7 ORDER BY 1, 2, 3;
+                                          QUERY PLAN                                          
+----------------------------------------------------------------------------------------------
+ Gather Merge
+   Workers Planned: 2
+   ->  Sort
+         Sort Key: pagg_tab_ml_p1.a, (sum(pagg_tab_ml_p1.b)), (count(*))
+         ->  Parallel Append
+               ->  HashAggregate
+                     Group Key: pagg_tab_ml_p1.a, pagg_tab_ml_p1.b, pagg_tab_ml_p1.c
+                     Filter: (avg(pagg_tab_ml_p1.b) > '7'::numeric)
+                     ->  Seq Scan on pagg_tab_ml_p1
+               ->  HashAggregate
+                     Group Key: pagg_tab_ml_p2_s1.a, pagg_tab_ml_p2_s1.b, pagg_tab_ml_p2_s1.c
+                     Filter: (avg(pagg_tab_ml_p2_s1.b) > '7'::numeric)
+                     ->  Seq Scan on pagg_tab_ml_p2_s1
+               ->  HashAggregate
+                     Group Key: pagg_tab_ml_p2_s2.a, pagg_tab_ml_p2_s2.b, pagg_tab_ml_p2_s2.c
+                     Filter: (avg(pagg_tab_ml_p2_s2.b) > '7'::numeric)
+                     ->  Seq Scan on pagg_tab_ml_p2_s2
+               ->  HashAggregate
+                     Group Key: pagg_tab_ml_p3_s1.a, pagg_tab_ml_p3_s1.b, pagg_tab_ml_p3_s1.c
+                     Filter: (avg(pagg_tab_ml_p3_s1.b) > '7'::numeric)
+                     ->  Seq Scan on pagg_tab_ml_p3_s1
+               ->  HashAggregate
+                     Group Key: pagg_tab_ml_p3_s2.a, pagg_tab_ml_p3_s2.b, pagg_tab_ml_p3_s2.c
+                     Filter: (avg(pagg_tab_ml_p3_s2.b) > '7'::numeric)
+                     ->  Seq Scan on pagg_tab_ml_p3_s2
+(25 rows)
+
+SELECT a, sum(b), count(*) FROM pagg_tab_ml GROUP BY a, b, c HAVING avg(b) > 7 ORDER BY 1, 2, 3;
+ a  | sum  | count 
+----+------+-------
+  8 | 4000 |   500
+  8 | 4000 |   500
+  9 | 4500 |   500
+  9 | 4500 |   500
+ 18 | 4000 |   500
+ 18 | 4000 |   500
+ 19 | 4500 |   500
+ 19 | 4500 |   500
+ 28 | 4000 |   500
+ 28 | 4000 |   500
+ 29 | 4500 |   500
+ 29 | 4500 |   500
+(12 rows)
+
+-- Parallelism within partitionwise aggregates (single level)
+-- Add few parallel setup cost, so that we will see a plan which gathers
+-- partially created paths even for full aggregation and sticks a single Gather
+-- followed by finalization step.
+-- Without this, the cost of doing partial aggregation + Gather + finalization
+-- for each partition and then Append over it turns out to be same and this
+-- wins as we add it first. This parallel_setup_cost plays a vital role in
+-- costing such plans.
+SET parallel_setup_cost TO 10;
+CREATE TABLE pagg_tab_para(x int, y int) PARTITION BY RANGE(x);
+CREATE TABLE pagg_tab_para_p1 PARTITION OF pagg_tab_para FOR VALUES FROM (0) TO (10);
+CREATE TABLE pagg_tab_para_p2 PARTITION OF pagg_tab_para FOR VALUES FROM (10) TO (20);
+CREATE TABLE pagg_tab_para_p3 PARTITION OF pagg_tab_para FOR VALUES FROM (20) TO (30);
+INSERT INTO pagg_tab_para SELECT i % 30, i % 20 FROM generate_series(0, 29999) i;
+ANALYZE pagg_tab_para;
+-- When GROUP BY clause matches; full aggregation is performed for each partition.
+EXPLAIN (COSTS OFF)
+SELECT x, sum(y), avg(y), count(*) FROM pagg_tab_para GROUP BY x HAVING avg(y) < 7 ORDER BY 1, 2, 3;
+                                      QUERY PLAN                                      
+--------------------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_para_p1.x, (sum(pagg_tab_para_p1.y)), (avg(pagg_tab_para_p1.y))
+   ->  Finalize GroupAggregate
+         Group Key: pagg_tab_para_p1.x
+         Filter: (avg(pagg_tab_para_p1.y) < '7'::numeric)
+         ->  Gather Merge
+               Workers Planned: 2
+               ->  Sort
+                     Sort Key: pagg_tab_para_p1.x
+                     ->  Parallel Append
+                           ->  Partial HashAggregate
+                                 Group Key: pagg_tab_para_p1.x
+                                 ->  Parallel Seq Scan on pagg_tab_para_p1
+                           ->  Partial HashAggregate
+                                 Group Key: pagg_tab_para_p2.x
+                                 ->  Parallel Seq Scan on pagg_tab_para_p2
+                           ->  Partial HashAggregate
+                                 Group Key: pagg_tab_para_p3.x
+                                 ->  Parallel Seq Scan on pagg_tab_para_p3
+(19 rows)
+
+SELECT x, sum(y), avg(y), count(*) FROM pagg_tab_para GROUP BY x HAVING avg(y) < 7 ORDER BY 1, 2, 3;
+ x  | sum  |        avg         | count 
+----+------+--------------------+-------
+  0 | 5000 | 5.0000000000000000 |  1000
+  1 | 6000 | 6.0000000000000000 |  1000
+ 10 | 5000 | 5.0000000000000000 |  1000
+ 11 | 6000 | 6.0000000000000000 |  1000
+ 20 | 5000 | 5.0000000000000000 |  1000
+ 21 | 6000 | 6.0000000000000000 |  1000
+(6 rows)
+
+-- When GROUP BY clause does not match; partial aggregation is performed for each partition.
+EXPLAIN (COSTS OFF)
+SELECT y, sum(x), avg(x), count(*) FROM pagg_tab_para GROUP BY y HAVING avg(x) < 12 ORDER BY 1, 2, 3;
+                                      QUERY PLAN                                      
+--------------------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_para_p1.y, (sum(pagg_tab_para_p1.x)), (avg(pagg_tab_para_p1.x))
+   ->  Finalize HashAggregate
+         Group Key: pagg_tab_para_p1.y
+         Filter: (avg(pagg_tab_para_p1.x) < '12'::numeric)
+         ->  Gather
+               Workers Planned: 2
+               ->  Parallel Append
+                     ->  Partial HashAggregate
+                           Group Key: pagg_tab_para_p1.y
+                           ->  Parallel Seq Scan on pagg_tab_para_p1
+                     ->  Partial HashAggregate
+                           Group Key: pagg_tab_para_p2.y
+                           ->  Parallel Seq Scan on pagg_tab_para_p2
+                     ->  Partial HashAggregate
+                           Group Key: pagg_tab_para_p3.y
+                           ->  Parallel Seq Scan on pagg_tab_para_p3
+(17 rows)
+
+SELECT y, sum(x), avg(x), count(*) FROM pagg_tab_para GROUP BY y HAVING avg(x) < 12 ORDER BY 1, 2, 3;
+ y  |  sum  |         avg         | count 
+----+-------+---------------------+-------
+  0 | 15000 | 10.0000000000000000 |  1500
+  1 | 16500 | 11.0000000000000000 |  1500
+ 10 | 15000 | 10.0000000000000000 |  1500
+ 11 | 16500 | 11.0000000000000000 |  1500
+(4 rows)
+
+-- Test when parent can produce parallel paths but not any (or some) of its children
+ALTER TABLE pagg_tab_para_p1 SET (parallel_workers = 0);
+ALTER TABLE pagg_tab_para_p3 SET (parallel_workers = 0);
+ANALYZE pagg_tab_para;
+EXPLAIN (COSTS OFF)
+SELECT x, sum(y), avg(y), count(*) FROM pagg_tab_para GROUP BY x HAVING avg(y) < 7 ORDER BY 1, 2, 3;
+                                      QUERY PLAN                                      
+--------------------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_para_p1.x, (sum(pagg_tab_para_p1.y)), (avg(pagg_tab_para_p1.y))
+   ->  Finalize GroupAggregate
+         Group Key: pagg_tab_para_p1.x
+         Filter: (avg(pagg_tab_para_p1.y) < '7'::numeric)
+         ->  Gather Merge
+               Workers Planned: 2
+               ->  Sort
+                     Sort Key: pagg_tab_para_p1.x
+                     ->  Partial HashAggregate
+                           Group Key: pagg_tab_para_p1.x
+                           ->  Parallel Append
+                                 ->  Seq Scan on pagg_tab_para_p1
+                                 ->  Seq Scan on pagg_tab_para_p3
+                                 ->  Parallel Seq Scan on pagg_tab_para_p2
+(15 rows)
+
+SELECT x, sum(y), avg(y), count(*) FROM pagg_tab_para GROUP BY x HAVING avg(y) < 7 ORDER BY 1, 2, 3;
+ x  | sum  |        avg         | count 
+----+------+--------------------+-------
+  0 | 5000 | 5.0000000000000000 |  1000
+  1 | 6000 | 6.0000000000000000 |  1000
+ 10 | 5000 | 5.0000000000000000 |  1000
+ 11 | 6000 | 6.0000000000000000 |  1000
+ 20 | 5000 | 5.0000000000000000 |  1000
+ 21 | 6000 | 6.0000000000000000 |  1000
+(6 rows)
+
+ALTER TABLE pagg_tab_para_p2 SET (parallel_workers = 0);
+ANALYZE pagg_tab_para;
+EXPLAIN (COSTS OFF)
+SELECT x, sum(y), avg(y), count(*) FROM pagg_tab_para GROUP BY x HAVING avg(y) < 7 ORDER BY 1, 2, 3;
+                                      QUERY PLAN                                      
+--------------------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_para_p1.x, (sum(pagg_tab_para_p1.y)), (avg(pagg_tab_para_p1.y))
+   ->  Finalize GroupAggregate
+         Group Key: pagg_tab_para_p1.x
+         Filter: (avg(pagg_tab_para_p1.y) < '7'::numeric)
+         ->  Gather Merge
+               Workers Planned: 2
+               ->  Sort
+                     Sort Key: pagg_tab_para_p1.x
+                     ->  Partial HashAggregate
+                           Group Key: pagg_tab_para_p1.x
+                           ->  Parallel Append
+                                 ->  Seq Scan on pagg_tab_para_p1
+                                 ->  Seq Scan on pagg_tab_para_p2
+                                 ->  Seq Scan on pagg_tab_para_p3
+(15 rows)
+
+SELECT x, sum(y), avg(y), count(*) FROM pagg_tab_para GROUP BY x HAVING avg(y) < 7 ORDER BY 1, 2, 3;
+ x  | sum  |        avg         | count 
+----+------+--------------------+-------
+  0 | 5000 | 5.0000000000000000 |  1000
+  1 | 6000 | 6.0000000000000000 |  1000
+ 10 | 5000 | 5.0000000000000000 |  1000
+ 11 | 6000 | 6.0000000000000000 |  1000
+ 20 | 5000 | 5.0000000000000000 |  1000
+ 21 | 6000 | 6.0000000000000000 |  1000
+(6 rows)
+
+-- Reset parallelism parameters to get partitionwise aggregation plan.
+RESET min_parallel_table_scan_size;
+RESET parallel_setup_cost;
+EXPLAIN (COSTS OFF)
+SELECT x, sum(y), avg(y), count(*) FROM pagg_tab_para GROUP BY x HAVING avg(y) < 7 ORDER BY 1, 2, 3;
+                                      QUERY PLAN                                      
+--------------------------------------------------------------------------------------
+ Sort
+   Sort Key: pagg_tab_para_p1.x, (sum(pagg_tab_para_p1.y)), (avg(pagg_tab_para_p1.y))
+   ->  Append
+         ->  HashAggregate
+               Group Key: pagg_tab_para_p1.x
+               Filter: (avg(pagg_tab_para_p1.y) < '7'::numeric)
+               ->  Seq Scan on pagg_tab_para_p1
+         ->  HashAggregate
+               Group Key: pagg_tab_para_p2.x
+               Filter: (avg(pagg_tab_para_p2.y) < '7'::numeric)
+               ->  Seq Scan on pagg_tab_para_p2
+         ->  HashAggregate
+               Group Key: pagg_tab_para_p3.x
+               Filter: (avg(pagg_tab_para_p3.y) < '7'::numeric)
+               ->  Seq Scan on pagg_tab_para_p3
+(15 rows)
+
+SELECT x, sum(y), avg(y), count(*) FROM pagg_tab_para GROUP BY x HAVING avg(y) < 7 ORDER BY 1, 2, 3;
+ x  | sum  |        avg         | count 
+----+------+--------------------+-------
+  0 | 5000 | 5.0000000000000000 |  1000
+  1 | 6000 | 6.0000000000000000 |  1000
+ 10 | 5000 | 5.0000000000000000 |  1000
+ 11 | 6000 | 6.0000000000000000 |  1000
+ 20 | 5000 | 5.0000000000000000 |  1000
+ 21 | 6000 | 6.0000000000000000 |  1000
+(6 rows)
+
diff --git a/src/test/regress/expected/partition_join_1.out b/src/test/regress/expected/partition_join_1.out
new file mode 100644
index 0000000..e2e31d7
--- /dev/null
+++ b/src/test/regress/expected/partition_join_1.out
@@ -0,0 +1,2005 @@
+--
+-- PARTITION_JOIN
+-- Test partitionwise join between partitioned tables
+--
+-- Enable partitionwise join, which by default is disabled.
+SET enable_partitionwise_join to true;
+--
+-- partitioned by a single column
+--
+CREATE TABLE prt1 (a int, b int, c varchar) PARTITION BY RANGE(a);
+CREATE TABLE prt1_p1 PARTITION OF prt1 FOR VALUES FROM (0) TO (250);
+CREATE TABLE prt1_p3 PARTITION OF prt1 FOR VALUES FROM (500) TO (600);
+CREATE TABLE prt1_p2 PARTITION OF prt1 FOR VALUES FROM (250) TO (500);
+INSERT INTO prt1 SELECT i, i % 25, to_char(i, 'FM0000') FROM generate_series(0, 599) i WHERE i % 2 = 0;
+CREATE INDEX iprt1_p1_a on prt1_p1(a);
+CREATE INDEX iprt1_p2_a on prt1_p2(a);
+CREATE INDEX iprt1_p3_a on prt1_p3(a);
+ANALYZE prt1;
+CREATE TABLE prt2 (a int, b int, c varchar) PARTITION BY RANGE(b);
+CREATE TABLE prt2_p1 PARTITION OF prt2 FOR VALUES FROM (0) TO (250);
+CREATE TABLE prt2_p2 PARTITION OF prt2 FOR VALUES FROM (250) TO (500);
+CREATE TABLE prt2_p3 PARTITION OF prt2 FOR VALUES FROM (500) TO (600);
+INSERT INTO prt2 SELECT i % 25, i, to_char(i, 'FM0000') FROM generate_series(0, 599) i WHERE i % 3 = 0;
+CREATE INDEX iprt2_p1_b on prt2_p1(b);
+CREATE INDEX iprt2_p2_b on prt2_p2(b);
+CREATE INDEX iprt2_p3_b on prt2_p3(b);
+ANALYZE prt2;
+-- inner join
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1 t1, prt2 t2 WHERE t1.a = t2.b AND t1.b = 0 ORDER BY t1.a, t2.b;
+                    QUERY PLAN                    
+--------------------------------------------------
+ Sort
+   Sort Key: t1.a
+   ->  Append
+         ->  Hash Join
+               Hash Cond: (t2.b = t1.a)
+               ->  Seq Scan on prt2_p1 t2
+               ->  Hash
+                     ->  Seq Scan on prt1_p1 t1
+                           Filter: (b = 0)
+         ->  Hash Join
+               Hash Cond: (t2_1.b = t1_1.a)
+               ->  Seq Scan on prt2_p2 t2_1
+               ->  Hash
+                     ->  Seq Scan on prt1_p2 t1_1
+                           Filter: (b = 0)
+         ->  Hash Join
+               Hash Cond: (t2_2.b = t1_2.a)
+               ->  Seq Scan on prt2_p3 t2_2
+               ->  Hash
+                     ->  Seq Scan on prt1_p3 t1_2
+                           Filter: (b = 0)
+(21 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1 t1, prt2 t2 WHERE t1.a = t2.b AND t1.b = 0 ORDER BY t1.a, t2.b;
+  a  |  c   |  b  |  c   
+-----+------+-----+------
+   0 | 0000 |   0 | 0000
+ 150 | 0150 | 150 | 0150
+ 300 | 0300 | 300 | 0300
+ 450 | 0450 | 450 | 0450
+(4 rows)
+
+-- left outer join, with whole-row reference; partitionwise join does not apply
+EXPLAIN (COSTS OFF)
+SELECT t1, t2 FROM prt1 t1 LEFT JOIN prt2 t2 ON t1.a = t2.b WHERE t1.b = 0 ORDER BY t1.a, t2.b;
+                    QUERY PLAN                    
+--------------------------------------------------
+ Sort
+   Sort Key: t1.a, t2.b
+   ->  Hash Right Join
+         Hash Cond: (t2.b = t1.a)
+         ->  Append
+               ->  Seq Scan on prt2_p1 t2
+               ->  Seq Scan on prt2_p2 t2_1
+               ->  Seq Scan on prt2_p3 t2_2
+         ->  Hash
+               ->  Append
+                     ->  Seq Scan on prt1_p1 t1
+                           Filter: (b = 0)
+                     ->  Seq Scan on prt1_p2 t1_1
+                           Filter: (b = 0)
+                     ->  Seq Scan on prt1_p3 t1_2
+                           Filter: (b = 0)
+(16 rows)
+
+SELECT t1, t2 FROM prt1 t1 LEFT JOIN prt2 t2 ON t1.a = t2.b WHERE t1.b = 0 ORDER BY t1.a, t2.b;
+      t1      |      t2      
+--------------+--------------
+ (0,0,0000)   | (0,0,0000)
+ (50,0,0050)  | 
+ (100,0,0100) | 
+ (150,0,0150) | (0,150,0150)
+ (200,0,0200) | 
+ (250,0,0250) | 
+ (300,0,0300) | (0,300,0300)
+ (350,0,0350) | 
+ (400,0,0400) | 
+ (450,0,0450) | (0,450,0450)
+ (500,0,0500) | 
+ (550,0,0550) | 
+(12 rows)
+
+-- right outer join
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1 t1 RIGHT JOIN prt2 t2 ON t1.a = t2.b WHERE t2.a = 0 ORDER BY t1.a, t2.b;
+                          QUERY PLAN                           
+---------------------------------------------------------------
+ Sort
+   Sort Key: t1.a, t2.b
+   ->  Append
+         ->  Hash Right Join
+               Hash Cond: (t1.a = t2.b)
+               ->  Seq Scan on prt1_p1 t1
+               ->  Hash
+                     ->  Seq Scan on prt2_p1 t2
+                           Filter: (a = 0)
+         ->  Hash Right Join
+               Hash Cond: (t1_1.a = t2_1.b)
+               ->  Seq Scan on prt1_p2 t1_1
+               ->  Hash
+                     ->  Seq Scan on prt2_p2 t2_1
+                           Filter: (a = 0)
+         ->  Nested Loop Left Join
+               ->  Seq Scan on prt2_p3 t2_2
+                     Filter: (a = 0)
+               ->  Index Scan using iprt1_p3_a on prt1_p3 t1_2
+                     Index Cond: (a = t2_2.b)
+(20 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1 t1 RIGHT JOIN prt2 t2 ON t1.a = t2.b WHERE t2.a = 0 ORDER BY t1.a, t2.b;
+  a  |  c   |  b  |  c   
+-----+------+-----+------
+   0 | 0000 |   0 | 0000
+ 150 | 0150 | 150 | 0150
+ 300 | 0300 | 300 | 0300
+ 450 | 0450 | 450 | 0450
+     |      |  75 | 0075
+     |      | 225 | 0225
+     |      | 375 | 0375
+     |      | 525 | 0525
+(8 rows)
+
+-- full outer join, with placeholder vars
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT 50 phv, * FROM prt1 WHERE prt1.b = 0) t1 FULL JOIN (SELECT 75 phv, * FROM prt2 WHERE prt2.a = 0) t2 ON (t1.a = t2.b) WHERE t1.phv = t1.a OR t2.phv = t2.b ORDER BY t1.a, t2.b;
+                            QUERY PLAN                            
+------------------------------------------------------------------
+ Sort
+   Sort Key: prt1_p1.a, prt2_p1.b
+   ->  Append
+         ->  Hash Full Join
+               Hash Cond: (prt1_p1.a = prt2_p1.b)
+               Filter: (((50) = prt1_p1.a) OR ((75) = prt2_p1.b))
+               ->  Seq Scan on prt1_p1
+                     Filter: (b = 0)
+               ->  Hash
+                     ->  Seq Scan on prt2_p1
+                           Filter: (a = 0)
+         ->  Hash Full Join
+               Hash Cond: (prt1_p2.a = prt2_p2.b)
+               Filter: (((50) = prt1_p2.a) OR ((75) = prt2_p2.b))
+               ->  Seq Scan on prt1_p2
+                     Filter: (b = 0)
+               ->  Hash
+                     ->  Seq Scan on prt2_p2
+                           Filter: (a = 0)
+         ->  Hash Full Join
+               Hash Cond: (prt1_p3.a = prt2_p3.b)
+               Filter: (((50) = prt1_p3.a) OR ((75) = prt2_p3.b))
+               ->  Seq Scan on prt1_p3
+                     Filter: (b = 0)
+               ->  Hash
+                     ->  Seq Scan on prt2_p3
+                           Filter: (a = 0)
+(27 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT 50 phv, * FROM prt1 WHERE prt1.b = 0) t1 FULL JOIN (SELECT 75 phv, * FROM prt2 WHERE prt2.a = 0) t2 ON (t1.a = t2.b) WHERE t1.phv = t1.a OR t2.phv = t2.b ORDER BY t1.a, t2.b;
+ a  |  c   | b  |  c   
+----+------+----+------
+ 50 | 0050 |    | 
+    |      | 75 | 0075
+(2 rows)
+
+-- Join with pruned partitions from joining relations
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1 t1, prt2 t2 WHERE t1.a = t2.b AND t1.a < 450 AND t2.b > 250 AND t1.b = 0 ORDER BY t1.a, t2.b;
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Sort
+   Sort Key: t1.a
+   ->  Hash Join
+         Hash Cond: (t2.b = t1.a)
+         ->  Seq Scan on prt2_p2 t2
+               Filter: (b > 250)
+         ->  Hash
+               ->  Seq Scan on prt1_p2 t1
+                     Filter: ((a < 450) AND (b = 0))
+(9 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1 t1, prt2 t2 WHERE t1.a = t2.b AND t1.a < 450 AND t2.b > 250 AND t1.b = 0 ORDER BY t1.a, t2.b;
+  a  |  c   |  b  |  c   
+-----+------+-----+------
+ 300 | 0300 | 300 | 0300
+(1 row)
+
+-- Currently we can't do partitioned join if nullable-side partitions are pruned
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT * FROM prt1 WHERE a < 450) t1 LEFT JOIN (SELECT * FROM prt2 WHERE b > 250) t2 ON t1.a = t2.b WHERE t1.b = 0 ORDER BY t1.a, t2.b;
+                        QUERY PLAN                         
+-----------------------------------------------------------
+ Sort
+   Sort Key: prt1_p1.a, prt2_p2.b
+   ->  Hash Right Join
+         Hash Cond: (prt2_p2.b = prt1_p1.a)
+         ->  Append
+               ->  Seq Scan on prt2_p2
+                     Filter: (b > 250)
+               ->  Seq Scan on prt2_p3
+                     Filter: (b > 250)
+         ->  Hash
+               ->  Append
+                     ->  Seq Scan on prt1_p1
+                           Filter: ((a < 450) AND (b = 0))
+                     ->  Seq Scan on prt1_p2
+                           Filter: ((a < 450) AND (b = 0))
+(15 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT * FROM prt1 WHERE a < 450) t1 LEFT JOIN (SELECT * FROM prt2 WHERE b > 250) t2 ON t1.a = t2.b WHERE t1.b = 0 ORDER BY t1.a, t2.b;
+  a  |  c   |  b  |  c   
+-----+------+-----+------
+   0 | 0000 |     | 
+  50 | 0050 |     | 
+ 100 | 0100 |     | 
+ 150 | 0150 |     | 
+ 200 | 0200 |     | 
+ 250 | 0250 |     | 
+ 300 | 0300 | 300 | 0300
+ 350 | 0350 |     | 
+ 400 | 0400 |     | 
+(9 rows)
+
+-- Currently we can't do partitioned join if nullable-side partitions are pruned
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT * FROM prt1 WHERE a < 450) t1 FULL JOIN (SELECT * FROM prt2 WHERE b > 250) t2 ON t1.a = t2.b WHERE t1.b = 0 OR t2.a = 0 ORDER BY t1.a, t2.b;
+                      QUERY PLAN                      
+------------------------------------------------------
+ Sort
+   Sort Key: prt1_p1.a, prt2_p2.b
+   ->  Hash Full Join
+         Hash Cond: (prt1_p1.a = prt2_p2.b)
+         Filter: ((prt1_p1.b = 0) OR (prt2_p2.a = 0))
+         ->  Append
+               ->  Seq Scan on prt1_p1
+                     Filter: (a < 450)
+               ->  Seq Scan on prt1_p2
+                     Filter: (a < 450)
+         ->  Hash
+               ->  Append
+                     ->  Seq Scan on prt2_p2
+                           Filter: (b > 250)
+                     ->  Seq Scan on prt2_p3
+                           Filter: (b > 250)
+(16 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT * FROM prt1 WHERE a < 450) t1 FULL JOIN (SELECT * FROM prt2 WHERE b > 250) t2 ON t1.a = t2.b WHERE t1.b = 0 OR t2.a = 0 ORDER BY t1.a, t2.b;
+  a  |  c   |  b  |  c   
+-----+------+-----+------
+   0 | 0000 |     | 
+  50 | 0050 |     | 
+ 100 | 0100 |     | 
+ 150 | 0150 |     | 
+ 200 | 0200 |     | 
+ 250 | 0250 |     | 
+ 300 | 0300 | 300 | 0300
+ 350 | 0350 |     | 
+ 400 | 0400 |     | 
+     |      | 375 | 0375
+     |      | 450 | 0450
+     |      | 525 | 0525
+(12 rows)
+
+-- Semi-join
+EXPLAIN (COSTS OFF)
+SELECT t1.* FROM prt1 t1 WHERE t1.a IN (SELECT t2.b FROM prt2 t2 WHERE t2.a = 0) AND t1.b = 0 ORDER BY t1.a;
+                    QUERY PLAN                    
+--------------------------------------------------
+ Sort
+   Sort Key: t1.a
+   ->  Append
+         ->  Hash Semi Join
+               Hash Cond: (t1.a = t2.b)
+               ->  Seq Scan on prt1_p1 t1
+                     Filter: (b = 0)
+               ->  Hash
+                     ->  Seq Scan on prt2_p1 t2
+                           Filter: (a = 0)
+         ->  Hash Semi Join
+               Hash Cond: (t1_1.a = t2_1.b)
+               ->  Seq Scan on prt1_p2 t1_1
+                     Filter: (b = 0)
+               ->  Hash
+                     ->  Seq Scan on prt2_p2 t2_1
+                           Filter: (a = 0)
+         ->  Nested Loop Semi Join
+               Join Filter: (t1_2.a = t2_2.b)
+               ->  Seq Scan on prt1_p3 t1_2
+                     Filter: (b = 0)
+               ->  Materialize
+                     ->  Seq Scan on prt2_p3 t2_2
+                           Filter: (a = 0)
+(24 rows)
+
+SELECT t1.* FROM prt1 t1 WHERE t1.a IN (SELECT t2.b FROM prt2 t2 WHERE t2.a = 0) AND t1.b = 0 ORDER BY t1.a;
+  a  | b |  c   
+-----+---+------
+   0 | 0 | 0000
+ 150 | 0 | 0150
+ 300 | 0 | 0300
+ 450 | 0 | 0450
+(4 rows)
+
+-- Anti-join with aggregates
+EXPLAIN (COSTS OFF)
+SELECT sum(t1.a), avg(t1.a), sum(t1.b), avg(t1.b) FROM prt1 t1 WHERE NOT EXISTS (SELECT 1 FROM prt2 t2 WHERE t1.a = t2.b);
+                    QUERY PLAN                    
+--------------------------------------------------
+ Aggregate
+   ->  Append
+         ->  Hash Anti Join
+               Hash Cond: (t1.a = t2.b)
+               ->  Seq Scan on prt1_p1 t1
+               ->  Hash
+                     ->  Seq Scan on prt2_p1 t2
+         ->  Hash Anti Join
+               Hash Cond: (t1_1.a = t2_1.b)
+               ->  Seq Scan on prt1_p2 t1_1
+               ->  Hash
+                     ->  Seq Scan on prt2_p2 t2_1
+         ->  Hash Anti Join
+               Hash Cond: (t1_2.a = t2_2.b)
+               ->  Seq Scan on prt1_p3 t1_2
+               ->  Hash
+                     ->  Seq Scan on prt2_p3 t2_2
+(17 rows)
+
+SELECT sum(t1.a), avg(t1.a), sum(t1.b), avg(t1.b) FROM prt1 t1 WHERE NOT EXISTS (SELECT 1 FROM prt2 t2 WHERE t1.a = t2.b);
+  sum  |         avg          | sum  |         avg         
+-------+----------------------+------+---------------------
+ 60000 | 300.0000000000000000 | 2400 | 12.0000000000000000
+(1 row)
+
+-- lateral reference
+EXPLAIN (COSTS OFF)
+SELECT * FROM prt1 t1 LEFT JOIN LATERAL
+			  (SELECT t2.a AS t2a, t3.a AS t3a, least(t1.a,t2.a,t3.b) FROM prt1 t2 JOIN prt2 t3 ON (t2.a = t3.b)) ss
+			  ON t1.a = ss.t2a WHERE t1.b = 0 ORDER BY t1.a;
+                                QUERY PLAN                                
+--------------------------------------------------------------------------
+ Sort
+   Sort Key: t1.a
+   ->  Append
+         ->  Nested Loop Left Join
+               ->  Seq Scan on prt1_p1 t1
+                     Filter: (b = 0)
+               ->  Nested Loop
+                     ->  Index Only Scan using iprt1_p1_a on prt1_p1 t2
+                           Index Cond: (a = t1.a)
+                     ->  Index Scan using iprt2_p1_b on prt2_p1 t3
+                           Index Cond: (b = t2.a)
+         ->  Nested Loop Left Join
+               ->  Seq Scan on prt1_p2 t1_1
+                     Filter: (b = 0)
+               ->  Nested Loop
+                     ->  Index Only Scan using iprt1_p2_a on prt1_p2 t2_1
+                           Index Cond: (a = t1_1.a)
+                     ->  Index Scan using iprt2_p2_b on prt2_p2 t3_1
+                           Index Cond: (b = t2_1.a)
+         ->  Nested Loop Left Join
+               ->  Seq Scan on prt1_p3 t1_2
+                     Filter: (b = 0)
+               ->  Nested Loop
+                     ->  Index Only Scan using iprt1_p3_a on prt1_p3 t2_2
+                           Index Cond: (a = t1_2.a)
+                     ->  Index Scan using iprt2_p3_b on prt2_p3 t3_2
+                           Index Cond: (b = t2_2.a)
+(27 rows)
+
+SELECT * FROM prt1 t1 LEFT JOIN LATERAL
+			  (SELECT t2.a AS t2a, t3.a AS t3a, least(t1.a,t2.a,t3.b) FROM prt1 t2 JOIN prt2 t3 ON (t2.a = t3.b)) ss
+			  ON t1.a = ss.t2a WHERE t1.b = 0 ORDER BY t1.a;
+  a  | b |  c   | t2a | t3a | least 
+-----+---+------+-----+-----+-------
+   0 | 0 | 0000 |   0 |   0 |     0
+  50 | 0 | 0050 |     |     |      
+ 100 | 0 | 0100 |     |     |      
+ 150 | 0 | 0150 | 150 |   0 |   150
+ 200 | 0 | 0200 |     |     |      
+ 250 | 0 | 0250 |     |     |      
+ 300 | 0 | 0300 | 300 |   0 |   300
+ 350 | 0 | 0350 |     |     |      
+ 400 | 0 | 0400 |     |     |      
+ 450 | 0 | 0450 | 450 |   0 |   450
+ 500 | 0 | 0500 |     |     |      
+ 550 | 0 | 0550 |     |     |      
+(12 rows)
+
+EXPLAIN (COSTS OFF)
+SELECT t1.a, ss.t2a, ss.t2c FROM prt1 t1 LEFT JOIN LATERAL
+			  (SELECT t2.a AS t2a, t3.a AS t3a, t2.b t2b, t2.c t2c, least(t1.a,t2.a,t3.b) FROM prt1 t2 JOIN prt2 t3 ON (t2.a = t3.b)) ss
+			  ON t1.c = ss.t2c WHERE (t1.b + coalesce(ss.t2b, 0)) = 0 ORDER BY t1.a;
+                          QUERY PLAN                          
+--------------------------------------------------------------
+ Sort
+   Sort Key: t1.a
+   ->  Hash Left Join
+         Hash Cond: ((t1.c)::text = (t2.c)::text)
+         Filter: ((t1.b + COALESCE(t2.b, 0)) = 0)
+         ->  Append
+               ->  Seq Scan on prt1_p1 t1
+               ->  Seq Scan on prt1_p2 t1_1
+               ->  Seq Scan on prt1_p3 t1_2
+         ->  Hash
+               ->  Append
+                     ->  Hash Join
+                           Hash Cond: (t2.a = t3.b)
+                           ->  Seq Scan on prt1_p1 t2
+                           ->  Hash
+                                 ->  Seq Scan on prt2_p1 t3
+                     ->  Hash Join
+                           Hash Cond: (t2_1.a = t3_1.b)
+                           ->  Seq Scan on prt1_p2 t2_1
+                           ->  Hash
+                                 ->  Seq Scan on prt2_p2 t3_1
+                     ->  Hash Join
+                           Hash Cond: (t2_2.a = t3_2.b)
+                           ->  Seq Scan on prt1_p3 t2_2
+                           ->  Hash
+                                 ->  Seq Scan on prt2_p3 t3_2
+(26 rows)
+
+SELECT t1.a, ss.t2a, ss.t2c FROM prt1 t1 LEFT JOIN LATERAL
+			  (SELECT t2.a AS t2a, t3.a AS t3a, t2.b t2b, t2.c t2c, least(t1.a,t2.a,t3.a) FROM prt1 t2 JOIN prt2 t3 ON (t2.a = t3.b)) ss
+			  ON t1.c = ss.t2c WHERE (t1.b + coalesce(ss.t2b, 0)) = 0 ORDER BY t1.a;
+  a  | t2a | t2c  
+-----+-----+------
+   0 |   0 | 0000
+  50 |     | 
+ 100 |     | 
+ 150 | 150 | 0150
+ 200 |     | 
+ 250 |     | 
+ 300 | 300 | 0300
+ 350 |     | 
+ 400 |     | 
+ 450 | 450 | 0450
+ 500 |     | 
+ 550 |     | 
+(12 rows)
+
+--
+-- partitioned by expression
+--
+CREATE TABLE prt1_e (a int, b int, c int) PARTITION BY RANGE(((a + b)/2));
+CREATE TABLE prt1_e_p1 PARTITION OF prt1_e FOR VALUES FROM (0) TO (250);
+CREATE TABLE prt1_e_p2 PARTITION OF prt1_e FOR VALUES FROM (250) TO (500);
+CREATE TABLE prt1_e_p3 PARTITION OF prt1_e FOR VALUES FROM (500) TO (600);
+INSERT INTO prt1_e SELECT i, i, i % 25 FROM generate_series(0, 599, 2) i;
+CREATE INDEX iprt1_e_p1_ab2 on prt1_e_p1(((a+b)/2));
+CREATE INDEX iprt1_e_p2_ab2 on prt1_e_p2(((a+b)/2));
+CREATE INDEX iprt1_e_p3_ab2 on prt1_e_p3(((a+b)/2));
+ANALYZE prt1_e;
+CREATE TABLE prt2_e (a int, b int, c int) PARTITION BY RANGE(((b + a)/2));
+CREATE TABLE prt2_e_p1 PARTITION OF prt2_e FOR VALUES FROM (0) TO (250);
+CREATE TABLE prt2_e_p2 PARTITION OF prt2_e FOR VALUES FROM (250) TO (500);
+CREATE TABLE prt2_e_p3 PARTITION OF prt2_e FOR VALUES FROM (500) TO (600);
+INSERT INTO prt2_e SELECT i, i, i % 25 FROM generate_series(0, 599, 3) i;
+ANALYZE prt2_e;
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_e t1, prt2_e t2 WHERE (t1.a + t1.b)/2 = (t2.b + t2.a)/2 AND t1.c = 0 ORDER BY t1.a, t2.b;
+                                  QUERY PLAN                                  
+------------------------------------------------------------------------------
+ Sort
+   Sort Key: t1.a, t2.b
+   ->  Append
+         ->  Hash Join
+               Hash Cond: (((t2.b + t2.a) / 2) = ((t1.a + t1.b) / 2))
+               ->  Seq Scan on prt2_e_p1 t2
+               ->  Hash
+                     ->  Seq Scan on prt1_e_p1 t1
+                           Filter: (c = 0)
+         ->  Hash Join
+               Hash Cond: (((t2_1.b + t2_1.a) / 2) = ((t1_1.a + t1_1.b) / 2))
+               ->  Seq Scan on prt2_e_p2 t2_1
+               ->  Hash
+                     ->  Seq Scan on prt1_e_p2 t1_1
+                           Filter: (c = 0)
+         ->  Hash Join
+               Hash Cond: (((t2_2.b + t2_2.a) / 2) = ((t1_2.a + t1_2.b) / 2))
+               ->  Seq Scan on prt2_e_p3 t2_2
+               ->  Hash
+                     ->  Seq Scan on prt1_e_p3 t1_2
+                           Filter: (c = 0)
+(21 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_e t1, prt2_e t2 WHERE (t1.a + t1.b)/2 = (t2.b + t2.a)/2 AND t1.c = 0 ORDER BY t1.a, t2.b;
+  a  | c |  b  | c 
+-----+---+-----+---
+   0 | 0 |   0 | 0
+ 150 | 0 | 150 | 0
+ 300 | 0 | 300 | 0
+ 450 | 0 | 450 | 0
+(4 rows)
+
+--
+-- N-way join
+--
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c, t3.a + t3.b, t3.c FROM prt1 t1, prt2 t2, prt1_e t3 WHERE t1.a = t2.b AND t1.a = (t3.a + t3.b)/2 AND t1.b = 0 ORDER BY t1.a, t2.b;
+                             QUERY PLAN                              
+---------------------------------------------------------------------
+ Sort
+   Sort Key: t1.a
+   ->  Append
+         ->  Nested Loop
+               Join Filter: (t1.a = ((t3.a + t3.b) / 2))
+               ->  Hash Join
+                     Hash Cond: (t2.b = t1.a)
+                     ->  Seq Scan on prt2_p1 t2
+                     ->  Hash
+                           ->  Seq Scan on prt1_p1 t1
+                                 Filter: (b = 0)
+               ->  Index Scan using iprt1_e_p1_ab2 on prt1_e_p1 t3
+                     Index Cond: (((a + b) / 2) = t2.b)
+         ->  Nested Loop
+               Join Filter: (t1_1.a = ((t3_1.a + t3_1.b) / 2))
+               ->  Hash Join
+                     Hash Cond: (t2_1.b = t1_1.a)
+                     ->  Seq Scan on prt2_p2 t2_1
+                     ->  Hash
+                           ->  Seq Scan on prt1_p2 t1_1
+                                 Filter: (b = 0)
+               ->  Index Scan using iprt1_e_p2_ab2 on prt1_e_p2 t3_1
+                     Index Cond: (((a + b) / 2) = t2_1.b)
+         ->  Nested Loop
+               Join Filter: (t1_2.a = ((t3_2.a + t3_2.b) / 2))
+               ->  Hash Join
+                     Hash Cond: (t2_2.b = t1_2.a)
+                     ->  Seq Scan on prt2_p3 t2_2
+                     ->  Hash
+                           ->  Seq Scan on prt1_p3 t1_2
+                                 Filter: (b = 0)
+               ->  Index Scan using iprt1_e_p3_ab2 on prt1_e_p3 t3_2
+                     Index Cond: (((a + b) / 2) = t2_2.b)
+(33 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c, t3.a + t3.b, t3.c FROM prt1 t1, prt2 t2, prt1_e t3 WHERE t1.a = t2.b AND t1.a = (t3.a + t3.b)/2 AND t1.b = 0 ORDER BY t1.a, t2.b;
+  a  |  c   |  b  |  c   | ?column? | c 
+-----+------+-----+------+----------+---
+   0 | 0000 |   0 | 0000 |        0 | 0
+ 150 | 0150 | 150 | 0150 |      300 | 0
+ 300 | 0300 | 300 | 0300 |      600 | 0
+ 450 | 0450 | 450 | 0450 |      900 | 0
+(4 rows)
+
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c, t3.a + t3.b, t3.c FROM (prt1 t1 LEFT JOIN prt2 t2 ON t1.a = t2.b) LEFT JOIN prt1_e t3 ON (t1.a = (t3.a + t3.b)/2) WHERE t1.b = 0 ORDER BY t1.a, t2.b, t3.a + t3.b;
+                          QUERY PLAN                          
+--------------------------------------------------------------
+ Sort
+   Sort Key: t1.a, t2.b, ((t3.a + t3.b))
+   ->  Append
+         ->  Hash Right Join
+               Hash Cond: (((t3.a + t3.b) / 2) = t1.a)
+               ->  Seq Scan on prt1_e_p1 t3
+               ->  Hash
+                     ->  Hash Right Join
+                           Hash Cond: (t2.b = t1.a)
+                           ->  Seq Scan on prt2_p1 t2
+                           ->  Hash
+                                 ->  Seq Scan on prt1_p1 t1
+                                       Filter: (b = 0)
+         ->  Hash Right Join
+               Hash Cond: (((t3_1.a + t3_1.b) / 2) = t1_1.a)
+               ->  Seq Scan on prt1_e_p2 t3_1
+               ->  Hash
+                     ->  Hash Right Join
+                           Hash Cond: (t2_1.b = t1_1.a)
+                           ->  Seq Scan on prt2_p2 t2_1
+                           ->  Hash
+                                 ->  Seq Scan on prt1_p2 t1_1
+                                       Filter: (b = 0)
+         ->  Hash Right Join
+               Hash Cond: (((t3_2.a + t3_2.b) / 2) = t1_2.a)
+               ->  Seq Scan on prt1_e_p3 t3_2
+               ->  Hash
+                     ->  Hash Right Join
+                           Hash Cond: (t2_2.b = t1_2.a)
+                           ->  Seq Scan on prt2_p3 t2_2
+                           ->  Hash
+                                 ->  Seq Scan on prt1_p3 t1_2
+                                       Filter: (b = 0)
+(33 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c, t3.a + t3.b, t3.c FROM (prt1 t1 LEFT JOIN prt2 t2 ON t1.a = t2.b) LEFT JOIN prt1_e t3 ON (t1.a = (t3.a + t3.b)/2) WHERE t1.b = 0 ORDER BY t1.a, t2.b, t3.a + t3.b;
+  a  |  c   |  b  |  c   | ?column? | c 
+-----+------+-----+------+----------+---
+   0 | 0000 |   0 | 0000 |        0 | 0
+  50 | 0050 |     |      |      100 | 0
+ 100 | 0100 |     |      |      200 | 0
+ 150 | 0150 | 150 | 0150 |      300 | 0
+ 200 | 0200 |     |      |      400 | 0
+ 250 | 0250 |     |      |      500 | 0
+ 300 | 0300 | 300 | 0300 |      600 | 0
+ 350 | 0350 |     |      |      700 | 0
+ 400 | 0400 |     |      |      800 | 0
+ 450 | 0450 | 450 | 0450 |      900 | 0
+ 500 | 0500 |     |      |     1000 | 0
+ 550 | 0550 |     |      |     1100 | 0
+(12 rows)
+
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c, t3.a + t3.b, t3.c FROM (prt1 t1 LEFT JOIN prt2 t2 ON t1.a = t2.b) RIGHT JOIN prt1_e t3 ON (t1.a = (t3.a + t3.b)/2) WHERE t3.c = 0 ORDER BY t1.a, t2.b, t3.a + t3.b;
+                            QUERY PLAN                             
+-------------------------------------------------------------------
+ Sort
+   Sort Key: t1.a, t2.b, ((t3.a + t3.b))
+   ->  Append
+         ->  Nested Loop Left Join
+               ->  Hash Right Join
+                     Hash Cond: (t1.a = ((t3.a + t3.b) / 2))
+                     ->  Seq Scan on prt1_p1 t1
+                     ->  Hash
+                           ->  Seq Scan on prt1_e_p1 t3
+                                 Filter: (c = 0)
+               ->  Index Scan using iprt2_p1_b on prt2_p1 t2
+                     Index Cond: (b = t1.a)
+         ->  Nested Loop Left Join
+               ->  Hash Right Join
+                     Hash Cond: (t1_1.a = ((t3_1.a + t3_1.b) / 2))
+                     ->  Seq Scan on prt1_p2 t1_1
+                     ->  Hash
+                           ->  Seq Scan on prt1_e_p2 t3_1
+                                 Filter: (c = 0)
+               ->  Index Scan using iprt2_p2_b on prt2_p2 t2_1
+                     Index Cond: (b = t1_1.a)
+         ->  Nested Loop Left Join
+               ->  Hash Right Join
+                     Hash Cond: (t1_2.a = ((t3_2.a + t3_2.b) / 2))
+                     ->  Seq Scan on prt1_p3 t1_2
+                     ->  Hash
+                           ->  Seq Scan on prt1_e_p3 t3_2
+                                 Filter: (c = 0)
+               ->  Index Scan using iprt2_p3_b on prt2_p3 t2_2
+                     Index Cond: (b = t1_2.a)
+(30 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c, t3.a + t3.b, t3.c FROM (prt1 t1 LEFT JOIN prt2 t2 ON t1.a = t2.b) RIGHT JOIN prt1_e t3 ON (t1.a = (t3.a + t3.b)/2) WHERE t3.c = 0 ORDER BY t1.a, t2.b, t3.a + t3.b;
+  a  |  c   |  b  |  c   | ?column? | c 
+-----+------+-----+------+----------+---
+   0 | 0000 |   0 | 0000 |        0 | 0
+  50 | 0050 |     |      |      100 | 0
+ 100 | 0100 |     |      |      200 | 0
+ 150 | 0150 | 150 | 0150 |      300 | 0
+ 200 | 0200 |     |      |      400 | 0
+ 250 | 0250 |     |      |      500 | 0
+ 300 | 0300 | 300 | 0300 |      600 | 0
+ 350 | 0350 |     |      |      700 | 0
+ 400 | 0400 |     |      |      800 | 0
+ 450 | 0450 | 450 | 0450 |      900 | 0
+ 500 | 0500 |     |      |     1000 | 0
+ 550 | 0550 |     |      |     1100 | 0
+(12 rows)
+
+-- Cases with non-nullable expressions in subquery results;
+-- make sure these go to null as expected
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.phv, t2.b, t2.phv, t3.a + t3.b, t3.phv FROM ((SELECT 50 phv, * FROM prt1 WHERE prt1.b = 0) t1 FULL JOIN (SELECT 75 phv, * FROM prt2 WHERE prt2.a = 0) t2 ON (t1.a = t2.b)) FULL JOIN (SELECT 50 phv, * FROM prt1_e WHERE prt1_e.c = 0) t3 ON (t1.a = (t3.a + t3.b)/2) WHERE t1.a = t1.phv OR t2.b = t2.phv OR (t3.a + t3.b)/2 = t3.phv ORDER BY t1.a, t2.b, t3.a + t3.b;
+                                                   QUERY PLAN                                                   
+----------------------------------------------------------------------------------------------------------------
+ Sort
+   Sort Key: prt1_p1.a, prt2_p1.b, ((prt1_e_p1.a + prt1_e_p1.b))
+   ->  Append
+         ->  Hash Full Join
+               Hash Cond: (prt1_p1.a = ((prt1_e_p1.a + prt1_e_p1.b) / 2))
+               Filter: ((prt1_p1.a = (50)) OR (prt2_p1.b = (75)) OR (((prt1_e_p1.a + prt1_e_p1.b) / 2) = (50)))
+               ->  Hash Full Join
+                     Hash Cond: (prt1_p1.a = prt2_p1.b)
+                     ->  Seq Scan on prt1_p1
+                           Filter: (b = 0)
+                     ->  Hash
+                           ->  Seq Scan on prt2_p1
+                                 Filter: (a = 0)
+               ->  Hash
+                     ->  Seq Scan on prt1_e_p1
+                           Filter: (c = 0)
+         ->  Hash Full Join
+               Hash Cond: (prt1_p2.a = ((prt1_e_p2.a + prt1_e_p2.b) / 2))
+               Filter: ((prt1_p2.a = (50)) OR (prt2_p2.b = (75)) OR (((prt1_e_p2.a + prt1_e_p2.b) / 2) = (50)))
+               ->  Hash Full Join
+                     Hash Cond: (prt1_p2.a = prt2_p2.b)
+                     ->  Seq Scan on prt1_p2
+                           Filter: (b = 0)
+                     ->  Hash
+                           ->  Seq Scan on prt2_p2
+                                 Filter: (a = 0)
+               ->  Hash
+                     ->  Seq Scan on prt1_e_p2
+                           Filter: (c = 0)
+         ->  Hash Full Join
+               Hash Cond: (prt1_p3.a = ((prt1_e_p3.a + prt1_e_p3.b) / 2))
+               Filter: ((prt1_p3.a = (50)) OR (prt2_p3.b = (75)) OR (((prt1_e_p3.a + prt1_e_p3.b) / 2) = (50)))
+               ->  Hash Full Join
+                     Hash Cond: (prt1_p3.a = prt2_p3.b)
+                     ->  Seq Scan on prt1_p3
+                           Filter: (b = 0)
+                     ->  Hash
+                           ->  Seq Scan on prt2_p3
+                                 Filter: (a = 0)
+               ->  Hash
+                     ->  Seq Scan on prt1_e_p3
+                           Filter: (c = 0)
+(42 rows)
+
+SELECT t1.a, t1.phv, t2.b, t2.phv, t3.a + t3.b, t3.phv FROM ((SELECT 50 phv, * FROM prt1 WHERE prt1.b = 0) t1 FULL JOIN (SELECT 75 phv, * FROM prt2 WHERE prt2.a = 0) t2 ON (t1.a = t2.b)) FULL JOIN (SELECT 50 phv, * FROM prt1_e WHERE prt1_e.c = 0) t3 ON (t1.a = (t3.a + t3.b)/2) WHERE t1.a = t1.phv OR t2.b = t2.phv OR (t3.a + t3.b)/2 = t3.phv ORDER BY t1.a, t2.b, t3.a + t3.b;
+ a  | phv | b  | phv | ?column? | phv 
+----+-----+----+-----+----------+-----
+ 50 |  50 |    |     |      100 |  50
+    |     | 75 |  75 |          |    
+(2 rows)
+
+-- Semi-join
+EXPLAIN (COSTS OFF)
+SELECT t1.* FROM prt1 t1 WHERE t1.a IN (SELECT t1.b FROM prt2 t1, prt1_e t2 WHERE t1.a = 0 AND t1.b = (t2.a + t2.b)/2) AND t1.b = 0 ORDER BY t1.a;
+                                   QUERY PLAN                                    
+---------------------------------------------------------------------------------
+ Sort
+   Sort Key: t1.a
+   ->  Append
+         ->  Nested Loop
+               Join Filter: (t1.a = t1_3.b)
+               ->  HashAggregate
+                     Group Key: t1_3.b
+                     ->  Hash Join
+                           Hash Cond: (((t2.a + t2.b) / 2) = t1_3.b)
+                           ->  Seq Scan on prt1_e_p1 t2
+                           ->  Hash
+                                 ->  Seq Scan on prt2_p1 t1_3
+                                       Filter: (a = 0)
+               ->  Index Scan using iprt1_p1_a on prt1_p1 t1
+                     Index Cond: (a = ((t2.a + t2.b) / 2))
+                     Filter: (b = 0)
+         ->  Nested Loop
+               Join Filter: (t1_1.a = t1_4.b)
+               ->  HashAggregate
+                     Group Key: t1_4.b
+                     ->  Hash Join
+                           Hash Cond: (((t2_1.a + t2_1.b) / 2) = t1_4.b)
+                           ->  Seq Scan on prt1_e_p2 t2_1
+                           ->  Hash
+                                 ->  Seq Scan on prt2_p2 t1_4
+                                       Filter: (a = 0)
+               ->  Index Scan using iprt1_p2_a on prt1_p2 t1_1
+                     Index Cond: (a = ((t2_1.a + t2_1.b) / 2))
+                     Filter: (b = 0)
+         ->  Nested Loop
+               Join Filter: (t1_2.a = t1_5.b)
+               ->  HashAggregate
+                     Group Key: t1_5.b
+                     ->  Nested Loop
+                           ->  Seq Scan on prt2_p3 t1_5
+                                 Filter: (a = 0)
+                           ->  Index Scan using iprt1_e_p3_ab2 on prt1_e_p3 t2_2
+                                 Index Cond: (((a + b) / 2) = t1_5.b)
+               ->  Index Scan using iprt1_p3_a on prt1_p3 t1_2
+                     Index Cond: (a = ((t2_2.a + t2_2.b) / 2))
+                     Filter: (b = 0)
+(41 rows)
+
+SELECT t1.* FROM prt1 t1 WHERE t1.a IN (SELECT t1.b FROM prt2 t1, prt1_e t2 WHERE t1.a = 0 AND t1.b = (t2.a + t2.b)/2) AND t1.b = 0 ORDER BY t1.a;
+  a  | b |  c   
+-----+---+------
+   0 | 0 | 0000
+ 150 | 0 | 0150
+ 300 | 0 | 0300
+ 450 | 0 | 0450
+(4 rows)
+
+EXPLAIN (COSTS OFF)
+SELECT t1.* FROM prt1 t1 WHERE t1.a IN (SELECT t1.b FROM prt2 t1 WHERE t1.b IN (SELECT (t1.a + t1.b)/2 FROM prt1_e t1 WHERE t1.c = 0)) AND t1.b = 0 ORDER BY t1.a;
+                               QUERY PLAN                                
+-------------------------------------------------------------------------
+ Sort
+   Sort Key: t1.a
+   ->  Append
+         ->  Nested Loop
+               ->  HashAggregate
+                     Group Key: t1_3.b
+                     ->  Hash Semi Join
+                           Hash Cond: (t1_3.b = ((t1_6.a + t1_6.b) / 2))
+                           ->  Seq Scan on prt2_p1 t1_3
+                           ->  Hash
+                                 ->  Seq Scan on prt1_e_p1 t1_6
+                                       Filter: (c = 0)
+               ->  Index Scan using iprt1_p1_a on prt1_p1 t1
+                     Index Cond: (a = t1_3.b)
+                     Filter: (b = 0)
+         ->  Nested Loop
+               ->  HashAggregate
+                     Group Key: t1_4.b
+                     ->  Hash Semi Join
+                           Hash Cond: (t1_4.b = ((t1_7.a + t1_7.b) / 2))
+                           ->  Seq Scan on prt2_p2 t1_4
+                           ->  Hash
+                                 ->  Seq Scan on prt1_e_p2 t1_7
+                                       Filter: (c = 0)
+               ->  Index Scan using iprt1_p2_a on prt1_p2 t1_1
+                     Index Cond: (a = t1_4.b)
+                     Filter: (b = 0)
+         ->  Nested Loop
+               ->  HashAggregate
+                     Group Key: t1_5.b
+                     ->  Hash Semi Join
+                           Hash Cond: (t1_5.b = ((t1_8.a + t1_8.b) / 2))
+                           ->  Seq Scan on prt2_p3 t1_5
+                           ->  Hash
+                                 ->  Seq Scan on prt1_e_p3 t1_8
+                                       Filter: (c = 0)
+               ->  Index Scan using iprt1_p3_a on prt1_p3 t1_2
+                     Index Cond: (a = t1_5.b)
+                     Filter: (b = 0)
+(39 rows)
+
+SELECT t1.* FROM prt1 t1 WHERE t1.a IN (SELECT t1.b FROM prt2 t1 WHERE t1.b IN (SELECT (t1.a + t1.b)/2 FROM prt1_e t1 WHERE t1.c = 0)) AND t1.b = 0 ORDER BY t1.a;
+  a  | b |  c   
+-----+---+------
+   0 | 0 | 0000
+ 150 | 0 | 0150
+ 300 | 0 | 0300
+ 450 | 0 | 0450
+(4 rows)
+
+-- test merge joins
+SET enable_hashjoin TO off;
+SET enable_nestloop TO off;
+EXPLAIN (COSTS OFF)
+SELECT t1.* FROM prt1 t1 WHERE t1.a IN (SELECT t1.b FROM prt2 t1 WHERE t1.b IN (SELECT (t1.a + t1.b)/2 FROM prt1_e t1 WHERE t1.c = 0)) AND t1.b = 0 ORDER BY t1.a;
+                           QUERY PLAN                           
+----------------------------------------------------------------
+ Merge Append
+   Sort Key: t1.a
+   ->  Merge Semi Join
+         Merge Cond: (t1.a = t1_3.b)
+         ->  Sort
+               Sort Key: t1.a
+               ->  Seq Scan on prt1_p1 t1
+                     Filter: (b = 0)
+         ->  Merge Semi Join
+               Merge Cond: (t1_3.b = (((t1_6.a + t1_6.b) / 2)))
+               ->  Sort
+                     Sort Key: t1_3.b
+                     ->  Seq Scan on prt2_p1 t1_3
+               ->  Sort
+                     Sort Key: (((t1_6.a + t1_6.b) / 2))
+                     ->  Seq Scan on prt1_e_p1 t1_6
+                           Filter: (c = 0)
+   ->  Merge Semi Join
+         Merge Cond: (t1_1.a = t1_4.b)
+         ->  Sort
+               Sort Key: t1_1.a
+               ->  Seq Scan on prt1_p2 t1_1
+                     Filter: (b = 0)
+         ->  Merge Semi Join
+               Merge Cond: (t1_4.b = (((t1_7.a + t1_7.b) / 2)))
+               ->  Sort
+                     Sort Key: t1_4.b
+                     ->  Seq Scan on prt2_p2 t1_4
+               ->  Sort
+                     Sort Key: (((t1_7.a + t1_7.b) / 2))
+                     ->  Seq Scan on prt1_e_p2 t1_7
+                           Filter: (c = 0)
+   ->  Merge Semi Join
+         Merge Cond: (t1_2.a = t1_5.b)
+         ->  Sort
+               Sort Key: t1_2.a
+               ->  Seq Scan on prt1_p3 t1_2
+                     Filter: (b = 0)
+         ->  Merge Semi Join
+               Merge Cond: (t1_5.b = (((t1_8.a + t1_8.b) / 2)))
+               ->  Sort
+                     Sort Key: t1_5.b
+                     ->  Seq Scan on prt2_p3 t1_5
+               ->  Sort
+                     Sort Key: (((t1_8.a + t1_8.b) / 2))
+                     ->  Seq Scan on prt1_e_p3 t1_8
+                           Filter: (c = 0)
+(47 rows)
+
+SELECT t1.* FROM prt1 t1 WHERE t1.a IN (SELECT t1.b FROM prt2 t1 WHERE t1.b IN (SELECT (t1.a + t1.b)/2 FROM prt1_e t1 WHERE t1.c = 0)) AND t1.b = 0 ORDER BY t1.a;
+  a  | b |  c   
+-----+---+------
+   0 | 0 | 0000
+ 150 | 0 | 0150
+ 300 | 0 | 0300
+ 450 | 0 | 0450
+(4 rows)
+
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c, t3.a + t3.b, t3.c FROM (prt1 t1 LEFT JOIN prt2 t2 ON t1.a = t2.b) RIGHT JOIN prt1_e t3 ON (t1.a = (t3.a + t3.b)/2) WHERE t3.c = 0 ORDER BY t1.a, t2.b, t3.a + t3.b;
+                                 QUERY PLAN                                 
+----------------------------------------------------------------------------
+ Sort
+   Sort Key: t1.a, t2.b, ((t3.a + t3.b))
+   ->  Append
+         ->  Merge Left Join
+               Merge Cond: (t1.a = t2.b)
+               ->  Sort
+                     Sort Key: t1.a
+                     ->  Merge Left Join
+                           Merge Cond: ((((t3.a + t3.b) / 2)) = t1.a)
+                           ->  Sort
+                                 Sort Key: (((t3.a + t3.b) / 2))
+                                 ->  Seq Scan on prt1_e_p1 t3
+                                       Filter: (c = 0)
+                           ->  Sort
+                                 Sort Key: t1.a
+                                 ->  Seq Scan on prt1_p1 t1
+               ->  Sort
+                     Sort Key: t2.b
+                     ->  Seq Scan on prt2_p1 t2
+         ->  Merge Left Join
+               Merge Cond: (t1_1.a = t2_1.b)
+               ->  Sort
+                     Sort Key: t1_1.a
+                     ->  Merge Left Join
+                           Merge Cond: ((((t3_1.a + t3_1.b) / 2)) = t1_1.a)
+                           ->  Sort
+                                 Sort Key: (((t3_1.a + t3_1.b) / 2))
+                                 ->  Seq Scan on prt1_e_p2 t3_1
+                                       Filter: (c = 0)
+                           ->  Sort
+                                 Sort Key: t1_1.a
+                                 ->  Seq Scan on prt1_p2 t1_1
+               ->  Sort
+                     Sort Key: t2_1.b
+                     ->  Seq Scan on prt2_p2 t2_1
+         ->  Merge Left Join
+               Merge Cond: (t1_2.a = t2_2.b)
+               ->  Sort
+                     Sort Key: t1_2.a
+                     ->  Merge Left Join
+                           Merge Cond: ((((t3_2.a + t3_2.b) / 2)) = t1_2.a)
+                           ->  Sort
+                                 Sort Key: (((t3_2.a + t3_2.b) / 2))
+                                 ->  Seq Scan on prt1_e_p3 t3_2
+                                       Filter: (c = 0)
+                           ->  Sort
+                                 Sort Key: t1_2.a
+                                 ->  Seq Scan on prt1_p3 t1_2
+               ->  Sort
+                     Sort Key: t2_2.b
+                     ->  Seq Scan on prt2_p3 t2_2
+(51 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c, t3.a + t3.b, t3.c FROM (prt1 t1 LEFT JOIN prt2 t2 ON t1.a = t2.b) RIGHT JOIN prt1_e t3 ON (t1.a = (t3.a + t3.b)/2) WHERE t3.c = 0 ORDER BY t1.a, t2.b, t3.a + t3.b;
+  a  |  c   |  b  |  c   | ?column? | c 
+-----+------+-----+------+----------+---
+   0 | 0000 |   0 | 0000 |        0 | 0
+  50 | 0050 |     |      |      100 | 0
+ 100 | 0100 |     |      |      200 | 0
+ 150 | 0150 | 150 | 0150 |      300 | 0
+ 200 | 0200 |     |      |      400 | 0
+ 250 | 0250 |     |      |      500 | 0
+ 300 | 0300 | 300 | 0300 |      600 | 0
+ 350 | 0350 |     |      |      700 | 0
+ 400 | 0400 |     |      |      800 | 0
+ 450 | 0450 | 450 | 0450 |      900 | 0
+ 500 | 0500 |     |      |     1000 | 0
+ 550 | 0550 |     |      |     1100 | 0
+(12 rows)
+
+-- MergeAppend on nullable column
+-- This should generate a partitionwise join, but currently fails to
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t2.b FROM (SELECT * FROM prt1 WHERE a < 450) t1 LEFT JOIN (SELECT * FROM prt2 WHERE b > 250) t2 ON t1.a = t2.b WHERE t1.b = 0 ORDER BY t1.a, t2.b;
+                        QUERY PLAN                         
+-----------------------------------------------------------
+ Sort
+   Sort Key: prt1_p1.a, prt2_p2.b
+   ->  Merge Left Join
+         Merge Cond: (prt1_p1.a = prt2_p2.b)
+         ->  Sort
+               Sort Key: prt1_p1.a
+               ->  Append
+                     ->  Seq Scan on prt1_p1
+                           Filter: ((a < 450) AND (b = 0))
+                     ->  Seq Scan on prt1_p2
+                           Filter: ((a < 450) AND (b = 0))
+         ->  Sort
+               Sort Key: prt2_p2.b
+               ->  Append
+                     ->  Seq Scan on prt2_p2
+                           Filter: (b > 250)
+                     ->  Seq Scan on prt2_p3
+                           Filter: (b > 250)
+(18 rows)
+
+SELECT t1.a, t2.b FROM (SELECT * FROM prt1 WHERE a < 450) t1 LEFT JOIN (SELECT * FROM prt2 WHERE b > 250) t2 ON t1.a = t2.b WHERE t1.b = 0 ORDER BY t1.a, t2.b;
+  a  |  b  
+-----+-----
+   0 |    
+  50 |    
+ 100 |    
+ 150 |    
+ 200 |    
+ 250 |    
+ 300 | 300
+ 350 |    
+ 400 |    
+(9 rows)
+
+-- merge join when expression with whole-row reference needs to be sorted;
+-- partitionwise join does not apply
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t2.b FROM prt1 t1, prt2 t2 WHERE t1::text = t2::text AND t1.a = t2.b ORDER BY t1.a;
+                                       QUERY PLAN                                        
+-----------------------------------------------------------------------------------------
+ Merge Join
+   Merge Cond: ((t1.a = t2.b) AND (((((t1.*)::prt1))::text) = ((((t2.*)::prt2))::text)))
+   ->  Sort
+         Sort Key: t1.a, ((((t1.*)::prt1))::text)
+         ->  Result
+               ->  Append
+                     ->  Seq Scan on prt1_p1 t1
+                     ->  Seq Scan on prt1_p2 t1_1
+                     ->  Seq Scan on prt1_p3 t1_2
+   ->  Sort
+         Sort Key: t2.b, ((((t2.*)::prt2))::text)
+         ->  Result
+               ->  Append
+                     ->  Seq Scan on prt2_p1 t2
+                     ->  Seq Scan on prt2_p2 t2_1
+                     ->  Seq Scan on prt2_p3 t2_2
+(16 rows)
+
+SELECT t1.a, t2.b FROM prt1 t1, prt2 t2 WHERE t1::text = t2::text AND t1.a = t2.b ORDER BY t1.a;
+ a  | b  
+----+----
+  0 |  0
+  6 |  6
+ 12 | 12
+ 18 | 18
+ 24 | 24
+(5 rows)
+
+RESET enable_hashjoin;
+RESET enable_nestloop;
+--
+-- partitioned by multiple columns
+--
+CREATE TABLE prt1_m (a int, b int, c int) PARTITION BY RANGE(a, ((a + b)/2));
+CREATE TABLE prt1_m_p1 PARTITION OF prt1_m FOR VALUES FROM (0, 0) TO (250, 250);
+CREATE TABLE prt1_m_p2 PARTITION OF prt1_m FOR VALUES FROM (250, 250) TO (500, 500);
+CREATE TABLE prt1_m_p3 PARTITION OF prt1_m FOR VALUES FROM (500, 500) TO (600, 600);
+INSERT INTO prt1_m SELECT i, i, i % 25 FROM generate_series(0, 599, 2) i;
+ANALYZE prt1_m;
+CREATE TABLE prt2_m (a int, b int, c int) PARTITION BY RANGE(((b + a)/2), b);
+CREATE TABLE prt2_m_p1 PARTITION OF prt2_m FOR VALUES FROM (0, 0) TO (250, 250);
+CREATE TABLE prt2_m_p2 PARTITION OF prt2_m FOR VALUES FROM (250, 250) TO (500, 500);
+CREATE TABLE prt2_m_p3 PARTITION OF prt2_m FOR VALUES FROM (500, 500) TO (600, 600);
+INSERT INTO prt2_m SELECT i, i, i % 25 FROM generate_series(0, 599, 3) i;
+ANALYZE prt2_m;
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT * FROM prt1_m WHERE prt1_m.c = 0) t1 FULL JOIN (SELECT * FROM prt2_m WHERE prt2_m.c = 0) t2 ON (t1.a = (t2.b + t2.a)/2 AND t2.b = (t1.a + t1.b)/2) ORDER BY t1.a, t2.b;
+                                                             QUERY PLAN                                                             
+------------------------------------------------------------------------------------------------------------------------------------
+ Sort
+   Sort Key: prt1_m_p1.a, prt2_m_p1.b
+   ->  Append
+         ->  Hash Full Join
+               Hash Cond: ((prt1_m_p1.a = ((prt2_m_p1.b + prt2_m_p1.a) / 2)) AND (((prt1_m_p1.a + prt1_m_p1.b) / 2) = prt2_m_p1.b))
+               ->  Seq Scan on prt1_m_p1
+                     Filter: (c = 0)
+               ->  Hash
+                     ->  Seq Scan on prt2_m_p1
+                           Filter: (c = 0)
+         ->  Hash Full Join
+               Hash Cond: ((prt1_m_p2.a = ((prt2_m_p2.b + prt2_m_p2.a) / 2)) AND (((prt1_m_p2.a + prt1_m_p2.b) / 2) = prt2_m_p2.b))
+               ->  Seq Scan on prt1_m_p2
+                     Filter: (c = 0)
+               ->  Hash
+                     ->  Seq Scan on prt2_m_p2
+                           Filter: (c = 0)
+         ->  Hash Full Join
+               Hash Cond: ((prt1_m_p3.a = ((prt2_m_p3.b + prt2_m_p3.a) / 2)) AND (((prt1_m_p3.a + prt1_m_p3.b) / 2) = prt2_m_p3.b))
+               ->  Seq Scan on prt1_m_p3
+                     Filter: (c = 0)
+               ->  Hash
+                     ->  Seq Scan on prt2_m_p3
+                           Filter: (c = 0)
+(24 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT * FROM prt1_m WHERE prt1_m.c = 0) t1 FULL JOIN (SELECT * FROM prt2_m WHERE prt2_m.c = 0) t2 ON (t1.a = (t2.b + t2.a)/2 AND t2.b = (t1.a + t1.b)/2) ORDER BY t1.a, t2.b;
+  a  | c |  b  | c 
+-----+---+-----+---
+   0 | 0 |   0 | 0
+  50 | 0 |     |  
+ 100 | 0 |     |  
+ 150 | 0 | 150 | 0
+ 200 | 0 |     |  
+ 250 | 0 |     |  
+ 300 | 0 | 300 | 0
+ 350 | 0 |     |  
+ 400 | 0 |     |  
+ 450 | 0 | 450 | 0
+ 500 | 0 |     |  
+ 550 | 0 |     |  
+     |   |  75 | 0
+     |   | 225 | 0
+     |   | 375 | 0
+     |   | 525 | 0
+(16 rows)
+
+--
+-- tests for list partitioned tables.
+--
+CREATE TABLE plt1 (a int, b int, c text) PARTITION BY LIST(c);
+CREATE TABLE plt1_p1 PARTITION OF plt1 FOR VALUES IN ('0000', '0003', '0004', '0010');
+CREATE TABLE plt1_p2 PARTITION OF plt1 FOR VALUES IN ('0001', '0005', '0002', '0009');
+CREATE TABLE plt1_p3 PARTITION OF plt1 FOR VALUES IN ('0006', '0007', '0008', '0011');
+INSERT INTO plt1 SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(0, 599, 2) i;
+ANALYZE plt1;
+CREATE TABLE plt2 (a int, b int, c text) PARTITION BY LIST(c);
+CREATE TABLE plt2_p1 PARTITION OF plt2 FOR VALUES IN ('0000', '0003', '0004', '0010');
+CREATE TABLE plt2_p2 PARTITION OF plt2 FOR VALUES IN ('0001', '0005', '0002', '0009');
+CREATE TABLE plt2_p3 PARTITION OF plt2 FOR VALUES IN ('0006', '0007', '0008', '0011');
+INSERT INTO plt2 SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(0, 599, 3) i;
+ANALYZE plt2;
+--
+-- list partitioned by expression
+--
+CREATE TABLE plt1_e (a int, b int, c text) PARTITION BY LIST(ltrim(c, 'A'));
+CREATE TABLE plt1_e_p1 PARTITION OF plt1_e FOR VALUES IN ('0000', '0003', '0004', '0010');
+CREATE TABLE plt1_e_p2 PARTITION OF plt1_e FOR VALUES IN ('0001', '0005', '0002', '0009');
+CREATE TABLE plt1_e_p3 PARTITION OF plt1_e FOR VALUES IN ('0006', '0007', '0008', '0011');
+INSERT INTO plt1_e SELECT i, i, 'A' || to_char(i/50, 'FM0000') FROM generate_series(0, 599, 2) i;
+ANALYZE plt1_e;
+-- test partition matching with N-way join
+EXPLAIN (COSTS OFF)
+SELECT avg(t1.a), avg(t2.b), avg(t3.a + t3.b), t1.c, t2.c, t3.c FROM plt1 t1, plt2 t2, plt1_e t3 WHERE t1.b = t2.b AND t1.c = t2.c AND ltrim(t3.c, 'A') = t1.c GROUP BY t1.c, t2.c, t3.c ORDER BY t1.c, t2.c, t3.c;
+                                   QUERY PLAN                                   
+--------------------------------------------------------------------------------
+ GroupAggregate
+   Group Key: t1.c, t2.c, t3.c
+   ->  Sort
+         Sort Key: t1.c, t3.c
+         ->  Append
+               ->  Hash Join
+                     Hash Cond: (t1.c = ltrim(t3.c, 'A'::text))
+                     ->  Hash Join
+                           Hash Cond: ((t1.b = t2.b) AND (t1.c = t2.c))
+                           ->  Seq Scan on plt1_p1 t1
+                           ->  Hash
+                                 ->  Seq Scan on plt2_p1 t2
+                     ->  Hash
+                           ->  Seq Scan on plt1_e_p1 t3
+               ->  Hash Join
+                     Hash Cond: (t1_1.c = ltrim(t3_1.c, 'A'::text))
+                     ->  Hash Join
+                           Hash Cond: ((t1_1.b = t2_1.b) AND (t1_1.c = t2_1.c))
+                           ->  Seq Scan on plt1_p2 t1_1
+                           ->  Hash
+                                 ->  Seq Scan on plt2_p2 t2_1
+                     ->  Hash
+                           ->  Seq Scan on plt1_e_p2 t3_1
+               ->  Hash Join
+                     Hash Cond: (t1_2.c = ltrim(t3_2.c, 'A'::text))
+                     ->  Hash Join
+                           Hash Cond: ((t1_2.b = t2_2.b) AND (t1_2.c = t2_2.c))
+                           ->  Seq Scan on plt1_p3 t1_2
+                           ->  Hash
+                                 ->  Seq Scan on plt2_p3 t2_2
+                     ->  Hash
+                           ->  Seq Scan on plt1_e_p3 t3_2
+(32 rows)
+
+SELECT avg(t1.a), avg(t2.b), avg(t3.a + t3.b), t1.c, t2.c, t3.c FROM plt1 t1, plt2 t2, plt1_e t3 WHERE t1.b = t2.b AND t1.c = t2.c AND ltrim(t3.c, 'A') = t1.c GROUP BY t1.c, t2.c, t3.c ORDER BY t1.c, t2.c, t3.c;
+         avg          |         avg          |          avg          |  c   |  c   |   c   
+----------------------+----------------------+-----------------------+------+------+-------
+  24.0000000000000000 |  24.0000000000000000 |   48.0000000000000000 | 0000 | 0000 | A0000
+  75.0000000000000000 |  75.0000000000000000 |  148.0000000000000000 | 0001 | 0001 | A0001
+ 123.0000000000000000 | 123.0000000000000000 |  248.0000000000000000 | 0002 | 0002 | A0002
+ 174.0000000000000000 | 174.0000000000000000 |  348.0000000000000000 | 0003 | 0003 | A0003
+ 225.0000000000000000 | 225.0000000000000000 |  448.0000000000000000 | 0004 | 0004 | A0004
+ 273.0000000000000000 | 273.0000000000000000 |  548.0000000000000000 | 0005 | 0005 | A0005
+ 324.0000000000000000 | 324.0000000000000000 |  648.0000000000000000 | 0006 | 0006 | A0006
+ 375.0000000000000000 | 375.0000000000000000 |  748.0000000000000000 | 0007 | 0007 | A0007
+ 423.0000000000000000 | 423.0000000000000000 |  848.0000000000000000 | 0008 | 0008 | A0008
+ 474.0000000000000000 | 474.0000000000000000 |  948.0000000000000000 | 0009 | 0009 | A0009
+ 525.0000000000000000 | 525.0000000000000000 | 1048.0000000000000000 | 0010 | 0010 | A0010
+ 573.0000000000000000 | 573.0000000000000000 | 1148.0000000000000000 | 0011 | 0011 | A0011
+(12 rows)
+
+-- joins where one of the relations is proven empty
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1 t1, prt2 t2 WHERE t1.a = t2.b AND t1.a = 1 AND t1.a = 2;
+        QUERY PLAN        
+--------------------------
+ Result
+   One-Time Filter: false
+(2 rows)
+
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT * FROM prt1 WHERE a = 1 AND a = 2) t1 LEFT JOIN prt2 t2 ON t1.a = t2.b;
+        QUERY PLAN        
+--------------------------
+ Result
+   One-Time Filter: false
+(2 rows)
+
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT * FROM prt1 WHERE a = 1 AND a = 2) t1 RIGHT JOIN prt2 t2 ON t1.a = t2.b, prt1 t3 WHERE t2.b = t3.a;
+                    QUERY PLAN                    
+--------------------------------------------------
+ Hash Left Join
+   Hash Cond: (t2.b = a)
+   ->  Append
+         ->  Hash Join
+               Hash Cond: (t3.a = t2.b)
+               ->  Seq Scan on prt1_p1 t3
+               ->  Hash
+                     ->  Seq Scan on prt2_p1 t2
+         ->  Hash Join
+               Hash Cond: (t3_1.a = t2_1.b)
+               ->  Seq Scan on prt1_p2 t3_1
+               ->  Hash
+                     ->  Seq Scan on prt2_p2 t2_1
+         ->  Hash Join
+               Hash Cond: (t3_2.a = t2_2.b)
+               ->  Seq Scan on prt1_p3 t3_2
+               ->  Hash
+                     ->  Seq Scan on prt2_p3 t2_2
+   ->  Hash
+         ->  Result
+               One-Time Filter: false
+(21 rows)
+
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT * FROM prt1 WHERE a = 1 AND a = 2) t1 FULL JOIN prt2 t2 ON t1.a = t2.b WHERE t2.a = 0 ORDER BY t1.a, t2.b;
+                 QUERY PLAN                 
+--------------------------------------------
+ Sort
+   Sort Key: a, t2.b
+   ->  Hash Left Join
+         Hash Cond: (t2.b = a)
+         ->  Append
+               ->  Seq Scan on prt2_p1 t2
+                     Filter: (a = 0)
+               ->  Seq Scan on prt2_p2 t2_1
+                     Filter: (a = 0)
+               ->  Seq Scan on prt2_p3 t2_2
+                     Filter: (a = 0)
+         ->  Hash
+               ->  Result
+                     One-Time Filter: false
+(14 rows)
+
+--
+-- tests for hash partitioned tables.
+--
+CREATE TABLE pht1 (a int, b int, c text) PARTITION BY HASH(c);
+CREATE TABLE pht1_p1 PARTITION OF pht1 FOR VALUES WITH (MODULUS 3, REMAINDER 0);
+CREATE TABLE pht1_p2 PARTITION OF pht1 FOR VALUES WITH (MODULUS 3, REMAINDER 1);
+CREATE TABLE pht1_p3 PARTITION OF pht1 FOR VALUES WITH (MODULUS 3, REMAINDER 2);
+INSERT INTO pht1 SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(0, 599, 2) i;
+ANALYZE pht1;
+CREATE TABLE pht2 (a int, b int, c text) PARTITION BY HASH(c);
+CREATE TABLE pht2_p1 PARTITION OF pht2 FOR VALUES WITH (MODULUS 3, REMAINDER 0);
+CREATE TABLE pht2_p2 PARTITION OF pht2 FOR VALUES WITH (MODULUS 3, REMAINDER 1);
+CREATE TABLE pht2_p3 PARTITION OF pht2 FOR VALUES WITH (MODULUS 3, REMAINDER 2);
+INSERT INTO pht2 SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(0, 599, 3) i;
+ANALYZE pht2;
+--
+-- hash partitioned by expression
+--
+CREATE TABLE pht1_e (a int, b int, c text) PARTITION BY HASH(ltrim(c, 'A'));
+CREATE TABLE pht1_e_p1 PARTITION OF pht1_e FOR VALUES WITH (MODULUS 3, REMAINDER 0);
+CREATE TABLE pht1_e_p2 PARTITION OF pht1_e FOR VALUES WITH (MODULUS 3, REMAINDER 1);
+CREATE TABLE pht1_e_p3 PARTITION OF pht1_e FOR VALUES WITH (MODULUS 3, REMAINDER 2);
+INSERT INTO pht1_e SELECT i, i, 'A' || to_char(i/50, 'FM0000') FROM generate_series(0, 299, 2) i;
+ANALYZE pht1_e;
+-- test partition matching with N-way join
+EXPLAIN (COSTS OFF)
+SELECT avg(t1.a), avg(t2.b), avg(t3.a + t3.b), t1.c, t2.c, t3.c FROM pht1 t1, pht2 t2, pht1_e t3 WHERE t1.b = t2.b AND t1.c = t2.c AND ltrim(t3.c, 'A') = t1.c GROUP BY t1.c, t2.c, t3.c ORDER BY t1.c, t2.c, t3.c;
+                                   QUERY PLAN                                   
+--------------------------------------------------------------------------------
+ GroupAggregate
+   Group Key: t1.c, t2.c, t3.c
+   ->  Sort
+         Sort Key: t1.c, t3.c
+         ->  Append
+               ->  Hash Join
+                     Hash Cond: (t1.c = ltrim(t3.c, 'A'::text))
+                     ->  Hash Join
+                           Hash Cond: ((t1.b = t2.b) AND (t1.c = t2.c))
+                           ->  Seq Scan on pht1_p1 t1
+                           ->  Hash
+                                 ->  Seq Scan on pht2_p1 t2
+                     ->  Hash
+                           ->  Seq Scan on pht1_e_p1 t3
+               ->  Hash Join
+                     Hash Cond: (t1_1.c = ltrim(t3_1.c, 'A'::text))
+                     ->  Hash Join
+                           Hash Cond: ((t1_1.b = t2_1.b) AND (t1_1.c = t2_1.c))
+                           ->  Seq Scan on pht1_p2 t1_1
+                           ->  Hash
+                                 ->  Seq Scan on pht2_p2 t2_1
+                     ->  Hash
+                           ->  Seq Scan on pht1_e_p2 t3_1
+               ->  Hash Join
+                     Hash Cond: (t1_2.c = ltrim(t3_2.c, 'A'::text))
+                     ->  Hash Join
+                           Hash Cond: ((t1_2.b = t2_2.b) AND (t1_2.c = t2_2.c))
+                           ->  Seq Scan on pht1_p3 t1_2
+                           ->  Hash
+                                 ->  Seq Scan on pht2_p3 t2_2
+                     ->  Hash
+                           ->  Seq Scan on pht1_e_p3 t3_2
+(32 rows)
+
+SELECT avg(t1.a), avg(t2.b), avg(t3.a + t3.b), t1.c, t2.c, t3.c FROM pht1 t1, pht2 t2, pht1_e t3 WHERE t1.b = t2.b AND t1.c = t2.c AND ltrim(t3.c, 'A') = t1.c GROUP BY t1.c, t2.c, t3.c ORDER BY t1.c, t2.c, t3.c;
+         avg          |         avg          |         avg          |  c   |  c   |   c   
+----------------------+----------------------+----------------------+------+------+-------
+  24.0000000000000000 |  24.0000000000000000 |  48.0000000000000000 | 0000 | 0000 | A0000
+  75.0000000000000000 |  75.0000000000000000 | 148.0000000000000000 | 0001 | 0001 | A0001
+ 123.0000000000000000 | 123.0000000000000000 | 248.0000000000000000 | 0002 | 0002 | A0002
+ 174.0000000000000000 | 174.0000000000000000 | 348.0000000000000000 | 0003 | 0003 | A0003
+ 225.0000000000000000 | 225.0000000000000000 | 448.0000000000000000 | 0004 | 0004 | A0004
+ 273.0000000000000000 | 273.0000000000000000 | 548.0000000000000000 | 0005 | 0005 | A0005
+(6 rows)
+
+-- test default partition behavior for range
+ALTER TABLE prt1 DETACH PARTITION prt1_p3;
+ALTER TABLE prt1 ATTACH PARTITION prt1_p3 DEFAULT;
+ANALYZE prt1;
+ALTER TABLE prt2 DETACH PARTITION prt2_p3;
+ALTER TABLE prt2 ATTACH PARTITION prt2_p3 DEFAULT;
+ANALYZE prt2;
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1 t1, prt2 t2 WHERE t1.a = t2.b AND t1.b = 0 ORDER BY t1.a, t2.b;
+                    QUERY PLAN                    
+--------------------------------------------------
+ Sort
+   Sort Key: t1.a
+   ->  Append
+         ->  Hash Join
+               Hash Cond: (t2.b = t1.a)
+               ->  Seq Scan on prt2_p1 t2
+               ->  Hash
+                     ->  Seq Scan on prt1_p1 t1
+                           Filter: (b = 0)
+         ->  Hash Join
+               Hash Cond: (t2_1.b = t1_1.a)
+               ->  Seq Scan on prt2_p2 t2_1
+               ->  Hash
+                     ->  Seq Scan on prt1_p2 t1_1
+                           Filter: (b = 0)
+         ->  Hash Join
+               Hash Cond: (t2_2.b = t1_2.a)
+               ->  Seq Scan on prt2_p3 t2_2
+               ->  Hash
+                     ->  Seq Scan on prt1_p3 t1_2
+                           Filter: (b = 0)
+(21 rows)
+
+-- test default partition behavior for list
+ALTER TABLE plt1 DETACH PARTITION plt1_p3;
+ALTER TABLE plt1 ATTACH PARTITION plt1_p3 DEFAULT;
+ANALYZE plt1;
+ALTER TABLE plt2 DETACH PARTITION plt2_p3;
+ALTER TABLE plt2 ATTACH PARTITION plt2_p3 DEFAULT;
+ANALYZE plt2;
+EXPLAIN (COSTS OFF)
+SELECT avg(t1.a), avg(t2.b), t1.c, t2.c FROM plt1 t1 RIGHT JOIN plt2 t2 ON t1.c = t2.c WHERE t1.a % 25 = 0 GROUP BY t1.c, t2.c ORDER BY t1.c, t2.c;
+                       QUERY PLAN                       
+--------------------------------------------------------
+ Sort
+   Sort Key: t1.c
+   ->  HashAggregate
+         Group Key: t1.c, t2.c
+         ->  Append
+               ->  Hash Join
+                     Hash Cond: (t2.c = t1.c)
+                     ->  Seq Scan on plt2_p1 t2
+                     ->  Hash
+                           ->  Seq Scan on plt1_p1 t1
+                                 Filter: ((a % 25) = 0)
+               ->  Hash Join
+                     Hash Cond: (t2_1.c = t1_1.c)
+                     ->  Seq Scan on plt2_p2 t2_1
+                     ->  Hash
+                           ->  Seq Scan on plt1_p2 t1_1
+                                 Filter: ((a % 25) = 0)
+               ->  Hash Join
+                     Hash Cond: (t2_2.c = t1_2.c)
+                     ->  Seq Scan on plt2_p3 t2_2
+                     ->  Hash
+                           ->  Seq Scan on plt1_p3 t1_2
+                                 Filter: ((a % 25) = 0)
+(23 rows)
+
+--
+-- multiple levels of partitioning
+--
+CREATE TABLE prt1_l (a int, b int, c varchar) PARTITION BY RANGE(a);
+CREATE TABLE prt1_l_p1 PARTITION OF prt1_l FOR VALUES FROM (0) TO (250);
+CREATE TABLE prt1_l_p2 PARTITION OF prt1_l FOR VALUES FROM (250) TO (500) PARTITION BY LIST (c);
+CREATE TABLE prt1_l_p2_p1 PARTITION OF prt1_l_p2 FOR VALUES IN ('0000', '0001');
+CREATE TABLE prt1_l_p2_p2 PARTITION OF prt1_l_p2 FOR VALUES IN ('0002', '0003');
+CREATE TABLE prt1_l_p3 PARTITION OF prt1_l FOR VALUES FROM (500) TO (600) PARTITION BY RANGE (b);
+CREATE TABLE prt1_l_p3_p1 PARTITION OF prt1_l_p3 FOR VALUES FROM (0) TO (13);
+CREATE TABLE prt1_l_p3_p2 PARTITION OF prt1_l_p3 FOR VALUES FROM (13) TO (25);
+INSERT INTO prt1_l SELECT i, i % 25, to_char(i % 4, 'FM0000') FROM generate_series(0, 599, 2) i;
+ANALYZE prt1_l;
+CREATE TABLE prt2_l (a int, b int, c varchar) PARTITION BY RANGE(b);
+CREATE TABLE prt2_l_p1 PARTITION OF prt2_l FOR VALUES FROM (0) TO (250);
+CREATE TABLE prt2_l_p2 PARTITION OF prt2_l FOR VALUES FROM (250) TO (500) PARTITION BY LIST (c);
+CREATE TABLE prt2_l_p2_p1 PARTITION OF prt2_l_p2 FOR VALUES IN ('0000', '0001');
+CREATE TABLE prt2_l_p2_p2 PARTITION OF prt2_l_p2 FOR VALUES IN ('0002', '0003');
+CREATE TABLE prt2_l_p3 PARTITION OF prt2_l FOR VALUES FROM (500) TO (600) PARTITION BY RANGE (a);
+CREATE TABLE prt2_l_p3_p1 PARTITION OF prt2_l_p3 FOR VALUES FROM (0) TO (13);
+CREATE TABLE prt2_l_p3_p2 PARTITION OF prt2_l_p3 FOR VALUES FROM (13) TO (25);
+INSERT INTO prt2_l SELECT i % 25, i, to_char(i % 4, 'FM0000') FROM generate_series(0, 599, 3) i;
+ANALYZE prt2_l;
+-- inner join, qual covering only top-level partitions
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_l t1, prt2_l t2 WHERE t1.a = t2.b AND t1.b = 0 ORDER BY t1.a, t2.b;
+                         QUERY PLAN                          
+-------------------------------------------------------------
+ Sort
+   Sort Key: t1.a
+   ->  Append
+         ->  Hash Join
+               Hash Cond: (t2.b = t1.a)
+               ->  Seq Scan on prt2_l_p1 t2
+               ->  Hash
+                     ->  Seq Scan on prt1_l_p1 t1
+                           Filter: (b = 0)
+         ->  Hash Join
+               Hash Cond: (t2_1.b = t1_1.a)
+               ->  Append
+                     ->  Seq Scan on prt2_l_p2_p1 t2_1
+                     ->  Seq Scan on prt2_l_p2_p2 t2_2
+               ->  Hash
+                     ->  Append
+                           ->  Seq Scan on prt1_l_p2_p1 t1_1
+                                 Filter: (b = 0)
+                           ->  Seq Scan on prt1_l_p2_p2 t1_2
+                                 Filter: (b = 0)
+         ->  Hash Join
+               Hash Cond: (t2_3.b = t1_3.a)
+               ->  Append
+                     ->  Seq Scan on prt2_l_p3_p1 t2_3
+                     ->  Seq Scan on prt2_l_p3_p2 t2_4
+               ->  Hash
+                     ->  Seq Scan on prt1_l_p3_p1 t1_3
+                           Filter: (b = 0)
+(28 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_l t1, prt2_l t2 WHERE t1.a = t2.b AND t1.b = 0 ORDER BY t1.a, t2.b;
+  a  |  c   |  b  |  c   
+-----+------+-----+------
+   0 | 0000 |   0 | 0000
+ 150 | 0002 | 150 | 0002
+ 300 | 0000 | 300 | 0000
+ 450 | 0002 | 450 | 0002
+(4 rows)
+
+-- left join
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_l t1 LEFT JOIN prt2_l t2 ON t1.a = t2.b AND t1.c = t2.c WHERE t1.b = 0 ORDER BY t1.a, t2.b;
+                                     QUERY PLAN                                     
+------------------------------------------------------------------------------------
+ Sort
+   Sort Key: t1.a, t2.b
+   ->  Append
+         ->  Hash Right Join
+               Hash Cond: ((t2.b = t1.a) AND ((t2.c)::text = (t1.c)::text))
+               ->  Seq Scan on prt2_l_p1 t2
+               ->  Hash
+                     ->  Seq Scan on prt1_l_p1 t1
+                           Filter: (b = 0)
+         ->  Hash Right Join
+               Hash Cond: ((t2_1.b = t1_1.a) AND ((t2_1.c)::text = (t1_1.c)::text))
+               ->  Seq Scan on prt2_l_p2_p1 t2_1
+               ->  Hash
+                     ->  Seq Scan on prt1_l_p2_p1 t1_1
+                           Filter: (b = 0)
+         ->  Hash Right Join
+               Hash Cond: ((t2_2.b = t1_2.a) AND ((t2_2.c)::text = (t1_2.c)::text))
+               ->  Seq Scan on prt2_l_p2_p2 t2_2
+               ->  Hash
+                     ->  Seq Scan on prt1_l_p2_p2 t1_2
+                           Filter: (b = 0)
+         ->  Hash Right Join
+               Hash Cond: ((t2_3.b = t1_3.a) AND ((t2_3.c)::text = (t1_3.c)::text))
+               ->  Append
+                     ->  Seq Scan on prt2_l_p3_p1 t2_3
+                     ->  Seq Scan on prt2_l_p3_p2 t2_4
+               ->  Hash
+                     ->  Seq Scan on prt1_l_p3_p1 t1_3
+                           Filter: (b = 0)
+(29 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_l t1 LEFT JOIN prt2_l t2 ON t1.a = t2.b AND t1.c = t2.c WHERE t1.b = 0 ORDER BY t1.a, t2.b;
+  a  |  c   |  b  |  c   
+-----+------+-----+------
+   0 | 0000 |   0 | 0000
+  50 | 0002 |     | 
+ 100 | 0000 |     | 
+ 150 | 0002 | 150 | 0002
+ 200 | 0000 |     | 
+ 250 | 0002 |     | 
+ 300 | 0000 | 300 | 0000
+ 350 | 0002 |     | 
+ 400 | 0000 |     | 
+ 450 | 0002 | 450 | 0002
+ 500 | 0000 |     | 
+ 550 | 0002 |     | 
+(12 rows)
+
+-- right join
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_l t1 RIGHT JOIN prt2_l t2 ON t1.a = t2.b AND t1.c = t2.c WHERE t2.a = 0 ORDER BY t1.a, t2.b;
+                                     QUERY PLAN                                     
+------------------------------------------------------------------------------------
+ Sort
+   Sort Key: t1.a, t2.b
+   ->  Append
+         ->  Hash Right Join
+               Hash Cond: ((t1.a = t2.b) AND ((t1.c)::text = (t2.c)::text))
+               ->  Seq Scan on prt1_l_p1 t1
+               ->  Hash
+                     ->  Seq Scan on prt2_l_p1 t2
+                           Filter: (a = 0)
+         ->  Hash Right Join
+               Hash Cond: ((t1_1.a = t2_1.b) AND ((t1_1.c)::text = (t2_1.c)::text))
+               ->  Seq Scan on prt1_l_p2_p1 t1_1
+               ->  Hash
+                     ->  Seq Scan on prt2_l_p2_p1 t2_1
+                           Filter: (a = 0)
+         ->  Hash Right Join
+               Hash Cond: ((t1_2.a = t2_2.b) AND ((t1_2.c)::text = (t2_2.c)::text))
+               ->  Seq Scan on prt1_l_p2_p2 t1_2
+               ->  Hash
+                     ->  Seq Scan on prt2_l_p2_p2 t2_2
+                           Filter: (a = 0)
+         ->  Hash Right Join
+               Hash Cond: ((t1_3.a = t2_3.b) AND ((t1_3.c)::text = (t2_3.c)::text))
+               ->  Append
+                     ->  Seq Scan on prt1_l_p3_p1 t1_3
+                     ->  Seq Scan on prt1_l_p3_p2 t1_4
+               ->  Hash
+                     ->  Seq Scan on prt2_l_p3_p1 t2_3
+                           Filter: (a = 0)
+(29 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_l t1 RIGHT JOIN prt2_l t2 ON t1.a = t2.b AND t1.c = t2.c WHERE t2.a = 0 ORDER BY t1.a, t2.b;
+  a  |  c   |  b  |  c   
+-----+------+-----+------
+   0 | 0000 |   0 | 0000
+ 150 | 0002 | 150 | 0002
+ 300 | 0000 | 300 | 0000
+ 450 | 0002 | 450 | 0002
+     |      |  75 | 0003
+     |      | 225 | 0001
+     |      | 375 | 0003
+     |      | 525 | 0001
+(8 rows)
+
+-- full join
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT * FROM prt1_l WHERE prt1_l.b = 0) t1 FULL JOIN (SELECT * FROM prt2_l WHERE prt2_l.a = 0) t2 ON (t1.a = t2.b AND t1.c = t2.c) ORDER BY t1.a, t2.b;
+                                                     QUERY PLAN                                                     
+--------------------------------------------------------------------------------------------------------------------
+ Sort
+   Sort Key: prt1_l_p1.a, prt2_l_p1.b
+   ->  Append
+         ->  Hash Full Join
+               Hash Cond: ((prt1_l_p1.a = prt2_l_p1.b) AND ((prt1_l_p1.c)::text = (prt2_l_p1.c)::text))
+               ->  Seq Scan on prt1_l_p1
+                     Filter: (b = 0)
+               ->  Hash
+                     ->  Seq Scan on prt2_l_p1
+                           Filter: (a = 0)
+         ->  Hash Full Join
+               Hash Cond: ((prt1_l_p2_p1.a = prt2_l_p2_p1.b) AND ((prt1_l_p2_p1.c)::text = (prt2_l_p2_p1.c)::text))
+               ->  Seq Scan on prt1_l_p2_p1
+                     Filter: (b = 0)
+               ->  Hash
+                     ->  Seq Scan on prt2_l_p2_p1
+                           Filter: (a = 0)
+         ->  Hash Full Join
+               Hash Cond: ((prt1_l_p2_p2.a = prt2_l_p2_p2.b) AND ((prt1_l_p2_p2.c)::text = (prt2_l_p2_p2.c)::text))
+               ->  Seq Scan on prt1_l_p2_p2
+                     Filter: (b = 0)
+               ->  Hash
+                     ->  Seq Scan on prt2_l_p2_p2
+                           Filter: (a = 0)
+         ->  Hash Full Join
+               Hash Cond: ((prt1_l_p3_p1.a = prt2_l_p3_p1.b) AND ((prt1_l_p3_p1.c)::text = (prt2_l_p3_p1.c)::text))
+               ->  Seq Scan on prt1_l_p3_p1
+                     Filter: (b = 0)
+               ->  Hash
+                     ->  Seq Scan on prt2_l_p3_p1
+                           Filter: (a = 0)
+(31 rows)
+
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT * FROM prt1_l WHERE prt1_l.b = 0) t1 FULL JOIN (SELECT * FROM prt2_l WHERE prt2_l.a = 0) t2 ON (t1.a = t2.b AND t1.c = t2.c) ORDER BY t1.a, t2.b;
+  a  |  c   |  b  |  c   
+-----+------+-----+------
+   0 | 0000 |   0 | 0000
+  50 | 0002 |     | 
+ 100 | 0000 |     | 
+ 150 | 0002 | 150 | 0002
+ 200 | 0000 |     | 
+ 250 | 0002 |     | 
+ 300 | 0000 | 300 | 0000
+ 350 | 0002 |     | 
+ 400 | 0000 |     | 
+ 450 | 0002 | 450 | 0002
+ 500 | 0000 |     | 
+ 550 | 0002 |     | 
+     |      |  75 | 0003
+     |      | 225 | 0001
+     |      | 375 | 0003
+     |      | 525 | 0001
+(16 rows)
+
+-- lateral partitionwise join
+EXPLAIN (COSTS OFF)
+SELECT * FROM prt1_l t1 LEFT JOIN LATERAL
+			  (SELECT t2.a AS t2a, t2.c AS t2c, t2.b AS t2b, t3.b AS t3b, least(t1.a,t2.a,t3.b) FROM prt1_l t2 JOIN prt2_l t3 ON (t2.a = t3.b AND t2.c = t3.c)) ss
+			  ON t1.a = ss.t2a AND t1.c = ss.t2c WHERE t1.b = 0 ORDER BY t1.a;
+                                          QUERY PLAN                                           
+-----------------------------------------------------------------------------------------------
+ Sort
+   Sort Key: t1.a
+   ->  Append
+         ->  Nested Loop Left Join
+               ->  Seq Scan on prt1_l_p1 t1
+                     Filter: (b = 0)
+               ->  Hash Join
+                     Hash Cond: ((t3.b = t2.a) AND ((t3.c)::text = (t2.c)::text))
+                     ->  Seq Scan on prt2_l_p1 t3
+                     ->  Hash
+                           ->  Seq Scan on prt1_l_p1 t2
+                                 Filter: ((t1.a = a) AND ((t1.c)::text = (c)::text))
+         ->  Nested Loop Left Join
+               ->  Seq Scan on prt1_l_p2_p1 t1_1
+                     Filter: (b = 0)
+               ->  Hash Join
+                     Hash Cond: ((t3_1.b = t2_1.a) AND ((t3_1.c)::text = (t2_1.c)::text))
+                     ->  Seq Scan on prt2_l_p2_p1 t3_1
+                     ->  Hash
+                           ->  Seq Scan on prt1_l_p2_p1 t2_1
+                                 Filter: ((t1_1.a = a) AND ((t1_1.c)::text = (c)::text))
+         ->  Nested Loop Left Join
+               ->  Seq Scan on prt1_l_p2_p2 t1_2
+                     Filter: (b = 0)
+               ->  Hash Join
+                     Hash Cond: ((t3_2.b = t2_2.a) AND ((t3_2.c)::text = (t2_2.c)::text))
+                     ->  Seq Scan on prt2_l_p2_p2 t3_2
+                     ->  Hash
+                           ->  Seq Scan on prt1_l_p2_p2 t2_2
+                                 Filter: ((t1_2.a = a) AND ((t1_2.c)::text = (c)::text))
+         ->  Nested Loop Left Join
+               ->  Seq Scan on prt1_l_p3_p1 t1_3
+                     Filter: (b = 0)
+               ->  Hash Join
+                     Hash Cond: ((t3_3.b = t2_3.a) AND ((t3_3.c)::text = (t2_3.c)::text))
+                     ->  Append
+                           ->  Seq Scan on prt2_l_p3_p1 t3_3
+                           ->  Seq Scan on prt2_l_p3_p2 t3_4
+                     ->  Hash
+                           ->  Append
+                                 ->  Seq Scan on prt1_l_p3_p1 t2_3
+                                       Filter: ((t1_3.a = a) AND ((t1_3.c)::text = (c)::text))
+                                 ->  Seq Scan on prt1_l_p3_p2 t2_4
+                                       Filter: ((t1_3.a = a) AND ((t1_3.c)::text = (c)::text))
+(44 rows)
+
+SELECT * FROM prt1_l t1 LEFT JOIN LATERAL
+			  (SELECT t2.a AS t2a, t2.c AS t2c, t2.b AS t2b, t3.b AS t3b, least(t1.a,t2.a,t3.b) FROM prt1_l t2 JOIN prt2_l t3 ON (t2.a = t3.b AND t2.c = t3.c)) ss
+			  ON t1.a = ss.t2a AND t1.c = ss.t2c WHERE t1.b = 0 ORDER BY t1.a;
+  a  | b |  c   | t2a | t2c  | t2b | t3b | least 
+-----+---+------+-----+------+-----+-----+-------
+   0 | 0 | 0000 |   0 | 0000 |   0 |   0 |     0
+  50 | 0 | 0002 |     |      |     |     |      
+ 100 | 0 | 0000 |     |      |     |     |      
+ 150 | 0 | 0002 | 150 | 0002 |   0 | 150 |   150
+ 200 | 0 | 0000 |     |      |     |     |      
+ 250 | 0 | 0002 |     |      |     |     |      
+ 300 | 0 | 0000 | 300 | 0000 |   0 | 300 |   300
+ 350 | 0 | 0002 |     |      |     |     |      
+ 400 | 0 | 0000 |     |      |     |     |      
+ 450 | 0 | 0002 | 450 | 0002 |   0 | 450 |   450
+ 500 | 0 | 0000 |     |      |     |     |      
+ 550 | 0 | 0002 |     |      |     |     |      
+(12 rows)
+
+-- join with one side empty
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM (SELECT * FROM prt1_l WHERE a = 1 AND a = 2) t1 RIGHT JOIN prt2_l t2 ON t1.a = t2.b AND t1.b = t2.a AND t1.c = t2.c;
+                               QUERY PLAN                                
+-------------------------------------------------------------------------
+ Hash Left Join
+   Hash Cond: ((t2.b = a) AND (t2.a = b) AND ((t2.c)::text = (c)::text))
+   ->  Append
+         ->  Seq Scan on prt2_l_p1 t2
+         ->  Seq Scan on prt2_l_p2_p1 t2_1
+         ->  Seq Scan on prt2_l_p2_p2 t2_2
+         ->  Seq Scan on prt2_l_p3_p1 t2_3
+         ->  Seq Scan on prt2_l_p3_p2 t2_4
+   ->  Hash
+         ->  Result
+               One-Time Filter: false
+(11 rows)
+
+-- Test case to verify proper handling of subqueries in a partitioned delete.
+-- The weird-looking lateral join is just there to force creation of a
+-- nestloop parameter within the subquery, which exposes the problem if the
+-- planner fails to make multiple copies of the subquery as appropriate.
+EXPLAIN (COSTS OFF)
+DELETE FROM prt1_l
+WHERE EXISTS (
+  SELECT 1
+    FROM int4_tbl,
+         LATERAL (SELECT int4_tbl.f1 FROM int8_tbl LIMIT 2) ss
+    WHERE prt1_l.c IS NULL);
+                          QUERY PLAN                           
+---------------------------------------------------------------
+ Delete on prt1_l
+   Delete on prt1_l_p1
+   Delete on prt1_l_p3_p1
+   Delete on prt1_l_p3_p2
+   ->  Nested Loop Semi Join
+         ->  Seq Scan on prt1_l_p1
+               Filter: (c IS NULL)
+         ->  Nested Loop
+               ->  Seq Scan on int4_tbl
+               ->  Subquery Scan on ss
+                     ->  Limit
+                           ->  Seq Scan on int8_tbl
+   ->  Nested Loop Semi Join
+         ->  Seq Scan on prt1_l_p3_p1
+               Filter: (c IS NULL)
+         ->  Nested Loop
+               ->  Seq Scan on int4_tbl
+               ->  Subquery Scan on ss_1
+                     ->  Limit
+                           ->  Seq Scan on int8_tbl int8_tbl_1
+   ->  Nested Loop Semi Join
+         ->  Seq Scan on prt1_l_p3_p2
+               Filter: (c IS NULL)
+         ->  Nested Loop
+               ->  Seq Scan on int4_tbl
+               ->  Subquery Scan on ss_2
+                     ->  Limit
+                           ->  Seq Scan on int8_tbl int8_tbl_2
+(28 rows)
+
+--
+-- negative testcases
+--
+CREATE TABLE prt1_n (a int, b int, c varchar) PARTITION BY RANGE(c);
+CREATE TABLE prt1_n_p1 PARTITION OF prt1_n FOR VALUES FROM ('0000') TO ('0250');
+CREATE TABLE prt1_n_p2 PARTITION OF prt1_n FOR VALUES FROM ('0250') TO ('0500');
+INSERT INTO prt1_n SELECT i, i, to_char(i, 'FM0000') FROM generate_series(0, 499, 2) i;
+ANALYZE prt1_n;
+CREATE TABLE prt2_n (a int, b int, c text) PARTITION BY LIST(c);
+CREATE TABLE prt2_n_p1 PARTITION OF prt2_n FOR VALUES IN ('0000', '0003', '0004', '0010', '0006', '0007');
+CREATE TABLE prt2_n_p2 PARTITION OF prt2_n FOR VALUES IN ('0001', '0005', '0002', '0009', '0008', '0011');
+INSERT INTO prt2_n SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(0, 599, 2) i;
+ANALYZE prt2_n;
+CREATE TABLE prt3_n (a int, b int, c text) PARTITION BY LIST(c);
+CREATE TABLE prt3_n_p1 PARTITION OF prt3_n FOR VALUES IN ('0000', '0004', '0006', '0007');
+CREATE TABLE prt3_n_p2 PARTITION OF prt3_n FOR VALUES IN ('0001', '0002', '0008', '0010');
+CREATE TABLE prt3_n_p3 PARTITION OF prt3_n FOR VALUES IN ('0003', '0005', '0009', '0011');
+INSERT INTO prt2_n SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(0, 599, 2) i;
+ANALYZE prt3_n;
+CREATE TABLE prt4_n (a int, b int, c text) PARTITION BY RANGE(a);
+CREATE TABLE prt4_n_p1 PARTITION OF prt4_n FOR VALUES FROM (0) TO (300);
+CREATE TABLE prt4_n_p2 PARTITION OF prt4_n FOR VALUES FROM (300) TO (500);
+CREATE TABLE prt4_n_p3 PARTITION OF prt4_n FOR VALUES FROM (500) TO (600);
+INSERT INTO prt4_n SELECT i, i, to_char(i, 'FM0000') FROM generate_series(0, 599, 2) i;
+ANALYZE prt4_n;
+-- partitionwise join can not be applied if the partition ranges differ
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1 t1, prt4_n t2 WHERE t1.a = t2.a;
+                  QUERY PLAN                  
+----------------------------------------------
+ Hash Join
+   Hash Cond: (t1.a = t2.a)
+   ->  Append
+         ->  Seq Scan on prt1_p1 t1
+         ->  Seq Scan on prt1_p2 t1_1
+         ->  Seq Scan on prt1_p3 t1_2
+   ->  Hash
+         ->  Append
+               ->  Seq Scan on prt4_n_p1 t2
+               ->  Seq Scan on prt4_n_p2 t2_1
+               ->  Seq Scan on prt4_n_p3 t2_2
+(11 rows)
+
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1 t1, prt4_n t2, prt2 t3 WHERE t1.a = t2.a and t1.a = t3.b;
+                       QUERY PLAN                       
+--------------------------------------------------------
+ Hash Join
+   Hash Cond: (t2.a = t1.a)
+   ->  Append
+         ->  Seq Scan on prt4_n_p1 t2
+         ->  Seq Scan on prt4_n_p2 t2_1
+         ->  Seq Scan on prt4_n_p3 t2_2
+   ->  Hash
+         ->  Append
+               ->  Hash Join
+                     Hash Cond: (t1.a = t3.b)
+                     ->  Seq Scan on prt1_p1 t1
+                     ->  Hash
+                           ->  Seq Scan on prt2_p1 t3
+               ->  Hash Join
+                     Hash Cond: (t1_1.a = t3_1.b)
+                     ->  Seq Scan on prt1_p2 t1_1
+                     ->  Hash
+                           ->  Seq Scan on prt2_p2 t3_1
+               ->  Hash Join
+                     Hash Cond: (t1_2.a = t3_2.b)
+                     ->  Seq Scan on prt1_p3 t1_2
+                     ->  Hash
+                           ->  Seq Scan on prt2_p3 t3_2
+(23 rows)
+
+-- partitionwise join can not be applied if there are no equi-join conditions
+-- between partition keys
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1 t1 LEFT JOIN prt2 t2 ON (t1.a < t2.b);
+                       QUERY PLAN                        
+---------------------------------------------------------
+ Nested Loop Left Join
+   ->  Append
+         ->  Seq Scan on prt1_p1 t1
+         ->  Seq Scan on prt1_p2 t1_1
+         ->  Seq Scan on prt1_p3 t1_2
+   ->  Append
+         ->  Index Scan using iprt2_p1_b on prt2_p1 t2
+               Index Cond: (b > t1.a)
+         ->  Index Scan using iprt2_p2_b on prt2_p2 t2_1
+               Index Cond: (b > t1.a)
+         ->  Index Scan using iprt2_p3_b on prt2_p3 t2_2
+               Index Cond: (b > t1.a)
+(12 rows)
+
+-- equi-join with join condition on partial keys does not qualify for
+-- partitionwise join
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_m t1, prt2_m t2 WHERE t1.a = (t2.b + t2.a)/2;
+                  QUERY PLAN                  
+----------------------------------------------
+ Hash Join
+   Hash Cond: (((t2.b + t2.a) / 2) = t1.a)
+   ->  Append
+         ->  Seq Scan on prt2_m_p1 t2
+         ->  Seq Scan on prt2_m_p2 t2_1
+         ->  Seq Scan on prt2_m_p3 t2_2
+   ->  Hash
+         ->  Append
+               ->  Seq Scan on prt1_m_p1 t1
+               ->  Seq Scan on prt1_m_p2 t1_1
+               ->  Seq Scan on prt1_m_p3 t1_2
+(11 rows)
+
+-- equi-join between out-of-order partition key columns does not qualify for
+-- partitionwise join
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_m t1 LEFT JOIN prt2_m t2 ON t1.a = t2.b;
+                  QUERY PLAN                  
+----------------------------------------------
+ Hash Left Join
+   Hash Cond: (t1.a = t2.b)
+   ->  Append
+         ->  Seq Scan on prt1_m_p1 t1
+         ->  Seq Scan on prt1_m_p2 t1_1
+         ->  Seq Scan on prt1_m_p3 t1_2
+   ->  Hash
+         ->  Append
+               ->  Seq Scan on prt2_m_p1 t2
+               ->  Seq Scan on prt2_m_p2 t2_1
+               ->  Seq Scan on prt2_m_p3 t2_2
+(11 rows)
+
+-- equi-join between non-key columns does not qualify for partitionwise join
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_m t1 LEFT JOIN prt2_m t2 ON t1.c = t2.c;
+                  QUERY PLAN                  
+----------------------------------------------
+ Hash Left Join
+   Hash Cond: (t1.c = t2.c)
+   ->  Append
+         ->  Seq Scan on prt1_m_p1 t1
+         ->  Seq Scan on prt1_m_p2 t1_1
+         ->  Seq Scan on prt1_m_p3 t1_2
+   ->  Hash
+         ->  Append
+               ->  Seq Scan on prt2_m_p1 t2
+               ->  Seq Scan on prt2_m_p2 t2_1
+               ->  Seq Scan on prt2_m_p3 t2_2
+(11 rows)
+
+-- partitionwise join can not be applied between tables with different
+-- partition lists
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_n t1 LEFT JOIN prt2_n t2 ON (t1.c = t2.c);
+                  QUERY PLAN                  
+----------------------------------------------
+ Hash Right Join
+   Hash Cond: (t2.c = (t1.c)::text)
+   ->  Append
+         ->  Seq Scan on prt2_n_p1 t2
+         ->  Seq Scan on prt2_n_p2 t2_1
+   ->  Hash
+         ->  Append
+               ->  Seq Scan on prt1_n_p1 t1
+               ->  Seq Scan on prt1_n_p2 t1_1
+(9 rows)
+
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_n t1 JOIN prt2_n t2 ON (t1.c = t2.c) JOIN plt1 t3 ON (t1.c = t3.c);
+                        QUERY PLAN                        
+----------------------------------------------------------
+ Hash Join
+   Hash Cond: (t3.c = (t1.c)::text)
+   ->  Append
+         ->  Seq Scan on plt1_p1 t3
+         ->  Seq Scan on plt1_p2 t3_1
+         ->  Seq Scan on plt1_p3 t3_2
+   ->  Hash
+         ->  Hash Join
+               Hash Cond: (t2.c = (t1.c)::text)
+               ->  Append
+                     ->  Seq Scan on prt2_n_p1 t2
+                     ->  Seq Scan on prt2_n_p2 t2_1
+               ->  Hash
+                     ->  Append
+                           ->  Seq Scan on prt1_n_p1 t1
+                           ->  Seq Scan on prt1_n_p2 t1_1
+(16 rows)
+
+-- partitionwise join can not be applied for a join between list and range
+-- partitioned table
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1_n t1 FULL JOIN prt1 t2 ON (t1.c = t2.c);
+                  QUERY PLAN                  
+----------------------------------------------
+ Hash Full Join
+   Hash Cond: ((t2.c)::text = (t1.c)::text)
+   ->  Append
+         ->  Seq Scan on prt1_p1 t2
+         ->  Seq Scan on prt1_p2 t2_1
+         ->  Seq Scan on prt1_p3 t2_2
+   ->  Hash
+         ->  Append
+               ->  Seq Scan on prt1_n_p1 t1
+               ->  Seq Scan on prt1_n_p2 t1_1
+(10 rows)
+
+-- partitionwise join can not be applied if only one of joining table has
+-- default partition
+ALTER TABLE prt2 DETACH PARTITION prt2_p3;
+ALTER TABLE prt2 ATTACH PARTITION prt2_p3 FOR VALUES FROM (500) TO (600);
+ANALYZE prt2;
+EXPLAIN (COSTS OFF)
+SELECT t1.a, t1.c, t2.b, t2.c FROM prt1 t1, prt2 t2 WHERE t1.a = t2.b AND t1.b = 0 ORDER BY t1.a, t2.b;
+                    QUERY PLAN                    
+--------------------------------------------------
+ Sort
+   Sort Key: t1.a
+   ->  Hash Join
+         Hash Cond: (t2.b = t1.a)
+         ->  Append
+               ->  Seq Scan on prt2_p1 t2
+               ->  Seq Scan on prt2_p2 t2_1
+               ->  Seq Scan on prt2_p3 t2_2
+         ->  Hash
+               ->  Append
+                     ->  Seq Scan on prt1_p1 t1
+                           Filter: (b = 0)
+                     ->  Seq Scan on prt1_p2 t1_1
+                           Filter: (b = 0)
+                     ->  Seq Scan on prt1_p3 t1_2
+                           Filter: (b = 0)
+(16 rows)
+
diff --git a/src/test/regress/expected/plpgsql.out b/src/test/regress/expected/plpgsql.out
index e85b294..44e67be 100644
--- a/src/test/regress/expected/plpgsql.out
+++ b/src/test/regress/expected/plpgsql.out
@@ -1615,15 +1615,15 @@ select test_found();
  t
 (1 row)
 
-select * from found_test_tbl;
+select * from found_test_tbl order by a;
   a  
 -----
    2
- 100
    3
    4
    5
    6
+ 100
 (6 rows)
 
 --
@@ -1638,15 +1638,15 @@ BEGIN
 	END LOOP;
 	RETURN;
 END;' language plpgsql;
-select * from test_table_func_rec();
+select * from test_table_func_rec() order by a;
   a  
 -----
    2
- 100
    3
    4
    5
    6
+ 100
 (6 rows)
 
 create function test_table_func_row() returns setof found_test_tbl as '
@@ -1658,15 +1658,15 @@ BEGIN
 	END LOOP;
 	RETURN;
 END;' language plpgsql;
-select * from test_table_func_row();
+select * from test_table_func_row() order by a;
   a  
 -----
    2
- 100
    3
    4
    5
    6
+ 100
 (6 rows)
 
 create function test_ret_set_scalar(int,int) returns setof int as '
diff --git a/src/test/regress/expected/plpgsql_1.out b/src/test/regress/expected/plpgsql_1.out
new file mode 100644
index 0000000..864d103
--- /dev/null
+++ b/src/test/regress/expected/plpgsql_1.out
@@ -0,0 +1,5766 @@
+--
+-- PLPGSQL
+--
+-- Scenario:
+--
+--     A building with a modern TP cable installation where any
+--     of the wall connectors can be used to plug in phones,
+--     ethernet interfaces or local office hubs. The backside
+--     of the wall connectors is wired to one of several patch-
+--     fields in the building.
+--
+--     In the patchfields, there are hubs and all the slots
+--     representing the wall connectors. In addition there are
+--     slots that can represent a phone line from the central
+--     phone system.
+--
+--     Triggers ensure consistency of the patching information.
+--
+--     Functions are used to build up powerful views that let
+--     you look behind the wall when looking at a patchfield
+--     or into a room.
+--
+create table Room (
+    roomno	char(8),
+    comment	text
+);
+create unique index Room_rno on Room using btree (roomno bpchar_ops);
+create table WSlot (
+    slotname	char(20),
+    roomno	char(8),
+    slotlink	char(20),
+    backlink	char(20)
+);
+create unique index WSlot_name on WSlot using btree (slotname bpchar_ops);
+create table PField (
+    name	text,
+    comment	text
+);
+create unique index PField_name on PField using btree (name text_ops);
+create table PSlot (
+    slotname	char(20),
+    pfname	text,
+    slotlink	char(20),
+    backlink	char(20)
+);
+create unique index PSlot_name on PSlot using btree (slotname bpchar_ops);
+create table PLine (
+    slotname	char(20),
+    phonenumber	char(20),
+    comment	text,
+    backlink	char(20)
+);
+create unique index PLine_name on PLine using btree (slotname bpchar_ops);
+create table Hub (
+    name	char(14),
+    comment	text,
+    nslots	integer
+);
+create unique index Hub_name on Hub using btree (name bpchar_ops);
+create table HSlot (
+    slotname	char(20),
+    hubname	char(14),
+    slotno	integer,
+    slotlink	char(20)
+);
+create unique index HSlot_name on HSlot using btree (slotname bpchar_ops);
+create index HSlot_hubname on HSlot using btree (hubname bpchar_ops);
+create table System (
+    name	text,
+    comment	text
+);
+create unique index System_name on System using btree (name text_ops);
+create table IFace (
+    slotname	char(20),
+    sysname	text,
+    ifname	text,
+    slotlink	char(20)
+);
+create unique index IFace_name on IFace using btree (slotname bpchar_ops);
+create table PHone (
+    slotname	char(20),
+    comment	text,
+    slotlink	char(20)
+);
+create unique index PHone_name on PHone using btree (slotname bpchar_ops);
+-- ************************************************************
+-- *
+-- * Trigger procedures and functions for the patchfield
+-- * test of PL/pgSQL
+-- *
+-- ************************************************************
+-- ************************************************************
+-- * AFTER UPDATE on Room
+-- *	- If room no changes let wall slots follow
+-- ************************************************************
+create function tg_room_au() returns trigger as '
+begin
+    if new.roomno != old.roomno then
+        update WSlot set roomno = new.roomno where roomno = old.roomno;
+    end if;
+    return new;
+end;
+' language plpgsql;
+create trigger tg_room_au after update
+    on Room for each row execute procedure tg_room_au();
+-- ************************************************************
+-- * AFTER DELETE on Room
+-- *	- delete wall slots in this room
+-- ************************************************************
+create function tg_room_ad() returns trigger as '
+begin
+    delete from WSlot where roomno = old.roomno;
+    return old;
+end;
+' language plpgsql;
+create trigger tg_room_ad after delete
+    on Room for each row execute procedure tg_room_ad();
+-- ************************************************************
+-- * BEFORE INSERT or UPDATE on WSlot
+-- *	- Check that room exists
+-- ************************************************************
+create function tg_wslot_biu() returns trigger as $$
+begin
+    if count(*) = 0 from Room where roomno = new.roomno then
+        raise exception 'Room % does not exist', new.roomno;
+    end if;
+    return new;
+end;
+$$ language plpgsql;
+create trigger tg_wslot_biu before insert or update
+    on WSlot for each row execute procedure tg_wslot_biu();
+-- ************************************************************
+-- * AFTER UPDATE on PField
+-- *	- Let PSlots of this field follow
+-- ************************************************************
+create function tg_pfield_au() returns trigger as '
+begin
+    if new.name != old.name then
+        update PSlot set pfname = new.name where pfname = old.name;
+    end if;
+    return new;
+end;
+' language plpgsql;
+create trigger tg_pfield_au after update
+    on PField for each row execute procedure tg_pfield_au();
+-- ************************************************************
+-- * AFTER DELETE on PField
+-- *	- Remove all slots of this patchfield
+-- ************************************************************
+create function tg_pfield_ad() returns trigger as '
+begin
+    delete from PSlot where pfname = old.name;
+    return old;
+end;
+' language plpgsql;
+create trigger tg_pfield_ad after delete
+    on PField for each row execute procedure tg_pfield_ad();
+-- ************************************************************
+-- * BEFORE INSERT or UPDATE on PSlot
+-- *	- Ensure that our patchfield does exist
+-- ************************************************************
+create function tg_pslot_biu() returns trigger as $proc$
+declare
+    pfrec	record;
+    ps          alias for new;
+begin
+    select into pfrec * from PField where name = ps.pfname;
+    if not found then
+        raise exception $$Patchfield "%" does not exist$$, ps.pfname;
+    end if;
+    return ps;
+end;
+$proc$ language plpgsql;
+create trigger tg_pslot_biu before insert or update
+    on PSlot for each row execute procedure tg_pslot_biu();
+-- ************************************************************
+-- * AFTER UPDATE on System
+-- *	- If system name changes let interfaces follow
+-- ************************************************************
+create function tg_system_au() returns trigger as '
+begin
+    if new.name != old.name then
+        update IFace set sysname = new.name where sysname = old.name;
+    end if;
+    return new;
+end;
+' language plpgsql;
+create trigger tg_system_au after update
+    on System for each row execute procedure tg_system_au();
+-- ************************************************************
+-- * BEFORE INSERT or UPDATE on IFace
+-- *	- set the slotname to IF.sysname.ifname
+-- ************************************************************
+create function tg_iface_biu() returns trigger as $$
+declare
+    sname	text;
+    sysrec	record;
+begin
+    select into sysrec * from system where name = new.sysname;
+    if not found then
+        raise exception $q$system "%" does not exist$q$, new.sysname;
+    end if;
+    sname := 'IF.' || new.sysname;
+    sname := sname || '.';
+    sname := sname || new.ifname;
+    if length(sname) > 20 then
+        raise exception 'IFace slotname "%" too long (20 char max)', sname;
+    end if;
+    new.slotname := sname;
+    return new;
+end;
+$$ language plpgsql;
+create trigger tg_iface_biu before insert or update
+    on IFace for each row execute procedure tg_iface_biu();
+-- ************************************************************
+-- * AFTER INSERT or UPDATE or DELETE on Hub
+-- *	- insert/delete/rename slots as required
+-- ************************************************************
+create function tg_hub_a() returns trigger as '
+declare
+    hname	text;
+    dummy	integer;
+begin
+    if tg_op = ''INSERT'' then
+	dummy := tg_hub_adjustslots(new.name, 0, new.nslots);
+	return new;
+    end if;
+    if tg_op = ''UPDATE'' then
+	if new.name != old.name then
+	    update HSlot set hubname = new.name where hubname = old.name;
+	end if;
+	dummy := tg_hub_adjustslots(new.name, old.nslots, new.nslots);
+	return new;
+    end if;
+    if tg_op = ''DELETE'' then
+	dummy := tg_hub_adjustslots(old.name, old.nslots, 0);
+	return old;
+    end if;
+end;
+' language plpgsql;
+create trigger tg_hub_a after insert or update or delete
+    on Hub for each row execute procedure tg_hub_a();
+-- ************************************************************
+-- * Support function to add/remove slots of Hub
+-- ************************************************************
+create function tg_hub_adjustslots(hname bpchar,
+                                   oldnslots integer,
+                                   newnslots integer)
+returns integer as '
+begin
+    if newnslots = oldnslots then
+        return 0;
+    end if;
+    if newnslots < oldnslots then
+        delete from HSlot where hubname = hname and slotno > newnslots;
+	return 0;
+    end if;
+    for i in oldnslots + 1 .. newnslots loop
+        insert into HSlot (slotname, hubname, slotno, slotlink)
+		values (''HS.dummy'', hname, i, '''');
+    end loop;
+    return 0;
+end
+' language plpgsql;
+-- Test comments
+COMMENT ON FUNCTION tg_hub_adjustslots_wrong(bpchar, integer, integer) IS 'function with args';
+ERROR:  function tg_hub_adjustslots_wrong(character, integer, integer) does not exist
+COMMENT ON FUNCTION tg_hub_adjustslots(bpchar, integer, integer) IS 'function with args';
+COMMENT ON FUNCTION tg_hub_adjustslots(bpchar, integer, integer) IS NULL;
+-- ************************************************************
+-- * BEFORE INSERT or UPDATE on HSlot
+-- *	- prevent from manual manipulation
+-- *	- set the slotname to HS.hubname.slotno
+-- ************************************************************
+create function tg_hslot_biu() returns trigger as '
+declare
+    sname	text;
+    xname	HSlot.slotname%TYPE;
+    hubrec	record;
+begin
+    select into hubrec * from Hub where name = new.hubname;
+    if not found then
+        raise exception ''no manual manipulation of HSlot'';
+    end if;
+    if new.slotno < 1 or new.slotno > hubrec.nslots then
+        raise exception ''no manual manipulation of HSlot'';
+    end if;
+    if tg_op = ''UPDATE'' and new.hubname != old.hubname then
+	if count(*) > 0 from Hub where name = old.hubname then
+	    raise exception ''no manual manipulation of HSlot'';
+	end if;
+    end if;
+    sname := ''HS.'' || trim(new.hubname);
+    sname := sname || ''.'';
+    sname := sname || new.slotno::text;
+    if length(sname) > 20 then
+        raise exception ''HSlot slotname "%" too long (20 char max)'', sname;
+    end if;
+    new.slotname := sname;
+    return new;
+end;
+' language plpgsql;
+create trigger tg_hslot_biu before insert or update
+    on HSlot for each row execute procedure tg_hslot_biu();
+-- ************************************************************
+-- * BEFORE DELETE on HSlot
+-- *	- prevent from manual manipulation
+-- ************************************************************
+create function tg_hslot_bd() returns trigger as '
+declare
+    hubrec	record;
+begin
+    select into hubrec * from Hub where name = old.hubname;
+    if not found then
+        return old;
+    end if;
+    if old.slotno > hubrec.nslots then
+        return old;
+    end if;
+    raise exception ''no manual manipulation of HSlot'';
+end;
+' language plpgsql;
+create trigger tg_hslot_bd before delete
+    on HSlot for each row execute procedure tg_hslot_bd();
+-- ************************************************************
+-- * BEFORE INSERT on all slots
+-- *	- Check name prefix
+-- ************************************************************
+create function tg_chkslotname() returns trigger as '
+begin
+    if substr(new.slotname, 1, 2) != tg_argv[0] then
+        raise exception ''slotname must begin with %'', tg_argv[0];
+    end if;
+    return new;
+end;
+' language plpgsql;
+create trigger tg_chkslotname before insert
+    on PSlot for each row execute procedure tg_chkslotname('PS');
+create trigger tg_chkslotname before insert
+    on WSlot for each row execute procedure tg_chkslotname('WS');
+create trigger tg_chkslotname before insert
+    on PLine for each row execute procedure tg_chkslotname('PL');
+create trigger tg_chkslotname before insert
+    on IFace for each row execute procedure tg_chkslotname('IF');
+create trigger tg_chkslotname before insert
+    on PHone for each row execute procedure tg_chkslotname('PH');
+-- ************************************************************
+-- * BEFORE INSERT or UPDATE on all slots with slotlink
+-- *	- Set slotlink to empty string if NULL value given
+-- ************************************************************
+create function tg_chkslotlink() returns trigger as '
+begin
+    if new.slotlink isnull then
+        new.slotlink := '''';
+    end if;
+    return new;
+end;
+' language plpgsql;
+create trigger tg_chkslotlink before insert or update
+    on PSlot for each row execute procedure tg_chkslotlink();
+create trigger tg_chkslotlink before insert or update
+    on WSlot for each row execute procedure tg_chkslotlink();
+create trigger tg_chkslotlink before insert or update
+    on IFace for each row execute procedure tg_chkslotlink();
+create trigger tg_chkslotlink before insert or update
+    on HSlot for each row execute procedure tg_chkslotlink();
+create trigger tg_chkslotlink before insert or update
+    on PHone for each row execute procedure tg_chkslotlink();
+-- ************************************************************
+-- * BEFORE INSERT or UPDATE on all slots with backlink
+-- *	- Set backlink to empty string if NULL value given
+-- ************************************************************
+create function tg_chkbacklink() returns trigger as '
+begin
+    if new.backlink isnull then
+        new.backlink := '''';
+    end if;
+    return new;
+end;
+' language plpgsql;
+create trigger tg_chkbacklink before insert or update
+    on PSlot for each row execute procedure tg_chkbacklink();
+create trigger tg_chkbacklink before insert or update
+    on WSlot for each row execute procedure tg_chkbacklink();
+create trigger tg_chkbacklink before insert or update
+    on PLine for each row execute procedure tg_chkbacklink();
+-- ************************************************************
+-- * BEFORE UPDATE on PSlot
+-- *	- do delete/insert instead of update if name changes
+-- ************************************************************
+create function tg_pslot_bu() returns trigger as '
+begin
+    if new.slotname != old.slotname then
+        delete from PSlot where slotname = old.slotname;
+	insert into PSlot (
+		    slotname,
+		    pfname,
+		    slotlink,
+		    backlink
+		) values (
+		    new.slotname,
+		    new.pfname,
+		    new.slotlink,
+		    new.backlink
+		);
+        return null;
+    end if;
+    return new;
+end;
+' language plpgsql;
+create trigger tg_pslot_bu before update
+    on PSlot for each row execute procedure tg_pslot_bu();
+-- ************************************************************
+-- * BEFORE UPDATE on WSlot
+-- *	- do delete/insert instead of update if name changes
+-- ************************************************************
+create function tg_wslot_bu() returns trigger as '
+begin
+    if new.slotname != old.slotname then
+        delete from WSlot where slotname = old.slotname;
+	insert into WSlot (
+		    slotname,
+		    roomno,
+		    slotlink,
+		    backlink
+		) values (
+		    new.slotname,
+		    new.roomno,
+		    new.slotlink,
+		    new.backlink
+		);
+        return null;
+    end if;
+    return new;
+end;
+' language plpgsql;
+create trigger tg_wslot_bu before update
+    on WSlot for each row execute procedure tg_Wslot_bu();
+-- ************************************************************
+-- * BEFORE UPDATE on PLine
+-- *	- do delete/insert instead of update if name changes
+-- ************************************************************
+create function tg_pline_bu() returns trigger as '
+begin
+    if new.slotname != old.slotname then
+        delete from PLine where slotname = old.slotname;
+	insert into PLine (
+		    slotname,
+		    phonenumber,
+		    comment,
+		    backlink
+		) values (
+		    new.slotname,
+		    new.phonenumber,
+		    new.comment,
+		    new.backlink
+		);
+        return null;
+    end if;
+    return new;
+end;
+' language plpgsql;
+create trigger tg_pline_bu before update
+    on PLine for each row execute procedure tg_pline_bu();
+-- ************************************************************
+-- * BEFORE UPDATE on IFace
+-- *	- do delete/insert instead of update if name changes
+-- ************************************************************
+create function tg_iface_bu() returns trigger as '
+begin
+    if new.slotname != old.slotname then
+        delete from IFace where slotname = old.slotname;
+	insert into IFace (
+		    slotname,
+		    sysname,
+		    ifname,
+		    slotlink
+		) values (
+		    new.slotname,
+		    new.sysname,
+		    new.ifname,
+		    new.slotlink
+		);
+        return null;
+    end if;
+    return new;
+end;
+' language plpgsql;
+create trigger tg_iface_bu before update
+    on IFace for each row execute procedure tg_iface_bu();
+-- ************************************************************
+-- * BEFORE UPDATE on HSlot
+-- *	- do delete/insert instead of update if name changes
+-- ************************************************************
+create function tg_hslot_bu() returns trigger as '
+begin
+    if new.slotname != old.slotname or new.hubname != old.hubname then
+        delete from HSlot where slotname = old.slotname;
+	insert into HSlot (
+		    slotname,
+		    hubname,
+		    slotno,
+		    slotlink
+		) values (
+		    new.slotname,
+		    new.hubname,
+		    new.slotno,
+		    new.slotlink
+		);
+        return null;
+    end if;
+    return new;
+end;
+' language plpgsql;
+create trigger tg_hslot_bu before update
+    on HSlot for each row execute procedure tg_hslot_bu();
+-- ************************************************************
+-- * BEFORE UPDATE on PHone
+-- *	- do delete/insert instead of update if name changes
+-- ************************************************************
+create function tg_phone_bu() returns trigger as '
+begin
+    if new.slotname != old.slotname then
+        delete from PHone where slotname = old.slotname;
+	insert into PHone (
+		    slotname,
+		    comment,
+		    slotlink
+		) values (
+		    new.slotname,
+		    new.comment,
+		    new.slotlink
+		);
+        return null;
+    end if;
+    return new;
+end;
+' language plpgsql;
+create trigger tg_phone_bu before update
+    on PHone for each row execute procedure tg_phone_bu();
+-- ************************************************************
+-- * AFTER INSERT or UPDATE or DELETE on slot with backlink
+-- *	- Ensure that the opponent correctly points back to us
+-- ************************************************************
+create function tg_backlink_a() returns trigger as '
+declare
+    dummy	integer;
+begin
+    if tg_op = ''INSERT'' then
+        if new.backlink != '''' then
+	    dummy := tg_backlink_set(new.backlink, new.slotname);
+	end if;
+	return new;
+    end if;
+    if tg_op = ''UPDATE'' then
+        if new.backlink != old.backlink then
+	    if old.backlink != '''' then
+	        dummy := tg_backlink_unset(old.backlink, old.slotname);
+	    end if;
+	    if new.backlink != '''' then
+	        dummy := tg_backlink_set(new.backlink, new.slotname);
+	    end if;
+	else
+	    if new.slotname != old.slotname and new.backlink != '''' then
+	        dummy := tg_slotlink_set(new.backlink, new.slotname);
+	    end if;
+	end if;
+	return new;
+    end if;
+    if tg_op = ''DELETE'' then
+        if old.backlink != '''' then
+	    dummy := tg_backlink_unset(old.backlink, old.slotname);
+	end if;
+	return old;
+    end if;
+end;
+' language plpgsql;
+create trigger tg_backlink_a after insert or update or delete
+    on PSlot for each row execute procedure tg_backlink_a('PS');
+create trigger tg_backlink_a after insert or update or delete
+    on WSlot for each row execute procedure tg_backlink_a('WS');
+create trigger tg_backlink_a after insert or update or delete
+    on PLine for each row execute procedure tg_backlink_a('PL');
+-- ************************************************************
+-- * Support function to set the opponents backlink field
+-- * if it does not already point to the requested slot
+-- ************************************************************
+create function tg_backlink_set(myname bpchar, blname bpchar)
+returns integer as '
+declare
+    mytype	char(2);
+    link	char(4);
+    rec		record;
+begin
+    mytype := substr(myname, 1, 2);
+    link := mytype || substr(blname, 1, 2);
+    if link = ''PLPL'' then
+        raise exception
+		''backlink between two phone lines does not make sense'';
+    end if;
+    if link in (''PLWS'', ''WSPL'') then
+        raise exception
+		''direct link of phone line to wall slot not permitted'';
+    end if;
+    if mytype = ''PS'' then
+        select into rec * from PSlot where slotname = myname;
+	if not found then
+	    raise exception ''% does not exist'', myname;
+	end if;
+	if rec.backlink != blname then
+	    update PSlot set backlink = blname where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    if mytype = ''WS'' then
+        select into rec * from WSlot where slotname = myname;
+	if not found then
+	    raise exception ''% does not exist'', myname;
+	end if;
+	if rec.backlink != blname then
+	    update WSlot set backlink = blname where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    if mytype = ''PL'' then
+        select into rec * from PLine where slotname = myname;
+	if not found then
+	    raise exception ''% does not exist'', myname;
+	end if;
+	if rec.backlink != blname then
+	    update PLine set backlink = blname where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    raise exception ''illegal backlink beginning with %'', mytype;
+end;
+' language plpgsql;
+-- ************************************************************
+-- * Support function to clear out the backlink field if
+-- * it still points to specific slot
+-- ************************************************************
+create function tg_backlink_unset(bpchar, bpchar)
+returns integer as '
+declare
+    myname	alias for $1;
+    blname	alias for $2;
+    mytype	char(2);
+    rec		record;
+begin
+    mytype := substr(myname, 1, 2);
+    if mytype = ''PS'' then
+        select into rec * from PSlot where slotname = myname;
+	if not found then
+	    return 0;
+	end if;
+	if rec.backlink = blname then
+	    update PSlot set backlink = '''' where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    if mytype = ''WS'' then
+        select into rec * from WSlot where slotname = myname;
+	if not found then
+	    return 0;
+	end if;
+	if rec.backlink = blname then
+	    update WSlot set backlink = '''' where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    if mytype = ''PL'' then
+        select into rec * from PLine where slotname = myname;
+	if not found then
+	    return 0;
+	end if;
+	if rec.backlink = blname then
+	    update PLine set backlink = '''' where slotname = myname;
+	end if;
+	return 0;
+    end if;
+end
+' language plpgsql;
+-- ************************************************************
+-- * AFTER INSERT or UPDATE or DELETE on slot with slotlink
+-- *	- Ensure that the opponent correctly points back to us
+-- ************************************************************
+create function tg_slotlink_a() returns trigger as '
+declare
+    dummy	integer;
+begin
+    if tg_op = ''INSERT'' then
+        if new.slotlink != '''' then
+	    dummy := tg_slotlink_set(new.slotlink, new.slotname);
+	end if;
+	return new;
+    end if;
+    if tg_op = ''UPDATE'' then
+        if new.slotlink != old.slotlink then
+	    if old.slotlink != '''' then
+	        dummy := tg_slotlink_unset(old.slotlink, old.slotname);
+	    end if;
+	    if new.slotlink != '''' then
+	        dummy := tg_slotlink_set(new.slotlink, new.slotname);
+	    end if;
+	else
+	    if new.slotname != old.slotname and new.slotlink != '''' then
+	        dummy := tg_slotlink_set(new.slotlink, new.slotname);
+	    end if;
+	end if;
+	return new;
+    end if;
+    if tg_op = ''DELETE'' then
+        if old.slotlink != '''' then
+	    dummy := tg_slotlink_unset(old.slotlink, old.slotname);
+	end if;
+	return old;
+    end if;
+end;
+' language plpgsql;
+create trigger tg_slotlink_a after insert or update or delete
+    on PSlot for each row execute procedure tg_slotlink_a('PS');
+create trigger tg_slotlink_a after insert or update or delete
+    on WSlot for each row execute procedure tg_slotlink_a('WS');
+create trigger tg_slotlink_a after insert or update or delete
+    on IFace for each row execute procedure tg_slotlink_a('IF');
+create trigger tg_slotlink_a after insert or update or delete
+    on HSlot for each row execute procedure tg_slotlink_a('HS');
+create trigger tg_slotlink_a after insert or update or delete
+    on PHone for each row execute procedure tg_slotlink_a('PH');
+-- ************************************************************
+-- * Support function to set the opponents slotlink field
+-- * if it does not already point to the requested slot
+-- ************************************************************
+create function tg_slotlink_set(bpchar, bpchar)
+returns integer as '
+declare
+    myname	alias for $1;
+    blname	alias for $2;
+    mytype	char(2);
+    link	char(4);
+    rec		record;
+begin
+    mytype := substr(myname, 1, 2);
+    link := mytype || substr(blname, 1, 2);
+    if link = ''PHPH'' then
+        raise exception
+		''slotlink between two phones does not make sense'';
+    end if;
+    if link in (''PHHS'', ''HSPH'') then
+        raise exception
+		''link of phone to hub does not make sense'';
+    end if;
+    if link in (''PHIF'', ''IFPH'') then
+        raise exception
+		''link of phone to hub does not make sense'';
+    end if;
+    if link in (''PSWS'', ''WSPS'') then
+        raise exception
+		''slotlink from patchslot to wallslot not permitted'';
+    end if;
+    if mytype = ''PS'' then
+        select into rec * from PSlot where slotname = myname;
+	if not found then
+	    raise exception ''% does not exist'', myname;
+	end if;
+	if rec.slotlink != blname then
+	    update PSlot set slotlink = blname where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    if mytype = ''WS'' then
+        select into rec * from WSlot where slotname = myname;
+	if not found then
+	    raise exception ''% does not exist'', myname;
+	end if;
+	if rec.slotlink != blname then
+	    update WSlot set slotlink = blname where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    if mytype = ''IF'' then
+        select into rec * from IFace where slotname = myname;
+	if not found then
+	    raise exception ''% does not exist'', myname;
+	end if;
+	if rec.slotlink != blname then
+	    update IFace set slotlink = blname where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    if mytype = ''HS'' then
+        select into rec * from HSlot where slotname = myname;
+	if not found then
+	    raise exception ''% does not exist'', myname;
+	end if;
+	if rec.slotlink != blname then
+	    update HSlot set slotlink = blname where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    if mytype = ''PH'' then
+        select into rec * from PHone where slotname = myname;
+	if not found then
+	    raise exception ''% does not exist'', myname;
+	end if;
+	if rec.slotlink != blname then
+	    update PHone set slotlink = blname where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    raise exception ''illegal slotlink beginning with %'', mytype;
+end;
+' language plpgsql;
+-- ************************************************************
+-- * Support function to clear out the slotlink field if
+-- * it still points to specific slot
+-- ************************************************************
+create function tg_slotlink_unset(bpchar, bpchar)
+returns integer as '
+declare
+    myname	alias for $1;
+    blname	alias for $2;
+    mytype	char(2);
+    rec		record;
+begin
+    mytype := substr(myname, 1, 2);
+    if mytype = ''PS'' then
+        select into rec * from PSlot where slotname = myname;
+	if not found then
+	    return 0;
+	end if;
+	if rec.slotlink = blname then
+	    update PSlot set slotlink = '''' where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    if mytype = ''WS'' then
+        select into rec * from WSlot where slotname = myname;
+	if not found then
+	    return 0;
+	end if;
+	if rec.slotlink = blname then
+	    update WSlot set slotlink = '''' where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    if mytype = ''IF'' then
+        select into rec * from IFace where slotname = myname;
+	if not found then
+	    return 0;
+	end if;
+	if rec.slotlink = blname then
+	    update IFace set slotlink = '''' where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    if mytype = ''HS'' then
+        select into rec * from HSlot where slotname = myname;
+	if not found then
+	    return 0;
+	end if;
+	if rec.slotlink = blname then
+	    update HSlot set slotlink = '''' where slotname = myname;
+	end if;
+	return 0;
+    end if;
+    if mytype = ''PH'' then
+        select into rec * from PHone where slotname = myname;
+	if not found then
+	    return 0;
+	end if;
+	if rec.slotlink = blname then
+	    update PHone set slotlink = '''' where slotname = myname;
+	end if;
+	return 0;
+    end if;
+end;
+' language plpgsql;
+-- ************************************************************
+-- * Describe the backside of a patchfield slot
+-- ************************************************************
+create function pslot_backlink_view(bpchar)
+returns text as '
+<<outer>>
+declare
+    rec		record;
+    bltype	char(2);
+    retval	text;
+begin
+    select into rec * from PSlot where slotname = $1;
+    if not found then
+        return '''';
+    end if;
+    if rec.backlink = '''' then
+        return ''-'';
+    end if;
+    bltype := substr(rec.backlink, 1, 2);
+    if bltype = ''PL'' then
+        declare
+	    rec		record;
+	begin
+	    select into rec * from PLine where slotname = "outer".rec.backlink;
+	    retval := ''Phone line '' || trim(rec.phonenumber);
+	    if rec.comment != '''' then
+	        retval := retval || '' ('';
+		retval := retval || rec.comment;
+		retval := retval || '')'';
+	    end if;
+	    return retval;
+	end;
+    end if;
+    if bltype = ''WS'' then
+        select into rec * from WSlot where slotname = rec.backlink;
+	retval := trim(rec.slotname) || '' in room '';
+	retval := retval || trim(rec.roomno);
+	retval := retval || '' -> '';
+	return retval || wslot_slotlink_view(rec.slotname);
+    end if;
+    return rec.backlink;
+end;
+' language plpgsql;
+-- ************************************************************
+-- * Describe the front of a patchfield slot
+-- ************************************************************
+create function pslot_slotlink_view(bpchar)
+returns text as '
+declare
+    psrec	record;
+    sltype	char(2);
+    retval	text;
+begin
+    select into psrec * from PSlot where slotname = $1;
+    if not found then
+        return '''';
+    end if;
+    if psrec.slotlink = '''' then
+        return ''-'';
+    end if;
+    sltype := substr(psrec.slotlink, 1, 2);
+    if sltype = ''PS'' then
+	retval := trim(psrec.slotlink) || '' -> '';
+	return retval || pslot_backlink_view(psrec.slotlink);
+    end if;
+    if sltype = ''HS'' then
+        retval := comment from Hub H, HSlot HS
+			where HS.slotname = psrec.slotlink
+			  and H.name = HS.hubname;
+        retval := retval || '' slot '';
+	retval := retval || slotno::text from HSlot
+			where slotname = psrec.slotlink;
+	return retval;
+    end if;
+    return psrec.slotlink;
+end;
+' language plpgsql;
+-- ************************************************************
+-- * Describe the front of a wall connector slot
+-- ************************************************************
+create function wslot_slotlink_view(bpchar)
+returns text as '
+declare
+    rec		record;
+    sltype	char(2);
+    retval	text;
+begin
+    select into rec * from WSlot where slotname = $1;
+    if not found then
+        return '''';
+    end if;
+    if rec.slotlink = '''' then
+        return ''-'';
+    end if;
+    sltype := substr(rec.slotlink, 1, 2);
+    if sltype = ''PH'' then
+        select into rec * from PHone where slotname = rec.slotlink;
+	retval := ''Phone '' || trim(rec.slotname);
+	if rec.comment != '''' then
+	    retval := retval || '' ('';
+	    retval := retval || rec.comment;
+	    retval := retval || '')'';
+	end if;
+	return retval;
+    end if;
+    if sltype = ''IF'' then
+	declare
+	    syrow	System%RowType;
+	    ifrow	IFace%ROWTYPE;
+        begin
+	    select into ifrow * from IFace where slotname = rec.slotlink;
+	    select into syrow * from System where name = ifrow.sysname;
+	    retval := syrow.name || '' IF '';
+	    retval := retval || ifrow.ifname;
+	    if syrow.comment != '''' then
+	        retval := retval || '' ('';
+		retval := retval || syrow.comment;
+		retval := retval || '')'';
+	    end if;
+	    return retval;
+	end;
+    end if;
+    return rec.slotlink;
+end;
+' language plpgsql;
+-- ************************************************************
+-- * View of a patchfield describing backside and patches
+-- ************************************************************
+create view Pfield_v1 as select PF.pfname, PF.slotname,
+	pslot_backlink_view(PF.slotname) as backside,
+	pslot_slotlink_view(PF.slotname) as patch
+    from PSlot PF;
+--
+-- First we build the house - so we create the rooms
+--
+insert into Room values ('001', 'Entrance');
+insert into Room values ('002', 'Office');
+insert into Room values ('003', 'Office');
+insert into Room values ('004', 'Technical');
+insert into Room values ('101', 'Office');
+insert into Room values ('102', 'Conference');
+insert into Room values ('103', 'Restroom');
+insert into Room values ('104', 'Technical');
+insert into Room values ('105', 'Office');
+insert into Room values ('106', 'Office');
+--
+-- Second we install the wall connectors
+--
+insert into WSlot values ('WS.001.1a', '001', '', '');
+insert into WSlot values ('WS.001.1b', '001', '', '');
+insert into WSlot values ('WS.001.2a', '001', '', '');
+insert into WSlot values ('WS.001.2b', '001', '', '');
+insert into WSlot values ('WS.001.3a', '001', '', '');
+insert into WSlot values ('WS.001.3b', '001', '', '');
+insert into WSlot values ('WS.002.1a', '002', '', '');
+insert into WSlot values ('WS.002.1b', '002', '', '');
+insert into WSlot values ('WS.002.2a', '002', '', '');
+insert into WSlot values ('WS.002.2b', '002', '', '');
+insert into WSlot values ('WS.002.3a', '002', '', '');
+insert into WSlot values ('WS.002.3b', '002', '', '');
+insert into WSlot values ('WS.003.1a', '003', '', '');
+insert into WSlot values ('WS.003.1b', '003', '', '');
+insert into WSlot values ('WS.003.2a', '003', '', '');
+insert into WSlot values ('WS.003.2b', '003', '', '');
+insert into WSlot values ('WS.003.3a', '003', '', '');
+insert into WSlot values ('WS.003.3b', '003', '', '');
+insert into WSlot values ('WS.101.1a', '101', '', '');
+insert into WSlot values ('WS.101.1b', '101', '', '');
+insert into WSlot values ('WS.101.2a', '101', '', '');
+insert into WSlot values ('WS.101.2b', '101', '', '');
+insert into WSlot values ('WS.101.3a', '101', '', '');
+insert into WSlot values ('WS.101.3b', '101', '', '');
+insert into WSlot values ('WS.102.1a', '102', '', '');
+insert into WSlot values ('WS.102.1b', '102', '', '');
+insert into WSlot values ('WS.102.2a', '102', '', '');
+insert into WSlot values ('WS.102.2b', '102', '', '');
+insert into WSlot values ('WS.102.3a', '102', '', '');
+insert into WSlot values ('WS.102.3b', '102', '', '');
+insert into WSlot values ('WS.105.1a', '105', '', '');
+insert into WSlot values ('WS.105.1b', '105', '', '');
+insert into WSlot values ('WS.105.2a', '105', '', '');
+insert into WSlot values ('WS.105.2b', '105', '', '');
+insert into WSlot values ('WS.105.3a', '105', '', '');
+insert into WSlot values ('WS.105.3b', '105', '', '');
+insert into WSlot values ('WS.106.1a', '106', '', '');
+insert into WSlot values ('WS.106.1b', '106', '', '');
+insert into WSlot values ('WS.106.2a', '106', '', '');
+insert into WSlot values ('WS.106.2b', '106', '', '');
+insert into WSlot values ('WS.106.3a', '106', '', '');
+insert into WSlot values ('WS.106.3b', '106', '', '');
+--
+-- Now create the patch fields and their slots
+--
+insert into PField values ('PF0_1', 'Wallslots basement');
+--
+-- The cables for these will be made later, so they are unconnected for now
+--
+insert into PSlot values ('PS.base.a1', 'PF0_1', '', '');
+insert into PSlot values ('PS.base.a2', 'PF0_1', '', '');
+insert into PSlot values ('PS.base.a3', 'PF0_1', '', '');
+insert into PSlot values ('PS.base.a4', 'PF0_1', '', '');
+insert into PSlot values ('PS.base.a5', 'PF0_1', '', '');
+insert into PSlot values ('PS.base.a6', 'PF0_1', '', '');
+--
+-- These are already wired to the wall connectors
+--
+insert into PSlot values ('PS.base.b1', 'PF0_1', '', 'WS.002.1a');
+insert into PSlot values ('PS.base.b2', 'PF0_1', '', 'WS.002.1b');
+insert into PSlot values ('PS.base.b3', 'PF0_1', '', 'WS.002.2a');
+insert into PSlot values ('PS.base.b4', 'PF0_1', '', 'WS.002.2b');
+insert into PSlot values ('PS.base.b5', 'PF0_1', '', 'WS.002.3a');
+insert into PSlot values ('PS.base.b6', 'PF0_1', '', 'WS.002.3b');
+insert into PSlot values ('PS.base.c1', 'PF0_1', '', 'WS.003.1a');
+insert into PSlot values ('PS.base.c2', 'PF0_1', '', 'WS.003.1b');
+insert into PSlot values ('PS.base.c3', 'PF0_1', '', 'WS.003.2a');
+insert into PSlot values ('PS.base.c4', 'PF0_1', '', 'WS.003.2b');
+insert into PSlot values ('PS.base.c5', 'PF0_1', '', 'WS.003.3a');
+insert into PSlot values ('PS.base.c6', 'PF0_1', '', 'WS.003.3b');
+--
+-- This patchfield will be renamed later into PF0_2 - so its
+-- slots references in pfname should follow
+--
+insert into PField values ('PF0_X', 'Phonelines basement');
+insert into PSlot values ('PS.base.ta1', 'PF0_X', '', '');
+insert into PSlot values ('PS.base.ta2', 'PF0_X', '', '');
+insert into PSlot values ('PS.base.ta3', 'PF0_X', '', '');
+insert into PSlot values ('PS.base.ta4', 'PF0_X', '', '');
+insert into PSlot values ('PS.base.ta5', 'PF0_X', '', '');
+insert into PSlot values ('PS.base.ta6', 'PF0_X', '', '');
+insert into PSlot values ('PS.base.tb1', 'PF0_X', '', '');
+insert into PSlot values ('PS.base.tb2', 'PF0_X', '', '');
+insert into PSlot values ('PS.base.tb3', 'PF0_X', '', '');
+insert into PSlot values ('PS.base.tb4', 'PF0_X', '', '');
+insert into PSlot values ('PS.base.tb5', 'PF0_X', '', '');
+insert into PSlot values ('PS.base.tb6', 'PF0_X', '', '');
+insert into PField values ('PF1_1', 'Wallslots first floor');
+insert into PSlot values ('PS.first.a1', 'PF1_1', '', 'WS.101.1a');
+insert into PSlot values ('PS.first.a2', 'PF1_1', '', 'WS.101.1b');
+insert into PSlot values ('PS.first.a3', 'PF1_1', '', 'WS.101.2a');
+insert into PSlot values ('PS.first.a4', 'PF1_1', '', 'WS.101.2b');
+insert into PSlot values ('PS.first.a5', 'PF1_1', '', 'WS.101.3a');
+insert into PSlot values ('PS.first.a6', 'PF1_1', '', 'WS.101.3b');
+insert into PSlot values ('PS.first.b1', 'PF1_1', '', 'WS.102.1a');
+insert into PSlot values ('PS.first.b2', 'PF1_1', '', 'WS.102.1b');
+insert into PSlot values ('PS.first.b3', 'PF1_1', '', 'WS.102.2a');
+insert into PSlot values ('PS.first.b4', 'PF1_1', '', 'WS.102.2b');
+insert into PSlot values ('PS.first.b5', 'PF1_1', '', 'WS.102.3a');
+insert into PSlot values ('PS.first.b6', 'PF1_1', '', 'WS.102.3b');
+insert into PSlot values ('PS.first.c1', 'PF1_1', '', 'WS.105.1a');
+insert into PSlot values ('PS.first.c2', 'PF1_1', '', 'WS.105.1b');
+insert into PSlot values ('PS.first.c3', 'PF1_1', '', 'WS.105.2a');
+insert into PSlot values ('PS.first.c4', 'PF1_1', '', 'WS.105.2b');
+insert into PSlot values ('PS.first.c5', 'PF1_1', '', 'WS.105.3a');
+insert into PSlot values ('PS.first.c6', 'PF1_1', '', 'WS.105.3b');
+insert into PSlot values ('PS.first.d1', 'PF1_1', '', 'WS.106.1a');
+insert into PSlot values ('PS.first.d2', 'PF1_1', '', 'WS.106.1b');
+insert into PSlot values ('PS.first.d3', 'PF1_1', '', 'WS.106.2a');
+insert into PSlot values ('PS.first.d4', 'PF1_1', '', 'WS.106.2b');
+insert into PSlot values ('PS.first.d5', 'PF1_1', '', 'WS.106.3a');
+insert into PSlot values ('PS.first.d6', 'PF1_1', '', 'WS.106.3b');
+--
+-- Now we wire the wall connectors 1a-2a in room 001 to the
+-- patchfield. In the second update we make an error, and
+-- correct it after
+--
+update PSlot set backlink = 'WS.001.1a' where slotname = 'PS.base.a1';
+update PSlot set backlink = 'WS.001.1b' where slotname = 'PS.base.a3';
+select * from WSlot where roomno = '001' order by slotname;
+       slotname       |  roomno  |       slotlink       |       backlink       
+----------------------+----------+----------------------+----------------------
+ WS.001.1a            | 001      |                      | PS.base.a1          
+ WS.001.1b            | 001      |                      | PS.base.a3          
+ WS.001.2a            | 001      |                      |                     
+ WS.001.2b            | 001      |                      |                     
+ WS.001.3a            | 001      |                      |                     
+ WS.001.3b            | 001      |                      |                     
+(6 rows)
+
+select * from PSlot where slotname ~ 'PS.base.a' order by slotname;
+       slotname       | pfname |       slotlink       |       backlink       
+----------------------+--------+----------------------+----------------------
+ PS.base.a1           | PF0_1  |                      | WS.001.1a           
+ PS.base.a2           | PF0_1  |                      |                     
+ PS.base.a3           | PF0_1  |                      | WS.001.1b           
+ PS.base.a4           | PF0_1  |                      |                     
+ PS.base.a5           | PF0_1  |                      |                     
+ PS.base.a6           | PF0_1  |                      |                     
+(6 rows)
+
+update PSlot set backlink = 'WS.001.2a' where slotname = 'PS.base.a3';
+select * from WSlot where roomno = '001' order by slotname;
+       slotname       |  roomno  |       slotlink       |       backlink       
+----------------------+----------+----------------------+----------------------
+ WS.001.1a            | 001      |                      | PS.base.a1          
+ WS.001.1b            | 001      |                      |                     
+ WS.001.2a            | 001      |                      | PS.base.a3          
+ WS.001.2b            | 001      |                      |                     
+ WS.001.3a            | 001      |                      |                     
+ WS.001.3b            | 001      |                      |                     
+(6 rows)
+
+select * from PSlot where slotname ~ 'PS.base.a' order by slotname;
+       slotname       | pfname |       slotlink       |       backlink       
+----------------------+--------+----------------------+----------------------
+ PS.base.a1           | PF0_1  |                      | WS.001.1a           
+ PS.base.a2           | PF0_1  |                      |                     
+ PS.base.a3           | PF0_1  |                      | WS.001.2a           
+ PS.base.a4           | PF0_1  |                      |                     
+ PS.base.a5           | PF0_1  |                      |                     
+ PS.base.a6           | PF0_1  |                      |                     
+(6 rows)
+
+update PSlot set backlink = 'WS.001.1b' where slotname = 'PS.base.a2';
+select * from WSlot where roomno = '001' order by slotname;
+       slotname       |  roomno  |       slotlink       |       backlink       
+----------------------+----------+----------------------+----------------------
+ WS.001.1a            | 001      |                      | PS.base.a1          
+ WS.001.1b            | 001      |                      | PS.base.a2          
+ WS.001.2a            | 001      |                      | PS.base.a3          
+ WS.001.2b            | 001      |                      |                     
+ WS.001.3a            | 001      |                      |                     
+ WS.001.3b            | 001      |                      |                     
+(6 rows)
+
+select * from PSlot where slotname ~ 'PS.base.a' order by slotname;
+       slotname       | pfname |       slotlink       |       backlink       
+----------------------+--------+----------------------+----------------------
+ PS.base.a1           | PF0_1  |                      | WS.001.1a           
+ PS.base.a2           | PF0_1  |                      | WS.001.1b           
+ PS.base.a3           | PF0_1  |                      | WS.001.2a           
+ PS.base.a4           | PF0_1  |                      |                     
+ PS.base.a5           | PF0_1  |                      |                     
+ PS.base.a6           | PF0_1  |                      |                     
+(6 rows)
+
+--
+-- Same procedure for 2b-3b but this time updating the WSlot instead
+-- of the PSlot. Due to the triggers the result is the same:
+-- WSlot and corresponding PSlot point to each other.
+--
+update WSlot set backlink = 'PS.base.a4' where slotname = 'WS.001.2b';
+update WSlot set backlink = 'PS.base.a6' where slotname = 'WS.001.3a';
+select * from WSlot where roomno = '001' order by slotname;
+       slotname       |  roomno  |       slotlink       |       backlink       
+----------------------+----------+----------------------+----------------------
+ WS.001.1a            | 001      |                      | PS.base.a1          
+ WS.001.1b            | 001      |                      | PS.base.a2          
+ WS.001.2a            | 001      |                      | PS.base.a3          
+ WS.001.2b            | 001      |                      | PS.base.a4          
+ WS.001.3a            | 001      |                      | PS.base.a6          
+ WS.001.3b            | 001      |                      |                     
+(6 rows)
+
+select * from PSlot where slotname ~ 'PS.base.a' order by slotname;
+       slotname       | pfname |       slotlink       |       backlink       
+----------------------+--------+----------------------+----------------------
+ PS.base.a1           | PF0_1  |                      | WS.001.1a           
+ PS.base.a2           | PF0_1  |                      | WS.001.1b           
+ PS.base.a3           | PF0_1  |                      | WS.001.2a           
+ PS.base.a4           | PF0_1  |                      | WS.001.2b           
+ PS.base.a5           | PF0_1  |                      |                     
+ PS.base.a6           | PF0_1  |                      | WS.001.3a           
+(6 rows)
+
+update WSlot set backlink = 'PS.base.a6' where slotname = 'WS.001.3b';
+select * from WSlot where roomno = '001' order by slotname;
+       slotname       |  roomno  |       slotlink       |       backlink       
+----------------------+----------+----------------------+----------------------
+ WS.001.1a            | 001      |                      | PS.base.a1          
+ WS.001.1b            | 001      |                      | PS.base.a2          
+ WS.001.2a            | 001      |                      | PS.base.a3          
+ WS.001.2b            | 001      |                      | PS.base.a4          
+ WS.001.3a            | 001      |                      |                     
+ WS.001.3b            | 001      |                      | PS.base.a6          
+(6 rows)
+
+select * from PSlot where slotname ~ 'PS.base.a' order by slotname;
+       slotname       | pfname |       slotlink       |       backlink       
+----------------------+--------+----------------------+----------------------
+ PS.base.a1           | PF0_1  |                      | WS.001.1a           
+ PS.base.a2           | PF0_1  |                      | WS.001.1b           
+ PS.base.a3           | PF0_1  |                      | WS.001.2a           
+ PS.base.a4           | PF0_1  |                      | WS.001.2b           
+ PS.base.a5           | PF0_1  |                      |                     
+ PS.base.a6           | PF0_1  |                      | WS.001.3b           
+(6 rows)
+
+update WSlot set backlink = 'PS.base.a5' where slotname = 'WS.001.3a';
+select * from WSlot where roomno = '001' order by slotname;
+       slotname       |  roomno  |       slotlink       |       backlink       
+----------------------+----------+----------------------+----------------------
+ WS.001.1a            | 001      |                      | PS.base.a1          
+ WS.001.1b            | 001      |                      | PS.base.a2          
+ WS.001.2a            | 001      |                      | PS.base.a3          
+ WS.001.2b            | 001      |                      | PS.base.a4          
+ WS.001.3a            | 001      |                      | PS.base.a5          
+ WS.001.3b            | 001      |                      | PS.base.a6          
+(6 rows)
+
+select * from PSlot where slotname ~ 'PS.base.a' order by slotname;
+       slotname       | pfname |       slotlink       |       backlink       
+----------------------+--------+----------------------+----------------------
+ PS.base.a1           | PF0_1  |                      | WS.001.1a           
+ PS.base.a2           | PF0_1  |                      | WS.001.1b           
+ PS.base.a3           | PF0_1  |                      | WS.001.2a           
+ PS.base.a4           | PF0_1  |                      | WS.001.2b           
+ PS.base.a5           | PF0_1  |                      | WS.001.3a           
+ PS.base.a6           | PF0_1  |                      | WS.001.3b           
+(6 rows)
+
+insert into PField values ('PF1_2', 'Phonelines first floor');
+insert into PSlot values ('PS.first.ta1', 'PF1_2', '', '');
+insert into PSlot values ('PS.first.ta2', 'PF1_2', '', '');
+insert into PSlot values ('PS.first.ta3', 'PF1_2', '', '');
+insert into PSlot values ('PS.first.ta4', 'PF1_2', '', '');
+insert into PSlot values ('PS.first.ta5', 'PF1_2', '', '');
+insert into PSlot values ('PS.first.ta6', 'PF1_2', '', '');
+insert into PSlot values ('PS.first.tb1', 'PF1_2', '', '');
+insert into PSlot values ('PS.first.tb2', 'PF1_2', '', '');
+insert into PSlot values ('PS.first.tb3', 'PF1_2', '', '');
+insert into PSlot values ('PS.first.tb4', 'PF1_2', '', '');
+insert into PSlot values ('PS.first.tb5', 'PF1_2', '', '');
+insert into PSlot values ('PS.first.tb6', 'PF1_2', '', '');
+--
+-- Fix the wrong name for patchfield PF0_2
+--
+update PField set name = 'PF0_2' where name = 'PF0_X';
+select * from PSlot order by slotname;
+       slotname       | pfname |       slotlink       |       backlink       
+----------------------+--------+----------------------+----------------------
+ PS.base.a1           | PF0_1  |                      | WS.001.1a           
+ PS.base.a2           | PF0_1  |                      | WS.001.1b           
+ PS.base.a3           | PF0_1  |                      | WS.001.2a           
+ PS.base.a4           | PF0_1  |                      | WS.001.2b           
+ PS.base.a5           | PF0_1  |                      | WS.001.3a           
+ PS.base.a6           | PF0_1  |                      | WS.001.3b           
+ PS.base.b1           | PF0_1  |                      | WS.002.1a           
+ PS.base.b2           | PF0_1  |                      | WS.002.1b           
+ PS.base.b3           | PF0_1  |                      | WS.002.2a           
+ PS.base.b4           | PF0_1  |                      | WS.002.2b           
+ PS.base.b5           | PF0_1  |                      | WS.002.3a           
+ PS.base.b6           | PF0_1  |                      | WS.002.3b           
+ PS.base.c1           | PF0_1  |                      | WS.003.1a           
+ PS.base.c2           | PF0_1  |                      | WS.003.1b           
+ PS.base.c3           | PF0_1  |                      | WS.003.2a           
+ PS.base.c4           | PF0_1  |                      | WS.003.2b           
+ PS.base.c5           | PF0_1  |                      | WS.003.3a           
+ PS.base.c6           | PF0_1  |                      | WS.003.3b           
+ PS.base.ta1          | PF0_2  |                      |                     
+ PS.base.ta2          | PF0_2  |                      |                     
+ PS.base.ta3          | PF0_2  |                      |                     
+ PS.base.ta4          | PF0_2  |                      |                     
+ PS.base.ta5          | PF0_2  |                      |                     
+ PS.base.ta6          | PF0_2  |                      |                     
+ PS.base.tb1          | PF0_2  |                      |                     
+ PS.base.tb2          | PF0_2  |                      |                     
+ PS.base.tb3          | PF0_2  |                      |                     
+ PS.base.tb4          | PF0_2  |                      |                     
+ PS.base.tb5          | PF0_2  |                      |                     
+ PS.base.tb6          | PF0_2  |                      |                     
+ PS.first.a1          | PF1_1  |                      | WS.101.1a           
+ PS.first.a2          | PF1_1  |                      | WS.101.1b           
+ PS.first.a3          | PF1_1  |                      | WS.101.2a           
+ PS.first.a4          | PF1_1  |                      | WS.101.2b           
+ PS.first.a5          | PF1_1  |                      | WS.101.3a           
+ PS.first.a6          | PF1_1  |                      | WS.101.3b           
+ PS.first.b1          | PF1_1  |                      | WS.102.1a           
+ PS.first.b2          | PF1_1  |                      | WS.102.1b           
+ PS.first.b3          | PF1_1  |                      | WS.102.2a           
+ PS.first.b4          | PF1_1  |                      | WS.102.2b           
+ PS.first.b5          | PF1_1  |                      | WS.102.3a           
+ PS.first.b6          | PF1_1  |                      | WS.102.3b           
+ PS.first.c1          | PF1_1  |                      | WS.105.1a           
+ PS.first.c2          | PF1_1  |                      | WS.105.1b           
+ PS.first.c3          | PF1_1  |                      | WS.105.2a           
+ PS.first.c4          | PF1_1  |                      | WS.105.2b           
+ PS.first.c5          | PF1_1  |                      | WS.105.3a           
+ PS.first.c6          | PF1_1  |                      | WS.105.3b           
+ PS.first.d1          | PF1_1  |                      | WS.106.1a           
+ PS.first.d2          | PF1_1  |                      | WS.106.1b           
+ PS.first.d3          | PF1_1  |                      | WS.106.2a           
+ PS.first.d4          | PF1_1  |                      | WS.106.2b           
+ PS.first.d5          | PF1_1  |                      | WS.106.3a           
+ PS.first.d6          | PF1_1  |                      | WS.106.3b           
+ PS.first.ta1         | PF1_2  |                      |                     
+ PS.first.ta2         | PF1_2  |                      |                     
+ PS.first.ta3         | PF1_2  |                      |                     
+ PS.first.ta4         | PF1_2  |                      |                     
+ PS.first.ta5         | PF1_2  |                      |                     
+ PS.first.ta6         | PF1_2  |                      |                     
+ PS.first.tb1         | PF1_2  |                      |                     
+ PS.first.tb2         | PF1_2  |                      |                     
+ PS.first.tb3         | PF1_2  |                      |                     
+ PS.first.tb4         | PF1_2  |                      |                     
+ PS.first.tb5         | PF1_2  |                      |                     
+ PS.first.tb6         | PF1_2  |                      |                     
+(66 rows)
+
+select * from WSlot order by slotname;
+       slotname       |  roomno  |       slotlink       |       backlink       
+----------------------+----------+----------------------+----------------------
+ WS.001.1a            | 001      |                      | PS.base.a1          
+ WS.001.1b            | 001      |                      | PS.base.a2          
+ WS.001.2a            | 001      |                      | PS.base.a3          
+ WS.001.2b            | 001      |                      | PS.base.a4          
+ WS.001.3a            | 001      |                      | PS.base.a5          
+ WS.001.3b            | 001      |                      | PS.base.a6          
+ WS.002.1a            | 002      |                      | PS.base.b1          
+ WS.002.1b            | 002      |                      | PS.base.b2          
+ WS.002.2a            | 002      |                      | PS.base.b3          
+ WS.002.2b            | 002      |                      | PS.base.b4          
+ WS.002.3a            | 002      |                      | PS.base.b5          
+ WS.002.3b            | 002      |                      | PS.base.b6          
+ WS.003.1a            | 003      |                      | PS.base.c1          
+ WS.003.1b            | 003      |                      | PS.base.c2          
+ WS.003.2a            | 003      |                      | PS.base.c3          
+ WS.003.2b            | 003      |                      | PS.base.c4          
+ WS.003.3a            | 003      |                      | PS.base.c5          
+ WS.003.3b            | 003      |                      | PS.base.c6          
+ WS.101.1a            | 101      |                      | PS.first.a1         
+ WS.101.1b            | 101      |                      | PS.first.a2         
+ WS.101.2a            | 101      |                      | PS.first.a3         
+ WS.101.2b            | 101      |                      | PS.first.a4         
+ WS.101.3a            | 101      |                      | PS.first.a5         
+ WS.101.3b            | 101      |                      | PS.first.a6         
+ WS.102.1a            | 102      |                      | PS.first.b1         
+ WS.102.1b            | 102      |                      | PS.first.b2         
+ WS.102.2a            | 102      |                      | PS.first.b3         
+ WS.102.2b            | 102      |                      | PS.first.b4         
+ WS.102.3a            | 102      |                      | PS.first.b5         
+ WS.102.3b            | 102      |                      | PS.first.b6         
+ WS.105.1a            | 105      |                      | PS.first.c1         
+ WS.105.1b            | 105      |                      | PS.first.c2         
+ WS.105.2a            | 105      |                      | PS.first.c3         
+ WS.105.2b            | 105      |                      | PS.first.c4         
+ WS.105.3a            | 105      |                      | PS.first.c5         
+ WS.105.3b            | 105      |                      | PS.first.c6         
+ WS.106.1a            | 106      |                      | PS.first.d1         
+ WS.106.1b            | 106      |                      | PS.first.d2         
+ WS.106.2a            | 106      |                      | PS.first.d3         
+ WS.106.2b            | 106      |                      | PS.first.d4         
+ WS.106.3a            | 106      |                      | PS.first.d5         
+ WS.106.3b            | 106      |                      | PS.first.d6         
+(42 rows)
+
+--
+-- Install the central phone system and create the phone numbers.
+-- They are wired on insert to the patchfields. Again the
+-- triggers automatically tell the PSlots to update their
+-- backlink field.
+--
+insert into PLine values ('PL.001', '-0', 'Central call', 'PS.base.ta1');
+insert into PLine values ('PL.002', '-101', '', 'PS.base.ta2');
+insert into PLine values ('PL.003', '-102', '', 'PS.base.ta3');
+insert into PLine values ('PL.004', '-103', '', 'PS.base.ta5');
+insert into PLine values ('PL.005', '-104', '', 'PS.base.ta6');
+insert into PLine values ('PL.006', '-106', '', 'PS.base.tb2');
+insert into PLine values ('PL.007', '-108', '', 'PS.base.tb3');
+insert into PLine values ('PL.008', '-109', '', 'PS.base.tb4');
+insert into PLine values ('PL.009', '-121', '', 'PS.base.tb5');
+insert into PLine values ('PL.010', '-122', '', 'PS.base.tb6');
+insert into PLine values ('PL.015', '-134', '', 'PS.first.ta1');
+insert into PLine values ('PL.016', '-137', '', 'PS.first.ta3');
+insert into PLine values ('PL.017', '-139', '', 'PS.first.ta4');
+insert into PLine values ('PL.018', '-362', '', 'PS.first.tb1');
+insert into PLine values ('PL.019', '-363', '', 'PS.first.tb2');
+insert into PLine values ('PL.020', '-364', '', 'PS.first.tb3');
+insert into PLine values ('PL.021', '-365', '', 'PS.first.tb5');
+insert into PLine values ('PL.022', '-367', '', 'PS.first.tb6');
+insert into PLine values ('PL.028', '-501', 'Fax entrance', 'PS.base.ta2');
+insert into PLine values ('PL.029', '-502', 'Fax first floor', 'PS.first.ta1');
+--
+-- Buy some phones, plug them into the wall and patch the
+-- phone lines to the corresponding patchfield slots.
+--
+insert into PHone values ('PH.hc001', 'Hicom standard', 'WS.001.1a');
+update PSlot set slotlink = 'PS.base.ta1' where slotname = 'PS.base.a1';
+insert into PHone values ('PH.hc002', 'Hicom standard', 'WS.002.1a');
+update PSlot set slotlink = 'PS.base.ta5' where slotname = 'PS.base.b1';
+insert into PHone values ('PH.hc003', 'Hicom standard', 'WS.002.2a');
+update PSlot set slotlink = 'PS.base.tb2' where slotname = 'PS.base.b3';
+insert into PHone values ('PH.fax001', 'Canon fax', 'WS.001.2a');
+update PSlot set slotlink = 'PS.base.ta2' where slotname = 'PS.base.a3';
+--
+-- Install a hub at one of the patchfields, plug a computers
+-- ethernet interface into the wall and patch it to the hub.
+--
+insert into Hub values ('base.hub1', 'Patchfield PF0_1 hub', 16);
+insert into System values ('orion', 'PC');
+insert into IFace values ('IF', 'orion', 'eth0', 'WS.002.1b');
+update PSlot set slotlink = 'HS.base.hub1.1' where slotname = 'PS.base.b2';
+--
+-- Now we take a look at the patchfield
+--
+select * from PField_v1 where pfname = 'PF0_1' order by slotname;
+ pfname |       slotname       |                         backside                         |                     patch                     
+--------+----------------------+----------------------------------------------------------+-----------------------------------------------
+ PF0_1  | PS.base.a1           | WS.001.1a in room 001 -> Phone PH.hc001 (Hicom standard) | PS.base.ta1 -> Phone line -0 (Central call)
+ PF0_1  | PS.base.a2           | WS.001.1b in room 001 -> -                               | -
+ PF0_1  | PS.base.a3           | WS.001.2a in room 001 -> Phone PH.fax001 (Canon fax)     | PS.base.ta2 -> Phone line -501 (Fax entrance)
+ PF0_1  | PS.base.a4           | WS.001.2b in room 001 -> -                               | -
+ PF0_1  | PS.base.a5           | WS.001.3a in room 001 -> -                               | -
+ PF0_1  | PS.base.a6           | WS.001.3b in room 001 -> -                               | -
+ PF0_1  | PS.base.b1           | WS.002.1a in room 002 -> Phone PH.hc002 (Hicom standard) | PS.base.ta5 -> Phone line -103
+ PF0_1  | PS.base.b2           | WS.002.1b in room 002 -> orion IF eth0 (PC)              | Patchfield PF0_1 hub slot 1
+ PF0_1  | PS.base.b3           | WS.002.2a in room 002 -> Phone PH.hc003 (Hicom standard) | PS.base.tb2 -> Phone line -106
+ PF0_1  | PS.base.b4           | WS.002.2b in room 002 -> -                               | -
+ PF0_1  | PS.base.b5           | WS.002.3a in room 002 -> -                               | -
+ PF0_1  | PS.base.b6           | WS.002.3b in room 002 -> -                               | -
+ PF0_1  | PS.base.c1           | WS.003.1a in room 003 -> -                               | -
+ PF0_1  | PS.base.c2           | WS.003.1b in room 003 -> -                               | -
+ PF0_1  | PS.base.c3           | WS.003.2a in room 003 -> -                               | -
+ PF0_1  | PS.base.c4           | WS.003.2b in room 003 -> -                               | -
+ PF0_1  | PS.base.c5           | WS.003.3a in room 003 -> -                               | -
+ PF0_1  | PS.base.c6           | WS.003.3b in room 003 -> -                               | -
+(18 rows)
+
+select * from PField_v1 where pfname = 'PF0_2' order by slotname;
+ pfname |       slotname       |            backside            |                                 patch                                  
+--------+----------------------+--------------------------------+------------------------------------------------------------------------
+ PF0_2  | PS.base.ta1          | Phone line -0 (Central call)   | PS.base.a1 -> WS.001.1a in room 001 -> Phone PH.hc001 (Hicom standard)
+ PF0_2  | PS.base.ta2          | Phone line -501 (Fax entrance) | PS.base.a3 -> WS.001.2a in room 001 -> Phone PH.fax001 (Canon fax)
+ PF0_2  | PS.base.ta3          | Phone line -102                | -
+ PF0_2  | PS.base.ta4          | -                              | -
+ PF0_2  | PS.base.ta5          | Phone line -103                | PS.base.b1 -> WS.002.1a in room 002 -> Phone PH.hc002 (Hicom standard)
+ PF0_2  | PS.base.ta6          | Phone line -104                | -
+ PF0_2  | PS.base.tb1          | -                              | -
+ PF0_2  | PS.base.tb2          | Phone line -106                | PS.base.b3 -> WS.002.2a in room 002 -> Phone PH.hc003 (Hicom standard)
+ PF0_2  | PS.base.tb3          | Phone line -108                | -
+ PF0_2  | PS.base.tb4          | Phone line -109                | -
+ PF0_2  | PS.base.tb5          | Phone line -121                | -
+ PF0_2  | PS.base.tb6          | Phone line -122                | -
+(12 rows)
+
+--
+-- Finally we want errors
+--
+insert into PField values ('PF1_1', 'should fail due to unique index');
+ERROR:  duplicate key value violates unique constraint "pfield_name"
+DETAIL:  Key (name)=(PF1_1) already exists.
+update PSlot set backlink = 'WS.not.there' where slotname = 'PS.base.a1';
+ERROR:  WS.not.there         does not exist
+CONTEXT:  PL/pgSQL function tg_backlink_set(character,character) line 30 at RAISE
+PL/pgSQL function tg_backlink_a() line 17 at assignment
+update PSlot set backlink = 'XX.illegal' where slotname = 'PS.base.a1';
+ERROR:  illegal backlink beginning with XX
+CONTEXT:  PL/pgSQL function tg_backlink_set(character,character) line 47 at RAISE
+PL/pgSQL function tg_backlink_a() line 17 at assignment
+update PSlot set slotlink = 'PS.not.there' where slotname = 'PS.base.a1';
+ERROR:  PS.not.there         does not exist
+CONTEXT:  PL/pgSQL function tg_slotlink_set(character,character) line 30 at RAISE
+PL/pgSQL function tg_slotlink_a() line 17 at assignment
+update PSlot set slotlink = 'XX.illegal' where slotname = 'PS.base.a1';
+ERROR:  illegal slotlink beginning with XX
+CONTEXT:  PL/pgSQL function tg_slotlink_set(character,character) line 77 at RAISE
+PL/pgSQL function tg_slotlink_a() line 17 at assignment
+insert into HSlot values ('HS', 'base.hub1', 1, '');
+ERROR:  duplicate key value violates unique constraint "hslot_name"
+DETAIL:  Key (slotname)=(HS.base.hub1.1      ) already exists.
+insert into HSlot values ('HS', 'base.hub1', 20, '');
+ERROR:  no manual manipulation of HSlot
+CONTEXT:  PL/pgSQL function tg_hslot_biu() line 12 at RAISE
+delete from HSlot;
+ERROR:  no manual manipulation of HSlot
+CONTEXT:  PL/pgSQL function tg_hslot_bd() line 12 at RAISE
+insert into IFace values ('IF', 'notthere', 'eth0', '');
+ERROR:  system "notthere" does not exist
+CONTEXT:  PL/pgSQL function tg_iface_biu() line 8 at RAISE
+insert into IFace values ('IF', 'orion', 'ethernet_interface_name_too_long', '');
+ERROR:  IFace slotname "IF.orion.ethernet_interface_name_too_long" too long (20 char max)
+CONTEXT:  PL/pgSQL function tg_iface_biu() line 14 at RAISE
+--
+-- The following tests are unrelated to the scenario outlined above;
+-- they merely exercise specific parts of PL/pgSQL
+--
+--
+-- Test recursion, per bug report 7-Sep-01
+--
+CREATE FUNCTION recursion_test(int,int) RETURNS text AS '
+DECLARE rslt text;
+BEGIN
+    IF $1 <= 0 THEN
+        rslt = CAST($2 AS TEXT);
+    ELSE
+        rslt = CAST($1 AS TEXT) || '','' || recursion_test($1 - 1, $2);
+    END IF;
+    RETURN rslt;
+END;' LANGUAGE plpgsql;
+SELECT recursion_test(4,3);
+ recursion_test 
+----------------
+ 4,3,2,1,3
+(1 row)
+
+--
+-- Test the FOUND magic variable
+--
+CREATE TABLE found_test_tbl (a int);
+create function test_found()
+  returns boolean as '
+  declare
+  begin
+  insert into found_test_tbl values (1);
+  if FOUND then
+     insert into found_test_tbl values (2);
+  end if;
+
+  update found_test_tbl set a = 100 where a = 1;
+  if FOUND then
+    insert into found_test_tbl values (3);
+  end if;
+
+  delete from found_test_tbl where a = 9999; -- matches no rows
+  if not FOUND then
+    insert into found_test_tbl values (4);
+  end if;
+
+  for i in 1 .. 10 loop
+    -- no need to do anything
+  end loop;
+  if FOUND then
+    insert into found_test_tbl values (5);
+  end if;
+
+  -- never executes the loop
+  for i in 2 .. 1 loop
+    -- no need to do anything
+  end loop;
+  if not FOUND then
+    insert into found_test_tbl values (6);
+  end if;
+  return true;
+  end;' language plpgsql;
+select test_found();
+ test_found 
+------------
+ t
+(1 row)
+
+select * from found_test_tbl;
+  a  
+-----
+ 100
+   2
+   3
+   4
+   5
+   6
+(6 rows)
+
+--
+-- Test set-returning functions for PL/pgSQL
+--
+create function test_table_func_rec() returns setof found_test_tbl as '
+DECLARE
+	rec RECORD;
+BEGIN
+	FOR rec IN select * from found_test_tbl LOOP
+		RETURN NEXT rec;
+	END LOOP;
+	RETURN;
+END;' language plpgsql;
+select * from test_table_func_rec();
+  a  
+-----
+ 100
+   2
+   3
+   4
+   5
+   6
+(6 rows)
+
+create function test_table_func_row() returns setof found_test_tbl as '
+DECLARE
+	row found_test_tbl%ROWTYPE;
+BEGIN
+	FOR row IN select * from found_test_tbl LOOP
+		RETURN NEXT row;
+	END LOOP;
+	RETURN;
+END;' language plpgsql;
+select * from test_table_func_row();
+  a  
+-----
+ 100
+   2
+   3
+   4
+   5
+   6
+(6 rows)
+
+create function test_ret_set_scalar(int,int) returns setof int as '
+DECLARE
+	i int;
+BEGIN
+	FOR i IN $1 .. $2 LOOP
+		RETURN NEXT i + 1;
+	END LOOP;
+	RETURN;
+END;' language plpgsql;
+select * from test_ret_set_scalar(1,10);
+ test_ret_set_scalar 
+---------------------
+                   2
+                   3
+                   4
+                   5
+                   6
+                   7
+                   8
+                   9
+                  10
+                  11
+(10 rows)
+
+create function test_ret_set_rec_dyn(int) returns setof record as '
+DECLARE
+	retval RECORD;
+BEGIN
+	IF $1 > 10 THEN
+		SELECT INTO retval 5, 10, 15;
+		RETURN NEXT retval;
+		RETURN NEXT retval;
+	ELSE
+		SELECT INTO retval 50, 5::numeric, ''xxx''::text;
+		RETURN NEXT retval;
+		RETURN NEXT retval;
+	END IF;
+	RETURN;
+END;' language plpgsql;
+SELECT * FROM test_ret_set_rec_dyn(1500) AS (a int, b int, c int);
+ a | b  | c  
+---+----+----
+ 5 | 10 | 15
+ 5 | 10 | 15
+(2 rows)
+
+SELECT * FROM test_ret_set_rec_dyn(5) AS (a int, b numeric, c text);
+ a  | b |  c  
+----+---+-----
+ 50 | 5 | xxx
+ 50 | 5 | xxx
+(2 rows)
+
+create function test_ret_rec_dyn(int) returns record as '
+DECLARE
+	retval RECORD;
+BEGIN
+	IF $1 > 10 THEN
+		SELECT INTO retval 5, 10, 15;
+		RETURN retval;
+	ELSE
+		SELECT INTO retval 50, 5::numeric, ''xxx''::text;
+		RETURN retval;
+	END IF;
+END;' language plpgsql;
+SELECT * FROM test_ret_rec_dyn(1500) AS (a int, b int, c int);
+ a | b  | c  
+---+----+----
+ 5 | 10 | 15
+(1 row)
+
+SELECT * FROM test_ret_rec_dyn(5) AS (a int, b numeric, c text);
+ a  | b |  c  
+----+---+-----
+ 50 | 5 | xxx
+(1 row)
+
+--
+-- Test handling of OUT parameters, including polymorphic cases.
+-- Note that RETURN is optional with OUT params; we try both ways.
+--
+-- wrong way to do it:
+create function f1(in i int, out j int) returns int as $$
+begin
+  return i+1;
+end$$ language plpgsql;
+ERROR:  RETURN cannot have a parameter in function with OUT parameters
+LINE 3:   return i+1;
+                 ^
+create function f1(in i int, out j int) as $$
+begin
+  j := i+1;
+  return;
+end$$ language plpgsql;
+select f1(42);
+ f1 
+----
+ 43
+(1 row)
+
+select * from f1(42);
+ j  
+----
+ 43
+(1 row)
+
+create or replace function f1(inout i int) as $$
+begin
+  i := i+1;
+end$$ language plpgsql;
+select f1(42);
+ f1 
+----
+ 43
+(1 row)
+
+select * from f1(42);
+ i  
+----
+ 43
+(1 row)
+
+drop function f1(int);
+create function f1(in i int, out j int) returns setof int as $$
+begin
+  j := i+1;
+  return next;
+  j := i+2;
+  return next;
+  return;
+end$$ language plpgsql;
+select * from f1(42);
+ j  
+----
+ 43
+ 44
+(2 rows)
+
+drop function f1(int);
+create function f1(in i int, out j int, out k text) as $$
+begin
+  j := i;
+  j := j+1;
+  k := 'foo';
+end$$ language plpgsql;
+select f1(42);
+    f1    
+----------
+ (43,foo)
+(1 row)
+
+select * from f1(42);
+ j  |  k  
+----+-----
+ 43 | foo
+(1 row)
+
+drop function f1(int);
+create function f1(in i int, out j int, out k text) returns setof record as $$
+begin
+  j := i+1;
+  k := 'foo';
+  return next;
+  j := j+1;
+  k := 'foot';
+  return next;
+end$$ language plpgsql;
+select * from f1(42);
+ j  |  k   
+----+------
+ 43 | foo
+ 44 | foot
+(2 rows)
+
+drop function f1(int);
+create function duplic(in i anyelement, out j anyelement, out k anyarray) as $$
+begin
+  j := i;
+  k := array[j,j];
+  return;
+end$$ language plpgsql;
+select * from duplic(42);
+ j  |    k    
+----+---------
+ 42 | {42,42}
+(1 row)
+
+select * from duplic('foo'::text);
+  j  |     k     
+-----+-----------
+ foo | {foo,foo}
+(1 row)
+
+drop function duplic(anyelement);
+--
+-- test PERFORM
+--
+create table perform_test (
+	a	INT,
+	b	INT
+);
+create function perform_simple_func(int) returns boolean as '
+BEGIN
+	IF $1 < 20 THEN
+		INSERT INTO perform_test VALUES ($1, $1 + 10);
+		RETURN TRUE;
+	ELSE
+		RETURN FALSE;
+	END IF;
+END;' language plpgsql;
+create function perform_test_func() returns void as '
+BEGIN
+	IF FOUND then
+		INSERT INTO perform_test VALUES (100, 100);
+	END IF;
+
+	PERFORM perform_simple_func(5);
+
+	IF FOUND then
+		INSERT INTO perform_test VALUES (100, 100);
+	END IF;
+
+	PERFORM perform_simple_func(50);
+
+	IF FOUND then
+		INSERT INTO perform_test VALUES (100, 100);
+	END IF;
+
+	RETURN;
+END;' language plpgsql;
+SELECT perform_test_func();
+ perform_test_func 
+-------------------
+ 
+(1 row)
+
+SELECT * FROM perform_test;
+  a  |  b  
+-----+-----
+   5 |  15
+ 100 | 100
+ 100 | 100
+(3 rows)
+
+drop table perform_test;
+--
+-- Test error trapping
+--
+create function trap_zero_divide(int) returns int as $$
+declare x int;
+	sx smallint;
+begin
+	begin	-- start a subtransaction
+		raise notice 'should see this';
+		x := 100 / $1;
+		raise notice 'should see this only if % <> 0', $1;
+		sx := $1;
+		raise notice 'should see this only if % fits in smallint', $1;
+		if $1 < 0 then
+			raise exception '% is less than zero', $1;
+		end if;
+	exception
+		when division_by_zero then
+			raise notice 'caught division_by_zero';
+			x := -1;
+		when NUMERIC_VALUE_OUT_OF_RANGE then
+			raise notice 'caught numeric_value_out_of_range';
+			x := -2;
+	end;
+	return x;
+end$$ language plpgsql;
+select trap_zero_divide(50);
+NOTICE:  should see this
+NOTICE:  should see this only if 50 <> 0
+NOTICE:  should see this only if 50 fits in smallint
+ trap_zero_divide 
+------------------
+                2
+(1 row)
+
+select trap_zero_divide(0);
+NOTICE:  should see this
+NOTICE:  caught division_by_zero
+ trap_zero_divide 
+------------------
+               -1
+(1 row)
+
+select trap_zero_divide(100000);
+NOTICE:  should see this
+NOTICE:  should see this only if 100000 <> 0
+NOTICE:  caught numeric_value_out_of_range
+ trap_zero_divide 
+------------------
+               -2
+(1 row)
+
+select trap_zero_divide(-100);
+NOTICE:  should see this
+NOTICE:  should see this only if -100 <> 0
+NOTICE:  should see this only if -100 fits in smallint
+ERROR:  -100 is less than zero
+CONTEXT:  PL/pgSQL function trap_zero_divide(integer) line 12 at RAISE
+create function trap_matching_test(int) returns int as $$
+declare x int;
+	sx smallint;
+	y int;
+begin
+	begin	-- start a subtransaction
+		x := 100 / $1;
+		sx := $1;
+		select into y unique1 from tenk1 where unique2 =
+			(select unique2 from tenk1 b where ten = $1);
+	exception
+		when data_exception then  -- category match
+			raise notice 'caught data_exception';
+			x := -1;
+		when NUMERIC_VALUE_OUT_OF_RANGE OR CARDINALITY_VIOLATION then
+			raise notice 'caught numeric_value_out_of_range or cardinality_violation';
+			x := -2;
+	end;
+	return x;
+end$$ language plpgsql;
+select trap_matching_test(50);
+ trap_matching_test 
+--------------------
+                  2
+(1 row)
+
+select trap_matching_test(0);
+NOTICE:  caught data_exception
+ trap_matching_test 
+--------------------
+                 -1
+(1 row)
+
+select trap_matching_test(100000);
+NOTICE:  caught data_exception
+ trap_matching_test 
+--------------------
+                 -1
+(1 row)
+
+select trap_matching_test(1);
+NOTICE:  caught numeric_value_out_of_range or cardinality_violation
+ trap_matching_test 
+--------------------
+                 -2
+(1 row)
+
+create temp table foo (f1 int);
+create function subxact_rollback_semantics() returns int as $$
+declare x int;
+begin
+  x := 1;
+  insert into foo values(x);
+  begin
+    x := x + 1;
+    insert into foo values(x);
+    raise exception 'inner';
+  exception
+    when others then
+      x := x * 10;
+  end;
+  insert into foo values(x);
+  return x;
+end$$ language plpgsql;
+select subxact_rollback_semantics();
+ subxact_rollback_semantics 
+----------------------------
+                         20
+(1 row)
+
+select * from foo;
+ f1 
+----
+  1
+ 20
+(2 rows)
+
+drop table foo;
+create function trap_timeout() returns void as $$
+begin
+  declare x int;
+  begin
+    -- we assume this will take longer than 2 seconds:
+    select count(*) into x from tenk1 a, tenk1 b, tenk1 c;
+  exception
+    when others then
+      raise notice 'caught others?';
+    when query_canceled then
+      raise notice 'nyeah nyeah, can''t stop me';
+  end;
+  -- Abort transaction to abandon the statement_timeout setting.  Otherwise,
+  -- the next top-level statement would be vulnerable to the timeout.
+  raise exception 'end of function';
+end$$ language plpgsql;
+begin;
+set statement_timeout to 2000;
+select trap_timeout();
+NOTICE:  nyeah nyeah, can't stop me
+ERROR:  end of function
+CONTEXT:  PL/pgSQL function trap_timeout() line 15 at RAISE
+rollback;
+-- Test for pass-by-ref values being stored in proper context
+create function test_variable_storage() returns text as $$
+declare x text;
+begin
+  x := '1234';
+  begin
+    x := x || '5678';
+    -- force error inside subtransaction SPI context
+    perform trap_zero_divide(-100);
+  exception
+    when others then
+      x := x || '9012';
+  end;
+  return x;
+end$$ language plpgsql;
+select test_variable_storage();
+NOTICE:  should see this
+NOTICE:  should see this only if -100 <> 0
+NOTICE:  should see this only if -100 fits in smallint
+ test_variable_storage 
+-----------------------
+ 123456789012
+(1 row)
+
+--
+-- test foreign key error trapping
+--
+create temp table master(f1 int primary key);
+create temp table slave(f1 int references master deferrable);
+insert into master values(1);
+insert into slave values(1);
+insert into slave values(2);	-- fails
+ERROR:  insert or update on table "slave" violates foreign key constraint "slave_f1_fkey"
+DETAIL:  Key (f1)=(2) is not present in table "master".
+create function trap_foreign_key(int) returns int as $$
+begin
+	begin	-- start a subtransaction
+		insert into slave values($1);
+	exception
+		when foreign_key_violation then
+			raise notice 'caught foreign_key_violation';
+			return 0;
+	end;
+	return 1;
+end$$ language plpgsql;
+create function trap_foreign_key_2() returns int as $$
+begin
+	begin	-- start a subtransaction
+		set constraints all immediate;
+	exception
+		when foreign_key_violation then
+			raise notice 'caught foreign_key_violation';
+			return 0;
+	end;
+	return 1;
+end$$ language plpgsql;
+select trap_foreign_key(1);
+ trap_foreign_key 
+------------------
+                1
+(1 row)
+
+select trap_foreign_key(2);	-- detects FK violation
+NOTICE:  caught foreign_key_violation
+ trap_foreign_key 
+------------------
+                0
+(1 row)
+
+begin;
+  set constraints all deferred;
+  select trap_foreign_key(2);	-- should not detect FK violation
+ trap_foreign_key 
+------------------
+                1
+(1 row)
+
+  savepoint x;
+    set constraints all immediate; -- fails
+ERROR:  insert or update on table "slave" violates foreign key constraint "slave_f1_fkey"
+DETAIL:  Key (f1)=(2) is not present in table "master".
+  rollback to x;
+  select trap_foreign_key_2();  -- detects FK violation
+NOTICE:  caught foreign_key_violation
+ trap_foreign_key_2 
+--------------------
+                  0
+(1 row)
+
+commit;				-- still fails
+ERROR:  insert or update on table "slave" violates foreign key constraint "slave_f1_fkey"
+DETAIL:  Key (f1)=(2) is not present in table "master".
+drop function trap_foreign_key(int);
+drop function trap_foreign_key_2();
+--
+-- Test proper snapshot handling in simple expressions
+--
+create temp table users(login text, id serial);
+create function sp_id_user(a_login text) returns int as $$
+declare x int;
+begin
+  select into x id from users where login = a_login;
+  if found then return x; end if;
+  return 0;
+end$$ language plpgsql stable;
+insert into users values('user1');
+select sp_id_user('user1');
+ sp_id_user 
+------------
+          1
+(1 row)
+
+select sp_id_user('userx');
+ sp_id_user 
+------------
+          0
+(1 row)
+
+create function sp_add_user(a_login text) returns int as $$
+declare my_id_user int;
+begin
+  my_id_user = sp_id_user( a_login );
+  IF  my_id_user > 0 THEN
+    RETURN -1;  -- error code for existing user
+  END IF;
+  INSERT INTO users ( login ) VALUES ( a_login );
+  my_id_user = sp_id_user( a_login );
+  IF  my_id_user = 0 THEN
+    RETURN -2;  -- error code for insertion failure
+  END IF;
+  RETURN my_id_user;
+end$$ language plpgsql;
+select sp_add_user('user1');
+ sp_add_user 
+-------------
+          -1
+(1 row)
+
+select sp_add_user('user2');
+ sp_add_user 
+-------------
+           2
+(1 row)
+
+select sp_add_user('user2');
+ sp_add_user 
+-------------
+          -1
+(1 row)
+
+select sp_add_user('user3');
+ sp_add_user 
+-------------
+           3
+(1 row)
+
+select sp_add_user('user3');
+ sp_add_user 
+-------------
+          -1
+(1 row)
+
+drop function sp_add_user(text);
+drop function sp_id_user(text);
+--
+-- tests for refcursors
+--
+create table rc_test (a int, b int);
+copy rc_test from stdin;
+create function return_unnamed_refcursor() returns refcursor as $$
+declare
+    rc refcursor;
+begin
+    open rc for select a from rc_test;
+    return rc;
+end
+$$ language plpgsql;
+create function use_refcursor(rc refcursor) returns int as $$
+declare
+    rc refcursor;
+    x record;
+begin
+    rc := return_unnamed_refcursor();
+    fetch next from rc into x;
+    return x.a;
+end
+$$ language plpgsql;
+select use_refcursor(return_unnamed_refcursor());
+ use_refcursor 
+---------------
+             5
+(1 row)
+
+create function return_refcursor(rc refcursor) returns refcursor as $$
+begin
+    open rc for select a from rc_test;
+    return rc;
+end
+$$ language plpgsql;
+create function refcursor_test1(refcursor) returns refcursor as $$
+begin
+    perform return_refcursor($1);
+    return $1;
+end
+$$ language plpgsql;
+begin;
+select refcursor_test1('test1');
+ refcursor_test1 
+-----------------
+ test1
+(1 row)
+
+fetch next in test1;
+ a 
+---
+ 5
+(1 row)
+
+select refcursor_test1('test2');
+ refcursor_test1 
+-----------------
+ test2
+(1 row)
+
+fetch all from test2;
+  a  
+-----
+   5
+  50
+ 500
+(3 rows)
+
+commit;
+-- should fail
+fetch next from test1;
+ERROR:  cursor "test1" does not exist
+create function refcursor_test2(int, int) returns boolean as $$
+declare
+    c1 cursor (param1 int, param2 int) for select * from rc_test where a > param1 and b > param2;
+    nonsense record;
+begin
+    open c1($1, $2);
+    fetch c1 into nonsense;
+    close c1;
+    if found then
+        return true;
+    else
+        return false;
+    end if;
+end
+$$ language plpgsql;
+select refcursor_test2(20000, 20000) as "Should be false",
+       refcursor_test2(20, 20) as "Should be true";
+ Should be false | Should be true 
+-----------------+----------------
+ f               | t
+(1 row)
+
+--
+-- tests for cursors with named parameter arguments
+--
+create function namedparmcursor_test1(int, int) returns boolean as $$
+declare
+    c1 cursor (param1 int, param12 int) for select * from rc_test where a > param1 and b > param12;
+    nonsense record;
+begin
+    open c1(param12 := $2, param1 := $1);
+    fetch c1 into nonsense;
+    close c1;
+    if found then
+        return true;
+    else
+        return false;
+    end if;
+end
+$$ language plpgsql;
+select namedparmcursor_test1(20000, 20000) as "Should be false",
+       namedparmcursor_test1(20, 20) as "Should be true";
+ Should be false | Should be true 
+-----------------+----------------
+ f               | t
+(1 row)
+
+-- mixing named and positional argument notations
+create function namedparmcursor_test2(int, int) returns boolean as $$
+declare
+    c1 cursor (param1 int, param2 int) for select * from rc_test where a > param1 and b > param2;
+    nonsense record;
+begin
+    open c1(param1 := $1, $2);
+    fetch c1 into nonsense;
+    close c1;
+    if found then
+        return true;
+    else
+        return false;
+    end if;
+end
+$$ language plpgsql;
+select namedparmcursor_test2(20, 20);
+ namedparmcursor_test2 
+-----------------------
+ t
+(1 row)
+
+-- mixing named and positional: param2 is given twice, once in named notation
+-- and second time in positional notation. Should throw an error at parse time
+create function namedparmcursor_test3() returns void as $$
+declare
+    c1 cursor (param1 int, param2 int) for select * from rc_test where a > param1 and b > param2;
+begin
+    open c1(param2 := 20, 21);
+end
+$$ language plpgsql;
+ERROR:  value for parameter "param2" of cursor "c1" specified more than once
+LINE 5:     open c1(param2 := 20, 21);
+                                  ^
+-- mixing named and positional: same as previous test, but param1 is duplicated
+create function namedparmcursor_test4() returns void as $$
+declare
+    c1 cursor (param1 int, param2 int) for select * from rc_test where a > param1 and b > param2;
+begin
+    open c1(20, param1 := 21);
+end
+$$ language plpgsql;
+ERROR:  value for parameter "param1" of cursor "c1" specified more than once
+LINE 5:     open c1(20, param1 := 21);
+                        ^
+-- duplicate named parameter, should throw an error at parse time
+create function namedparmcursor_test5() returns void as $$
+declare
+  c1 cursor (p1 int, p2 int) for
+    select * from tenk1 where thousand = p1 and tenthous = p2;
+begin
+  open c1 (p2 := 77, p2 := 42);
+end
+$$ language plpgsql;
+ERROR:  value for parameter "p2" of cursor "c1" specified more than once
+LINE 6:   open c1 (p2 := 77, p2 := 42);
+                             ^
+-- not enough parameters, should throw an error at parse time
+create function namedparmcursor_test6() returns void as $$
+declare
+  c1 cursor (p1 int, p2 int) for
+    select * from tenk1 where thousand = p1 and tenthous = p2;
+begin
+  open c1 (p2 := 77);
+end
+$$ language plpgsql;
+ERROR:  not enough arguments for cursor "c1"
+LINE 6:   open c1 (p2 := 77);
+                           ^
+-- division by zero runtime error, the context given in the error message
+-- should be sensible
+create function namedparmcursor_test7() returns void as $$
+declare
+  c1 cursor (p1 int, p2 int) for
+    select * from tenk1 where thousand = p1 and tenthous = p2;
+begin
+  open c1 (p2 := 77, p1 := 42/0);
+end $$ language plpgsql;
+select namedparmcursor_test7();
+ERROR:  division by zero
+CONTEXT:  SQL statement "SELECT 42/0 AS p1, 77 AS p2;"
+PL/pgSQL function namedparmcursor_test7() line 6 at OPEN
+-- check that line comments work correctly within the argument list (there
+-- is some special handling of this case in the code: the newline after the
+-- comment must be preserved when the argument-evaluating query is
+-- constructed, otherwise the comment effectively comments out the next
+-- argument, too)
+create function namedparmcursor_test8() returns int4 as $$
+declare
+  c1 cursor (p1 int, p2 int) for
+    select count(*) from tenk1 where thousand = p1 and tenthous = p2;
+  n int4;
+begin
+  open c1 (77 -- test
+  , 42);
+  fetch c1 into n;
+  return n;
+end $$ language plpgsql;
+select namedparmcursor_test8();
+ namedparmcursor_test8 
+-----------------------
+                     0
+(1 row)
+
+-- cursor parameter name can match plpgsql variable or unreserved keyword
+create function namedparmcursor_test9(p1 int) returns int4 as $$
+declare
+  c1 cursor (p1 int, p2 int, debug int) for
+    select count(*) from tenk1 where thousand = p1 and tenthous = p2
+      and four = debug;
+  p2 int4 := 1006;
+  n int4;
+begin
+  open c1 (p1 := p1, p2 := p2, debug := 2);
+  fetch c1 into n;
+  return n;
+end $$ language plpgsql;
+select namedparmcursor_test9(6);
+ namedparmcursor_test9 
+-----------------------
+                     1
+(1 row)
+
+--
+-- tests for "raise" processing
+--
+create function raise_test1(int) returns int as $$
+begin
+    raise notice 'This message has too many parameters!', $1;
+    return $1;
+end;
+$$ language plpgsql;
+ERROR:  too many parameters specified for RAISE
+CONTEXT:  compilation of PL/pgSQL function "raise_test1" near line 3
+create function raise_test2(int) returns int as $$
+begin
+    raise notice 'This message has too few parameters: %, %, %', $1, $1;
+    return $1;
+end;
+$$ language plpgsql;
+ERROR:  too few parameters specified for RAISE
+CONTEXT:  compilation of PL/pgSQL function "raise_test2" near line 3
+create function raise_test3(int) returns int as $$
+begin
+    raise notice 'This message has no parameters (despite having %% signs in it)!';
+    return $1;
+end;
+$$ language plpgsql;
+select raise_test3(1);
+NOTICE:  This message has no parameters (despite having % signs in it)!
+ raise_test3 
+-------------
+           1
+(1 row)
+
+-- Test re-RAISE inside a nested exception block.  This case is allowed
+-- by Oracle's PL/SQL but was handled differently by PG before 9.1.
+CREATE FUNCTION reraise_test() RETURNS void AS $$
+BEGIN
+   BEGIN
+       RAISE syntax_error;
+   EXCEPTION
+       WHEN syntax_error THEN
+           BEGIN
+               raise notice 'exception % thrown in inner block, reraising', sqlerrm;
+               RAISE;
+           EXCEPTION
+               WHEN OTHERS THEN
+                   raise notice 'RIGHT - exception % caught in inner block', sqlerrm;
+           END;
+   END;
+EXCEPTION
+   WHEN OTHERS THEN
+       raise notice 'WRONG - exception % caught in outer block', sqlerrm;
+END;
+$$ LANGUAGE plpgsql;
+SELECT reraise_test();
+NOTICE:  exception syntax_error thrown in inner block, reraising
+NOTICE:  RIGHT - exception syntax_error caught in inner block
+ reraise_test 
+--------------
+ 
+(1 row)
+
+--
+-- reject function definitions that contain malformed SQL queries at
+-- compile-time, where possible
+--
+create function bad_sql1() returns int as $$
+declare a int;
+begin
+    a := 5;
+    Johnny Yuma;
+    a := 10;
+    return a;
+end$$ language plpgsql;
+ERROR:  syntax error at or near "Johnny"
+LINE 5:     Johnny Yuma;
+            ^
+create function bad_sql2() returns int as $$
+declare r record;
+begin
+    for r in select I fought the law, the law won LOOP
+        raise notice 'in loop';
+    end loop;
+    return 5;
+end;$$ language plpgsql;
+ERROR:  syntax error at or near "the"
+LINE 4:     for r in select I fought the law, the law won LOOP
+                                     ^
+-- a RETURN expression is mandatory, except for void-returning
+-- functions, where it is not allowed
+create function missing_return_expr() returns int as $$
+begin
+    return ;
+end;$$ language plpgsql;
+ERROR:  missing expression at or near ";"
+LINE 3:     return ;
+                   ^
+create function void_return_expr() returns void as $$
+begin
+    return 5;
+end;$$ language plpgsql;
+ERROR:  RETURN cannot have a parameter in function returning void
+LINE 3:     return 5;
+                   ^
+-- VOID functions are allowed to omit RETURN
+create function void_return_expr() returns void as $$
+begin
+    perform 2+2;
+end;$$ language plpgsql;
+select void_return_expr();
+ void_return_expr 
+------------------
+ 
+(1 row)
+
+-- but ordinary functions are not
+create function missing_return_expr() returns int as $$
+begin
+    perform 2+2;
+end;$$ language plpgsql;
+select missing_return_expr();
+ERROR:  control reached end of function without RETURN
+CONTEXT:  PL/pgSQL function missing_return_expr()
+drop function void_return_expr();
+drop function missing_return_expr();
+--
+-- EXECUTE ... INTO test
+--
+create table eifoo (i integer, y integer);
+create type eitype as (i integer, y integer);
+create or replace function execute_into_test(varchar) returns record as $$
+declare
+    _r record;
+    _rt eifoo%rowtype;
+    _v eitype;
+    i int;
+    j int;
+    k int;
+begin
+    execute 'insert into '||$1||' values(10,15)';
+    execute 'select (row).* from (select row(10,1)::eifoo) s' into _r;
+    raise notice '% %', _r.i, _r.y;
+    execute 'select * from '||$1||' limit 1' into _rt;
+    raise notice '% %', _rt.i, _rt.y;
+    execute 'select *, 20 from '||$1||' limit 1' into i, j, k;
+    raise notice '% % %', i, j, k;
+    execute 'select 1,2' into _v;
+    return _v;
+end; $$ language plpgsql;
+select execute_into_test('eifoo');
+NOTICE:  10 1
+NOTICE:  10 15
+NOTICE:  10 15 20
+ execute_into_test 
+-------------------
+ (1,2)
+(1 row)
+
+drop table eifoo cascade;
+drop type eitype cascade;
+--
+-- SQLSTATE and SQLERRM test
+--
+create function excpt_test1() returns void as $$
+begin
+    raise notice '% %', sqlstate, sqlerrm;
+end; $$ language plpgsql;
+-- should fail: SQLSTATE and SQLERRM are only in defined EXCEPTION
+-- blocks
+select excpt_test1();
+ERROR:  column "sqlstate" does not exist
+LINE 1: SELECT sqlstate
+               ^
+QUERY:  SELECT sqlstate
+CONTEXT:  PL/pgSQL function excpt_test1() line 3 at RAISE
+create function excpt_test2() returns void as $$
+begin
+    begin
+        begin
+            raise notice '% %', sqlstate, sqlerrm;
+        end;
+    end;
+end; $$ language plpgsql;
+-- should fail
+select excpt_test2();
+ERROR:  column "sqlstate" does not exist
+LINE 1: SELECT sqlstate
+               ^
+QUERY:  SELECT sqlstate
+CONTEXT:  PL/pgSQL function excpt_test2() line 5 at RAISE
+create function excpt_test3() returns void as $$
+begin
+    begin
+        raise exception 'user exception';
+    exception when others then
+	    raise notice 'caught exception % %', sqlstate, sqlerrm;
+	    begin
+	        raise notice '% %', sqlstate, sqlerrm;
+	        perform 10/0;
+        exception
+            when substring_error then
+                -- this exception handler shouldn't be invoked
+                raise notice 'unexpected exception: % %', sqlstate, sqlerrm;
+	        when division_by_zero then
+	            raise notice 'caught exception % %', sqlstate, sqlerrm;
+	    end;
+	    raise notice '% %', sqlstate, sqlerrm;
+    end;
+end; $$ language plpgsql;
+select excpt_test3();
+NOTICE:  caught exception P0001 user exception
+NOTICE:  P0001 user exception
+NOTICE:  caught exception 22012 division by zero
+NOTICE:  P0001 user exception
+ excpt_test3 
+-------------
+ 
+(1 row)
+
+create function excpt_test4() returns text as $$
+begin
+	begin perform 1/0;
+	exception when others then return sqlerrm; end;
+end; $$ language plpgsql;
+select excpt_test4();
+   excpt_test4    
+------------------
+ division by zero
+(1 row)
+
+drop function excpt_test1();
+drop function excpt_test2();
+drop function excpt_test3();
+drop function excpt_test4();
+-- parameters of raise stmt can be expressions
+create function raise_exprs() returns void as $$
+declare
+    a integer[] = '{10,20,30}';
+    c varchar = 'xyz';
+    i integer;
+begin
+    i := 2;
+    raise notice '%; %; %; %; %; %', a, a[i], c, (select c || 'abc'), row(10,'aaa',NULL,30), NULL;
+end;$$ language plpgsql;
+select raise_exprs();
+NOTICE:  {10,20,30}; 20; xyz; xyzabc; (10,aaa,,30); <NULL>
+ raise_exprs 
+-------------
+ 
+(1 row)
+
+drop function raise_exprs();
+-- regression test: verify that multiple uses of same plpgsql datum within
+-- a SQL command all get mapped to the same $n parameter.  The return value
+-- of the SELECT is not important, we only care that it doesn't fail with
+-- a complaint about an ungrouped column reference.
+create function multi_datum_use(p1 int) returns bool as $$
+declare
+  x int;
+  y int;
+begin
+  select into x,y unique1/p1, unique1/$1 from tenk1 group by unique1/p1;
+  return x = y;
+end$$ language plpgsql;
+select multi_datum_use(42);
+ multi_datum_use 
+-----------------
+ t
+(1 row)
+
+--
+-- Test STRICT limiter in both planned and EXECUTE invocations.
+-- Note that a data-modifying query is quasi strict (disallow multi rows)
+-- by default in the planned case, but not in EXECUTE.
+--
+create temp table foo (f1 int, f2 int);
+insert into foo values (1,2), (3,4);
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- should work
+  insert into foo values(5,6) returning * into x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+NOTICE:  x.f1 = 5, x.f2 = 6
+ stricttest 
+------------
+ 
+(1 row)
+
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- should fail due to implicit strict
+  insert into foo values(7,8),(9,10) returning * into x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+ERROR:  query returned more than one row
+HINT:  Make sure the query returns a single row, or use LIMIT 1.
+CONTEXT:  PL/pgSQL function stricttest() line 5 at SQL statement
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- should work
+  execute 'insert into foo values(5,6) returning *' into x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+NOTICE:  x.f1 = 5, x.f2 = 6
+ stricttest 
+------------
+ 
+(1 row)
+
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- this should work since EXECUTE isn't as picky
+  execute 'insert into foo values(7,8),(9,10) returning *' into x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+NOTICE:  x.f1 = 7, x.f2 = 8
+ stricttest 
+------------
+ 
+(1 row)
+
+select * from foo;
+ f1 | f2 
+----+----
+  1 |  2
+  3 |  4
+  5 |  6
+  5 |  6
+  7 |  8
+  9 | 10
+(6 rows)
+
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- should work
+  select * from foo where f1 = 3 into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+NOTICE:  x.f1 = 3, x.f2 = 4
+ stricttest 
+------------
+ 
+(1 row)
+
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- should fail, no rows
+  select * from foo where f1 = 0 into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+ERROR:  query returned no rows
+CONTEXT:  PL/pgSQL function stricttest() line 5 at SQL statement
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- should fail, too many rows
+  select * from foo where f1 > 3 into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+ERROR:  query returned more than one row
+HINT:  Make sure the query returns a single row, or use LIMIT 1.
+CONTEXT:  PL/pgSQL function stricttest() line 5 at SQL statement
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- should work
+  execute 'select * from foo where f1 = 3' into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+NOTICE:  x.f1 = 3, x.f2 = 4
+ stricttest 
+------------
+ 
+(1 row)
+
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- should fail, no rows
+  execute 'select * from foo where f1 = 0' into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+ERROR:  query returned no rows
+CONTEXT:  PL/pgSQL function stricttest() line 5 at EXECUTE
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- should fail, too many rows
+  execute 'select * from foo where f1 > 3' into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+ERROR:  query returned more than one row
+CONTEXT:  PL/pgSQL function stricttest() line 5 at EXECUTE
+drop function stricttest();
+-- test printing parameters after failure due to STRICT
+set plpgsql.print_strict_params to true;
+create or replace function stricttest() returns void as $$
+declare
+x record;
+p1 int := 2;
+p3 text := 'foo';
+begin
+  -- no rows
+  select * from foo where f1 = p1 and f1::text = p3 into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+ERROR:  query returned no rows
+DETAIL:  parameters: p1 = '2', p3 = 'foo'
+CONTEXT:  PL/pgSQL function stricttest() line 8 at SQL statement
+create or replace function stricttest() returns void as $$
+declare
+x record;
+p1 int := 2;
+p3 text := 'foo';
+begin
+  -- too many rows
+  select * from foo where f1 > p1 or f1::text = p3  into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+ERROR:  query returned more than one row
+DETAIL:  parameters: p1 = '2', p3 = 'foo'
+HINT:  Make sure the query returns a single row, or use LIMIT 1.
+CONTEXT:  PL/pgSQL function stricttest() line 8 at SQL statement
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- too many rows, no params
+  select * from foo where f1 > 3 into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+ERROR:  query returned more than one row
+HINT:  Make sure the query returns a single row, or use LIMIT 1.
+CONTEXT:  PL/pgSQL function stricttest() line 5 at SQL statement
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- no rows
+  execute 'select * from foo where f1 = $1 or f1::text = $2' using 0, 'foo' into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+ERROR:  query returned no rows
+DETAIL:  parameters: $1 = '0', $2 = 'foo'
+CONTEXT:  PL/pgSQL function stricttest() line 5 at EXECUTE
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- too many rows
+  execute 'select * from foo where f1 > $1' using 1 into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+ERROR:  query returned more than one row
+DETAIL:  parameters: $1 = '1'
+CONTEXT:  PL/pgSQL function stricttest() line 5 at EXECUTE
+create or replace function stricttest() returns void as $$
+declare x record;
+begin
+  -- too many rows, no parameters
+  execute 'select * from foo where f1 > 3' into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+ERROR:  query returned more than one row
+CONTEXT:  PL/pgSQL function stricttest() line 5 at EXECUTE
+create or replace function stricttest() returns void as $$
+-- override the global
+#print_strict_params off
+declare
+x record;
+p1 int := 2;
+p3 text := 'foo';
+begin
+  -- too many rows
+  select * from foo where f1 > p1 or f1::text = p3  into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+ERROR:  query returned more than one row
+HINT:  Make sure the query returns a single row, or use LIMIT 1.
+CONTEXT:  PL/pgSQL function stricttest() line 10 at SQL statement
+reset plpgsql.print_strict_params;
+create or replace function stricttest() returns void as $$
+-- override the global
+#print_strict_params on
+declare
+x record;
+p1 int := 2;
+p3 text := 'foo';
+begin
+  -- too many rows
+  select * from foo where f1 > p1 or f1::text = p3  into strict x;
+  raise notice 'x.f1 = %, x.f2 = %', x.f1, x.f2;
+end$$ language plpgsql;
+select stricttest();
+ERROR:  query returned more than one row
+DETAIL:  parameters: p1 = '2', p3 = 'foo'
+HINT:  Make sure the query returns a single row, or use LIMIT 1.
+CONTEXT:  PL/pgSQL function stricttest() line 10 at SQL statement
+-- test warnings and errors
+set plpgsql.extra_warnings to 'all';
+set plpgsql.extra_warnings to 'none';
+set plpgsql.extra_errors to 'all';
+set plpgsql.extra_errors to 'none';
+-- test warnings when shadowing a variable
+set plpgsql.extra_warnings to 'shadowed_variables';
+-- simple shadowing of input and output parameters
+create or replace function shadowtest(in1 int)
+	returns table (out1 int) as $$
+declare
+in1 int;
+out1 int;
+begin
+end
+$$ language plpgsql;
+WARNING:  variable "in1" shadows a previously defined variable
+LINE 4: in1 int;
+        ^
+WARNING:  variable "out1" shadows a previously defined variable
+LINE 5: out1 int;
+        ^
+select shadowtest(1);
+ shadowtest 
+------------
+(0 rows)
+
+set plpgsql.extra_warnings to 'shadowed_variables';
+select shadowtest(1);
+ shadowtest 
+------------
+(0 rows)
+
+create or replace function shadowtest(in1 int)
+	returns table (out1 int) as $$
+declare
+in1 int;
+out1 int;
+begin
+end
+$$ language plpgsql;
+WARNING:  variable "in1" shadows a previously defined variable
+LINE 4: in1 int;
+        ^
+WARNING:  variable "out1" shadows a previously defined variable
+LINE 5: out1 int;
+        ^
+select shadowtest(1);
+ shadowtest 
+------------
+(0 rows)
+
+drop function shadowtest(int);
+-- shadowing in a second DECLARE block
+create or replace function shadowtest()
+	returns void as $$
+declare
+f1 int;
+begin
+	declare
+	f1 int;
+	begin
+	end;
+end$$ language plpgsql;
+WARNING:  variable "f1" shadows a previously defined variable
+LINE 7:  f1 int;
+         ^
+drop function shadowtest();
+-- several levels of shadowing
+create or replace function shadowtest(in1 int)
+	returns void as $$
+declare
+in1 int;
+begin
+	declare
+	in1 int;
+	begin
+	end;
+end$$ language plpgsql;
+WARNING:  variable "in1" shadows a previously defined variable
+LINE 4: in1 int;
+        ^
+WARNING:  variable "in1" shadows a previously defined variable
+LINE 7:  in1 int;
+         ^
+drop function shadowtest(int);
+-- shadowing in cursor definitions
+create or replace function shadowtest()
+	returns void as $$
+declare
+f1 int;
+c1 cursor (f1 int) for select 1;
+begin
+end$$ language plpgsql;
+WARNING:  variable "f1" shadows a previously defined variable
+LINE 5: c1 cursor (f1 int) for select 1;
+                   ^
+drop function shadowtest();
+-- test errors when shadowing a variable
+set plpgsql.extra_errors to 'shadowed_variables';
+create or replace function shadowtest(f1 int)
+	returns boolean as $$
+declare f1 int; begin return 1; end $$ language plpgsql;
+ERROR:  variable "f1" shadows a previously defined variable
+LINE 3: declare f1 int; begin return 1; end $$ language plpgsql;
+                ^
+select shadowtest(1);
+ERROR:  function shadowtest(integer) does not exist
+LINE 1: select shadowtest(1);
+               ^
+HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
+reset plpgsql.extra_errors;
+reset plpgsql.extra_warnings;
+create or replace function shadowtest(f1 int)
+	returns boolean as $$
+declare f1 int; begin return 1; end $$ language plpgsql;
+select shadowtest(1);
+ shadowtest 
+------------
+ t
+(1 row)
+
+-- runtime extra checks
+set plpgsql.extra_warnings to 'too_many_rows';
+do $$
+declare x int;
+begin
+  select v from generate_series(1,2) g(v) into x;
+end;
+$$;
+WARNING:  query returned more than one row
+HINT:  Make sure the query returns a single row, or use LIMIT 1.
+set plpgsql.extra_errors to 'too_many_rows';
+do $$
+declare x int;
+begin
+  select v from generate_series(1,2) g(v) into x;
+end;
+$$;
+ERROR:  query returned more than one row
+HINT:  Make sure the query returns a single row, or use LIMIT 1.
+CONTEXT:  PL/pgSQL function inline_code_block line 4 at SQL statement
+reset plpgsql.extra_errors;
+reset plpgsql.extra_warnings;
+set plpgsql.extra_warnings to 'strict_multi_assignment';
+do $$
+declare
+  x int;
+  y int;
+begin
+  select 1 into x, y;
+  select 1,2 into x, y;
+  select 1,2,3 into x, y;
+end
+$$;
+WARNING:  number of source and target fields in assignment do not match
+DETAIL:  strict_multi_assignment check of extra_warnings is active.
+HINT:  Make sure the query returns the exact list of columns.
+WARNING:  number of source and target fields in assignment do not match
+DETAIL:  strict_multi_assignment check of extra_warnings is active.
+HINT:  Make sure the query returns the exact list of columns.
+set plpgsql.extra_errors to 'strict_multi_assignment';
+do $$
+declare
+  x int;
+  y int;
+begin
+  select 1 into x, y;
+  select 1,2 into x, y;
+  select 1,2,3 into x, y;
+end
+$$;
+ERROR:  number of source and target fields in assignment do not match
+DETAIL:  strict_multi_assignment check of extra_errors is active.
+HINT:  Make sure the query returns the exact list of columns.
+CONTEXT:  PL/pgSQL function inline_code_block line 6 at SQL statement
+create table test_01(a int, b int, c int);
+alter table test_01 drop column a;
+-- the check is active only when source table is not empty
+insert into test_01 values(10,20);
+do $$
+declare
+  x int;
+  y int;
+begin
+  select * from test_01 into x, y; -- should be ok
+  raise notice 'ok';
+  select * from test_01 into x;    -- should to fail
+end;
+$$;
+NOTICE:  ok
+ERROR:  number of source and target fields in assignment do not match
+DETAIL:  strict_multi_assignment check of extra_errors is active.
+HINT:  Make sure the query returns the exact list of columns.
+CONTEXT:  PL/pgSQL function inline_code_block line 8 at SQL statement
+do $$
+declare
+  t test_01;
+begin
+  select 1, 2 into t;  -- should be ok
+  raise notice 'ok';
+  select 1, 2, 3 into t; -- should fail;
+end;
+$$;
+NOTICE:  ok
+ERROR:  number of source and target fields in assignment do not match
+DETAIL:  strict_multi_assignment check of extra_errors is active.
+HINT:  Make sure the query returns the exact list of columns.
+CONTEXT:  PL/pgSQL function inline_code_block line 7 at SQL statement
+do $$
+declare
+  t test_01;
+begin
+  select 1 into t; -- should fail;
+end;
+$$;
+ERROR:  number of source and target fields in assignment do not match
+DETAIL:  strict_multi_assignment check of extra_errors is active.
+HINT:  Make sure the query returns the exact list of columns.
+CONTEXT:  PL/pgSQL function inline_code_block line 5 at SQL statement
+drop table test_01;
+reset plpgsql.extra_errors;
+reset plpgsql.extra_warnings;
+-- test scrollable cursor support
+create function sc_test() returns setof integer as $$
+declare
+  c scroll cursor for select f1 from int4_tbl;
+  x integer;
+begin
+  open c;
+  fetch last from c into x;
+  while found loop
+    return next x;
+    fetch prior from c into x;
+  end loop;
+  close c;
+end;
+$$ language plpgsql;
+select * from sc_test();
+   sc_test   
+-------------
+ -2147483647
+  2147483647
+     -123456
+      123456
+           0
+(5 rows)
+
+create or replace function sc_test() returns setof integer as $$
+declare
+  c no scroll cursor for select f1 from int4_tbl;
+  x integer;
+begin
+  open c;
+  fetch last from c into x;
+  while found loop
+    return next x;
+    fetch prior from c into x;
+  end loop;
+  close c;
+end;
+$$ language plpgsql;
+select * from sc_test();  -- fails because of NO SCROLL specification
+ERROR:  cursor can only scan forward
+HINT:  Declare it with SCROLL option to enable backward scan.
+CONTEXT:  PL/pgSQL function sc_test() line 7 at FETCH
+create or replace function sc_test() returns setof integer as $$
+declare
+  c refcursor;
+  x integer;
+begin
+  open c scroll for select f1 from int4_tbl;
+  fetch last from c into x;
+  while found loop
+    return next x;
+    fetch prior from c into x;
+  end loop;
+  close c;
+end;
+$$ language plpgsql;
+select * from sc_test();
+   sc_test   
+-------------
+ -2147483647
+  2147483647
+     -123456
+      123456
+           0
+(5 rows)
+
+create or replace function sc_test() returns setof integer as $$
+declare
+  c refcursor;
+  x integer;
+begin
+  open c scroll for execute 'select f1 from int4_tbl';
+  fetch last from c into x;
+  while found loop
+    return next x;
+    fetch relative -2 from c into x;
+  end loop;
+  close c;
+end;
+$$ language plpgsql;
+select * from sc_test();
+   sc_test   
+-------------
+ -2147483647
+     -123456
+           0
+(3 rows)
+
+create or replace function sc_test() returns setof integer as $$
+declare
+  c refcursor;
+  x integer;
+begin
+  open c scroll for execute 'select f1 from int4_tbl';
+  fetch last from c into x;
+  while found loop
+    return next x;
+    move backward 2 from c;
+    fetch relative -1 from c into x;
+  end loop;
+  close c;
+end;
+$$ language plpgsql;
+select * from sc_test();
+   sc_test   
+-------------
+ -2147483647
+      123456
+(2 rows)
+
+create or replace function sc_test() returns setof integer as $$
+declare
+  c cursor for select * from generate_series(1, 10);
+  x integer;
+begin
+  open c;
+  loop
+      move relative 2 in c;
+      if not found then
+          exit;
+      end if;
+      fetch next from c into x;
+      if found then
+          return next x;
+      end if;
+  end loop;
+  close c;
+end;
+$$ language plpgsql;
+select * from sc_test();
+ sc_test 
+---------
+       3
+       6
+       9
+(3 rows)
+
+create or replace function sc_test() returns setof integer as $$
+declare
+  c cursor for select * from generate_series(1, 10);
+  x integer;
+begin
+  open c;
+  move forward all in c;
+  fetch backward from c into x;
+  if found then
+    return next x;
+  end if;
+  close c;
+end;
+$$ language plpgsql;
+select * from sc_test();
+ sc_test 
+---------
+      10
+(1 row)
+
+drop function sc_test();
+-- test qualified variable names
+create function pl_qual_names (param1 int) returns void as $$
+<<outerblock>>
+declare
+  param1 int := 1;
+begin
+  <<innerblock>>
+  declare
+    param1 int := 2;
+  begin
+    raise notice 'param1 = %', param1;
+    raise notice 'pl_qual_names.param1 = %', pl_qual_names.param1;
+    raise notice 'outerblock.param1 = %', outerblock.param1;
+    raise notice 'innerblock.param1 = %', innerblock.param1;
+  end;
+end;
+$$ language plpgsql;
+select pl_qual_names(42);
+NOTICE:  param1 = 2
+NOTICE:  pl_qual_names.param1 = 42
+NOTICE:  outerblock.param1 = 1
+NOTICE:  innerblock.param1 = 2
+ pl_qual_names 
+---------------
+ 
+(1 row)
+
+drop function pl_qual_names(int);
+-- tests for RETURN QUERY
+create function ret_query1(out int, out int) returns setof record as $$
+begin
+    $1 := -1;
+    $2 := -2;
+    return next;
+    return query select x + 1, x * 10 from generate_series(0, 10) s (x);
+    return next;
+end;
+$$ language plpgsql;
+select * from ret_query1();
+ column1 | column2 
+---------+---------
+      -1 |      -2
+       1 |       0
+       2 |      10
+       3 |      20
+       4 |      30
+       5 |      40
+       6 |      50
+       7 |      60
+       8 |      70
+       9 |      80
+      10 |      90
+      11 |     100
+      -1 |      -2
+(13 rows)
+
+create type record_type as (x text, y int, z boolean);
+create or replace function ret_query2(lim int) returns setof record_type as $$
+begin
+    return query select md5(s.x::text), s.x, s.x > 0
+                 from generate_series(-8, lim) s (x) where s.x % 2 = 0;
+end;
+$$ language plpgsql;
+select * from ret_query2(8);
+                x                 | y  | z 
+----------------------------------+----+---
+ a8d2ec85eaf98407310b72eb73dda247 | -8 | f
+ 596a3d04481816330f07e4f97510c28f | -6 | f
+ 0267aaf632e87a63288a08331f22c7c3 | -4 | f
+ 5d7b9adcbe1c629ec722529dd12e5129 | -2 | f
+ cfcd208495d565ef66e7dff9f98764da |  0 | f
+ c81e728d9d4c2f636f067f89cc14862c |  2 | t
+ a87ff679a2f3e71d9181a67b7542122c |  4 | t
+ 1679091c5a880faf6fb5e6087eb1b2dc |  6 | t
+ c9f0f895fb98ab9159f51fd0297e236d |  8 | t
+(9 rows)
+
+-- test EXECUTE USING
+create function exc_using(int, text) returns int as $$
+declare i int;
+begin
+  for i in execute 'select * from generate_series(1,$1)' using $1+1 loop
+    raise notice '%', i;
+  end loop;
+  execute 'select $2 + $2*3 + length($1)' into i using $2,$1;
+  return i;
+end
+$$ language plpgsql;
+select exc_using(5, 'foobar');
+NOTICE:  1
+NOTICE:  2
+NOTICE:  3
+NOTICE:  4
+NOTICE:  5
+NOTICE:  6
+ exc_using 
+-----------
+        26
+(1 row)
+
+drop function exc_using(int, text);
+create or replace function exc_using(int) returns void as $$
+declare
+  c refcursor;
+  i int;
+begin
+  open c for execute 'select * from generate_series(1,$1)' using $1+1;
+  loop
+    fetch c into i;
+    exit when not found;
+    raise notice '%', i;
+  end loop;
+  close c;
+  return;
+end;
+$$ language plpgsql;
+select exc_using(5);
+NOTICE:  1
+NOTICE:  2
+NOTICE:  3
+NOTICE:  4
+NOTICE:  5
+NOTICE:  6
+ exc_using 
+-----------
+ 
+(1 row)
+
+drop function exc_using(int);
+-- test FOR-over-cursor
+create or replace function forc01() returns void as $$
+declare
+  c cursor(r1 integer, r2 integer)
+       for select * from generate_series(r1,r2) i;
+  c2 cursor
+       for select * from generate_series(41,43) i;
+begin
+  for r in c(5,7) loop
+    raise notice '% from %', r.i, c;
+  end loop;
+  -- again, to test if cursor was closed properly
+  for r in c(9,10) loop
+    raise notice '% from %', r.i, c;
+  end loop;
+  -- and test a parameterless cursor
+  for r in c2 loop
+    raise notice '% from %', r.i, c2;
+  end loop;
+  -- and try it with a hand-assigned name
+  raise notice 'after loop, c2 = %', c2;
+  c2 := 'special_name';
+  for r in c2 loop
+    raise notice '% from %', r.i, c2;
+  end loop;
+  raise notice 'after loop, c2 = %', c2;
+  -- and try it with a generated name
+  -- (which we can't show in the output because it's variable)
+  c2 := null;
+  for r in c2 loop
+    raise notice '%', r.i;
+  end loop;
+  raise notice 'after loop, c2 = %', c2;
+  return;
+end;
+$$ language plpgsql;
+select forc01();
+NOTICE:  5 from c
+NOTICE:  6 from c
+NOTICE:  7 from c
+NOTICE:  9 from c
+NOTICE:  10 from c
+NOTICE:  41 from c2
+NOTICE:  42 from c2
+NOTICE:  43 from c2
+NOTICE:  after loop, c2 = c2
+NOTICE:  41 from special_name
+NOTICE:  42 from special_name
+NOTICE:  43 from special_name
+NOTICE:  after loop, c2 = special_name
+NOTICE:  41
+NOTICE:  42
+NOTICE:  43
+NOTICE:  after loop, c2 = <NULL>
+ forc01 
+--------
+ 
+(1 row)
+
+-- try updating the cursor's current row
+create temp table forc_test as
+  select n as i, n as j from generate_series(1,10) n;
+create or replace function forc01() returns void as $$
+declare
+  c cursor for select * from forc_test;
+begin
+  for r in c loop
+    raise notice '%, %', r.i, r.j;
+    update forc_test set i = i * 100, j = r.j * 2 where current of c;
+  end loop;
+end;
+$$ language plpgsql;
+select forc01();
+NOTICE:  1, 1
+NOTICE:  2, 2
+NOTICE:  3, 3
+NOTICE:  4, 4
+NOTICE:  5, 5
+NOTICE:  6, 6
+NOTICE:  7, 7
+NOTICE:  8, 8
+NOTICE:  9, 9
+NOTICE:  10, 10
+ forc01 
+--------
+ 
+(1 row)
+
+select * from forc_test;
+  i   | j  
+------+----
+  100 |  2
+  200 |  4
+  300 |  6
+  400 |  8
+  500 | 10
+  600 | 12
+  700 | 14
+  800 | 16
+  900 | 18
+ 1000 | 20
+(10 rows)
+
+-- same, with a cursor whose portal name doesn't match variable name
+create or replace function forc01() returns void as $$
+declare
+  c refcursor := 'fooled_ya';
+  r record;
+begin
+  open c for select * from forc_test;
+  loop
+    fetch c into r;
+    exit when not found;
+    raise notice '%, %', r.i, r.j;
+    update forc_test set i = i * 100, j = r.j * 2 where current of c;
+  end loop;
+end;
+$$ language plpgsql;
+select forc01();
+NOTICE:  100, 2
+NOTICE:  200, 4
+NOTICE:  300, 6
+NOTICE:  400, 8
+NOTICE:  500, 10
+NOTICE:  600, 12
+NOTICE:  700, 14
+NOTICE:  800, 16
+NOTICE:  900, 18
+NOTICE:  1000, 20
+ forc01 
+--------
+ 
+(1 row)
+
+select * from forc_test;
+   i    | j  
+--------+----
+  10000 |  4
+  20000 |  8
+  30000 | 12
+  40000 | 16
+  50000 | 20
+  60000 | 24
+  70000 | 28
+  80000 | 32
+  90000 | 36
+ 100000 | 40
+(10 rows)
+
+drop function forc01();
+-- fail because cursor has no query bound to it
+create or replace function forc_bad() returns void as $$
+declare
+  c refcursor;
+begin
+  for r in c loop
+    raise notice '%', r.i;
+  end loop;
+end;
+$$ language plpgsql;
+ERROR:  cursor FOR loop must use a bound cursor variable
+LINE 5:   for r in c loop
+                   ^
+-- test RETURN QUERY EXECUTE
+create or replace function return_dquery()
+returns setof int as $$
+begin
+  return query execute 'select * from (values(10),(20)) f';
+  return query execute 'select * from (values($1),($2)) f' using 40,50;
+end;
+$$ language plpgsql;
+select * from return_dquery();
+ return_dquery 
+---------------
+            10
+            20
+            40
+            50
+(4 rows)
+
+drop function return_dquery();
+-- test RETURN QUERY with dropped columns
+create table tabwithcols(a int, b int, c int, d int);
+insert into tabwithcols values(10,20,30,40),(50,60,70,80);
+create or replace function returnqueryf()
+returns setof tabwithcols as $$
+begin
+  return query select * from tabwithcols;
+  return query execute 'select * from tabwithcols';
+end;
+$$ language plpgsql;
+select * from returnqueryf();
+ a  | b  | c  | d  
+----+----+----+----
+ 10 | 20 | 30 | 40
+ 50 | 60 | 70 | 80
+ 10 | 20 | 30 | 40
+ 50 | 60 | 70 | 80
+(4 rows)
+
+alter table tabwithcols drop column b;
+select * from returnqueryf();
+ a  | c  | d  
+----+----+----
+ 10 | 30 | 40
+ 50 | 70 | 80
+ 10 | 30 | 40
+ 50 | 70 | 80
+(4 rows)
+
+alter table tabwithcols drop column d;
+select * from returnqueryf();
+ a  | c  
+----+----
+ 10 | 30
+ 50 | 70
+ 10 | 30
+ 50 | 70
+(4 rows)
+
+alter table tabwithcols add column d int;
+select * from returnqueryf();
+ a  | c  | d 
+----+----+---
+ 10 | 30 |  
+ 50 | 70 |  
+ 10 | 30 |  
+ 50 | 70 |  
+(4 rows)
+
+drop function returnqueryf();
+drop table tabwithcols;
+--
+-- Tests for composite-type results
+--
+create type compostype as (x int, y varchar);
+-- test: use of variable of composite type in return statement
+create or replace function compos() returns compostype as $$
+declare
+  v compostype;
+begin
+  v := (1, 'hello');
+  return v;
+end;
+$$ language plpgsql;
+select compos();
+  compos   
+-----------
+ (1,hello)
+(1 row)
+
+-- test: use of variable of record type in return statement
+create or replace function compos() returns compostype as $$
+declare
+  v record;
+begin
+  v := (1, 'hello'::varchar);
+  return v;
+end;
+$$ language plpgsql;
+select compos();
+  compos   
+-----------
+ (1,hello)
+(1 row)
+
+-- test: use of row expr in return statement
+create or replace function compos() returns compostype as $$
+begin
+  return (1, 'hello'::varchar);
+end;
+$$ language plpgsql;
+select compos();
+  compos   
+-----------
+ (1,hello)
+(1 row)
+
+-- this does not work currently (no implicit casting)
+create or replace function compos() returns compostype as $$
+begin
+  return (1, 'hello');
+end;
+$$ language plpgsql;
+select compos();
+ERROR:  returned record type does not match expected record type
+DETAIL:  Returned type unknown does not match expected type character varying in column 2.
+CONTEXT:  PL/pgSQL function compos() while casting return value to function's return type
+-- ... but this does
+create or replace function compos() returns compostype as $$
+begin
+  return (1, 'hello')::compostype;
+end;
+$$ language plpgsql;
+select compos();
+  compos   
+-----------
+ (1,hello)
+(1 row)
+
+drop function compos();
+-- test: return a row expr as record.
+create or replace function composrec() returns record as $$
+declare
+  v record;
+begin
+  v := (1, 'hello');
+  return v;
+end;
+$$ language plpgsql;
+select composrec();
+ composrec 
+-----------
+ (1,hello)
+(1 row)
+
+-- test: return row expr in return statement.
+create or replace function composrec() returns record as $$
+begin
+  return (1, 'hello');
+end;
+$$ language plpgsql;
+select composrec();
+ composrec 
+-----------
+ (1,hello)
+(1 row)
+
+drop function composrec();
+-- test: row expr in RETURN NEXT statement.
+create or replace function compos() returns setof compostype as $$
+begin
+  for i in 1..3
+  loop
+    return next (1, 'hello'::varchar);
+  end loop;
+  return next null::compostype;
+  return next (2, 'goodbye')::compostype;
+end;
+$$ language plpgsql;
+select * from compos();
+ x |    y    
+---+---------
+ 1 | hello
+ 1 | hello
+ 1 | hello
+   | 
+ 2 | goodbye
+(5 rows)
+
+drop function compos();
+-- test: use invalid expr in return statement.
+create or replace function compos() returns compostype as $$
+begin
+  return 1 + 1;
+end;
+$$ language plpgsql;
+select compos();
+ERROR:  cannot return non-composite value from function returning composite type
+CONTEXT:  PL/pgSQL function compos() line 3 at RETURN
+-- RETURN variable is a different code path ...
+create or replace function compos() returns compostype as $$
+declare x int := 42;
+begin
+  return x;
+end;
+$$ language plpgsql;
+select * from compos();
+ERROR:  cannot return non-composite value from function returning composite type
+CONTEXT:  PL/pgSQL function compos() line 4 at RETURN
+drop function compos();
+-- test: invalid use of composite variable in scalar-returning function
+create or replace function compos() returns int as $$
+declare
+  v compostype;
+begin
+  v := (1, 'hello');
+  return v;
+end;
+$$ language plpgsql;
+select compos();
+ERROR:  invalid input syntax for type integer: "(1,hello)"
+CONTEXT:  PL/pgSQL function compos() while casting return value to function's return type
+-- test: invalid use of composite expression in scalar-returning function
+create or replace function compos() returns int as $$
+begin
+  return (1, 'hello')::compostype;
+end;
+$$ language plpgsql;
+select compos();
+ERROR:  invalid input syntax for type integer: "(1,hello)"
+CONTEXT:  PL/pgSQL function compos() while casting return value to function's return type
+drop function compos();
+drop type compostype;
+--
+-- Tests for 8.4's new RAISE features
+--
+create or replace function raise_test() returns void as $$
+begin
+  raise notice '% % %', 1, 2, 3
+     using errcode = '55001', detail = 'some detail info', hint = 'some hint';
+  raise '% % %', 1, 2, 3
+     using errcode = 'division_by_zero', detail = 'some detail info';
+end;
+$$ language plpgsql;
+select raise_test();
+NOTICE:  1 2 3
+DETAIL:  some detail info
+HINT:  some hint
+ERROR:  1 2 3
+DETAIL:  some detail info
+CONTEXT:  PL/pgSQL function raise_test() line 5 at RAISE
+-- Since we can't actually see the thrown SQLSTATE in default psql output,
+-- test it like this; this also tests re-RAISE
+create or replace function raise_test() returns void as $$
+begin
+  raise 'check me'
+     using errcode = 'division_by_zero', detail = 'some detail info';
+  exception
+    when others then
+      raise notice 'SQLSTATE: % SQLERRM: %', sqlstate, sqlerrm;
+      raise;
+end;
+$$ language plpgsql;
+select raise_test();
+NOTICE:  SQLSTATE: 22012 SQLERRM: check me
+ERROR:  check me
+DETAIL:  some detail info
+CONTEXT:  PL/pgSQL function raise_test() line 3 at RAISE
+create or replace function raise_test() returns void as $$
+begin
+  raise 'check me'
+     using errcode = '1234F', detail = 'some detail info';
+  exception
+    when others then
+      raise notice 'SQLSTATE: % SQLERRM: %', sqlstate, sqlerrm;
+      raise;
+end;
+$$ language plpgsql;
+select raise_test();
+NOTICE:  SQLSTATE: 1234F SQLERRM: check me
+ERROR:  check me
+DETAIL:  some detail info
+CONTEXT:  PL/pgSQL function raise_test() line 3 at RAISE
+-- SQLSTATE specification in WHEN
+create or replace function raise_test() returns void as $$
+begin
+  raise 'check me'
+     using errcode = '1234F', detail = 'some detail info';
+  exception
+    when sqlstate '1234F' then
+      raise notice 'SQLSTATE: % SQLERRM: %', sqlstate, sqlerrm;
+      raise;
+end;
+$$ language plpgsql;
+select raise_test();
+NOTICE:  SQLSTATE: 1234F SQLERRM: check me
+ERROR:  check me
+DETAIL:  some detail info
+CONTEXT:  PL/pgSQL function raise_test() line 3 at RAISE
+create or replace function raise_test() returns void as $$
+begin
+  raise division_by_zero using detail = 'some detail info';
+  exception
+    when others then
+      raise notice 'SQLSTATE: % SQLERRM: %', sqlstate, sqlerrm;
+      raise;
+end;
+$$ language plpgsql;
+select raise_test();
+NOTICE:  SQLSTATE: 22012 SQLERRM: division_by_zero
+ERROR:  division_by_zero
+DETAIL:  some detail info
+CONTEXT:  PL/pgSQL function raise_test() line 3 at RAISE
+create or replace function raise_test() returns void as $$
+begin
+  raise division_by_zero;
+end;
+$$ language plpgsql;
+select raise_test();
+ERROR:  division_by_zero
+CONTEXT:  PL/pgSQL function raise_test() line 3 at RAISE
+create or replace function raise_test() returns void as $$
+begin
+  raise sqlstate '1234F';
+end;
+$$ language plpgsql;
+select raise_test();
+ERROR:  1234F
+CONTEXT:  PL/pgSQL function raise_test() line 3 at RAISE
+create or replace function raise_test() returns void as $$
+begin
+  raise division_by_zero using message = 'custom' || ' message';
+end;
+$$ language plpgsql;
+select raise_test();
+ERROR:  custom message
+CONTEXT:  PL/pgSQL function raise_test() line 3 at RAISE
+create or replace function raise_test() returns void as $$
+begin
+  raise using message = 'custom' || ' message', errcode = '22012';
+end;
+$$ language plpgsql;
+select raise_test();
+ERROR:  custom message
+CONTEXT:  PL/pgSQL function raise_test() line 3 at RAISE
+-- conflict on message
+create or replace function raise_test() returns void as $$
+begin
+  raise notice 'some message' using message = 'custom' || ' message', errcode = '22012';
+end;
+$$ language plpgsql;
+select raise_test();
+ERROR:  RAISE option already specified: MESSAGE
+CONTEXT:  PL/pgSQL function raise_test() line 3 at RAISE
+-- conflict on errcode
+create or replace function raise_test() returns void as $$
+begin
+  raise division_by_zero using message = 'custom' || ' message', errcode = '22012';
+end;
+$$ language plpgsql;
+select raise_test();
+ERROR:  RAISE option already specified: ERRCODE
+CONTEXT:  PL/pgSQL function raise_test() line 3 at RAISE
+-- nothing to re-RAISE
+create or replace function raise_test() returns void as $$
+begin
+  raise;
+end;
+$$ language plpgsql;
+select raise_test();
+ERROR:  RAISE without parameters cannot be used outside an exception handler
+CONTEXT:  PL/pgSQL function raise_test() line 3 at RAISE
+-- test access to exception data
+create function zero_divide() returns int as $$
+declare v int := 0;
+begin
+  return 10 / v;
+end;
+$$ language plpgsql;
+create or replace function raise_test() returns void as $$
+begin
+  raise exception 'custom exception'
+     using detail = 'some detail of custom exception',
+           hint = 'some hint related to custom exception';
+end;
+$$ language plpgsql;
+create function stacked_diagnostics_test() returns void as $$
+declare _sqlstate text;
+        _message text;
+        _context text;
+begin
+  perform zero_divide();
+exception when others then
+  get stacked diagnostics
+        _sqlstate = returned_sqlstate,
+        _message = message_text,
+        _context = pg_exception_context;
+  raise notice 'sqlstate: %, message: %, context: [%]',
+    _sqlstate, _message, replace(_context, E'\n', ' <- ');
+end;
+$$ language plpgsql;
+select stacked_diagnostics_test();
+NOTICE:  sqlstate: 22012, message: division by zero, context: [PL/pgSQL function zero_divide() line 4 at RETURN <- SQL statement "SELECT zero_divide()" <- PL/pgSQL function stacked_diagnostics_test() line 6 at PERFORM]
+ stacked_diagnostics_test 
+--------------------------
+ 
+(1 row)
+
+create or replace function stacked_diagnostics_test() returns void as $$
+declare _detail text;
+        _hint text;
+        _message text;
+begin
+  perform raise_test();
+exception when others then
+  get stacked diagnostics
+        _message = message_text,
+        _detail = pg_exception_detail,
+        _hint = pg_exception_hint;
+  raise notice 'message: %, detail: %, hint: %', _message, _detail, _hint;
+end;
+$$ language plpgsql;
+select stacked_diagnostics_test();
+NOTICE:  message: custom exception, detail: some detail of custom exception, hint: some hint related to custom exception
+ stacked_diagnostics_test 
+--------------------------
+ 
+(1 row)
+
+-- fail, cannot use stacked diagnostics statement outside handler
+create or replace function stacked_diagnostics_test() returns void as $$
+declare _detail text;
+        _hint text;
+        _message text;
+begin
+  get stacked diagnostics
+        _message = message_text,
+        _detail = pg_exception_detail,
+        _hint = pg_exception_hint;
+  raise notice 'message: %, detail: %, hint: %', _message, _detail, _hint;
+end;
+$$ language plpgsql;
+select stacked_diagnostics_test();
+ERROR:  GET STACKED DIAGNOSTICS cannot be used outside an exception handler
+CONTEXT:  PL/pgSQL function stacked_diagnostics_test() line 6 at GET STACKED DIAGNOSTICS
+drop function zero_divide();
+drop function stacked_diagnostics_test();
+-- check cases where implicit SQLSTATE variable could be confused with
+-- SQLSTATE as a keyword, cf bug #5524
+create or replace function raise_test() returns void as $$
+begin
+  perform 1/0;
+exception
+  when sqlstate '22012' then
+    raise notice using message = sqlstate;
+    raise sqlstate '22012' using message = 'substitute message';
+end;
+$$ language plpgsql;
+select raise_test();
+NOTICE:  22012
+ERROR:  substitute message
+CONTEXT:  PL/pgSQL function raise_test() line 7 at RAISE
+drop function raise_test();
+-- test passing column_name, constraint_name, datatype_name, table_name
+-- and schema_name error fields
+create or replace function stacked_diagnostics_test() returns void as $$
+declare _column_name text;
+        _constraint_name text;
+        _datatype_name text;
+        _table_name text;
+        _schema_name text;
+begin
+  raise exception using
+    column = '>>some column name<<',
+    constraint = '>>some constraint name<<',
+    datatype = '>>some datatype name<<',
+    table = '>>some table name<<',
+    schema = '>>some schema name<<';
+exception when others then
+  get stacked diagnostics
+        _column_name = column_name,
+        _constraint_name = constraint_name,
+        _datatype_name = pg_datatype_name,
+        _table_name = table_name,
+        _schema_name = schema_name;
+  raise notice 'column %, constraint %, type %, table %, schema %',
+    _column_name, _constraint_name, _datatype_name, _table_name, _schema_name;
+end;
+$$ language plpgsql;
+select stacked_diagnostics_test();
+NOTICE:  column >>some column name<<, constraint >>some constraint name<<, type >>some datatype name<<, table >>some table name<<, schema >>some schema name<<
+ stacked_diagnostics_test 
+--------------------------
+ 
+(1 row)
+
+drop function stacked_diagnostics_test();
+-- test variadic functions
+create or replace function vari(variadic int[])
+returns void as $$
+begin
+  for i in array_lower($1,1)..array_upper($1,1) loop
+    raise notice '%', $1[i];
+  end loop; end;
+$$ language plpgsql;
+select vari(1,2,3,4,5);
+NOTICE:  1
+NOTICE:  2
+NOTICE:  3
+NOTICE:  4
+NOTICE:  5
+ vari 
+------
+ 
+(1 row)
+
+select vari(3,4,5);
+NOTICE:  3
+NOTICE:  4
+NOTICE:  5
+ vari 
+------
+ 
+(1 row)
+
+select vari(variadic array[5,6,7]);
+NOTICE:  5
+NOTICE:  6
+NOTICE:  7
+ vari 
+------
+ 
+(1 row)
+
+drop function vari(int[]);
+-- coercion test
+create or replace function pleast(variadic numeric[])
+returns numeric as $$
+declare aux numeric = $1[array_lower($1,1)];
+begin
+  for i in array_lower($1,1)+1..array_upper($1,1) loop
+    if $1[i] < aux then aux := $1[i]; end if;
+  end loop;
+  return aux;
+end;
+$$ language plpgsql immutable strict;
+select pleast(10,1,2,3,-16);
+ pleast 
+--------
+    -16
+(1 row)
+
+select pleast(10.2,2.2,-1.1);
+ pleast 
+--------
+   -1.1
+(1 row)
+
+select pleast(10.2,10, -20);
+ pleast 
+--------
+    -20
+(1 row)
+
+select pleast(10,20, -1.0);
+ pleast 
+--------
+   -1.0
+(1 row)
+
+-- in case of conflict, non-variadic version is preferred
+create or replace function pleast(numeric)
+returns numeric as $$
+begin
+  raise notice 'non-variadic function called';
+  return $1;
+end;
+$$ language plpgsql immutable strict;
+select pleast(10);
+NOTICE:  non-variadic function called
+ pleast 
+--------
+     10
+(1 row)
+
+drop function pleast(numeric[]);
+drop function pleast(numeric);
+-- test table functions
+create function tftest(int) returns table(a int, b int) as $$
+begin
+  return query select $1, $1+i from generate_series(1,5) g(i);
+end;
+$$ language plpgsql immutable strict;
+select * from tftest(10);
+ a  | b  
+----+----
+ 10 | 11
+ 10 | 12
+ 10 | 13
+ 10 | 14
+ 10 | 15
+(5 rows)
+
+create or replace function tftest(a1 int) returns table(a int, b int) as $$
+begin
+  a := a1; b := a1 + 1;
+  return next;
+  a := a1 * 10; b := a1 * 10 + 1;
+  return next;
+end;
+$$ language plpgsql immutable strict;
+select * from tftest(10);
+  a  |  b  
+-----+-----
+  10 |  11
+ 100 | 101
+(2 rows)
+
+drop function tftest(int);
+create or replace function rttest()
+returns setof int as $$
+declare rc int;
+  rca int[];
+begin
+  return query values(10),(20);
+  get diagnostics rc = row_count;
+  raise notice '% %', found, rc;
+  return query select * from (values(10),(20)) f(a) where false;
+  get diagnostics rc = row_count;
+  raise notice '% %', found, rc;
+  return query execute 'values(10),(20)';
+  -- just for fun, let's use array elements as targets
+  get diagnostics rca[1] = row_count;
+  raise notice '% %', found, rca[1];
+  return query execute 'select * from (values(10),(20)) f(a) where false';
+  get diagnostics rca[2] = row_count;
+  raise notice '% %', found, rca[2];
+end;
+$$ language plpgsql;
+select * from rttest();
+NOTICE:  t 2
+NOTICE:  f 0
+NOTICE:  t 2
+NOTICE:  f 0
+ rttest 
+--------
+     10
+     20
+     10
+     20
+(4 rows)
+
+drop function rttest();
+-- Test for proper cleanup at subtransaction exit.  This example
+-- exposed a bug in PG 8.2.
+CREATE FUNCTION leaker_1(fail BOOL) RETURNS INTEGER AS $$
+DECLARE
+  v_var INTEGER;
+BEGIN
+  BEGIN
+    v_var := (leaker_2(fail)).error_code;
+  EXCEPTION
+    WHEN others THEN RETURN 0;
+  END;
+  RETURN 1;
+END;
+$$ LANGUAGE plpgsql;
+CREATE FUNCTION leaker_2(fail BOOL, OUT error_code INTEGER, OUT new_id INTEGER)
+  RETURNS RECORD AS $$
+BEGIN
+  IF fail THEN
+    RAISE EXCEPTION 'fail ...';
+  END IF;
+  error_code := 1;
+  new_id := 1;
+  RETURN;
+END;
+$$ LANGUAGE plpgsql;
+SELECT * FROM leaker_1(false);
+ leaker_1 
+----------
+        1
+(1 row)
+
+SELECT * FROM leaker_1(true);
+ leaker_1 
+----------
+        0
+(1 row)
+
+DROP FUNCTION leaker_1(bool);
+DROP FUNCTION leaker_2(bool);
+-- Test for appropriate cleanup of non-simple expression evaluations
+-- (bug in all versions prior to August 2010)
+CREATE FUNCTION nonsimple_expr_test() RETURNS text[] AS $$
+DECLARE
+  arr text[];
+  lr text;
+  i integer;
+BEGIN
+  arr := array[array['foo','bar'], array['baz', 'quux']];
+  lr := 'fool';
+  i := 1;
+  -- use sub-SELECTs to make expressions non-simple
+  arr[(SELECT i)][(SELECT i+1)] := (SELECT lr);
+  RETURN arr;
+END;
+$$ LANGUAGE plpgsql;
+SELECT nonsimple_expr_test();
+   nonsimple_expr_test   
+-------------------------
+ {{foo,fool},{baz,quux}}
+(1 row)
+
+DROP FUNCTION nonsimple_expr_test();
+CREATE FUNCTION nonsimple_expr_test() RETURNS integer AS $$
+declare
+   i integer NOT NULL := 0;
+begin
+  begin
+    i := (SELECT NULL::integer);  -- should throw error
+  exception
+    WHEN OTHERS THEN
+      i := (SELECT 1::integer);
+  end;
+  return i;
+end;
+$$ LANGUAGE plpgsql;
+SELECT nonsimple_expr_test();
+ nonsimple_expr_test 
+---------------------
+                   1
+(1 row)
+
+DROP FUNCTION nonsimple_expr_test();
+--
+-- Test cases involving recursion and error recovery in simple expressions
+-- (bugs in all versions before October 2010).  The problems are most
+-- easily exposed by mutual recursion between plpgsql and sql functions.
+--
+create function recurse(float8) returns float8 as
+$$
+begin
+  if ($1 > 0) then
+    return sql_recurse($1 - 1);
+  else
+    return $1;
+  end if;
+end;
+$$ language plpgsql;
+-- "limit" is to prevent this from being inlined
+create function sql_recurse(float8) returns float8 as
+$$ select recurse($1) limit 1; $$ language sql;
+select recurse(10);
+ recurse 
+---------
+       0
+(1 row)
+
+create function error1(text) returns text language sql as
+$$ SELECT relname::text FROM pg_class c WHERE c.oid = $1::regclass $$;
+create function error2(p_name_table text) returns text language plpgsql as $$
+begin
+  return error1(p_name_table);
+end$$;
+BEGIN;
+create table public.stuffs (stuff text);
+SAVEPOINT a;
+select error2('nonexistent.stuffs');
+ERROR:  schema "nonexistent" does not exist
+CONTEXT:  SQL function "error1" statement 1
+PL/pgSQL function error2(text) line 3 at RETURN
+ROLLBACK TO a;
+select error2('public.stuffs');
+ error2 
+--------
+ stuffs
+(1 row)
+
+rollback;
+drop function error2(p_name_table text);
+drop function error1(text);
+-- Test for proper handling of cast-expression caching
+create function sql_to_date(integer) returns date as $$
+select $1::text::date
+$$ language sql immutable strict;
+create cast (integer as date) with function sql_to_date(integer) as assignment;
+create function cast_invoker(integer) returns date as $$
+begin
+  return $1;
+end$$ language plpgsql;
+select cast_invoker(20150717);
+ cast_invoker 
+--------------
+ 07-17-2015
+(1 row)
+
+select cast_invoker(20150718);  -- second call crashed in pre-release 9.5
+ cast_invoker 
+--------------
+ 07-18-2015
+(1 row)
+
+begin;
+select cast_invoker(20150717);
+ cast_invoker 
+--------------
+ 07-17-2015
+(1 row)
+
+select cast_invoker(20150718);
+ cast_invoker 
+--------------
+ 07-18-2015
+(1 row)
+
+savepoint s1;
+select cast_invoker(20150718);
+ cast_invoker 
+--------------
+ 07-18-2015
+(1 row)
+
+select cast_invoker(-1); -- fails
+ERROR:  invalid input syntax for type date: "-1"
+CONTEXT:  SQL function "sql_to_date" statement 1
+PL/pgSQL function cast_invoker(integer) while casting return value to function's return type
+rollback to savepoint s1;
+select cast_invoker(20150719);
+ cast_invoker 
+--------------
+ 07-19-2015
+(1 row)
+
+select cast_invoker(20150720);
+ cast_invoker 
+--------------
+ 07-20-2015
+(1 row)
+
+commit;
+drop function cast_invoker(integer);
+drop function sql_to_date(integer) cascade;
+NOTICE:  drop cascades to cast from integer to date
+-- Test handling of cast cache inside DO blocks
+-- (to check the original crash case, this must be a cast not previously
+-- used in this session)
+begin;
+do $$ declare x text[]; begin x := '{1.23, 4.56}'::numeric[]; end $$;
+do $$ declare x text[]; begin x := '{1.23, 4.56}'::numeric[]; end $$;
+end;
+-- Test for consistent reporting of error context
+create function fail() returns int language plpgsql as $$
+begin
+  return 1/0;
+end
+$$;
+select fail();
+ERROR:  division by zero
+CONTEXT:  SQL statement "SELECT 1/0"
+PL/pgSQL function fail() line 3 at RETURN
+select fail();
+ERROR:  division by zero
+CONTEXT:  SQL statement "SELECT 1/0"
+PL/pgSQL function fail() line 3 at RETURN
+drop function fail();
+-- Test handling of string literals.
+set standard_conforming_strings = off;
+create or replace function strtest() returns text as $$
+begin
+  raise notice 'foo\\bar\041baz';
+  return 'foo\\bar\041baz';
+end
+$$ language plpgsql;
+WARNING:  nonstandard use of \\ in a string literal
+LINE 3:   raise notice 'foo\\bar\041baz';
+                       ^
+HINT:  Use the escape string syntax for backslashes, e.g., E'\\'.
+WARNING:  nonstandard use of \\ in a string literal
+LINE 4:   return 'foo\\bar\041baz';
+                 ^
+HINT:  Use the escape string syntax for backslashes, e.g., E'\\'.
+WARNING:  nonstandard use of \\ in a string literal
+LINE 4:   return 'foo\\bar\041baz';
+                 ^
+HINT:  Use the escape string syntax for backslashes, e.g., E'\\'.
+select strtest();
+NOTICE:  foo\bar!baz
+WARNING:  nonstandard use of \\ in a string literal
+LINE 1: SELECT 'foo\\bar\041baz'
+               ^
+HINT:  Use the escape string syntax for backslashes, e.g., E'\\'.
+QUERY:  SELECT 'foo\\bar\041baz'
+   strtest   
+-------------
+ foo\bar!baz
+(1 row)
+
+create or replace function strtest() returns text as $$
+begin
+  raise notice E'foo\\bar\041baz';
+  return E'foo\\bar\041baz';
+end
+$$ language plpgsql;
+select strtest();
+NOTICE:  foo\bar!baz
+   strtest   
+-------------
+ foo\bar!baz
+(1 row)
+
+set standard_conforming_strings = on;
+create or replace function strtest() returns text as $$
+begin
+  raise notice 'foo\\bar\041baz\';
+  return 'foo\\bar\041baz\';
+end
+$$ language plpgsql;
+select strtest();
+NOTICE:  foo\\bar\041baz\
+     strtest      
+------------------
+ foo\\bar\041baz\
+(1 row)
+
+create or replace function strtest() returns text as $$
+begin
+  raise notice E'foo\\bar\041baz';
+  return E'foo\\bar\041baz';
+end
+$$ language plpgsql;
+select strtest();
+NOTICE:  foo\bar!baz
+   strtest   
+-------------
+ foo\bar!baz
+(1 row)
+
+drop function strtest();
+-- Test anonymous code blocks.
+DO $$
+DECLARE r record;
+BEGIN
+    FOR r IN SELECT rtrim(roomno) AS roomno, comment FROM Room ORDER BY roomno
+    LOOP
+        RAISE NOTICE '%, %', r.roomno, r.comment;
+    END LOOP;
+END$$;
+NOTICE:  001, Entrance
+NOTICE:  002, Office
+NOTICE:  003, Office
+NOTICE:  004, Technical
+NOTICE:  101, Office
+NOTICE:  102, Conference
+NOTICE:  103, Restroom
+NOTICE:  104, Technical
+NOTICE:  105, Office
+NOTICE:  106, Office
+-- these are to check syntax error reporting
+DO LANGUAGE plpgsql $$begin return 1; end$$;
+ERROR:  RETURN cannot have a parameter in function returning void
+LINE 1: DO LANGUAGE plpgsql $$begin return 1; end$$;
+                                           ^
+DO $$
+DECLARE r record;
+BEGIN
+    FOR r IN SELECT rtrim(roomno) AS roomno, foo FROM Room ORDER BY roomno
+    LOOP
+        RAISE NOTICE '%, %', r.roomno, r.comment;
+    END LOOP;
+END$$;
+ERROR:  column "foo" does not exist
+LINE 1: SELECT rtrim(roomno) AS roomno, foo FROM Room ORDER BY roomn...
+                                        ^
+QUERY:  SELECT rtrim(roomno) AS roomno, foo FROM Room ORDER BY roomno
+CONTEXT:  PL/pgSQL function inline_code_block line 4 at FOR over SELECT rows
+-- Check handling of errors thrown from/into anonymous code blocks.
+do $outer$
+begin
+  for i in 1..10 loop
+   begin
+    execute $ex$
+      do $$
+      declare x int = 0;
+      begin
+        x := 1 / x;
+      end;
+      $$;
+    $ex$;
+  exception when division_by_zero then
+    raise notice 'caught division by zero';
+  end;
+  end loop;
+end;
+$outer$;
+NOTICE:  caught division by zero
+NOTICE:  caught division by zero
+NOTICE:  caught division by zero
+NOTICE:  caught division by zero
+NOTICE:  caught division by zero
+NOTICE:  caught division by zero
+NOTICE:  caught division by zero
+NOTICE:  caught division by zero
+NOTICE:  caught division by zero
+NOTICE:  caught division by zero
+-- Check variable scoping -- a var is not available in its own or prior
+-- default expressions.
+create function scope_test() returns int as $$
+declare x int := 42;
+begin
+  declare y int := x + 1;
+          x int := x + 2;
+  begin
+    return x * 100 + y;
+  end;
+end;
+$$ language plpgsql;
+select scope_test();
+ scope_test 
+------------
+       4443
+(1 row)
+
+drop function scope_test();
+-- Check handling of conflicts between plpgsql vars and table columns.
+set plpgsql.variable_conflict = error;
+create function conflict_test() returns setof int8_tbl as $$
+declare r record;
+  q1 bigint := 42;
+begin
+  for r in select q1,q2 from int8_tbl loop
+    return next r;
+  end loop;
+end;
+$$ language plpgsql;
+select * from conflict_test();
+ERROR:  column reference "q1" is ambiguous
+LINE 1: select q1,q2 from int8_tbl
+               ^
+DETAIL:  It could refer to either a PL/pgSQL variable or a table column.
+QUERY:  select q1,q2 from int8_tbl
+CONTEXT:  PL/pgSQL function conflict_test() line 5 at FOR over SELECT rows
+create or replace function conflict_test() returns setof int8_tbl as $$
+#variable_conflict use_variable
+declare r record;
+  q1 bigint := 42;
+begin
+  for r in select q1,q2 from int8_tbl loop
+    return next r;
+  end loop;
+end;
+$$ language plpgsql;
+select * from conflict_test();
+ q1 |        q2         
+----+-------------------
+ 42 |               456
+ 42 |  4567890123456789
+ 42 |               123
+ 42 |  4567890123456789
+ 42 | -4567890123456789
+(5 rows)
+
+create or replace function conflict_test() returns setof int8_tbl as $$
+#variable_conflict use_column
+declare r record;
+  q1 bigint := 42;
+begin
+  for r in select q1,q2 from int8_tbl loop
+    return next r;
+  end loop;
+end;
+$$ language plpgsql;
+select * from conflict_test();
+        q1        |        q2         
+------------------+-------------------
+              123 |               456
+              123 |  4567890123456789
+ 4567890123456789 |               123
+ 4567890123456789 |  4567890123456789
+ 4567890123456789 | -4567890123456789
+(5 rows)
+
+drop function conflict_test();
+-- Check that an unreserved keyword can be used as a variable name
+create function unreserved_test() returns int as $$
+declare
+  forward int := 21;
+begin
+  forward := forward * 2;
+  return forward;
+end
+$$ language plpgsql;
+select unreserved_test();
+ unreserved_test 
+-----------------
+              42
+(1 row)
+
+create or replace function unreserved_test() returns int as $$
+declare
+  return int := 42;
+begin
+  return := return + 1;
+  return return;
+end
+$$ language plpgsql;
+select unreserved_test();
+ unreserved_test 
+-----------------
+              43
+(1 row)
+
+create or replace function unreserved_test() returns int as $$
+declare
+  comment int := 21;
+begin
+  comment := comment * 2;
+  comment on function unreserved_test() is 'this is a test';
+  return comment;
+end
+$$ language plpgsql;
+select unreserved_test();
+ unreserved_test 
+-----------------
+              42
+(1 row)
+
+select obj_description('unreserved_test()'::regprocedure, 'pg_proc');
+ obj_description 
+-----------------
+ this is a test
+(1 row)
+
+drop function unreserved_test();
+--
+-- Test FOREACH over arrays
+--
+create function foreach_test(anyarray)
+returns void as $$
+declare x int;
+begin
+  foreach x in array $1
+  loop
+    raise notice '%', x;
+  end loop;
+  end;
+$$ language plpgsql;
+select foreach_test(ARRAY[1,2,3,4]);
+NOTICE:  1
+NOTICE:  2
+NOTICE:  3
+NOTICE:  4
+ foreach_test 
+--------------
+ 
+(1 row)
+
+select foreach_test(ARRAY[[1,2],[3,4]]);
+NOTICE:  1
+NOTICE:  2
+NOTICE:  3
+NOTICE:  4
+ foreach_test 
+--------------
+ 
+(1 row)
+
+create or replace function foreach_test(anyarray)
+returns void as $$
+declare x int;
+begin
+  foreach x slice 1 in array $1
+  loop
+    raise notice '%', x;
+  end loop;
+  end;
+$$ language plpgsql;
+-- should fail
+select foreach_test(ARRAY[1,2,3,4]);
+ERROR:  FOREACH ... SLICE loop variable must be of an array type
+CONTEXT:  PL/pgSQL function foreach_test(anyarray) line 4 at FOREACH over array
+select foreach_test(ARRAY[[1,2],[3,4]]);
+ERROR:  FOREACH ... SLICE loop variable must be of an array type
+CONTEXT:  PL/pgSQL function foreach_test(anyarray) line 4 at FOREACH over array
+create or replace function foreach_test(anyarray)
+returns void as $$
+declare x int[];
+begin
+  foreach x slice 1 in array $1
+  loop
+    raise notice '%', x;
+  end loop;
+  end;
+$$ language plpgsql;
+select foreach_test(ARRAY[1,2,3,4]);
+NOTICE:  {1,2,3,4}
+ foreach_test 
+--------------
+ 
+(1 row)
+
+select foreach_test(ARRAY[[1,2],[3,4]]);
+NOTICE:  {1,2}
+NOTICE:  {3,4}
+ foreach_test 
+--------------
+ 
+(1 row)
+
+-- higher level of slicing
+create or replace function foreach_test(anyarray)
+returns void as $$
+declare x int[];
+begin
+  foreach x slice 2 in array $1
+  loop
+    raise notice '%', x;
+  end loop;
+  end;
+$$ language plpgsql;
+-- should fail
+select foreach_test(ARRAY[1,2,3,4]);
+ERROR:  slice dimension (2) is out of the valid range 0..1
+CONTEXT:  PL/pgSQL function foreach_test(anyarray) line 4 at FOREACH over array
+-- ok
+select foreach_test(ARRAY[[1,2],[3,4]]);
+NOTICE:  {{1,2},{3,4}}
+ foreach_test 
+--------------
+ 
+(1 row)
+
+select foreach_test(ARRAY[[[1,2]],[[3,4]]]);
+NOTICE:  {{1,2}}
+NOTICE:  {{3,4}}
+ foreach_test 
+--------------
+ 
+(1 row)
+
+create type xy_tuple AS (x int, y int);
+-- iteration over array of records
+create or replace function foreach_test(anyarray)
+returns void as $$
+declare r record;
+begin
+  foreach r in array $1
+  loop
+    raise notice '%', r;
+  end loop;
+  end;
+$$ language plpgsql;
+select foreach_test(ARRAY[(10,20),(40,69),(35,78)]::xy_tuple[]);
+NOTICE:  (10,20)
+NOTICE:  (40,69)
+NOTICE:  (35,78)
+ foreach_test 
+--------------
+ 
+(1 row)
+
+select foreach_test(ARRAY[[(10,20),(40,69)],[(35,78),(88,76)]]::xy_tuple[]);
+NOTICE:  (10,20)
+NOTICE:  (40,69)
+NOTICE:  (35,78)
+NOTICE:  (88,76)
+ foreach_test 
+--------------
+ 
+(1 row)
+
+create or replace function foreach_test(anyarray)
+returns void as $$
+declare x int; y int;
+begin
+  foreach x, y in array $1
+  loop
+    raise notice 'x = %, y = %', x, y;
+  end loop;
+  end;
+$$ language plpgsql;
+select foreach_test(ARRAY[(10,20),(40,69),(35,78)]::xy_tuple[]);
+NOTICE:  x = 10, y = 20
+NOTICE:  x = 40, y = 69
+NOTICE:  x = 35, y = 78
+ foreach_test 
+--------------
+ 
+(1 row)
+
+select foreach_test(ARRAY[[(10,20),(40,69)],[(35,78),(88,76)]]::xy_tuple[]);
+NOTICE:  x = 10, y = 20
+NOTICE:  x = 40, y = 69
+NOTICE:  x = 35, y = 78
+NOTICE:  x = 88, y = 76
+ foreach_test 
+--------------
+ 
+(1 row)
+
+-- slicing over array of composite types
+create or replace function foreach_test(anyarray)
+returns void as $$
+declare x xy_tuple[];
+begin
+  foreach x slice 1 in array $1
+  loop
+    raise notice '%', x;
+  end loop;
+  end;
+$$ language plpgsql;
+select foreach_test(ARRAY[(10,20),(40,69),(35,78)]::xy_tuple[]);
+NOTICE:  {"(10,20)","(40,69)","(35,78)"}
+ foreach_test 
+--------------
+ 
+(1 row)
+
+select foreach_test(ARRAY[[(10,20),(40,69)],[(35,78),(88,76)]]::xy_tuple[]);
+NOTICE:  {"(10,20)","(40,69)"}
+NOTICE:  {"(35,78)","(88,76)"}
+ foreach_test 
+--------------
+ 
+(1 row)
+
+drop function foreach_test(anyarray);
+drop type xy_tuple;
+--
+-- Assorted tests for array subscript assignment
+--
+create temp table rtype (id int, ar text[]);
+create function arrayassign1() returns text[] language plpgsql as $$
+declare
+ r record;
+begin
+  r := row(12, '{foo,bar,baz}')::rtype;
+  r.ar[2] := 'replace';
+  return r.ar;
+end$$;
+select arrayassign1();
+   arrayassign1    
+-------------------
+ {foo,replace,baz}
+(1 row)
+
+select arrayassign1(); -- try again to exercise internal caching
+   arrayassign1    
+-------------------
+ {foo,replace,baz}
+(1 row)
+
+create domain orderedarray as int[2]
+  constraint sorted check (value[1] < value[2]);
+select '{1,2}'::orderedarray;
+ orderedarray 
+--------------
+ {1,2}
+(1 row)
+
+select '{2,1}'::orderedarray;  -- fail
+ERROR:  value for domain orderedarray violates check constraint "sorted"
+create function testoa(x1 int, x2 int, x3 int) returns orderedarray
+language plpgsql as $$
+declare res orderedarray;
+begin
+  res := array[x1, x2];
+  res[2] := x3;
+  return res;
+end$$;
+select testoa(1,2,3);
+ testoa 
+--------
+ {1,3}
+(1 row)
+
+select testoa(1,2,3); -- try again to exercise internal caching
+ testoa 
+--------
+ {1,3}
+(1 row)
+
+select testoa(2,1,3); -- fail at initial assign
+ERROR:  value for domain orderedarray violates check constraint "sorted"
+CONTEXT:  PL/pgSQL function testoa(integer,integer,integer) line 4 at assignment
+select testoa(1,2,1); -- fail at update
+ERROR:  value for domain orderedarray violates check constraint "sorted"
+CONTEXT:  PL/pgSQL function testoa(integer,integer,integer) line 5 at assignment
+drop function arrayassign1();
+drop function testoa(x1 int, x2 int, x3 int);
+--
+-- Test handling of expanded arrays
+--
+create function returns_rw_array(int) returns int[]
+language plpgsql as $$
+  declare r int[];
+  begin r := array[$1, $1]; return r; end;
+$$ stable;
+create function consumes_rw_array(int[]) returns int
+language plpgsql as $$
+  begin return $1[1]; end;
+$$ stable;
+select consumes_rw_array(returns_rw_array(42));
+ consumes_rw_array 
+-------------------
+                42
+(1 row)
+
+-- bug #14174
+explain (verbose, costs off)
+select i, a from
+  (select returns_rw_array(1) as a offset 0) ss,
+  lateral consumes_rw_array(a) i;
+                           QUERY PLAN                            
+-----------------------------------------------------------------
+ Nested Loop
+   Output: i.i, (returns_rw_array(1))
+   ->  Result
+         Output: returns_rw_array(1)
+   ->  Function Scan on public.consumes_rw_array i
+         Output: i.i
+         Function Call: consumes_rw_array((returns_rw_array(1)))
+(7 rows)
+
+select i, a from
+  (select returns_rw_array(1) as a offset 0) ss,
+  lateral consumes_rw_array(a) i;
+ i |   a   
+---+-------
+ 1 | {1,1}
+(1 row)
+
+explain (verbose, costs off)
+select consumes_rw_array(a), a from returns_rw_array(1) a;
+                 QUERY PLAN                 
+--------------------------------------------
+ Function Scan on public.returns_rw_array a
+   Output: consumes_rw_array(a), a
+   Function Call: returns_rw_array(1)
+(3 rows)
+
+select consumes_rw_array(a), a from returns_rw_array(1) a;
+ consumes_rw_array |   a   
+-------------------+-------
+                 1 | {1,1}
+(1 row)
+
+explain (verbose, costs off)
+select consumes_rw_array(a), a from
+  (values (returns_rw_array(1)), (returns_rw_array(2))) v(a);
+                             QUERY PLAN                              
+---------------------------------------------------------------------
+ Values Scan on "*VALUES*"
+   Output: consumes_rw_array("*VALUES*".column1), "*VALUES*".column1
+(2 rows)
+
+select consumes_rw_array(a), a from
+  (values (returns_rw_array(1)), (returns_rw_array(2))) v(a);
+ consumes_rw_array |   a   
+-------------------+-------
+                 1 | {1,1}
+                 2 | {2,2}
+(2 rows)
+
+do $$
+declare a int[] := array[1,2];
+begin
+  a := a || 3;
+  raise notice 'a = %', a;
+end$$;
+NOTICE:  a = {1,2,3}
+--
+-- Test access to call stack
+--
+create function inner_func(int)
+returns int as $$
+declare _context text;
+begin
+  get diagnostics _context = pg_context;
+  raise notice '***%***', _context;
+  -- lets do it again, just for fun..
+  get diagnostics _context = pg_context;
+  raise notice '***%***', _context;
+  raise notice 'lets make sure we didnt break anything';
+  return 2 * $1;
+end;
+$$ language plpgsql;
+create or replace function outer_func(int)
+returns int as $$
+declare
+  myresult int;
+begin
+  raise notice 'calling down into inner_func()';
+  myresult := inner_func($1);
+  raise notice 'inner_func() done';
+  return myresult;
+end;
+$$ language plpgsql;
+create or replace function outer_outer_func(int)
+returns int as $$
+declare
+  myresult int;
+begin
+  raise notice 'calling down into outer_func()';
+  myresult := outer_func($1);
+  raise notice 'outer_func() done';
+  return myresult;
+end;
+$$ language plpgsql;
+select outer_outer_func(10);
+NOTICE:  calling down into outer_func()
+NOTICE:  calling down into inner_func()
+NOTICE:  ***PL/pgSQL function inner_func(integer) line 4 at GET DIAGNOSTICS
+PL/pgSQL function outer_func(integer) line 6 at assignment
+PL/pgSQL function outer_outer_func(integer) line 6 at assignment***
+NOTICE:  ***PL/pgSQL function inner_func(integer) line 7 at GET DIAGNOSTICS
+PL/pgSQL function outer_func(integer) line 6 at assignment
+PL/pgSQL function outer_outer_func(integer) line 6 at assignment***
+NOTICE:  lets make sure we didnt break anything
+NOTICE:  inner_func() done
+NOTICE:  outer_func() done
+ outer_outer_func 
+------------------
+               20
+(1 row)
+
+-- repeated call should to work
+select outer_outer_func(20);
+NOTICE:  calling down into outer_func()
+NOTICE:  calling down into inner_func()
+NOTICE:  ***PL/pgSQL function inner_func(integer) line 4 at GET DIAGNOSTICS
+PL/pgSQL function outer_func(integer) line 6 at assignment
+PL/pgSQL function outer_outer_func(integer) line 6 at assignment***
+NOTICE:  ***PL/pgSQL function inner_func(integer) line 7 at GET DIAGNOSTICS
+PL/pgSQL function outer_func(integer) line 6 at assignment
+PL/pgSQL function outer_outer_func(integer) line 6 at assignment***
+NOTICE:  lets make sure we didnt break anything
+NOTICE:  inner_func() done
+NOTICE:  outer_func() done
+ outer_outer_func 
+------------------
+               40
+(1 row)
+
+drop function outer_outer_func(int);
+drop function outer_func(int);
+drop function inner_func(int);
+-- access to call stack from exception
+create function inner_func(int)
+returns int as $$
+declare
+  _context text;
+  sx int := 5;
+begin
+  begin
+    perform sx / 0;
+  exception
+    when division_by_zero then
+      get diagnostics _context = pg_context;
+      raise notice '***%***', _context;
+  end;
+
+  -- lets do it again, just for fun..
+  get diagnostics _context = pg_context;
+  raise notice '***%***', _context;
+  raise notice 'lets make sure we didnt break anything';
+  return 2 * $1;
+end;
+$$ language plpgsql;
+create or replace function outer_func(int)
+returns int as $$
+declare
+  myresult int;
+begin
+  raise notice 'calling down into inner_func()';
+  myresult := inner_func($1);
+  raise notice 'inner_func() done';
+  return myresult;
+end;
+$$ language plpgsql;
+create or replace function outer_outer_func(int)
+returns int as $$
+declare
+  myresult int;
+begin
+  raise notice 'calling down into outer_func()';
+  myresult := outer_func($1);
+  raise notice 'outer_func() done';
+  return myresult;
+end;
+$$ language plpgsql;
+select outer_outer_func(10);
+NOTICE:  calling down into outer_func()
+NOTICE:  calling down into inner_func()
+NOTICE:  ***PL/pgSQL function inner_func(integer) line 10 at GET DIAGNOSTICS
+PL/pgSQL function outer_func(integer) line 6 at assignment
+PL/pgSQL function outer_outer_func(integer) line 6 at assignment***
+NOTICE:  ***PL/pgSQL function inner_func(integer) line 15 at GET DIAGNOSTICS
+PL/pgSQL function outer_func(integer) line 6 at assignment
+PL/pgSQL function outer_outer_func(integer) line 6 at assignment***
+NOTICE:  lets make sure we didnt break anything
+NOTICE:  inner_func() done
+NOTICE:  outer_func() done
+ outer_outer_func 
+------------------
+               20
+(1 row)
+
+-- repeated call should to work
+select outer_outer_func(20);
+NOTICE:  calling down into outer_func()
+NOTICE:  calling down into inner_func()
+NOTICE:  ***PL/pgSQL function inner_func(integer) line 10 at GET DIAGNOSTICS
+PL/pgSQL function outer_func(integer) line 6 at assignment
+PL/pgSQL function outer_outer_func(integer) line 6 at assignment***
+NOTICE:  ***PL/pgSQL function inner_func(integer) line 15 at GET DIAGNOSTICS
+PL/pgSQL function outer_func(integer) line 6 at assignment
+PL/pgSQL function outer_outer_func(integer) line 6 at assignment***
+NOTICE:  lets make sure we didnt break anything
+NOTICE:  inner_func() done
+NOTICE:  outer_func() done
+ outer_outer_func 
+------------------
+               40
+(1 row)
+
+drop function outer_outer_func(int);
+drop function outer_func(int);
+drop function inner_func(int);
+--
+-- Test ASSERT
+--
+do $$
+begin
+  assert 1=1;  -- should succeed
+end;
+$$;
+do $$
+begin
+  assert 1=0;  -- should fail
+end;
+$$;
+ERROR:  assertion failed
+CONTEXT:  PL/pgSQL function inline_code_block line 3 at ASSERT
+do $$
+begin
+  assert NULL;  -- should fail
+end;
+$$;
+ERROR:  assertion failed
+CONTEXT:  PL/pgSQL function inline_code_block line 3 at ASSERT
+-- check controlling GUC
+set plpgsql.check_asserts = off;
+do $$
+begin
+  assert 1=0;  -- won't be tested
+end;
+$$;
+reset plpgsql.check_asserts;
+-- test custom message
+do $$
+declare var text := 'some value';
+begin
+  assert 1=0, format('assertion failed, var = "%s"', var);
+end;
+$$;
+ERROR:  assertion failed, var = "some value"
+CONTEXT:  PL/pgSQL function inline_code_block line 4 at ASSERT
+-- ensure assertions are not trapped by 'others'
+do $$
+begin
+  assert 1=0, 'unhandled assertion';
+exception when others then
+  null; -- do nothing
+end;
+$$;
+ERROR:  unhandled assertion
+CONTEXT:  PL/pgSQL function inline_code_block line 3 at ASSERT
+-- Test use of plpgsql in a domain check constraint (cf. bug #14414)
+create function plpgsql_domain_check(val int) returns boolean as $$
+begin return val > 0; end
+$$ language plpgsql immutable;
+create domain plpgsql_domain as integer check(plpgsql_domain_check(value));
+do $$
+declare v_test plpgsql_domain;
+begin
+  v_test := 1;
+end;
+$$;
+do $$
+declare v_test plpgsql_domain := 1;
+begin
+  v_test := 0;  -- fail
+end;
+$$;
+ERROR:  value for domain plpgsql_domain violates check constraint "plpgsql_domain_check"
+CONTEXT:  PL/pgSQL function inline_code_block line 4 at assignment
+-- Test handling of expanded array passed to a domain constraint (bug #14472)
+create function plpgsql_arr_domain_check(val int[]) returns boolean as $$
+begin return val[1] > 0; end
+$$ language plpgsql immutable;
+create domain plpgsql_arr_domain as int[] check(plpgsql_arr_domain_check(value));
+do $$
+declare v_test plpgsql_arr_domain;
+begin
+  v_test := array[1];
+  v_test := v_test || 2;
+end;
+$$;
+do $$
+declare v_test plpgsql_arr_domain := array[1];
+begin
+  v_test := 0 || v_test;  -- fail
+end;
+$$;
+ERROR:  value for domain plpgsql_arr_domain violates check constraint "plpgsql_arr_domain_check"
+CONTEXT:  PL/pgSQL function inline_code_block line 4 at assignment
+--
+-- test usage of transition tables in AFTER triggers
+--
+CREATE TABLE transition_table_base (id int PRIMARY KEY, val text);
+CREATE FUNCTION transition_table_base_ins_func()
+  RETURNS trigger
+  LANGUAGE plpgsql
+AS $$
+DECLARE
+  t text;
+  l text;
+BEGIN
+  t = '';
+  FOR l IN EXECUTE
+           $q$
+             EXPLAIN (TIMING off, COSTS off, VERBOSE on)
+             SELECT * FROM newtable
+           $q$ LOOP
+    t = t || l || E'\n';
+  END LOOP;
+
+  RAISE INFO '%', t;
+  RETURN new;
+END;
+$$;
+CREATE TRIGGER transition_table_base_ins_trig
+  AFTER INSERT ON transition_table_base
+  REFERENCING OLD TABLE AS oldtable NEW TABLE AS newtable
+  FOR EACH STATEMENT
+  EXECUTE PROCEDURE transition_table_base_ins_func();
+ERROR:  OLD TABLE can only be specified for a DELETE or UPDATE trigger
+CREATE TRIGGER transition_table_base_ins_trig
+  AFTER INSERT ON transition_table_base
+  REFERENCING NEW TABLE AS newtable
+  FOR EACH STATEMENT
+  EXECUTE PROCEDURE transition_table_base_ins_func();
+INSERT INTO transition_table_base VALUES (1, 'One'), (2, 'Two');
+INFO:  Named Tuplestore Scan
+  Output: id, val
+
+INSERT INTO transition_table_base VALUES (3, 'Three'), (4, 'Four');
+INFO:  Named Tuplestore Scan
+  Output: id, val
+
+CREATE OR REPLACE FUNCTION transition_table_base_upd_func()
+  RETURNS trigger
+  LANGUAGE plpgsql
+AS $$
+DECLARE
+  t text;
+  l text;
+BEGIN
+  t = '';
+  FOR l IN EXECUTE
+           $q$
+             EXPLAIN (TIMING off, COSTS off, VERBOSE on)
+             SELECT * FROM oldtable ot FULL JOIN newtable nt USING (id)
+           $q$ LOOP
+    t = t || l || E'\n';
+  END LOOP;
+
+  RAISE INFO '%', t;
+  RETURN new;
+END;
+$$;
+CREATE TRIGGER transition_table_base_upd_trig
+  AFTER UPDATE ON transition_table_base
+  REFERENCING OLD TABLE AS oldtable NEW TABLE AS newtable
+  FOR EACH STATEMENT
+  EXECUTE PROCEDURE transition_table_base_upd_func();
+UPDATE transition_table_base
+  SET val = '*' || val || '*'
+  WHERE id BETWEEN 2 AND 3;
+INFO:  Hash Full Join
+  Output: COALESCE(ot.id, nt.id), ot.val, nt.val
+  Hash Cond: (ot.id = nt.id)
+  ->  Named Tuplestore Scan
+        Output: ot.id, ot.val
+  ->  Hash
+        Output: nt.id, nt.val
+        ->  Named Tuplestore Scan
+              Output: nt.id, nt.val
+
+CREATE TABLE transition_table_level1
+(
+      level1_no serial NOT NULL ,
+      level1_node_name varchar(255),
+       PRIMARY KEY (level1_no)
+) WITHOUT OIDS;
+CREATE TABLE transition_table_level2
+(
+      level2_no serial NOT NULL ,
+      parent_no int NOT NULL,
+      level1_node_name varchar(255),
+       PRIMARY KEY (level2_no)
+) WITHOUT OIDS;
+CREATE TABLE transition_table_status
+(
+      level int NOT NULL,
+      node_no int NOT NULL,
+      status int,
+       PRIMARY KEY (level, node_no)
+) WITHOUT OIDS;
+CREATE FUNCTION transition_table_level1_ri_parent_del_func()
+  RETURNS TRIGGER
+  LANGUAGE plpgsql
+AS $$
+  DECLARE n bigint;
+  BEGIN
+    PERFORM FROM p JOIN transition_table_level2 c ON c.parent_no = p.level1_no;
+    IF FOUND THEN
+      RAISE EXCEPTION 'RI error';
+    END IF;
+    RETURN NULL;
+  END;
+$$;
+CREATE TRIGGER transition_table_level1_ri_parent_del_trigger
+  AFTER DELETE ON transition_table_level1
+  REFERENCING OLD TABLE AS p
+  FOR EACH STATEMENT EXECUTE PROCEDURE
+    transition_table_level1_ri_parent_del_func();
+CREATE FUNCTION transition_table_level1_ri_parent_upd_func()
+  RETURNS TRIGGER
+  LANGUAGE plpgsql
+AS $$
+  DECLARE
+    x int;
+  BEGIN
+    WITH p AS (SELECT level1_no, sum(delta) cnt
+                 FROM (SELECT level1_no, 1 AS delta FROM i
+                       UNION ALL
+                       SELECT level1_no, -1 AS delta FROM d) w
+                 GROUP BY level1_no
+                 HAVING sum(delta) < 0)
+    SELECT level1_no
+      FROM p JOIN transition_table_level2 c ON c.parent_no = p.level1_no
+      INTO x;
+    IF FOUND THEN
+      RAISE EXCEPTION 'RI error';
+    END IF;
+    RETURN NULL;
+  END;
+$$;
+CREATE TRIGGER transition_table_level1_ri_parent_upd_trigger
+  AFTER UPDATE ON transition_table_level1
+  REFERENCING OLD TABLE AS d NEW TABLE AS i
+  FOR EACH STATEMENT EXECUTE PROCEDURE
+    transition_table_level1_ri_parent_upd_func();
+CREATE FUNCTION transition_table_level2_ri_child_insupd_func()
+  RETURNS TRIGGER
+  LANGUAGE plpgsql
+AS $$
+  BEGIN
+    PERFORM FROM i
+      LEFT JOIN transition_table_level1 p
+        ON p.level1_no IS NOT NULL AND p.level1_no = i.parent_no
+      WHERE p.level1_no IS NULL;
+    IF FOUND THEN
+      RAISE EXCEPTION 'RI error';
+    END IF;
+    RETURN NULL;
+  END;
+$$;
+CREATE TRIGGER transition_table_level2_ri_child_ins_trigger
+  AFTER INSERT ON transition_table_level2
+  REFERENCING NEW TABLE AS i
+  FOR EACH STATEMENT EXECUTE PROCEDURE
+    transition_table_level2_ri_child_insupd_func();
+CREATE TRIGGER transition_table_level2_ri_child_upd_trigger
+  AFTER UPDATE ON transition_table_level2
+  REFERENCING NEW TABLE AS i
+  FOR EACH STATEMENT EXECUTE PROCEDURE
+    transition_table_level2_ri_child_insupd_func();
+-- create initial test data
+INSERT INTO transition_table_level1 (level1_no)
+  SELECT generate_series(1,200);
+ANALYZE transition_table_level1;
+INSERT INTO transition_table_level2 (level2_no, parent_no)
+  SELECT level2_no, level2_no / 50 + 1 AS parent_no
+    FROM generate_series(1,9999) level2_no;
+ANALYZE transition_table_level2;
+INSERT INTO transition_table_status (level, node_no, status)
+  SELECT 1, level1_no, 0 FROM transition_table_level1;
+INSERT INTO transition_table_status (level, node_no, status)
+  SELECT 2, level2_no, 0 FROM transition_table_level2;
+ANALYZE transition_table_status;
+INSERT INTO transition_table_level1(level1_no)
+  SELECT generate_series(201,1000);
+ANALYZE transition_table_level1;
+-- behave reasonably if someone tries to modify a transition table
+CREATE FUNCTION transition_table_level2_bad_usage_func()
+  RETURNS TRIGGER
+  LANGUAGE plpgsql
+AS $$
+  BEGIN
+    INSERT INTO dx VALUES (1000000, 1000000, 'x');
+    RETURN NULL;
+  END;
+$$;
+CREATE TRIGGER transition_table_level2_bad_usage_trigger
+  AFTER DELETE ON transition_table_level2
+  REFERENCING OLD TABLE AS dx
+  FOR EACH STATEMENT EXECUTE PROCEDURE
+    transition_table_level2_bad_usage_func();
+DELETE FROM transition_table_level2
+  WHERE level2_no BETWEEN 301 AND 305;
+ERROR:  relation "dx" cannot be the target of a modifying statement
+CONTEXT:  SQL statement "INSERT INTO dx VALUES (1000000, 1000000, 'x')"
+PL/pgSQL function transition_table_level2_bad_usage_func() line 3 at SQL statement
+DROP TRIGGER transition_table_level2_bad_usage_trigger
+  ON transition_table_level2;
+-- attempt modifications which would break RI (should all fail)
+DELETE FROM transition_table_level1
+  WHERE level1_no = 25;
+ERROR:  RI error
+CONTEXT:  PL/pgSQL function transition_table_level1_ri_parent_del_func() line 6 at RAISE
+UPDATE transition_table_level1 SET level1_no = -1
+  WHERE level1_no = 30;
+ERROR:  RI error
+CONTEXT:  PL/pgSQL function transition_table_level1_ri_parent_upd_func() line 15 at RAISE
+INSERT INTO transition_table_level2 (level2_no, parent_no)
+  VALUES (10000, 10000);
+ERROR:  RI error
+CONTEXT:  PL/pgSQL function transition_table_level2_ri_child_insupd_func() line 8 at RAISE
+UPDATE transition_table_level2 SET parent_no = 2000
+  WHERE level2_no = 40;
+ERROR:  RI error
+CONTEXT:  PL/pgSQL function transition_table_level2_ri_child_insupd_func() line 8 at RAISE
+-- attempt modifications which would not break RI (should all succeed)
+DELETE FROM transition_table_level1
+  WHERE level1_no BETWEEN 201 AND 1000;
+DELETE FROM transition_table_level1
+  WHERE level1_no BETWEEN 100000000 AND 100000010;
+SELECT count(*) FROM transition_table_level1;
+ count 
+-------
+   200
+(1 row)
+
+DELETE FROM transition_table_level2
+  WHERE level2_no BETWEEN 211 AND 220;
+SELECT count(*) FROM transition_table_level2;
+ count 
+-------
+  9989
+(1 row)
+
+CREATE TABLE alter_table_under_transition_tables
+(
+  id int PRIMARY KEY,
+  name text
+);
+CREATE FUNCTION alter_table_under_transition_tables_upd_func()
+  RETURNS TRIGGER
+  LANGUAGE plpgsql
+AS $$
+BEGIN
+  RAISE WARNING 'old table = %, new table = %',
+                  (SELECT string_agg(id || '=' || name, ',') FROM d),
+                  (SELECT string_agg(id || '=' || name, ',') FROM i);
+  RAISE NOTICE 'one = %', (SELECT 1 FROM alter_table_under_transition_tables LIMIT 1);
+  RETURN NULL;
+END;
+$$;
+-- should fail, TRUNCATE is not compatible with transition tables
+CREATE TRIGGER alter_table_under_transition_tables_upd_trigger
+  AFTER TRUNCATE OR UPDATE ON alter_table_under_transition_tables
+  REFERENCING OLD TABLE AS d NEW TABLE AS i
+  FOR EACH STATEMENT EXECUTE PROCEDURE
+    alter_table_under_transition_tables_upd_func();
+ERROR:  TRUNCATE triggers with transition tables are not supported
+-- should work
+CREATE TRIGGER alter_table_under_transition_tables_upd_trigger
+  AFTER UPDATE ON alter_table_under_transition_tables
+  REFERENCING OLD TABLE AS d NEW TABLE AS i
+  FOR EACH STATEMENT EXECUTE PROCEDURE
+    alter_table_under_transition_tables_upd_func();
+INSERT INTO alter_table_under_transition_tables
+  VALUES (1, '1'), (2, '2'), (3, '3');
+UPDATE alter_table_under_transition_tables
+  SET name = name || name;
+WARNING:  old table = 1=1,2=2,3=3, new table = 1=11,2=22,3=33
+NOTICE:  one = 1
+-- now change 'name' to an integer to see what happens...
+ALTER TABLE alter_table_under_transition_tables
+  ALTER COLUMN name TYPE int USING name::integer;
+UPDATE alter_table_under_transition_tables
+  SET name = (name::text || name::text)::integer;
+WARNING:  old table = 1=11,2=22,3=33, new table = 1=1111,2=2222,3=3333
+NOTICE:  one = 1
+-- now drop column 'name'
+ALTER TABLE alter_table_under_transition_tables
+  DROP column name;
+UPDATE alter_table_under_transition_tables
+  SET id = id;
+ERROR:  column "name" does not exist
+LINE 1: SELECT (SELECT string_agg(id || '=' || name, ',') FROM d)
+                                               ^
+QUERY:  SELECT (SELECT string_agg(id || '=' || name, ',') FROM d)
+CONTEXT:  PL/pgSQL function alter_table_under_transition_tables_upd_func() line 3 at RAISE
+--
+-- Test multiple reference to a transition table
+--
+CREATE TABLE multi_test (i int);
+INSERT INTO multi_test VALUES (1);
+CREATE OR REPLACE FUNCTION multi_test_trig() RETURNS trigger
+LANGUAGE plpgsql AS $$
+BEGIN
+    RAISE NOTICE 'count = %', (SELECT COUNT(*) FROM new_test);
+    RAISE NOTICE 'count union = %',
+      (SELECT COUNT(*)
+       FROM (SELECT * FROM new_test UNION ALL SELECT * FROM new_test) ss);
+    RETURN NULL;
+END$$;
+CREATE TRIGGER my_trigger AFTER UPDATE ON multi_test
+  REFERENCING NEW TABLE AS new_test OLD TABLE as old_test
+  FOR EACH STATEMENT EXECUTE PROCEDURE multi_test_trig();
+UPDATE multi_test SET i = i;
+NOTICE:  count = 1
+NOTICE:  count union = 2
+DROP TABLE multi_test;
+DROP FUNCTION multi_test_trig();
+--
+-- Check type parsing and record fetching from partitioned tables
+--
+CREATE TABLE partitioned_table (a int, b text) PARTITION BY LIST (a);
+CREATE TABLE pt_part1 PARTITION OF partitioned_table FOR VALUES IN (1);
+CREATE TABLE pt_part2 PARTITION OF partitioned_table FOR VALUES IN (2);
+INSERT INTO partitioned_table VALUES (1, 'Row 1');
+INSERT INTO partitioned_table VALUES (2, 'Row 2');
+CREATE OR REPLACE FUNCTION get_from_partitioned_table(partitioned_table.a%type)
+RETURNS partitioned_table AS $$
+DECLARE
+    a_val partitioned_table.a%TYPE;
+    result partitioned_table%ROWTYPE;
+BEGIN
+    a_val := $1;
+    SELECT * INTO result FROM partitioned_table WHERE a = a_val;
+    RETURN result;
+END; $$ LANGUAGE plpgsql;
+NOTICE:  type reference partitioned_table.a%TYPE converted to integer
+SELECT * FROM get_from_partitioned_table(1) AS t;
+ a |   b   
+---+-------
+ 1 | Row 1
+(1 row)
+
+CREATE OR REPLACE FUNCTION list_partitioned_table()
+RETURNS SETOF partitioned_table.a%TYPE AS $$
+DECLARE
+    row partitioned_table%ROWTYPE;
+    a_val partitioned_table.a%TYPE;
+BEGIN
+    FOR row IN SELECT * FROM partitioned_table ORDER BY a LOOP
+        a_val := row.a;
+        RETURN NEXT a_val;
+    END LOOP;
+    RETURN;
+END; $$ LANGUAGE plpgsql;
+NOTICE:  type reference partitioned_table.a%TYPE converted to integer
+SELECT * FROM list_partitioned_table() AS t;
+ t 
+---
+ 1
+ 2
+(2 rows)
+
+--
+-- Check argument name is used instead of $n in error message
+--
+CREATE FUNCTION fx(x WSlot) RETURNS void AS $$
+BEGIN
+  GET DIAGNOSTICS x = ROW_COUNT;
+  RETURN;
+END; $$ LANGUAGE plpgsql;
+ERROR:  "x" is not a scalar variable
+LINE 3:   GET DIAGNOSTICS x = ROW_COUNT;
+                          ^
diff --git a/src/test/regress/expected/portals.out b/src/test/regress/expected/portals.out
index dc0d2ef..8a01d5f 100644
--- a/src/test/regress/expected/portals.out
+++ b/src/test/regress/expected/portals.out
@@ -967,7 +967,7 @@ FETCH c1;
 (1 row)
 
 UPDATE uctest SET f1 = 8 WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 |  f2   
 ----+-------
   3 | three
@@ -975,7 +975,7 @@ SELECT * FROM uctest;
 (2 rows)
 
 COMMIT;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 |  f2   
 ----+-------
   3 | three
@@ -984,7 +984,7 @@ SELECT * FROM uctest;
 
 -- Check repeated-update and update-then-delete cases
 BEGIN;
-DECLARE c1 CURSOR FOR SELECT * FROM uctest;
+DECLARE c1 CURSOR FOR SELECT * FROM uctest WHERE f1 = 3;
 FETCH c1;
  f1 |  f2   
 ----+-------
@@ -992,7 +992,7 @@ FETCH c1;
 (1 row)
 
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 |  f2   
 ----+-------
   8 | one
@@ -1000,7 +1000,7 @@ SELECT * FROM uctest;
 (2 rows)
 
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 |  f2   
 ----+-------
   8 | one
@@ -1015,21 +1015,21 @@ FETCH RELATIVE 0 FROM c1;
 (1 row)
 
 DELETE FROM uctest WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 | f2  
 ----+-----
   8 | one
 (1 row)
 
 DELETE FROM uctest WHERE CURRENT OF c1; -- no-op
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 | f2  
 ----+-----
   8 | one
 (1 row)
 
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1; -- no-op
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 | f2  
 ----+-----
   8 | one
@@ -1042,7 +1042,7 @@ FETCH RELATIVE 0 FROM c1;
 (1 row)
 
 ROLLBACK;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 |  f2   
 ----+-------
   3 | three
@@ -1050,7 +1050,7 @@ SELECT * FROM uctest;
 (2 rows)
 
 BEGIN;
-DECLARE c1 CURSOR FOR SELECT * FROM uctest FOR UPDATE;
+DECLARE c1 CURSOR FOR SELECT * FROM uctest ORDER BY 1 FOR UPDATE;
 FETCH c1;
  f1 |  f2   
 ----+-------
@@ -1058,7 +1058,7 @@ FETCH c1;
 (1 row)
 
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 |  f2   
 ----+-------
   8 | one
@@ -1066,7 +1066,7 @@ SELECT * FROM uctest;
 (2 rows)
 
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 |  f2   
 ----+-------
   8 | one
@@ -1074,21 +1074,21 @@ SELECT * FROM uctest;
 (2 rows)
 
 DELETE FROM uctest WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 | f2  
 ----+-----
   8 | one
 (1 row)
 
 DELETE FROM uctest WHERE CURRENT OF c1; -- no-op
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 | f2  
 ----+-----
   8 | one
 (1 row)
 
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1; -- no-op
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 | f2  
 ----+-----
   8 | one
@@ -1099,7 +1099,7 @@ FETCH RELATIVE 0 FROM c1;
 ERROR:  cursor can only scan forward
 HINT:  Declare it with SCROLL option to enable backward scan.
 ROLLBACK;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1 |  f2   
 ----+-------
   3 | three
@@ -1109,7 +1109,7 @@ SELECT * FROM uctest;
 -- Check inheritance cases
 CREATE TEMP TABLE ucchild () inherits (uctest);
 INSERT INTO ucchild values(100, 'hundred');
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1  |   f2    
 -----+---------
    3 | three
@@ -1118,7 +1118,7 @@ SELECT * FROM uctest;
 (3 rows)
 
 BEGIN;
-DECLARE c1 CURSOR FOR SELECT * FROM uctest FOR UPDATE;
+DECLARE c1 CURSOR FOR SELECT * FROM uctest ORDER BY 1 FOR UPDATE;
 FETCH 1 FROM c1;
  f1 |  f2   
 ----+-------
@@ -1146,7 +1146,7 @@ FETCH 1 FROM c1;
 (0 rows)
 
 COMMIT;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1  |   f2    
 -----+---------
   13 | three
@@ -1186,7 +1186,7 @@ FETCH 1 FROM c1;
 (1 row)
 
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
  f1  |   f2    
 -----+---------
   13 | three
@@ -1236,7 +1236,7 @@ CREATE TEMP VIEW ucview AS SELECT * FROM uctest;
 CREATE RULE ucrule AS ON DELETE TO ucview DO INSTEAD
   DELETE FROM uctest WHERE f1 = OLD.f1;
 BEGIN;
-DECLARE c1 CURSOR FOR SELECT * FROM ucview;
+DECLARE c1 CURSOR FOR SELECT * FROM ucview ORDER BY 1;
 FETCH FROM c1;
  f1 |  f2   
 ----+-------
diff --git a/src/test/regress/expected/reloptions.out b/src/test/regress/expected/reloptions.out
index 7cb7467..a8f9bda 100644
--- a/src/test/regress/expected/reloptions.out
+++ b/src/test/regress/expected/reloptions.out
@@ -1,4 +1,5 @@
 -- Simple create
+CREATE TABLE reloptions_empty(i INT);
 CREATE TABLE reloptions_test(i INT) WITH (FiLLFaCToR=30,
 	autovacuum_enabled = false, autovacuum_analyze_scale_factor = 0.2);
 SELECT reloptions FROM pg_class WHERE oid = 'reloptions_test'::regclass;
@@ -103,7 +104,7 @@ INSERT INTO reloptions_test VALUES (1, NULL), (NULL, NULL);
 ERROR:  null value in column "i" violates not-null constraint
 DETAIL:  Failing row contains (null, null).
 VACUUM reloptions_test;
-SELECT pg_relation_size('reloptions_test') > 0;
+SELECT pg_relation_size('reloptions_test') > pg_relation_size('reloptions_empty');
  ?column? 
 ----------
  t
@@ -128,7 +129,7 @@ INSERT INTO reloptions_test VALUES (1, NULL), (NULL, NULL);
 ERROR:  null value in column "i" violates not-null constraint
 DETAIL:  Failing row contains (null, null).
 VACUUM reloptions_test;
-SELECT pg_relation_size('reloptions_test') = 0;
+SELECT pg_relation_size('reloptions_test') = pg_relation_size('reloptions_empty');
  ?column? 
 ----------
  t
diff --git a/src/test/regress/expected/returning_1.out b/src/test/regress/expected/returning_1.out
new file mode 100644
index 0000000..3e83604
--- /dev/null
+++ b/src/test/regress/expected/returning_1.out
@@ -0,0 +1,357 @@
+--
+-- Test INSERT/UPDATE/DELETE RETURNING
+--
+-- Simple cases
+CREATE TEMP TABLE foo (f1 serial, f2 text, f3 int default 42);
+INSERT INTO foo (f2,f3)
+  VALUES ('test', DEFAULT), ('More', 11), (upper('more'), 7+9)
+  RETURNING *, f1+f3 AS sum;
+ f1 |  f2  | f3 | sum 
+----+------+----+-----
+  1 | test | 42 |  43
+  2 | More | 11 |  13
+  3 | MORE | 16 |  19
+(3 rows)
+
+SELECT * FROM foo;
+ f1 |  f2  | f3 
+----+------+----
+  1 | test | 42
+  2 | More | 11
+  3 | MORE | 16
+(3 rows)
+
+UPDATE foo SET f2 = lower(f2), f3 = DEFAULT RETURNING foo.*, f1+f3 AS sum13;
+ f1 |  f2  | f3 | sum13 
+----+------+----+-------
+  1 | test | 42 |    43
+  2 | more | 42 |    44
+  3 | more | 42 |    45
+(3 rows)
+
+SELECT * FROM foo;
+ f1 |  f2  | f3 
+----+------+----
+  1 | test | 42
+  2 | more | 42
+  3 | more | 42
+(3 rows)
+
+DELETE FROM foo WHERE f1 > 2 RETURNING f3, f2, f1, least(f1,f3);
+ f3 |  f2  | f1 | least 
+----+------+----+-------
+ 42 | more |  3 |     3
+(1 row)
+
+SELECT * FROM foo;
+ f1 |  f2  | f3 
+----+------+----
+  1 | test | 42
+  2 | more | 42
+(2 rows)
+
+-- Subplans and initplans in the RETURNING list
+INSERT INTO foo SELECT f1+10, f2, f3+99 FROM foo
+  RETURNING *, f1+112 IN (SELECT q1 FROM int8_tbl) AS subplan,
+    EXISTS(SELECT * FROM int4_tbl) AS initplan;
+ f1 |  f2  | f3  | subplan | initplan 
+----+------+-----+---------+----------
+ 11 | test | 141 | t       | t
+ 12 | more | 141 | f       | t
+(2 rows)
+
+UPDATE foo SET f3 = f3 * 2
+  WHERE f1 > 10
+  RETURNING *, f1+112 IN (SELECT q1 FROM int8_tbl) AS subplan,
+    EXISTS(SELECT * FROM int4_tbl) AS initplan;
+ f1 |  f2  | f3  | subplan | initplan 
+----+------+-----+---------+----------
+ 11 | test | 282 | t       | t
+ 12 | more | 282 | f       | t
+(2 rows)
+
+DELETE FROM foo
+  WHERE f1 > 10
+  RETURNING *, f1+112 IN (SELECT q1 FROM int8_tbl) AS subplan,
+    EXISTS(SELECT * FROM int4_tbl) AS initplan;
+ f1 |  f2  | f3  | subplan | initplan 
+----+------+-----+---------+----------
+ 11 | test | 282 | t       | t
+ 12 | more | 282 | f       | t
+(2 rows)
+
+-- Joins
+UPDATE foo SET f3 = f3*2
+  FROM int4_tbl i
+  WHERE foo.f1 + 123455 = i.f1
+  RETURNING foo.*, i.f1 as "i.f1";
+ f1 |  f2  | f3 |  i.f1  
+----+------+----+--------
+  1 | test | 84 | 123456
+(1 row)
+
+SELECT * FROM foo;
+ f1 |  f2  | f3 
+----+------+----
+  1 | test | 84
+  2 | more | 42
+(2 rows)
+
+DELETE FROM foo
+  USING int4_tbl i
+  WHERE foo.f1 + 123455 = i.f1
+  RETURNING foo.*, i.f1 as "i.f1";
+ f1 |  f2  | f3 |  i.f1  
+----+------+----+--------
+  1 | test | 84 | 123456
+(1 row)
+
+SELECT * FROM foo;
+ f1 |  f2  | f3 
+----+------+----
+  2 | more | 42
+(1 row)
+
+-- Check inheritance cases
+CREATE TEMP TABLE foochild (fc int) INHERITS (foo);
+INSERT INTO foochild VALUES(123,'child',999,-123);
+ALTER TABLE foo ADD COLUMN f4 int8 DEFAULT 99;
+SELECT * FROM foo;
+ f1  |  f2   | f3  | f4 
+-----+-------+-----+----
+   2 | more  |  42 | 99
+ 123 | child | 999 | 99
+(2 rows)
+
+SELECT * FROM foochild;
+ f1  |  f2   | f3  |  fc  | f4 
+-----+-------+-----+------+----
+ 123 | child | 999 | -123 | 99
+(1 row)
+
+UPDATE foo SET f4 = f4 + f3 WHERE f4 = 99 RETURNING *;
+ f1  |  f2   | f3  |  f4  
+-----+-------+-----+------
+   2 | more  |  42 |  141
+ 123 | child | 999 | 1098
+(2 rows)
+
+SELECT * FROM foo;
+ f1  |  f2   | f3  |  f4  
+-----+-------+-----+------
+   2 | more  |  42 |  141
+ 123 | child | 999 | 1098
+(2 rows)
+
+SELECT * FROM foochild;
+ f1  |  f2   | f3  |  fc  |  f4  
+-----+-------+-----+------+------
+ 123 | child | 999 | -123 | 1098
+(1 row)
+
+UPDATE foo SET f3 = f3*2
+  FROM int8_tbl i
+  WHERE foo.f1 = i.q2
+  RETURNING *;
+ f1  |  f2   |  f3  |  f4  |        q1        | q2  
+-----+-------+------+------+------------------+-----
+ 123 | child | 1998 | 1098 | 4567890123456789 | 123
+(1 row)
+
+SELECT * FROM foo;
+ f1  |  f2   |  f3  |  f4  
+-----+-------+------+------
+   2 | more  |   42 |  141
+ 123 | child | 1998 | 1098
+(2 rows)
+
+SELECT * FROM foochild;
+ f1  |  f2   |  f3  |  fc  |  f4  
+-----+-------+------+------+------
+ 123 | child | 1998 | -123 | 1098
+(1 row)
+
+DELETE FROM foo
+  USING int8_tbl i
+  WHERE foo.f1 = i.q2
+  RETURNING *;
+ f1  |  f2   |  f3  |  f4  |        q1        | q2  
+-----+-------+------+------+------------------+-----
+ 123 | child | 1998 | 1098 | 4567890123456789 | 123
+(1 row)
+
+SELECT * FROM foo;
+ f1 |  f2  | f3 | f4  
+----+------+----+-----
+  2 | more | 42 | 141
+(1 row)
+
+SELECT * FROM foochild;
+ f1 | f2 | f3 | fc | f4 
+----+----+----+----+----
+(0 rows)
+
+DROP TABLE foochild;
+-- Rules and views
+CREATE TEMP VIEW voo AS SELECT f1, f2 FROM foo;
+CREATE RULE voo_i AS ON INSERT TO voo DO INSTEAD
+  INSERT INTO foo VALUES(new.*, 57);
+INSERT INTO voo VALUES(11,'zit');
+-- fails:
+INSERT INTO voo VALUES(12,'zoo') RETURNING *, f1*2;
+ERROR:  cannot perform INSERT RETURNING on relation "voo"
+HINT:  You need an unconditional ON INSERT DO INSTEAD rule with a RETURNING clause.
+-- fails, incompatible list:
+CREATE OR REPLACE RULE voo_i AS ON INSERT TO voo DO INSTEAD
+  INSERT INTO foo VALUES(new.*, 57) RETURNING *;
+ERROR:  RETURNING list has too many entries
+CREATE OR REPLACE RULE voo_i AS ON INSERT TO voo DO INSTEAD
+  INSERT INTO foo VALUES(new.*, 57) RETURNING f1, f2;
+-- should still work
+INSERT INTO voo VALUES(13,'zit2');
+-- works now
+INSERT INTO voo VALUES(14,'zoo2') RETURNING *;
+ f1 |  f2  
+----+------
+ 14 | zoo2
+(1 row)
+
+SELECT * FROM foo;
+ f1 |  f2  | f3 | f4  
+----+------+----+-----
+  2 | more | 42 | 141
+ 11 | zit  | 57 |  99
+ 13 | zit2 | 57 |  99
+ 14 | zoo2 | 57 |  99
+(4 rows)
+
+SELECT * FROM voo;
+ f1 |  f2  
+----+------
+  2 | more
+ 11 | zit
+ 13 | zit2
+ 14 | zoo2
+(4 rows)
+
+CREATE OR REPLACE RULE voo_u AS ON UPDATE TO voo DO INSTEAD
+  UPDATE foo SET f1 = new.f1, f2 = new.f2 WHERE f1 = old.f1
+  RETURNING f1, f2;
+update voo set f1 = f1 + 1 where f2 = 'zoo2';
+update voo set f1 = f1 + 1 where f2 = 'zoo2' RETURNING *, f1*2;
+ f1 |  f2  | ?column? 
+----+------+----------
+ 16 | zoo2 |       32
+(1 row)
+
+SELECT * FROM foo;
+ f1 |  f2  | f3 | f4  
+----+------+----+-----
+  2 | more | 42 | 141
+ 11 | zit  | 57 |  99
+ 13 | zit2 | 57 |  99
+ 16 | zoo2 | 57 |  99
+(4 rows)
+
+SELECT * FROM voo;
+ f1 |  f2  
+----+------
+  2 | more
+ 11 | zit
+ 13 | zit2
+ 16 | zoo2
+(4 rows)
+
+CREATE OR REPLACE RULE voo_d AS ON DELETE TO voo DO INSTEAD
+  DELETE FROM foo WHERE f1 = old.f1
+  RETURNING f1, f2;
+DELETE FROM foo WHERE f1 = 13;
+DELETE FROM foo WHERE f2 = 'zit' RETURNING *;
+ f1 | f2  | f3 | f4 
+----+-----+----+----
+ 11 | zit | 57 | 99
+(1 row)
+
+SELECT * FROM foo;
+ f1 |  f2  | f3 | f4  
+----+------+----+-----
+  2 | more | 42 | 141
+ 16 | zoo2 | 57 |  99
+(2 rows)
+
+SELECT * FROM voo;
+ f1 |  f2  
+----+------
+  2 | more
+ 16 | zoo2
+(2 rows)
+
+-- Try a join case
+CREATE TEMP TABLE joinme (f2j text, other int);
+INSERT INTO joinme VALUES('more', 12345);
+INSERT INTO joinme VALUES('zoo2', 54321);
+INSERT INTO joinme VALUES('other', 0);
+CREATE TEMP VIEW joinview AS
+  SELECT foo.*, other FROM foo JOIN joinme ON (f2 = f2j);
+SELECT * FROM joinview;
+ f1 |  f2  | f3 | f4  | other 
+----+------+----+-----+-------
+  2 | more | 42 | 141 | 12345
+ 16 | zoo2 | 57 |  99 | 54321
+(2 rows)
+
+CREATE RULE joinview_u AS ON UPDATE TO joinview DO INSTEAD
+  UPDATE foo SET f1 = new.f1, f3 = new.f3
+    FROM joinme WHERE f2 = f2j AND f2 = old.f2
+    RETURNING foo.*, other;
+UPDATE joinview SET f1 = f1 + 1 WHERE f3 = 57 RETURNING *, other + 1;
+ f1 |  f2  | f3 | f4 | other | ?column? 
+----+------+----+----+-------+----------
+ 17 | zoo2 | 57 | 99 | 54321 |    54322
+(1 row)
+
+SELECT * FROM joinview;
+ f1 |  f2  | f3 | f4  | other 
+----+------+----+-----+-------
+  2 | more | 42 | 141 | 12345
+ 17 | zoo2 | 57 |  99 | 54321
+(2 rows)
+
+SELECT * FROM foo;
+ f1 |  f2  | f3 | f4  
+----+------+----+-----
+  2 | more | 42 | 141
+ 17 | zoo2 | 57 |  99
+(2 rows)
+
+SELECT * FROM voo;
+ f1 |  f2  
+----+------
+  2 | more
+ 17 | zoo2
+(2 rows)
+
+-- Check aliased target relation
+INSERT INTO foo AS bar DEFAULT VALUES RETURNING *; -- ok
+ f1 | f2 | f3 | f4 
+----+----+----+----
+  4 |    | 42 | 99
+(1 row)
+
+INSERT INTO foo AS bar DEFAULT VALUES RETURNING foo.*; -- fails, wrong name
+ERROR:  invalid reference to FROM-clause entry for table "foo"
+LINE 1: INSERT INTO foo AS bar DEFAULT VALUES RETURNING foo.*;
+                                                        ^
+HINT:  Perhaps you meant to reference the table alias "bar".
+INSERT INTO foo AS bar DEFAULT VALUES RETURNING bar.*; -- ok
+ f1 | f2 | f3 | f4 
+----+----+----+----
+  5 |    | 42 | 99
+(1 row)
+
+INSERT INTO foo AS bar DEFAULT VALUES RETURNING bar.f3; -- ok
+ f3 
+----
+ 42
+(1 row)
+
diff --git a/src/test/regress/expected/rowsecurity.out b/src/test/regress/expected/rowsecurity.out
index aa3b083..5ccedaa 100644
--- a/src/test/regress/expected/rowsecurity.out
+++ b/src/test/regress/expected/rowsecurity.out
@@ -27,9 +27,11 @@ CREATE SCHEMA regress_rls_schema;
 GRANT ALL ON SCHEMA regress_rls_schema to public;
 SET search_path = regress_rls_schema;
 -- setup of malicious function
+CREATE TEMP TABLE f_leak_table(a text);
 CREATE OR REPLACE FUNCTION f_leak(text) RETURNS bool
     COST 0.0000001 LANGUAGE plpgsql
-    AS 'BEGIN RAISE NOTICE ''f_leak => %'', $1; RETURN true; END';
+    AS 'BEGIN INSERT INTO f_leak_table values($1); RETURN true; END';
+GRANT INSERT, SELECT,TRUNCATE ON TABLE f_leak_table TO public;
 GRANT EXECUTE ON FUNCTION f_leak(text) TO public;
 -- BASIC Row-Level Security Scenario
 SET SESSION AUTHORIZATION regress_rls_alice;
@@ -151,11 +153,6 @@ SELECT * FROM pg_policies WHERE schemaname = 'regress_rls_schema' AND tablename
 SET SESSION AUTHORIZATION regress_rls_bob;
 SET row_security TO ON;
 SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my first manga
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => great manga
-NOTICE:  f_leak => awesome science fiction
  did | cid | dlevel |      dauthor      |         dtitle          
 -----+-----+--------+-------------------+-------------------------
    1 |  11 |      1 | regress_rls_bob   | my first novel
@@ -165,12 +162,18 @@ NOTICE:  f_leak => awesome science fiction
    9 |  22 |      1 | regress_rls_dave  | awesome science fiction
 (5 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great manga
+ great science fiction
+ my first manga
+ my first novel
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
 SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my first manga
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => great manga
-NOTICE:  f_leak => awesome science fiction
  cid | did | dlevel |      dauthor      |         dtitle          |      cname      
 -----+-----+--------+-------------------+-------------------------+-----------------
   11 |   1 |      1 | regress_rls_bob   | my first novel          | novel
@@ -180,13 +183,20 @@ NOTICE:  f_leak => awesome science fiction
   22 |   9 |      1 | regress_rls_dave  | awesome science fiction | science fiction
 (5 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great manga
+ great science fiction
+ my first manga
+ my first novel
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
 -- try a sampled version
 SELECT * FROM document TABLESAMPLE BERNOULLI(50) REPEATABLE(0)
   WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first manga
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => great manga
-NOTICE:  f_leak => awesome science fiction
  did | cid | dlevel |      dauthor      |         dtitle          
 -----+-----+--------+-------------------+-------------------------
    4 |  44 |      1 | regress_rls_bob   | my first manga
@@ -195,19 +205,19 @@ NOTICE:  f_leak => awesome science fiction
    9 |  22 |      1 | regress_rls_dave  | awesome science fiction
 (4 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great manga
+ great science fiction
+ my first manga
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
 -- viewpoint from regress_rls_carol
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my second novel
-NOTICE:  f_leak => my science fiction
-NOTICE:  f_leak => my first manga
-NOTICE:  f_leak => my second manga
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => great technology book
-NOTICE:  f_leak => great manga
-NOTICE:  f_leak => awesome science fiction
-NOTICE:  f_leak => awesome technology book
  did | cid | dlevel |      dauthor      |         dtitle          
 -----+-----+--------+-------------------+-------------------------
    1 |  11 |      1 | regress_rls_bob   | my first novel
@@ -222,17 +232,23 @@ NOTICE:  f_leak => awesome technology book
   10 |  33 |      2 | regress_rls_dave  | awesome technology book
 (10 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ awesome technology book
+ great manga
+ great science fiction
+ great technology book
+ my first manga
+ my first novel
+ my science fiction
+ my second manga
+ my second novel
+(10 rows)
+
+TRUNCATE TABLE f_leak_table;
 SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my second novel
-NOTICE:  f_leak => my science fiction
-NOTICE:  f_leak => my first manga
-NOTICE:  f_leak => my second manga
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => great technology book
-NOTICE:  f_leak => great manga
-NOTICE:  f_leak => awesome science fiction
-NOTICE:  f_leak => awesome technology book
  cid | did | dlevel |      dauthor      |         dtitle          |      cname      
 -----+-----+--------+-------------------+-------------------------+-----------------
   11 |   1 |      1 | regress_rls_bob   | my first novel          | novel
@@ -247,14 +263,25 @@ NOTICE:  f_leak => awesome technology book
   33 |  10 |      2 | regress_rls_dave  | awesome technology book | technology
 (10 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ awesome technology book
+ great manga
+ great science fiction
+ great technology book
+ my first manga
+ my first novel
+ my science fiction
+ my second manga
+ my second novel
+(10 rows)
+
+TRUNCATE TABLE f_leak_table;
 -- try a sampled version
 SELECT * FROM document TABLESAMPLE BERNOULLI(50) REPEATABLE(0)
   WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first manga
-NOTICE:  f_leak => my second manga
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => great manga
-NOTICE:  f_leak => awesome science fiction
  did | cid | dlevel |      dauthor      |         dtitle          
 -----+-----+--------+-------------------+-------------------------
    4 |  44 |      1 | regress_rls_bob   | my first manga
@@ -264,6 +291,17 @@ NOTICE:  f_leak => awesome science fiction
    9 |  22 |      1 | regress_rls_dave  | awesome science fiction
 (5 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great manga
+ great science fiction
+ my first manga
+ my second manga
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM document WHERE f_leak(dtitle);
                      QUERY PLAN                     
 ----------------------------------------------------
@@ -291,13 +329,6 @@ EXPLAIN (COSTS OFF) SELECT * FROM document NATURAL JOIN category WHERE f_leak(dt
 -- viewpoint from regress_rls_dave
 SET SESSION AUTHORIZATION regress_rls_dave;
 SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my second novel
-NOTICE:  f_leak => my science fiction
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => great technology book
-NOTICE:  f_leak => awesome science fiction
-NOTICE:  f_leak => awesome technology book
  did | cid | dlevel |      dauthor      |         dtitle          
 -----+-----+--------+-------------------+-------------------------
    1 |  11 |      1 | regress_rls_bob   | my first novel
@@ -309,14 +340,20 @@ NOTICE:  f_leak => awesome technology book
   10 |  33 |      2 | regress_rls_dave  | awesome technology book
 (7 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ awesome technology book
+ great science fiction
+ great technology book
+ my first novel
+ my science fiction
+ my second novel
+(7 rows)
+
+TRUNCATE TABLE f_leak_table;
 SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my second novel
-NOTICE:  f_leak => my science fiction
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => great technology book
-NOTICE:  f_leak => awesome science fiction
-NOTICE:  f_leak => awesome technology book
  cid | did | dlevel |      dauthor      |         dtitle          |      cname      
 -----+-----+--------+-------------------+-------------------------+-----------------
   11 |   1 |      1 | regress_rls_bob   | my first novel          | novel
@@ -328,6 +365,19 @@ NOTICE:  f_leak => awesome technology book
   33 |  10 |      2 | regress_rls_dave  | awesome technology book | technology
 (7 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ awesome technology book
+ great science fiction
+ great technology book
+ my first novel
+ my science fiction
+ my second novel
+(7 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM document WHERE f_leak(dtitle);
                                           QUERY PLAN                                          
 ----------------------------------------------------------------------------------------------
@@ -369,11 +419,6 @@ ALTER POLICY p1 ON document USING (dauthor = current_user);
 -- viewpoint from regress_rls_bob again
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my second novel
-NOTICE:  f_leak => my science fiction
-NOTICE:  f_leak => my first manga
-NOTICE:  f_leak => my second manga
  did | cid | dlevel |     dauthor     |       dtitle       
 -----+-----+--------+-----------------+--------------------
    1 |  11 |      1 | regress_rls_bob | my first novel
@@ -383,12 +428,18 @@ NOTICE:  f_leak => my second manga
    5 |  44 |      2 | regress_rls_bob | my second manga
 (5 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+         a          
+--------------------
+ my first manga
+ my first novel
+ my science fiction
+ my second manga
+ my second novel
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
 SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER by did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my second novel
-NOTICE:  f_leak => my science fiction
-NOTICE:  f_leak => my first manga
-NOTICE:  f_leak => my second manga
  cid | did | dlevel |     dauthor     |       dtitle       |      cname      
 -----+-----+--------+-----------------+--------------------+-----------------
   11 |   1 |      1 | regress_rls_bob | my first novel     | novel
@@ -398,12 +449,20 @@ NOTICE:  f_leak => my second manga
   44 |   5 |      2 | regress_rls_bob | my second manga    | manga
 (5 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+         a          
+--------------------
+ my first manga
+ my first novel
+ my science fiction
+ my second manga
+ my second novel
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
 -- viewpoint from rls_regres_carol again
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => great technology book
-NOTICE:  f_leak => great manga
  did | cid | dlevel |      dauthor      |        dtitle         
 -----+-----+--------+-------------------+-----------------------
    6 |  22 |      1 | regress_rls_carol | great science fiction
@@ -411,10 +470,16 @@ NOTICE:  f_leak => great manga
    8 |  44 |      1 | regress_rls_carol | great manga
 (3 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+           a           
+-----------------------
+ great manga
+ great science fiction
+ great technology book
+(3 rows)
+
+TRUNCATE TABLE f_leak_table;
 SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER by did;
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => great technology book
-NOTICE:  f_leak => great manga
  cid | did | dlevel |      dauthor      |        dtitle         |      cname      
 -----+-----+--------+-------------------+-----------------------+-----------------
   22 |   6 |      1 | regress_rls_carol | great science fiction | science fiction
@@ -422,6 +487,15 @@ NOTICE:  f_leak => great manga
   44 |   8 |      1 | regress_rls_carol | great manga           | manga
 (3 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+           a           
+-----------------------
+ great manga
+ great science fiction
+ great technology book
+(3 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM document WHERE f_leak(dtitle);
                        QUERY PLAN                        
 ---------------------------------------------------------
@@ -671,11 +745,6 @@ EXPLAIN (COSTS OFF) SELECT * FROM t1;
 (7 rows)
 
 SELECT * FROM t1 WHERE f_leak(b);
-NOTICE:  f_leak => bbb
-NOTICE:  f_leak => dad
-NOTICE:  f_leak => bcd
-NOTICE:  f_leak => def
-NOTICE:  f_leak => yyy
  id  | a |  b  
 -----+---+-----
  102 | 2 | bbb
@@ -685,6 +754,17 @@ NOTICE:  f_leak => yyy
  302 | 2 | yyy
 (5 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ bcd
+ dad
+ def
+ yyy
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b);
                   QUERY PLAN                   
 -----------------------------------------------
@@ -768,11 +848,6 @@ EXPLAIN (COSTS OFF) SELECT * FROM t1 FOR SHARE;
 (8 rows)
 
 SELECT * FROM t1 WHERE f_leak(b) FOR SHARE;
-NOTICE:  f_leak => bbb
-NOTICE:  f_leak => dad
-NOTICE:  f_leak => bcd
-NOTICE:  f_leak => def
-NOTICE:  f_leak => yyy
  id  | a |  b  
 -----+---+-----
  102 | 2 | bbb
@@ -782,6 +857,17 @@ NOTICE:  f_leak => yyy
  302 | 2 | yyy
 (5 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ bcd
+ dad
+ def
+ yyy
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b) FOR SHARE;
                      QUERY PLAN                      
 -----------------------------------------------------
@@ -819,17 +905,6 @@ EXPLAIN (COSTS OFF) SELECT a, b, tableoid::regclass FROM t2 UNION ALL SELECT a,
 RESET SESSION AUTHORIZATION;
 SET row_security TO OFF;
 SELECT * FROM t1 WHERE f_leak(b);
-NOTICE:  f_leak => aba
-NOTICE:  f_leak => bbb
-NOTICE:  f_leak => ccc
-NOTICE:  f_leak => dad
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => bcd
-NOTICE:  f_leak => cde
-NOTICE:  f_leak => def
-NOTICE:  f_leak => xxx
-NOTICE:  f_leak => yyy
-NOTICE:  f_leak => zzz
  id  | a |  b  
 -----+---+-----
  101 | 1 | aba
@@ -845,6 +920,23 @@ NOTICE:  f_leak => zzz
  303 | 3 | zzz
 (11 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ abc
+ bbb
+ bcd
+ ccc
+ cde
+ dad
+ def
+ xxx
+ yyy
+ zzz
+(11 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b);
         QUERY PLAN         
 ---------------------------
@@ -861,17 +953,6 @@ EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b);
 SET SESSION AUTHORIZATION regress_rls_exempt_user;
 SET row_security TO OFF;
 SELECT * FROM t1 WHERE f_leak(b);
-NOTICE:  f_leak => aba
-NOTICE:  f_leak => bbb
-NOTICE:  f_leak => ccc
-NOTICE:  f_leak => dad
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => bcd
-NOTICE:  f_leak => cde
-NOTICE:  f_leak => def
-NOTICE:  f_leak => xxx
-NOTICE:  f_leak => yyy
-NOTICE:  f_leak => zzz
  id  | a |  b  
 -----+---+-----
  101 | 1 | aba
@@ -887,6 +968,23 @@ NOTICE:  f_leak => zzz
  303 | 3 | zzz
 (11 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ abc
+ bbb
+ bcd
+ ccc
+ cde
+ dad
+ def
+ xxx
+ yyy
+ zzz
+(11 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b);
         QUERY PLAN         
 ---------------------------
@@ -972,10 +1070,6 @@ SELECT * FROM pg_policies WHERE schemaname = 'regress_rls_schema' AND tablename
 SET SESSION AUTHORIZATION regress_rls_bob;
 SET row_security TO ON;
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => awesome science fiction
-NOTICE:  f_leak => my first satire
  did | cid | dlevel |      dauthor      |         dtitle          
 -----+-----+--------+-------------------+-------------------------
    1 |  11 |      1 | regress_rls_bob   | my first novel
@@ -984,6 +1078,16 @@ NOTICE:  f_leak => my first satire
    9 |  11 |      1 | regress_rls_dave  | awesome science fiction
 (4 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great science fiction
+ my first novel
+ my first satire
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
                      QUERY PLAN                      
 -----------------------------------------------------
@@ -1002,16 +1106,6 @@ EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
 -- viewpoint from regress_rls_carol
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my second novel
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => awesome science fiction
-NOTICE:  f_leak => my first satire
-NOTICE:  f_leak => great satire
-NOTICE:  f_leak => my science textbook
-NOTICE:  f_leak => my history book
-NOTICE:  f_leak => great technology book
-NOTICE:  f_leak => awesome technology book
  did | cid | dlevel |      dauthor      |         dtitle          
 -----+-----+--------+-------------------+-------------------------
    1 |  11 |      1 | regress_rls_bob   | my first novel
@@ -1026,6 +1120,22 @@ NOTICE:  f_leak => awesome technology book
   10 |  99 |      2 | regress_rls_dave  | awesome technology book
 (10 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ awesome technology book
+ great satire
+ great science fiction
+ great technology book
+ my first novel
+ my first satire
+ my history book
+ my science textbook
+ my second novel
+(10 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
                      QUERY PLAN                      
 -----------------------------------------------------
@@ -1044,10 +1154,6 @@ EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
 -- viewpoint from regress_rls_dave
 SET SESSION AUTHORIZATION regress_rls_dave;
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my second novel
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => awesome science fiction
  did | cid | dlevel |      dauthor      |         dtitle          
 -----+-----+--------+-------------------+-------------------------
    1 |  11 |      1 | regress_rls_bob   | my first novel
@@ -1056,6 +1162,16 @@ NOTICE:  f_leak => awesome science fiction
    9 |  11 |      1 | regress_rls_dave  | awesome science fiction
 (4 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great science fiction
+ my first novel
+ my second novel
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
                           QUERY PLAN                          
 --------------------------------------------------------------
@@ -1080,10 +1196,6 @@ ERROR:  new row violates row-level security policy "pp1r" for table "part_docume
 INSERT INTO part_document_satire VALUES (100, 55, 1, 'regress_rls_dave', 'testing RLS with partitions'); -- success
 -- We still cannot see the row using the parent
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my second novel
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => awesome science fiction
  did | cid | dlevel |      dauthor      |         dtitle          
 -----+-----+--------+-------------------+-------------------------
    1 |  11 |      1 | regress_rls_bob   | my first novel
@@ -1092,11 +1204,18 @@ NOTICE:  f_leak => awesome science fiction
    9 |  11 |      1 | regress_rls_dave  | awesome science fiction
 (4 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great science fiction
+ my first novel
+ my second novel
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
 -- But we can if we look directly
 SELECT * FROM part_document_satire WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first satire
-NOTICE:  f_leak => great satire
-NOTICE:  f_leak => testing RLS with partitions
  did | cid | dlevel |      dauthor      |           dtitle            
 -----+-----+--------+-------------------+-----------------------------
    4 |  55 |      1 | regress_rls_bob   | my first satire
@@ -1104,6 +1223,15 @@ NOTICE:  f_leak => testing RLS with partitions
  100 |  55 |      1 | regress_rls_dave  | testing RLS with partitions
 (3 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+              a              
+-----------------------------
+ great satire
+ my first satire
+ testing RLS with partitions
+(3 rows)
+
+TRUNCATE TABLE f_leak_table;
 -- Turn on RLS and create policy on child to show RLS is checked before constraints
 SET SESSION AUTHORIZATION regress_rls_alice;
 ALTER TABLE part_document_satire ENABLE ROW LEVEL SECURITY;
@@ -1119,13 +1247,15 @@ SELECT * FROM part_document_satire WHERE f_leak(dtitle) ORDER BY did;
 -----+-----+--------+---------+--------
 (0 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE TABLE f_leak_table;
 -- The parent looks same as before
 -- viewpoint from regress_rls_dave
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my second novel
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => awesome science fiction
  did | cid | dlevel |      dauthor      |         dtitle          
 -----+-----+--------+-------------------+-------------------------
    1 |  11 |      1 | regress_rls_bob   | my first novel
@@ -1134,6 +1264,16 @@ NOTICE:  f_leak => awesome science fiction
    9 |  11 |      1 | regress_rls_dave  | awesome science fiction
 (4 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great science fiction
+ my first novel
+ my second novel
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
                           QUERY PLAN                          
 --------------------------------------------------------------
@@ -1147,17 +1287,6 @@ EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
 -- viewpoint from regress_rls_carol
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my second novel
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => awesome science fiction
-NOTICE:  f_leak => my first satire
-NOTICE:  f_leak => great satire
-NOTICE:  f_leak => testing RLS with partitions
-NOTICE:  f_leak => my science textbook
-NOTICE:  f_leak => my history book
-NOTICE:  f_leak => great technology book
-NOTICE:  f_leak => awesome technology book
  did | cid | dlevel |      dauthor      |           dtitle            
 -----+-----+--------+-------------------+-----------------------------
    1 |  11 |      1 | regress_rls_bob   | my first novel
@@ -1173,6 +1302,23 @@ NOTICE:  f_leak => awesome technology book
  100 |  55 |      1 | regress_rls_dave  | testing RLS with partitions
 (11 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+              a              
+-----------------------------
+ awesome science fiction
+ awesome technology book
+ great satire
+ great science fiction
+ great technology book
+ my first novel
+ my first satire
+ my history book
+ my science textbook
+ my second novel
+ testing RLS with partitions
+(11 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
                      QUERY PLAN                      
 -----------------------------------------------------
@@ -1198,11 +1344,6 @@ ALTER POLICY pp1 ON part_document USING (dauthor = current_user);
 -- viewpoint from regress_rls_bob again
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => my first novel
-NOTICE:  f_leak => my second novel
-NOTICE:  f_leak => my first satire
-NOTICE:  f_leak => my science textbook
-NOTICE:  f_leak => my history book
  did | cid | dlevel |     dauthor     |       dtitle        
 -----+-----+--------+-----------------+---------------------
    1 |  11 |      1 | regress_rls_bob | my first novel
@@ -1212,12 +1353,20 @@ NOTICE:  f_leak => my history book
    5 |  99 |      2 | regress_rls_bob | my history book
 (5 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+          a          
+---------------------
+ my first novel
+ my first satire
+ my history book
+ my science textbook
+ my second novel
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
 -- viewpoint from rls_regres_carol again
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
-NOTICE:  f_leak => great science fiction
-NOTICE:  f_leak => great satire
-NOTICE:  f_leak => great technology book
  did | cid | dlevel |      dauthor      |        dtitle         
 -----+-----+--------+-------------------+-----------------------
    6 |  11 |      1 | regress_rls_carol | great science fiction
@@ -1225,6 +1374,15 @@ NOTICE:  f_leak => great technology book
    8 |  55 |      2 | regress_rls_carol | great satire
 (3 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+           a           
+-----------------------
+ great satire
+ great science fiction
+ great technology book
+(3 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
                           QUERY PLAN                           
 ---------------------------------------------------------------
@@ -1421,6 +1579,12 @@ SET SESSION AUTHORIZATION regress_rls_bob;
 CREATE VIEW v2 AS SELECT * FROM s2 WHERE y like '%af%';
 SELECT * FROM s1 WHERE f_leak(b); -- fail (infinite recursion)
 ERROR:  infinite recursion detected in policy for relation "s1"
+SELECT * FROM f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE TABLE f_leak_table;
 INSERT INTO s1 VALUES (1, 'foo'); -- fail (infinite recursion)
 ERROR:  infinite recursion detected in policy for relation "s1"
 SET SESSION AUTHORIZATION regress_rls_alice;
@@ -1428,14 +1592,20 @@ DROP POLICY p3 on s1;
 ALTER POLICY p2 ON s2 USING (x % 2 = 0);
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM s1 WHERE f_leak(b);	-- OK
-NOTICE:  f_leak => c81e728d9d4c2f636f067f89cc14862c
-NOTICE:  f_leak => a87ff679a2f3e71d9181a67b7542122c
  a |                b                 
 ---+----------------------------------
  2 | c81e728d9d4c2f636f067f89cc14862c
  4 | a87ff679a2f3e71d9181a67b7542122c
 (2 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ a87ff679a2f3e71d9181a67b7542122c
+ c81e728d9d4c2f636f067f89cc14862c
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM only s1 WHERE f_leak(b);
                         QUERY PLAN                         
 -----------------------------------------------------------
@@ -1450,14 +1620,20 @@ SET SESSION AUTHORIZATION regress_rls_alice;
 ALTER POLICY p1 ON s1 USING (a in (select x from v2)); -- using VIEW in RLS policy
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM s1 WHERE f_leak(b);	-- OK
-NOTICE:  f_leak => 0267aaf632e87a63288a08331f22c7c3
-NOTICE:  f_leak => 1679091c5a880faf6fb5e6087eb1b2dc
  a  |                b                 
 ----+----------------------------------
  -4 | 0267aaf632e87a63288a08331f22c7c3
   6 | 1679091c5a880faf6fb5e6087eb1b2dc
 (2 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ 0267aaf632e87a63288a08331f22c7c3
+ 1679091c5a880faf6fb5e6087eb1b2dc
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM s1 WHERE f_leak(b);
                         QUERY PLAN                         
 -----------------------------------------------------------
@@ -1495,6 +1671,12 @@ ALTER POLICY p2 ON s2 USING (x in (select a from s1 where b like '%d2%'));
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM s1 WHERE f_leak(b);	-- fail (infinite recursion via view)
 ERROR:  infinite recursion detected in policy for relation "s1"
+SELECT * FROM f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE TABLE f_leak_table;
 -- prepared statement with regress_rls_alice privilege
 PREPARE p1(int) AS SELECT * FROM t1 WHERE a <= $1;
 EXECUTE p1(2);
@@ -1521,17 +1703,6 @@ EXPLAIN (COSTS OFF) EXECUTE p1(2);
 RESET SESSION AUTHORIZATION;
 SET row_security TO OFF;
 SELECT * FROM t1 WHERE f_leak(b);
-NOTICE:  f_leak => aba
-NOTICE:  f_leak => bbb
-NOTICE:  f_leak => ccc
-NOTICE:  f_leak => dad
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => bcd
-NOTICE:  f_leak => cde
-NOTICE:  f_leak => def
-NOTICE:  f_leak => xxx
-NOTICE:  f_leak => yyy
-NOTICE:  f_leak => zzz
  id  | a |  b  
 -----+---+-----
  101 | 1 | aba
@@ -1547,6 +1718,23 @@ NOTICE:  f_leak => zzz
  303 | 3 | zzz
 (11 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ abc
+ bbb
+ bcd
+ ccc
+ cde
+ dad
+ def
+ xxx
+ yyy
+ zzz
+(11 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b);
         QUERY PLAN         
 ---------------------------
@@ -1647,11 +1835,17 @@ EXPLAIN (COSTS OFF) UPDATE t1 SET b = b || b WHERE f_leak(b);
 (10 rows)
 
 UPDATE t1 SET b = b || b WHERE f_leak(b);
-NOTICE:  f_leak => bbb
-NOTICE:  f_leak => dad
-NOTICE:  f_leak => bcd
-NOTICE:  f_leak => def
-NOTICE:  f_leak => yyy
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ bcd
+ dad
+ def
+ yyy
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) UPDATE only t1 SET b = b || '_updt' WHERE f_leak(b);
                   QUERY PLAN                   
 -----------------------------------------------
@@ -1661,48 +1855,75 @@ EXPLAIN (COSTS OFF) UPDATE only t1 SET b = b || '_updt' WHERE f_leak(b);
 (3 rows)
 
 UPDATE only t1 SET b = b || '_updt' WHERE f_leak(b);
-NOTICE:  f_leak => bbbbbb
-NOTICE:  f_leak => daddad
+SELECT * FROM f_leak_table ORDER BY a;
+   a    
+--------
+ bbbbbb
+ daddad
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
 -- returning clause with system column
-UPDATE only t1 SET b = b WHERE f_leak(b) RETURNING tableoid::regclass, *, t1;
-NOTICE:  f_leak => bbbbbb_updt
-NOTICE:  f_leak => daddad_updt
+WITH UPDATED AS (UPDATE only t1 SET b = b WHERE f_leak(b)
+RETURNING tableoid::regclass, *, t1) SELECT * FROM UPDATED ORDER BY (a,b);
  tableoid | id  | a |      b      |         t1          
 ----------+-----+---+-------------+---------------------
  t1       | 102 | 2 | bbbbbb_updt | (102,2,bbbbbb_updt)
  t1       | 104 | 4 | daddad_updt | (104,4,daddad_updt)
 (2 rows)
 
-UPDATE t1 SET b = b WHERE f_leak(b) RETURNING *;
-NOTICE:  f_leak => bbbbbb_updt
-NOTICE:  f_leak => daddad_updt
-NOTICE:  f_leak => bcdbcd
-NOTICE:  f_leak => defdef
-NOTICE:  f_leak => yyyyyy
+SELECT * from f_leak_table ORDER BY a;
+      a      
+-------------
+ bbbbbb_updt
+ daddad_updt
+(2 rows)
+
+TRUNCATE table f_leak_table;
+WITH UPDATED AS (UPDATE t1 SET b = b WHERE f_leak(b)
+RETURNING *) SELECT * FROM UPDATED ORDER BY (a,b);
  id  | a |      b      
 -----+---+-------------
  102 | 2 | bbbbbb_updt
- 104 | 4 | daddad_updt
  202 | 2 | bcdbcd
- 204 | 4 | defdef
  302 | 2 | yyyyyy
+ 104 | 4 | daddad_updt
+ 204 | 4 | defdef
 (5 rows)
 
-UPDATE t1 SET b = b WHERE f_leak(b) RETURNING tableoid::regclass, *, t1;
-NOTICE:  f_leak => bbbbbb_updt
-NOTICE:  f_leak => daddad_updt
-NOTICE:  f_leak => bcdbcd
-NOTICE:  f_leak => defdef
-NOTICE:  f_leak => yyyyyy
+SELECT * from f_leak_table ORDER BY a;
+      a      
+-------------
+ bbbbbb_updt
+ bcdbcd
+ daddad_updt
+ defdef
+ yyyyyy
+(5 rows)
+
+TRUNCATE table f_leak_table;
+WITH UPDATED AS (UPDATE t1 SET b = b WHERE f_leak(b)
+RETURNING tableoid::regclass, *, t1) SELECT * FROM UPDATED ORDER BY (a,b);
  tableoid | id  | a |      b      |         t1          
 ----------+-----+---+-------------+---------------------
  t1       | 102 | 2 | bbbbbb_updt | (102,2,bbbbbb_updt)
- t1       | 104 | 4 | daddad_updt | (104,4,daddad_updt)
  t2       | 202 | 2 | bcdbcd      | (202,2,bcdbcd)
- t2       | 204 | 4 | defdef      | (204,4,defdef)
  t3       | 302 | 2 | yyyyyy      | (302,2,yyyyyy)
+ t1       | 104 | 4 | daddad_updt | (104,4,daddad_updt)
+ t2       | 204 | 4 | defdef      | (204,4,defdef)
 (5 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+      a      
+-------------
+ bbbbbb_updt
+ bcdbcd
+ daddad_updt
+ defdef
+ yyyyyy
+(5 rows)
+
+TRUNCATE table f_leak_table;
 -- updates with from clause
 EXPLAIN (COSTS OFF) UPDATE t2 SET b=t2.b FROM t3
 WHERE t2.a = 3 and t3.a = 2 AND f_leak(t2.b) AND f_leak(t3.b);
@@ -1718,8 +1939,14 @@ WHERE t2.a = 3 and t3.a = 2 AND f_leak(t2.b) AND f_leak(t3.b);
 
 UPDATE t2 SET b=t2.b FROM t3
 WHERE t2.a = 3 and t3.a = 2 AND f_leak(t2.b) AND f_leak(t3.b);
-NOTICE:  f_leak => cde
-NOTICE:  f_leak => yyyyyy
+SELECT * from f_leak_table ORDER BY a;
+   a    
+--------
+ cde
+ yyyyyy
+(2 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) UPDATE t1 SET b=t1.b FROM t2
 WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
                            QUERY PLAN                            
@@ -1747,6 +1974,12 @@ WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
 
 UPDATE t1 SET b=t1.b FROM t2
 WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
+SELECT * from f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) UPDATE t2 SET b=t2.b FROM t1
 WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
                               QUERY PLAN                               
@@ -1766,7 +1999,13 @@ WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
 
 UPDATE t2 SET b=t2.b FROM t1
 WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
-NOTICE:  f_leak => cde
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ cde
+(1 row)
+
+TRUNCATE table f_leak_table;
 -- updates with from clause self join
 EXPLAIN (COSTS OFF) UPDATE t2 t2_1 SET b = t2_2.b FROM t2 t2_2
 WHERE t2_1.a = 3 AND t2_2.a = t2_1.a AND t2_2.b = t2_1.b
@@ -1782,16 +2021,22 @@ AND f_leak(t2_1.b) AND f_leak(t2_2.b) RETURNING *, t2_1, t2_2;
                Filter: ((a = 3) AND ((a % 2) = 1) AND f_leak(b))
 (7 rows)
 
-UPDATE t2 t2_1 SET b = t2_2.b FROM t2 t2_2
+WITH UPDATED AS (UPDATE t2 t2_1 SET b = t2_2.b FROM t2 t2_2
 WHERE t2_1.a = 3 AND t2_2.a = t2_1.a AND t2_2.b = t2_1.b
-AND f_leak(t2_1.b) AND f_leak(t2_2.b) RETURNING *, t2_1, t2_2;
-NOTICE:  f_leak => cde
-NOTICE:  f_leak => cde
- id  | a |  b  |  c  | id  | a |  b  |  c  |      t2_1       |      t2_2       
------+---+-----+-----+-----+---+-----+-----+-----------------+-----------------
- 203 | 3 | cde | 3.3 | 203 | 3 | cde | 3.3 | (203,3,cde,3.3) | (203,3,cde,3.3)
+AND f_leak(t2_1.b) AND f_leak(t2_2.b) RETURNING *, t2_1.a d, t2_2.b e) SELECT * FROM UPDATED ORDER BY (d,e);
+ id  | a |  b  |  c  | id  | a |  b  |  c  | d |  e  
+-----+---+-----+-----+-----+---+-----+-----+---+-----
+ 203 | 3 | cde | 3.3 | 203 | 3 | cde | 3.3 | 3 | cde
 (1 row)
 
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ cde
+ cde
+(2 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) UPDATE t1 t1_1 SET b = t1_2.b FROM t1 t1_2
 WHERE t1_1.a = 4 AND t1_2.a = t1_1.a AND t1_2.b = t1_1.b
 AND f_leak(t1_1.b) AND f_leak(t1_2.b) RETURNING *, t1_1, t1_2;
@@ -1836,21 +2081,27 @@ AND f_leak(t1_1.b) AND f_leak(t1_2.b) RETURNING *, t1_1, t1_2;
                      Filter: ((a = 4) AND ((a % 2) = 0) AND f_leak(b))
 (37 rows)
 
-UPDATE t1 t1_1 SET b = t1_2.b FROM t1 t1_2
+WITH UPDATED AS (UPDATE t1 t1_1 SET b = t1_2.b FROM t1 t1_2
 WHERE t1_1.a = 4 AND t1_2.a = t1_1.a AND t1_2.b = t1_1.b
-AND f_leak(t1_1.b) AND f_leak(t1_2.b) RETURNING *, t1_1, t1_2;
-NOTICE:  f_leak => daddad_updt
-NOTICE:  f_leak => daddad_updt
-NOTICE:  f_leak => defdef
-NOTICE:  f_leak => defdef
-NOTICE:  f_leak => daddad_updt
-NOTICE:  f_leak => defdef
- id  | a |      b      | id  | a |      b      |        t1_1         |        t1_2         
------+---+-------------+-----+---+-------------+---------------------+---------------------
- 104 | 4 | daddad_updt | 104 | 4 | daddad_updt | (104,4,daddad_updt) | (104,4,daddad_updt)
- 204 | 4 | defdef      | 204 | 4 | defdef      | (204,4,defdef)      | (204,4,defdef)
+AND f_leak(t1_1.b) AND f_leak(t1_2.b) RETURNING *, t1_1.a d, t1_2.b e) SELECT * FROM UPDATED ORDER BY (d,e);
+ id  | a |      b      | id  | a |      b      | d |      e      
+-----+---+-------------+-----+---+-------------+---+-------------
+ 104 | 4 | daddad_updt | 104 | 4 | daddad_updt | 4 | daddad_updt
+ 204 | 4 | defdef      | 204 | 4 | defdef      | 4 | defdef
 (2 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+      a      
+-------------
+ daddad_updt
+ daddad_updt
+ daddad_updt
+ defdef
+ defdef
+ defdef
+(6 rows)
+
+TRUNCATE table f_leak_table;
 RESET SESSION AUTHORIZATION;
 SET row_security TO OFF;
 SELECT * FROM t1 ORDER BY a,b;
@@ -1894,26 +2145,38 @@ EXPLAIN (COSTS OFF) DELETE FROM t1 WHERE f_leak(b);
          Filter: (((a % 2) = 0) AND f_leak(b))
 (10 rows)
 
-DELETE FROM only t1 WHERE f_leak(b) RETURNING tableoid::regclass, *, t1;
-NOTICE:  f_leak => bbbbbb_updt
-NOTICE:  f_leak => daddad_updt
+WITH CTE1 AS (DELETE FROM only t1 WHERE f_leak(b) RETURNING tableoid::regclass, *, t1) SELECT * FROM CTE1 ORDER BY (a,b);
  tableoid | id  | a |      b      |         t1          
 ----------+-----+---+-------------+---------------------
  t1       | 102 | 2 | bbbbbb_updt | (102,2,bbbbbb_updt)
  t1       | 104 | 4 | daddad_updt | (104,4,daddad_updt)
 (2 rows)
 
-DELETE FROM t1 WHERE f_leak(b) RETURNING tableoid::regclass, *, t1;
-NOTICE:  f_leak => bcdbcd
-NOTICE:  f_leak => defdef
-NOTICE:  f_leak => yyyyyy
+SELECT * FROM f_leak_table ORDER BY a;
+      a      
+-------------
+ bbbbbb_updt
+ daddad_updt
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
+WITH CTE1 AS (DELETE FROM t1 WHERE f_leak(b) RETURNING tableoid::regclass, *, t1) SELECT * FROM CTE1 ORDER BY (a,b);
  tableoid | id  | a |   b    |       t1       
 ----------+-----+---+--------+----------------
  t2       | 202 | 2 | bcdbcd | (202,2,bcdbcd)
- t2       | 204 | 4 | defdef | (204,4,defdef)
  t3       | 302 | 2 | yyyyyy | (302,2,yyyyyy)
+ t2       | 204 | 4 | defdef | (204,4,defdef)
+(3 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+   a    
+--------
+ bcdbcd
+ defdef
+ yyyyyy
 (3 rows)
 
+TRUNCATE TABLE f_leak_table;
 --
 -- S.b. view on top of Row-level security
 --
@@ -1937,11 +2200,6 @@ EXPLAIN (COSTS OFF) SELECT * FROM bv1 WHERE f_leak(b);
 (4 rows)
 
 SELECT * FROM bv1 WHERE f_leak(b);
-NOTICE:  f_leak => c81e728d9d4c2f636f067f89cc14862c
-NOTICE:  f_leak => a87ff679a2f3e71d9181a67b7542122c
-NOTICE:  f_leak => 1679091c5a880faf6fb5e6087eb1b2dc
-NOTICE:  f_leak => c9f0f895fb98ab9159f51fd0297e236d
-NOTICE:  f_leak => d3d9446802a44259755d38e6d163e820
  a  |                b                 
 ----+----------------------------------
   2 | c81e728d9d4c2f636f067f89cc14862c
@@ -1951,6 +2209,17 @@ NOTICE:  f_leak => d3d9446802a44259755d38e6d163e820
  10 | d3d9446802a44259755d38e6d163e820
 (5 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ 1679091c5a880faf6fb5e6087eb1b2dc
+ a87ff679a2f3e71d9181a67b7542122c
+ c81e728d9d4c2f636f067f89cc14862c
+ c9f0f895fb98ab9159f51fd0297e236d
+ d3d9446802a44259755d38e6d163e820
+(5 rows)
+
+TRUNCATE table f_leak_table;
 INSERT INTO bv1 VALUES (-1, 'xxx'); -- should fail view WCO
 ERROR:  new row violates row-level security policy for table "b1"
 INSERT INTO bv1 VALUES (11, 'xxx'); -- should fail RLS check
@@ -1965,7 +2234,13 @@ EXPLAIN (COSTS OFF) UPDATE bv1 SET b = 'yyy' WHERE a = 4 AND f_leak(b);
 (3 rows)
 
 UPDATE bv1 SET b = 'yyy' WHERE a = 4 AND f_leak(b);
-NOTICE:  f_leak => a87ff679a2f3e71d9181a67b7542122c
+SELECT * from f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ a87ff679a2f3e71d9181a67b7542122c
+(1 row)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) DELETE FROM bv1 WHERE a = 6 AND f_leak(b);
                               QUERY PLAN                               
 -----------------------------------------------------------------------
@@ -1975,9 +2250,15 @@ EXPLAIN (COSTS OFF) DELETE FROM bv1 WHERE a = 6 AND f_leak(b);
 (3 rows)
 
 DELETE FROM bv1 WHERE a = 6 AND f_leak(b);
-NOTICE:  f_leak => 1679091c5a880faf6fb5e6087eb1b2dc
+SELECT * from f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ 1679091c5a880faf6fb5e6087eb1b2dc
+(1 row)
+
+TRUNCATE table f_leak_table;
 SET SESSION AUTHORIZATION regress_rls_alice;
-SELECT * FROM b1;
+SELECT * FROM b1 ORDER BY a;
   a  |                b                 
 -----+----------------------------------
  -10 | 1b0fd9efa5279c4203b7c70233f86dbf
@@ -1994,13 +2275,13 @@ SELECT * FROM b1;
    1 | c4ca4238a0b923820dcc509a6f75849b
    2 | c81e728d9d4c2f636f067f89cc14862c
    3 | eccbc87e4b5ce2fe28308fd9f2a7baf3
+   4 | yyy
    5 | e4da3b7fbbce2345d7772b0674a318d5
    7 | 8f14e45fceea167a5a36dedd4bea2543
    8 | c9f0f895fb98ab9159f51fd0297e236d
    9 | 45c48cce2e2d7fbdea1afc51c7c6ad26
   10 | d3d9446802a44259755d38e6d163e820
   12 | xxx
-   4 | yyy
 (21 rows)
 
 --
@@ -2154,14 +2435,20 @@ CREATE POLICY p2 ON z1 TO regress_rls_group2 USING (a % 2 = 1);
 ALTER TABLE z1 ENABLE ROW LEVEL SECURITY;
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM z1 WHERE f_leak(b);
-NOTICE:  f_leak => bbb
-NOTICE:  f_leak => dad
  a |  b  
 ---+-----
  2 | bbb
  4 | dad
 (2 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ dad
+(2 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM z1 WHERE f_leak(b);
                QUERY PLAN                
 -----------------------------------------
@@ -2170,6 +2457,12 @@ EXPLAIN (COSTS OFF) SELECT * FROM z1 WHERE f_leak(b);
 (2 rows)
 
 PREPARE plancache_test AS SELECT * FROM z1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) EXECUTE plancache_test;
                QUERY PLAN                
 -----------------------------------------
@@ -2178,6 +2471,12 @@ EXPLAIN (COSTS OFF) EXECUTE plancache_test;
 (2 rows)
 
 PREPARE plancache_test2 AS WITH q AS MATERIALIZED (SELECT * FROM z1 WHERE f_leak(b)) SELECT * FROM q,z2;
+SELECT * from f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) EXECUTE plancache_test2;
                    QUERY PLAN                    
 -------------------------------------------------
@@ -2191,6 +2490,12 @@ EXPLAIN (COSTS OFF) EXECUTE plancache_test2;
 (7 rows)
 
 PREPARE plancache_test3 AS WITH q AS MATERIALIZED (SELECT * FROM z2) SELECT * FROM q,z1 WHERE f_leak(z1.b);
+SELECT * from f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) EXECUTE plancache_test3;
                      QUERY PLAN                      
 -----------------------------------------------------
@@ -2205,14 +2510,20 @@ EXPLAIN (COSTS OFF) EXECUTE plancache_test3;
 
 SET ROLE regress_rls_group1;
 SELECT * FROM z1 WHERE f_leak(b);
-NOTICE:  f_leak => bbb
-NOTICE:  f_leak => dad
  a |  b  
 ---+-----
  2 | bbb
  4 | dad
 (2 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ dad
+(2 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM z1 WHERE f_leak(b);
                QUERY PLAN                
 -----------------------------------------
@@ -2253,14 +2564,20 @@ EXPLAIN (COSTS OFF) EXECUTE plancache_test3;
 
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM z1 WHERE f_leak(b);
-NOTICE:  f_leak => aba
-NOTICE:  f_leak => ccc
  a |  b  
 ---+-----
  1 | aba
  3 | ccc
 (2 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ ccc
+(2 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM z1 WHERE f_leak(b);
                QUERY PLAN                
 -----------------------------------------
@@ -2301,14 +2618,20 @@ EXPLAIN (COSTS OFF) EXECUTE plancache_test3;
 
 SET ROLE regress_rls_group2;
 SELECT * FROM z1 WHERE f_leak(b);
-NOTICE:  f_leak => aba
-NOTICE:  f_leak => ccc
  a |  b  
 ---+-----
  1 | aba
  3 | ccc
 (2 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ ccc
+(2 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM z1 WHERE f_leak(b);
                QUERY PLAN                
 -----------------------------------------
@@ -2357,10 +2680,6 @@ GRANT SELECT ON rls_view TO regress_rls_bob;
 -- Query as role that is not owner of view or table.  Should return all records.
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM rls_view;
-NOTICE:  f_leak => aba
-NOTICE:  f_leak => bbb
-NOTICE:  f_leak => ccc
-NOTICE:  f_leak => dad
  a |  b  
 ---+-----
  1 | aba
@@ -2369,6 +2688,16 @@ NOTICE:  f_leak => dad
  4 | dad
 (4 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ bbb
+ ccc
+ dad
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
      QUERY PLAN      
 ---------------------
@@ -2379,10 +2708,6 @@ EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
 -- Query as view/table owner.  Should return all records.
 SET SESSION AUTHORIZATION regress_rls_alice;
 SELECT * FROM rls_view;
-NOTICE:  f_leak => aba
-NOTICE:  f_leak => bbb
-NOTICE:  f_leak => ccc
-NOTICE:  f_leak => dad
  a |  b  
 ---+-----
  1 | aba
@@ -2391,6 +2716,16 @@ NOTICE:  f_leak => dad
  4 | dad
 (4 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ bbb
+ ccc
+ dad
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
      QUERY PLAN      
 ---------------------
@@ -2407,14 +2742,20 @@ GRANT SELECT ON rls_view TO regress_rls_alice;
 -- Should return records based on view owner policies.
 SET SESSION AUTHORIZATION regress_rls_alice;
 SELECT * FROM rls_view;
-NOTICE:  f_leak => bbb
-NOTICE:  f_leak => dad
  a |  b  
 ---+-----
  2 | bbb
  4 | dad
 (2 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ dad
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
                QUERY PLAN                
 -----------------------------------------
@@ -2426,14 +2767,20 @@ EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
 -- Should return records based on view owner policies.
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM rls_view;
-NOTICE:  f_leak => bbb
-NOTICE:  f_leak => dad
  a |  b  
 ---+-----
  2 | bbb
  4 | dad
 (2 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ dad
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
                QUERY PLAN                
 -----------------------------------------
@@ -2445,20 +2792,32 @@ EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM rls_view; --fail - permission denied.
 ERROR:  permission denied for view rls_view
+SELECT * FROM f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM rls_view; --fail - permission denied.
 ERROR:  permission denied for view rls_view
 -- Query as role that is not the owner of the table or view with permissions.
 SET SESSION AUTHORIZATION regress_rls_bob;
 GRANT SELECT ON rls_view TO regress_rls_carol;
 SELECT * FROM rls_view;
-NOTICE:  f_leak => bbb
-NOTICE:  f_leak => dad
  a |  b  
 ---+-----
  2 | bbb
  4 | dad
 (2 rows)
 
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ dad
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
                QUERY PLAN                
 -----------------------------------------
@@ -2491,12 +2850,6 @@ CREATE POLICY p4 ON x1 FOR DELETE USING (a < 8);
 ALTER TABLE x1 ENABLE ROW LEVEL SECURITY;
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM x1 WHERE f_leak(b) ORDER BY a ASC;
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => bcd
-NOTICE:  f_leak => def
-NOTICE:  f_leak => efg
-NOTICE:  f_leak => fgh
-NOTICE:  f_leak => fgh
  a |  b  |         c         
 ---+-----+-------------------
  1 | abc | regress_rls_bob
@@ -2507,13 +2860,20 @@ NOTICE:  f_leak => fgh
  8 | fgh | regress_rls_carol
 (6 rows)
 
-UPDATE x1 SET b = b || '_updt' WHERE f_leak(b) RETURNING *;
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => bcd
-NOTICE:  f_leak => def
-NOTICE:  f_leak => efg
-NOTICE:  f_leak => fgh
-NOTICE:  f_leak => fgh
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ abc
+ bcd
+ def
+ efg
+ fgh
+ fgh
+(6 rows)
+
+TRUNCATE table f_leak_table;
+WITH UPDATED AS (UPDATE x1 SET b = b || '_updt' WHERE f_leak(b)
+RETURNING *) SELECT * FROM UPDATED ORDER BY (a,b);
  a |    b     |         c         
 ---+----------+-------------------
  1 | abc_updt | regress_rls_bob
@@ -2524,14 +2884,20 @@ NOTICE:  f_leak => fgh
  8 | fgh_updt | regress_rls_carol
 (6 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ abc
+ bcd
+ def
+ efg
+ fgh
+ fgh
+(6 rows)
+
+TRUNCATE table f_leak_table;
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM x1 WHERE f_leak(b) ORDER BY a ASC;
-NOTICE:  f_leak => cde
-NOTICE:  f_leak => fgh
-NOTICE:  f_leak => bcd_updt
-NOTICE:  f_leak => def_updt
-NOTICE:  f_leak => fgh_updt
-NOTICE:  f_leak => fgh_updt
  a |    b     |         c         
 ---+----------+-------------------
  2 | bcd_updt | regress_rls_bob
@@ -2542,40 +2908,65 @@ NOTICE:  f_leak => fgh_updt
  8 | fgh_updt | regress_rls_carol
 (6 rows)
 
-UPDATE x1 SET b = b || '_updt' WHERE f_leak(b) RETURNING *;
-NOTICE:  f_leak => cde
-NOTICE:  f_leak => fgh
-NOTICE:  f_leak => bcd_updt
-NOTICE:  f_leak => def_updt
-NOTICE:  f_leak => fgh_updt
-NOTICE:  f_leak => fgh_updt
+SELECT * from f_leak_table ORDER BY a;
+    a     
+----------
+ bcd_updt
+ cde
+ def_updt
+ fgh
+ fgh_updt
+ fgh_updt
+(6 rows)
+
+TRUNCATE table f_leak_table;
+WITH UPDATED AS (UPDATE x1 SET b = b || '_updt' WHERE f_leak(b)
+RETURNING *) SELECT * FROM UPDATED ORDER BY (a,b);
  a |       b       |         c         
 ---+---------------+-------------------
- 3 | cde_updt      | regress_rls_carol
- 7 | fgh_updt      | regress_rls_carol
  2 | bcd_updt_updt | regress_rls_bob
+ 3 | cde_updt      | regress_rls_carol
  4 | def_updt_updt | regress_rls_carol
  6 | fgh_updt_updt | regress_rls_bob
+ 7 | fgh_updt      | regress_rls_carol
  8 | fgh_updt_updt | regress_rls_carol
 (6 rows)
 
-DELETE FROM x1 WHERE f_leak(b) RETURNING *;
-NOTICE:  f_leak => cde_updt
-NOTICE:  f_leak => fgh_updt
-NOTICE:  f_leak => bcd_updt_updt
-NOTICE:  f_leak => def_updt_updt
-NOTICE:  f_leak => fgh_updt_updt
-NOTICE:  f_leak => fgh_updt_updt
+SELECT * from f_leak_table ORDER BY a;
+    a     
+----------
+ bcd_updt
+ cde
+ def_updt
+ fgh
+ fgh_updt
+ fgh_updt
+(6 rows)
+
+TRUNCATE table f_leak_table;
+WITH cte1 AS (DELETE FROM x1 WHERE f_leak(b) RETURNING *) SELECT * FROM cte1 ORDER BY (a,b);
  a |       b       |         c         
 ---+---------------+-------------------
- 3 | cde_updt      | regress_rls_carol
- 7 | fgh_updt      | regress_rls_carol
  2 | bcd_updt_updt | regress_rls_bob
+ 3 | cde_updt      | regress_rls_carol
  4 | def_updt_updt | regress_rls_carol
  6 | fgh_updt_updt | regress_rls_bob
+ 7 | fgh_updt      | regress_rls_carol
  8 | fgh_updt_updt | regress_rls_carol
 (6 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+       a       
+---------------
+ bcd_updt_updt
+ cde_updt
+ def_updt_updt
+ fgh_updt
+ fgh_updt_updt
+ fgh_updt_updt
+(6 rows)
+
+TRUNCATE table f_leak_table;
 --
 -- Duplicate Policy Names
 --
@@ -2597,6 +2988,12 @@ ALTER TABLE y2 ENABLE ROW LEVEL SECURITY;
 SET SESSION AUTHORIZATION regress_rls_alice;
 CREATE VIEW rls_sbv WITH (security_barrier) AS
     SELECT * FROM y1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM rls_sbv WHERE (a = 1);
             QUERY PLAN             
 -----------------------------------
@@ -2609,6 +3006,12 @@ DROP VIEW rls_sbv;
 SET SESSION AUTHORIZATION regress_rls_bob;
 CREATE VIEW rls_sbv WITH (security_barrier) AS
     SELECT * FROM y1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM rls_sbv WHERE (a = 1);
                             QUERY PLAN                            
 ------------------------------------------------------------------
@@ -2626,20 +3029,6 @@ CREATE POLICY p2 ON y2 USING (a % 3 = 0);
 CREATE POLICY p3 ON y2 USING (a % 4 = 0);
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM y2 WHERE f_leak(b);
-NOTICE:  f_leak => cfcd208495d565ef66e7dff9f98764da
-NOTICE:  f_leak => c81e728d9d4c2f636f067f89cc14862c
-NOTICE:  f_leak => eccbc87e4b5ce2fe28308fd9f2a7baf3
-NOTICE:  f_leak => a87ff679a2f3e71d9181a67b7542122c
-NOTICE:  f_leak => 1679091c5a880faf6fb5e6087eb1b2dc
-NOTICE:  f_leak => c9f0f895fb98ab9159f51fd0297e236d
-NOTICE:  f_leak => 45c48cce2e2d7fbdea1afc51c7c6ad26
-NOTICE:  f_leak => d3d9446802a44259755d38e6d163e820
-NOTICE:  f_leak => c20ad4d76fe97759aa27a0c99bff6710
-NOTICE:  f_leak => aab3238922bcc25a6f606eb525ffdc56
-NOTICE:  f_leak => 9bf31c7ff062936a96d3c8bd1f8f2ff3
-NOTICE:  f_leak => c74d97b01eae257e44aa9d5bade97baf
-NOTICE:  f_leak => 6f4922f45568161a8cdf4ad2299f6d23
-NOTICE:  f_leak => 98f13708210194c475687be6106a3b84
  a  |                b                 
 ----+----------------------------------
   0 | cfcd208495d565ef66e7dff9f98764da
@@ -2658,6 +3047,26 @@ NOTICE:  f_leak => 98f13708210194c475687be6106a3b84
  20 | 98f13708210194c475687be6106a3b84
 (14 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ 1679091c5a880faf6fb5e6087eb1b2dc
+ 45c48cce2e2d7fbdea1afc51c7c6ad26
+ 6f4922f45568161a8cdf4ad2299f6d23
+ 98f13708210194c475687be6106a3b84
+ 9bf31c7ff062936a96d3c8bd1f8f2ff3
+ a87ff679a2f3e71d9181a67b7542122c
+ aab3238922bcc25a6f606eb525ffdc56
+ c20ad4d76fe97759aa27a0c99bff6710
+ c74d97b01eae257e44aa9d5bade97baf
+ c81e728d9d4c2f636f067f89cc14862c
+ c9f0f895fb98ab9159f51fd0297e236d
+ cfcd208495d565ef66e7dff9f98764da
+ d3d9446802a44259755d38e6d163e820
+ eccbc87e4b5ce2fe28308fd9f2a7baf3
+(14 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM y2 WHERE f_leak(b);
                                  QUERY PLAN                                  
 -----------------------------------------------------------------------------
@@ -2669,27 +3078,6 @@ EXPLAIN (COSTS OFF) SELECT * FROM y2 WHERE f_leak(b);
 -- Qual push-down of leaky functions, when not referring to table
 --
 SELECT * FROM y2 WHERE f_leak('abc');
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => abc
  a  |                b                 
 ----+----------------------------------
   0 | cfcd208495d565ef66e7dff9f98764da
@@ -2708,6 +3096,33 @@ NOTICE:  f_leak => abc
  20 | 98f13708210194c475687be6106a3b84
 (14 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+(21 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM y2 WHERE f_leak('abc');
                                       QUERY PLAN                                       
 ---------------------------------------------------------------------------------------
@@ -2720,12 +3135,18 @@ CREATE TABLE test_qual_pushdown (
 );
 INSERT INTO test_qual_pushdown VALUES ('abc'),('def');
 SELECT * FROM y2 JOIN test_qual_pushdown ON (b = abc) WHERE f_leak(abc);
-NOTICE:  f_leak => abc
-NOTICE:  f_leak => def
  a | b | abc 
 ---+---+-----
 (0 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ abc
+ def
+(2 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM y2 JOIN test_qual_pushdown ON (b = abc) WHERE f_leak(abc);
                                QUERY PLAN                                
 -------------------------------------------------------------------------
@@ -2739,24 +3160,30 @@ EXPLAIN (COSTS OFF) SELECT * FROM y2 JOIN test_qual_pushdown ON (b = abc) WHERE
 (7 rows)
 
 SELECT * FROM y2 JOIN test_qual_pushdown ON (b = abc) WHERE f_leak(b);
-NOTICE:  f_leak => cfcd208495d565ef66e7dff9f98764da
-NOTICE:  f_leak => c81e728d9d4c2f636f067f89cc14862c
-NOTICE:  f_leak => eccbc87e4b5ce2fe28308fd9f2a7baf3
-NOTICE:  f_leak => a87ff679a2f3e71d9181a67b7542122c
-NOTICE:  f_leak => 1679091c5a880faf6fb5e6087eb1b2dc
-NOTICE:  f_leak => c9f0f895fb98ab9159f51fd0297e236d
-NOTICE:  f_leak => 45c48cce2e2d7fbdea1afc51c7c6ad26
-NOTICE:  f_leak => d3d9446802a44259755d38e6d163e820
-NOTICE:  f_leak => c20ad4d76fe97759aa27a0c99bff6710
-NOTICE:  f_leak => aab3238922bcc25a6f606eb525ffdc56
-NOTICE:  f_leak => 9bf31c7ff062936a96d3c8bd1f8f2ff3
-NOTICE:  f_leak => c74d97b01eae257e44aa9d5bade97baf
-NOTICE:  f_leak => 6f4922f45568161a8cdf4ad2299f6d23
-NOTICE:  f_leak => 98f13708210194c475687be6106a3b84
  a | b | abc 
 ---+---+-----
 (0 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ 1679091c5a880faf6fb5e6087eb1b2dc
+ 45c48cce2e2d7fbdea1afc51c7c6ad26
+ 6f4922f45568161a8cdf4ad2299f6d23
+ 98f13708210194c475687be6106a3b84
+ 9bf31c7ff062936a96d3c8bd1f8f2ff3
+ a87ff679a2f3e71d9181a67b7542122c
+ aab3238922bcc25a6f606eb525ffdc56
+ c20ad4d76fe97759aa27a0c99bff6710
+ c74d97b01eae257e44aa9d5bade97baf
+ c81e728d9d4c2f636f067f89cc14862c
+ c9f0f895fb98ab9159f51fd0297e236d
+ cfcd208495d565ef66e7dff9f98764da
+ d3d9446802a44259755d38e6d163e820
+ eccbc87e4b5ce2fe28308fd9f2a7baf3
+(14 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF) SELECT * FROM y2 JOIN test_qual_pushdown ON (b = abc) WHERE f_leak(b);
                                        QUERY PLAN                                        
 -----------------------------------------------------------------------------------------
@@ -2825,17 +3252,6 @@ GRANT ALL ON t1 TO regress_rls_bob;
 INSERT INTO t1 (SELECT x, md5(x::text) FROM generate_series(0,20) x);
 SET SESSION AUTHORIZATION regress_rls_bob;
 WITH cte1 AS MATERIALIZED (SELECT * FROM t1 WHERE f_leak(b)) SELECT * FROM cte1;
-NOTICE:  f_leak => cfcd208495d565ef66e7dff9f98764da
-NOTICE:  f_leak => c81e728d9d4c2f636f067f89cc14862c
-NOTICE:  f_leak => a87ff679a2f3e71d9181a67b7542122c
-NOTICE:  f_leak => 1679091c5a880faf6fb5e6087eb1b2dc
-NOTICE:  f_leak => c9f0f895fb98ab9159f51fd0297e236d
-NOTICE:  f_leak => d3d9446802a44259755d38e6d163e820
-NOTICE:  f_leak => c20ad4d76fe97759aa27a0c99bff6710
-NOTICE:  f_leak => aab3238922bcc25a6f606eb525ffdc56
-NOTICE:  f_leak => c74d97b01eae257e44aa9d5bade97baf
-NOTICE:  f_leak => 6f4922f45568161a8cdf4ad2299f6d23
-NOTICE:  f_leak => 98f13708210194c475687be6106a3b84
  a  |                b                 
 ----+----------------------------------
   0 | cfcd208495d565ef66e7dff9f98764da
@@ -2851,6 +3267,23 @@ NOTICE:  f_leak => 98f13708210194c475687be6106a3b84
  20 | 98f13708210194c475687be6106a3b84
 (11 rows)
 
+SELECT * from f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ 1679091c5a880faf6fb5e6087eb1b2dc
+ 6f4922f45568161a8cdf4ad2299f6d23
+ 98f13708210194c475687be6106a3b84
+ a87ff679a2f3e71d9181a67b7542122c
+ aab3238922bcc25a6f606eb525ffdc56
+ c20ad4d76fe97759aa27a0c99bff6710
+ c74d97b01eae257e44aa9d5bade97baf
+ c81e728d9d4c2f636f067f89cc14862c
+ c9f0f895fb98ab9159f51fd0297e236d
+ cfcd208495d565ef66e7dff9f98764da
+ d3d9446802a44259755d38e6d163e820
+(11 rows)
+
+TRUNCATE table f_leak_table;
 EXPLAIN (COSTS OFF)
 WITH cte1 AS MATERIALIZED (SELECT * FROM t1 WHERE f_leak(b)) SELECT * FROM cte1;
                    QUERY PLAN                    
@@ -3051,29 +3484,29 @@ DROP POLICY p2 ON t1;
 ALTER TABLE t1 OWNER TO regress_rls_alice;
 -- Check that default deny does not apply to superuser.
 RESET SESSION AUTHORIZATION;
-SELECT * FROM t1;
+SELECT * FROM t1 ORDER BY a;
  a  |                b                 
 ----+----------------------------------
-  1 | c4ca4238a0b923820dcc509a6f75849b
-  3 | eccbc87e4b5ce2fe28308fd9f2a7baf3
-  5 | e4da3b7fbbce2345d7772b0674a318d5
-  7 | 8f14e45fceea167a5a36dedd4bea2543
-  9 | 45c48cce2e2d7fbdea1afc51c7c6ad26
- 11 | 6512bd43d9caa6e02c990b0a82652dca
- 13 | c51ce410c124a10e0db5e4b97fc2af39
- 15 | 9bf31c7ff062936a96d3c8bd1f8f2ff3
- 17 | 70efdf2ec9b086079795c442636b55fb
- 19 | 1f0e3dad99908345f7439f8ffabdffc4
   0 | cfcd208495d565ef66e7dff9f98764da
+  1 | c4ca4238a0b923820dcc509a6f75849b
   2 | c81e728d9d4c2f636f067f89cc14862c
+  3 | eccbc87e4b5ce2fe28308fd9f2a7baf3
   4 | a87ff679a2f3e71d9181a67b7542122c
+  5 | e4da3b7fbbce2345d7772b0674a318d5
   6 | 1679091c5a880faf6fb5e6087eb1b2dc
+  7 | 8f14e45fceea167a5a36dedd4bea2543
   8 | c9f0f895fb98ab9159f51fd0297e236d
+  9 | 45c48cce2e2d7fbdea1afc51c7c6ad26
  10 | d3d9446802a44259755d38e6d163e820
+ 11 | 6512bd43d9caa6e02c990b0a82652dca
  12 | c20ad4d76fe97759aa27a0c99bff6710
+ 13 | c51ce410c124a10e0db5e4b97fc2af39
  14 | aab3238922bcc25a6f606eb525ffdc56
+ 15 | 9bf31c7ff062936a96d3c8bd1f8f2ff3
  16 | c74d97b01eae257e44aa9d5bade97baf
+ 17 | 70efdf2ec9b086079795c442636b55fb
  18 | 6f4922f45568161a8cdf4ad2299f6d23
+ 19 | 1f0e3dad99908345f7439f8ffabdffc4
  20 | 98f13708210194c475687be6106a3b84
  20 | Success
 (22 rows)
@@ -3086,29 +3519,29 @@ EXPLAIN (COSTS OFF) SELECT * FROM t1;
 
 -- Check that default deny does not apply to table owner.
 SET SESSION AUTHORIZATION regress_rls_alice;
-SELECT * FROM t1;
+SELECT * FROM t1 ORDER BY a;
  a  |                b                 
 ----+----------------------------------
-  1 | c4ca4238a0b923820dcc509a6f75849b
-  3 | eccbc87e4b5ce2fe28308fd9f2a7baf3
-  5 | e4da3b7fbbce2345d7772b0674a318d5
-  7 | 8f14e45fceea167a5a36dedd4bea2543
-  9 | 45c48cce2e2d7fbdea1afc51c7c6ad26
- 11 | 6512bd43d9caa6e02c990b0a82652dca
- 13 | c51ce410c124a10e0db5e4b97fc2af39
- 15 | 9bf31c7ff062936a96d3c8bd1f8f2ff3
- 17 | 70efdf2ec9b086079795c442636b55fb
- 19 | 1f0e3dad99908345f7439f8ffabdffc4
   0 | cfcd208495d565ef66e7dff9f98764da
+  1 | c4ca4238a0b923820dcc509a6f75849b
   2 | c81e728d9d4c2f636f067f89cc14862c
+  3 | eccbc87e4b5ce2fe28308fd9f2a7baf3
   4 | a87ff679a2f3e71d9181a67b7542122c
+  5 | e4da3b7fbbce2345d7772b0674a318d5
   6 | 1679091c5a880faf6fb5e6087eb1b2dc
+  7 | 8f14e45fceea167a5a36dedd4bea2543
   8 | c9f0f895fb98ab9159f51fd0297e236d
+  9 | 45c48cce2e2d7fbdea1afc51c7c6ad26
  10 | d3d9446802a44259755d38e6d163e820
+ 11 | 6512bd43d9caa6e02c990b0a82652dca
  12 | c20ad4d76fe97759aa27a0c99bff6710
+ 13 | c51ce410c124a10e0db5e4b97fc2af39
  14 | aab3238922bcc25a6f606eb525ffdc56
+ 15 | 9bf31c7ff062936a96d3c8bd1f8f2ff3
  16 | c74d97b01eae257e44aa9d5bade97baf
+ 17 | 70efdf2ec9b086079795c442636b55fb
  18 | 6f4922f45568161a8cdf4ad2299f6d23
+ 19 | 1f0e3dad99908345f7439f8ffabdffc4
  20 | 98f13708210194c475687be6106a3b84
  20 | Success
 (22 rows)
@@ -3933,6 +4366,12 @@ SELECT * FROM rls_view; -- OK
  10
 (1 row)
 
+SELECT * FROM f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE TABLE f_leak_table;
 RESET SESSION AUTHORIZATION;
 DROP VIEW rls_view;
 DROP TABLE rls_tbl;
diff --git a/src/test/regress/expected/rowsecurity_1.out b/src/test/regress/expected/rowsecurity_1.out
new file mode 100644
index 0000000..1cb0fe5
--- /dev/null
+++ b/src/test/regress/expected/rowsecurity_1.out
@@ -0,0 +1,4461 @@
+--
+-- Test of Row-level security feature
+--
+-- Clean up in case a prior regression run failed
+-- Suppress NOTICE messages when users/groups don't exist
+SET client_min_messages TO 'warning';
+DROP USER IF EXISTS regress_rls_alice;
+DROP USER IF EXISTS regress_rls_bob;
+DROP USER IF EXISTS regress_rls_carol;
+DROP USER IF EXISTS regress_rls_dave;
+DROP USER IF EXISTS regress_rls_exempt_user;
+DROP ROLE IF EXISTS regress_rls_group1;
+DROP ROLE IF EXISTS regress_rls_group2;
+DROP SCHEMA IF EXISTS regress_rls_schema CASCADE;
+RESET client_min_messages;
+-- initial setup
+CREATE USER regress_rls_alice NOLOGIN;
+CREATE USER regress_rls_bob NOLOGIN;
+CREATE USER regress_rls_carol NOLOGIN;
+CREATE USER regress_rls_dave NOLOGIN;
+CREATE USER regress_rls_exempt_user BYPASSRLS NOLOGIN;
+CREATE ROLE regress_rls_group1 NOLOGIN;
+CREATE ROLE regress_rls_group2 NOLOGIN;
+GRANT regress_rls_group1 TO regress_rls_bob;
+GRANT regress_rls_group2 TO regress_rls_carol;
+CREATE SCHEMA regress_rls_schema;
+GRANT ALL ON SCHEMA regress_rls_schema to public;
+SET search_path = regress_rls_schema;
+-- setup of malicious function
+CREATE TEMP TABLE f_leak_table(a text);
+CREATE OR REPLACE FUNCTION f_leak(text) RETURNS bool
+    COST 0.0000001 LANGUAGE plpgsql
+    AS 'BEGIN INSERT INTO f_leak_table values($1); RETURN true; END';
+GRANT INSERT, SELECT,TRUNCATE ON TABLE f_leak_table TO public;
+GRANT EXECUTE ON FUNCTION f_leak(text) TO public;
+-- BASIC Row-Level Security Scenario
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE TABLE uaccount (
+    pguser      name primary key,
+    seclv       int
+);
+GRANT SELECT ON uaccount TO public;
+INSERT INTO uaccount VALUES
+    ('regress_rls_alice', 99),
+    ('regress_rls_bob', 1),
+    ('regress_rls_carol', 2),
+    ('regress_rls_dave', 3);
+CREATE TABLE category (
+    cid        int primary key,
+    cname      text
+);
+GRANT ALL ON category TO public;
+INSERT INTO category VALUES
+    (11, 'novel'),
+    (22, 'science fiction'),
+    (33, 'technology'),
+    (44, 'manga');
+CREATE TABLE document (
+    did         int primary key,
+    cid         int references category(cid),
+    dlevel      int not null,
+    dauthor     name,
+    dtitle      text
+);
+GRANT ALL ON document TO public;
+INSERT INTO document VALUES
+    ( 1, 11, 1, 'regress_rls_bob', 'my first novel'),
+    ( 2, 11, 2, 'regress_rls_bob', 'my second novel'),
+    ( 3, 22, 2, 'regress_rls_bob', 'my science fiction'),
+    ( 4, 44, 1, 'regress_rls_bob', 'my first manga'),
+    ( 5, 44, 2, 'regress_rls_bob', 'my second manga'),
+    ( 6, 22, 1, 'regress_rls_carol', 'great science fiction'),
+    ( 7, 33, 2, 'regress_rls_carol', 'great technology book'),
+    ( 8, 44, 1, 'regress_rls_carol', 'great manga'),
+    ( 9, 22, 1, 'regress_rls_dave', 'awesome science fiction'),
+    (10, 33, 2, 'regress_rls_dave', 'awesome technology book');
+ALTER TABLE document ENABLE ROW LEVEL SECURITY;
+-- user's security level must be higher than or equal to document's
+CREATE POLICY p1 ON document AS PERMISSIVE
+    USING (dlevel <= (SELECT seclv FROM uaccount WHERE pguser = current_user));
+-- try to create a policy of bogus type
+CREATE POLICY p1 ON document AS UGLY
+    USING (dlevel <= (SELECT seclv FROM uaccount WHERE pguser = current_user));
+ERROR:  unrecognized row security option "ugly"
+LINE 1: CREATE POLICY p1 ON document AS UGLY
+                                        ^
+HINT:  Only PERMISSIVE or RESTRICTIVE policies are supported currently.
+-- but Dave isn't allowed to anything at cid 50 or above
+-- this is to make sure that we sort the policies by name first
+-- when applying WITH CHECK, a later INSERT by Dave should fail due
+-- to p1r first
+CREATE POLICY p2r ON document AS RESTRICTIVE TO regress_rls_dave
+    USING (cid <> 44 AND cid < 50);
+-- and Dave isn't allowed to see manga documents
+CREATE POLICY p1r ON document AS RESTRICTIVE TO regress_rls_dave
+    USING (cid <> 44);
+\dp
+                                                                  Access privileges
+       Schema       |   Name   | Type  |              Access privileges              | Column privileges |                  Policies                  
+--------------------+----------+-------+---------------------------------------------+-------------------+--------------------------------------------
+ regress_rls_schema | category | table | regress_rls_alice=arwdDxt/regress_rls_alice+|                   | 
+                    |          |       | =arwdDxt/regress_rls_alice                  |                   | 
+ regress_rls_schema | document | table | regress_rls_alice=arwdDxt/regress_rls_alice+|                   | p1:                                       +
+                    |          |       | =arwdDxt/regress_rls_alice                  |                   |   (u): (dlevel <= ( SELECT uaccount.seclv +
+                    |          |       |                                             |                   |    FROM uaccount                          +
+                    |          |       |                                             |                   |   WHERE (uaccount.pguser = CURRENT_USER)))+
+                    |          |       |                                             |                   | p2r (RESTRICTIVE):                        +
+                    |          |       |                                             |                   |   (u): ((cid <> 44) AND (cid < 50))       +
+                    |          |       |                                             |                   |   to: regress_rls_dave                    +
+                    |          |       |                                             |                   | p1r (RESTRICTIVE):                        +
+                    |          |       |                                             |                   |   (u): (cid <> 44)                        +
+                    |          |       |                                             |                   |   to: regress_rls_dave
+ regress_rls_schema | uaccount | table | regress_rls_alice=arwdDxt/regress_rls_alice+|                   | 
+                    |          |       | =r/regress_rls_alice                        |                   | 
+(3 rows)
+
+\d document
+        Table "regress_rls_schema.document"
+ Column  |  Type   | Collation | Nullable | Default 
+---------+---------+-----------+----------+---------
+ did     | integer |           | not null | 
+ cid     | integer |           |          | 
+ dlevel  | integer |           | not null | 
+ dauthor | name    |           |          | 
+ dtitle  | text    |           |          | 
+Indexes:
+    "document_pkey" PRIMARY KEY, btree (did)
+Foreign-key constraints:
+    "document_cid_fkey" FOREIGN KEY (cid) REFERENCES category(cid)
+Policies:
+    POLICY "p1"
+      USING ((dlevel <= ( SELECT uaccount.seclv
+   FROM uaccount
+  WHERE (uaccount.pguser = CURRENT_USER))))
+    POLICY "p1r" AS RESTRICTIVE
+      TO regress_rls_dave
+      USING ((cid <> 44))
+    POLICY "p2r" AS RESTRICTIVE
+      TO regress_rls_dave
+      USING (((cid <> 44) AND (cid < 50)))
+
+SELECT * FROM pg_policies WHERE schemaname = 'regress_rls_schema' AND tablename = 'document' ORDER BY policyname;
+     schemaname     | tablename | policyname | permissive  |       roles        | cmd |                    qual                    | with_check 
+--------------------+-----------+------------+-------------+--------------------+-----+--------------------------------------------+------------
+ regress_rls_schema | document  | p1         | PERMISSIVE  | {public}           | ALL | (dlevel <= ( SELECT uaccount.seclv        +| 
+                    |           |            |             |                    |     |    FROM uaccount                          +| 
+                    |           |            |             |                    |     |   WHERE (uaccount.pguser = CURRENT_USER))) | 
+ regress_rls_schema | document  | p1r        | RESTRICTIVE | {regress_rls_dave} | ALL | (cid <> 44)                                | 
+ regress_rls_schema | document  | p2r        | RESTRICTIVE | {regress_rls_dave} | ALL | ((cid <> 44) AND (cid < 50))               | 
+(3 rows)
+
+-- viewpoint from regress_rls_bob
+SET SESSION AUTHORIZATION regress_rls_bob;
+SET row_security TO ON;
+SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   4 |  44 |      1 | regress_rls_bob   | my first manga
+   6 |  22 |      1 | regress_rls_carol | great science fiction
+   8 |  44 |      1 | regress_rls_carol | great manga
+   9 |  22 |      1 | regress_rls_dave  | awesome science fiction
+(5 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great manga
+ great science fiction
+ my first manga
+ my first novel
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
+SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER BY did;
+ cid | did | dlevel |      dauthor      |         dtitle          |      cname      
+-----+-----+--------+-------------------+-------------------------+-----------------
+  11 |   1 |      1 | regress_rls_bob   | my first novel          | novel
+  44 |   4 |      1 | regress_rls_bob   | my first manga          | manga
+  22 |   6 |      1 | regress_rls_carol | great science fiction   | science fiction
+  44 |   8 |      1 | regress_rls_carol | great manga             | manga
+  22 |   9 |      1 | regress_rls_dave  | awesome science fiction | science fiction
+(5 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great manga
+ great science fiction
+ my first manga
+ my first novel
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
+-- try a sampled version
+SELECT * FROM document TABLESAMPLE BERNOULLI(50) REPEATABLE(0)
+  WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   4 |  44 |      1 | regress_rls_bob   | my first manga
+   6 |  22 |      1 | regress_rls_carol | great science fiction
+   8 |  44 |      1 | regress_rls_carol | great manga
+   9 |  22 |      1 | regress_rls_dave  | awesome science fiction
+(4 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great manga
+ great science fiction
+ my first manga
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
+-- viewpoint from regress_rls_carol
+SET SESSION AUTHORIZATION regress_rls_carol;
+SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   3 |  22 |      2 | regress_rls_bob   | my science fiction
+   4 |  44 |      1 | regress_rls_bob   | my first manga
+   5 |  44 |      2 | regress_rls_bob   | my second manga
+   6 |  22 |      1 | regress_rls_carol | great science fiction
+   7 |  33 |      2 | regress_rls_carol | great technology book
+   8 |  44 |      1 | regress_rls_carol | great manga
+   9 |  22 |      1 | regress_rls_dave  | awesome science fiction
+  10 |  33 |      2 | regress_rls_dave  | awesome technology book
+(10 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ awesome technology book
+ great manga
+ great science fiction
+ great technology book
+ my first manga
+ my first novel
+ my science fiction
+ my second manga
+ my second novel
+(10 rows)
+
+TRUNCATE TABLE f_leak_table;
+SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER BY did;
+ cid | did | dlevel |      dauthor      |         dtitle          |      cname      
+-----+-----+--------+-------------------+-------------------------+-----------------
+  11 |   1 |      1 | regress_rls_bob   | my first novel          | novel
+  11 |   2 |      2 | regress_rls_bob   | my second novel         | novel
+  22 |   3 |      2 | regress_rls_bob   | my science fiction      | science fiction
+  44 |   4 |      1 | regress_rls_bob   | my first manga          | manga
+  44 |   5 |      2 | regress_rls_bob   | my second manga         | manga
+  22 |   6 |      1 | regress_rls_carol | great science fiction   | science fiction
+  33 |   7 |      2 | regress_rls_carol | great technology book   | technology
+  44 |   8 |      1 | regress_rls_carol | great manga             | manga
+  22 |   9 |      1 | regress_rls_dave  | awesome science fiction | science fiction
+  33 |  10 |      2 | regress_rls_dave  | awesome technology book | technology
+(10 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ awesome technology book
+ great manga
+ great science fiction
+ great technology book
+ my first manga
+ my first novel
+ my science fiction
+ my second manga
+ my second novel
+(10 rows)
+
+TRUNCATE TABLE f_leak_table;
+-- try a sampled version
+SELECT * FROM document TABLESAMPLE BERNOULLI(50) REPEATABLE(0)
+  WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   3 |  22 |      2 | regress_rls_bob   | my science fiction
+   4 |  44 |      1 | regress_rls_bob   | my first manga
+   6 |  22 |      1 | regress_rls_carol | great science fiction
+   8 |  44 |      1 | regress_rls_carol | great manga
+   9 |  22 |      1 | regress_rls_dave  | awesome science fiction
+  10 |  33 |      2 | regress_rls_dave  | awesome technology book
+(7 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ awesome technology book
+ great manga
+ great science fiction
+ my first manga
+ my science fiction
+ my second novel
+(7 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM document WHERE f_leak(dtitle);
+                     QUERY PLAN                     
+----------------------------------------------------
+ Seq Scan on document
+   Filter: ((dlevel <= $0) AND f_leak(dtitle))
+   InitPlan 1 (returns $0)
+     ->  Index Scan using uaccount_pkey on uaccount
+           Index Cond: (pguser = CURRENT_USER)
+(5 rows)
+
+EXPLAIN (COSTS OFF) SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle);
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Hash Join
+   Hash Cond: (document.cid = category.cid)
+   InitPlan 1 (returns $0)
+     ->  Index Scan using uaccount_pkey on uaccount
+           Index Cond: (pguser = CURRENT_USER)
+   ->  Seq Scan on document
+         Filter: ((dlevel <= $0) AND f_leak(dtitle))
+   ->  Hash
+         ->  Seq Scan on category
+(9 rows)
+
+-- viewpoint from regress_rls_dave
+SET SESSION AUTHORIZATION regress_rls_dave;
+SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   3 |  22 |      2 | regress_rls_bob   | my science fiction
+   6 |  22 |      1 | regress_rls_carol | great science fiction
+   7 |  33 |      2 | regress_rls_carol | great technology book
+   9 |  22 |      1 | regress_rls_dave  | awesome science fiction
+  10 |  33 |      2 | regress_rls_dave  | awesome technology book
+(7 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ awesome technology book
+ great science fiction
+ great technology book
+ my first novel
+ my science fiction
+ my second novel
+(7 rows)
+
+TRUNCATE TABLE f_leak_table;
+SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER BY did;
+ cid | did | dlevel |      dauthor      |         dtitle          |      cname      
+-----+-----+--------+-------------------+-------------------------+-----------------
+  11 |   1 |      1 | regress_rls_bob   | my first novel          | novel
+  11 |   2 |      2 | regress_rls_bob   | my second novel         | novel
+  22 |   3 |      2 | regress_rls_bob   | my science fiction      | science fiction
+  22 |   6 |      1 | regress_rls_carol | great science fiction   | science fiction
+  33 |   7 |      2 | regress_rls_carol | great technology book   | technology
+  22 |   9 |      1 | regress_rls_dave  | awesome science fiction | science fiction
+  33 |  10 |      2 | regress_rls_dave  | awesome technology book | technology
+(7 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ awesome technology book
+ great science fiction
+ great technology book
+ my first novel
+ my science fiction
+ my second novel
+(7 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM document WHERE f_leak(dtitle);
+                                          QUERY PLAN                                          
+----------------------------------------------------------------------------------------------
+ Seq Scan on document
+   Filter: ((cid <> 44) AND (cid <> 44) AND (cid < 50) AND (dlevel <= $0) AND f_leak(dtitle))
+   InitPlan 1 (returns $0)
+     ->  Index Scan using uaccount_pkey on uaccount
+           Index Cond: (pguser = CURRENT_USER)
+(5 rows)
+
+EXPLAIN (COSTS OFF) SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle);
+                                                QUERY PLAN                                                
+----------------------------------------------------------------------------------------------------------
+ Hash Join
+   Hash Cond: (category.cid = document.cid)
+   InitPlan 1 (returns $0)
+     ->  Index Scan using uaccount_pkey on uaccount
+           Index Cond: (pguser = CURRENT_USER)
+   ->  Seq Scan on category
+   ->  Hash
+         ->  Seq Scan on document
+               Filter: ((cid <> 44) AND (cid <> 44) AND (cid < 50) AND (dlevel <= $0) AND f_leak(dtitle))
+(9 rows)
+
+-- 44 would technically fail for both p2r and p1r, but we should get an error
+-- back from p1r for this because it sorts first
+INSERT INTO document VALUES (100, 44, 1, 'regress_rls_dave', 'testing sorting of policies'); -- fail
+ERROR:  new row violates row-level security policy "p1r" for table "document"
+-- Just to see a p2r error
+INSERT INTO document VALUES (100, 55, 1, 'regress_rls_dave', 'testing sorting of policies'); -- fail
+ERROR:  new row violates row-level security policy "p2r" for table "document"
+-- only owner can change policies
+ALTER POLICY p1 ON document USING (true);    --fail
+ERROR:  must be owner of table document
+DROP POLICY p1 ON document;                  --fail
+ERROR:  must be owner of relation document
+SET SESSION AUTHORIZATION regress_rls_alice;
+ALTER POLICY p1 ON document USING (dauthor = current_user);
+-- viewpoint from regress_rls_bob again
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |     dauthor     |       dtitle       
+-----+-----+--------+-----------------+--------------------
+   1 |  11 |      1 | regress_rls_bob | my first novel
+   2 |  11 |      2 | regress_rls_bob | my second novel
+   3 |  22 |      2 | regress_rls_bob | my science fiction
+   4 |  44 |      1 | regress_rls_bob | my first manga
+   5 |  44 |      2 | regress_rls_bob | my second manga
+(5 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+         a          
+--------------------
+ my first manga
+ my first novel
+ my science fiction
+ my second manga
+ my second novel
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
+SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER by did;
+ cid | did | dlevel |     dauthor     |       dtitle       |      cname      
+-----+-----+--------+-----------------+--------------------+-----------------
+  11 |   1 |      1 | regress_rls_bob | my first novel     | novel
+  11 |   2 |      2 | regress_rls_bob | my second novel    | novel
+  22 |   3 |      2 | regress_rls_bob | my science fiction | science fiction
+  44 |   4 |      1 | regress_rls_bob | my first manga     | manga
+  44 |   5 |      2 | regress_rls_bob | my second manga    | manga
+(5 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+         a          
+--------------------
+ my first manga
+ my first novel
+ my science fiction
+ my second manga
+ my second novel
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
+-- viewpoint from rls_regres_carol again
+SET SESSION AUTHORIZATION regress_rls_carol;
+SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |        dtitle         
+-----+-----+--------+-------------------+-----------------------
+   6 |  22 |      1 | regress_rls_carol | great science fiction
+   7 |  33 |      2 | regress_rls_carol | great technology book
+   8 |  44 |      1 | regress_rls_carol | great manga
+(3 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+           a           
+-----------------------
+ great manga
+ great science fiction
+ great technology book
+(3 rows)
+
+TRUNCATE TABLE f_leak_table;
+SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER by did;
+ cid | did | dlevel |      dauthor      |        dtitle         |      cname      
+-----+-----+--------+-------------------+-----------------------+-----------------
+  22 |   6 |      1 | regress_rls_carol | great science fiction | science fiction
+  33 |   7 |      2 | regress_rls_carol | great technology book | technology
+  44 |   8 |      1 | regress_rls_carol | great manga           | manga
+(3 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+           a           
+-----------------------
+ great manga
+ great science fiction
+ great technology book
+(3 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM document WHERE f_leak(dtitle);
+                       QUERY PLAN                        
+---------------------------------------------------------
+ Seq Scan on document
+   Filter: ((dauthor = CURRENT_USER) AND f_leak(dtitle))
+(2 rows)
+
+EXPLAIN (COSTS OFF) SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle);
+                          QUERY PLAN                           
+---------------------------------------------------------------
+ Nested Loop
+   ->  Seq Scan on document
+         Filter: ((dauthor = CURRENT_USER) AND f_leak(dtitle))
+   ->  Index Scan using category_pkey on category
+         Index Cond: (cid = document.cid)
+(5 rows)
+
+-- interaction of FK/PK constraints
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE POLICY p2 ON category
+    USING (CASE WHEN current_user = 'regress_rls_bob' THEN cid IN (11, 33)
+           WHEN current_user = 'regress_rls_carol' THEN cid IN (22, 44)
+           ELSE false END);
+ALTER TABLE category ENABLE ROW LEVEL SECURITY;
+-- cannot delete PK referenced by invisible FK
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM document d FULL OUTER JOIN category c on d.cid = c.cid ORDER BY d.did, c.cid;
+ did | cid | dlevel |     dauthor     |       dtitle       | cid |   cname    
+-----+-----+--------+-----------------+--------------------+-----+------------
+   1 |  11 |      1 | regress_rls_bob | my first novel     |  11 | novel
+   2 |  11 |      2 | regress_rls_bob | my second novel    |  11 | novel
+   3 |  22 |      2 | regress_rls_bob | my science fiction |     | 
+   4 |  44 |      1 | regress_rls_bob | my first manga     |     | 
+   5 |  44 |      2 | regress_rls_bob | my second manga    |     | 
+     |     |        |                 |                    |  33 | technology
+(6 rows)
+
+DELETE FROM category WHERE cid = 33;    -- fails with FK violation
+ERROR:  update or delete on table "category" violates foreign key constraint "document_cid_fkey" on table "document"
+DETAIL:  Key is still referenced from table "document".
+-- can insert FK referencing invisible PK
+SET SESSION AUTHORIZATION regress_rls_carol;
+SELECT * FROM document d FULL OUTER JOIN category c on d.cid = c.cid ORDER BY d.did, c.cid;
+ did | cid | dlevel |      dauthor      |        dtitle         | cid |      cname      
+-----+-----+--------+-------------------+-----------------------+-----+-----------------
+   6 |  22 |      1 | regress_rls_carol | great science fiction |  22 | science fiction
+   7 |  33 |      2 | regress_rls_carol | great technology book |     | 
+   8 |  44 |      1 | regress_rls_carol | great manga           |  44 | manga
+(3 rows)
+
+INSERT INTO document VALUES (11, 33, 1, current_user, 'hoge');
+-- UNIQUE or PRIMARY KEY constraint violation DOES reveal presence of row
+SET SESSION AUTHORIZATION regress_rls_bob;
+INSERT INTO document VALUES (8, 44, 1, 'regress_rls_bob', 'my third manga'); -- Must fail with unique violation, revealing presence of did we can't see
+ERROR:  duplicate key value violates unique constraint "document_pkey"
+SELECT * FROM document WHERE did = 8; -- and confirm we can't see it
+ did | cid | dlevel | dauthor | dtitle 
+-----+-----+--------+---------+--------
+(0 rows)
+
+-- RLS policies are checked before constraints
+INSERT INTO document VALUES (8, 44, 1, 'regress_rls_carol', 'my third manga'); -- Should fail with RLS check violation, not duplicate key violation
+ERROR:  new row violates row-level security policy for table "document"
+UPDATE document SET did = 8, dauthor = 'regress_rls_carol' WHERE did = 5; -- Should fail with RLS check violation, not duplicate key violation
+ERROR:  new row violates row-level security policy for table "document"
+-- database superuser does bypass RLS policy when enabled
+RESET SESSION AUTHORIZATION;
+SET row_security TO ON;
+SELECT * FROM document;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   3 |  22 |      2 | regress_rls_bob   | my science fiction
+   4 |  44 |      1 | regress_rls_bob   | my first manga
+   5 |  44 |      2 | regress_rls_bob   | my second manga
+   6 |  22 |      1 | regress_rls_carol | great science fiction
+   7 |  33 |      2 | regress_rls_carol | great technology book
+   8 |  44 |      1 | regress_rls_carol | great manga
+   9 |  22 |      1 | regress_rls_dave  | awesome science fiction
+  10 |  33 |      2 | regress_rls_dave  | awesome technology book
+  11 |  33 |      1 | regress_rls_carol | hoge
+(11 rows)
+
+SELECT * FROM category;
+ cid |      cname      
+-----+-----------------
+  11 | novel
+  22 | science fiction
+  33 | technology
+  44 | manga
+(4 rows)
+
+-- database superuser does bypass RLS policy when disabled
+RESET SESSION AUTHORIZATION;
+SET row_security TO OFF;
+SELECT * FROM document;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   3 |  22 |      2 | regress_rls_bob   | my science fiction
+   4 |  44 |      1 | regress_rls_bob   | my first manga
+   5 |  44 |      2 | regress_rls_bob   | my second manga
+   6 |  22 |      1 | regress_rls_carol | great science fiction
+   7 |  33 |      2 | regress_rls_carol | great technology book
+   8 |  44 |      1 | regress_rls_carol | great manga
+   9 |  22 |      1 | regress_rls_dave  | awesome science fiction
+  10 |  33 |      2 | regress_rls_dave  | awesome technology book
+  11 |  33 |      1 | regress_rls_carol | hoge
+(11 rows)
+
+SELECT * FROM category;
+ cid |      cname      
+-----+-----------------
+  11 | novel
+  22 | science fiction
+  33 | technology
+  44 | manga
+(4 rows)
+
+-- database non-superuser with bypass privilege can bypass RLS policy when disabled
+SET SESSION AUTHORIZATION regress_rls_exempt_user;
+SET row_security TO OFF;
+SELECT * FROM document;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   3 |  22 |      2 | regress_rls_bob   | my science fiction
+   4 |  44 |      1 | regress_rls_bob   | my first manga
+   5 |  44 |      2 | regress_rls_bob   | my second manga
+   6 |  22 |      1 | regress_rls_carol | great science fiction
+   7 |  33 |      2 | regress_rls_carol | great technology book
+   8 |  44 |      1 | regress_rls_carol | great manga
+   9 |  22 |      1 | regress_rls_dave  | awesome science fiction
+  10 |  33 |      2 | regress_rls_dave  | awesome technology book
+  11 |  33 |      1 | regress_rls_carol | hoge
+(11 rows)
+
+SELECT * FROM category;
+ cid |      cname      
+-----+-----------------
+  11 | novel
+  22 | science fiction
+  33 | technology
+  44 | manga
+(4 rows)
+
+-- RLS policy does not apply to table owner when RLS enabled.
+SET SESSION AUTHORIZATION regress_rls_alice;
+SET row_security TO ON;
+SELECT * FROM document;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   3 |  22 |      2 | regress_rls_bob   | my science fiction
+   4 |  44 |      1 | regress_rls_bob   | my first manga
+   5 |  44 |      2 | regress_rls_bob   | my second manga
+   6 |  22 |      1 | regress_rls_carol | great science fiction
+   7 |  33 |      2 | regress_rls_carol | great technology book
+   8 |  44 |      1 | regress_rls_carol | great manga
+   9 |  22 |      1 | regress_rls_dave  | awesome science fiction
+  10 |  33 |      2 | regress_rls_dave  | awesome technology book
+  11 |  33 |      1 | regress_rls_carol | hoge
+(11 rows)
+
+SELECT * FROM category;
+ cid |      cname      
+-----+-----------------
+  11 | novel
+  22 | science fiction
+  33 | technology
+  44 | manga
+(4 rows)
+
+-- RLS policy does not apply to table owner when RLS disabled.
+SET SESSION AUTHORIZATION regress_rls_alice;
+SET row_security TO OFF;
+SELECT * FROM document;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   3 |  22 |      2 | regress_rls_bob   | my science fiction
+   4 |  44 |      1 | regress_rls_bob   | my first manga
+   5 |  44 |      2 | regress_rls_bob   | my second manga
+   6 |  22 |      1 | regress_rls_carol | great science fiction
+   7 |  33 |      2 | regress_rls_carol | great technology book
+   8 |  44 |      1 | regress_rls_carol | great manga
+   9 |  22 |      1 | regress_rls_dave  | awesome science fiction
+  10 |  33 |      2 | regress_rls_dave  | awesome technology book
+  11 |  33 |      1 | regress_rls_carol | hoge
+(11 rows)
+
+SELECT * FROM category;
+ cid |      cname      
+-----+-----------------
+  11 | novel
+  22 | science fiction
+  33 | technology
+  44 | manga
+(4 rows)
+
+--
+-- Table inheritance and RLS policy
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+SET row_security TO ON;
+CREATE TABLE t1 (id int not null primary key, a int, junk1 text, b text);
+ALTER TABLE t1 DROP COLUMN junk1;    -- just a disturbing factor
+GRANT ALL ON t1 TO public;
+COPY t1 FROM stdin WITH ;
+CREATE TABLE t2 (c float) INHERITS (t1);
+GRANT ALL ON t2 TO public;
+COPY t2 FROM stdin;
+CREATE TABLE t3 (id int not null primary key, c text, b text, a int);
+ALTER TABLE t3 INHERIT t1;
+GRANT ALL ON t3 TO public;
+COPY t3(id, a,b,c) FROM stdin;
+CREATE POLICY p1 ON t1 FOR ALL TO PUBLIC USING (a % 2 = 0); -- be even number
+CREATE POLICY p2 ON t2 FOR ALL TO PUBLIC USING (a % 2 = 1); -- be odd number
+ALTER TABLE t1 ENABLE ROW LEVEL SECURITY;
+ALTER TABLE t2 ENABLE ROW LEVEL SECURITY;
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM t1;
+ id  | a |  b  
+-----+---+-----
+ 102 | 2 | bbb
+ 104 | 4 | dad
+ 202 | 2 | bcd
+ 204 | 4 | def
+ 302 | 2 | yyy
+(5 rows)
+
+EXPLAIN (COSTS OFF) SELECT * FROM t1;
+          QUERY PLAN           
+-------------------------------
+ Append
+   ->  Seq Scan on t1
+         Filter: ((a % 2) = 0)
+   ->  Seq Scan on t2
+         Filter: ((a % 2) = 0)
+   ->  Seq Scan on t3
+         Filter: ((a % 2) = 0)
+(7 rows)
+
+SELECT * FROM t1 WHERE f_leak(b);
+ id  | a |  b  
+-----+---+-----
+ 102 | 2 | bbb
+ 104 | 4 | dad
+ 202 | 2 | bcd
+ 204 | 4 | def
+ 302 | 2 | yyy
+(5 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ bcd
+ dad
+ def
+ yyy
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b);
+                  QUERY PLAN                   
+-----------------------------------------------
+ Append
+   ->  Seq Scan on t1
+         Filter: (((a % 2) = 0) AND f_leak(b))
+   ->  Seq Scan on t2
+         Filter: (((a % 2) = 0) AND f_leak(b))
+   ->  Seq Scan on t3
+         Filter: (((a % 2) = 0) AND f_leak(b))
+(7 rows)
+
+-- reference to system column
+SELECT tableoid::regclass, * FROM t1;
+ tableoid | id  | a |  b  
+----------+-----+---+-----
+ t1       | 102 | 2 | bbb
+ t1       | 104 | 4 | dad
+ t2       | 202 | 2 | bcd
+ t2       | 204 | 4 | def
+ t3       | 302 | 2 | yyy
+(5 rows)
+
+EXPLAIN (COSTS OFF) SELECT *, t1 FROM t1;
+          QUERY PLAN           
+-------------------------------
+ Append
+   ->  Seq Scan on t1
+         Filter: ((a % 2) = 0)
+   ->  Seq Scan on t2
+         Filter: ((a % 2) = 0)
+   ->  Seq Scan on t3
+         Filter: ((a % 2) = 0)
+(7 rows)
+
+-- reference to whole-row reference
+SELECT *, t1 FROM t1;
+ id  | a |  b  |     t1      
+-----+---+-----+-------------
+ 102 | 2 | bbb | (102,2,bbb)
+ 104 | 4 | dad | (104,4,dad)
+ 202 | 2 | bcd | (202,2,bcd)
+ 204 | 4 | def | (204,4,def)
+ 302 | 2 | yyy | (302,2,yyy)
+(5 rows)
+
+EXPLAIN (COSTS OFF) SELECT *, t1 FROM t1;
+          QUERY PLAN           
+-------------------------------
+ Append
+   ->  Seq Scan on t1
+         Filter: ((a % 2) = 0)
+   ->  Seq Scan on t2
+         Filter: ((a % 2) = 0)
+   ->  Seq Scan on t3
+         Filter: ((a % 2) = 0)
+(7 rows)
+
+-- for share/update lock
+SELECT * FROM t1 FOR SHARE;
+ id  | a |  b  
+-----+---+-----
+ 102 | 2 | bbb
+ 104 | 4 | dad
+ 202 | 2 | bcd
+ 204 | 4 | def
+ 302 | 2 | yyy
+(5 rows)
+
+EXPLAIN (COSTS OFF) SELECT * FROM t1 FOR SHARE;
+             QUERY PLAN              
+-------------------------------------
+ LockRows
+   ->  Append
+         ->  Seq Scan on t1
+               Filter: ((a % 2) = 0)
+         ->  Seq Scan on t2
+               Filter: ((a % 2) = 0)
+         ->  Seq Scan on t3
+               Filter: ((a % 2) = 0)
+(8 rows)
+
+SELECT * FROM t1 WHERE f_leak(b) FOR SHARE;
+ id  | a |  b  
+-----+---+-----
+ 102 | 2 | bbb
+ 104 | 4 | dad
+ 202 | 2 | bcd
+ 204 | 4 | def
+ 302 | 2 | yyy
+(5 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ bcd
+ dad
+ def
+ yyy
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b) FOR SHARE;
+                     QUERY PLAN                      
+-----------------------------------------------------
+ LockRows
+   ->  Append
+         ->  Seq Scan on t1
+               Filter: (((a % 2) = 0) AND f_leak(b))
+         ->  Seq Scan on t2
+               Filter: (((a % 2) = 0) AND f_leak(b))
+         ->  Seq Scan on t3
+               Filter: (((a % 2) = 0) AND f_leak(b))
+(8 rows)
+
+-- union all query
+SELECT a, b, tableoid::regclass FROM t2 UNION ALL SELECT a, b, tableoid::regclass FROM t3;
+ a |  b  | tableoid 
+---+-----+----------
+ 1 | abc | t2
+ 3 | cde | t2
+ 1 | xxx | t3
+ 2 | yyy | t3
+ 3 | zzz | t3
+(5 rows)
+
+EXPLAIN (COSTS OFF) SELECT a, b, tableoid::regclass FROM t2 UNION ALL SELECT a, b, tableoid::regclass FROM t3;
+          QUERY PLAN           
+-------------------------------
+ Append
+   ->  Seq Scan on t2
+         Filter: ((a % 2) = 1)
+   ->  Seq Scan on t3
+(4 rows)
+
+-- superuser is allowed to bypass RLS checks
+RESET SESSION AUTHORIZATION;
+SET row_security TO OFF;
+SELECT * FROM t1 WHERE f_leak(b);
+ id  | a |  b  
+-----+---+-----
+ 101 | 1 | aba
+ 102 | 2 | bbb
+ 103 | 3 | ccc
+ 104 | 4 | dad
+ 201 | 1 | abc
+ 202 | 2 | bcd
+ 203 | 3 | cde
+ 204 | 4 | def
+ 301 | 1 | xxx
+ 302 | 2 | yyy
+ 303 | 3 | zzz
+(11 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ abc
+ bbb
+ bcd
+ ccc
+ cde
+ dad
+ def
+ xxx
+ yyy
+ zzz
+(11 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b);
+        QUERY PLAN         
+---------------------------
+ Append
+   ->  Seq Scan on t1
+         Filter: f_leak(b)
+   ->  Seq Scan on t2
+         Filter: f_leak(b)
+   ->  Seq Scan on t3
+         Filter: f_leak(b)
+(7 rows)
+
+-- non-superuser with bypass privilege can bypass RLS policy when disabled
+SET SESSION AUTHORIZATION regress_rls_exempt_user;
+SET row_security TO OFF;
+SELECT * FROM t1 WHERE f_leak(b);
+ id  | a |  b  
+-----+---+-----
+ 101 | 1 | aba
+ 102 | 2 | bbb
+ 103 | 3 | ccc
+ 104 | 4 | dad
+ 201 | 1 | abc
+ 202 | 2 | bcd
+ 203 | 3 | cde
+ 204 | 4 | def
+ 301 | 1 | xxx
+ 302 | 2 | yyy
+ 303 | 3 | zzz
+(11 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ abc
+ bbb
+ bcd
+ ccc
+ cde
+ dad
+ def
+ xxx
+ yyy
+ zzz
+(11 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b);
+        QUERY PLAN         
+---------------------------
+ Append
+   ->  Seq Scan on t1
+         Filter: f_leak(b)
+   ->  Seq Scan on t2
+         Filter: f_leak(b)
+   ->  Seq Scan on t3
+         Filter: f_leak(b)
+(7 rows)
+
+--
+-- Partitioned Tables
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE TABLE part_document (
+    did         int,
+    cid         int,
+    dlevel      int not null,
+    dauthor     name,
+    dtitle      text
+) PARTITION BY RANGE (cid);
+GRANT ALL ON part_document TO public;
+-- Create partitions for document categories
+CREATE TABLE part_document_fiction PARTITION OF part_document FOR VALUES FROM (11) to (12);
+CREATE TABLE part_document_satire PARTITION OF part_document FOR VALUES FROM (55) to (56);
+CREATE TABLE part_document_nonfiction PARTITION OF part_document FOR VALUES FROM (99) to (100);
+GRANT ALL ON part_document_fiction TO public;
+GRANT ALL ON part_document_satire TO public;
+GRANT ALL ON part_document_nonfiction TO public;
+INSERT INTO part_document VALUES
+    ( 1, 11, 1, 'regress_rls_bob', 'my first novel'),
+    ( 2, 11, 2, 'regress_rls_bob', 'my second novel'),
+    ( 3, 99, 2, 'regress_rls_bob', 'my science textbook'),
+    ( 4, 55, 1, 'regress_rls_bob', 'my first satire'),
+    ( 5, 99, 2, 'regress_rls_bob', 'my history book'),
+    ( 6, 11, 1, 'regress_rls_carol', 'great science fiction'),
+    ( 7, 99, 2, 'regress_rls_carol', 'great technology book'),
+    ( 8, 55, 2, 'regress_rls_carol', 'great satire'),
+    ( 9, 11, 1, 'regress_rls_dave', 'awesome science fiction'),
+    (10, 99, 2, 'regress_rls_dave', 'awesome technology book');
+ALTER TABLE part_document ENABLE ROW LEVEL SECURITY;
+-- Create policy on parent
+-- user's security level must be higher than or equal to document's
+CREATE POLICY pp1 ON part_document AS PERMISSIVE
+    USING (dlevel <= (SELECT seclv FROM uaccount WHERE pguser = current_user));
+-- Dave is only allowed to see cid < 55
+CREATE POLICY pp1r ON part_document AS RESTRICTIVE TO regress_rls_dave
+    USING (cid < 55);
+\d+ part_document
+                    Partitioned table "regress_rls_schema.part_document"
+ Column  |  Type   | Collation | Nullable | Default | Storage  | Stats target | Description 
+---------+---------+-----------+----------+---------+----------+--------------+-------------
+ did     | integer |           |          |         | plain    |              | 
+ cid     | integer |           |          |         | plain    |              | 
+ dlevel  | integer |           | not null |         | plain    |              | 
+ dauthor | name    |           |          |         | plain    |              | 
+ dtitle  | text    |           |          |         | extended |              | 
+Partition key: RANGE (cid)
+Policies:
+    POLICY "pp1"
+      USING ((dlevel <= ( SELECT uaccount.seclv
+   FROM uaccount
+  WHERE (uaccount.pguser = CURRENT_USER))))
+    POLICY "pp1r" AS RESTRICTIVE
+      TO regress_rls_dave
+      USING ((cid < 55))
+Partitions: part_document_fiction FOR VALUES FROM (11) TO (12),
+            part_document_nonfiction FOR VALUES FROM (99) TO (100),
+            part_document_satire FOR VALUES FROM (55) TO (56)
+
+SELECT * FROM pg_policies WHERE schemaname = 'regress_rls_schema' AND tablename like '%part_document%' ORDER BY policyname;
+     schemaname     |   tablename   | policyname | permissive  |       roles        | cmd |                    qual                    | with_check 
+--------------------+---------------+------------+-------------+--------------------+-----+--------------------------------------------+------------
+ regress_rls_schema | part_document | pp1        | PERMISSIVE  | {public}           | ALL | (dlevel <= ( SELECT uaccount.seclv        +| 
+                    |               |            |             |                    |     |    FROM uaccount                          +| 
+                    |               |            |             |                    |     |   WHERE (uaccount.pguser = CURRENT_USER))) | 
+ regress_rls_schema | part_document | pp1r       | RESTRICTIVE | {regress_rls_dave} | ALL | (cid < 55)                                 | 
+(2 rows)
+
+-- viewpoint from regress_rls_bob
+SET SESSION AUTHORIZATION regress_rls_bob;
+SET row_security TO ON;
+SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   4 |  55 |      1 | regress_rls_bob   | my first satire
+   6 |  11 |      1 | regress_rls_carol | great science fiction
+   9 |  11 |      1 | regress_rls_dave  | awesome science fiction
+(4 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great science fiction
+ my first novel
+ my first satire
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Append
+   InitPlan 1 (returns $0)
+     ->  Index Scan using uaccount_pkey on uaccount
+           Index Cond: (pguser = CURRENT_USER)
+   ->  Seq Scan on part_document_fiction
+         Filter: ((dlevel <= $0) AND f_leak(dtitle))
+   ->  Seq Scan on part_document_satire
+         Filter: ((dlevel <= $0) AND f_leak(dtitle))
+   ->  Seq Scan on part_document_nonfiction
+         Filter: ((dlevel <= $0) AND f_leak(dtitle))
+(10 rows)
+
+-- viewpoint from regress_rls_carol
+SET SESSION AUTHORIZATION regress_rls_carol;
+SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   3 |  99 |      2 | regress_rls_bob   | my science textbook
+   4 |  55 |      1 | regress_rls_bob   | my first satire
+   5 |  99 |      2 | regress_rls_bob   | my history book
+   6 |  11 |      1 | regress_rls_carol | great science fiction
+   7 |  99 |      2 | regress_rls_carol | great technology book
+   8 |  55 |      2 | regress_rls_carol | great satire
+   9 |  11 |      1 | regress_rls_dave  | awesome science fiction
+  10 |  99 |      2 | regress_rls_dave  | awesome technology book
+(10 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ awesome technology book
+ great satire
+ great science fiction
+ great technology book
+ my first novel
+ my first satire
+ my history book
+ my science textbook
+ my second novel
+(10 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Append
+   InitPlan 1 (returns $0)
+     ->  Index Scan using uaccount_pkey on uaccount
+           Index Cond: (pguser = CURRENT_USER)
+   ->  Seq Scan on part_document_fiction
+         Filter: ((dlevel <= $0) AND f_leak(dtitle))
+   ->  Seq Scan on part_document_satire
+         Filter: ((dlevel <= $0) AND f_leak(dtitle))
+   ->  Seq Scan on part_document_nonfiction
+         Filter: ((dlevel <= $0) AND f_leak(dtitle))
+(10 rows)
+
+-- viewpoint from regress_rls_dave
+SET SESSION AUTHORIZATION regress_rls_dave;
+SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   6 |  11 |      1 | regress_rls_carol | great science fiction
+   9 |  11 |      1 | regress_rls_dave  | awesome science fiction
+(4 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great science fiction
+ my first novel
+ my second novel
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
+                          QUERY PLAN                          
+--------------------------------------------------------------
+ Seq Scan on part_document_fiction
+   Filter: ((cid < 55) AND (dlevel <= $0) AND f_leak(dtitle))
+   InitPlan 1 (returns $0)
+     ->  Index Scan using uaccount_pkey on uaccount
+           Index Cond: (pguser = CURRENT_USER)
+(5 rows)
+
+-- pp1 ERROR
+INSERT INTO part_document VALUES (100, 11, 5, 'regress_rls_dave', 'testing pp1'); -- fail
+ERROR:  new row violates row-level security policy for table "part_document"
+-- pp1r ERROR
+INSERT INTO part_document VALUES (100, 99, 1, 'regress_rls_dave', 'testing pp1r'); -- fail
+ERROR:  new row violates row-level security policy "pp1r" for table "part_document"
+-- Show that RLS policy does not apply for direct inserts to children
+-- This should fail with RLS POLICY pp1r violation.
+INSERT INTO part_document VALUES (100, 55, 1, 'regress_rls_dave', 'testing RLS with partitions'); -- fail
+ERROR:  new row violates row-level security policy "pp1r" for table "part_document"
+-- But this should succeed.
+INSERT INTO part_document_satire VALUES (100, 55, 1, 'regress_rls_dave', 'testing RLS with partitions'); -- success
+-- We still cannot see the row using the parent
+SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   6 |  11 |      1 | regress_rls_carol | great science fiction
+   9 |  11 |      1 | regress_rls_dave  | awesome science fiction
+(4 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great science fiction
+ my first novel
+ my second novel
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
+-- But we can if we look directly
+SELECT * FROM part_document_satire WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |           dtitle            
+-----+-----+--------+-------------------+-----------------------------
+   4 |  55 |      1 | regress_rls_bob   | my first satire
+   8 |  55 |      2 | regress_rls_carol | great satire
+ 100 |  55 |      1 | regress_rls_dave  | testing RLS with partitions
+(3 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+              a              
+-----------------------------
+ great satire
+ my first satire
+ testing RLS with partitions
+(3 rows)
+
+TRUNCATE TABLE f_leak_table;
+-- Turn on RLS and create policy on child to show RLS is checked before constraints
+SET SESSION AUTHORIZATION regress_rls_alice;
+ALTER TABLE part_document_satire ENABLE ROW LEVEL SECURITY;
+CREATE POLICY pp3 ON part_document_satire AS RESTRICTIVE
+    USING (cid < 55);
+-- This should fail with RLS violation now.
+SET SESSION AUTHORIZATION regress_rls_dave;
+INSERT INTO part_document_satire VALUES (101, 55, 1, 'regress_rls_dave', 'testing RLS with partitions'); -- fail
+ERROR:  new row violates row-level security policy for table "part_document_satire"
+-- And now we cannot see directly into the partition either, due to RLS
+SELECT * FROM part_document_satire WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel | dauthor | dtitle 
+-----+-----+--------+---------+--------
+(0 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE TABLE f_leak_table;
+-- The parent looks same as before
+-- viewpoint from regress_rls_dave
+SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |         dtitle          
+-----+-----+--------+-------------------+-------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   6 |  11 |      1 | regress_rls_carol | great science fiction
+   9 |  11 |      1 | regress_rls_dave  | awesome science fiction
+(4 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+            a            
+-------------------------
+ awesome science fiction
+ great science fiction
+ my first novel
+ my second novel
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
+                          QUERY PLAN                          
+--------------------------------------------------------------
+ Seq Scan on part_document_fiction
+   Filter: ((cid < 55) AND (dlevel <= $0) AND f_leak(dtitle))
+   InitPlan 1 (returns $0)
+     ->  Index Scan using uaccount_pkey on uaccount
+           Index Cond: (pguser = CURRENT_USER)
+(5 rows)
+
+-- viewpoint from regress_rls_carol
+SET SESSION AUTHORIZATION regress_rls_carol;
+SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |           dtitle            
+-----+-----+--------+-------------------+-----------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   3 |  99 |      2 | regress_rls_bob   | my science textbook
+   4 |  55 |      1 | regress_rls_bob   | my first satire
+   5 |  99 |      2 | regress_rls_bob   | my history book
+   6 |  11 |      1 | regress_rls_carol | great science fiction
+   7 |  99 |      2 | regress_rls_carol | great technology book
+   8 |  55 |      2 | regress_rls_carol | great satire
+   9 |  11 |      1 | regress_rls_dave  | awesome science fiction
+  10 |  99 |      2 | regress_rls_dave  | awesome technology book
+ 100 |  55 |      1 | regress_rls_dave  | testing RLS with partitions
+(11 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+              a              
+-----------------------------
+ awesome science fiction
+ awesome technology book
+ great satire
+ great science fiction
+ great technology book
+ my first novel
+ my first satire
+ my history book
+ my science textbook
+ my second novel
+ testing RLS with partitions
+(11 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Append
+   InitPlan 1 (returns $0)
+     ->  Index Scan using uaccount_pkey on uaccount
+           Index Cond: (pguser = CURRENT_USER)
+   ->  Seq Scan on part_document_fiction
+         Filter: ((dlevel <= $0) AND f_leak(dtitle))
+   ->  Seq Scan on part_document_satire
+         Filter: ((dlevel <= $0) AND f_leak(dtitle))
+   ->  Seq Scan on part_document_nonfiction
+         Filter: ((dlevel <= $0) AND f_leak(dtitle))
+(10 rows)
+
+-- only owner can change policies
+ALTER POLICY pp1 ON part_document USING (true);    --fail
+ERROR:  must be owner of table part_document
+DROP POLICY pp1 ON part_document;                  --fail
+ERROR:  must be owner of relation part_document
+SET SESSION AUTHORIZATION regress_rls_alice;
+ALTER POLICY pp1 ON part_document USING (dauthor = current_user);
+-- viewpoint from regress_rls_bob again
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |     dauthor     |       dtitle        
+-----+-----+--------+-----------------+---------------------
+   1 |  11 |      1 | regress_rls_bob | my first novel
+   2 |  11 |      2 | regress_rls_bob | my second novel
+   3 |  99 |      2 | regress_rls_bob | my science textbook
+   4 |  55 |      1 | regress_rls_bob | my first satire
+   5 |  99 |      2 | regress_rls_bob | my history book
+(5 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+          a          
+---------------------
+ my first novel
+ my first satire
+ my history book
+ my science textbook
+ my second novel
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
+-- viewpoint from rls_regres_carol again
+SET SESSION AUTHORIZATION regress_rls_carol;
+SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+ did | cid | dlevel |      dauthor      |        dtitle         
+-----+-----+--------+-------------------+-----------------------
+   6 |  11 |      1 | regress_rls_carol | great science fiction
+   7 |  99 |      2 | regress_rls_carol | great technology book
+   8 |  55 |      2 | regress_rls_carol | great satire
+(3 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+           a           
+-----------------------
+ great satire
+ great science fiction
+ great technology book
+(3 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
+                          QUERY PLAN                           
+---------------------------------------------------------------
+ Append
+   ->  Seq Scan on part_document_fiction
+         Filter: ((dauthor = CURRENT_USER) AND f_leak(dtitle))
+   ->  Seq Scan on part_document_satire
+         Filter: ((dauthor = CURRENT_USER) AND f_leak(dtitle))
+   ->  Seq Scan on part_document_nonfiction
+         Filter: ((dauthor = CURRENT_USER) AND f_leak(dtitle))
+(7 rows)
+
+-- database superuser does bypass RLS policy when enabled
+RESET SESSION AUTHORIZATION;
+SET row_security TO ON;
+SELECT * FROM part_document ORDER BY did;
+ did | cid | dlevel |      dauthor      |           dtitle            
+-----+-----+--------+-------------------+-----------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   3 |  99 |      2 | regress_rls_bob   | my science textbook
+   4 |  55 |      1 | regress_rls_bob   | my first satire
+   5 |  99 |      2 | regress_rls_bob   | my history book
+   6 |  11 |      1 | regress_rls_carol | great science fiction
+   7 |  99 |      2 | regress_rls_carol | great technology book
+   8 |  55 |      2 | regress_rls_carol | great satire
+   9 |  11 |      1 | regress_rls_dave  | awesome science fiction
+  10 |  99 |      2 | regress_rls_dave  | awesome technology book
+ 100 |  55 |      1 | regress_rls_dave  | testing RLS with partitions
+(11 rows)
+
+SELECT * FROM part_document_satire ORDER by did;
+ did | cid | dlevel |      dauthor      |           dtitle            
+-----+-----+--------+-------------------+-----------------------------
+   4 |  55 |      1 | regress_rls_bob   | my first satire
+   8 |  55 |      2 | regress_rls_carol | great satire
+ 100 |  55 |      1 | regress_rls_dave  | testing RLS with partitions
+(3 rows)
+
+-- database non-superuser with bypass privilege can bypass RLS policy when disabled
+SET SESSION AUTHORIZATION regress_rls_exempt_user;
+SET row_security TO OFF;
+SELECT * FROM part_document ORDER BY did;
+ did | cid | dlevel |      dauthor      |           dtitle            
+-----+-----+--------+-------------------+-----------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   3 |  99 |      2 | regress_rls_bob   | my science textbook
+   4 |  55 |      1 | regress_rls_bob   | my first satire
+   5 |  99 |      2 | regress_rls_bob   | my history book
+   6 |  11 |      1 | regress_rls_carol | great science fiction
+   7 |  99 |      2 | regress_rls_carol | great technology book
+   8 |  55 |      2 | regress_rls_carol | great satire
+   9 |  11 |      1 | regress_rls_dave  | awesome science fiction
+  10 |  99 |      2 | regress_rls_dave  | awesome technology book
+ 100 |  55 |      1 | regress_rls_dave  | testing RLS with partitions
+(11 rows)
+
+SELECT * FROM part_document_satire ORDER by did;
+ did | cid | dlevel |      dauthor      |           dtitle            
+-----+-----+--------+-------------------+-----------------------------
+   4 |  55 |      1 | regress_rls_bob   | my first satire
+   8 |  55 |      2 | regress_rls_carol | great satire
+ 100 |  55 |      1 | regress_rls_dave  | testing RLS with partitions
+(3 rows)
+
+-- RLS policy does not apply to table owner when RLS enabled.
+SET SESSION AUTHORIZATION regress_rls_alice;
+SET row_security TO ON;
+SELECT * FROM part_document ORDER by did;
+ did | cid | dlevel |      dauthor      |           dtitle            
+-----+-----+--------+-------------------+-----------------------------
+   1 |  11 |      1 | regress_rls_bob   | my first novel
+   2 |  11 |      2 | regress_rls_bob   | my second novel
+   3 |  99 |      2 | regress_rls_bob   | my science textbook
+   4 |  55 |      1 | regress_rls_bob   | my first satire
+   5 |  99 |      2 | regress_rls_bob   | my history book
+   6 |  11 |      1 | regress_rls_carol | great science fiction
+   7 |  99 |      2 | regress_rls_carol | great technology book
+   8 |  55 |      2 | regress_rls_carol | great satire
+   9 |  11 |      1 | regress_rls_dave  | awesome science fiction
+  10 |  99 |      2 | regress_rls_dave  | awesome technology book
+ 100 |  55 |      1 | regress_rls_dave  | testing RLS with partitions
+(11 rows)
+
+SELECT * FROM part_document_satire ORDER by did;
+ did | cid | dlevel |      dauthor      |           dtitle            
+-----+-----+--------+-------------------+-----------------------------
+   4 |  55 |      1 | regress_rls_bob   | my first satire
+   8 |  55 |      2 | regress_rls_carol | great satire
+ 100 |  55 |      1 | regress_rls_dave  | testing RLS with partitions
+(3 rows)
+
+-- When RLS disabled, other users get ERROR.
+SET SESSION AUTHORIZATION regress_rls_dave;
+SET row_security TO OFF;
+SELECT * FROM part_document ORDER by did;
+ERROR:  query would be affected by row-level security policy for table "part_document"
+SELECT * FROM part_document_satire ORDER by did;
+ERROR:  query would be affected by row-level security policy for table "part_document_satire"
+-- Check behavior with a policy that uses a SubPlan not an InitPlan.
+SET SESSION AUTHORIZATION regress_rls_alice;
+SET row_security TO ON;
+CREATE POLICY pp3 ON part_document AS RESTRICTIVE
+    USING ((SELECT dlevel <= seclv FROM uaccount WHERE pguser = current_user));
+SET SESSION AUTHORIZATION regress_rls_carol;
+INSERT INTO part_document VALUES (100, 11, 5, 'regress_rls_carol', 'testing pp3'); -- fail
+ERROR:  new row violates row-level security policy "pp3" for table "part_document"
+----- Dependencies -----
+SET SESSION AUTHORIZATION regress_rls_alice;
+SET row_security TO ON;
+CREATE TABLE dependee (x integer, y integer);
+CREATE TABLE dependent (x integer, y integer);
+CREATE POLICY d1 ON dependent FOR ALL
+    TO PUBLIC
+    USING (x = (SELECT d.x FROM dependee d WHERE d.y = y));
+DROP TABLE dependee; -- Should fail without CASCADE due to dependency on row security qual?
+ERROR:  cannot drop table dependee because other objects depend on it
+DETAIL:  policy d1 on table dependent depends on table dependee
+HINT:  Use DROP ... CASCADE to drop the dependent objects too.
+DROP TABLE dependee CASCADE;
+NOTICE:  drop cascades to policy d1 on table dependent
+EXPLAIN (COSTS OFF) SELECT * FROM dependent; -- After drop, should be unqualified
+      QUERY PLAN       
+-----------------------
+ Seq Scan on dependent
+(1 row)
+
+-----   RECURSION    ----
+--
+-- Simple recursion
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE TABLE rec1 (x integer, y integer);
+CREATE POLICY r1 ON rec1 USING (x = (SELECT r.x FROM rec1 r WHERE y = r.y));
+ALTER TABLE rec1 ENABLE ROW LEVEL SECURITY;
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM rec1; -- fail, direct recursion
+ERROR:  infinite recursion detected in policy for relation "rec1"
+--
+-- Mutual recursion
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE TABLE rec2 (a integer, b integer);
+ALTER POLICY r1 ON rec1 USING (x = (SELECT a FROM rec2 WHERE b = y));
+CREATE POLICY r2 ON rec2 USING (a = (SELECT x FROM rec1 WHERE y = b));
+ALTER TABLE rec2 ENABLE ROW LEVEL SECURITY;
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM rec1;    -- fail, mutual recursion
+ERROR:  infinite recursion detected in policy for relation "rec1"
+--
+-- Mutual recursion via views
+--
+SET SESSION AUTHORIZATION regress_rls_bob;
+CREATE VIEW rec1v AS SELECT * FROM rec1;
+CREATE VIEW rec2v AS SELECT * FROM rec2;
+SET SESSION AUTHORIZATION regress_rls_alice;
+ALTER POLICY r1 ON rec1 USING (x = (SELECT a FROM rec2v WHERE b = y));
+ALTER POLICY r2 ON rec2 USING (a = (SELECT x FROM rec1v WHERE y = b));
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM rec1;    -- fail, mutual recursion via views
+ERROR:  infinite recursion detected in policy for relation "rec1"
+--
+-- Mutual recursion via .s.b views
+--
+SET SESSION AUTHORIZATION regress_rls_bob;
+DROP VIEW rec1v, rec2v CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to policy r1 on table rec1
+drop cascades to policy r2 on table rec2
+CREATE VIEW rec1v WITH (security_barrier) AS SELECT * FROM rec1;
+CREATE VIEW rec2v WITH (security_barrier) AS SELECT * FROM rec2;
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE POLICY r1 ON rec1 USING (x = (SELECT a FROM rec2v WHERE b = y));
+CREATE POLICY r2 ON rec2 USING (a = (SELECT x FROM rec1v WHERE y = b));
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM rec1;    -- fail, mutual recursion via s.b. views
+ERROR:  infinite recursion detected in policy for relation "rec1"
+--
+-- recursive RLS and VIEWs in policy
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE TABLE s1 (a int, b text);
+INSERT INTO s1 (SELECT x, md5(x::text) FROM generate_series(-10,10) x);
+CREATE TABLE s2 (x int, y text);
+INSERT INTO s2 (SELECT x, md5(x::text) FROM generate_series(-6,6) x);
+GRANT SELECT ON s1, s2 TO regress_rls_bob;
+CREATE POLICY p1 ON s1 USING (a in (select x from s2 where y like '%2f%'));
+CREATE POLICY p2 ON s2 USING (x in (select a from s1 where b like '%22%'));
+CREATE POLICY p3 ON s1 FOR INSERT WITH CHECK (a = (SELECT a FROM s1));
+ALTER TABLE s1 ENABLE ROW LEVEL SECURITY;
+ALTER TABLE s2 ENABLE ROW LEVEL SECURITY;
+SET SESSION AUTHORIZATION regress_rls_bob;
+CREATE VIEW v2 AS SELECT * FROM s2 WHERE y like '%af%';
+SELECT * FROM s1 WHERE f_leak(b); -- fail (infinite recursion)
+ERROR:  infinite recursion detected in policy for relation "s1"
+SELECT * FROM f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE TABLE f_leak_table;
+INSERT INTO s1 VALUES (1, 'foo'); -- fail (infinite recursion)
+ERROR:  infinite recursion detected in policy for relation "s1"
+SET SESSION AUTHORIZATION regress_rls_alice;
+DROP POLICY p3 on s1;
+ALTER POLICY p2 ON s2 USING (x % 2 = 0);
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM s1 WHERE f_leak(b);	-- OK
+ a |                b                 
+---+----------------------------------
+ 2 | c81e728d9d4c2f636f067f89cc14862c
+ 4 | a87ff679a2f3e71d9181a67b7542122c
+(2 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ a87ff679a2f3e71d9181a67b7542122c
+ c81e728d9d4c2f636f067f89cc14862c
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM only s1 WHERE f_leak(b);
+                        QUERY PLAN                         
+-----------------------------------------------------------
+ Seq Scan on s1
+   Filter: ((hashed SubPlan 1) AND f_leak(b))
+   SubPlan 1
+     ->  Seq Scan on s2
+           Filter: (((x % 2) = 0) AND (y ~~ '%2f%'::text))
+(5 rows)
+
+SET SESSION AUTHORIZATION regress_rls_alice;
+ALTER POLICY p1 ON s1 USING (a in (select x from v2)); -- using VIEW in RLS policy
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM s1 WHERE f_leak(b);	-- OK
+ a  |                b                 
+----+----------------------------------
+ -4 | 0267aaf632e87a63288a08331f22c7c3
+  6 | 1679091c5a880faf6fb5e6087eb1b2dc
+(2 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ 0267aaf632e87a63288a08331f22c7c3
+ 1679091c5a880faf6fb5e6087eb1b2dc
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM s1 WHERE f_leak(b);
+                        QUERY PLAN                         
+-----------------------------------------------------------
+ Seq Scan on s1
+   Filter: ((hashed SubPlan 1) AND f_leak(b))
+   SubPlan 1
+     ->  Seq Scan on s2
+           Filter: (((x % 2) = 0) AND (y ~~ '%af%'::text))
+(5 rows)
+
+SELECT (SELECT x FROM s1 LIMIT 1) xx, * FROM s2 WHERE y like '%28%';
+ xx | x  |                y                 
+----+----+----------------------------------
+ -6 | -6 | 596a3d04481816330f07e4f97510c28f
+ -4 | -4 | 0267aaf632e87a63288a08331f22c7c3
+  2 |  2 | c81e728d9d4c2f636f067f89cc14862c
+(3 rows)
+
+EXPLAIN (COSTS OFF) SELECT (SELECT x FROM s1 LIMIT 1) xx, * FROM s2 WHERE y like '%28%';
+                               QUERY PLAN                                
+-------------------------------------------------------------------------
+ Seq Scan on s2
+   Filter: (((x % 2) = 0) AND (y ~~ '%28%'::text))
+   SubPlan 2
+     ->  Limit
+           ->  Seq Scan on s1
+                 Filter: (hashed SubPlan 1)
+                 SubPlan 1
+                   ->  Seq Scan on s2 s2_1
+                         Filter: (((x % 2) = 0) AND (y ~~ '%af%'::text))
+(9 rows)
+
+SET SESSION AUTHORIZATION regress_rls_alice;
+ALTER POLICY p2 ON s2 USING (x in (select a from s1 where b like '%d2%'));
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM s1 WHERE f_leak(b);	-- fail (infinite recursion via view)
+ERROR:  infinite recursion detected in policy for relation "s1"
+SELECT * FROM f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE TABLE f_leak_table;
+-- prepared statement with regress_rls_alice privilege
+PREPARE p1(int) AS SELECT * FROM t1 WHERE a <= $1;
+EXECUTE p1(2);
+ id  | a |  b  
+-----+---+-----
+ 102 | 2 | bbb
+ 202 | 2 | bcd
+ 302 | 2 | yyy
+(3 rows)
+
+EXPLAIN (COSTS OFF) EXECUTE p1(2);
+                  QUERY PLAN                  
+----------------------------------------------
+ Append
+   ->  Seq Scan on t1
+         Filter: ((a <= 2) AND ((a % 2) = 0))
+   ->  Seq Scan on t2
+         Filter: ((a <= 2) AND ((a % 2) = 0))
+   ->  Seq Scan on t3
+         Filter: ((a <= 2) AND ((a % 2) = 0))
+(7 rows)
+
+-- superuser is allowed to bypass RLS checks
+RESET SESSION AUTHORIZATION;
+SET row_security TO OFF;
+SELECT * FROM t1 WHERE f_leak(b);
+ id  | a |  b  
+-----+---+-----
+ 101 | 1 | aba
+ 102 | 2 | bbb
+ 103 | 3 | ccc
+ 104 | 4 | dad
+ 201 | 1 | abc
+ 202 | 2 | bcd
+ 203 | 3 | cde
+ 204 | 4 | def
+ 301 | 1 | xxx
+ 302 | 2 | yyy
+ 303 | 3 | zzz
+(11 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ abc
+ bbb
+ bcd
+ ccc
+ cde
+ dad
+ def
+ xxx
+ yyy
+ zzz
+(11 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b);
+        QUERY PLAN         
+---------------------------
+ Append
+   ->  Seq Scan on t1
+         Filter: f_leak(b)
+   ->  Seq Scan on t2
+         Filter: f_leak(b)
+   ->  Seq Scan on t3
+         Filter: f_leak(b)
+(7 rows)
+
+-- plan cache should be invalidated
+EXECUTE p1(2);
+ id  | a |  b  
+-----+---+-----
+ 101 | 1 | aba
+ 102 | 2 | bbb
+ 201 | 1 | abc
+ 202 | 2 | bcd
+ 301 | 1 | xxx
+ 302 | 2 | yyy
+(6 rows)
+
+EXPLAIN (COSTS OFF) EXECUTE p1(2);
+        QUERY PLAN        
+--------------------------
+ Append
+   ->  Seq Scan on t1
+         Filter: (a <= 2)
+   ->  Seq Scan on t2
+         Filter: (a <= 2)
+   ->  Seq Scan on t3
+         Filter: (a <= 2)
+(7 rows)
+
+PREPARE p2(int) AS SELECT * FROM t1 WHERE a = $1;
+EXECUTE p2(2);
+ id  | a |  b  
+-----+---+-----
+ 102 | 2 | bbb
+ 202 | 2 | bcd
+ 302 | 2 | yyy
+(3 rows)
+
+EXPLAIN (COSTS OFF) EXECUTE p2(2);
+       QUERY PLAN        
+-------------------------
+ Append
+   ->  Seq Scan on t1
+         Filter: (a = 2)
+   ->  Seq Scan on t2
+         Filter: (a = 2)
+   ->  Seq Scan on t3
+         Filter: (a = 2)
+(7 rows)
+
+-- also, case when privilege switch from superuser
+SET SESSION AUTHORIZATION regress_rls_bob;
+SET row_security TO ON;
+EXECUTE p2(2);
+ id  | a |  b  
+-----+---+-----
+ 102 | 2 | bbb
+ 202 | 2 | bcd
+ 302 | 2 | yyy
+(3 rows)
+
+EXPLAIN (COSTS OFF) EXECUTE p2(2);
+                 QUERY PLAN                  
+---------------------------------------------
+ Append
+   ->  Seq Scan on t1
+         Filter: ((a = 2) AND ((a % 2) = 0))
+   ->  Seq Scan on t2
+         Filter: ((a = 2) AND ((a % 2) = 0))
+   ->  Seq Scan on t3
+         Filter: ((a = 2) AND ((a % 2) = 0))
+(7 rows)
+
+--
+-- UPDATE / DELETE and Row-level security
+--
+SET SESSION AUTHORIZATION regress_rls_bob;
+EXPLAIN (COSTS OFF) UPDATE t1 SET b = b || b WHERE f_leak(b);
+                  QUERY PLAN                   
+-----------------------------------------------
+ Update on t1
+   Update on t1
+   Update on t2
+   Update on t3
+   ->  Seq Scan on t1
+         Filter: (((a % 2) = 0) AND f_leak(b))
+   ->  Seq Scan on t2
+         Filter: (((a % 2) = 0) AND f_leak(b))
+   ->  Seq Scan on t3
+         Filter: (((a % 2) = 0) AND f_leak(b))
+(10 rows)
+
+UPDATE t1 SET b = b || b WHERE f_leak(b);
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ bcd
+ dad
+ def
+ yyy
+(5 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) UPDATE only t1 SET b = b || '_updt' WHERE f_leak(b);
+                  QUERY PLAN                   
+-----------------------------------------------
+ Update on t1
+   ->  Seq Scan on t1
+         Filter: (((a % 2) = 0) AND f_leak(b))
+(3 rows)
+
+UPDATE only t1 SET b = b || '_updt' WHERE f_leak(b);
+SELECT * FROM f_leak_table ORDER BY a;
+   a    
+--------
+ bbbbbb
+ daddad
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
+-- returning clause with system column
+WITH UPDATED AS (UPDATE only t1 SET b = b WHERE f_leak(b)
+RETURNING tableoid::regclass, *, t1) SELECT * FROM UPDATED ORDER BY (a,b);
+ tableoid | id  | a |      b      |         t1          
+----------+-----+---+-------------+---------------------
+ t1       | 102 | 2 | bbbbbb_updt | (102,2,bbbbbb_updt)
+ t1       | 104 | 4 | daddad_updt | (104,4,daddad_updt)
+(2 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+      a      
+-------------
+ bbbbbb_updt
+ daddad_updt
+(2 rows)
+
+TRUNCATE table f_leak_table;
+WITH UPDATED AS (UPDATE t1 SET b = b WHERE f_leak(b)
+RETURNING *) SELECT * FROM UPDATED ORDER BY (a,b);
+ id  | a |      b      
+-----+---+-------------
+ 102 | 2 | bbbbbb_updt
+ 202 | 2 | bcdbcd
+ 302 | 2 | yyyyyy
+ 104 | 4 | daddad_updt
+ 204 | 4 | defdef
+(5 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+      a      
+-------------
+ bbbbbb_updt
+ bcdbcd
+ daddad_updt
+ defdef
+ yyyyyy
+(5 rows)
+
+TRUNCATE table f_leak_table;
+WITH UPDATED AS (UPDATE t1 SET b = b WHERE f_leak(b)
+RETURNING tableoid::regclass, *, t1) SELECT * FROM UPDATED ORDER BY (a,b);
+ tableoid | id  | a |      b      |         t1          
+----------+-----+---+-------------+---------------------
+ t1       | 102 | 2 | bbbbbb_updt | (102,2,bbbbbb_updt)
+ t2       | 202 | 2 | bcdbcd      | (202,2,bcdbcd)
+ t3       | 302 | 2 | yyyyyy      | (302,2,yyyyyy)
+ t1       | 104 | 4 | daddad_updt | (104,4,daddad_updt)
+ t2       | 204 | 4 | defdef      | (204,4,defdef)
+(5 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+      a      
+-------------
+ bbbbbb_updt
+ bcdbcd
+ daddad_updt
+ defdef
+ yyyyyy
+(5 rows)
+
+TRUNCATE table f_leak_table;
+-- updates with from clause
+EXPLAIN (COSTS OFF) UPDATE t2 SET b=t2.b FROM t3
+WHERE t2.a = 3 and t3.a = 2 AND f_leak(t2.b) AND f_leak(t3.b);
+                           QUERY PLAN                            
+-----------------------------------------------------------------
+ Update on t2
+   ->  Nested Loop
+         ->  Seq Scan on t2
+               Filter: ((a = 3) AND ((a % 2) = 1) AND f_leak(b))
+         ->  Seq Scan on t3
+               Filter: ((a = 2) AND f_leak(b))
+(6 rows)
+
+UPDATE t2 SET b=t2.b FROM t3
+WHERE t2.a = 3 and t3.a = 2 AND f_leak(t2.b) AND f_leak(t3.b);
+SELECT * from f_leak_table ORDER BY a;
+   a    
+--------
+ cde
+ yyyyyy
+(2 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) UPDATE t1 SET b=t1.b FROM t2
+WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
+                           QUERY PLAN                            
+-----------------------------------------------------------------
+ Update on t1
+   Update on t1
+   Update on t2 t2_1
+   Update on t3
+   ->  Nested Loop
+         ->  Seq Scan on t1
+               Filter: ((a = 3) AND ((a % 2) = 0) AND f_leak(b))
+         ->  Seq Scan on t2
+               Filter: ((a = 3) AND ((a % 2) = 1) AND f_leak(b))
+   ->  Nested Loop
+         ->  Seq Scan on t2 t2_1
+               Filter: ((a = 3) AND ((a % 2) = 0) AND f_leak(b))
+         ->  Seq Scan on t2
+               Filter: ((a = 3) AND ((a % 2) = 1) AND f_leak(b))
+   ->  Nested Loop
+         ->  Seq Scan on t3
+               Filter: ((a = 3) AND ((a % 2) = 0) AND f_leak(b))
+         ->  Seq Scan on t2
+               Filter: ((a = 3) AND ((a % 2) = 1) AND f_leak(b))
+(19 rows)
+
+UPDATE t1 SET b=t1.b FROM t2
+WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
+SELECT * from f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) UPDATE t2 SET b=t2.b FROM t1
+WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
+                              QUERY PLAN                               
+-----------------------------------------------------------------------
+ Update on t2
+   ->  Nested Loop
+         ->  Seq Scan on t2
+               Filter: ((a = 3) AND ((a % 2) = 1) AND f_leak(b))
+         ->  Append
+               ->  Seq Scan on t1
+                     Filter: ((a = 3) AND ((a % 2) = 0) AND f_leak(b))
+               ->  Seq Scan on t2 t2_1
+                     Filter: ((a = 3) AND ((a % 2) = 0) AND f_leak(b))
+               ->  Seq Scan on t3
+                     Filter: ((a = 3) AND ((a % 2) = 0) AND f_leak(b))
+(11 rows)
+
+UPDATE t2 SET b=t2.b FROM t1
+WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ cde
+(1 row)
+
+TRUNCATE table f_leak_table;
+-- updates with from clause self join
+EXPLAIN (COSTS OFF) UPDATE t2 t2_1 SET b = t2_2.b FROM t2 t2_2
+WHERE t2_1.a = 3 AND t2_2.a = t2_1.a AND t2_2.b = t2_1.b
+AND f_leak(t2_1.b) AND f_leak(t2_2.b) RETURNING *, t2_1, t2_2;
+                           QUERY PLAN                            
+-----------------------------------------------------------------
+ Update on t2 t2_1
+   ->  Nested Loop
+         Join Filter: (t2_1.b = t2_2.b)
+         ->  Seq Scan on t2 t2_1
+               Filter: ((a = 3) AND ((a % 2) = 1) AND f_leak(b))
+         ->  Seq Scan on t2 t2_2
+               Filter: ((a = 3) AND ((a % 2) = 1) AND f_leak(b))
+(7 rows)
+
+WITH UPDATED AS (UPDATE t2 t2_1 SET b = t2_2.b FROM t2 t2_2
+WHERE t2_1.a = 3 AND t2_2.a = t2_1.a AND t2_2.b = t2_1.b
+AND f_leak(t2_1.b) AND f_leak(t2_2.b) RETURNING *, t2_1.a d, t2_2.b e) SELECT * FROM UPDATED ORDER BY (d,e);
+ id  | a |  b  |  c  | id  | a |  b  |  c  | d |  e  
+-----+---+-----+-----+-----+---+-----+-----+---+-----
+ 203 | 3 | cde | 3.3 | 203 | 3 | cde | 3.3 | 3 | cde
+(1 row)
+
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ cde
+ cde
+(2 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) UPDATE t1 t1_1 SET b = t1_2.b FROM t1 t1_2
+WHERE t1_1.a = 4 AND t1_2.a = t1_1.a AND t1_2.b = t1_1.b
+AND f_leak(t1_1.b) AND f_leak(t1_2.b) RETURNING *, t1_1, t1_2;
+                              QUERY PLAN                               
+-----------------------------------------------------------------------
+ Update on t1 t1_1
+   Update on t1 t1_1
+   Update on t2 t1_1_1
+   Update on t3 t1_1_2
+   ->  Nested Loop
+         Join Filter: (t1_1.b = t1_2.b)
+         ->  Seq Scan on t1 t1_1
+               Filter: ((a = 4) AND ((a % 2) = 0) AND f_leak(b))
+         ->  Append
+               ->  Seq Scan on t1 t1_2
+                     Filter: ((a = 4) AND ((a % 2) = 0) AND f_leak(b))
+               ->  Seq Scan on t2 t1_2_1
+                     Filter: ((a = 4) AND ((a % 2) = 0) AND f_leak(b))
+               ->  Seq Scan on t3 t1_2_2
+                     Filter: ((a = 4) AND ((a % 2) = 0) AND f_leak(b))
+   ->  Nested Loop
+         Join Filter: (t1_1_1.b = t1_2.b)
+         ->  Seq Scan on t2 t1_1_1
+               Filter: ((a = 4) AND ((a % 2) = 0) AND f_leak(b))
+         ->  Append
+               ->  Seq Scan on t1 t1_2
+                     Filter: ((a = 4) AND ((a % 2) = 0) AND f_leak(b))
+               ->  Seq Scan on t2 t1_2_1
+                     Filter: ((a = 4) AND ((a % 2) = 0) AND f_leak(b))
+               ->  Seq Scan on t3 t1_2_2
+                     Filter: ((a = 4) AND ((a % 2) = 0) AND f_leak(b))
+   ->  Nested Loop
+         Join Filter: (t1_1_2.b = t1_2.b)
+         ->  Seq Scan on t3 t1_1_2
+               Filter: ((a = 4) AND ((a % 2) = 0) AND f_leak(b))
+         ->  Append
+               ->  Seq Scan on t1 t1_2
+                     Filter: ((a = 4) AND ((a % 2) = 0) AND f_leak(b))
+               ->  Seq Scan on t2 t1_2_1
+                     Filter: ((a = 4) AND ((a % 2) = 0) AND f_leak(b))
+               ->  Seq Scan on t3 t1_2_2
+                     Filter: ((a = 4) AND ((a % 2) = 0) AND f_leak(b))
+(37 rows)
+
+WITH UPDATED AS (UPDATE t1 t1_1 SET b = t1_2.b FROM t1 t1_2
+WHERE t1_1.a = 4 AND t1_2.a = t1_1.a AND t1_2.b = t1_1.b
+AND f_leak(t1_1.b) AND f_leak(t1_2.b) RETURNING *, t1_1.a d, t1_2.b e) SELECT * FROM UPDATED ORDER BY (d,e);
+ id  | a |      b      | id  | a |      b      | d |      e      
+-----+---+-------------+-----+---+-------------+---+-------------
+ 104 | 4 | daddad_updt | 104 | 4 | daddad_updt | 4 | daddad_updt
+ 204 | 4 | defdef      | 204 | 4 | defdef      | 4 | defdef
+(2 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+      a      
+-------------
+ daddad_updt
+ daddad_updt
+ daddad_updt
+ defdef
+ defdef
+ defdef
+(6 rows)
+
+TRUNCATE table f_leak_table;
+RESET SESSION AUTHORIZATION;
+SET row_security TO OFF;
+SELECT * FROM t1 ORDER BY a,b;
+ id  | a |      b      
+-----+---+-------------
+ 101 | 1 | aba
+ 201 | 1 | abc
+ 301 | 1 | xxx
+ 102 | 2 | bbbbbb_updt
+ 202 | 2 | bcdbcd
+ 302 | 2 | yyyyyy
+ 103 | 3 | ccc
+ 203 | 3 | cde
+ 303 | 3 | zzz
+ 104 | 4 | daddad_updt
+ 204 | 4 | defdef
+(11 rows)
+
+SET SESSION AUTHORIZATION regress_rls_bob;
+SET row_security TO ON;
+EXPLAIN (COSTS OFF) DELETE FROM only t1 WHERE f_leak(b);
+                  QUERY PLAN                   
+-----------------------------------------------
+ Delete on t1
+   ->  Seq Scan on t1
+         Filter: (((a % 2) = 0) AND f_leak(b))
+(3 rows)
+
+EXPLAIN (COSTS OFF) DELETE FROM t1 WHERE f_leak(b);
+                  QUERY PLAN                   
+-----------------------------------------------
+ Delete on t1
+   Delete on t1
+   Delete on t2
+   Delete on t3
+   ->  Seq Scan on t1
+         Filter: (((a % 2) = 0) AND f_leak(b))
+   ->  Seq Scan on t2
+         Filter: (((a % 2) = 0) AND f_leak(b))
+   ->  Seq Scan on t3
+         Filter: (((a % 2) = 0) AND f_leak(b))
+(10 rows)
+
+WITH CTE1 AS (DELETE FROM only t1 WHERE f_leak(b) RETURNING tableoid::regclass, *, t1) SELECT * FROM CTE1 ORDER BY (a,b);
+ tableoid | id  | a |      b      |         t1          
+----------+-----+---+-------------+---------------------
+ t1       | 102 | 2 | bbbbbb_updt | (102,2,bbbbbb_updt)
+ t1       | 104 | 4 | daddad_updt | (104,4,daddad_updt)
+(2 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+      a      
+-------------
+ bbbbbb_updt
+ daddad_updt
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
+WITH CTE1 AS (DELETE FROM t1 WHERE f_leak(b) RETURNING tableoid::regclass, *, t1) SELECT * FROM CTE1 ORDER BY (a,b);
+ tableoid | id  | a |   b    |       t1       
+----------+-----+---+--------+----------------
+ t2       | 202 | 2 | bcdbcd | (202,2,bcdbcd)
+ t3       | 302 | 2 | yyyyyy | (302,2,yyyyyy)
+ t2       | 204 | 4 | defdef | (204,4,defdef)
+(3 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+   a    
+--------
+ bcdbcd
+ defdef
+ yyyyyy
+(3 rows)
+
+TRUNCATE TABLE f_leak_table;
+--
+-- S.b. view on top of Row-level security
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE TABLE b1 (a int, b text);
+INSERT INTO b1 (SELECT x, md5(x::text) FROM generate_series(-10,10) x);
+CREATE POLICY p1 ON b1 USING (a % 2 = 0);
+ALTER TABLE b1 ENABLE ROW LEVEL SECURITY;
+GRANT ALL ON b1 TO regress_rls_bob;
+SET SESSION AUTHORIZATION regress_rls_bob;
+CREATE VIEW bv1 WITH (security_barrier) AS SELECT * FROM b1 WHERE a > 0 WITH CHECK OPTION;
+GRANT ALL ON bv1 TO regress_rls_carol;
+SET SESSION AUTHORIZATION regress_rls_carol;
+EXPLAIN (COSTS OFF) SELECT * FROM bv1 WHERE f_leak(b);
+                 QUERY PLAN                  
+---------------------------------------------
+ Subquery Scan on bv1
+   Filter: f_leak(bv1.b)
+   ->  Seq Scan on b1
+         Filter: ((a > 0) AND ((a % 2) = 0))
+(4 rows)
+
+SELECT * FROM bv1 WHERE f_leak(b);
+ a  |                b                 
+----+----------------------------------
+  2 | c81e728d9d4c2f636f067f89cc14862c
+  4 | a87ff679a2f3e71d9181a67b7542122c
+  6 | 1679091c5a880faf6fb5e6087eb1b2dc
+  8 | c9f0f895fb98ab9159f51fd0297e236d
+ 10 | d3d9446802a44259755d38e6d163e820
+(5 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ 1679091c5a880faf6fb5e6087eb1b2dc
+ a87ff679a2f3e71d9181a67b7542122c
+ c81e728d9d4c2f636f067f89cc14862c
+ c9f0f895fb98ab9159f51fd0297e236d
+ d3d9446802a44259755d38e6d163e820
+(5 rows)
+
+TRUNCATE table f_leak_table;
+INSERT INTO bv1 VALUES (-1, 'xxx'); -- should fail view WCO
+ERROR:  new row violates row-level security policy for table "b1"
+INSERT INTO bv1 VALUES (11, 'xxx'); -- should fail RLS check
+ERROR:  new row violates row-level security policy for table "b1"
+INSERT INTO bv1 VALUES (12, 'xxx'); -- ok
+EXPLAIN (COSTS OFF) UPDATE bv1 SET b = 'yyy' WHERE a = 4 AND f_leak(b);
+                              QUERY PLAN                               
+-----------------------------------------------------------------------
+ Update on b1
+   ->  Seq Scan on b1
+         Filter: ((a > 0) AND (a = 4) AND ((a % 2) = 0) AND f_leak(b))
+(3 rows)
+
+UPDATE bv1 SET b = 'yyy' WHERE a = 4 AND f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ a87ff679a2f3e71d9181a67b7542122c
+(1 row)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) DELETE FROM bv1 WHERE a = 6 AND f_leak(b);
+                              QUERY PLAN                               
+-----------------------------------------------------------------------
+ Delete on b1
+   ->  Seq Scan on b1
+         Filter: ((a > 0) AND (a = 6) AND ((a % 2) = 0) AND f_leak(b))
+(3 rows)
+
+DELETE FROM bv1 WHERE a = 6 AND f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ 1679091c5a880faf6fb5e6087eb1b2dc
+(1 row)
+
+TRUNCATE table f_leak_table;
+SET SESSION AUTHORIZATION regress_rls_alice;
+SELECT * FROM b1 ORDER BY a;
+  a  |                b                 
+-----+----------------------------------
+ -10 | 1b0fd9efa5279c4203b7c70233f86dbf
+  -9 | 252e691406782824eec43d7eadc3d256
+  -8 | a8d2ec85eaf98407310b72eb73dda247
+  -7 | 74687a12d3915d3c4d83f1af7b3683d5
+  -6 | 596a3d04481816330f07e4f97510c28f
+  -5 | 47c1b025fa18ea96c33fbb6718688c0f
+  -4 | 0267aaf632e87a63288a08331f22c7c3
+  -3 | b3149ecea4628efd23d2f86e5a723472
+  -2 | 5d7b9adcbe1c629ec722529dd12e5129
+  -1 | 6bb61e3b7bce0931da574d19d1d82c88
+   0 | cfcd208495d565ef66e7dff9f98764da
+   1 | c4ca4238a0b923820dcc509a6f75849b
+   2 | c81e728d9d4c2f636f067f89cc14862c
+   3 | eccbc87e4b5ce2fe28308fd9f2a7baf3
+   4 | yyy
+   5 | e4da3b7fbbce2345d7772b0674a318d5
+   7 | 8f14e45fceea167a5a36dedd4bea2543
+   8 | c9f0f895fb98ab9159f51fd0297e236d
+   9 | 45c48cce2e2d7fbdea1afc51c7c6ad26
+  10 | d3d9446802a44259755d38e6d163e820
+  12 | xxx
+(21 rows)
+
+--
+-- INSERT ... ON CONFLICT DO UPDATE and Row-level security
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+DROP POLICY p1 ON document;
+DROP POLICY p1r ON document;
+CREATE POLICY p1 ON document FOR SELECT USING (true);
+CREATE POLICY p2 ON document FOR INSERT WITH CHECK (dauthor = current_user);
+CREATE POLICY p3 ON document FOR UPDATE
+  USING (cid = (SELECT cid from category WHERE cname = 'novel'))
+  WITH CHECK (dauthor = current_user);
+SET SESSION AUTHORIZATION regress_rls_bob;
+-- Exists...
+SELECT * FROM document WHERE did = 2;
+ did | cid | dlevel |     dauthor     |     dtitle      
+-----+-----+--------+-----------------+-----------------
+   2 |  11 |      2 | regress_rls_bob | my second novel
+(1 row)
+
+-- ...so violates actual WITH CHECK OPTION within UPDATE (not INSERT, since
+-- alternative UPDATE path happens to be taken):
+INSERT INTO document VALUES (2, (SELECT cid from category WHERE cname = 'novel'), 1, 'regress_rls_carol', 'my first novel')
+    ON CONFLICT (did) DO UPDATE SET dtitle = EXCLUDED.dtitle, dauthor = EXCLUDED.dauthor;
+ERROR:  new row violates row-level security policy for table "document"
+-- Violates USING qual for UPDATE policy p3.
+--
+-- UPDATE path is taken, but UPDATE fails purely because *existing* row to be
+-- updated is not a "novel"/cid 11 (row is not leaked, even though we have
+-- SELECT privileges sufficient to see the row in this instance):
+INSERT INTO document VALUES (33, 22, 1, 'regress_rls_bob', 'okay science fiction'); -- preparation for next statement
+INSERT INTO document VALUES (33, (SELECT cid from category WHERE cname = 'novel'), 1, 'regress_rls_bob', 'Some novel, replaces sci-fi') -- takes UPDATE path
+    ON CONFLICT (did) DO UPDATE SET dtitle = EXCLUDED.dtitle;
+ERROR:  new row violates row-level security policy (USING expression) for table "document"
+-- Fine (we UPDATE, since INSERT WCOs and UPDATE security barrier quals + WCOs
+-- not violated):
+INSERT INTO document VALUES (2, (SELECT cid from category WHERE cname = 'novel'), 1, 'regress_rls_bob', 'my first novel')
+    ON CONFLICT (did) DO UPDATE SET dtitle = EXCLUDED.dtitle RETURNING *;
+ did | cid | dlevel |     dauthor     |     dtitle     
+-----+-----+--------+-----------------+----------------
+   2 |  11 |      2 | regress_rls_bob | my first novel
+(1 row)
+
+-- Fine (we INSERT, so "cid = 33" ("technology") isn't evaluated):
+INSERT INTO document VALUES (78, (SELECT cid from category WHERE cname = 'novel'), 1, 'regress_rls_bob', 'some technology novel')
+    ON CONFLICT (did) DO UPDATE SET dtitle = EXCLUDED.dtitle, cid = 33 RETURNING *;
+ did | cid | dlevel |     dauthor     |        dtitle         
+-----+-----+--------+-----------------+-----------------------
+  78 |  11 |      1 | regress_rls_bob | some technology novel
+(1 row)
+
+-- Fine (same query, but we UPDATE, so "cid = 33", ("technology") is not the
+-- case in respect of *existing* tuple):
+INSERT INTO document VALUES (78, (SELECT cid from category WHERE cname = 'novel'), 1, 'regress_rls_bob', 'some technology novel')
+    ON CONFLICT (did) DO UPDATE SET dtitle = EXCLUDED.dtitle, cid = 33 RETURNING *;
+ did | cid | dlevel |     dauthor     |        dtitle         
+-----+-----+--------+-----------------+-----------------------
+  78 |  33 |      1 | regress_rls_bob | some technology novel
+(1 row)
+
+-- Same query a third time, but now fails due to existing tuple finally not
+-- passing quals:
+INSERT INTO document VALUES (78, (SELECT cid from category WHERE cname = 'novel'), 1, 'regress_rls_bob', 'some technology novel')
+    ON CONFLICT (did) DO UPDATE SET dtitle = EXCLUDED.dtitle, cid = 33 RETURNING *;
+ERROR:  new row violates row-level security policy (USING expression) for table "document"
+-- Don't fail just because INSERT doesn't satisfy WITH CHECK option that
+-- originated as a barrier/USING() qual from the UPDATE.  Note that the UPDATE
+-- path *isn't* taken, and so UPDATE-related policy does not apply:
+INSERT INTO document VALUES (79, (SELECT cid from category WHERE cname = 'technology'), 1, 'regress_rls_bob', 'technology book, can only insert')
+    ON CONFLICT (did) DO UPDATE SET dtitle = EXCLUDED.dtitle RETURNING *;
+ did | cid | dlevel |     dauthor     |              dtitle              
+-----+-----+--------+-----------------+----------------------------------
+  79 |  33 |      1 | regress_rls_bob | technology book, can only insert
+(1 row)
+
+-- But this time, the same statement fails, because the UPDATE path is taken,
+-- and updating the row just inserted falls afoul of security barrier qual
+-- (enforced as WCO) -- what we might have updated target tuple to is
+-- irrelevant, in fact.
+INSERT INTO document VALUES (79, (SELECT cid from category WHERE cname = 'technology'), 1, 'regress_rls_bob', 'technology book, can only insert')
+    ON CONFLICT (did) DO UPDATE SET dtitle = EXCLUDED.dtitle RETURNING *;
+ERROR:  new row violates row-level security policy (USING expression) for table "document"
+-- Test default USING qual enforced as WCO
+SET SESSION AUTHORIZATION regress_rls_alice;
+DROP POLICY p1 ON document;
+DROP POLICY p2 ON document;
+DROP POLICY p3 ON document;
+CREATE POLICY p3_with_default ON document FOR UPDATE
+  USING (cid = (SELECT cid from category WHERE cname = 'novel'));
+SET SESSION AUTHORIZATION regress_rls_bob;
+-- Just because WCO-style enforcement of USING quals occurs with
+-- existing/target tuple does not mean that the implementation can be allowed
+-- to fail to also enforce this qual against the final tuple appended to
+-- relation (since in the absence of an explicit WCO, this is also interpreted
+-- as an UPDATE/ALL WCO in general).
+--
+-- UPDATE path is taken here (fails due to existing tuple).  Note that this is
+-- not reported as a "USING expression", because it's an RLS UPDATE check that originated as
+-- a USING qual for the purposes of RLS in general, as opposed to an explicit
+-- USING qual that is ordinarily a security barrier.  We leave it up to the
+-- UPDATE to make this fail:
+INSERT INTO document VALUES (79, (SELECT cid from category WHERE cname = 'technology'), 1, 'regress_rls_bob', 'technology book, can only insert')
+    ON CONFLICT (did) DO UPDATE SET dtitle = EXCLUDED.dtitle RETURNING *;
+ERROR:  new row violates row-level security policy for table "document"
+-- UPDATE path is taken here.  Existing tuple passes, since its cid
+-- corresponds to "novel", but default USING qual is enforced against
+-- post-UPDATE tuple too (as always when updating with a policy that lacks an
+-- explicit WCO), and so this fails:
+INSERT INTO document VALUES (2, (SELECT cid from category WHERE cname = 'technology'), 1, 'regress_rls_bob', 'my first novel')
+    ON CONFLICT (did) DO UPDATE SET cid = EXCLUDED.cid, dtitle = EXCLUDED.dtitle RETURNING *;
+ERROR:  new row violates row-level security policy for table "document"
+SET SESSION AUTHORIZATION regress_rls_alice;
+DROP POLICY p3_with_default ON document;
+--
+-- Test ALL policies with ON CONFLICT DO UPDATE (much the same as existing UPDATE
+-- tests)
+--
+CREATE POLICY p3_with_all ON document FOR ALL
+  USING (cid = (SELECT cid from category WHERE cname = 'novel'))
+  WITH CHECK (dauthor = current_user);
+SET SESSION AUTHORIZATION regress_rls_bob;
+-- Fails, since ALL WCO is enforced in insert path:
+INSERT INTO document VALUES (80, (SELECT cid from category WHERE cname = 'novel'), 1, 'regress_rls_carol', 'my first novel')
+    ON CONFLICT (did) DO UPDATE SET dtitle = EXCLUDED.dtitle, cid = 33;
+ERROR:  new row violates row-level security policy for table "document"
+-- Fails, since ALL policy USING qual is enforced (existing, target tuple is in
+-- violation, since it has the "manga" cid):
+INSERT INTO document VALUES (4, (SELECT cid from category WHERE cname = 'novel'), 1, 'regress_rls_bob', 'my first novel')
+    ON CONFLICT (did) DO UPDATE SET dtitle = EXCLUDED.dtitle;
+ERROR:  new row violates row-level security policy (USING expression) for table "document"
+-- Fails, since ALL WCO are enforced:
+INSERT INTO document VALUES (1, (SELECT cid from category WHERE cname = 'novel'), 1, 'regress_rls_bob', 'my first novel')
+    ON CONFLICT (did) DO UPDATE SET dauthor = 'regress_rls_carol';
+ERROR:  new row violates row-level security policy for table "document"
+--
+-- ROLE/GROUP
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE TABLE z1 (a int, b text);
+CREATE TABLE z2 (a int, b text);
+GRANT SELECT ON z1,z2 TO regress_rls_group1, regress_rls_group2,
+    regress_rls_bob, regress_rls_carol;
+INSERT INTO z1 VALUES
+    (1, 'aba'),
+    (2, 'bbb'),
+    (3, 'ccc'),
+    (4, 'dad');
+CREATE POLICY p1 ON z1 TO regress_rls_group1 USING (a % 2 = 0);
+CREATE POLICY p2 ON z1 TO regress_rls_group2 USING (a % 2 = 1);
+ALTER TABLE z1 ENABLE ROW LEVEL SECURITY;
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM z1 WHERE f_leak(b);
+ a |  b  
+---+-----
+ 2 | bbb
+ 4 | dad
+(2 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ dad
+(2 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM z1 WHERE f_leak(b);
+               QUERY PLAN                
+-----------------------------------------
+ Seq Scan on z1
+   Filter: (((a % 2) = 0) AND f_leak(b))
+(2 rows)
+
+PREPARE plancache_test AS SELECT * FROM z1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) EXECUTE plancache_test;
+               QUERY PLAN                
+-----------------------------------------
+ Seq Scan on z1
+   Filter: (((a % 2) = 0) AND f_leak(b))
+(2 rows)
+
+PREPARE plancache_test2 AS WITH q AS MATERIALIZED (SELECT * FROM z1 WHERE f_leak(b)) SELECT * FROM q,z2;
+SELECT * from f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) EXECUTE plancache_test2;
+                   QUERY PLAN                    
+-------------------------------------------------
+ Nested Loop
+   CTE q
+     ->  Seq Scan on z1
+           Filter: (((a % 2) = 0) AND f_leak(b))
+   ->  CTE Scan on q
+   ->  Materialize
+         ->  Seq Scan on z2
+(7 rows)
+
+PREPARE plancache_test3 AS WITH q AS MATERIALIZED (SELECT * FROM z2) SELECT * FROM q,z1 WHERE f_leak(z1.b);
+SELECT * from f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) EXECUTE plancache_test3;
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Nested Loop
+   CTE q
+     ->  Seq Scan on z2
+   ->  CTE Scan on q
+   ->  Materialize
+         ->  Seq Scan on z1
+               Filter: (((a % 2) = 0) AND f_leak(b))
+(7 rows)
+
+SET ROLE regress_rls_group1;
+SELECT * FROM z1 WHERE f_leak(b);
+ a |  b  
+---+-----
+ 2 | bbb
+ 4 | dad
+(2 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ dad
+(2 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM z1 WHERE f_leak(b);
+               QUERY PLAN                
+-----------------------------------------
+ Seq Scan on z1
+   Filter: (((a % 2) = 0) AND f_leak(b))
+(2 rows)
+
+EXPLAIN (COSTS OFF) EXECUTE plancache_test;
+               QUERY PLAN                
+-----------------------------------------
+ Seq Scan on z1
+   Filter: (((a % 2) = 0) AND f_leak(b))
+(2 rows)
+
+EXPLAIN (COSTS OFF) EXECUTE plancache_test2;
+                   QUERY PLAN                    
+-------------------------------------------------
+ Nested Loop
+   CTE q
+     ->  Seq Scan on z1
+           Filter: (((a % 2) = 0) AND f_leak(b))
+   ->  CTE Scan on q
+   ->  Materialize
+         ->  Seq Scan on z2
+(7 rows)
+
+EXPLAIN (COSTS OFF) EXECUTE plancache_test3;
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Nested Loop
+   CTE q
+     ->  Seq Scan on z2
+   ->  CTE Scan on q
+   ->  Materialize
+         ->  Seq Scan on z1
+               Filter: (((a % 2) = 0) AND f_leak(b))
+(7 rows)
+
+SET SESSION AUTHORIZATION regress_rls_carol;
+SELECT * FROM z1 WHERE f_leak(b);
+ a |  b  
+---+-----
+ 1 | aba
+ 3 | ccc
+(2 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ ccc
+(2 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM z1 WHERE f_leak(b);
+               QUERY PLAN                
+-----------------------------------------
+ Seq Scan on z1
+   Filter: (((a % 2) = 1) AND f_leak(b))
+(2 rows)
+
+EXPLAIN (COSTS OFF) EXECUTE plancache_test;
+               QUERY PLAN                
+-----------------------------------------
+ Seq Scan on z1
+   Filter: (((a % 2) = 1) AND f_leak(b))
+(2 rows)
+
+EXPLAIN (COSTS OFF) EXECUTE plancache_test2;
+                   QUERY PLAN                    
+-------------------------------------------------
+ Nested Loop
+   CTE q
+     ->  Seq Scan on z1
+           Filter: (((a % 2) = 1) AND f_leak(b))
+   ->  CTE Scan on q
+   ->  Materialize
+         ->  Seq Scan on z2
+(7 rows)
+
+EXPLAIN (COSTS OFF) EXECUTE plancache_test3;
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Nested Loop
+   CTE q
+     ->  Seq Scan on z2
+   ->  CTE Scan on q
+   ->  Materialize
+         ->  Seq Scan on z1
+               Filter: (((a % 2) = 1) AND f_leak(b))
+(7 rows)
+
+SET ROLE regress_rls_group2;
+SELECT * FROM z1 WHERE f_leak(b);
+ a |  b  
+---+-----
+ 1 | aba
+ 3 | ccc
+(2 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ ccc
+(2 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM z1 WHERE f_leak(b);
+               QUERY PLAN                
+-----------------------------------------
+ Seq Scan on z1
+   Filter: (((a % 2) = 1) AND f_leak(b))
+(2 rows)
+
+EXPLAIN (COSTS OFF) EXECUTE plancache_test;
+               QUERY PLAN                
+-----------------------------------------
+ Seq Scan on z1
+   Filter: (((a % 2) = 1) AND f_leak(b))
+(2 rows)
+
+EXPLAIN (COSTS OFF) EXECUTE plancache_test2;
+                   QUERY PLAN                    
+-------------------------------------------------
+ Nested Loop
+   CTE q
+     ->  Seq Scan on z1
+           Filter: (((a % 2) = 1) AND f_leak(b))
+   ->  CTE Scan on q
+   ->  Materialize
+         ->  Seq Scan on z2
+(7 rows)
+
+EXPLAIN (COSTS OFF) EXECUTE plancache_test3;
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Nested Loop
+   CTE q
+     ->  Seq Scan on z2
+   ->  CTE Scan on q
+   ->  Materialize
+         ->  Seq Scan on z1
+               Filter: (((a % 2) = 1) AND f_leak(b))
+(7 rows)
+
+--
+-- Views should follow policy for view owner.
+--
+-- View and Table owner are the same.
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE VIEW rls_view AS SELECT * FROM z1 WHERE f_leak(b);
+GRANT SELECT ON rls_view TO regress_rls_bob;
+-- Query as role that is not owner of view or table.  Should return all records.
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM rls_view;
+ a |  b  
+---+-----
+ 1 | aba
+ 2 | bbb
+ 3 | ccc
+ 4 | dad
+(4 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ bbb
+ ccc
+ dad
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
+     QUERY PLAN      
+---------------------
+ Seq Scan on z1
+   Filter: f_leak(b)
+(2 rows)
+
+-- Query as view/table owner.  Should return all records.
+SET SESSION AUTHORIZATION regress_rls_alice;
+SELECT * FROM rls_view;
+ a |  b  
+---+-----
+ 1 | aba
+ 2 | bbb
+ 3 | ccc
+ 4 | dad
+(4 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ aba
+ bbb
+ ccc
+ dad
+(4 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
+     QUERY PLAN      
+---------------------
+ Seq Scan on z1
+   Filter: f_leak(b)
+(2 rows)
+
+DROP VIEW rls_view;
+-- View and Table owners are different.
+SET SESSION AUTHORIZATION regress_rls_bob;
+CREATE VIEW rls_view AS SELECT * FROM z1 WHERE f_leak(b);
+GRANT SELECT ON rls_view TO regress_rls_alice;
+-- Query as role that is not owner of view but is owner of table.
+-- Should return records based on view owner policies.
+SET SESSION AUTHORIZATION regress_rls_alice;
+SELECT * FROM rls_view;
+ a |  b  
+---+-----
+ 2 | bbb
+ 4 | dad
+(2 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ dad
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
+               QUERY PLAN                
+-----------------------------------------
+ Seq Scan on z1
+   Filter: (((a % 2) = 0) AND f_leak(b))
+(2 rows)
+
+-- Query as role that is not owner of table but is owner of view.
+-- Should return records based on view owner policies.
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM rls_view;
+ a |  b  
+---+-----
+ 2 | bbb
+ 4 | dad
+(2 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ dad
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
+               QUERY PLAN                
+-----------------------------------------
+ Seq Scan on z1
+   Filter: (((a % 2) = 0) AND f_leak(b))
+(2 rows)
+
+-- Query as role that is not the owner of the table or view without permissions.
+SET SESSION AUTHORIZATION regress_rls_carol;
+SELECT * FROM rls_view; --fail - permission denied.
+ERROR:  permission denied for view rls_view
+SELECT * FROM f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM rls_view; --fail - permission denied.
+ERROR:  permission denied for view rls_view
+-- Query as role that is not the owner of the table or view with permissions.
+SET SESSION AUTHORIZATION regress_rls_bob;
+GRANT SELECT ON rls_view TO regress_rls_carol;
+SELECT * FROM rls_view;
+ a |  b  
+---+-----
+ 2 | bbb
+ 4 | dad
+(2 rows)
+
+SELECT * FROM f_leak_table ORDER BY a;
+  a  
+-----
+ bbb
+ dad
+(2 rows)
+
+TRUNCATE TABLE f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
+               QUERY PLAN                
+-----------------------------------------
+ Seq Scan on z1
+   Filter: (((a % 2) = 0) AND f_leak(b))
+(2 rows)
+
+SET SESSION AUTHORIZATION regress_rls_bob;
+DROP VIEW rls_view;
+--
+-- Command specific
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE TABLE x1 (a int, b text, c text);
+GRANT ALL ON x1 TO PUBLIC;
+INSERT INTO x1 VALUES
+    (1, 'abc', 'regress_rls_bob'),
+    (2, 'bcd', 'regress_rls_bob'),
+    (3, 'cde', 'regress_rls_carol'),
+    (4, 'def', 'regress_rls_carol'),
+    (5, 'efg', 'regress_rls_bob'),
+    (6, 'fgh', 'regress_rls_bob'),
+    (7, 'fgh', 'regress_rls_carol'),
+    (8, 'fgh', 'regress_rls_carol');
+CREATE POLICY p0 ON x1 FOR ALL USING (c = current_user);
+CREATE POLICY p1 ON x1 FOR SELECT USING (a % 2 = 0);
+CREATE POLICY p2 ON x1 FOR INSERT WITH CHECK (a % 2 = 1);
+CREATE POLICY p3 ON x1 FOR UPDATE USING (a % 2 = 0);
+CREATE POLICY p4 ON x1 FOR DELETE USING (a < 8);
+ALTER TABLE x1 ENABLE ROW LEVEL SECURITY;
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM x1 WHERE f_leak(b) ORDER BY a ASC;
+ a |  b  |         c         
+---+-----+-------------------
+ 1 | abc | regress_rls_bob
+ 2 | bcd | regress_rls_bob
+ 4 | def | regress_rls_carol
+ 5 | efg | regress_rls_bob
+ 6 | fgh | regress_rls_bob
+ 8 | fgh | regress_rls_carol
+(6 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ abc
+ bcd
+ def
+ efg
+ fgh
+ fgh
+(6 rows)
+
+TRUNCATE table f_leak_table;
+WITH UPDATED AS (UPDATE x1 SET b = b || '_updt' WHERE f_leak(b)
+RETURNING *) SELECT * FROM UPDATED ORDER BY (a,b);
+ a |    b     |         c         
+---+----------+-------------------
+ 1 | abc_updt | regress_rls_bob
+ 2 | bcd_updt | regress_rls_bob
+ 4 | def_updt | regress_rls_carol
+ 5 | efg_updt | regress_rls_bob
+ 6 | fgh_updt | regress_rls_bob
+ 8 | fgh_updt | regress_rls_carol
+(6 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ abc
+ bcd
+ def
+ efg
+ fgh
+ fgh
+(6 rows)
+
+TRUNCATE table f_leak_table;
+SET SESSION AUTHORIZATION regress_rls_carol;
+SELECT * FROM x1 WHERE f_leak(b) ORDER BY a ASC;
+ a |    b     |         c         
+---+----------+-------------------
+ 2 | bcd_updt | regress_rls_bob
+ 3 | cde      | regress_rls_carol
+ 4 | def_updt | regress_rls_carol
+ 6 | fgh_updt | regress_rls_bob
+ 7 | fgh      | regress_rls_carol
+ 8 | fgh_updt | regress_rls_carol
+(6 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+    a     
+----------
+ bcd_updt
+ cde
+ def_updt
+ fgh
+ fgh_updt
+ fgh_updt
+(6 rows)
+
+TRUNCATE table f_leak_table;
+WITH UPDATED AS (UPDATE x1 SET b = b || '_updt' WHERE f_leak(b)
+RETURNING *) SELECT * FROM UPDATED ORDER BY (a,b);
+ a |       b       |         c         
+---+---------------+-------------------
+ 2 | bcd_updt_updt | regress_rls_bob
+ 3 | cde_updt      | regress_rls_carol
+ 4 | def_updt_updt | regress_rls_carol
+ 6 | fgh_updt_updt | regress_rls_bob
+ 7 | fgh_updt      | regress_rls_carol
+ 8 | fgh_updt_updt | regress_rls_carol
+(6 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+    a     
+----------
+ bcd_updt
+ cde
+ def_updt
+ fgh
+ fgh_updt
+ fgh_updt
+(6 rows)
+
+TRUNCATE table f_leak_table;
+WITH cte1 AS (DELETE FROM x1 WHERE f_leak(b) RETURNING *) SELECT * FROM cte1 ORDER BY (a,b);
+ a |       b       |         c         
+---+---------------+-------------------
+ 2 | bcd_updt_updt | regress_rls_bob
+ 3 | cde_updt      | regress_rls_carol
+ 4 | def_updt_updt | regress_rls_carol
+ 6 | fgh_updt_updt | regress_rls_bob
+ 7 | fgh_updt      | regress_rls_carol
+ 8 | fgh_updt_updt | regress_rls_carol
+(6 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+       a       
+---------------
+ bcd_updt_updt
+ cde_updt
+ def_updt_updt
+ fgh_updt
+ fgh_updt_updt
+ fgh_updt_updt
+(6 rows)
+
+TRUNCATE table f_leak_table;
+--
+-- Duplicate Policy Names
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE TABLE y1 (a int, b text);
+CREATE TABLE y2 (a int, b text);
+GRANT ALL ON y1, y2 TO regress_rls_bob;
+CREATE POLICY p1 ON y1 FOR ALL USING (a % 2 = 0);
+CREATE POLICY p2 ON y1 FOR SELECT USING (a > 2);
+CREATE POLICY p1 ON y1 FOR SELECT USING (a % 2 = 1);  --fail
+ERROR:  policy "p1" for table "y1" already exists
+CREATE POLICY p1 ON y2 FOR ALL USING (a % 2 = 0);  --OK
+ALTER TABLE y1 ENABLE ROW LEVEL SECURITY;
+ALTER TABLE y2 ENABLE ROW LEVEL SECURITY;
+--
+-- Expression structure with SBV
+--
+-- Create view as table owner.  RLS should NOT be applied.
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE VIEW rls_sbv WITH (security_barrier) AS
+    SELECT * FROM y1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM rls_sbv WHERE (a = 1);
+            QUERY PLAN             
+-----------------------------------
+ Seq Scan on y1
+   Filter: (f_leak(b) AND (a = 1))
+(2 rows)
+
+DROP VIEW rls_sbv;
+-- Create view as role that does not own table.  RLS should be applied.
+SET SESSION AUTHORIZATION regress_rls_bob;
+CREATE VIEW rls_sbv WITH (security_barrier) AS
+    SELECT * FROM y1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM rls_sbv WHERE (a = 1);
+                            QUERY PLAN                            
+------------------------------------------------------------------
+ Seq Scan on y1
+   Filter: ((a = 1) AND ((a > 2) OR ((a % 2) = 0)) AND f_leak(b))
+(2 rows)
+
+DROP VIEW rls_sbv;
+--
+-- Expression structure
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+INSERT INTO y2 (SELECT x, md5(x::text) FROM generate_series(0,20) x);
+CREATE POLICY p2 ON y2 USING (a % 3 = 0);
+CREATE POLICY p3 ON y2 USING (a % 4 = 0);
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM y2 WHERE f_leak(b);
+ a  |                b                 
+----+----------------------------------
+  0 | cfcd208495d565ef66e7dff9f98764da
+  2 | c81e728d9d4c2f636f067f89cc14862c
+  3 | eccbc87e4b5ce2fe28308fd9f2a7baf3
+  4 | a87ff679a2f3e71d9181a67b7542122c
+  6 | 1679091c5a880faf6fb5e6087eb1b2dc
+  8 | c9f0f895fb98ab9159f51fd0297e236d
+  9 | 45c48cce2e2d7fbdea1afc51c7c6ad26
+ 10 | d3d9446802a44259755d38e6d163e820
+ 12 | c20ad4d76fe97759aa27a0c99bff6710
+ 14 | aab3238922bcc25a6f606eb525ffdc56
+ 15 | 9bf31c7ff062936a96d3c8bd1f8f2ff3
+ 16 | c74d97b01eae257e44aa9d5bade97baf
+ 18 | 6f4922f45568161a8cdf4ad2299f6d23
+ 20 | 98f13708210194c475687be6106a3b84
+(14 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ 1679091c5a880faf6fb5e6087eb1b2dc
+ 45c48cce2e2d7fbdea1afc51c7c6ad26
+ 6f4922f45568161a8cdf4ad2299f6d23
+ 98f13708210194c475687be6106a3b84
+ 9bf31c7ff062936a96d3c8bd1f8f2ff3
+ a87ff679a2f3e71d9181a67b7542122c
+ aab3238922bcc25a6f606eb525ffdc56
+ c20ad4d76fe97759aa27a0c99bff6710
+ c74d97b01eae257e44aa9d5bade97baf
+ c81e728d9d4c2f636f067f89cc14862c
+ c9f0f895fb98ab9159f51fd0297e236d
+ cfcd208495d565ef66e7dff9f98764da
+ d3d9446802a44259755d38e6d163e820
+ eccbc87e4b5ce2fe28308fd9f2a7baf3
+(14 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM y2 WHERE f_leak(b);
+                                 QUERY PLAN                                  
+-----------------------------------------------------------------------------
+ Seq Scan on y2
+   Filter: ((((a % 4) = 0) OR ((a % 3) = 0) OR ((a % 2) = 0)) AND f_leak(b))
+(2 rows)
+
+--
+-- Qual push-down of leaky functions, when not referring to table
+--
+SELECT * FROM y2 WHERE f_leak('abc');
+ a  |                b                 
+----+----------------------------------
+  0 | cfcd208495d565ef66e7dff9f98764da
+  2 | c81e728d9d4c2f636f067f89cc14862c
+  3 | eccbc87e4b5ce2fe28308fd9f2a7baf3
+  4 | a87ff679a2f3e71d9181a67b7542122c
+  6 | 1679091c5a880faf6fb5e6087eb1b2dc
+  8 | c9f0f895fb98ab9159f51fd0297e236d
+  9 | 45c48cce2e2d7fbdea1afc51c7c6ad26
+ 10 | d3d9446802a44259755d38e6d163e820
+ 12 | c20ad4d76fe97759aa27a0c99bff6710
+ 14 | aab3238922bcc25a6f606eb525ffdc56
+ 15 | 9bf31c7ff062936a96d3c8bd1f8f2ff3
+ 16 | c74d97b01eae257e44aa9d5bade97baf
+ 18 | 6f4922f45568161a8cdf4ad2299f6d23
+ 20 | 98f13708210194c475687be6106a3b84
+(14 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+ abc
+(21 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM y2 WHERE f_leak('abc');
+                                      QUERY PLAN                                       
+---------------------------------------------------------------------------------------
+ Seq Scan on y2
+   Filter: (f_leak('abc'::text) AND (((a % 4) = 0) OR ((a % 3) = 0) OR ((a % 2) = 0)))
+(2 rows)
+
+CREATE TABLE test_qual_pushdown (
+    abc text
+);
+INSERT INTO test_qual_pushdown VALUES ('abc'),('def');
+SELECT * FROM y2 JOIN test_qual_pushdown ON (b = abc) WHERE f_leak(abc);
+ a | b | abc 
+---+---+-----
+(0 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+  a  
+-----
+ abc
+ def
+(2 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM y2 JOIN test_qual_pushdown ON (b = abc) WHERE f_leak(abc);
+                               QUERY PLAN                                
+-------------------------------------------------------------------------
+ Hash Join
+   Hash Cond: (test_qual_pushdown.abc = y2.b)
+   ->  Seq Scan on test_qual_pushdown
+         Filter: f_leak(abc)
+   ->  Hash
+         ->  Seq Scan on y2
+               Filter: (((a % 4) = 0) OR ((a % 3) = 0) OR ((a % 2) = 0))
+(7 rows)
+
+SELECT * FROM y2 JOIN test_qual_pushdown ON (b = abc) WHERE f_leak(b);
+ a | b | abc 
+---+---+-----
+(0 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ 1679091c5a880faf6fb5e6087eb1b2dc
+ 45c48cce2e2d7fbdea1afc51c7c6ad26
+ 6f4922f45568161a8cdf4ad2299f6d23
+ 98f13708210194c475687be6106a3b84
+ 9bf31c7ff062936a96d3c8bd1f8f2ff3
+ a87ff679a2f3e71d9181a67b7542122c
+ aab3238922bcc25a6f606eb525ffdc56
+ c20ad4d76fe97759aa27a0c99bff6710
+ c74d97b01eae257e44aa9d5bade97baf
+ c81e728d9d4c2f636f067f89cc14862c
+ c9f0f895fb98ab9159f51fd0297e236d
+ cfcd208495d565ef66e7dff9f98764da
+ d3d9446802a44259755d38e6d163e820
+ eccbc87e4b5ce2fe28308fd9f2a7baf3
+(14 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF) SELECT * FROM y2 JOIN test_qual_pushdown ON (b = abc) WHERE f_leak(b);
+                                       QUERY PLAN                                        
+-----------------------------------------------------------------------------------------
+ Hash Join
+   Hash Cond: (test_qual_pushdown.abc = y2.b)
+   ->  Seq Scan on test_qual_pushdown
+   ->  Hash
+         ->  Seq Scan on y2
+               Filter: ((((a % 4) = 0) OR ((a % 3) = 0) OR ((a % 2) = 0)) AND f_leak(b))
+(6 rows)
+
+DROP TABLE test_qual_pushdown;
+--
+-- Plancache invalidate on user change.
+--
+RESET SESSION AUTHORIZATION;
+DROP TABLE t1 CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to table t2
+drop cascades to table t3
+CREATE TABLE t1 (a integer);
+GRANT SELECT ON t1 TO regress_rls_bob, regress_rls_carol;
+CREATE POLICY p1 ON t1 TO regress_rls_bob USING ((a % 2) = 0);
+CREATE POLICY p2 ON t1 TO regress_rls_carol USING ((a % 4) = 0);
+ALTER TABLE t1 ENABLE ROW LEVEL SECURITY;
+-- Prepare as regress_rls_bob
+SET ROLE regress_rls_bob;
+PREPARE role_inval AS SELECT * FROM t1;
+-- Check plan
+EXPLAIN (COSTS OFF) EXECUTE role_inval;
+       QUERY PLAN        
+-------------------------
+ Seq Scan on t1
+   Filter: ((a % 2) = 0)
+(2 rows)
+
+-- Change to regress_rls_carol
+SET ROLE regress_rls_carol;
+-- Check plan- should be different
+EXPLAIN (COSTS OFF) EXECUTE role_inval;
+       QUERY PLAN        
+-------------------------
+ Seq Scan on t1
+   Filter: ((a % 4) = 0)
+(2 rows)
+
+-- Change back to regress_rls_bob
+SET ROLE regress_rls_bob;
+-- Check plan- should be back to original
+EXPLAIN (COSTS OFF) EXECUTE role_inval;
+       QUERY PLAN        
+-------------------------
+ Seq Scan on t1
+   Filter: ((a % 2) = 0)
+(2 rows)
+
+--
+-- CTE and RLS
+--
+RESET SESSION AUTHORIZATION;
+DROP TABLE t1 CASCADE;
+CREATE TABLE t1 (a integer, b text);
+CREATE POLICY p1 ON t1 USING (a % 2 = 0);
+ALTER TABLE t1 ENABLE ROW LEVEL SECURITY;
+GRANT ALL ON t1 TO regress_rls_bob;
+INSERT INTO t1 (SELECT x, md5(x::text) FROM generate_series(0,20) x);
+SET SESSION AUTHORIZATION regress_rls_bob;
+WITH cte1 AS MATERIALIZED (SELECT * FROM t1 WHERE f_leak(b)) SELECT * FROM cte1;
+ a  |                b                 
+----+----------------------------------
+  0 | cfcd208495d565ef66e7dff9f98764da
+  2 | c81e728d9d4c2f636f067f89cc14862c
+  4 | a87ff679a2f3e71d9181a67b7542122c
+  6 | 1679091c5a880faf6fb5e6087eb1b2dc
+  8 | c9f0f895fb98ab9159f51fd0297e236d
+ 10 | d3d9446802a44259755d38e6d163e820
+ 12 | c20ad4d76fe97759aa27a0c99bff6710
+ 14 | aab3238922bcc25a6f606eb525ffdc56
+ 16 | c74d97b01eae257e44aa9d5bade97baf
+ 18 | 6f4922f45568161a8cdf4ad2299f6d23
+ 20 | 98f13708210194c475687be6106a3b84
+(11 rows)
+
+SELECT * from f_leak_table ORDER BY a;
+                a                 
+----------------------------------
+ 1679091c5a880faf6fb5e6087eb1b2dc
+ 6f4922f45568161a8cdf4ad2299f6d23
+ 98f13708210194c475687be6106a3b84
+ a87ff679a2f3e71d9181a67b7542122c
+ aab3238922bcc25a6f606eb525ffdc56
+ c20ad4d76fe97759aa27a0c99bff6710
+ c74d97b01eae257e44aa9d5bade97baf
+ c81e728d9d4c2f636f067f89cc14862c
+ c9f0f895fb98ab9159f51fd0297e236d
+ cfcd208495d565ef66e7dff9f98764da
+ d3d9446802a44259755d38e6d163e820
+(11 rows)
+
+TRUNCATE table f_leak_table;
+EXPLAIN (COSTS OFF)
+WITH cte1 AS MATERIALIZED (SELECT * FROM t1 WHERE f_leak(b)) SELECT * FROM cte1;
+                   QUERY PLAN                    
+-------------------------------------------------
+ CTE Scan on cte1
+   CTE cte1
+     ->  Seq Scan on t1
+           Filter: (((a % 2) = 0) AND f_leak(b))
+(4 rows)
+
+WITH cte1 AS (UPDATE t1 SET a = a + 1 RETURNING *) SELECT * FROM cte1; --fail
+ERROR:  new row violates row-level security policy for table "t1"
+WITH cte1 AS (UPDATE t1 SET a = a RETURNING *) SELECT * FROM cte1; --ok
+ a  |                b                 
+----+----------------------------------
+  0 | cfcd208495d565ef66e7dff9f98764da
+  2 | c81e728d9d4c2f636f067f89cc14862c
+  4 | a87ff679a2f3e71d9181a67b7542122c
+  6 | 1679091c5a880faf6fb5e6087eb1b2dc
+  8 | c9f0f895fb98ab9159f51fd0297e236d
+ 10 | d3d9446802a44259755d38e6d163e820
+ 12 | c20ad4d76fe97759aa27a0c99bff6710
+ 14 | aab3238922bcc25a6f606eb525ffdc56
+ 16 | c74d97b01eae257e44aa9d5bade97baf
+ 18 | 6f4922f45568161a8cdf4ad2299f6d23
+ 20 | 98f13708210194c475687be6106a3b84
+(11 rows)
+
+WITH cte1 AS (INSERT INTO t1 VALUES (21, 'Fail') RETURNING *) SELECT * FROM cte1; --fail
+ERROR:  new row violates row-level security policy for table "t1"
+WITH cte1 AS (INSERT INTO t1 VALUES (20, 'Success') RETURNING *) SELECT * FROM cte1; --ok
+ a  |    b    
+----+---------
+ 20 | Success
+(1 row)
+
+--
+-- Rename Policy
+--
+RESET SESSION AUTHORIZATION;
+ALTER POLICY p1 ON t1 RENAME TO p1; --fail
+ERROR:  policy "p1" for table "t1" already exists
+SELECT polname, relname
+    FROM pg_policy pol
+    JOIN pg_class pc ON (pc.oid = pol.polrelid)
+    WHERE relname = 't1';
+ polname | relname 
+---------+---------
+ p1      | t1
+(1 row)
+
+ALTER POLICY p1 ON t1 RENAME TO p2; --ok
+SELECT polname, relname
+    FROM pg_policy pol
+    JOIN pg_class pc ON (pc.oid = pol.polrelid)
+    WHERE relname = 't1';
+ polname | relname 
+---------+---------
+ p2      | t1
+(1 row)
+
+--
+-- Check INSERT SELECT
+--
+SET SESSION AUTHORIZATION regress_rls_bob;
+CREATE TABLE t2 (a integer, b text);
+INSERT INTO t2 (SELECT * FROM t1);
+EXPLAIN (COSTS OFF) INSERT INTO t2 (SELECT * FROM t1);
+          QUERY PLAN           
+-------------------------------
+ Insert on t2
+   ->  Seq Scan on t1
+         Filter: ((a % 2) = 0)
+(3 rows)
+
+SELECT * FROM t2;
+ a  |                b                 
+----+----------------------------------
+  0 | cfcd208495d565ef66e7dff9f98764da
+  2 | c81e728d9d4c2f636f067f89cc14862c
+  4 | a87ff679a2f3e71d9181a67b7542122c
+  6 | 1679091c5a880faf6fb5e6087eb1b2dc
+  8 | c9f0f895fb98ab9159f51fd0297e236d
+ 10 | d3d9446802a44259755d38e6d163e820
+ 12 | c20ad4d76fe97759aa27a0c99bff6710
+ 14 | aab3238922bcc25a6f606eb525ffdc56
+ 16 | c74d97b01eae257e44aa9d5bade97baf
+ 18 | 6f4922f45568161a8cdf4ad2299f6d23
+ 20 | 98f13708210194c475687be6106a3b84
+ 20 | Success
+(12 rows)
+
+EXPLAIN (COSTS OFF) SELECT * FROM t2;
+   QUERY PLAN   
+----------------
+ Seq Scan on t2
+(1 row)
+
+CREATE TABLE t3 AS SELECT * FROM t1;
+SELECT * FROM t3;
+ a  |                b                 
+----+----------------------------------
+  0 | cfcd208495d565ef66e7dff9f98764da
+  2 | c81e728d9d4c2f636f067f89cc14862c
+  4 | a87ff679a2f3e71d9181a67b7542122c
+  6 | 1679091c5a880faf6fb5e6087eb1b2dc
+  8 | c9f0f895fb98ab9159f51fd0297e236d
+ 10 | d3d9446802a44259755d38e6d163e820
+ 12 | c20ad4d76fe97759aa27a0c99bff6710
+ 14 | aab3238922bcc25a6f606eb525ffdc56
+ 16 | c74d97b01eae257e44aa9d5bade97baf
+ 18 | 6f4922f45568161a8cdf4ad2299f6d23
+ 20 | 98f13708210194c475687be6106a3b84
+ 20 | Success
+(12 rows)
+
+SELECT * INTO t4 FROM t1;
+SELECT * FROM t4;
+ a  |                b                 
+----+----------------------------------
+  0 | cfcd208495d565ef66e7dff9f98764da
+  2 | c81e728d9d4c2f636f067f89cc14862c
+  4 | a87ff679a2f3e71d9181a67b7542122c
+  6 | 1679091c5a880faf6fb5e6087eb1b2dc
+  8 | c9f0f895fb98ab9159f51fd0297e236d
+ 10 | d3d9446802a44259755d38e6d163e820
+ 12 | c20ad4d76fe97759aa27a0c99bff6710
+ 14 | aab3238922bcc25a6f606eb525ffdc56
+ 16 | c74d97b01eae257e44aa9d5bade97baf
+ 18 | 6f4922f45568161a8cdf4ad2299f6d23
+ 20 | 98f13708210194c475687be6106a3b84
+ 20 | Success
+(12 rows)
+
+--
+-- RLS with JOIN
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE TABLE blog (id integer, author text, post text);
+CREATE TABLE comment (blog_id integer, message text);
+GRANT ALL ON blog, comment TO regress_rls_bob;
+CREATE POLICY blog_1 ON blog USING (id % 2 = 0);
+ALTER TABLE blog ENABLE ROW LEVEL SECURITY;
+INSERT INTO blog VALUES
+    (1, 'alice', 'blog #1'),
+    (2, 'bob', 'blog #1'),
+    (3, 'alice', 'blog #2'),
+    (4, 'alice', 'blog #3'),
+    (5, 'john', 'blog #1');
+INSERT INTO comment VALUES
+    (1, 'cool blog'),
+    (1, 'fun blog'),
+    (3, 'crazy blog'),
+    (5, 'what?'),
+    (4, 'insane!'),
+    (2, 'who did it?');
+SET SESSION AUTHORIZATION regress_rls_bob;
+-- Check RLS JOIN with Non-RLS.
+SELECT id, author, message FROM blog JOIN comment ON id = blog_id;
+ id | author |   message   
+----+--------+-------------
+  4 | alice  | insane!
+  2 | bob    | who did it?
+(2 rows)
+
+-- Check Non-RLS JOIN with RLS.
+SELECT id, author, message FROM comment JOIN blog ON id = blog_id;
+ id | author |   message   
+----+--------+-------------
+  4 | alice  | insane!
+  2 | bob    | who did it?
+(2 rows)
+
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE POLICY comment_1 ON comment USING (blog_id < 4);
+ALTER TABLE comment ENABLE ROW LEVEL SECURITY;
+SET SESSION AUTHORIZATION regress_rls_bob;
+-- Check RLS JOIN RLS
+SELECT id, author, message FROM blog JOIN comment ON id = blog_id;
+ id | author |   message   
+----+--------+-------------
+  2 | bob    | who did it?
+(1 row)
+
+SELECT id, author, message FROM comment JOIN blog ON id = blog_id;
+ id | author |   message   
+----+--------+-------------
+  2 | bob    | who did it?
+(1 row)
+
+SET SESSION AUTHORIZATION regress_rls_alice;
+DROP TABLE blog, comment;
+--
+-- Default Deny Policy
+--
+RESET SESSION AUTHORIZATION;
+DROP POLICY p2 ON t1;
+ALTER TABLE t1 OWNER TO regress_rls_alice;
+-- Check that default deny does not apply to superuser.
+RESET SESSION AUTHORIZATION;
+SELECT * FROM t1 ORDER BY a;
+ a  |                b                 
+----+----------------------------------
+  0 | cfcd208495d565ef66e7dff9f98764da
+  1 | c4ca4238a0b923820dcc509a6f75849b
+  2 | c81e728d9d4c2f636f067f89cc14862c
+  3 | eccbc87e4b5ce2fe28308fd9f2a7baf3
+  4 | a87ff679a2f3e71d9181a67b7542122c
+  5 | e4da3b7fbbce2345d7772b0674a318d5
+  6 | 1679091c5a880faf6fb5e6087eb1b2dc
+  7 | 8f14e45fceea167a5a36dedd4bea2543
+  8 | c9f0f895fb98ab9159f51fd0297e236d
+  9 | 45c48cce2e2d7fbdea1afc51c7c6ad26
+ 10 | d3d9446802a44259755d38e6d163e820
+ 11 | 6512bd43d9caa6e02c990b0a82652dca
+ 12 | c20ad4d76fe97759aa27a0c99bff6710
+ 13 | c51ce410c124a10e0db5e4b97fc2af39
+ 14 | aab3238922bcc25a6f606eb525ffdc56
+ 15 | 9bf31c7ff062936a96d3c8bd1f8f2ff3
+ 16 | c74d97b01eae257e44aa9d5bade97baf
+ 17 | 70efdf2ec9b086079795c442636b55fb
+ 18 | 6f4922f45568161a8cdf4ad2299f6d23
+ 19 | 1f0e3dad99908345f7439f8ffabdffc4
+ 20 | 98f13708210194c475687be6106a3b84
+ 20 | Success
+(22 rows)
+
+EXPLAIN (COSTS OFF) SELECT * FROM t1;
+   QUERY PLAN   
+----------------
+ Seq Scan on t1
+(1 row)
+
+-- Check that default deny does not apply to table owner.
+SET SESSION AUTHORIZATION regress_rls_alice;
+SELECT * FROM t1 ORDER BY a;
+ a  |                b                 
+----+----------------------------------
+  0 | cfcd208495d565ef66e7dff9f98764da
+  1 | c4ca4238a0b923820dcc509a6f75849b
+  2 | c81e728d9d4c2f636f067f89cc14862c
+  3 | eccbc87e4b5ce2fe28308fd9f2a7baf3
+  4 | a87ff679a2f3e71d9181a67b7542122c
+  5 | e4da3b7fbbce2345d7772b0674a318d5
+  6 | 1679091c5a880faf6fb5e6087eb1b2dc
+  7 | 8f14e45fceea167a5a36dedd4bea2543
+  8 | c9f0f895fb98ab9159f51fd0297e236d
+  9 | 45c48cce2e2d7fbdea1afc51c7c6ad26
+ 10 | d3d9446802a44259755d38e6d163e820
+ 11 | 6512bd43d9caa6e02c990b0a82652dca
+ 12 | c20ad4d76fe97759aa27a0c99bff6710
+ 13 | c51ce410c124a10e0db5e4b97fc2af39
+ 14 | aab3238922bcc25a6f606eb525ffdc56
+ 15 | 9bf31c7ff062936a96d3c8bd1f8f2ff3
+ 16 | c74d97b01eae257e44aa9d5bade97baf
+ 17 | 70efdf2ec9b086079795c442636b55fb
+ 18 | 6f4922f45568161a8cdf4ad2299f6d23
+ 19 | 1f0e3dad99908345f7439f8ffabdffc4
+ 20 | 98f13708210194c475687be6106a3b84
+ 20 | Success
+(22 rows)
+
+EXPLAIN (COSTS OFF) SELECT * FROM t1;
+   QUERY PLAN   
+----------------
+ Seq Scan on t1
+(1 row)
+
+-- Check that default deny applies to non-owner/non-superuser when RLS on.
+SET SESSION AUTHORIZATION regress_rls_bob;
+SET row_security TO ON;
+SELECT * FROM t1;
+ a | b 
+---+---
+(0 rows)
+
+EXPLAIN (COSTS OFF) SELECT * FROM t1;
+        QUERY PLAN        
+--------------------------
+ Result
+   One-Time Filter: false
+(2 rows)
+
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM t1;
+ a | b 
+---+---
+(0 rows)
+
+EXPLAIN (COSTS OFF) SELECT * FROM t1;
+        QUERY PLAN        
+--------------------------
+ Result
+   One-Time Filter: false
+(2 rows)
+
+--
+-- COPY TO/FROM
+--
+RESET SESSION AUTHORIZATION;
+DROP TABLE copy_t CASCADE;
+ERROR:  table "copy_t" does not exist
+CREATE TABLE copy_t (a integer, b text);
+CREATE POLICY p1 ON copy_t USING (a % 2 = 0);
+ALTER TABLE copy_t ENABLE ROW LEVEL SECURITY;
+GRANT ALL ON copy_t TO regress_rls_bob, regress_rls_exempt_user;
+INSERT INTO copy_t (SELECT x, md5(x::text) FROM generate_series(0,10) x);
+-- Check COPY TO as Superuser/owner.
+RESET SESSION AUTHORIZATION;
+SET row_security TO OFF;
+COPY (SELECT * FROM copy_t ORDER BY a ASC) TO STDOUT WITH DELIMITER ',';
+0,cfcd208495d565ef66e7dff9f98764da
+1,c4ca4238a0b923820dcc509a6f75849b
+2,c81e728d9d4c2f636f067f89cc14862c
+3,eccbc87e4b5ce2fe28308fd9f2a7baf3
+4,a87ff679a2f3e71d9181a67b7542122c
+5,e4da3b7fbbce2345d7772b0674a318d5
+6,1679091c5a880faf6fb5e6087eb1b2dc
+7,8f14e45fceea167a5a36dedd4bea2543
+8,c9f0f895fb98ab9159f51fd0297e236d
+9,45c48cce2e2d7fbdea1afc51c7c6ad26
+10,d3d9446802a44259755d38e6d163e820
+SET row_security TO ON;
+COPY (SELECT * FROM copy_t ORDER BY a ASC) TO STDOUT WITH DELIMITER ',';
+0,cfcd208495d565ef66e7dff9f98764da
+1,c4ca4238a0b923820dcc509a6f75849b
+2,c81e728d9d4c2f636f067f89cc14862c
+3,eccbc87e4b5ce2fe28308fd9f2a7baf3
+4,a87ff679a2f3e71d9181a67b7542122c
+5,e4da3b7fbbce2345d7772b0674a318d5
+6,1679091c5a880faf6fb5e6087eb1b2dc
+7,8f14e45fceea167a5a36dedd4bea2543
+8,c9f0f895fb98ab9159f51fd0297e236d
+9,45c48cce2e2d7fbdea1afc51c7c6ad26
+10,d3d9446802a44259755d38e6d163e820
+-- Check COPY TO as user with permissions.
+SET SESSION AUTHORIZATION regress_rls_bob;
+SET row_security TO OFF;
+COPY (SELECT * FROM copy_t ORDER BY a ASC) TO STDOUT WITH DELIMITER ','; --fail - would be affected by RLS
+ERROR:  query would be affected by row-level security policy for table "copy_t"
+SET row_security TO ON;
+COPY (SELECT * FROM copy_t ORDER BY a ASC) TO STDOUT WITH DELIMITER ','; --ok
+0,cfcd208495d565ef66e7dff9f98764da
+2,c81e728d9d4c2f636f067f89cc14862c
+4,a87ff679a2f3e71d9181a67b7542122c
+6,1679091c5a880faf6fb5e6087eb1b2dc
+8,c9f0f895fb98ab9159f51fd0297e236d
+10,d3d9446802a44259755d38e6d163e820
+-- Check COPY TO as user with permissions and BYPASSRLS
+SET SESSION AUTHORIZATION regress_rls_exempt_user;
+SET row_security TO OFF;
+COPY (SELECT * FROM copy_t ORDER BY a ASC) TO STDOUT WITH DELIMITER ','; --ok
+0,cfcd208495d565ef66e7dff9f98764da
+1,c4ca4238a0b923820dcc509a6f75849b
+2,c81e728d9d4c2f636f067f89cc14862c
+3,eccbc87e4b5ce2fe28308fd9f2a7baf3
+4,a87ff679a2f3e71d9181a67b7542122c
+5,e4da3b7fbbce2345d7772b0674a318d5
+6,1679091c5a880faf6fb5e6087eb1b2dc
+7,8f14e45fceea167a5a36dedd4bea2543
+8,c9f0f895fb98ab9159f51fd0297e236d
+9,45c48cce2e2d7fbdea1afc51c7c6ad26
+10,d3d9446802a44259755d38e6d163e820
+SET row_security TO ON;
+COPY (SELECT * FROM copy_t ORDER BY a ASC) TO STDOUT WITH DELIMITER ','; --ok
+0,cfcd208495d565ef66e7dff9f98764da
+1,c4ca4238a0b923820dcc509a6f75849b
+2,c81e728d9d4c2f636f067f89cc14862c
+3,eccbc87e4b5ce2fe28308fd9f2a7baf3
+4,a87ff679a2f3e71d9181a67b7542122c
+5,e4da3b7fbbce2345d7772b0674a318d5
+6,1679091c5a880faf6fb5e6087eb1b2dc
+7,8f14e45fceea167a5a36dedd4bea2543
+8,c9f0f895fb98ab9159f51fd0297e236d
+9,45c48cce2e2d7fbdea1afc51c7c6ad26
+10,d3d9446802a44259755d38e6d163e820
+-- Check COPY TO as user without permissions. SET row_security TO OFF;
+SET SESSION AUTHORIZATION regress_rls_carol;
+SET row_security TO OFF;
+COPY (SELECT * FROM copy_t ORDER BY a ASC) TO STDOUT WITH DELIMITER ','; --fail - would be affected by RLS
+ERROR:  query would be affected by row-level security policy for table "copy_t"
+SET row_security TO ON;
+COPY (SELECT * FROM copy_t ORDER BY a ASC) TO STDOUT WITH DELIMITER ','; --fail - permission denied
+ERROR:  permission denied for table copy_t
+-- Check COPY relation TO; keep it just one row to avoid reordering issues
+RESET SESSION AUTHORIZATION;
+SET row_security TO ON;
+CREATE TABLE copy_rel_to (a integer, b text);
+CREATE POLICY p1 ON copy_rel_to USING (a % 2 = 0);
+ALTER TABLE copy_rel_to ENABLE ROW LEVEL SECURITY;
+GRANT ALL ON copy_rel_to TO regress_rls_bob, regress_rls_exempt_user;
+INSERT INTO copy_rel_to VALUES (1, md5('1'));
+-- Check COPY TO as Superuser/owner.
+RESET SESSION AUTHORIZATION;
+SET row_security TO OFF;
+COPY copy_rel_to TO STDOUT WITH DELIMITER ',';
+1,c4ca4238a0b923820dcc509a6f75849b
+SET row_security TO ON;
+COPY copy_rel_to TO STDOUT WITH DELIMITER ',';
+1,c4ca4238a0b923820dcc509a6f75849b
+-- Check COPY TO as user with permissions.
+SET SESSION AUTHORIZATION regress_rls_bob;
+SET row_security TO OFF;
+COPY copy_rel_to TO STDOUT WITH DELIMITER ','; --fail - would be affected by RLS
+ERROR:  query would be affected by row-level security policy for table "copy_rel_to"
+SET row_security TO ON;
+COPY copy_rel_to TO STDOUT WITH DELIMITER ','; --ok
+-- Check COPY TO as user with permissions and BYPASSRLS
+SET SESSION AUTHORIZATION regress_rls_exempt_user;
+SET row_security TO OFF;
+COPY copy_rel_to TO STDOUT WITH DELIMITER ','; --ok
+1,c4ca4238a0b923820dcc509a6f75849b
+SET row_security TO ON;
+COPY copy_rel_to TO STDOUT WITH DELIMITER ','; --ok
+1,c4ca4238a0b923820dcc509a6f75849b
+-- Check COPY TO as user without permissions. SET row_security TO OFF;
+SET SESSION AUTHORIZATION regress_rls_carol;
+SET row_security TO OFF;
+COPY copy_rel_to TO STDOUT WITH DELIMITER ','; --fail - permission denied
+ERROR:  permission denied for table copy_rel_to
+SET row_security TO ON;
+COPY copy_rel_to TO STDOUT WITH DELIMITER ','; --fail - permission denied
+ERROR:  permission denied for table copy_rel_to
+-- Check COPY FROM as Superuser/owner.
+RESET SESSION AUTHORIZATION;
+SET row_security TO OFF;
+COPY copy_t FROM STDIN; --ok
+SET row_security TO ON;
+COPY copy_t FROM STDIN; --ok
+-- Check COPY FROM as user with permissions.
+SET SESSION AUTHORIZATION regress_rls_bob;
+SET row_security TO OFF;
+COPY copy_t FROM STDIN; --fail - would be affected by RLS.
+ERROR:  query would be affected by row-level security policy for table "copy_t"
+SET row_security TO ON;
+COPY copy_t FROM STDIN; --fail - COPY FROM not supported by RLS.
+ERROR:  COPY FROM not supported with row-level security
+HINT:  Use INSERT statements instead.
+-- Check COPY FROM as user with permissions and BYPASSRLS
+SET SESSION AUTHORIZATION regress_rls_exempt_user;
+SET row_security TO ON;
+COPY copy_t FROM STDIN; --ok
+-- Check COPY FROM as user without permissions.
+SET SESSION AUTHORIZATION regress_rls_carol;
+SET row_security TO OFF;
+COPY copy_t FROM STDIN; --fail - permission denied.
+ERROR:  permission denied for table copy_t
+SET row_security TO ON;
+COPY copy_t FROM STDIN; --fail - permission denied.
+ERROR:  permission denied for table copy_t
+RESET SESSION AUTHORIZATION;
+DROP TABLE copy_t;
+DROP TABLE copy_rel_to CASCADE;
+-- Check WHERE CURRENT OF
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE TABLE current_check (currentid int, payload text, rlsuser text);
+GRANT ALL ON current_check TO PUBLIC;
+INSERT INTO current_check VALUES
+    (1, 'abc', 'regress_rls_bob'),
+    (2, 'bcd', 'regress_rls_bob'),
+    (3, 'cde', 'regress_rls_bob'),
+    (4, 'def', 'regress_rls_bob');
+CREATE POLICY p1 ON current_check FOR SELECT USING (currentid % 2 = 0);
+CREATE POLICY p2 ON current_check FOR DELETE USING (currentid = 4 AND rlsuser = current_user);
+CREATE POLICY p3 ON current_check FOR UPDATE USING (currentid = 4) WITH CHECK (rlsuser = current_user);
+ALTER TABLE current_check ENABLE ROW LEVEL SECURITY;
+SET SESSION AUTHORIZATION regress_rls_bob;
+-- Can SELECT even rows
+SELECT * FROM current_check;
+ currentid | payload |     rlsuser     
+-----------+---------+-----------------
+         2 | bcd     | regress_rls_bob
+         4 | def     | regress_rls_bob
+(2 rows)
+
+-- Cannot UPDATE row 2
+UPDATE current_check SET payload = payload || '_new' WHERE currentid = 2 RETURNING *;
+ currentid | payload | rlsuser 
+-----------+---------+---------
+(0 rows)
+
+BEGIN;
+DECLARE current_check_cursor SCROLL CURSOR FOR SELECT * FROM current_check;
+-- Returns rows that can be seen according to SELECT policy, like plain SELECT
+-- above (even rows)
+FETCH ABSOLUTE 1 FROM current_check_cursor;
+ currentid | payload |     rlsuser     
+-----------+---------+-----------------
+         2 | bcd     | regress_rls_bob
+(1 row)
+
+-- Still cannot UPDATE row 2 through cursor
+UPDATE current_check SET payload = payload || '_new' WHERE CURRENT OF current_check_cursor RETURNING *;
+ currentid | payload | rlsuser 
+-----------+---------+---------
+(0 rows)
+
+-- Can update row 4 through cursor, which is the next visible row
+FETCH RELATIVE 1 FROM current_check_cursor;
+ currentid | payload |     rlsuser     
+-----------+---------+-----------------
+         4 | def     | regress_rls_bob
+(1 row)
+
+UPDATE current_check SET payload = payload || '_new' WHERE CURRENT OF current_check_cursor RETURNING *;
+ currentid | payload |     rlsuser     
+-----------+---------+-----------------
+         4 | def_new | regress_rls_bob
+(1 row)
+
+SELECT * FROM current_check;
+ currentid | payload |     rlsuser     
+-----------+---------+-----------------
+         2 | bcd     | regress_rls_bob
+         4 | def_new | regress_rls_bob
+(2 rows)
+
+-- Plan should be a subquery TID scan
+EXPLAIN (COSTS OFF) UPDATE current_check SET payload = payload WHERE CURRENT OF current_check_cursor;
+                         QUERY PLAN                          
+-------------------------------------------------------------
+ Update on current_check
+   ->  Tid Scan on current_check
+         TID Cond: CURRENT OF current_check_cursor
+         Filter: ((currentid = 4) AND ((currentid % 2) = 0))
+(4 rows)
+
+-- Similarly can only delete row 4
+FETCH ABSOLUTE 1 FROM current_check_cursor;
+ currentid | payload |     rlsuser     
+-----------+---------+-----------------
+         2 | bcd     | regress_rls_bob
+(1 row)
+
+DELETE FROM current_check WHERE CURRENT OF current_check_cursor RETURNING *;
+ currentid | payload | rlsuser 
+-----------+---------+---------
+(0 rows)
+
+FETCH RELATIVE 1 FROM current_check_cursor;
+ currentid | payload |     rlsuser     
+-----------+---------+-----------------
+         4 | def     | regress_rls_bob
+(1 row)
+
+DELETE FROM current_check WHERE CURRENT OF current_check_cursor RETURNING *;
+ currentid | payload |     rlsuser     
+-----------+---------+-----------------
+         4 | def_new | regress_rls_bob
+(1 row)
+
+SELECT * FROM current_check;
+ currentid | payload |     rlsuser     
+-----------+---------+-----------------
+         2 | bcd     | regress_rls_bob
+(1 row)
+
+COMMIT;
+--
+-- check pg_stats view filtering
+--
+SET row_security TO ON;
+SET SESSION AUTHORIZATION regress_rls_alice;
+ANALYZE current_check;
+-- Stats visible
+SELECT row_security_active('current_check');
+ row_security_active 
+---------------------
+ f
+(1 row)
+
+SELECT attname, most_common_vals FROM pg_stats
+  WHERE tablename = 'current_check'
+  ORDER BY 1;
+  attname  | most_common_vals  
+-----------+-------------------
+ currentid | 
+ payload   | 
+ rlsuser   | {regress_rls_bob}
+(3 rows)
+
+SET SESSION AUTHORIZATION regress_rls_bob;
+-- Stats not visible
+SELECT row_security_active('current_check');
+ row_security_active 
+---------------------
+ t
+(1 row)
+
+SELECT attname, most_common_vals FROM pg_stats
+  WHERE tablename = 'current_check'
+  ORDER BY 1;
+ attname | most_common_vals 
+---------+------------------
+(0 rows)
+
+--
+-- Collation support
+--
+BEGIN;
+CREATE TABLE coll_t (c) AS VALUES ('bar'::text);
+CREATE POLICY coll_p ON coll_t USING (c < ('foo'::text COLLATE "C"));
+ALTER TABLE coll_t ENABLE ROW LEVEL SECURITY;
+GRANT SELECT ON coll_t TO regress_rls_alice;
+SELECT (string_to_array(polqual, ':'))[7] AS inputcollid FROM pg_policy WHERE polrelid = 'coll_t'::regclass;
+   inputcollid    
+------------------
+ inputcollid 950 
+(1 row)
+
+SET SESSION AUTHORIZATION regress_rls_alice;
+SELECT * FROM coll_t;
+  c  
+-----
+ bar
+(1 row)
+
+ROLLBACK;
+--
+-- Shared Object Dependencies
+--
+RESET SESSION AUTHORIZATION;
+BEGIN;
+CREATE ROLE regress_rls_eve;
+CREATE ROLE regress_rls_frank;
+CREATE TABLE tbl1 (c) AS VALUES ('bar'::text);
+GRANT SELECT ON TABLE tbl1 TO regress_rls_eve;
+CREATE POLICY P ON tbl1 TO regress_rls_eve, regress_rls_frank USING (true);
+SELECT refclassid::regclass, deptype
+  FROM pg_depend
+  WHERE classid = 'pg_policy'::regclass
+  AND refobjid = 'tbl1'::regclass;
+ refclassid | deptype 
+------------+---------
+ pg_class   | a
+(1 row)
+
+SELECT refclassid::regclass, deptype
+  FROM pg_shdepend
+  WHERE classid = 'pg_policy'::regclass
+  AND refobjid IN ('regress_rls_eve'::regrole, 'regress_rls_frank'::regrole);
+ refclassid | deptype 
+------------+---------
+ pg_authid  | r
+ pg_authid  | r
+(2 rows)
+
+SAVEPOINT q;
+DROP ROLE regress_rls_eve; --fails due to dependency on POLICY p
+ERROR:  role "regress_rls_eve" cannot be dropped because some objects depend on it
+DETAIL:  privileges for table tbl1
+target of policy p on table tbl1
+ROLLBACK TO q;
+ALTER POLICY p ON tbl1 TO regress_rls_frank USING (true);
+SAVEPOINT q;
+DROP ROLE regress_rls_eve; --fails due to dependency on GRANT SELECT
+ERROR:  role "regress_rls_eve" cannot be dropped because some objects depend on it
+DETAIL:  privileges for table tbl1
+ROLLBACK TO q;
+REVOKE ALL ON TABLE tbl1 FROM regress_rls_eve;
+SAVEPOINT q;
+DROP ROLE regress_rls_eve; --succeeds
+ROLLBACK TO q;
+SAVEPOINT q;
+DROP ROLE regress_rls_frank; --fails due to dependency on POLICY p
+ERROR:  role "regress_rls_frank" cannot be dropped because some objects depend on it
+DETAIL:  target of policy p on table tbl1
+ROLLBACK TO q;
+DROP POLICY p ON tbl1;
+SAVEPOINT q;
+DROP ROLE regress_rls_frank; -- succeeds
+ROLLBACK TO q;
+ROLLBACK; -- cleanup
+--
+-- Converting table to view
+--
+BEGIN;
+CREATE TABLE t (c int);
+CREATE POLICY p ON t USING (c % 2 = 1);
+ALTER TABLE t ENABLE ROW LEVEL SECURITY;
+SAVEPOINT q;
+CREATE RULE "_RETURN" AS ON SELECT TO t DO INSTEAD
+  SELECT * FROM generate_series(1,5) t0(c); -- fails due to row level security enabled
+ERROR:  could not convert table "t" to a view because it has row security enabled
+ROLLBACK TO q;
+ALTER TABLE t DISABLE ROW LEVEL SECURITY;
+SAVEPOINT q;
+CREATE RULE "_RETURN" AS ON SELECT TO t DO INSTEAD
+  SELECT * FROM generate_series(1,5) t0(c); -- fails due to policy p on t
+ERROR:  could not convert table "t" to a view because it has row security policies
+ROLLBACK TO q;
+DROP POLICY p ON t;
+CREATE RULE "_RETURN" AS ON SELECT TO t DO INSTEAD
+  SELECT * FROM generate_series(1,5) t0(c); -- succeeds
+ROLLBACK;
+--
+-- Policy expression handling
+--
+BEGIN;
+CREATE TABLE t (c) AS VALUES ('bar'::text);
+CREATE POLICY p ON t USING (max(c)); -- fails: aggregate functions are not allowed in policy expressions
+ERROR:  aggregate functions are not allowed in policy expressions
+ROLLBACK;
+--
+-- Non-target relations are only subject to SELECT policies
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE TABLE r1 (a int);
+CREATE TABLE r2 (a int);
+INSERT INTO r1 VALUES (10), (20);
+INSERT INTO r2 VALUES (10), (20);
+GRANT ALL ON r1, r2 TO regress_rls_bob;
+CREATE POLICY p1 ON r1 USING (true);
+ALTER TABLE r1 ENABLE ROW LEVEL SECURITY;
+CREATE POLICY p1 ON r2 FOR SELECT USING (true);
+CREATE POLICY p2 ON r2 FOR INSERT WITH CHECK (false);
+CREATE POLICY p3 ON r2 FOR UPDATE USING (false);
+CREATE POLICY p4 ON r2 FOR DELETE USING (false);
+ALTER TABLE r2 ENABLE ROW LEVEL SECURITY;
+SET SESSION AUTHORIZATION regress_rls_bob;
+SELECT * FROM r1;
+ a  
+----
+ 10
+ 20
+(2 rows)
+
+SELECT * FROM r2;
+ a  
+----
+ 10
+ 20
+(2 rows)
+
+-- r2 is read-only
+INSERT INTO r2 VALUES (2); -- Not allowed
+ERROR:  new row violates row-level security policy for table "r2"
+UPDATE r2 SET a = 2 RETURNING *; -- Updates nothing
+ a 
+---
+(0 rows)
+
+DELETE FROM r2 RETURNING *; -- Deletes nothing
+ a 
+---
+(0 rows)
+
+-- r2 can be used as a non-target relation in DML
+INSERT INTO r1 SELECT a + 1 FROM r2 RETURNING *; -- OK
+ a  
+----
+ 11
+ 21
+(2 rows)
+
+UPDATE r1 SET a = r2.a + 2 FROM r2 WHERE r1.a = r2.a RETURNING *; -- OK
+ a  | a  
+----+----
+ 12 | 10
+ 22 | 20
+(2 rows)
+
+DELETE FROM r1 USING r2 WHERE r1.a = r2.a + 2 RETURNING *; -- OK
+ a  | a  
+----+----
+ 12 | 10
+ 22 | 20
+(2 rows)
+
+SELECT * FROM r1;
+ a  
+----
+ 11
+ 21
+(2 rows)
+
+SELECT * FROM r2;
+ a  
+----
+ 10
+ 20
+(2 rows)
+
+SET SESSION AUTHORIZATION regress_rls_alice;
+DROP TABLE r1;
+DROP TABLE r2;
+--
+-- FORCE ROW LEVEL SECURITY applies RLS to owners too
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+SET row_security = on;
+CREATE TABLE r1 (a int);
+INSERT INTO r1 VALUES (10), (20);
+CREATE POLICY p1 ON r1 USING (false);
+ALTER TABLE r1 ENABLE ROW LEVEL SECURITY;
+ALTER TABLE r1 FORCE ROW LEVEL SECURITY;
+-- No error, but no rows
+TABLE r1;
+ a 
+---
+(0 rows)
+
+-- RLS error
+INSERT INTO r1 VALUES (1);
+ERROR:  new row violates row-level security policy for table "r1"
+-- No error (unable to see any rows to update)
+UPDATE r1 SET a = 1;
+TABLE r1;
+ a 
+---
+(0 rows)
+
+-- No error (unable to see any rows to delete)
+DELETE FROM r1;
+TABLE r1;
+ a 
+---
+(0 rows)
+
+SET row_security = off;
+-- these all fail, would be affected by RLS
+TABLE r1;
+ERROR:  query would be affected by row-level security policy for table "r1"
+HINT:  To disable the policy for the table's owner, use ALTER TABLE NO FORCE ROW LEVEL SECURITY.
+UPDATE r1 SET a = 1;
+ERROR:  query would be affected by row-level security policy for table "r1"
+HINT:  To disable the policy for the table's owner, use ALTER TABLE NO FORCE ROW LEVEL SECURITY.
+DELETE FROM r1;
+ERROR:  query would be affected by row-level security policy for table "r1"
+HINT:  To disable the policy for the table's owner, use ALTER TABLE NO FORCE ROW LEVEL SECURITY.
+DROP TABLE r1;
+--
+-- FORCE ROW LEVEL SECURITY does not break RI
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+SET row_security = on;
+CREATE TABLE r1 (a int PRIMARY KEY);
+CREATE TABLE r2 (a int REFERENCES r1);
+INSERT INTO r1 VALUES (10), (20);
+INSERT INTO r2 VALUES (10), (20);
+-- Create policies on r2 which prevent the
+-- owner from seeing any rows, but RI should
+-- still see them.
+CREATE POLICY p1 ON r2 USING (false);
+ALTER TABLE r2 ENABLE ROW LEVEL SECURITY;
+ALTER TABLE r2 FORCE ROW LEVEL SECURITY;
+-- Errors due to rows in r2
+DELETE FROM r1;
+ERROR:  update or delete on table "r1" violates foreign key constraint "r2_a_fkey" on table "r2"
+DETAIL:  Key (a)=(10) is still referenced from table "r2".
+-- Reset r2 to no-RLS
+DROP POLICY p1 ON r2;
+ALTER TABLE r2 NO FORCE ROW LEVEL SECURITY;
+ALTER TABLE r2 DISABLE ROW LEVEL SECURITY;
+-- clean out r2 for INSERT test below
+DELETE FROM r2;
+-- Change r1 to not allow rows to be seen
+CREATE POLICY p1 ON r1 USING (false);
+ALTER TABLE r1 ENABLE ROW LEVEL SECURITY;
+ALTER TABLE r1 FORCE ROW LEVEL SECURITY;
+-- No rows seen
+TABLE r1;
+ a 
+---
+(0 rows)
+
+-- No error, RI still sees that row exists in r1
+INSERT INTO r2 VALUES (10);
+DROP TABLE r2;
+DROP TABLE r1;
+-- Ensure cascaded DELETE works
+CREATE TABLE r1 (a int PRIMARY KEY);
+CREATE TABLE r2 (a int REFERENCES r1 ON DELETE CASCADE);
+INSERT INTO r1 VALUES (10), (20);
+INSERT INTO r2 VALUES (10), (20);
+-- Create policies on r2 which prevent the
+-- owner from seeing any rows, but RI should
+-- still see them.
+CREATE POLICY p1 ON r2 USING (false);
+ALTER TABLE r2 ENABLE ROW LEVEL SECURITY;
+ALTER TABLE r2 FORCE ROW LEVEL SECURITY;
+-- Deletes all records from both
+DELETE FROM r1;
+-- Remove FORCE from r2
+ALTER TABLE r2 NO FORCE ROW LEVEL SECURITY;
+-- As owner, we now bypass RLS
+-- verify no rows in r2 now
+TABLE r2;
+ a 
+---
+(0 rows)
+
+DROP TABLE r2;
+DROP TABLE r1;
+-- Ensure cascaded UPDATE works
+CREATE TABLE r1 (a int PRIMARY KEY);
+CREATE TABLE r2 (a int REFERENCES r1 ON UPDATE CASCADE);
+INSERT INTO r1 VALUES (10), (20);
+INSERT INTO r2 VALUES (10), (20);
+-- Create policies on r2 which prevent the
+-- owner from seeing any rows, but RI should
+-- still see them.
+CREATE POLICY p1 ON r2 USING (false);
+ALTER TABLE r2 ENABLE ROW LEVEL SECURITY;
+ALTER TABLE r2 FORCE ROW LEVEL SECURITY;
+-- Updates records in both
+UPDATE r1 SET a = a+5;
+-- Remove FORCE from r2
+ALTER TABLE r2 NO FORCE ROW LEVEL SECURITY;
+-- As owner, we now bypass RLS
+-- verify records in r2 updated
+TABLE r2;
+ a  
+----
+ 15
+ 25
+(2 rows)
+
+DROP TABLE r2;
+DROP TABLE r1;
+--
+-- Test INSERT+RETURNING applies SELECT policies as
+-- WithCheckOptions (meaning an error is thrown)
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+SET row_security = on;
+CREATE TABLE r1 (a int);
+CREATE POLICY p1 ON r1 FOR SELECT USING (false);
+CREATE POLICY p2 ON r1 FOR INSERT WITH CHECK (true);
+ALTER TABLE r1 ENABLE ROW LEVEL SECURITY;
+ALTER TABLE r1 FORCE ROW LEVEL SECURITY;
+-- Works fine
+INSERT INTO r1 VALUES (10), (20);
+-- No error, but no rows
+TABLE r1;
+ a 
+---
+(0 rows)
+
+SET row_security = off;
+-- fail, would be affected by RLS
+TABLE r1;
+ERROR:  query would be affected by row-level security policy for table "r1"
+HINT:  To disable the policy for the table's owner, use ALTER TABLE NO FORCE ROW LEVEL SECURITY.
+SET row_security = on;
+-- Error
+INSERT INTO r1 VALUES (10), (20) RETURNING *;
+ERROR:  new row violates row-level security policy for table "r1"
+DROP TABLE r1;
+--
+-- Test UPDATE+RETURNING applies SELECT policies as
+-- WithCheckOptions (meaning an error is thrown)
+--
+SET SESSION AUTHORIZATION regress_rls_alice;
+SET row_security = on;
+CREATE TABLE r1 (a int PRIMARY KEY);
+CREATE POLICY p1 ON r1 FOR SELECT USING (a < 20);
+CREATE POLICY p2 ON r1 FOR UPDATE USING (a < 20) WITH CHECK (true);
+CREATE POLICY p3 ON r1 FOR INSERT WITH CHECK (true);
+INSERT INTO r1 VALUES (10);
+ALTER TABLE r1 ENABLE ROW LEVEL SECURITY;
+ALTER TABLE r1 FORCE ROW LEVEL SECURITY;
+-- Works fine
+UPDATE r1 SET a = 30;
+-- Show updated rows
+ALTER TABLE r1 NO FORCE ROW LEVEL SECURITY;
+TABLE r1;
+ a  
+----
+ 30
+(1 row)
+
+-- reset value in r1 for test with RETURNING
+UPDATE r1 SET a = 10;
+-- Verify row reset
+TABLE r1;
+ a  
+----
+ 10
+(1 row)
+
+ALTER TABLE r1 FORCE ROW LEVEL SECURITY;
+-- Error
+UPDATE r1 SET a = 30 RETURNING *;
+ERROR:  new row violates row-level security policy for table "r1"
+-- UPDATE path of INSERT ... ON CONFLICT DO UPDATE should also error out
+INSERT INTO r1 VALUES (10)
+    ON CONFLICT (a) DO UPDATE SET a = 30 RETURNING *;
+ERROR:  new row violates row-level security policy for table "r1"
+-- Should still error out without RETURNING (use of arbiter always requires
+-- SELECT permissions)
+INSERT INTO r1 VALUES (10)
+    ON CONFLICT (a) DO UPDATE SET a = 30;
+ERROR:  new row violates row-level security policy for table "r1"
+INSERT INTO r1 VALUES (10)
+    ON CONFLICT ON CONSTRAINT r1_pkey DO UPDATE SET a = 30;
+ERROR:  new row violates row-level security policy for table "r1"
+DROP TABLE r1;
+-- Check dependency handling
+RESET SESSION AUTHORIZATION;
+CREATE TABLE dep1 (c1 int);
+CREATE TABLE dep2 (c1 int);
+CREATE POLICY dep_p1 ON dep1 TO regress_rls_bob USING (c1 > (select max(dep2.c1) from dep2));
+ALTER POLICY dep_p1 ON dep1 TO regress_rls_bob,regress_rls_carol;
+-- Should return one
+SELECT count(*) = 1 FROM pg_depend
+				   WHERE objid = (SELECT oid FROM pg_policy WHERE polname = 'dep_p1')
+					 AND refobjid = (SELECT oid FROM pg_class WHERE relname = 'dep2');
+ ?column? 
+----------
+ t
+(1 row)
+
+ALTER POLICY dep_p1 ON dep1 USING (true);
+-- Should return one
+SELECT count(*) = 1 FROM pg_shdepend
+				   WHERE objid = (SELECT oid FROM pg_policy WHERE polname = 'dep_p1')
+					 AND refobjid = (SELECT oid FROM pg_authid WHERE rolname = 'regress_rls_bob');
+ ?column? 
+----------
+ t
+(1 row)
+
+-- Should return one
+SELECT count(*) = 1 FROM pg_shdepend
+				   WHERE objid = (SELECT oid FROM pg_policy WHERE polname = 'dep_p1')
+					 AND refobjid = (SELECT oid FROM pg_authid WHERE rolname = 'regress_rls_carol');
+ ?column? 
+----------
+ t
+(1 row)
+
+-- Should return zero
+SELECT count(*) = 0 FROM pg_depend
+				   WHERE objid = (SELECT oid FROM pg_policy WHERE polname = 'dep_p1')
+					 AND refobjid = (SELECT oid FROM pg_class WHERE relname = 'dep2');
+ ?column? 
+----------
+ t
+(1 row)
+
+-- DROP OWNED BY testing
+RESET SESSION AUTHORIZATION;
+CREATE ROLE regress_rls_dob_role1;
+CREATE ROLE regress_rls_dob_role2;
+CREATE TABLE dob_t1 (c1 int);
+CREATE TABLE dob_t2 (c1 int) PARTITION BY RANGE (c1);
+CREATE POLICY p1 ON dob_t1 TO regress_rls_dob_role1 USING (true);
+DROP OWNED BY regress_rls_dob_role1;
+DROP POLICY p1 ON dob_t1; -- should fail, already gone
+ERROR:  policy "p1" for table "dob_t1" does not exist
+CREATE POLICY p1 ON dob_t1 TO regress_rls_dob_role1,regress_rls_dob_role2 USING (true);
+DROP OWNED BY regress_rls_dob_role1;
+DROP POLICY p1 ON dob_t1; -- should succeed
+CREATE POLICY p1 ON dob_t2 TO regress_rls_dob_role1,regress_rls_dob_role2 USING (true);
+DROP OWNED BY regress_rls_dob_role1;
+DROP POLICY p1 ON dob_t2; -- should succeed
+DROP USER regress_rls_dob_role1;
+DROP USER regress_rls_dob_role2;
+-- Bug #15708: view + table with RLS should check policies as view owner
+CREATE TABLE ref_tbl (a int);
+INSERT INTO ref_tbl VALUES (1);
+CREATE TABLE rls_tbl (a int);
+INSERT INTO rls_tbl VALUES (10);
+ALTER TABLE rls_tbl ENABLE ROW LEVEL SECURITY;
+CREATE POLICY p1 ON rls_tbl USING (EXISTS (SELECT 1 FROM ref_tbl));
+GRANT SELECT ON ref_tbl TO regress_rls_bob;
+GRANT SELECT ON rls_tbl TO regress_rls_bob;
+CREATE VIEW rls_view AS SELECT * FROM rls_tbl;
+ALTER VIEW rls_view OWNER TO regress_rls_bob;
+GRANT SELECT ON rls_view TO regress_rls_alice;
+SET SESSION AUTHORIZATION regress_rls_alice;
+SELECT * FROM ref_tbl; -- Permission denied
+ERROR:  permission denied for table ref_tbl
+SELECT * FROM rls_tbl; -- Permission denied
+ERROR:  permission denied for table rls_tbl
+SELECT * FROM rls_view; -- OK
+ a  
+----
+ 10
+(1 row)
+
+SELECT * FROM f_leak_table ORDER BY a;
+ a 
+---
+(0 rows)
+
+TRUNCATE TABLE f_leak_table;
+RESET SESSION AUTHORIZATION;
+DROP VIEW rls_view;
+DROP TABLE rls_tbl;
+DROP TABLE ref_tbl;
+-- Leaky operator test
+CREATE TABLE rls_tbl (a int);
+INSERT INTO rls_tbl SELECT x/10 FROM generate_series(1, 100) x;
+ANALYZE rls_tbl;
+ALTER TABLE rls_tbl ENABLE ROW LEVEL SECURITY;
+GRANT SELECT ON rls_tbl TO regress_rls_alice;
+SET SESSION AUTHORIZATION regress_rls_alice;
+CREATE FUNCTION op_leak(int, int) RETURNS bool
+    AS 'BEGIN RAISE NOTICE ''op_leak => %, %'', $1, $2; RETURN $1 < $2; END'
+    LANGUAGE plpgsql;
+CREATE OPERATOR <<< (procedure = op_leak, leftarg = int, rightarg = int,
+                     restrict = scalarltsel);
+SELECT * FROM rls_tbl WHERE a <<< 1000;
+ a 
+---
+(0 rows)
+
+DROP OPERATOR <<< (int, int);
+DROP FUNCTION op_leak(int, int);
+RESET SESSION AUTHORIZATION;
+DROP TABLE rls_tbl;
+--
+-- Clean up objects
+--
+RESET SESSION AUTHORIZATION;
+DROP SCHEMA regress_rls_schema CASCADE;
+NOTICE:  drop cascades to 29 other objects
+DETAIL:  drop cascades to function f_leak(text)
+drop cascades to table uaccount
+drop cascades to table category
+drop cascades to table document
+drop cascades to table part_document
+drop cascades to table dependent
+drop cascades to table rec1
+drop cascades to table rec2
+drop cascades to view rec1v
+drop cascades to view rec2v
+drop cascades to table s1
+drop cascades to table s2
+drop cascades to view v2
+drop cascades to table b1
+drop cascades to view bv1
+drop cascades to table z1
+drop cascades to table z2
+drop cascades to table x1
+drop cascades to table y1
+drop cascades to table y2
+drop cascades to table t1
+drop cascades to table t2
+drop cascades to table t3
+drop cascades to table t4
+drop cascades to table current_check
+drop cascades to table dep1
+drop cascades to table dep2
+drop cascades to table dob_t1
+drop cascades to table dob_t2
+DROP USER regress_rls_alice;
+DROP USER regress_rls_bob;
+DROP USER regress_rls_carol;
+DROP USER regress_rls_dave;
+DROP USER regress_rls_exempt_user;
+DROP ROLE regress_rls_group1;
+DROP ROLE regress_rls_group2;
+-- Arrange to have a few policies left over, for testing
+-- pg_dump/pg_restore
+CREATE SCHEMA regress_rls_schema;
+CREATE TABLE rls_tbl (c1 int);
+ALTER TABLE rls_tbl ENABLE ROW LEVEL SECURITY;
+CREATE POLICY p1 ON rls_tbl USING (c1 > 5);
+CREATE POLICY p2 ON rls_tbl FOR SELECT USING (c1 <= 3);
+CREATE POLICY p3 ON rls_tbl FOR UPDATE USING (c1 <= 3) WITH CHECK (c1 > 5);
+CREATE POLICY p4 ON rls_tbl FOR DELETE USING (c1 <= 3);
+CREATE TABLE rls_tbl_force (c1 int);
+ALTER TABLE rls_tbl_force ENABLE ROW LEVEL SECURITY;
+ALTER TABLE rls_tbl_force FORCE ROW LEVEL SECURITY;
+CREATE POLICY p1 ON rls_tbl_force USING (c1 = 5) WITH CHECK (c1 < 5);
+CREATE POLICY p2 ON rls_tbl_force FOR SELECT USING (c1 = 8);
+CREATE POLICY p3 ON rls_tbl_force FOR UPDATE USING (c1 = 8) WITH CHECK (c1 >= 5);
+CREATE POLICY p4 ON rls_tbl_force FOR DELETE USING (c1 = 8);
diff --git a/src/test/regress/expected/rules.out b/src/test/regress/expected/rules.out
index 7098461..92fe829 100644
--- a/src/test/regress/expected/rules.out
+++ b/src/test/regress/expected/rules.out
@@ -250,29 +250,29 @@ select * from rtest_v1;
 
 -- now updates with constant expression
 update rtest_v1 set b = 42 where a = 2;
-select * from rtest_v1;
+select * from rtest_v1 order by a;
  a | b  
 ---+----
  1 | 21
- 3 | 23
  2 | 42
+ 3 | 23
 (3 rows)
 
 update rtest_v1 set b = 99 where b = 42;
-select * from rtest_v1;
+select * from rtest_v1 order by a;
  a | b  
 ---+----
  1 | 21
- 3 | 23
  2 | 99
+ 3 | 23
 (3 rows)
 
 update rtest_v1 set b = 88 where b < 50;
-select * from rtest_v1;
+select * from rtest_v1 order by a;
  a | b  
 ---+----
- 2 | 99
  1 | 88
+ 2 | 99
  3 | 88
 (3 rows)
 
@@ -290,7 +290,7 @@ select * from rtest_v1;
 
 -- updates in a mergejoin
 update rtest_v1 set b = rtest_t2.b from rtest_t2 where rtest_v1.a = rtest_t2.a;
-select * from rtest_v1;
+select * from rtest_v1 order by a;
  a | b  
 ---+----
  1 | 21
@@ -299,21 +299,21 @@ select * from rtest_v1;
 (3 rows)
 
 insert into rtest_v1 select * from rtest_t3;
-select * from rtest_v1;
+select * from rtest_v1 order by a, b;
  a | b  
 ---+----
  1 | 21
- 2 | 22
- 3 | 23
  1 | 31
+ 2 | 22
  2 | 32
+ 3 | 23
  3 | 33
  4 | 34
  5 | 35
 (8 rows)
 
 update rtest_t1 set a = a + 10 where b > 30;
-select * from rtest_v1;
+select * from rtest_v1 order by a;
  a  | b  
 ----+----
   1 | 21
@@ -327,7 +327,7 @@ select * from rtest_v1;
 (8 rows)
 
 update rtest_v1 set a = rtest_t3.a + 20 from rtest_t3 where rtest_v1.b = rtest_t3.b;
-select * from rtest_v1;
+select * from rtest_v1 order by a, b;
  a  | b  
 ----+----
   1 | 21
@@ -393,7 +393,7 @@ select * from rtest_interface;
  pluto   | eth0
 (2 rows)
 
-select * from rtest_admin;
+select * from rtest_admin order by pname, sysname;
  pname  | sysname 
 --------+---------
  bm     | pluto
@@ -2795,17 +2795,17 @@ select * from only t1;
 ---
 (0 rows)
 
-select * from only t1_1;
+select * from only t1_1 order by a;
  a 
 ---
+ 4
  6
  7
  8
  9
- 4
 (5 rows)
 
-select * from only t1_2;
+select * from only t1_2 order by a;
  a  
 ----
  10
diff --git a/src/test/regress/expected/rules_1.out b/src/test/regress/expected/rules_1.out
new file mode 100644
index 0000000..4f309e6
--- /dev/null
+++ b/src/test/regress/expected/rules_1.out
@@ -0,0 +1,3309 @@
+--
+-- RULES
+-- From Jan's original setup_ruletest.sql and run_ruletest.sql
+-- - thomas 1998-09-13
+--
+--
+-- Tables and rules for the view test
+--
+create table rtest_t1 (a int4, b int4);
+create table rtest_t2 (a int4, b int4);
+create table rtest_t3 (a int4, b int4);
+create view rtest_v1 as select * from rtest_t1;
+create rule rtest_v1_ins as on insert to rtest_v1 do instead
+	insert into rtest_t1 values (new.a, new.b);
+create rule rtest_v1_upd as on update to rtest_v1 do instead
+	update rtest_t1 set a = new.a, b = new.b
+	where a = old.a;
+create rule rtest_v1_del as on delete to rtest_v1 do instead
+	delete from rtest_t1 where a = old.a;
+-- Test comments
+COMMENT ON RULE rtest_v1_bad ON rtest_v1 IS 'bad rule';
+ERROR:  rule "rtest_v1_bad" for relation "rtest_v1" does not exist
+COMMENT ON RULE rtest_v1_del ON rtest_v1 IS 'delete rule';
+COMMENT ON RULE rtest_v1_del ON rtest_v1 IS NULL;
+--
+-- Tables and rules for the constraint update/delete test
+--
+-- Note:
+-- 	Now that we have multiple action rule support, we check
+-- 	both possible syntaxes to define them (The last action
+--  can but must not have a semicolon at the end).
+--
+create table rtest_system (sysname text, sysdesc text);
+create table rtest_interface (sysname text, ifname text);
+create table rtest_person (pname text, pdesc text);
+create table rtest_admin (pname text, sysname text);
+create rule rtest_sys_upd as on update to rtest_system do also (
+	update rtest_interface set sysname = new.sysname
+		where sysname = old.sysname;
+	update rtest_admin set sysname = new.sysname
+		where sysname = old.sysname
+	);
+create rule rtest_sys_del as on delete to rtest_system do also (
+	delete from rtest_interface where sysname = old.sysname;
+	delete from rtest_admin where sysname = old.sysname;
+	);
+create rule rtest_pers_upd as on update to rtest_person do also
+	update rtest_admin set pname = new.pname where pname = old.pname;
+create rule rtest_pers_del as on delete to rtest_person do also
+	delete from rtest_admin where pname = old.pname;
+--
+-- Tables and rules for the logging test
+--
+create table rtest_emp (ename char(20), salary money);
+create table rtest_emplog (ename char(20), who name, action char(10), newsal money, oldsal money);
+create table rtest_empmass (ename char(20), salary money);
+create rule rtest_emp_ins as on insert to rtest_emp do
+	insert into rtest_emplog values (new.ename, current_user,
+			'hired', new.salary, '0.00');
+create rule rtest_emp_upd as on update to rtest_emp where new.salary != old.salary do
+	insert into rtest_emplog values (new.ename, current_user,
+			'honored', new.salary, old.salary);
+create rule rtest_emp_del as on delete to rtest_emp do
+	insert into rtest_emplog values (old.ename, current_user,
+			'fired', '0.00', old.salary);
+--
+-- Tables and rules for the multiple cascaded qualified instead
+-- rule test
+--
+create table rtest_t4 (a int4, b text);
+create table rtest_t5 (a int4, b text);
+create table rtest_t6 (a int4, b text);
+create table rtest_t7 (a int4, b text);
+create table rtest_t8 (a int4, b text);
+create table rtest_t9 (a int4, b text);
+create rule rtest_t4_ins1 as on insert to rtest_t4
+		where new.a >= 10 and new.a < 20 do instead
+	insert into rtest_t5 values (new.a, new.b);
+create rule rtest_t4_ins2 as on insert to rtest_t4
+		where new.a >= 20 and new.a < 30 do
+	insert into rtest_t6 values (new.a, new.b);
+create rule rtest_t5_ins as on insert to rtest_t5
+		where new.a > 15 do
+	insert into rtest_t7 values (new.a, new.b);
+create rule rtest_t6_ins as on insert to rtest_t6
+		where new.a > 25 do instead
+	insert into rtest_t8 values (new.a, new.b);
+--
+-- Tables and rules for the rule fire order test
+--
+-- As of PG 7.3, the rules should fire in order by name, regardless
+-- of INSTEAD attributes or creation order.
+--
+create table rtest_order1 (a int4);
+create table rtest_order2 (a int4, b int4, c text);
+create sequence rtest_seq;
+create rule rtest_order_r3 as on insert to rtest_order1 do instead
+	insert into rtest_order2 values (new.a, nextval('rtest_seq'),
+		'rule 3 - this should run 3rd');
+create rule rtest_order_r4 as on insert to rtest_order1
+		where a < 100 do instead
+	insert into rtest_order2 values (new.a, nextval('rtest_seq'),
+		'rule 4 - this should run 4th');
+create rule rtest_order_r2 as on insert to rtest_order1 do
+	insert into rtest_order2 values (new.a, nextval('rtest_seq'),
+		'rule 2 - this should run 2nd');
+create rule rtest_order_r1 as on insert to rtest_order1 do instead
+	insert into rtest_order2 values (new.a, nextval('rtest_seq'),
+		'rule 1 - this should run 1st');
+--
+-- Tables and rules for the instead nothing test
+--
+create table rtest_nothn1 (a int4, b text);
+create table rtest_nothn2 (a int4, b text);
+create table rtest_nothn3 (a int4, b text);
+create table rtest_nothn4 (a int4, b text);
+create rule rtest_nothn_r1 as on insert to rtest_nothn1
+	where new.a >= 10 and new.a < 20 do instead nothing;
+create rule rtest_nothn_r2 as on insert to rtest_nothn1
+	where new.a >= 30 and new.a < 40 do instead nothing;
+create rule rtest_nothn_r3 as on insert to rtest_nothn2
+	where new.a >= 100 do instead
+	insert into rtest_nothn3 values (new.a, new.b);
+create rule rtest_nothn_r4 as on insert to rtest_nothn2
+	do instead nothing;
+--
+-- Tests on a view that is select * of a table
+-- and has insert/update/delete instead rules to
+-- behave close like the real table.
+--
+--
+-- We need test date later
+--
+insert into rtest_t2 values (1, 21);
+insert into rtest_t2 values (2, 22);
+insert into rtest_t2 values (3, 23);
+insert into rtest_t3 values (1, 31);
+insert into rtest_t3 values (2, 32);
+insert into rtest_t3 values (3, 33);
+insert into rtest_t3 values (4, 34);
+insert into rtest_t3 values (5, 35);
+-- insert values
+insert into rtest_v1 values (1, 11);
+insert into rtest_v1 values (2, 12);
+select * from rtest_v1;
+ a | b  
+---+----
+ 1 | 11
+ 2 | 12
+(2 rows)
+
+-- delete with constant expression
+delete from rtest_v1 where a = 1;
+select * from rtest_v1;
+ a | b  
+---+----
+ 2 | 12
+(1 row)
+
+insert into rtest_v1 values (1, 11);
+delete from rtest_v1 where b = 12;
+select * from rtest_v1;
+ a | b  
+---+----
+ 1 | 11
+(1 row)
+
+insert into rtest_v1 values (2, 12);
+insert into rtest_v1 values (2, 13);
+select * from rtest_v1;
+ a | b  
+---+----
+ 1 | 11
+ 2 | 12
+ 2 | 13
+(3 rows)
+
+** Remember the delete rule on rtest_v1: It says
+** DO INSTEAD DELETE FROM rtest_t1 WHERE a = old.a
+** So this time both rows with a = 2 must get deleted
+\p
+** Remember the delete rule on rtest_v1: It says
+** DO INSTEAD DELETE FROM rtest_t1 WHERE a = old.a
+** So this time both rows with a = 2 must get deleted
+\r
+delete from rtest_v1 where b = 12;
+select * from rtest_v1;
+ a | b  
+---+----
+ 1 | 11
+(1 row)
+
+delete from rtest_v1;
+-- insert select
+insert into rtest_v1 select * from rtest_t2;
+select * from rtest_v1;
+ a | b  
+---+----
+ 1 | 21
+ 2 | 22
+ 3 | 23
+(3 rows)
+
+delete from rtest_v1;
+-- same with swapped targetlist
+insert into rtest_v1 (b, a) select b, a from rtest_t2;
+select * from rtest_v1;
+ a | b  
+---+----
+ 1 | 21
+ 2 | 22
+ 3 | 23
+(3 rows)
+
+-- now with only one target attribute
+insert into rtest_v1 (a) select a from rtest_t3;
+select * from rtest_v1;
+ a | b  
+---+----
+ 1 | 21
+ 2 | 22
+ 3 | 23
+ 1 |   
+ 2 |   
+ 3 |   
+ 4 |   
+ 5 |   
+(8 rows)
+
+select * from rtest_v1 where b isnull;
+ a | b 
+---+---
+ 1 |  
+ 2 |  
+ 3 |  
+ 4 |  
+ 5 |  
+(5 rows)
+
+-- let attribute a differ (must be done on rtest_t1 - see above)
+update rtest_t1 set a = a + 10 where b isnull;
+delete from rtest_v1 where b isnull;
+select * from rtest_v1;
+ a | b  
+---+----
+ 1 | 21
+ 2 | 22
+ 3 | 23
+(3 rows)
+
+-- now updates with constant expression
+update rtest_v1 set b = 42 where a = 2;
+select * from rtest_v1 order by a;
+ a | b  
+---+----
+ 1 | 21
+ 2 | 42
+ 3 | 23
+(3 rows)
+
+update rtest_v1 set b = 99 where b = 42;
+select * from rtest_v1 order by a;
+ a | b  
+---+----
+ 1 | 21
+ 2 | 99
+ 3 | 23
+(3 rows)
+
+update rtest_v1 set b = 88 where b < 50;
+select * from rtest_v1 order by a;
+ a | b  
+---+----
+ 1 | 88
+ 2 | 99
+ 3 | 88
+(3 rows)
+
+delete from rtest_v1;
+insert into rtest_v1 select rtest_t2.a, rtest_t3.b
+    from rtest_t2, rtest_t3
+    where rtest_t2.a = rtest_t3.a;
+select * from rtest_v1;
+ a | b  
+---+----
+ 1 | 31
+ 2 | 32
+ 3 | 33
+(3 rows)
+
+-- updates in a mergejoin
+update rtest_v1 set b = rtest_t2.b from rtest_t2 where rtest_v1.a = rtest_t2.a;
+select * from rtest_v1 order by a;
+ a | b  
+---+----
+ 1 | 21
+ 2 | 22
+ 3 | 23
+(3 rows)
+
+insert into rtest_v1 select * from rtest_t3;
+select * from rtest_v1 order by a, b;
+ a | b  
+---+----
+ 1 | 21
+ 1 | 31
+ 2 | 22
+ 2 | 32
+ 3 | 23
+ 3 | 33
+ 4 | 34
+ 5 | 35
+(8 rows)
+
+update rtest_t1 set a = a + 10 where b > 30;
+select * from rtest_v1 order by a;
+ a  | b  
+----+----
+  1 | 21
+  2 | 22
+  3 | 23
+ 11 | 31
+ 12 | 32
+ 13 | 33
+ 14 | 34
+ 15 | 35
+(8 rows)
+
+update rtest_v1 set a = rtest_t3.a + 20 from rtest_t3 where rtest_v1.b = rtest_t3.b;
+select * from rtest_v1 order by a, b;
+ a  | b  
+----+----
+  1 | 21
+  2 | 22
+  3 | 23
+ 21 | 31
+ 22 | 32
+ 23 | 33
+ 24 | 34
+ 25 | 35
+(8 rows)
+
+--
+-- Test for constraint updates/deletes
+--
+insert into rtest_system values ('orion', 'Linux Jan Wieck');
+insert into rtest_system values ('notjw', 'WinNT Jan Wieck (notebook)');
+insert into rtest_system values ('neptun', 'Fileserver');
+insert into rtest_interface values ('orion', 'eth0');
+insert into rtest_interface values ('orion', 'eth1');
+insert into rtest_interface values ('notjw', 'eth0');
+insert into rtest_interface values ('neptun', 'eth0');
+insert into rtest_person values ('jw', 'Jan Wieck');
+insert into rtest_person values ('bm', 'Bruce Momjian');
+insert into rtest_admin values ('jw', 'orion');
+insert into rtest_admin values ('jw', 'notjw');
+insert into rtest_admin values ('bm', 'neptun');
+update rtest_system set sysname = 'pluto' where sysname = 'neptun';
+select * from rtest_interface;
+ sysname | ifname 
+---------+--------
+ orion   | eth0
+ orion   | eth1
+ notjw   | eth0
+ pluto   | eth0
+(4 rows)
+
+select * from rtest_admin;
+ pname | sysname 
+-------+---------
+ jw    | orion
+ jw    | notjw
+ bm    | pluto
+(3 rows)
+
+update rtest_person set pname = 'jwieck' where pdesc = 'Jan Wieck';
+-- Note: use ORDER BY here to ensure consistent output across all systems.
+-- The above UPDATE affects two rows with equal keys, so they could be
+-- updated in either order depending on the whim of the local qsort().
+select * from rtest_admin order by pname, sysname;
+ pname  | sysname 
+--------+---------
+ bm     | pluto
+ jwieck | notjw
+ jwieck | orion
+(3 rows)
+
+delete from rtest_system where sysname = 'orion';
+select * from rtest_interface;
+ sysname | ifname 
+---------+--------
+ notjw   | eth0
+ pluto   | eth0
+(2 rows)
+
+select * from rtest_admin order by pname, sysname;
+ pname  | sysname 
+--------+---------
+ bm     | pluto
+ jwieck | notjw
+(2 rows)
+
+--
+-- Rule qualification test
+--
+insert into rtest_emp values ('wiecc', '5000.00');
+insert into rtest_emp values ('gates', '80000.00');
+update rtest_emp set ename = 'wiecx' where ename = 'wiecc';
+update rtest_emp set ename = 'wieck', salary = '6000.00' where ename = 'wiecx';
+update rtest_emp set salary = '7000.00' where ename = 'wieck';
+delete from rtest_emp where ename = 'gates';
+select ename, who = current_user as "matches user", action, newsal, oldsal from rtest_emplog order by ename, action, newsal;
+        ename         | matches user |   action   |   newsal   |   oldsal   
+----------------------+--------------+------------+------------+------------
+ gates                | t            | fired      |      $0.00 | $80,000.00
+ gates                | t            | hired      | $80,000.00 |      $0.00
+ wiecc                | t            | hired      |  $5,000.00 |      $0.00
+ wieck                | t            | honored    |  $6,000.00 |  $5,000.00
+ wieck                | t            | honored    |  $7,000.00 |  $6,000.00
+(5 rows)
+
+insert into rtest_empmass values ('meyer', '4000.00');
+insert into rtest_empmass values ('maier', '5000.00');
+insert into rtest_empmass values ('mayr', '6000.00');
+insert into rtest_emp select * from rtest_empmass;
+select ename, who = current_user as "matches user", action, newsal, oldsal from rtest_emplog order by ename, action, newsal;
+        ename         | matches user |   action   |   newsal   |   oldsal   
+----------------------+--------------+------------+------------+------------
+ gates                | t            | fired      |      $0.00 | $80,000.00
+ gates                | t            | hired      | $80,000.00 |      $0.00
+ maier                | t            | hired      |  $5,000.00 |      $0.00
+ mayr                 | t            | hired      |  $6,000.00 |      $0.00
+ meyer                | t            | hired      |  $4,000.00 |      $0.00
+ wiecc                | t            | hired      |  $5,000.00 |      $0.00
+ wieck                | t            | honored    |  $6,000.00 |  $5,000.00
+ wieck                | t            | honored    |  $7,000.00 |  $6,000.00
+(8 rows)
+
+update rtest_empmass set salary = salary + '1000.00';
+update rtest_emp set salary = rtest_empmass.salary from rtest_empmass where rtest_emp.ename = rtest_empmass.ename;
+select ename, who = current_user as "matches user", action, newsal, oldsal from rtest_emplog order by ename, action, newsal;
+        ename         | matches user |   action   |   newsal   |   oldsal   
+----------------------+--------------+------------+------------+------------
+ gates                | t            | fired      |      $0.00 | $80,000.00
+ gates                | t            | hired      | $80,000.00 |      $0.00
+ maier                | t            | hired      |  $5,000.00 |      $0.00
+ maier                | t            | honored    |  $6,000.00 |  $5,000.00
+ mayr                 | t            | hired      |  $6,000.00 |      $0.00
+ mayr                 | t            | honored    |  $7,000.00 |  $6,000.00
+ meyer                | t            | hired      |  $4,000.00 |      $0.00
+ meyer                | t            | honored    |  $5,000.00 |  $4,000.00
+ wiecc                | t            | hired      |  $5,000.00 |      $0.00
+ wieck                | t            | honored    |  $6,000.00 |  $5,000.00
+ wieck                | t            | honored    |  $7,000.00 |  $6,000.00
+(11 rows)
+
+delete from rtest_emp using rtest_empmass where rtest_emp.ename = rtest_empmass.ename;
+select ename, who = current_user as "matches user", action, newsal, oldsal from rtest_emplog order by ename, action, newsal;
+        ename         | matches user |   action   |   newsal   |   oldsal   
+----------------------+--------------+------------+------------+------------
+ gates                | t            | fired      |      $0.00 | $80,000.00
+ gates                | t            | hired      | $80,000.00 |      $0.00
+ maier                | t            | fired      |      $0.00 |  $6,000.00
+ maier                | t            | hired      |  $5,000.00 |      $0.00
+ maier                | t            | honored    |  $6,000.00 |  $5,000.00
+ mayr                 | t            | fired      |      $0.00 |  $7,000.00
+ mayr                 | t            | hired      |  $6,000.00 |      $0.00
+ mayr                 | t            | honored    |  $7,000.00 |  $6,000.00
+ meyer                | t            | fired      |      $0.00 |  $5,000.00
+ meyer                | t            | hired      |  $4,000.00 |      $0.00
+ meyer                | t            | honored    |  $5,000.00 |  $4,000.00
+ wiecc                | t            | hired      |  $5,000.00 |      $0.00
+ wieck                | t            | honored    |  $6,000.00 |  $5,000.00
+ wieck                | t            | honored    |  $7,000.00 |  $6,000.00
+(14 rows)
+
+--
+-- Multiple cascaded qualified instead rule test
+--
+insert into rtest_t4 values (1, 'Record should go to rtest_t4');
+insert into rtest_t4 values (2, 'Record should go to rtest_t4');
+insert into rtest_t4 values (10, 'Record should go to rtest_t5');
+insert into rtest_t4 values (15, 'Record should go to rtest_t5');
+insert into rtest_t4 values (19, 'Record should go to rtest_t5 and t7');
+insert into rtest_t4 values (20, 'Record should go to rtest_t4 and t6');
+insert into rtest_t4 values (26, 'Record should go to rtest_t4 and t8');
+insert into rtest_t4 values (28, 'Record should go to rtest_t4 and t8');
+insert into rtest_t4 values (30, 'Record should go to rtest_t4');
+insert into rtest_t4 values (40, 'Record should go to rtest_t4');
+select * from rtest_t4;
+ a  |                  b                  
+----+-------------------------------------
+  1 | Record should go to rtest_t4
+  2 | Record should go to rtest_t4
+ 20 | Record should go to rtest_t4 and t6
+ 26 | Record should go to rtest_t4 and t8
+ 28 | Record should go to rtest_t4 and t8
+ 30 | Record should go to rtest_t4
+ 40 | Record should go to rtest_t4
+(7 rows)
+
+select * from rtest_t5;
+ a  |                  b                  
+----+-------------------------------------
+ 10 | Record should go to rtest_t5
+ 15 | Record should go to rtest_t5
+ 19 | Record should go to rtest_t5 and t7
+(3 rows)
+
+select * from rtest_t6;
+ a  |                  b                  
+----+-------------------------------------
+ 20 | Record should go to rtest_t4 and t6
+(1 row)
+
+select * from rtest_t7;
+ a  |                  b                  
+----+-------------------------------------
+ 19 | Record should go to rtest_t5 and t7
+(1 row)
+
+select * from rtest_t8;
+ a  |                  b                  
+----+-------------------------------------
+ 26 | Record should go to rtest_t4 and t8
+ 28 | Record should go to rtest_t4 and t8
+(2 rows)
+
+delete from rtest_t4;
+delete from rtest_t5;
+delete from rtest_t6;
+delete from rtest_t7;
+delete from rtest_t8;
+insert into rtest_t9 values (1, 'Record should go to rtest_t4');
+insert into rtest_t9 values (2, 'Record should go to rtest_t4');
+insert into rtest_t9 values (10, 'Record should go to rtest_t5');
+insert into rtest_t9 values (15, 'Record should go to rtest_t5');
+insert into rtest_t9 values (19, 'Record should go to rtest_t5 and t7');
+insert into rtest_t9 values (20, 'Record should go to rtest_t4 and t6');
+insert into rtest_t9 values (26, 'Record should go to rtest_t4 and t8');
+insert into rtest_t9 values (28, 'Record should go to rtest_t4 and t8');
+insert into rtest_t9 values (30, 'Record should go to rtest_t4');
+insert into rtest_t9 values (40, 'Record should go to rtest_t4');
+insert into rtest_t4 select * from rtest_t9 where a < 20;
+select * from rtest_t4;
+ a |              b               
+---+------------------------------
+ 1 | Record should go to rtest_t4
+ 2 | Record should go to rtest_t4
+(2 rows)
+
+select * from rtest_t5;
+ a  |                  b                  
+----+-------------------------------------
+ 10 | Record should go to rtest_t5
+ 15 | Record should go to rtest_t5
+ 19 | Record should go to rtest_t5 and t7
+(3 rows)
+
+select * from rtest_t6;
+ a | b 
+---+---
+(0 rows)
+
+select * from rtest_t7;
+ a  |                  b                  
+----+-------------------------------------
+ 19 | Record should go to rtest_t5 and t7
+(1 row)
+
+select * from rtest_t8;
+ a | b 
+---+---
+(0 rows)
+
+insert into rtest_t4 select * from rtest_t9 where b ~ 'and t8';
+select * from rtest_t4;
+ a  |                  b                  
+----+-------------------------------------
+  1 | Record should go to rtest_t4
+  2 | Record should go to rtest_t4
+ 26 | Record should go to rtest_t4 and t8
+ 28 | Record should go to rtest_t4 and t8
+(4 rows)
+
+select * from rtest_t5;
+ a  |                  b                  
+----+-------------------------------------
+ 10 | Record should go to rtest_t5
+ 15 | Record should go to rtest_t5
+ 19 | Record should go to rtest_t5 and t7
+(3 rows)
+
+select * from rtest_t6;
+ a | b 
+---+---
+(0 rows)
+
+select * from rtest_t7;
+ a  |                  b                  
+----+-------------------------------------
+ 19 | Record should go to rtest_t5 and t7
+(1 row)
+
+select * from rtest_t8;
+ a  |                  b                  
+----+-------------------------------------
+ 26 | Record should go to rtest_t4 and t8
+ 28 | Record should go to rtest_t4 and t8
+(2 rows)
+
+insert into rtest_t4 select a + 1, b from rtest_t9 where a in (20, 30, 40);
+select * from rtest_t4;
+ a  |                  b                  
+----+-------------------------------------
+  1 | Record should go to rtest_t4
+  2 | Record should go to rtest_t4
+ 26 | Record should go to rtest_t4 and t8
+ 28 | Record should go to rtest_t4 and t8
+ 21 | Record should go to rtest_t4 and t6
+ 31 | Record should go to rtest_t4
+ 41 | Record should go to rtest_t4
+(7 rows)
+
+select * from rtest_t5;
+ a  |                  b                  
+----+-------------------------------------
+ 10 | Record should go to rtest_t5
+ 15 | Record should go to rtest_t5
+ 19 | Record should go to rtest_t5 and t7
+(3 rows)
+
+select * from rtest_t6;
+ a  |                  b                  
+----+-------------------------------------
+ 21 | Record should go to rtest_t4 and t6
+(1 row)
+
+select * from rtest_t7;
+ a  |                  b                  
+----+-------------------------------------
+ 19 | Record should go to rtest_t5 and t7
+(1 row)
+
+select * from rtest_t8;
+ a  |                  b                  
+----+-------------------------------------
+ 26 | Record should go to rtest_t4 and t8
+ 28 | Record should go to rtest_t4 and t8
+(2 rows)
+
+--
+-- Check that the ordering of rules fired is correct
+--
+insert into rtest_order1 values (1);
+select * from rtest_order2;
+ a | b |              c               
+---+---+------------------------------
+ 1 | 1 | rule 1 - this should run 1st
+ 1 | 2 | rule 2 - this should run 2nd
+ 1 | 3 | rule 3 - this should run 3rd
+ 1 | 4 | rule 4 - this should run 4th
+(4 rows)
+
+--
+-- Check if instead nothing w/without qualification works
+--
+insert into rtest_nothn1 values (1, 'want this');
+insert into rtest_nothn1 values (2, 'want this');
+insert into rtest_nothn1 values (10, 'don''t want this');
+insert into rtest_nothn1 values (19, 'don''t want this');
+insert into rtest_nothn1 values (20, 'want this');
+insert into rtest_nothn1 values (29, 'want this');
+insert into rtest_nothn1 values (30, 'don''t want this');
+insert into rtest_nothn1 values (39, 'don''t want this');
+insert into rtest_nothn1 values (40, 'want this');
+insert into rtest_nothn1 values (50, 'want this');
+insert into rtest_nothn1 values (60, 'want this');
+select * from rtest_nothn1;
+ a  |     b     
+----+-----------
+  1 | want this
+  2 | want this
+ 20 | want this
+ 29 | want this
+ 40 | want this
+ 50 | want this
+ 60 | want this
+(7 rows)
+
+insert into rtest_nothn2 values (10, 'too small');
+insert into rtest_nothn2 values (50, 'too small');
+insert into rtest_nothn2 values (100, 'OK');
+insert into rtest_nothn2 values (200, 'OK');
+select * from rtest_nothn2;
+ a | b 
+---+---
+(0 rows)
+
+select * from rtest_nothn3;
+  a  | b  
+-----+----
+ 100 | OK
+ 200 | OK
+(2 rows)
+
+delete from rtest_nothn1;
+delete from rtest_nothn2;
+delete from rtest_nothn3;
+insert into rtest_nothn4 values (1, 'want this');
+insert into rtest_nothn4 values (2, 'want this');
+insert into rtest_nothn4 values (10, 'don''t want this');
+insert into rtest_nothn4 values (19, 'don''t want this');
+insert into rtest_nothn4 values (20, 'want this');
+insert into rtest_nothn4 values (29, 'want this');
+insert into rtest_nothn4 values (30, 'don''t want this');
+insert into rtest_nothn4 values (39, 'don''t want this');
+insert into rtest_nothn4 values (40, 'want this');
+insert into rtest_nothn4 values (50, 'want this');
+insert into rtest_nothn4 values (60, 'want this');
+insert into rtest_nothn1 select * from rtest_nothn4;
+select * from rtest_nothn1;
+ a  |     b     
+----+-----------
+  1 | want this
+  2 | want this
+ 20 | want this
+ 29 | want this
+ 40 | want this
+ 50 | want this
+ 60 | want this
+(7 rows)
+
+delete from rtest_nothn4;
+insert into rtest_nothn4 values (10, 'too small');
+insert into rtest_nothn4 values (50, 'too small');
+insert into rtest_nothn4 values (100, 'OK');
+insert into rtest_nothn4 values (200, 'OK');
+insert into rtest_nothn2 select * from rtest_nothn4;
+select * from rtest_nothn2;
+ a | b 
+---+---
+(0 rows)
+
+select * from rtest_nothn3;
+  a  | b  
+-----+----
+ 100 | OK
+ 200 | OK
+(2 rows)
+
+create table rtest_view1 (a int4, b text, v bool);
+create table rtest_view2 (a int4);
+create table rtest_view3 (a int4, b text);
+create table rtest_view4 (a int4, b text, c int4);
+create view rtest_vview1 as select a, b from rtest_view1 X
+	where 0 < (select count(*) from rtest_view2 Y where Y.a = X.a);
+create view rtest_vview2 as select a, b from rtest_view1 where v;
+create view rtest_vview3 as select a, b from rtest_vview2 X
+	where 0 < (select count(*) from rtest_view2 Y where Y.a = X.a);
+create view rtest_vview4 as select X.a, X.b, count(Y.a) as refcount
+	from rtest_view1 X, rtest_view2 Y
+	where X.a = Y.a
+	group by X.a, X.b;
+create function rtest_viewfunc1(int4) returns int4 as
+	'select count(*)::int4 from rtest_view2 where a = $1'
+	language sql;
+create view rtest_vview5 as select a, b, rtest_viewfunc1(a) as refcount
+	from rtest_view1;
+insert into rtest_view1 values (1, 'item 1', 't');
+insert into rtest_view1 values (2, 'item 2', 't');
+insert into rtest_view1 values (3, 'item 3', 't');
+insert into rtest_view1 values (4, 'item 4', 'f');
+insert into rtest_view1 values (5, 'item 5', 't');
+insert into rtest_view1 values (6, 'item 6', 'f');
+insert into rtest_view1 values (7, 'item 7', 't');
+insert into rtest_view1 values (8, 'item 8', 't');
+insert into rtest_view2 values (2);
+insert into rtest_view2 values (2);
+insert into rtest_view2 values (4);
+insert into rtest_view2 values (5);
+insert into rtest_view2 values (7);
+insert into rtest_view2 values (7);
+insert into rtest_view2 values (7);
+insert into rtest_view2 values (7);
+select * from rtest_vview1;
+ a |   b    
+---+--------
+ 2 | item 2
+ 4 | item 4
+ 5 | item 5
+ 7 | item 7
+(4 rows)
+
+select * from rtest_vview2;
+ a |   b    
+---+--------
+ 1 | item 1
+ 2 | item 2
+ 3 | item 3
+ 5 | item 5
+ 7 | item 7
+ 8 | item 8
+(6 rows)
+
+select * from rtest_vview3;
+ a |   b    
+---+--------
+ 2 | item 2
+ 5 | item 5
+ 7 | item 7
+(3 rows)
+
+select * from rtest_vview4 order by a, b;
+ a |   b    | refcount 
+---+--------+----------
+ 2 | item 2 |        2
+ 4 | item 4 |        1
+ 5 | item 5 |        1
+ 7 | item 7 |        4
+(4 rows)
+
+select * from rtest_vview5;
+ a |   b    | refcount 
+---+--------+----------
+ 1 | item 1 |        0
+ 2 | item 2 |        2
+ 3 | item 3 |        0
+ 4 | item 4 |        1
+ 5 | item 5 |        1
+ 6 | item 6 |        0
+ 7 | item 7 |        4
+ 8 | item 8 |        0
+(8 rows)
+
+insert into rtest_view3 select * from rtest_vview1 where a < 7;
+select * from rtest_view3;
+ a |   b    
+---+--------
+ 2 | item 2
+ 4 | item 4
+ 5 | item 5
+(3 rows)
+
+delete from rtest_view3;
+insert into rtest_view3 select * from rtest_vview2 where a != 5 and b !~ '2';
+select * from rtest_view3;
+ a |   b    
+---+--------
+ 1 | item 1
+ 3 | item 3
+ 7 | item 7
+ 8 | item 8
+(4 rows)
+
+delete from rtest_view3;
+insert into rtest_view3 select * from rtest_vview3;
+select * from rtest_view3;
+ a |   b    
+---+--------
+ 2 | item 2
+ 5 | item 5
+ 7 | item 7
+(3 rows)
+
+delete from rtest_view3;
+insert into rtest_view4 select * from rtest_vview4 where 3 > refcount;
+select * from rtest_view4 order by a, b;
+ a |   b    | c 
+---+--------+---
+ 2 | item 2 | 2
+ 4 | item 4 | 1
+ 5 | item 5 | 1
+(3 rows)
+
+delete from rtest_view4;
+insert into rtest_view4 select * from rtest_vview5 where a > 2 and refcount = 0;
+select * from rtest_view4;
+ a |   b    | c 
+---+--------+---
+ 3 | item 3 | 0
+ 6 | item 6 | 0
+ 8 | item 8 | 0
+(3 rows)
+
+delete from rtest_view4;
+--
+-- Test for computations in views
+--
+create table rtest_comp (
+	part	text,
+	unit	char(4),
+	size	float
+);
+create table rtest_unitfact (
+	unit	char(4),
+	factor	float
+);
+create view rtest_vcomp as
+	select X.part, (X.size * Y.factor) as size_in_cm
+			from rtest_comp X, rtest_unitfact Y
+			where X.unit = Y.unit;
+insert into rtest_unitfact values ('m', 100.0);
+insert into rtest_unitfact values ('cm', 1.0);
+insert into rtest_unitfact values ('inch', 2.54);
+insert into rtest_comp values ('p1', 'm', 5.0);
+insert into rtest_comp values ('p2', 'm', 3.0);
+insert into rtest_comp values ('p3', 'cm', 5.0);
+insert into rtest_comp values ('p4', 'cm', 15.0);
+insert into rtest_comp values ('p5', 'inch', 7.0);
+insert into rtest_comp values ('p6', 'inch', 4.4);
+select * from rtest_vcomp order by part;
+ part | size_in_cm 
+------+------------
+ p1   |        500
+ p2   |        300
+ p3   |          5
+ p4   |         15
+ p5   |      17.78
+ p6   |     11.176
+(6 rows)
+
+select * from rtest_vcomp where size_in_cm > 10.0 order by size_in_cm using >;
+ part | size_in_cm 
+------+------------
+ p1   |        500
+ p2   |        300
+ p5   |      17.78
+ p4   |         15
+ p6   |     11.176
+(5 rows)
+
+--
+-- In addition run the (slightly modified) queries from the
+-- programmers manual section on the rule system.
+--
+CREATE TABLE shoe_data (
+	shoename   char(10),      -- primary key
+	sh_avail   integer,       -- available # of pairs
+	slcolor    char(10),      -- preferred shoelace color
+	slminlen   float,         -- minimum shoelace length
+	slmaxlen   float,         -- maximum shoelace length
+	slunit     char(8)        -- length unit
+);
+CREATE TABLE shoelace_data (
+	sl_name    char(10),      -- primary key
+	sl_avail   integer,       -- available # of pairs
+	sl_color   char(10),      -- shoelace color
+	sl_len     float,         -- shoelace length
+	sl_unit    char(8)        -- length unit
+);
+CREATE TABLE unit (
+	un_name    char(8),       -- the primary key
+	un_fact    float          -- factor to transform to cm
+);
+CREATE VIEW shoe AS
+	SELECT sh.shoename,
+		   sh.sh_avail,
+		   sh.slcolor,
+		   sh.slminlen,
+		   sh.slminlen * un.un_fact AS slminlen_cm,
+		   sh.slmaxlen,
+		   sh.slmaxlen * un.un_fact AS slmaxlen_cm,
+		   sh.slunit
+	  FROM shoe_data sh, unit un
+	 WHERE sh.slunit = un.un_name;
+CREATE VIEW shoelace AS
+	SELECT s.sl_name,
+		   s.sl_avail,
+		   s.sl_color,
+		   s.sl_len,
+		   s.sl_unit,
+		   s.sl_len * u.un_fact AS sl_len_cm
+	  FROM shoelace_data s, unit u
+	 WHERE s.sl_unit = u.un_name;
+CREATE VIEW shoe_ready AS
+	SELECT rsh.shoename,
+		   rsh.sh_avail,
+		   rsl.sl_name,
+		   rsl.sl_avail,
+		   int4smaller(rsh.sh_avail, rsl.sl_avail) AS total_avail
+	  FROM shoe rsh, shoelace rsl
+	 WHERE rsl.sl_color = rsh.slcolor
+	   AND rsl.sl_len_cm >= rsh.slminlen_cm
+	   AND rsl.sl_len_cm <= rsh.slmaxlen_cm;
+INSERT INTO unit VALUES ('cm', 1.0);
+INSERT INTO unit VALUES ('m', 100.0);
+INSERT INTO unit VALUES ('inch', 2.54);
+INSERT INTO shoe_data VALUES ('sh1', 2, 'black', 70.0, 90.0, 'cm');
+INSERT INTO shoe_data VALUES ('sh2', 0, 'black', 30.0, 40.0, 'inch');
+INSERT INTO shoe_data VALUES ('sh3', 4, 'brown', 50.0, 65.0, 'cm');
+INSERT INTO shoe_data VALUES ('sh4', 3, 'brown', 40.0, 50.0, 'inch');
+INSERT INTO shoelace_data VALUES ('sl1', 5, 'black', 80.0, 'cm');
+INSERT INTO shoelace_data VALUES ('sl2', 6, 'black', 100.0, 'cm');
+INSERT INTO shoelace_data VALUES ('sl3', 0, 'black', 35.0 , 'inch');
+INSERT INTO shoelace_data VALUES ('sl4', 8, 'black', 40.0 , 'inch');
+INSERT INTO shoelace_data VALUES ('sl5', 4, 'brown', 1.0 , 'm');
+INSERT INTO shoelace_data VALUES ('sl6', 0, 'brown', 0.9 , 'm');
+INSERT INTO shoelace_data VALUES ('sl7', 7, 'brown', 60 , 'cm');
+INSERT INTO shoelace_data VALUES ('sl8', 1, 'brown', 40 , 'inch');
+-- SELECTs in doc
+SELECT * FROM shoelace ORDER BY sl_name;
+  sl_name   | sl_avail |  sl_color  | sl_len | sl_unit  | sl_len_cm 
+------------+----------+------------+--------+----------+-----------
+ sl1        |        5 | black      |     80 | cm       |        80
+ sl2        |        6 | black      |    100 | cm       |       100
+ sl3        |        0 | black      |     35 | inch     |      88.9
+ sl4        |        8 | black      |     40 | inch     |     101.6
+ sl5        |        4 | brown      |      1 | m        |       100
+ sl6        |        0 | brown      |    0.9 | m        |        90
+ sl7        |        7 | brown      |     60 | cm       |        60
+ sl8        |        1 | brown      |     40 | inch     |     101.6
+(8 rows)
+
+SELECT * FROM shoe_ready WHERE total_avail >= 2 ORDER BY 1;
+  shoename  | sh_avail |  sl_name   | sl_avail | total_avail 
+------------+----------+------------+----------+-------------
+ sh1        |        2 | sl1        |        5 |           2
+ sh3        |        4 | sl7        |        7 |           4
+(2 rows)
+
+    CREATE TABLE shoelace_log (
+        sl_name    char(10),      -- shoelace changed
+        sl_avail   integer,       -- new available value
+        log_who    name,          -- who did it
+        log_when   timestamp      -- when
+    );
+-- Want "log_who" to be CURRENT_USER,
+-- but that is non-portable for the regression test
+-- - thomas 1999-02-21
+    CREATE RULE log_shoelace AS ON UPDATE TO shoelace_data
+        WHERE NEW.sl_avail != OLD.sl_avail
+        DO INSERT INTO shoelace_log VALUES (
+                                        NEW.sl_name,
+                                        NEW.sl_avail,
+                                        'Al Bundy',
+                                        'epoch'
+                                    );
+UPDATE shoelace_data SET sl_avail = 6 WHERE  sl_name = 'sl7';
+SELECT * FROM shoelace_log;
+  sl_name   | sl_avail | log_who  |         log_when         
+------------+----------+----------+--------------------------
+ sl7        |        6 | Al Bundy | Thu Jan 01 00:00:00 1970
+(1 row)
+
+    CREATE RULE shoelace_ins AS ON INSERT TO shoelace
+        DO INSTEAD
+        INSERT INTO shoelace_data VALUES (
+               NEW.sl_name,
+               NEW.sl_avail,
+               NEW.sl_color,
+               NEW.sl_len,
+               NEW.sl_unit);
+    CREATE RULE shoelace_upd AS ON UPDATE TO shoelace
+        DO INSTEAD
+        UPDATE shoelace_data SET
+               sl_name = NEW.sl_name,
+               sl_avail = NEW.sl_avail,
+               sl_color = NEW.sl_color,
+               sl_len = NEW.sl_len,
+               sl_unit = NEW.sl_unit
+         WHERE sl_name = OLD.sl_name;
+    CREATE RULE shoelace_del AS ON DELETE TO shoelace
+        DO INSTEAD
+        DELETE FROM shoelace_data
+         WHERE sl_name = OLD.sl_name;
+    CREATE TABLE shoelace_arrive (
+        arr_name    char(10),
+        arr_quant   integer
+    );
+    CREATE TABLE shoelace_ok (
+        ok_name     char(10),
+        ok_quant    integer
+    );
+    CREATE RULE shoelace_ok_ins AS ON INSERT TO shoelace_ok
+        DO INSTEAD
+        UPDATE shoelace SET
+               sl_avail = sl_avail + NEW.ok_quant
+         WHERE sl_name = NEW.ok_name;
+INSERT INTO shoelace_arrive VALUES ('sl3', 10);
+INSERT INTO shoelace_arrive VALUES ('sl6', 20);
+INSERT INTO shoelace_arrive VALUES ('sl8', 20);
+SELECT * FROM shoelace ORDER BY sl_name;
+  sl_name   | sl_avail |  sl_color  | sl_len | sl_unit  | sl_len_cm 
+------------+----------+------------+--------+----------+-----------
+ sl1        |        5 | black      |     80 | cm       |        80
+ sl2        |        6 | black      |    100 | cm       |       100
+ sl3        |        0 | black      |     35 | inch     |      88.9
+ sl4        |        8 | black      |     40 | inch     |     101.6
+ sl5        |        4 | brown      |      1 | m        |       100
+ sl6        |        0 | brown      |    0.9 | m        |        90
+ sl7        |        6 | brown      |     60 | cm       |        60
+ sl8        |        1 | brown      |     40 | inch     |     101.6
+(8 rows)
+
+insert into shoelace_ok select * from shoelace_arrive;
+SELECT * FROM shoelace ORDER BY sl_name;
+  sl_name   | sl_avail |  sl_color  | sl_len | sl_unit  | sl_len_cm 
+------------+----------+------------+--------+----------+-----------
+ sl1        |        5 | black      |     80 | cm       |        80
+ sl2        |        6 | black      |    100 | cm       |       100
+ sl3        |       10 | black      |     35 | inch     |      88.9
+ sl4        |        8 | black      |     40 | inch     |     101.6
+ sl5        |        4 | brown      |      1 | m        |       100
+ sl6        |       20 | brown      |    0.9 | m        |        90
+ sl7        |        6 | brown      |     60 | cm       |        60
+ sl8        |       21 | brown      |     40 | inch     |     101.6
+(8 rows)
+
+SELECT * FROM shoelace_log ORDER BY sl_name;
+  sl_name   | sl_avail | log_who  |         log_when         
+------------+----------+----------+--------------------------
+ sl3        |       10 | Al Bundy | Thu Jan 01 00:00:00 1970
+ sl6        |       20 | Al Bundy | Thu Jan 01 00:00:00 1970
+ sl7        |        6 | Al Bundy | Thu Jan 01 00:00:00 1970
+ sl8        |       21 | Al Bundy | Thu Jan 01 00:00:00 1970
+(4 rows)
+
+    CREATE VIEW shoelace_obsolete AS
+	SELECT * FROM shoelace WHERE NOT EXISTS
+	    (SELECT shoename FROM shoe WHERE slcolor = sl_color);
+    CREATE VIEW shoelace_candelete AS
+	SELECT * FROM shoelace_obsolete WHERE sl_avail = 0;
+insert into shoelace values ('sl9', 0, 'pink', 35.0, 'inch', 0.0);
+insert into shoelace values ('sl10', 1000, 'magenta', 40.0, 'inch', 0.0);
+-- Unsupported (even though a similar updatable view construct is)
+insert into shoelace values ('sl10', 1000, 'magenta', 40.0, 'inch', 0.0)
+  on conflict do nothing;
+ERROR:  INSERT with ON CONFLICT clause cannot be used with table that has INSERT or UPDATE rules
+SELECT * FROM shoelace_obsolete ORDER BY sl_len_cm;
+  sl_name   | sl_avail |  sl_color  | sl_len | sl_unit  | sl_len_cm 
+------------+----------+------------+--------+----------+-----------
+ sl9        |        0 | pink       |     35 | inch     |      88.9
+ sl10       |     1000 | magenta    |     40 | inch     |     101.6
+(2 rows)
+
+SELECT * FROM shoelace_candelete;
+  sl_name   | sl_avail |  sl_color  | sl_len | sl_unit  | sl_len_cm 
+------------+----------+------------+--------+----------+-----------
+ sl9        |        0 | pink       |     35 | inch     |      88.9
+(1 row)
+
+DELETE FROM shoelace WHERE EXISTS
+    (SELECT * FROM shoelace_candelete
+             WHERE sl_name = shoelace.sl_name);
+SELECT * FROM shoelace ORDER BY sl_name;
+  sl_name   | sl_avail |  sl_color  | sl_len | sl_unit  | sl_len_cm 
+------------+----------+------------+--------+----------+-----------
+ sl1        |        5 | black      |     80 | cm       |        80
+ sl10       |     1000 | magenta    |     40 | inch     |     101.6
+ sl2        |        6 | black      |    100 | cm       |       100
+ sl3        |       10 | black      |     35 | inch     |      88.9
+ sl4        |        8 | black      |     40 | inch     |     101.6
+ sl5        |        4 | brown      |      1 | m        |       100
+ sl6        |       20 | brown      |    0.9 | m        |        90
+ sl7        |        6 | brown      |     60 | cm       |        60
+ sl8        |       21 | brown      |     40 | inch     |     101.6
+(9 rows)
+
+SELECT * FROM shoe ORDER BY shoename;
+  shoename  | sh_avail |  slcolor   | slminlen | slminlen_cm | slmaxlen | slmaxlen_cm |  slunit  
+------------+----------+------------+----------+-------------+----------+-------------+----------
+ sh1        |        2 | black      |       70 |          70 |       90 |          90 | cm      
+ sh2        |        0 | black      |       30 |        76.2 |       40 |       101.6 | inch    
+ sh3        |        4 | brown      |       50 |          50 |       65 |          65 | cm      
+ sh4        |        3 | brown      |       40 |       101.6 |       50 |         127 | inch    
+(4 rows)
+
+SELECT count(*) FROM shoe;
+ count 
+-------
+     4
+(1 row)
+
+--
+-- Simple test of qualified ON INSERT ... this did not work in 7.0 ...
+--
+create table rules_foo (f1 int);
+create table rules_foo2 (f1 int);
+create rule rules_foorule as on insert to rules_foo where f1 < 100
+do instead nothing;
+insert into rules_foo values(1);
+insert into rules_foo values(1001);
+select * from rules_foo;
+  f1  
+------
+ 1001
+(1 row)
+
+drop rule rules_foorule on rules_foo;
+-- this should fail because f1 is not exposed for unqualified reference:
+create rule rules_foorule as on insert to rules_foo where f1 < 100
+do instead insert into rules_foo2 values (f1);
+ERROR:  column "f1" does not exist
+LINE 2: do instead insert into rules_foo2 values (f1);
+                                                  ^
+HINT:  There is a column named "f1" in table "old", but it cannot be referenced from this part of the query.
+-- this is the correct way:
+create rule rules_foorule as on insert to rules_foo where f1 < 100
+do instead insert into rules_foo2 values (new.f1);
+insert into rules_foo values(2);
+insert into rules_foo values(100);
+select * from rules_foo;
+  f1  
+------
+ 1001
+  100
+(2 rows)
+
+select * from rules_foo2;
+ f1 
+----
+  2
+(1 row)
+
+drop rule rules_foorule on rules_foo;
+drop table rules_foo;
+drop table rules_foo2;
+--
+-- Test rules containing INSERT ... SELECT, which is a very ugly special
+-- case as of 7.1.  Example is based on bug report from Joel Burton.
+--
+create table pparent (pid int, txt text);
+insert into pparent values (1,'parent1');
+insert into pparent values (2,'parent2');
+create table cchild (pid int, descrip text);
+insert into cchild values (1,'descrip1');
+create view vview as
+  select pparent.pid, txt, descrip from
+    pparent left join cchild using (pid);
+create rule rrule as
+  on update to vview do instead
+(
+  insert into cchild (pid, descrip)
+    select old.pid, new.descrip where old.descrip isnull;
+  update cchild set descrip = new.descrip where cchild.pid = old.pid;
+);
+select * from vview;
+ pid |   txt   | descrip  
+-----+---------+----------
+   1 | parent1 | descrip1
+   2 | parent2 | 
+(2 rows)
+
+update vview set descrip='test1' where pid=1;
+select * from vview;
+ pid |   txt   | descrip 
+-----+---------+---------
+   1 | parent1 | test1
+   2 | parent2 | 
+(2 rows)
+
+update vview set descrip='test2' where pid=2;
+select * from vview;
+ pid |   txt   | descrip 
+-----+---------+---------
+   1 | parent1 | test1
+   2 | parent2 | test2
+(2 rows)
+
+update vview set descrip='test3' where pid=3;
+select * from vview;
+ pid |   txt   | descrip 
+-----+---------+---------
+   1 | parent1 | test1
+   2 | parent2 | test2
+(2 rows)
+
+select * from cchild;
+ pid | descrip 
+-----+---------
+   1 | test1
+   2 | test2
+(2 rows)
+
+drop rule rrule on vview;
+drop view vview;
+drop table pparent;
+drop table cchild;
+--
+-- Check that ruleutils are working
+--
+-- temporarily disable fancy output, so view changes create less diff noise
+\a\t
+SELECT viewname, definition FROM pg_views WHERE schemaname <> 'information_schema' ORDER BY viewname;
+iexit| SELECT ih.name,
+    ih.thepath,
+    interpt_pp(ih.thepath, r.thepath) AS exit
+   FROM ihighway ih,
+    ramp r
+  WHERE (ih.thepath ## r.thepath);
+mvtest_tv| SELECT mvtest_t.type,
+    sum(mvtest_t.amt) AS totamt
+   FROM mvtest_t
+  GROUP BY mvtest_t.type;
+mvtest_tvv| SELECT sum(mvtest_tv.totamt) AS grandtot
+   FROM mvtest_tv;
+mvtest_tvvmv| SELECT mvtest_tvvm.grandtot
+   FROM mvtest_tvvm;
+pg_available_extension_versions| SELECT e.name,
+    e.version,
+    (x.extname IS NOT NULL) AS installed,
+    e.superuser,
+    e.relocatable,
+    e.schema,
+    e.requires,
+    e.comment
+   FROM (pg_available_extension_versions() e(name, version, superuser, relocatable, schema, requires, comment)
+     LEFT JOIN pg_extension x ON (((e.name = x.extname) AND (e.version = x.extversion))));
+pg_available_extensions| SELECT e.name,
+    e.default_version,
+    x.extversion AS installed_version,
+    e.comment
+   FROM (pg_available_extensions() e(name, default_version, comment)
+     LEFT JOIN pg_extension x ON ((e.name = x.extname)));
+pg_config| SELECT pg_config.name,
+    pg_config.setting
+   FROM pg_config() pg_config(name, setting);
+pg_cursors| SELECT c.name,
+    c.statement,
+    c.is_holdable,
+    c.is_binary,
+    c.is_scrollable,
+    c.creation_time
+   FROM pg_cursor() c(name, statement, is_holdable, is_binary, is_scrollable, creation_time);
+pg_file_settings| SELECT a.sourcefile,
+    a.sourceline,
+    a.seqno,
+    a.name,
+    a.setting,
+    a.applied,
+    a.error
+   FROM pg_show_all_file_settings() a(sourcefile, sourceline, seqno, name, setting, applied, error);
+pg_group| SELECT pg_authid.rolname AS groname,
+    pg_authid.oid AS grosysid,
+    ARRAY( SELECT pg_auth_members.member
+           FROM pg_auth_members
+          WHERE (pg_auth_members.roleid = pg_authid.oid)) AS grolist
+   FROM pg_authid
+  WHERE (NOT pg_authid.rolcanlogin);
+pg_hba_file_rules| SELECT a.line_number,
+    a.type,
+    a.database,
+    a.user_name,
+    a.address,
+    a.netmask,
+    a.auth_method,
+    a.options,
+    a.error
+   FROM pg_hba_file_rules() a(line_number, type, database, user_name, address, netmask, auth_method, options, error);
+pg_indexes| SELECT n.nspname AS schemaname,
+    c.relname AS tablename,
+    i.relname AS indexname,
+    t.spcname AS tablespace,
+    pg_get_indexdef(i.oid) AS indexdef
+   FROM ((((pg_index x
+     JOIN pg_class c ON ((c.oid = x.indrelid)))
+     JOIN pg_class i ON ((i.oid = x.indexrelid)))
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+     LEFT JOIN pg_tablespace t ON ((t.oid = i.reltablespace)))
+  WHERE ((c.relkind = ANY (ARRAY['r'::"char", 'm'::"char"])) AND (i.relkind = 'i'::"char"));
+pg_locks| SELECT l.locktype,
+    l.database,
+    l.relation,
+    l.page,
+    l.tuple,
+    l.virtualxid,
+    l.transactionid,
+    l.classid,
+    l.objid,
+    l.objsubid,
+    l.virtualtransaction,
+    l.pid,
+    l.mode,
+    l.granted,
+    l.fastpath
+   FROM pg_lock_status() l(locktype, database, relation, page, tuple, virtualxid, transactionid, classid, objid, objsubid, virtualtransaction, pid, mode, granted, fastpath);
+pg_matviews| SELECT n.nspname AS schemaname,
+    c.relname AS matviewname,
+    pg_get_userbyid(c.relowner) AS matviewowner,
+    t.spcname AS tablespace,
+    c.relhasindex AS hasindexes,
+    c.relispopulated AS ispopulated,
+    pg_get_viewdef(c.oid) AS definition
+   FROM ((pg_class c
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+     LEFT JOIN pg_tablespace t ON ((t.oid = c.reltablespace)))
+  WHERE (c.relkind = 'm'::"char");
+pg_policies| SELECT n.nspname AS schemaname,
+    c.relname AS tablename,
+    pol.polname AS policyname,
+        CASE
+            WHEN pol.polpermissive THEN 'PERMISSIVE'::text
+            ELSE 'RESTRICTIVE'::text
+        END AS permissive,
+        CASE
+            WHEN (pol.polroles = '{0}'::oid[]) THEN (string_to_array('public'::text, ''::text))::name[]
+            ELSE ARRAY( SELECT pg_authid.rolname
+               FROM pg_authid
+              WHERE (pg_authid.oid = ANY (pol.polroles))
+              ORDER BY pg_authid.rolname)
+        END AS roles,
+        CASE pol.polcmd
+            WHEN 'r'::"char" THEN 'SELECT'::text
+            WHEN 'a'::"char" THEN 'INSERT'::text
+            WHEN 'w'::"char" THEN 'UPDATE'::text
+            WHEN 'd'::"char" THEN 'DELETE'::text
+            WHEN '*'::"char" THEN 'ALL'::text
+            ELSE NULL::text
+        END AS cmd,
+    pg_get_expr(pol.polqual, pol.polrelid) AS qual,
+    pg_get_expr(pol.polwithcheck, pol.polrelid) AS with_check
+   FROM ((pg_policy pol
+     JOIN pg_class c ON ((c.oid = pol.polrelid)))
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)));
+pg_prepared_statements| SELECT p.name,
+    p.statement,
+    p.prepare_time,
+    p.parameter_types,
+    p.from_sql
+   FROM pg_prepared_statement() p(name, statement, prepare_time, parameter_types, from_sql);
+pg_prepared_xacts| SELECT p.transaction,
+    p.gid,
+    p.prepared,
+    u.rolname AS owner,
+    d.datname AS database
+   FROM ((pg_prepared_xact() p(transaction, gid, prepared, ownerid, dbid)
+     LEFT JOIN pg_authid u ON ((p.ownerid = u.oid)))
+     LEFT JOIN pg_database d ON ((p.dbid = d.oid)));
+pg_publication_tables| SELECT p.pubname,
+    n.nspname AS schemaname,
+    c.relname AS tablename
+   FROM pg_publication p,
+    (pg_class c
+     JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+  WHERE (c.oid IN ( SELECT pg_get_publication_tables.relid
+           FROM pg_get_publication_tables((p.pubname)::text) pg_get_publication_tables(relid)));
+pg_replication_origin_status| SELECT pg_show_replication_origin_status.local_id,
+    pg_show_replication_origin_status.external_id,
+    pg_show_replication_origin_status.remote_lsn,
+    pg_show_replication_origin_status.local_lsn
+   FROM pg_show_replication_origin_status() pg_show_replication_origin_status(local_id, external_id, remote_lsn, local_lsn);
+pg_replication_slots| SELECT l.slot_name,
+    l.plugin,
+    l.slot_type,
+    l.datoid,
+    d.datname AS database,
+    l.temporary,
+    l.active,
+    l.active_pid,
+    l.xmin,
+    l.catalog_xmin,
+    l.restart_lsn,
+    l.confirmed_flush_lsn
+   FROM (pg_get_replication_slots() l(slot_name, plugin, slot_type, datoid, temporary, active, active_pid, xmin, catalog_xmin, restart_lsn, confirmed_flush_lsn)
+     LEFT JOIN pg_database d ON ((l.datoid = d.oid)));
+pg_roles| SELECT pg_authid.rolname,
+    pg_authid.rolsuper,
+    pg_authid.rolinherit,
+    pg_authid.rolcreaterole,
+    pg_authid.rolcreatedb,
+    pg_authid.rolcanlogin,
+    pg_authid.rolreplication,
+    pg_authid.rolconnlimit,
+    '********'::text AS rolpassword,
+    pg_authid.rolvaliduntil,
+    pg_authid.rolbypassrls,
+    s.setconfig AS rolconfig,
+    pg_authid.oid
+   FROM (pg_authid
+     LEFT JOIN pg_db_role_setting s ON (((pg_authid.oid = s.setrole) AND (s.setdatabase = (0)::oid))));
+pg_rules| SELECT n.nspname AS schemaname,
+    c.relname AS tablename,
+    r.rulename,
+    pg_get_ruledef(r.oid) AS definition
+   FROM ((pg_rewrite r
+     JOIN pg_class c ON ((c.oid = r.ev_class)))
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+  WHERE (r.rulename <> '_RETURN'::name);
+pg_seclabels| SELECT l.objoid,
+    l.classoid,
+    l.objsubid,
+        CASE
+            WHEN (rel.relkind = ANY (ARRAY['r'::"char", 'p'::"char"])) THEN 'table'::text
+            WHEN (rel.relkind = 'v'::"char") THEN 'view'::text
+            WHEN (rel.relkind = 'm'::"char") THEN 'materialized view'::text
+            WHEN (rel.relkind = 'S'::"char") THEN 'sequence'::text
+            WHEN (rel.relkind = 'f'::"char") THEN 'foreign table'::text
+            ELSE NULL::text
+        END AS objtype,
+    rel.relnamespace AS objnamespace,
+        CASE
+            WHEN pg_table_is_visible(rel.oid) THEN quote_ident((rel.relname)::text)
+            ELSE ((quote_ident((nsp.nspname)::text) || '.'::text) || quote_ident((rel.relname)::text))
+        END AS objname,
+    l.provider,
+    l.label
+   FROM ((pg_seclabel l
+     JOIN pg_class rel ON (((l.classoid = rel.tableoid) AND (l.objoid = rel.oid))))
+     JOIN pg_namespace nsp ON ((rel.relnamespace = nsp.oid)))
+  WHERE (l.objsubid = 0)
+UNION ALL
+ SELECT l.objoid,
+    l.classoid,
+    l.objsubid,
+    'column'::text AS objtype,
+    rel.relnamespace AS objnamespace,
+    ((
+        CASE
+            WHEN pg_table_is_visible(rel.oid) THEN quote_ident((rel.relname)::text)
+            ELSE ((quote_ident((nsp.nspname)::text) || '.'::text) || quote_ident((rel.relname)::text))
+        END || '.'::text) || (att.attname)::text) AS objname,
+    l.provider,
+    l.label
+   FROM (((pg_seclabel l
+     JOIN pg_class rel ON (((l.classoid = rel.tableoid) AND (l.objoid = rel.oid))))
+     JOIN pg_attribute att ON (((rel.oid = att.attrelid) AND (l.objsubid = att.attnum))))
+     JOIN pg_namespace nsp ON ((rel.relnamespace = nsp.oid)))
+  WHERE (l.objsubid <> 0)
+UNION ALL
+ SELECT l.objoid,
+    l.classoid,
+    l.objsubid,
+        CASE pro.prokind
+            WHEN 'a'::"char" THEN 'aggregate'::text
+            WHEN 'f'::"char" THEN 'function'::text
+            WHEN 'p'::"char" THEN 'procedure'::text
+            WHEN 'w'::"char" THEN 'window'::text
+            ELSE NULL::text
+        END AS objtype,
+    pro.pronamespace AS objnamespace,
+    (((
+        CASE
+            WHEN pg_function_is_visible(pro.oid) THEN quote_ident((pro.proname)::text)
+            ELSE ((quote_ident((nsp.nspname)::text) || '.'::text) || quote_ident((pro.proname)::text))
+        END || '('::text) || pg_get_function_arguments(pro.oid)) || ')'::text) AS objname,
+    l.provider,
+    l.label
+   FROM ((pg_seclabel l
+     JOIN pg_proc pro ON (((l.classoid = pro.tableoid) AND (l.objoid = pro.oid))))
+     JOIN pg_namespace nsp ON ((pro.pronamespace = nsp.oid)))
+  WHERE (l.objsubid = 0)
+UNION ALL
+ SELECT l.objoid,
+    l.classoid,
+    l.objsubid,
+        CASE
+            WHEN (typ.typtype = 'd'::"char") THEN 'domain'::text
+            ELSE 'type'::text
+        END AS objtype,
+    typ.typnamespace AS objnamespace,
+        CASE
+            WHEN pg_type_is_visible(typ.oid) THEN quote_ident((typ.typname)::text)
+            ELSE ((quote_ident((nsp.nspname)::text) || '.'::text) || quote_ident((typ.typname)::text))
+        END AS objname,
+    l.provider,
+    l.label
+   FROM ((pg_seclabel l
+     JOIN pg_type typ ON (((l.classoid = typ.tableoid) AND (l.objoid = typ.oid))))
+     JOIN pg_namespace nsp ON ((typ.typnamespace = nsp.oid)))
+  WHERE (l.objsubid = 0)
+UNION ALL
+ SELECT l.objoid,
+    l.classoid,
+    l.objsubid,
+    'large object'::text AS objtype,
+    NULL::oid AS objnamespace,
+    (l.objoid)::text AS objname,
+    l.provider,
+    l.label
+   FROM (pg_seclabel l
+     JOIN pg_largeobject_metadata lom ON ((l.objoid = lom.oid)))
+  WHERE ((l.classoid = ('pg_largeobject'::regclass)::oid) AND (l.objsubid = 0))
+UNION ALL
+ SELECT l.objoid,
+    l.classoid,
+    l.objsubid,
+    'language'::text AS objtype,
+    NULL::oid AS objnamespace,
+    quote_ident((lan.lanname)::text) AS objname,
+    l.provider,
+    l.label
+   FROM (pg_seclabel l
+     JOIN pg_language lan ON (((l.classoid = lan.tableoid) AND (l.objoid = lan.oid))))
+  WHERE (l.objsubid = 0)
+UNION ALL
+ SELECT l.objoid,
+    l.classoid,
+    l.objsubid,
+    'schema'::text AS objtype,
+    nsp.oid AS objnamespace,
+    quote_ident((nsp.nspname)::text) AS objname,
+    l.provider,
+    l.label
+   FROM (pg_seclabel l
+     JOIN pg_namespace nsp ON (((l.classoid = nsp.tableoid) AND (l.objoid = nsp.oid))))
+  WHERE (l.objsubid = 0)
+UNION ALL
+ SELECT l.objoid,
+    l.classoid,
+    l.objsubid,
+    'event trigger'::text AS objtype,
+    NULL::oid AS objnamespace,
+    quote_ident((evt.evtname)::text) AS objname,
+    l.provider,
+    l.label
+   FROM (pg_seclabel l
+     JOIN pg_event_trigger evt ON (((l.classoid = evt.tableoid) AND (l.objoid = evt.oid))))
+  WHERE (l.objsubid = 0)
+UNION ALL
+ SELECT l.objoid,
+    l.classoid,
+    l.objsubid,
+    'publication'::text AS objtype,
+    NULL::oid AS objnamespace,
+    quote_ident((p.pubname)::text) AS objname,
+    l.provider,
+    l.label
+   FROM (pg_seclabel l
+     JOIN pg_publication p ON (((l.classoid = p.tableoid) AND (l.objoid = p.oid))))
+  WHERE (l.objsubid = 0)
+UNION ALL
+ SELECT l.objoid,
+    l.classoid,
+    0 AS objsubid,
+    'subscription'::text AS objtype,
+    NULL::oid AS objnamespace,
+    quote_ident((s.subname)::text) AS objname,
+    l.provider,
+    l.label
+   FROM (pg_shseclabel l
+     JOIN pg_subscription s ON (((l.classoid = s.tableoid) AND (l.objoid = s.oid))))
+UNION ALL
+ SELECT l.objoid,
+    l.classoid,
+    0 AS objsubid,
+    'database'::text AS objtype,
+    NULL::oid AS objnamespace,
+    quote_ident((dat.datname)::text) AS objname,
+    l.provider,
+    l.label
+   FROM (pg_shseclabel l
+     JOIN pg_database dat ON (((l.classoid = dat.tableoid) AND (l.objoid = dat.oid))))
+UNION ALL
+ SELECT l.objoid,
+    l.classoid,
+    0 AS objsubid,
+    'tablespace'::text AS objtype,
+    NULL::oid AS objnamespace,
+    quote_ident((spc.spcname)::text) AS objname,
+    l.provider,
+    l.label
+   FROM (pg_shseclabel l
+     JOIN pg_tablespace spc ON (((l.classoid = spc.tableoid) AND (l.objoid = spc.oid))))
+UNION ALL
+ SELECT l.objoid,
+    l.classoid,
+    0 AS objsubid,
+    'role'::text AS objtype,
+    NULL::oid AS objnamespace,
+    quote_ident((rol.rolname)::text) AS objname,
+    l.provider,
+    l.label
+   FROM (pg_shseclabel l
+     JOIN pg_authid rol ON (((l.classoid = rol.tableoid) AND (l.objoid = rol.oid))));
+pg_sequences| SELECT n.nspname AS schemaname,
+    c.relname AS sequencename,
+    pg_get_userbyid(c.relowner) AS sequenceowner,
+    (s.seqtypid)::regtype AS data_type,
+    s.seqstart AS start_value,
+    s.seqmin AS min_value,
+    s.seqmax AS max_value,
+    s.seqincrement AS increment_by,
+    s.seqcycle AS cycle,
+    s.seqcache AS cache_size,
+        CASE
+            WHEN has_sequence_privilege(c.oid, 'SELECT,USAGE'::text) THEN pg_sequence_last_value((c.oid)::regclass)
+            ELSE NULL::bigint
+        END AS last_value
+   FROM ((pg_sequence s
+     JOIN pg_class c ON ((c.oid = s.seqrelid)))
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+  WHERE ((NOT pg_is_other_temp_schema(n.oid)) AND (c.relkind = 'S'::"char"));
+pg_settings| SELECT a.name,
+    a.setting,
+    a.unit,
+    a.category,
+    a.short_desc,
+    a.extra_desc,
+    a.context,
+    a.vartype,
+    a.source,
+    a.min_val,
+    a.max_val,
+    a.enumvals,
+    a.boot_val,
+    a.reset_val,
+    a.sourcefile,
+    a.sourceline,
+    a.pending_restart
+   FROM pg_show_all_settings() a(name, setting, unit, category, short_desc, extra_desc, context, vartype, source, min_val, max_val, enumvals, boot_val, reset_val, sourcefile, sourceline, pending_restart);
+pg_shadow| SELECT pg_authid.rolname AS usename,
+    pg_authid.oid AS usesysid,
+    pg_authid.rolcreatedb AS usecreatedb,
+    pg_authid.rolsuper AS usesuper,
+    pg_authid.rolreplication AS userepl,
+    pg_authid.rolbypassrls AS usebypassrls,
+    pg_authid.rolpassword AS passwd,
+    (pg_authid.rolvaliduntil)::abstime AS valuntil,
+    s.setconfig AS useconfig
+   FROM (pg_authid
+     LEFT JOIN pg_db_role_setting s ON (((pg_authid.oid = s.setrole) AND (s.setdatabase = (0)::oid))))
+  WHERE pg_authid.rolcanlogin;
+pg_stat_activity| SELECT s.datid,
+    d.datname,
+    s.pid,
+    s.usesysid,
+    u.rolname AS usename,
+    s.application_name,
+    s.client_addr,
+    s.client_hostname,
+    s.client_port,
+    s.backend_start,
+    s.xact_start,
+    s.query_start,
+    s.state_change,
+    s.wait_event_type,
+    s.wait_event,
+    s.state,
+    s.backend_xid,
+    s.backend_xmin,
+    s.query,
+    s.backend_type
+   FROM ((pg_stat_get_activity(NULL::integer) s(datid, pid, usesysid, application_name, state, query, wait_event_type, wait_event, xact_start, query_start, backend_start, state_change, client_addr, client_hostname, client_port, backend_xid, backend_xmin, backend_type, ssl, sslversion, sslcipher, sslbits, sslcompression, sslclientdn)
+     LEFT JOIN pg_database d ON ((s.datid = d.oid)))
+     LEFT JOIN pg_authid u ON ((s.usesysid = u.oid)));
+pg_stat_all_indexes| SELECT c.oid AS relid,
+    i.oid AS indexrelid,
+    n.nspname AS schemaname,
+    c.relname,
+    i.relname AS indexrelname,
+    pg_stat_get_numscans(i.oid) AS idx_scan,
+    pg_stat_get_tuples_returned(i.oid) AS idx_tup_read,
+    pg_stat_get_tuples_fetched(i.oid) AS idx_tup_fetch
+   FROM (((pg_class c
+     JOIN pg_index x ON ((c.oid = x.indrelid)))
+     JOIN pg_class i ON ((i.oid = x.indexrelid)))
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+  WHERE (c.relkind = ANY (ARRAY['r'::"char", 't'::"char", 'm'::"char"]));
+pg_stat_all_tables| SELECT c.oid AS relid,
+    n.nspname AS schemaname,
+    c.relname,
+    pg_stat_get_numscans(c.oid) AS seq_scan,
+    pg_stat_get_tuples_returned(c.oid) AS seq_tup_read,
+    (sum(pg_stat_get_numscans(i.indexrelid)))::bigint AS idx_scan,
+    ((sum(pg_stat_get_tuples_fetched(i.indexrelid)))::bigint + pg_stat_get_tuples_fetched(c.oid)) AS idx_tup_fetch,
+    pg_stat_get_tuples_inserted(c.oid) AS n_tup_ins,
+    pg_stat_get_tuples_updated(c.oid) AS n_tup_upd,
+    pg_stat_get_tuples_deleted(c.oid) AS n_tup_del,
+    pg_stat_get_tuples_hot_updated(c.oid) AS n_tup_hot_upd,
+    pg_stat_get_live_tuples(c.oid) AS n_live_tup,
+    pg_stat_get_dead_tuples(c.oid) AS n_dead_tup,
+    pg_stat_get_mod_since_analyze(c.oid) AS n_mod_since_analyze,
+    pg_stat_get_last_vacuum_time(c.oid) AS last_vacuum,
+    pg_stat_get_last_autovacuum_time(c.oid) AS last_autovacuum,
+    pg_stat_get_last_analyze_time(c.oid) AS last_analyze,
+    pg_stat_get_last_autoanalyze_time(c.oid) AS last_autoanalyze,
+    pg_stat_get_vacuum_count(c.oid) AS vacuum_count,
+    pg_stat_get_autovacuum_count(c.oid) AS autovacuum_count,
+    pg_stat_get_analyze_count(c.oid) AS analyze_count,
+    pg_stat_get_autoanalyze_count(c.oid) AS autoanalyze_count
+   FROM ((pg_class c
+     LEFT JOIN pg_index i ON ((c.oid = i.indrelid)))
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+  WHERE (c.relkind = ANY (ARRAY['r'::"char", 't'::"char", 'm'::"char"]))
+  GROUP BY c.oid, n.nspname, c.relname;
+pg_stat_archiver| SELECT s.archived_count,
+    s.last_archived_wal,
+    s.last_archived_time,
+    s.failed_count,
+    s.last_failed_wal,
+    s.last_failed_time,
+    s.stats_reset
+   FROM pg_stat_get_archiver() s(archived_count, last_archived_wal, last_archived_time, failed_count, last_failed_wal, last_failed_time, stats_reset);
+pg_stat_bgwriter| SELECT pg_stat_get_bgwriter_timed_checkpoints() AS checkpoints_timed,
+    pg_stat_get_bgwriter_requested_checkpoints() AS checkpoints_req,
+    pg_stat_get_checkpoint_write_time() AS checkpoint_write_time,
+    pg_stat_get_checkpoint_sync_time() AS checkpoint_sync_time,
+    pg_stat_get_bgwriter_buf_written_checkpoints() AS buffers_checkpoint,
+    pg_stat_get_bgwriter_buf_written_clean() AS buffers_clean,
+    pg_stat_get_bgwriter_maxwritten_clean() AS maxwritten_clean,
+    pg_stat_get_buf_written_backend() AS buffers_backend,
+    pg_stat_get_buf_fsync_backend() AS buffers_backend_fsync,
+    pg_stat_get_buf_alloc() AS buffers_alloc,
+    pg_stat_get_bgwriter_stat_reset_time() AS stats_reset;
+pg_stat_database| SELECT d.oid AS datid,
+    d.datname,
+    pg_stat_get_db_numbackends(d.oid) AS numbackends,
+    pg_stat_get_db_xact_commit(d.oid) AS xact_commit,
+    pg_stat_get_db_xact_rollback(d.oid) AS xact_rollback,
+    (pg_stat_get_db_blocks_fetched(d.oid) - pg_stat_get_db_blocks_hit(d.oid)) AS blks_read,
+    pg_stat_get_db_blocks_hit(d.oid) AS blks_hit,
+    pg_stat_get_db_tuples_returned(d.oid) AS tup_returned,
+    pg_stat_get_db_tuples_fetched(d.oid) AS tup_fetched,
+    pg_stat_get_db_tuples_inserted(d.oid) AS tup_inserted,
+    pg_stat_get_db_tuples_updated(d.oid) AS tup_updated,
+    pg_stat_get_db_tuples_deleted(d.oid) AS tup_deleted,
+    pg_stat_get_db_conflict_all(d.oid) AS conflicts,
+    pg_stat_get_db_temp_files(d.oid) AS temp_files,
+    pg_stat_get_db_temp_bytes(d.oid) AS temp_bytes,
+    pg_stat_get_db_deadlocks(d.oid) AS deadlocks,
+    pg_stat_get_db_blk_read_time(d.oid) AS blk_read_time,
+    pg_stat_get_db_blk_write_time(d.oid) AS blk_write_time,
+    pg_stat_get_db_stat_reset_time(d.oid) AS stats_reset
+   FROM pg_database d;
+pg_stat_database_conflicts| SELECT d.oid AS datid,
+    d.datname,
+    pg_stat_get_db_conflict_tablespace(d.oid) AS confl_tablespace,
+    pg_stat_get_db_conflict_lock(d.oid) AS confl_lock,
+    pg_stat_get_db_conflict_snapshot(d.oid) AS confl_snapshot,
+    pg_stat_get_db_conflict_bufferpin(d.oid) AS confl_bufferpin,
+    pg_stat_get_db_conflict_startup_deadlock(d.oid) AS confl_deadlock
+   FROM pg_database d;
+pg_stat_progress_vacuum| SELECT s.pid,
+    s.datid,
+    d.datname,
+    s.relid,
+        CASE s.param1
+            WHEN 0 THEN 'initializing'::text
+            WHEN 1 THEN 'scanning heap'::text
+            WHEN 2 THEN 'vacuuming indexes'::text
+            WHEN 3 THEN 'vacuuming heap'::text
+            WHEN 4 THEN 'cleaning up indexes'::text
+            WHEN 5 THEN 'truncating heap'::text
+            WHEN 6 THEN 'performing final cleanup'::text
+            ELSE NULL::text
+        END AS phase,
+    s.param2 AS heap_blks_total,
+    s.param3 AS heap_blks_scanned,
+    s.param4 AS heap_blks_vacuumed,
+    s.param5 AS index_vacuum_count,
+    s.param6 AS max_dead_tuples,
+    s.param7 AS num_dead_tuples
+   FROM (pg_stat_get_progress_info('VACUUM'::text) s(pid, datid, relid, param1, param2, param3, param4, param5, param6, param7, param8, param9, param10)
+     LEFT JOIN pg_database d ON ((s.datid = d.oid)));
+pg_stat_replication| SELECT s.pid,
+    s.usesysid,
+    u.rolname AS usename,
+    s.application_name,
+    s.client_addr,
+    s.client_hostname,
+    s.client_port,
+    s.backend_start,
+    s.backend_xmin,
+    w.state,
+    w.sent_lsn,
+    w.write_lsn,
+    w.flush_lsn,
+    w.replay_lsn,
+    w.write_lag,
+    w.flush_lag,
+    w.replay_lag,
+    w.sync_priority,
+    w.sync_state
+   FROM ((pg_stat_get_activity(NULL::integer) s(datid, pid, usesysid, application_name, state, query, wait_event_type, wait_event, xact_start, query_start, backend_start, state_change, client_addr, client_hostname, client_port, backend_xid, backend_xmin, backend_type, ssl, sslversion, sslcipher, sslbits, sslcompression, sslclientdn)
+     JOIN pg_stat_get_wal_senders() w(pid, state, sent_lsn, write_lsn, flush_lsn, replay_lsn, write_lag, flush_lag, replay_lag, sync_priority, sync_state) ON ((s.pid = w.pid)))
+     LEFT JOIN pg_authid u ON ((s.usesysid = u.oid)));
+pg_stat_ssl| SELECT s.pid,
+    s.ssl,
+    s.sslversion AS version,
+    s.sslcipher AS cipher,
+    s.sslbits AS bits,
+    s.sslcompression AS compression,
+    s.sslclientdn AS clientdn
+   FROM pg_stat_get_activity(NULL::integer) s(datid, pid, usesysid, application_name, state, query, wait_event_type, wait_event, xact_start, query_start, backend_start, state_change, client_addr, client_hostname, client_port, backend_xid, backend_xmin, backend_type, ssl, sslversion, sslcipher, sslbits, sslcompression, sslclientdn);
+pg_stat_subscription| SELECT su.oid AS subid,
+    su.subname,
+    st.pid,
+    st.relid,
+    st.received_lsn,
+    st.last_msg_send_time,
+    st.last_msg_receipt_time,
+    st.latest_end_lsn,
+    st.latest_end_time
+   FROM (pg_subscription su
+     LEFT JOIN pg_stat_get_subscription(NULL::oid) st(subid, relid, pid, received_lsn, last_msg_send_time, last_msg_receipt_time, latest_end_lsn, latest_end_time) ON ((st.subid = su.oid)));
+pg_stat_sys_indexes| SELECT pg_stat_all_indexes.relid,
+    pg_stat_all_indexes.indexrelid,
+    pg_stat_all_indexes.schemaname,
+    pg_stat_all_indexes.relname,
+    pg_stat_all_indexes.indexrelname,
+    pg_stat_all_indexes.idx_scan,
+    pg_stat_all_indexes.idx_tup_read,
+    pg_stat_all_indexes.idx_tup_fetch
+   FROM pg_stat_all_indexes
+  WHERE ((pg_stat_all_indexes.schemaname = ANY (ARRAY['pg_catalog'::name, 'information_schema'::name])) OR (pg_stat_all_indexes.schemaname ~ '^pg_toast'::text));
+pg_stat_sys_tables| SELECT pg_stat_all_tables.relid,
+    pg_stat_all_tables.schemaname,
+    pg_stat_all_tables.relname,
+    pg_stat_all_tables.seq_scan,
+    pg_stat_all_tables.seq_tup_read,
+    pg_stat_all_tables.idx_scan,
+    pg_stat_all_tables.idx_tup_fetch,
+    pg_stat_all_tables.n_tup_ins,
+    pg_stat_all_tables.n_tup_upd,
+    pg_stat_all_tables.n_tup_del,
+    pg_stat_all_tables.n_tup_hot_upd,
+    pg_stat_all_tables.n_live_tup,
+    pg_stat_all_tables.n_dead_tup,
+    pg_stat_all_tables.n_mod_since_analyze,
+    pg_stat_all_tables.last_vacuum,
+    pg_stat_all_tables.last_autovacuum,
+    pg_stat_all_tables.last_analyze,
+    pg_stat_all_tables.last_autoanalyze,
+    pg_stat_all_tables.vacuum_count,
+    pg_stat_all_tables.autovacuum_count,
+    pg_stat_all_tables.analyze_count,
+    pg_stat_all_tables.autoanalyze_count
+   FROM pg_stat_all_tables
+  WHERE ((pg_stat_all_tables.schemaname = ANY (ARRAY['pg_catalog'::name, 'information_schema'::name])) OR (pg_stat_all_tables.schemaname ~ '^pg_toast'::text));
+pg_stat_undo_logs| SELECT pg_stat_get_undo_logs.log_number,
+    pg_stat_get_undo_logs.persistence,
+    pg_stat_get_undo_logs.tablespace,
+    pg_stat_get_undo_logs.discard,
+    pg_stat_get_undo_logs.insert,
+    pg_stat_get_undo_logs."end",
+    pg_stat_get_undo_logs.xid,
+    pg_stat_get_undo_logs.pid
+   FROM pg_stat_get_undo_logs() pg_stat_get_undo_logs(log_number, persistence, tablespace, discard, insert, "end", xid, pid);
+pg_stat_user_functions| SELECT p.oid AS funcid,
+    n.nspname AS schemaname,
+    p.proname AS funcname,
+    pg_stat_get_function_calls(p.oid) AS calls,
+    pg_stat_get_function_total_time(p.oid) AS total_time,
+    pg_stat_get_function_self_time(p.oid) AS self_time
+   FROM (pg_proc p
+     LEFT JOIN pg_namespace n ON ((n.oid = p.pronamespace)))
+  WHERE ((p.prolang <> (12)::oid) AND (pg_stat_get_function_calls(p.oid) IS NOT NULL));
+pg_stat_user_indexes| SELECT pg_stat_all_indexes.relid,
+    pg_stat_all_indexes.indexrelid,
+    pg_stat_all_indexes.schemaname,
+    pg_stat_all_indexes.relname,
+    pg_stat_all_indexes.indexrelname,
+    pg_stat_all_indexes.idx_scan,
+    pg_stat_all_indexes.idx_tup_read,
+    pg_stat_all_indexes.idx_tup_fetch
+   FROM pg_stat_all_indexes
+  WHERE ((pg_stat_all_indexes.schemaname <> ALL (ARRAY['pg_catalog'::name, 'information_schema'::name])) AND (pg_stat_all_indexes.schemaname !~ '^pg_toast'::text));
+pg_stat_user_tables| SELECT pg_stat_all_tables.relid,
+    pg_stat_all_tables.schemaname,
+    pg_stat_all_tables.relname,
+    pg_stat_all_tables.seq_scan,
+    pg_stat_all_tables.seq_tup_read,
+    pg_stat_all_tables.idx_scan,
+    pg_stat_all_tables.idx_tup_fetch,
+    pg_stat_all_tables.n_tup_ins,
+    pg_stat_all_tables.n_tup_upd,
+    pg_stat_all_tables.n_tup_del,
+    pg_stat_all_tables.n_tup_hot_upd,
+    pg_stat_all_tables.n_live_tup,
+    pg_stat_all_tables.n_dead_tup,
+    pg_stat_all_tables.n_mod_since_analyze,
+    pg_stat_all_tables.last_vacuum,
+    pg_stat_all_tables.last_autovacuum,
+    pg_stat_all_tables.last_analyze,
+    pg_stat_all_tables.last_autoanalyze,
+    pg_stat_all_tables.vacuum_count,
+    pg_stat_all_tables.autovacuum_count,
+    pg_stat_all_tables.analyze_count,
+    pg_stat_all_tables.autoanalyze_count
+   FROM pg_stat_all_tables
+  WHERE ((pg_stat_all_tables.schemaname <> ALL (ARRAY['pg_catalog'::name, 'information_schema'::name])) AND (pg_stat_all_tables.schemaname !~ '^pg_toast'::text));
+pg_stat_wal_receiver| SELECT s.pid,
+    s.status,
+    s.receive_start_lsn,
+    s.receive_start_tli,
+    s.received_lsn,
+    s.received_tli,
+    s.last_msg_send_time,
+    s.last_msg_receipt_time,
+    s.latest_end_lsn,
+    s.latest_end_time,
+    s.slot_name,
+    s.sender_host,
+    s.sender_port,
+    s.conninfo
+   FROM pg_stat_get_wal_receiver() s(pid, status, receive_start_lsn, receive_start_tli, received_lsn, received_tli, last_msg_send_time, last_msg_receipt_time, latest_end_lsn, latest_end_time, slot_name, sender_host, sender_port, conninfo)
+  WHERE (s.pid IS NOT NULL);
+pg_stat_xact_all_tables| SELECT c.oid AS relid,
+    n.nspname AS schemaname,
+    c.relname,
+    pg_stat_get_xact_numscans(c.oid) AS seq_scan,
+    pg_stat_get_xact_tuples_returned(c.oid) AS seq_tup_read,
+    (sum(pg_stat_get_xact_numscans(i.indexrelid)))::bigint AS idx_scan,
+    ((sum(pg_stat_get_xact_tuples_fetched(i.indexrelid)))::bigint + pg_stat_get_xact_tuples_fetched(c.oid)) AS idx_tup_fetch,
+    pg_stat_get_xact_tuples_inserted(c.oid) AS n_tup_ins,
+    pg_stat_get_xact_tuples_updated(c.oid) AS n_tup_upd,
+    pg_stat_get_xact_tuples_deleted(c.oid) AS n_tup_del,
+    pg_stat_get_xact_tuples_hot_updated(c.oid) AS n_tup_hot_upd
+   FROM ((pg_class c
+     LEFT JOIN pg_index i ON ((c.oid = i.indrelid)))
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+  WHERE (c.relkind = ANY (ARRAY['r'::"char", 't'::"char", 'm'::"char"]))
+  GROUP BY c.oid, n.nspname, c.relname;
+pg_stat_xact_sys_tables| SELECT pg_stat_xact_all_tables.relid,
+    pg_stat_xact_all_tables.schemaname,
+    pg_stat_xact_all_tables.relname,
+    pg_stat_xact_all_tables.seq_scan,
+    pg_stat_xact_all_tables.seq_tup_read,
+    pg_stat_xact_all_tables.idx_scan,
+    pg_stat_xact_all_tables.idx_tup_fetch,
+    pg_stat_xact_all_tables.n_tup_ins,
+    pg_stat_xact_all_tables.n_tup_upd,
+    pg_stat_xact_all_tables.n_tup_del,
+    pg_stat_xact_all_tables.n_tup_hot_upd
+   FROM pg_stat_xact_all_tables
+  WHERE ((pg_stat_xact_all_tables.schemaname = ANY (ARRAY['pg_catalog'::name, 'information_schema'::name])) OR (pg_stat_xact_all_tables.schemaname ~ '^pg_toast'::text));
+pg_stat_xact_user_functions| SELECT p.oid AS funcid,
+    n.nspname AS schemaname,
+    p.proname AS funcname,
+    pg_stat_get_xact_function_calls(p.oid) AS calls,
+    pg_stat_get_xact_function_total_time(p.oid) AS total_time,
+    pg_stat_get_xact_function_self_time(p.oid) AS self_time
+   FROM (pg_proc p
+     LEFT JOIN pg_namespace n ON ((n.oid = p.pronamespace)))
+  WHERE ((p.prolang <> (12)::oid) AND (pg_stat_get_xact_function_calls(p.oid) IS NOT NULL));
+pg_stat_xact_user_tables| SELECT pg_stat_xact_all_tables.relid,
+    pg_stat_xact_all_tables.schemaname,
+    pg_stat_xact_all_tables.relname,
+    pg_stat_xact_all_tables.seq_scan,
+    pg_stat_xact_all_tables.seq_tup_read,
+    pg_stat_xact_all_tables.idx_scan,
+    pg_stat_xact_all_tables.idx_tup_fetch,
+    pg_stat_xact_all_tables.n_tup_ins,
+    pg_stat_xact_all_tables.n_tup_upd,
+    pg_stat_xact_all_tables.n_tup_del,
+    pg_stat_xact_all_tables.n_tup_hot_upd
+   FROM pg_stat_xact_all_tables
+  WHERE ((pg_stat_xact_all_tables.schemaname <> ALL (ARRAY['pg_catalog'::name, 'information_schema'::name])) AND (pg_stat_xact_all_tables.schemaname !~ '^pg_toast'::text));
+pg_statio_all_indexes| SELECT c.oid AS relid,
+    i.oid AS indexrelid,
+    n.nspname AS schemaname,
+    c.relname,
+    i.relname AS indexrelname,
+    (pg_stat_get_blocks_fetched(i.oid) - pg_stat_get_blocks_hit(i.oid)) AS idx_blks_read,
+    pg_stat_get_blocks_hit(i.oid) AS idx_blks_hit
+   FROM (((pg_class c
+     JOIN pg_index x ON ((c.oid = x.indrelid)))
+     JOIN pg_class i ON ((i.oid = x.indexrelid)))
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+  WHERE (c.relkind = ANY (ARRAY['r'::"char", 't'::"char", 'm'::"char"]));
+pg_statio_all_sequences| SELECT c.oid AS relid,
+    n.nspname AS schemaname,
+    c.relname,
+    (pg_stat_get_blocks_fetched(c.oid) - pg_stat_get_blocks_hit(c.oid)) AS blks_read,
+    pg_stat_get_blocks_hit(c.oid) AS blks_hit
+   FROM (pg_class c
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+  WHERE (c.relkind = 'S'::"char");
+pg_statio_all_tables| SELECT c.oid AS relid,
+    n.nspname AS schemaname,
+    c.relname,
+    (pg_stat_get_blocks_fetched(c.oid) - pg_stat_get_blocks_hit(c.oid)) AS heap_blks_read,
+    pg_stat_get_blocks_hit(c.oid) AS heap_blks_hit,
+    (sum((pg_stat_get_blocks_fetched(i.indexrelid) - pg_stat_get_blocks_hit(i.indexrelid))))::bigint AS idx_blks_read,
+    (sum(pg_stat_get_blocks_hit(i.indexrelid)))::bigint AS idx_blks_hit,
+    (pg_stat_get_blocks_fetched(t.oid) - pg_stat_get_blocks_hit(t.oid)) AS toast_blks_read,
+    pg_stat_get_blocks_hit(t.oid) AS toast_blks_hit,
+    (sum((pg_stat_get_blocks_fetched(x.indexrelid) - pg_stat_get_blocks_hit(x.indexrelid))))::bigint AS tidx_blks_read,
+    (sum(pg_stat_get_blocks_hit(x.indexrelid)))::bigint AS tidx_blks_hit
+   FROM ((((pg_class c
+     LEFT JOIN pg_index i ON ((c.oid = i.indrelid)))
+     LEFT JOIN pg_class t ON ((c.reltoastrelid = t.oid)))
+     LEFT JOIN pg_index x ON ((t.oid = x.indrelid)))
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+  WHERE (c.relkind = ANY (ARRAY['r'::"char", 't'::"char", 'm'::"char"]))
+  GROUP BY c.oid, n.nspname, c.relname, t.oid, x.indrelid;
+pg_statio_sys_indexes| SELECT pg_statio_all_indexes.relid,
+    pg_statio_all_indexes.indexrelid,
+    pg_statio_all_indexes.schemaname,
+    pg_statio_all_indexes.relname,
+    pg_statio_all_indexes.indexrelname,
+    pg_statio_all_indexes.idx_blks_read,
+    pg_statio_all_indexes.idx_blks_hit
+   FROM pg_statio_all_indexes
+  WHERE ((pg_statio_all_indexes.schemaname = ANY (ARRAY['pg_catalog'::name, 'information_schema'::name])) OR (pg_statio_all_indexes.schemaname ~ '^pg_toast'::text));
+pg_statio_sys_sequences| SELECT pg_statio_all_sequences.relid,
+    pg_statio_all_sequences.schemaname,
+    pg_statio_all_sequences.relname,
+    pg_statio_all_sequences.blks_read,
+    pg_statio_all_sequences.blks_hit
+   FROM pg_statio_all_sequences
+  WHERE ((pg_statio_all_sequences.schemaname = ANY (ARRAY['pg_catalog'::name, 'information_schema'::name])) OR (pg_statio_all_sequences.schemaname ~ '^pg_toast'::text));
+pg_statio_sys_tables| SELECT pg_statio_all_tables.relid,
+    pg_statio_all_tables.schemaname,
+    pg_statio_all_tables.relname,
+    pg_statio_all_tables.heap_blks_read,
+    pg_statio_all_tables.heap_blks_hit,
+    pg_statio_all_tables.idx_blks_read,
+    pg_statio_all_tables.idx_blks_hit,
+    pg_statio_all_tables.toast_blks_read,
+    pg_statio_all_tables.toast_blks_hit,
+    pg_statio_all_tables.tidx_blks_read,
+    pg_statio_all_tables.tidx_blks_hit
+   FROM pg_statio_all_tables
+  WHERE ((pg_statio_all_tables.schemaname = ANY (ARRAY['pg_catalog'::name, 'information_schema'::name])) OR (pg_statio_all_tables.schemaname ~ '^pg_toast'::text));
+pg_statio_user_indexes| SELECT pg_statio_all_indexes.relid,
+    pg_statio_all_indexes.indexrelid,
+    pg_statio_all_indexes.schemaname,
+    pg_statio_all_indexes.relname,
+    pg_statio_all_indexes.indexrelname,
+    pg_statio_all_indexes.idx_blks_read,
+    pg_statio_all_indexes.idx_blks_hit
+   FROM pg_statio_all_indexes
+  WHERE ((pg_statio_all_indexes.schemaname <> ALL (ARRAY['pg_catalog'::name, 'information_schema'::name])) AND (pg_statio_all_indexes.schemaname !~ '^pg_toast'::text));
+pg_statio_user_sequences| SELECT pg_statio_all_sequences.relid,
+    pg_statio_all_sequences.schemaname,
+    pg_statio_all_sequences.relname,
+    pg_statio_all_sequences.blks_read,
+    pg_statio_all_sequences.blks_hit
+   FROM pg_statio_all_sequences
+  WHERE ((pg_statio_all_sequences.schemaname <> ALL (ARRAY['pg_catalog'::name, 'information_schema'::name])) AND (pg_statio_all_sequences.schemaname !~ '^pg_toast'::text));
+pg_statio_user_tables| SELECT pg_statio_all_tables.relid,
+    pg_statio_all_tables.schemaname,
+    pg_statio_all_tables.relname,
+    pg_statio_all_tables.heap_blks_read,
+    pg_statio_all_tables.heap_blks_hit,
+    pg_statio_all_tables.idx_blks_read,
+    pg_statio_all_tables.idx_blks_hit,
+    pg_statio_all_tables.toast_blks_read,
+    pg_statio_all_tables.toast_blks_hit,
+    pg_statio_all_tables.tidx_blks_read,
+    pg_statio_all_tables.tidx_blks_hit
+   FROM pg_statio_all_tables
+  WHERE ((pg_statio_all_tables.schemaname <> ALL (ARRAY['pg_catalog'::name, 'information_schema'::name])) AND (pg_statio_all_tables.schemaname !~ '^pg_toast'::text));
+pg_stats| SELECT n.nspname AS schemaname,
+    c.relname AS tablename,
+    a.attname,
+    s.stainherit AS inherited,
+    s.stanullfrac AS null_frac,
+    s.stawidth AS avg_width,
+    s.stadistinct AS n_distinct,
+        CASE
+            WHEN (s.stakind1 = 1) THEN s.stavalues1
+            WHEN (s.stakind2 = 1) THEN s.stavalues2
+            WHEN (s.stakind3 = 1) THEN s.stavalues3
+            WHEN (s.stakind4 = 1) THEN s.stavalues4
+            WHEN (s.stakind5 = 1) THEN s.stavalues5
+            ELSE NULL::anyarray
+        END AS most_common_vals,
+        CASE
+            WHEN (s.stakind1 = 1) THEN s.stanumbers1
+            WHEN (s.stakind2 = 1) THEN s.stanumbers2
+            WHEN (s.stakind3 = 1) THEN s.stanumbers3
+            WHEN (s.stakind4 = 1) THEN s.stanumbers4
+            WHEN (s.stakind5 = 1) THEN s.stanumbers5
+            ELSE NULL::real[]
+        END AS most_common_freqs,
+        CASE
+            WHEN (s.stakind1 = 2) THEN s.stavalues1
+            WHEN (s.stakind2 = 2) THEN s.stavalues2
+            WHEN (s.stakind3 = 2) THEN s.stavalues3
+            WHEN (s.stakind4 = 2) THEN s.stavalues4
+            WHEN (s.stakind5 = 2) THEN s.stavalues5
+            ELSE NULL::anyarray
+        END AS histogram_bounds,
+        CASE
+            WHEN (s.stakind1 = 3) THEN s.stanumbers1[1]
+            WHEN (s.stakind2 = 3) THEN s.stanumbers2[1]
+            WHEN (s.stakind3 = 3) THEN s.stanumbers3[1]
+            WHEN (s.stakind4 = 3) THEN s.stanumbers4[1]
+            WHEN (s.stakind5 = 3) THEN s.stanumbers5[1]
+            ELSE NULL::real
+        END AS correlation,
+        CASE
+            WHEN (s.stakind1 = 4) THEN s.stavalues1
+            WHEN (s.stakind2 = 4) THEN s.stavalues2
+            WHEN (s.stakind3 = 4) THEN s.stavalues3
+            WHEN (s.stakind4 = 4) THEN s.stavalues4
+            WHEN (s.stakind5 = 4) THEN s.stavalues5
+            ELSE NULL::anyarray
+        END AS most_common_elems,
+        CASE
+            WHEN (s.stakind1 = 4) THEN s.stanumbers1
+            WHEN (s.stakind2 = 4) THEN s.stanumbers2
+            WHEN (s.stakind3 = 4) THEN s.stanumbers3
+            WHEN (s.stakind4 = 4) THEN s.stanumbers4
+            WHEN (s.stakind5 = 4) THEN s.stanumbers5
+            ELSE NULL::real[]
+        END AS most_common_elem_freqs,
+        CASE
+            WHEN (s.stakind1 = 5) THEN s.stanumbers1
+            WHEN (s.stakind2 = 5) THEN s.stanumbers2
+            WHEN (s.stakind3 = 5) THEN s.stanumbers3
+            WHEN (s.stakind4 = 5) THEN s.stanumbers4
+            WHEN (s.stakind5 = 5) THEN s.stanumbers5
+            ELSE NULL::real[]
+        END AS elem_count_histogram
+   FROM (((pg_statistic s
+     JOIN pg_class c ON ((c.oid = s.starelid)))
+     JOIN pg_attribute a ON (((c.oid = a.attrelid) AND (a.attnum = s.staattnum))))
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+  WHERE ((NOT a.attisdropped) AND has_column_privilege(c.oid, a.attnum, 'select'::text) AND ((c.relrowsecurity = false) OR (NOT row_security_active(c.oid))));
+pg_tables| SELECT n.nspname AS schemaname,
+    c.relname AS tablename,
+    pg_get_userbyid(c.relowner) AS tableowner,
+    t.spcname AS tablespace,
+    c.relhasindex AS hasindexes,
+    c.relhasrules AS hasrules,
+    c.relhastriggers AS hastriggers,
+    c.relrowsecurity AS rowsecurity
+   FROM ((pg_class c
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+     LEFT JOIN pg_tablespace t ON ((t.oid = c.reltablespace)))
+  WHERE (c.relkind = ANY (ARRAY['r'::"char", 'p'::"char"]));
+pg_timezone_abbrevs| SELECT pg_timezone_abbrevs.abbrev,
+    pg_timezone_abbrevs.utc_offset,
+    pg_timezone_abbrevs.is_dst
+   FROM pg_timezone_abbrevs() pg_timezone_abbrevs(abbrev, utc_offset, is_dst);
+pg_timezone_names| SELECT pg_timezone_names.name,
+    pg_timezone_names.abbrev,
+    pg_timezone_names.utc_offset,
+    pg_timezone_names.is_dst
+   FROM pg_timezone_names() pg_timezone_names(name, abbrev, utc_offset, is_dst);
+pg_user| SELECT pg_shadow.usename,
+    pg_shadow.usesysid,
+    pg_shadow.usecreatedb,
+    pg_shadow.usesuper,
+    pg_shadow.userepl,
+    pg_shadow.usebypassrls,
+    '********'::text AS passwd,
+    pg_shadow.valuntil,
+    pg_shadow.useconfig
+   FROM pg_shadow;
+pg_user_mappings| SELECT u.oid AS umid,
+    s.oid AS srvid,
+    s.srvname,
+    u.umuser,
+        CASE
+            WHEN (u.umuser = (0)::oid) THEN 'public'::name
+            ELSE a.rolname
+        END AS usename,
+        CASE
+            WHEN (((u.umuser <> (0)::oid) AND (a.rolname = CURRENT_USER) AND (pg_has_role(s.srvowner, 'USAGE'::text) OR has_server_privilege(s.oid, 'USAGE'::text))) OR ((u.umuser = (0)::oid) AND pg_has_role(s.srvowner, 'USAGE'::text)) OR ( SELECT pg_authid.rolsuper
+               FROM pg_authid
+              WHERE (pg_authid.rolname = CURRENT_USER))) THEN u.umoptions
+            ELSE NULL::text[]
+        END AS umoptions
+   FROM ((pg_user_mapping u
+     JOIN pg_foreign_server s ON ((u.umserver = s.oid)))
+     LEFT JOIN pg_authid a ON ((a.oid = u.umuser)));
+pg_views| SELECT n.nspname AS schemaname,
+    c.relname AS viewname,
+    pg_get_userbyid(c.relowner) AS viewowner,
+    pg_get_viewdef(c.oid) AS definition
+   FROM (pg_class c
+     LEFT JOIN pg_namespace n ON ((n.oid = c.relnamespace)))
+  WHERE (c.relkind = 'v'::"char");
+rtest_v1| SELECT rtest_t1.a,
+    rtest_t1.b
+   FROM rtest_t1;
+rtest_vcomp| SELECT x.part,
+    (x.size * y.factor) AS size_in_cm
+   FROM rtest_comp x,
+    rtest_unitfact y
+  WHERE (x.unit = y.unit);
+rtest_vview1| SELECT x.a,
+    x.b
+   FROM rtest_view1 x
+  WHERE (0 < ( SELECT count(*) AS count
+           FROM rtest_view2 y
+          WHERE (y.a = x.a)));
+rtest_vview2| SELECT rtest_view1.a,
+    rtest_view1.b
+   FROM rtest_view1
+  WHERE rtest_view1.v;
+rtest_vview3| SELECT x.a,
+    x.b
+   FROM rtest_vview2 x
+  WHERE (0 < ( SELECT count(*) AS count
+           FROM rtest_view2 y
+          WHERE (y.a = x.a)));
+rtest_vview4| SELECT x.a,
+    x.b,
+    count(y.a) AS refcount
+   FROM rtest_view1 x,
+    rtest_view2 y
+  WHERE (x.a = y.a)
+  GROUP BY x.a, x.b;
+rtest_vview5| SELECT rtest_view1.a,
+    rtest_view1.b,
+    rtest_viewfunc1(rtest_view1.a) AS refcount
+   FROM rtest_view1;
+shoe| SELECT sh.shoename,
+    sh.sh_avail,
+    sh.slcolor,
+    sh.slminlen,
+    (sh.slminlen * un.un_fact) AS slminlen_cm,
+    sh.slmaxlen,
+    (sh.slmaxlen * un.un_fact) AS slmaxlen_cm,
+    sh.slunit
+   FROM shoe_data sh,
+    unit un
+  WHERE (sh.slunit = un.un_name);
+shoe_ready| SELECT rsh.shoename,
+    rsh.sh_avail,
+    rsl.sl_name,
+    rsl.sl_avail,
+    int4smaller(rsh.sh_avail, rsl.sl_avail) AS total_avail
+   FROM shoe rsh,
+    shoelace rsl
+  WHERE ((rsl.sl_color = rsh.slcolor) AND (rsl.sl_len_cm >= rsh.slminlen_cm) AND (rsl.sl_len_cm <= rsh.slmaxlen_cm));
+shoelace| SELECT s.sl_name,
+    s.sl_avail,
+    s.sl_color,
+    s.sl_len,
+    s.sl_unit,
+    (s.sl_len * u.un_fact) AS sl_len_cm
+   FROM shoelace_data s,
+    unit u
+  WHERE (s.sl_unit = u.un_name);
+shoelace_candelete| SELECT shoelace_obsolete.sl_name,
+    shoelace_obsolete.sl_avail,
+    shoelace_obsolete.sl_color,
+    shoelace_obsolete.sl_len,
+    shoelace_obsolete.sl_unit,
+    shoelace_obsolete.sl_len_cm
+   FROM shoelace_obsolete
+  WHERE (shoelace_obsolete.sl_avail = 0);
+shoelace_obsolete| SELECT shoelace.sl_name,
+    shoelace.sl_avail,
+    shoelace.sl_color,
+    shoelace.sl_len,
+    shoelace.sl_unit,
+    shoelace.sl_len_cm
+   FROM shoelace
+  WHERE (NOT (EXISTS ( SELECT shoe.shoename
+           FROM shoe
+          WHERE (shoe.slcolor = shoelace.sl_color))));
+street| SELECT r.name,
+    r.thepath,
+    c.cname
+   FROM ONLY road r,
+    real_city c
+  WHERE (c.outline ## r.thepath);
+test_tablesample_v1| SELECT test_tablesample.id
+   FROM test_tablesample TABLESAMPLE system ((10 * 2)) REPEATABLE (2);
+test_tablesample_v2| SELECT test_tablesample.id
+   FROM test_tablesample TABLESAMPLE system (99);
+toyemp| SELECT emp.name,
+    emp.age,
+    emp.location,
+    (12 * emp.salary) AS annualsal
+   FROM emp;
+SELECT tablename, rulename, definition FROM pg_rules
+	ORDER BY tablename, rulename;
+pg_settings|pg_settings_n|CREATE RULE pg_settings_n AS
+    ON UPDATE TO pg_catalog.pg_settings DO INSTEAD NOTHING;
+pg_settings|pg_settings_u|CREATE RULE pg_settings_u AS
+    ON UPDATE TO pg_catalog.pg_settings
+   WHERE (new.name = old.name) DO  SELECT set_config(old.name, new.setting, false) AS set_config;
+rtest_emp|rtest_emp_del|CREATE RULE rtest_emp_del AS
+    ON DELETE TO public.rtest_emp DO  INSERT INTO rtest_emplog (ename, who, action, newsal, oldsal)
+  VALUES (old.ename, CURRENT_USER, 'fired'::bpchar, '$0.00'::money, old.salary);
+rtest_emp|rtest_emp_ins|CREATE RULE rtest_emp_ins AS
+    ON INSERT TO public.rtest_emp DO  INSERT INTO rtest_emplog (ename, who, action, newsal, oldsal)
+  VALUES (new.ename, CURRENT_USER, 'hired'::bpchar, new.salary, '$0.00'::money);
+rtest_emp|rtest_emp_upd|CREATE RULE rtest_emp_upd AS
+    ON UPDATE TO public.rtest_emp
+   WHERE (new.salary <> old.salary) DO  INSERT INTO rtest_emplog (ename, who, action, newsal, oldsal)
+  VALUES (new.ename, CURRENT_USER, 'honored'::bpchar, new.salary, old.salary);
+rtest_nothn1|rtest_nothn_r1|CREATE RULE rtest_nothn_r1 AS
+    ON INSERT TO public.rtest_nothn1
+   WHERE ((new.a >= 10) AND (new.a < 20)) DO INSTEAD NOTHING;
+rtest_nothn1|rtest_nothn_r2|CREATE RULE rtest_nothn_r2 AS
+    ON INSERT TO public.rtest_nothn1
+   WHERE ((new.a >= 30) AND (new.a < 40)) DO INSTEAD NOTHING;
+rtest_nothn2|rtest_nothn_r3|CREATE RULE rtest_nothn_r3 AS
+    ON INSERT TO public.rtest_nothn2
+   WHERE (new.a >= 100) DO INSTEAD  INSERT INTO rtest_nothn3 (a, b)
+  VALUES (new.a, new.b);
+rtest_nothn2|rtest_nothn_r4|CREATE RULE rtest_nothn_r4 AS
+    ON INSERT TO public.rtest_nothn2 DO INSTEAD NOTHING;
+rtest_order1|rtest_order_r1|CREATE RULE rtest_order_r1 AS
+    ON INSERT TO public.rtest_order1 DO INSTEAD  INSERT INTO rtest_order2 (a, b, c)
+  VALUES (new.a, nextval('rtest_seq'::regclass), 'rule 1 - this should run 1st'::text);
+rtest_order1|rtest_order_r2|CREATE RULE rtest_order_r2 AS
+    ON INSERT TO public.rtest_order1 DO  INSERT INTO rtest_order2 (a, b, c)
+  VALUES (new.a, nextval('rtest_seq'::regclass), 'rule 2 - this should run 2nd'::text);
+rtest_order1|rtest_order_r3|CREATE RULE rtest_order_r3 AS
+    ON INSERT TO public.rtest_order1 DO INSTEAD  INSERT INTO rtest_order2 (a, b, c)
+  VALUES (new.a, nextval('rtest_seq'::regclass), 'rule 3 - this should run 3rd'::text);
+rtest_order1|rtest_order_r4|CREATE RULE rtest_order_r4 AS
+    ON INSERT TO public.rtest_order1
+   WHERE (new.a < 100) DO INSTEAD  INSERT INTO rtest_order2 (a, b, c)
+  VALUES (new.a, nextval('rtest_seq'::regclass), 'rule 4 - this should run 4th'::text);
+rtest_person|rtest_pers_del|CREATE RULE rtest_pers_del AS
+    ON DELETE TO public.rtest_person DO  DELETE FROM rtest_admin
+  WHERE (rtest_admin.pname = old.pname);
+rtest_person|rtest_pers_upd|CREATE RULE rtest_pers_upd AS
+    ON UPDATE TO public.rtest_person DO  UPDATE rtest_admin SET pname = new.pname
+  WHERE (rtest_admin.pname = old.pname);
+rtest_system|rtest_sys_del|CREATE RULE rtest_sys_del AS
+    ON DELETE TO public.rtest_system DO ( DELETE FROM rtest_interface
+  WHERE (rtest_interface.sysname = old.sysname);
+ DELETE FROM rtest_admin
+  WHERE (rtest_admin.sysname = old.sysname);
+);
+rtest_system|rtest_sys_upd|CREATE RULE rtest_sys_upd AS
+    ON UPDATE TO public.rtest_system DO ( UPDATE rtest_interface SET sysname = new.sysname
+  WHERE (rtest_interface.sysname = old.sysname);
+ UPDATE rtest_admin SET sysname = new.sysname
+  WHERE (rtest_admin.sysname = old.sysname);
+);
+rtest_t4|rtest_t4_ins1|CREATE RULE rtest_t4_ins1 AS
+    ON INSERT TO public.rtest_t4
+   WHERE ((new.a >= 10) AND (new.a < 20)) DO INSTEAD  INSERT INTO rtest_t5 (a, b)
+  VALUES (new.a, new.b);
+rtest_t4|rtest_t4_ins2|CREATE RULE rtest_t4_ins2 AS
+    ON INSERT TO public.rtest_t4
+   WHERE ((new.a >= 20) AND (new.a < 30)) DO  INSERT INTO rtest_t6 (a, b)
+  VALUES (new.a, new.b);
+rtest_t5|rtest_t5_ins|CREATE RULE rtest_t5_ins AS
+    ON INSERT TO public.rtest_t5
+   WHERE (new.a > 15) DO  INSERT INTO rtest_t7 (a, b)
+  VALUES (new.a, new.b);
+rtest_t6|rtest_t6_ins|CREATE RULE rtest_t6_ins AS
+    ON INSERT TO public.rtest_t6
+   WHERE (new.a > 25) DO INSTEAD  INSERT INTO rtest_t8 (a, b)
+  VALUES (new.a, new.b);
+rtest_v1|rtest_v1_del|CREATE RULE rtest_v1_del AS
+    ON DELETE TO public.rtest_v1 DO INSTEAD  DELETE FROM rtest_t1
+  WHERE (rtest_t1.a = old.a);
+rtest_v1|rtest_v1_ins|CREATE RULE rtest_v1_ins AS
+    ON INSERT TO public.rtest_v1 DO INSTEAD  INSERT INTO rtest_t1 (a, b)
+  VALUES (new.a, new.b);
+rtest_v1|rtest_v1_upd|CREATE RULE rtest_v1_upd AS
+    ON UPDATE TO public.rtest_v1 DO INSTEAD  UPDATE rtest_t1 SET a = new.a, b = new.b
+  WHERE (rtest_t1.a = old.a);
+shoelace|shoelace_del|CREATE RULE shoelace_del AS
+    ON DELETE TO public.shoelace DO INSTEAD  DELETE FROM shoelace_data
+  WHERE (shoelace_data.sl_name = old.sl_name);
+shoelace|shoelace_ins|CREATE RULE shoelace_ins AS
+    ON INSERT TO public.shoelace DO INSTEAD  INSERT INTO shoelace_data (sl_name, sl_avail, sl_color, sl_len, sl_unit)
+  VALUES (new.sl_name, new.sl_avail, new.sl_color, new.sl_len, new.sl_unit);
+shoelace|shoelace_upd|CREATE RULE shoelace_upd AS
+    ON UPDATE TO public.shoelace DO INSTEAD  UPDATE shoelace_data SET sl_name = new.sl_name, sl_avail = new.sl_avail, sl_color = new.sl_color, sl_len = new.sl_len, sl_unit = new.sl_unit
+  WHERE (shoelace_data.sl_name = old.sl_name);
+shoelace_data|log_shoelace|CREATE RULE log_shoelace AS
+    ON UPDATE TO public.shoelace_data
+   WHERE (new.sl_avail <> old.sl_avail) DO  INSERT INTO shoelace_log (sl_name, sl_avail, log_who, log_when)
+  VALUES (new.sl_name, new.sl_avail, 'Al Bundy'::name, 'Thu Jan 01 00:00:00 1970'::timestamp without time zone);
+shoelace_ok|shoelace_ok_ins|CREATE RULE shoelace_ok_ins AS
+    ON INSERT TO public.shoelace_ok DO INSTEAD  UPDATE shoelace SET sl_avail = (shoelace.sl_avail + new.ok_quant)
+  WHERE (shoelace.sl_name = new.ok_name);
+-- restore normal output mode
+\a\t
+--
+-- CREATE OR REPLACE RULE
+--
+CREATE TABLE ruletest_tbl (a int, b int);
+CREATE TABLE ruletest_tbl2 (a int, b int);
+CREATE OR REPLACE RULE myrule AS ON INSERT TO ruletest_tbl
+	DO INSTEAD INSERT INTO ruletest_tbl2 VALUES (10, 10);
+INSERT INTO ruletest_tbl VALUES (99, 99);
+CREATE OR REPLACE RULE myrule AS ON INSERT TO ruletest_tbl
+	DO INSTEAD INSERT INTO ruletest_tbl2 VALUES (1000, 1000);
+INSERT INTO ruletest_tbl VALUES (99, 99);
+SELECT * FROM ruletest_tbl2;
+  a   |  b   
+------+------
+   10 |   10
+ 1000 | 1000
+(2 rows)
+
+-- Check that rewrite rules splitting one INSERT into multiple
+-- conditional statements does not disable FK checking.
+create table rule_and_refint_t1 (
+	id1a integer,
+	id1b integer,
+	primary key (id1a, id1b)
+);
+create table rule_and_refint_t2 (
+	id2a integer,
+	id2c integer,
+	primary key (id2a, id2c)
+);
+create table rule_and_refint_t3 (
+	id3a integer,
+	id3b integer,
+	id3c integer,
+	data text,
+	primary key (id3a, id3b, id3c),
+	foreign key (id3a, id3b) references rule_and_refint_t1 (id1a, id1b),
+	foreign key (id3a, id3c) references rule_and_refint_t2 (id2a, id2c)
+);
+insert into rule_and_refint_t1 values (1, 11);
+insert into rule_and_refint_t1 values (1, 12);
+insert into rule_and_refint_t1 values (2, 21);
+insert into rule_and_refint_t1 values (2, 22);
+insert into rule_and_refint_t2 values (1, 11);
+insert into rule_and_refint_t2 values (1, 12);
+insert into rule_and_refint_t2 values (2, 21);
+insert into rule_and_refint_t2 values (2, 22);
+insert into rule_and_refint_t3 values (1, 11, 11, 'row1');
+insert into rule_and_refint_t3 values (1, 11, 12, 'row2');
+insert into rule_and_refint_t3 values (1, 12, 11, 'row3');
+insert into rule_and_refint_t3 values (1, 12, 12, 'row4');
+insert into rule_and_refint_t3 values (1, 11, 13, 'row5');
+ERROR:  insert or update on table "rule_and_refint_t3" violates foreign key constraint "rule_and_refint_t3_id3a_fkey1"
+DETAIL:  Key (id3a, id3c)=(1, 13) is not present in table "rule_and_refint_t2".
+insert into rule_and_refint_t3 values (1, 13, 11, 'row6');
+ERROR:  insert or update on table "rule_and_refint_t3" violates foreign key constraint "rule_and_refint_t3_id3a_fkey"
+DETAIL:  Key (id3a, id3b)=(1, 13) is not present in table "rule_and_refint_t1".
+-- Ordinary table
+insert into rule_and_refint_t3 values (1, 13, 11, 'row6')
+  on conflict do nothing;
+ERROR:  insert or update on table "rule_and_refint_t3" violates foreign key constraint "rule_and_refint_t3_id3a_fkey"
+DETAIL:  Key (id3a, id3b)=(1, 13) is not present in table "rule_and_refint_t1".
+-- rule not fired, so fk violation
+insert into rule_and_refint_t3 values (1, 13, 11, 'row6')
+  on conflict (id3a, id3b, id3c) do update
+  set id3b = excluded.id3b;
+ERROR:  insert or update on table "rule_and_refint_t3" violates foreign key constraint "rule_and_refint_t3_id3a_fkey"
+DETAIL:  Key (id3a, id3b)=(1, 13) is not present in table "rule_and_refint_t1".
+-- rule fired, so unsupported
+insert into shoelace values ('sl9', 0, 'pink', 35.0, 'inch', 0.0)
+  on conflict (sl_name) do update
+  set sl_avail = excluded.sl_avail;
+ERROR:  INSERT with ON CONFLICT clause cannot be used with table that has INSERT or UPDATE rules
+create rule rule_and_refint_t3_ins as on insert to rule_and_refint_t3
+	where (exists (select 1 from rule_and_refint_t3
+			where (((rule_and_refint_t3.id3a = new.id3a)
+			and (rule_and_refint_t3.id3b = new.id3b))
+			and (rule_and_refint_t3.id3c = new.id3c))))
+	do instead update rule_and_refint_t3 set data = new.data
+	where (((rule_and_refint_t3.id3a = new.id3a)
+	and (rule_and_refint_t3.id3b = new.id3b))
+	and (rule_and_refint_t3.id3c = new.id3c));
+insert into rule_and_refint_t3 values (1, 11, 13, 'row7');
+ERROR:  insert or update on table "rule_and_refint_t3" violates foreign key constraint "rule_and_refint_t3_id3a_fkey1"
+DETAIL:  Key (id3a, id3c)=(1, 13) is not present in table "rule_and_refint_t2".
+insert into rule_and_refint_t3 values (1, 13, 11, 'row8');
+ERROR:  insert or update on table "rule_and_refint_t3" violates foreign key constraint "rule_and_refint_t3_id3a_fkey"
+DETAIL:  Key (id3a, id3b)=(1, 13) is not present in table "rule_and_refint_t1".
+--
+-- disallow dropping a view's rule (bug #5072)
+--
+create view rules_fooview as select 'rules_foo'::text;
+drop rule "_RETURN" on rules_fooview;
+ERROR:  cannot drop rule _RETURN on view rules_fooview because view rules_fooview requires it
+HINT:  You can drop view rules_fooview instead.
+drop view rules_fooview;
+--
+-- test conversion of table to view (needed to load some pg_dump files)
+--
+create table rules_fooview (x int, y text);
+select xmin, * from rules_fooview;
+ xmin | x | y 
+------+---+---
+(0 rows)
+
+create rule "_RETURN" as on select to rules_fooview do instead
+  select 1 as x, 'aaa'::text as y;
+select * from rules_fooview;
+ x |  y  
+---+-----
+ 1 | aaa
+(1 row)
+
+select xmin, * from rules_fooview;  -- fail, views don't have such a column
+ERROR:  column "xmin" does not exist
+LINE 1: select xmin, * from rules_fooview;
+               ^
+select reltoastrelid, relkind, relfrozenxid
+  from pg_class where oid = 'rules_fooview'::regclass;
+ reltoastrelid | relkind | relfrozenxid 
+---------------+---------+--------------
+             0 | v       |            0
+(1 row)
+
+drop view rules_fooview;
+-- trying to convert a partitioned table to view is not allowed
+create table rules_fooview (x int, y text) partition by list (x);
+create rule "_RETURN" as on select to rules_fooview do instead
+  select 1 as x, 'aaa'::text as y;
+ERROR:  cannot convert partitioned table "rules_fooview" to a view
+-- nor can one convert a partition to view
+create table rules_fooview_part partition of rules_fooview for values in (1);
+create rule "_RETURN" as on select to rules_fooview_part do instead
+  select 1 as x, 'aaa'::text as y;
+ERROR:  cannot convert partition "rules_fooview_part" to a view
+--
+-- check for planner problems with complex inherited UPDATES
+--
+create table id (id serial primary key, name text);
+-- currently, must respecify PKEY for each inherited subtable
+create table test_1 (id integer primary key) inherits (id);
+NOTICE:  merging column "id" with inherited definition
+create table test_2 (id integer primary key) inherits (id);
+NOTICE:  merging column "id" with inherited definition
+create table test_3 (id integer primary key) inherits (id);
+NOTICE:  merging column "id" with inherited definition
+insert into test_1 (name) values ('Test 1');
+insert into test_1 (name) values ('Test 2');
+insert into test_2 (name) values ('Test 3');
+insert into test_2 (name) values ('Test 4');
+insert into test_3 (name) values ('Test 5');
+insert into test_3 (name) values ('Test 6');
+create view id_ordered as select * from id order by id;
+create rule update_id_ordered as on update to id_ordered
+	do instead update id set name = new.name where id = old.id;
+select * from id_ordered;
+ id |  name  
+----+--------
+  1 | Test 1
+  2 | Test 2
+  3 | Test 3
+  4 | Test 4
+  5 | Test 5
+  6 | Test 6
+(6 rows)
+
+update id_ordered set name = 'update 2' where id = 2;
+update id_ordered set name = 'update 4' where id = 4;
+update id_ordered set name = 'update 5' where id = 5;
+select * from id_ordered;
+ id |   name   
+----+----------
+  1 | Test 1
+  2 | update 2
+  3 | Test 3
+  4 | update 4
+  5 | update 5
+  6 | Test 6
+(6 rows)
+
+\set VERBOSITY terse \\ -- suppress cascade details
+drop table id cascade;
+NOTICE:  drop cascades to 4 other objects
+\set VERBOSITY default
+--
+-- check corner case where an entirely-dummy subplan is created by
+-- constraint exclusion
+--
+create temp table t1 (a integer primary key);
+create temp table t1_1 (check (a >= 0 and a < 10)) inherits (t1);
+create temp table t1_2 (check (a >= 10 and a < 20)) inherits (t1);
+create rule t1_ins_1 as on insert to t1
+	where new.a >= 0 and new.a < 10
+	do instead
+	insert into t1_1 values (new.a);
+create rule t1_ins_2 as on insert to t1
+	where new.a >= 10 and new.a < 20
+	do instead
+	insert into t1_2 values (new.a);
+create rule t1_upd_1 as on update to t1
+	where old.a >= 0 and old.a < 10
+	do instead
+	update t1_1 set a = new.a where a = old.a;
+create rule t1_upd_2 as on update to t1
+	where old.a >= 10 and old.a < 20
+	do instead
+	update t1_2 set a = new.a where a = old.a;
+set constraint_exclusion = on;
+insert into t1 select * from generate_series(5,19,1) g;
+update t1 set a = 4 where a = 5;
+select * from only t1;
+ a 
+---
+(0 rows)
+
+select * from only t1_1 order by a;
+ a 
+---
+ 4
+ 6
+ 7
+ 8
+ 9
+(5 rows)
+
+select * from only t1_2 order by a;
+ a  
+----
+ 10
+ 11
+ 12
+ 13
+ 14
+ 15
+ 16
+ 17
+ 18
+ 19
+(10 rows)
+
+reset constraint_exclusion;
+-- test various flavors of pg_get_viewdef()
+select pg_get_viewdef('shoe'::regclass) as unpretty;
+                    unpretty                    
+------------------------------------------------
+  SELECT sh.shoename,                          +
+     sh.sh_avail,                              +
+     sh.slcolor,                               +
+     sh.slminlen,                              +
+     (sh.slminlen * un.un_fact) AS slminlen_cm,+
+     sh.slmaxlen,                              +
+     (sh.slmaxlen * un.un_fact) AS slmaxlen_cm,+
+     sh.slunit                                 +
+    FROM shoe_data sh,                         +
+     unit un                                   +
+   WHERE (sh.slunit = un.un_name);
+(1 row)
+
+select pg_get_viewdef('shoe'::regclass,true) as pretty;
+                    pretty                    
+----------------------------------------------
+  SELECT sh.shoename,                        +
+     sh.sh_avail,                            +
+     sh.slcolor,                             +
+     sh.slminlen,                            +
+     sh.slminlen * un.un_fact AS slminlen_cm,+
+     sh.slmaxlen,                            +
+     sh.slmaxlen * un.un_fact AS slmaxlen_cm,+
+     sh.slunit                               +
+    FROM shoe_data sh,                       +
+     unit un                                 +
+   WHERE sh.slunit = un.un_name;
+(1 row)
+
+select pg_get_viewdef('shoe'::regclass,0) as prettier;
+                   prettier                   
+----------------------------------------------
+  SELECT sh.shoename,                        +
+     sh.sh_avail,                            +
+     sh.slcolor,                             +
+     sh.slminlen,                            +
+     sh.slminlen * un.un_fact AS slminlen_cm,+
+     sh.slmaxlen,                            +
+     sh.slmaxlen * un.un_fact AS slmaxlen_cm,+
+     sh.slunit                               +
+    FROM shoe_data sh,                       +
+     unit un                                 +
+   WHERE sh.slunit = un.un_name;
+(1 row)
+
+--
+-- check multi-row VALUES in rules
+--
+create table rules_src(f1 int, f2 int);
+create table rules_log(f1 int, f2 int, tag text);
+insert into rules_src values(1,2), (11,12);
+create rule r1 as on update to rules_src do also
+  insert into rules_log values(old.*, 'old'), (new.*, 'new');
+update rules_src set f2 = f2 + 1;
+update rules_src set f2 = f2 * 10;
+select * from rules_src;
+ f1 | f2  
+----+-----
+  1 |  30
+ 11 | 130
+(2 rows)
+
+select * from rules_log;
+ f1 | f2  | tag 
+----+-----+-----
+  1 |   2 | old
+  1 |   3 | new
+ 11 |  12 | old
+ 11 |  13 | new
+  1 |   3 | old
+  1 |  30 | new
+ 11 |  13 | old
+ 11 | 130 | new
+(8 rows)
+
+create rule r2 as on update to rules_src do also
+  values(old.*, 'old'), (new.*, 'new');
+update rules_src set f2 = f2 / 10;
+ column1 | column2 | column3 
+---------+---------+---------
+       1 |      30 | old
+       1 |       3 | new
+      11 |     130 | old
+      11 |      13 | new
+(4 rows)
+
+select * from rules_src;
+ f1 | f2 
+----+----
+  1 |  3
+ 11 | 13
+(2 rows)
+
+select * from rules_log;
+ f1 | f2  | tag 
+----+-----+-----
+  1 |   2 | old
+  1 |   3 | new
+ 11 |  12 | old
+ 11 |  13 | new
+  1 |   3 | old
+  1 |  30 | new
+ 11 |  13 | old
+ 11 | 130 | new
+  1 |  30 | old
+  1 |   3 | new
+ 11 | 130 | old
+ 11 |  13 | new
+(12 rows)
+
+create rule r3 as on delete to rules_src do notify rules_src_deletion;
+\d+ rules_src
+                                 Table "public.rules_src"
+ Column |  Type   | Collation | Nullable | Default | Storage | Stats target | Description 
+--------+---------+-----------+----------+---------+---------+--------------+-------------
+ f1     | integer |           |          |         | plain   |              | 
+ f2     | integer |           |          |         | plain   |              | 
+Rules:
+    r1 AS
+    ON UPDATE TO rules_src DO  INSERT INTO rules_log (f1, f2, tag) VALUES (old.f1,old.f2,'old'::text), (new.f1,new.f2,'new'::text)
+    r2 AS
+    ON UPDATE TO rules_src DO  VALUES (old.f1,old.f2,'old'::text), (new.f1,new.f2,'new'::text)
+    r3 AS
+    ON DELETE TO rules_src DO
+ NOTIFY rules_src_deletion
+
+--
+-- Ensure an aliased target relation for insert is correctly deparsed.
+--
+create rule r4 as on insert to rules_src do instead insert into rules_log AS trgt SELECT NEW.* RETURNING trgt.f1, trgt.f2;
+create rule r5 as on update to rules_src do instead UPDATE rules_log AS trgt SET tag = 'updated' WHERE trgt.f1 = new.f1;
+\d+ rules_src
+                                 Table "public.rules_src"
+ Column |  Type   | Collation | Nullable | Default | Storage | Stats target | Description 
+--------+---------+-----------+----------+---------+---------+--------------+-------------
+ f1     | integer |           |          |         | plain   |              | 
+ f2     | integer |           |          |         | plain   |              | 
+Rules:
+    r1 AS
+    ON UPDATE TO rules_src DO  INSERT INTO rules_log (f1, f2, tag) VALUES (old.f1,old.f2,'old'::text), (new.f1,new.f2,'new'::text)
+    r2 AS
+    ON UPDATE TO rules_src DO  VALUES (old.f1,old.f2,'old'::text), (new.f1,new.f2,'new'::text)
+    r3 AS
+    ON DELETE TO rules_src DO
+ NOTIFY rules_src_deletion
+    r4 AS
+    ON INSERT TO rules_src DO INSTEAD  INSERT INTO rules_log AS trgt (f1, f2)  SELECT new.f1,
+            new.f2
+  RETURNING trgt.f1,
+    trgt.f2
+    r5 AS
+    ON UPDATE TO rules_src DO INSTEAD  UPDATE rules_log trgt SET tag = 'updated'::text
+  WHERE trgt.f1 = new.f1
+
+--
+-- check alter rename rule
+--
+CREATE TABLE rule_t1 (a INT);
+CREATE VIEW rule_v1 AS SELECT * FROM rule_t1;
+CREATE RULE InsertRule AS
+    ON INSERT TO rule_v1
+    DO INSTEAD
+        INSERT INTO rule_t1 VALUES(new.a);
+ALTER RULE InsertRule ON rule_v1 RENAME to NewInsertRule;
+INSERT INTO rule_v1 VALUES(1);
+SELECT * FROM rule_v1;
+ a 
+---
+ 1
+(1 row)
+
+\d+ rule_v1
+                           View "public.rule_v1"
+ Column |  Type   | Collation | Nullable | Default | Storage | Description 
+--------+---------+-----------+----------+---------+---------+-------------
+ a      | integer |           |          |         | plain   | 
+View definition:
+ SELECT rule_t1.a
+   FROM rule_t1;
+Rules:
+ newinsertrule AS
+    ON INSERT TO rule_v1 DO INSTEAD  INSERT INTO rule_t1 (a)
+  VALUES (new.a)
+
+--
+-- error conditions for alter rename rule
+--
+ALTER RULE InsertRule ON rule_v1 RENAME TO NewInsertRule; -- doesn't exist
+ERROR:  rule "insertrule" for relation "rule_v1" does not exist
+ALTER RULE NewInsertRule ON rule_v1 RENAME TO "_RETURN"; -- already exists
+ERROR:  rule "_RETURN" for relation "rule_v1" already exists
+ALTER RULE "_RETURN" ON rule_v1 RENAME TO abc; -- ON SELECT rule cannot be renamed
+ERROR:  renaming an ON SELECT rule is not allowed
+DROP VIEW rule_v1;
+DROP TABLE rule_t1;
+--
+-- check display of VALUES in view definitions
+--
+create view rule_v1 as values(1,2);
+\d+ rule_v1
+                           View "public.rule_v1"
+ Column  |  Type   | Collation | Nullable | Default | Storage | Description 
+---------+---------+-----------+----------+---------+---------+-------------
+ column1 | integer |           |          |         | plain   | 
+ column2 | integer |           |          |         | plain   | 
+View definition:
+ VALUES (1,2);
+
+drop view rule_v1;
+create view rule_v1(x) as values(1,2);
+\d+ rule_v1
+                           View "public.rule_v1"
+ Column  |  Type   | Collation | Nullable | Default | Storage | Description 
+---------+---------+-----------+----------+---------+---------+-------------
+ x       | integer |           |          |         | plain   | 
+ column2 | integer |           |          |         | plain   | 
+View definition:
+ SELECT "*VALUES*".column1 AS x,
+    "*VALUES*".column2
+   FROM (VALUES (1,2)) "*VALUES*";
+
+drop view rule_v1;
+create view rule_v1(x) as select * from (values(1,2)) v;
+\d+ rule_v1
+                           View "public.rule_v1"
+ Column  |  Type   | Collation | Nullable | Default | Storage | Description 
+---------+---------+-----------+----------+---------+---------+-------------
+ x       | integer |           |          |         | plain   | 
+ column2 | integer |           |          |         | plain   | 
+View definition:
+ SELECT v.column1 AS x,
+    v.column2
+   FROM ( VALUES (1,2)) v;
+
+drop view rule_v1;
+create view rule_v1(x) as select * from (values(1,2)) v(q,w);
+\d+ rule_v1
+                           View "public.rule_v1"
+ Column |  Type   | Collation | Nullable | Default | Storage | Description 
+--------+---------+-----------+----------+---------+---------+-------------
+ x      | integer |           |          |         | plain   | 
+ w      | integer |           |          |         | plain   | 
+View definition:
+ SELECT v.q AS x,
+    v.w
+   FROM ( VALUES (1,2)) v(q, w);
+
+drop view rule_v1;
+--
+-- Check DO INSTEAD rules with ON CONFLICT
+--
+CREATE TABLE hats (
+	hat_name    char(10) primary key,
+	hat_color   char(10)      -- hat color
+);
+CREATE TABLE hat_data (
+	hat_name    char(10),
+	hat_color   char(10)      -- hat color
+);
+create unique index hat_data_unique_idx
+  on hat_data (hat_name COLLATE "C" bpchar_pattern_ops);
+-- DO NOTHING with ON CONFLICT
+CREATE RULE hat_nosert AS ON INSERT TO hats
+    DO INSTEAD
+    INSERT INTO hat_data VALUES (
+           NEW.hat_name,
+           NEW.hat_color)
+        ON CONFLICT (hat_name COLLATE "C" bpchar_pattern_ops) WHERE hat_color = 'green'
+        DO NOTHING
+        RETURNING *;
+SELECT definition FROM pg_rules WHERE tablename = 'hats' ORDER BY rulename;
+                                         definition                                          
+---------------------------------------------------------------------------------------------
+ CREATE RULE hat_nosert AS                                                                  +
+     ON INSERT TO public.hats DO INSTEAD  INSERT INTO hat_data (hat_name, hat_color)        +
+   VALUES (new.hat_name, new.hat_color) ON CONFLICT(hat_name COLLATE "C" bpchar_pattern_ops)+
+   WHERE (hat_color = 'green'::bpchar) DO NOTHING                                           +
+   RETURNING hat_data.hat_name,                                                             +
+     hat_data.hat_color;
+(1 row)
+
+-- Works (projects row)
+INSERT INTO hats VALUES ('h7', 'black') RETURNING *;
+  hat_name  | hat_color  
+------------+------------
+ h7         | black     
+(1 row)
+
+-- Works (does nothing)
+INSERT INTO hats VALUES ('h7', 'black') RETURNING *;
+ hat_name | hat_color 
+----------+-----------
+(0 rows)
+
+SELECT tablename, rulename, definition FROM pg_rules
+	WHERE tablename = 'hats';
+ tablename |  rulename  |                                         definition                                          
+-----------+------------+---------------------------------------------------------------------------------------------
+ hats      | hat_nosert | CREATE RULE hat_nosert AS                                                                  +
+           |            |     ON INSERT TO public.hats DO INSTEAD  INSERT INTO hat_data (hat_name, hat_color)        +
+           |            |   VALUES (new.hat_name, new.hat_color) ON CONFLICT(hat_name COLLATE "C" bpchar_pattern_ops)+
+           |            |   WHERE (hat_color = 'green'::bpchar) DO NOTHING                                           +
+           |            |   RETURNING hat_data.hat_name,                                                             +
+           |            |     hat_data.hat_color;
+(1 row)
+
+DROP RULE hat_nosert ON hats;
+-- DO NOTHING without ON CONFLICT
+CREATE RULE hat_nosert_all AS ON INSERT TO hats
+    DO INSTEAD
+    INSERT INTO hat_data VALUES (
+           NEW.hat_name,
+           NEW.hat_color)
+        ON CONFLICT
+        DO NOTHING
+        RETURNING *;
+SELECT definition FROM pg_rules WHERE tablename = 'hats' ORDER BY rulename;
+                                     definition                                      
+-------------------------------------------------------------------------------------
+ CREATE RULE hat_nosert_all AS                                                      +
+     ON INSERT TO public.hats DO INSTEAD  INSERT INTO hat_data (hat_name, hat_color)+
+   VALUES (new.hat_name, new.hat_color) ON CONFLICT DO NOTHING                      +
+   RETURNING hat_data.hat_name,                                                     +
+     hat_data.hat_color;
+(1 row)
+
+DROP RULE hat_nosert_all ON hats;
+-- Works (does nothing)
+INSERT INTO hats VALUES ('h7', 'black') RETURNING *;
+  hat_name  | hat_color  
+------------+------------
+ h7         | black     
+(1 row)
+
+-- DO UPDATE with a WHERE clause
+CREATE RULE hat_upsert AS ON INSERT TO hats
+    DO INSTEAD
+    INSERT INTO hat_data VALUES (
+           NEW.hat_name,
+           NEW.hat_color)
+        ON CONFLICT (hat_name)
+        DO UPDATE
+           SET hat_name = hat_data.hat_name, hat_color = excluded.hat_color
+           WHERE excluded.hat_color <>  'forbidden' AND hat_data.* != excluded.*
+        RETURNING *;
+SELECT definition FROM pg_rules WHERE tablename = 'hats' ORDER BY rulename;
+                                                               definition                                                                
+-----------------------------------------------------------------------------------------------------------------------------------------
+ CREATE RULE hat_upsert AS                                                                                                              +
+     ON INSERT TO public.hats DO INSTEAD  INSERT INTO hat_data (hat_name, hat_color)                                                    +
+   VALUES (new.hat_name, new.hat_color) ON CONFLICT(hat_name) DO UPDATE SET hat_name = hat_data.hat_name, hat_color = excluded.hat_color+
+   WHERE ((excluded.hat_color <> 'forbidden'::bpchar) AND (hat_data.* <> excluded.*))                                                   +
+   RETURNING hat_data.hat_name,                                                                                                         +
+     hat_data.hat_color;
+(1 row)
+
+-- Works (does upsert)
+INSERT INTO hats VALUES ('h8', 'black') RETURNING *;
+  hat_name  | hat_color  
+------------+------------
+ h8         | black     
+(1 row)
+
+SELECT * FROM hat_data WHERE hat_name = 'h8';
+  hat_name  | hat_color  
+------------+------------
+ h8         | black     
+(1 row)
+
+INSERT INTO hats VALUES ('h8', 'white') RETURNING *;
+  hat_name  | hat_color  
+------------+------------
+ h8         | white     
+(1 row)
+
+SELECT * FROM hat_data WHERE hat_name = 'h8';
+  hat_name  | hat_color  
+------------+------------
+ h8         | white     
+(1 row)
+
+INSERT INTO hats VALUES ('h8', 'forbidden') RETURNING *;
+ hat_name | hat_color 
+----------+-----------
+(0 rows)
+
+SELECT * FROM hat_data WHERE hat_name = 'h8';
+  hat_name  | hat_color  
+------------+------------
+ h8         | white     
+(1 row)
+
+SELECT tablename, rulename, definition FROM pg_rules
+	WHERE tablename = 'hats';
+ tablename |  rulename  |                                                               definition                                                                
+-----------+------------+-----------------------------------------------------------------------------------------------------------------------------------------
+ hats      | hat_upsert | CREATE RULE hat_upsert AS                                                                                                              +
+           |            |     ON INSERT TO public.hats DO INSTEAD  INSERT INTO hat_data (hat_name, hat_color)                                                    +
+           |            |   VALUES (new.hat_name, new.hat_color) ON CONFLICT(hat_name) DO UPDATE SET hat_name = hat_data.hat_name, hat_color = excluded.hat_color+
+           |            |   WHERE ((excluded.hat_color <> 'forbidden'::bpchar) AND (hat_data.* <> excluded.*))                                                   +
+           |            |   RETURNING hat_data.hat_name,                                                                                                         +
+           |            |     hat_data.hat_color;
+(1 row)
+
+-- ensure explain works for on insert conflict rules
+explain (costs off) INSERT INTO hats VALUES ('h8', 'forbidden') RETURNING *;
+                                           QUERY PLAN                                            
+-------------------------------------------------------------------------------------------------
+ Insert on hat_data
+   Conflict Resolution: UPDATE
+   Conflict Arbiter Indexes: hat_data_unique_idx
+   Conflict Filter: ((excluded.hat_color <> 'forbidden'::bpchar) AND (hat_data.* <> excluded.*))
+   ->  Result
+(5 rows)
+
+-- ensure upserting into a rule, with a CTE (different offsets!) works
+WITH data(hat_name, hat_color) AS (
+    VALUES ('h8', 'green'),
+        ('h9', 'blue'),
+        ('h7', 'forbidden')
+)
+INSERT INTO hats
+    SELECT * FROM data
+RETURNING *;
+  hat_name  | hat_color  
+------------+------------
+ h8         | green     
+ h9         | blue      
+(2 rows)
+
+EXPLAIN (costs off) WITH data(hat_name, hat_color) AS (
+    VALUES ('h8', 'green'),
+        ('h9', 'blue'),
+        ('h7', 'forbidden')
+)
+INSERT INTO hats
+    SELECT * FROM data
+RETURNING *;
+                                           QUERY PLAN                                            
+-------------------------------------------------------------------------------------------------
+ Insert on hat_data
+   Conflict Resolution: UPDATE
+   Conflict Arbiter Indexes: hat_data_unique_idx
+   Conflict Filter: ((excluded.hat_color <> 'forbidden'::bpchar) AND (hat_data.* <> excluded.*))
+   CTE data
+     ->  Values Scan on "*VALUES*"
+   ->  CTE Scan on data
+(7 rows)
+
+SELECT * FROM hat_data WHERE hat_name IN ('h8', 'h9', 'h7') ORDER BY hat_name;
+  hat_name  | hat_color  
+------------+------------
+ h7         | black     
+ h8         | green     
+ h9         | blue      
+(3 rows)
+
+DROP RULE hat_upsert ON hats;
+drop table hats;
+drop table hat_data;
+-- test for pg_get_functiondef properly regurgitating SET parameters
+-- Note that the function is kept around to stress pg_dump.
+CREATE FUNCTION func_with_set_params() RETURNS integer
+    AS 'select 1;'
+    LANGUAGE SQL
+    SET search_path TO PG_CATALOG
+    SET extra_float_digits TO 2
+    SET work_mem TO '4MB'
+    SET datestyle to iso, mdy
+    SET local_preload_libraries TO "Mixed/Case", 'c:/"a"/path'
+    IMMUTABLE STRICT;
+SELECT pg_get_functiondef('func_with_set_params()'::regprocedure);
+                      pg_get_functiondef                       
+---------------------------------------------------------------
+ CREATE OR REPLACE FUNCTION public.func_with_set_params()     +
+  RETURNS integer                                             +
+  LANGUAGE sql                                                +
+  IMMUTABLE STRICT                                            +
+  SET search_path TO pg_catalog                               +
+  SET extra_float_digits TO '2'                               +
+  SET work_mem TO '4MB'                                       +
+  SET "DateStyle" TO 'iso, mdy'                               +
+  SET local_preload_libraries TO "Mixed/Case", "c:/""a""/path"+
+ AS $function$select 1;$function$                             +
+ 
+(1 row)
+
+-- tests for pg_get_*def with invalid objects
+SELECT pg_get_constraintdef(0);
+ pg_get_constraintdef 
+----------------------
+ 
+(1 row)
+
+SELECT pg_get_functiondef(0);
+ pg_get_functiondef 
+--------------------
+ 
+(1 row)
+
+SELECT pg_get_indexdef(0);
+ pg_get_indexdef 
+-----------------
+ 
+(1 row)
+
+SELECT pg_get_ruledef(0);
+ pg_get_ruledef 
+----------------
+ 
+(1 row)
+
+SELECT pg_get_statisticsobjdef(0);
+ pg_get_statisticsobjdef 
+-------------------------
+ 
+(1 row)
+
+SELECT pg_get_triggerdef(0);
+ pg_get_triggerdef 
+-------------------
+ 
+(1 row)
+
+SELECT pg_get_viewdef(0);
+ pg_get_viewdef 
+----------------
+ 
+(1 row)
+
+SELECT pg_get_function_arguments(0);
+ pg_get_function_arguments 
+---------------------------
+ 
+(1 row)
+
+SELECT pg_get_function_identity_arguments(0);
+ pg_get_function_identity_arguments 
+------------------------------------
+ 
+(1 row)
+
+SELECT pg_get_function_result(0);
+ pg_get_function_result 
+------------------------
+ 
+(1 row)
+
+SELECT pg_get_function_arg_default(0, 0);
+ pg_get_function_arg_default 
+-----------------------------
+ 
+(1 row)
+
+SELECT pg_get_function_arg_default('pg_class'::regclass, 0);
+ pg_get_function_arg_default 
+-----------------------------
+ 
+(1 row)
+
+SELECT pg_get_partkeydef(0);
+ pg_get_partkeydef 
+-------------------
+ 
+(1 row)
+
+-- test rename for a rule defined on a partitioned table
+CREATE TABLE rules_parted_table (a int) PARTITION BY LIST (a);
+CREATE TABLE rules_parted_table_1 PARTITION OF rules_parted_table FOR VALUES IN (1);
+CREATE RULE rules_parted_table_insert AS ON INSERT to rules_parted_table
+    DO INSTEAD INSERT INTO rules_parted_table_1 VALUES (NEW.*);
+ALTER RULE rules_parted_table_insert ON rules_parted_table RENAME TO rules_parted_table_insert_redirect;
+DROP TABLE rules_parted_table;
+--
+-- Test enabling/disabling
+--
+CREATE TABLE ruletest1 (a int);
+CREATE TABLE ruletest2 (b int);
+CREATE RULE rule1 AS ON INSERT TO ruletest1
+    DO INSTEAD INSERT INTO ruletest2 VALUES (NEW.*);
+INSERT INTO ruletest1 VALUES (1);
+ALTER TABLE ruletest1 DISABLE RULE rule1;
+INSERT INTO ruletest1 VALUES (2);
+ALTER TABLE ruletest1 ENABLE RULE rule1;
+SET session_replication_role = replica;
+INSERT INTO ruletest1 VALUES (3);
+ALTER TABLE ruletest1 ENABLE REPLICA RULE rule1;
+INSERT INTO ruletest1 VALUES (4);
+RESET session_replication_role;
+INSERT INTO ruletest1 VALUES (5);
+SELECT * FROM ruletest1;
+ a 
+---
+ 2
+ 3
+ 5
+(3 rows)
+
+SELECT * FROM ruletest2;
+ b 
+---
+ 1
+ 4
+(2 rows)
+
+DROP TABLE ruletest1;
+DROP TABLE ruletest2;
diff --git a/src/test/regress/expected/select_parallel_1.out b/src/test/regress/expected/select_parallel_1.out
new file mode 100644
index 0000000..de41ad0
--- /dev/null
+++ b/src/test/regress/expected/select_parallel_1.out
@@ -0,0 +1,1163 @@
+--
+-- PARALLEL
+--
+create function sp_parallel_restricted(int) returns int as
+  $$begin return $1; end$$ language plpgsql parallel restricted;
+-- Serializable isolation would disable parallel query, so explicitly use an
+-- arbitrary other level.
+begin isolation level repeatable read;
+-- encourage use of parallel plans
+set parallel_setup_cost=0;
+set parallel_tuple_cost=0;
+set min_parallel_table_scan_size=0;
+set max_parallel_workers_per_gather=4;
+-- Parallel Append with partial-subplans
+explain (costs off)
+  select round(avg(aa)), sum(aa) from a_star;
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Finalize Aggregate
+   ->  Gather
+         Workers Planned: 3
+         ->  Partial Aggregate
+               ->  Parallel Append
+                     ->  Parallel Seq Scan on d_star
+                     ->  Parallel Seq Scan on f_star
+                     ->  Parallel Seq Scan on e_star
+                     ->  Parallel Seq Scan on b_star
+                     ->  Parallel Seq Scan on c_star
+                     ->  Parallel Seq Scan on a_star
+(11 rows)
+
+select round(avg(aa)), sum(aa) from a_star a1;
+ round | sum 
+-------+-----
+    14 | 355
+(1 row)
+
+-- Parallel Append with both partial and non-partial subplans
+alter table c_star set (parallel_workers = 0);
+alter table d_star set (parallel_workers = 0);
+explain (costs off)
+  select round(avg(aa)), sum(aa) from a_star;
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Finalize Aggregate
+   ->  Gather
+         Workers Planned: 3
+         ->  Partial Aggregate
+               ->  Parallel Append
+                     ->  Seq Scan on d_star
+                     ->  Seq Scan on c_star
+                     ->  Parallel Seq Scan on f_star
+                     ->  Parallel Seq Scan on e_star
+                     ->  Parallel Seq Scan on b_star
+                     ->  Parallel Seq Scan on a_star
+(11 rows)
+
+select round(avg(aa)), sum(aa) from a_star a2;
+ round | sum 
+-------+-----
+    14 | 355
+(1 row)
+
+-- Parallel Append with only non-partial subplans
+alter table a_star set (parallel_workers = 0);
+alter table b_star set (parallel_workers = 0);
+alter table e_star set (parallel_workers = 0);
+alter table f_star set (parallel_workers = 0);
+explain (costs off)
+  select round(avg(aa)), sum(aa) from a_star;
+                 QUERY PLAN                 
+--------------------------------------------
+ Finalize Aggregate
+   ->  Gather
+         Workers Planned: 3
+         ->  Partial Aggregate
+               ->  Parallel Append
+                     ->  Seq Scan on d_star
+                     ->  Seq Scan on f_star
+                     ->  Seq Scan on e_star
+                     ->  Seq Scan on b_star
+                     ->  Seq Scan on c_star
+                     ->  Seq Scan on a_star
+(11 rows)
+
+select round(avg(aa)), sum(aa) from a_star a3;
+ round | sum 
+-------+-----
+    14 | 355
+(1 row)
+
+-- Temporary hack to investigate whether extra vacuum/analyze is happening
+select relname, relpages, reltuples
+from pg_class
+where relname like '__star' order by relname;
+ relname | relpages | reltuples 
+---------+----------+-----------
+ a_star  |        2 |         3
+ b_star  |        2 |         4
+ c_star  |        2 |         4
+ d_star  |        2 |        16
+ e_star  |        2 |         7
+ f_star  |        2 |        16
+(6 rows)
+
+select relname, vacuum_count, analyze_count, autovacuum_count, autoanalyze_count
+from pg_stat_all_tables
+where relname like '__star' order by relname;
+ relname | vacuum_count | analyze_count | autovacuum_count | autoanalyze_count 
+---------+--------------+---------------+------------------+-------------------
+ a_star  |            1 |             0 |                0 |                 0
+ b_star  |            1 |             0 |                0 |                 0
+ c_star  |            1 |             0 |                0 |                 0
+ d_star  |            1 |             0 |                0 |                 0
+ e_star  |            1 |             0 |                0 |                 0
+ f_star  |            1 |             0 |                0 |                 0
+(6 rows)
+
+-- Disable Parallel Append
+alter table a_star reset (parallel_workers);
+alter table b_star reset (parallel_workers);
+alter table c_star reset (parallel_workers);
+alter table d_star reset (parallel_workers);
+alter table e_star reset (parallel_workers);
+alter table f_star reset (parallel_workers);
+set enable_parallel_append to off;
+explain (costs off)
+  select round(avg(aa)), sum(aa) from a_star;
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Finalize Aggregate
+   ->  Gather
+         Workers Planned: 1
+         ->  Partial Aggregate
+               ->  Append
+                     ->  Parallel Seq Scan on a_star
+                     ->  Parallel Seq Scan on b_star
+                     ->  Parallel Seq Scan on c_star
+                     ->  Parallel Seq Scan on d_star
+                     ->  Parallel Seq Scan on e_star
+                     ->  Parallel Seq Scan on f_star
+(11 rows)
+
+select round(avg(aa)), sum(aa) from a_star a4;
+ round | sum 
+-------+-----
+    14 | 355
+(1 row)
+
+reset enable_parallel_append;
+-- Parallel Append that runs serially
+create function sp_test_func() returns setof text as
+$$ select 'foo'::varchar union all select 'bar'::varchar $$
+language sql stable;
+select sp_test_func() order by 1;
+ sp_test_func 
+--------------
+ bar
+ foo
+(2 rows)
+
+-- Parallel Append is not to be used when the subpath depends on the outer param
+create table part_pa_test(a int, b int) partition by range(a);
+create table part_pa_test_p1 partition of part_pa_test for values from (minvalue) to (0);
+create table part_pa_test_p2 partition of part_pa_test for values from (0) to (maxvalue);
+explain (costs off)
+	select (select max((select pa1.b from part_pa_test pa1 where pa1.a = pa2.a)))
+	from part_pa_test pa2;
+                          QUERY PLAN                          
+--------------------------------------------------------------
+ Aggregate
+   ->  Gather
+         Workers Planned: 3
+         ->  Parallel Append
+               ->  Parallel Seq Scan on part_pa_test_p1 pa2
+               ->  Parallel Seq Scan on part_pa_test_p2 pa2_1
+   SubPlan 2
+     ->  Result
+   SubPlan 1
+     ->  Append
+           ->  Seq Scan on part_pa_test_p1 pa1
+                 Filter: (a = pa2.a)
+           ->  Seq Scan on part_pa_test_p2 pa1_1
+                 Filter: (a = pa2.a)
+(14 rows)
+
+drop table part_pa_test;
+-- test with leader participation disabled
+set parallel_leader_participation = off;
+explain (costs off)
+  select count(*) from tenk1 where stringu1 = 'GRAAAA';
+                       QUERY PLAN                        
+---------------------------------------------------------
+ Finalize Aggregate
+   ->  Gather
+         Workers Planned: 4
+         ->  Partial Aggregate
+               ->  Parallel Seq Scan on tenk1
+                     Filter: (stringu1 = 'GRAAAA'::name)
+(6 rows)
+
+select count(*) from tenk1 where stringu1 = 'GRAAAA';
+ count 
+-------
+    15
+(1 row)
+
+-- test with leader participation disabled, but no workers available (so
+-- the leader will have to run the plan despite the setting)
+set max_parallel_workers = 0;
+explain (costs off)
+  select count(*) from tenk1 where stringu1 = 'GRAAAA';
+                       QUERY PLAN                        
+---------------------------------------------------------
+ Finalize Aggregate
+   ->  Gather
+         Workers Planned: 4
+         ->  Partial Aggregate
+               ->  Parallel Seq Scan on tenk1
+                     Filter: (stringu1 = 'GRAAAA'::name)
+(6 rows)
+
+select count(*) from tenk1 where stringu1 = 'GRAAAA';
+ count 
+-------
+    15
+(1 row)
+
+reset max_parallel_workers;
+reset parallel_leader_participation;
+-- test that parallel_restricted function doesn't run in worker
+alter table tenk1 set (parallel_workers = 4);
+explain (verbose, costs off)
+select sp_parallel_restricted(unique1) from tenk1
+  where stringu1 = 'GRAAAA' order by 1;
+                       QUERY PLAN                        
+---------------------------------------------------------
+ Sort
+   Output: (sp_parallel_restricted(unique1))
+   Sort Key: (sp_parallel_restricted(tenk1.unique1))
+   ->  Gather
+         Output: sp_parallel_restricted(unique1)
+         Workers Planned: 4
+         ->  Parallel Seq Scan on public.tenk1
+               Output: unique1
+               Filter: (tenk1.stringu1 = 'GRAAAA'::name)
+(9 rows)
+
+-- test parallel plan when group by expression is in target list.
+explain (costs off)
+	select length(stringu1) from tenk1 group by length(stringu1);
+                    QUERY PLAN                     
+---------------------------------------------------
+ Finalize HashAggregate
+   Group Key: (length((stringu1)::text))
+   ->  Gather
+         Workers Planned: 4
+         ->  Partial HashAggregate
+               Group Key: length((stringu1)::text)
+               ->  Parallel Seq Scan on tenk1
+(7 rows)
+
+select length(stringu1) from tenk1 group by length(stringu1);
+ length 
+--------
+      6
+(1 row)
+
+explain (costs off)
+	select stringu1, count(*) from tenk1 group by stringu1 order by stringu1;
+                     QUERY PLAN                     
+----------------------------------------------------
+ Sort
+   Sort Key: stringu1
+   ->  Finalize HashAggregate
+         Group Key: stringu1
+         ->  Gather
+               Workers Planned: 4
+               ->  Partial HashAggregate
+                     Group Key: stringu1
+                     ->  Parallel Seq Scan on tenk1
+(9 rows)
+
+-- test that parallel plan for aggregates is not selected when
+-- target list contains parallel restricted clause.
+explain (costs off)
+	select  sum(sp_parallel_restricted(unique1)) from tenk1
+	group by(sp_parallel_restricted(unique1));
+                            QUERY PLAN                             
+-------------------------------------------------------------------
+ HashAggregate
+   Group Key: sp_parallel_restricted(unique1)
+   ->  Gather
+         Workers Planned: 4
+         ->  Parallel Index Only Scan using tenk1_unique1 on tenk1
+(5 rows)
+
+-- test prepared statement
+prepare tenk1_count(integer) As select  count((unique1)) from tenk1 where hundred > $1;
+explain (costs off) execute tenk1_count(1);
+                  QUERY PLAN                  
+----------------------------------------------
+ Finalize Aggregate
+   ->  Gather
+         Workers Planned: 4
+         ->  Partial Aggregate
+               ->  Parallel Seq Scan on tenk1
+                     Filter: (hundred > 1)
+(6 rows)
+
+execute tenk1_count(1);
+ count 
+-------
+  9800
+(1 row)
+
+deallocate tenk1_count;
+-- test parallel plans for queries containing un-correlated subplans.
+alter table tenk2 set (parallel_workers = 0);
+explain (costs off)
+	select count(*) from tenk1 where (two, four) not in
+	(select hundred, thousand from tenk2 where thousand > 100);
+                      QUERY PLAN                      
+------------------------------------------------------
+ Finalize Aggregate
+   ->  Gather
+         Workers Planned: 4
+         ->  Partial Aggregate
+               ->  Parallel Seq Scan on tenk1
+                     Filter: (NOT (hashed SubPlan 1))
+                     SubPlan 1
+                       ->  Seq Scan on tenk2
+                             Filter: (thousand > 100)
+(9 rows)
+
+select count(*) from tenk1 where (two, four) not in
+	(select hundred, thousand from tenk2 where thousand > 100);
+ count 
+-------
+ 10000
+(1 row)
+
+-- this is not parallel-safe due to use of random() within SubLink's testexpr:
+explain (costs off)
+	select * from tenk1 where (unique1 + random())::integer not in
+	(select ten from tenk2);
+             QUERY PLAN             
+------------------------------------
+ Seq Scan on tenk1
+   Filter: (NOT (hashed SubPlan 1))
+   SubPlan 1
+     ->  Seq Scan on tenk2
+(4 rows)
+
+alter table tenk2 reset (parallel_workers);
+-- test parallel plan for a query containing initplan.
+set enable_indexscan = off;
+set enable_indexonlyscan = off;
+set enable_bitmapscan = off;
+alter table tenk2 set (parallel_workers = 2);
+explain (costs off)
+	select count(*) from tenk1
+        where tenk1.unique1 = (Select max(tenk2.unique1) from tenk2);
+                      QUERY PLAN                      
+------------------------------------------------------
+ Aggregate
+   InitPlan 1 (returns $2)
+     ->  Finalize Aggregate
+           ->  Gather
+                 Workers Planned: 2
+                 ->  Partial Aggregate
+                       ->  Parallel Seq Scan on tenk2
+   ->  Gather
+         Workers Planned: 4
+         Params Evaluated: $2
+         ->  Parallel Seq Scan on tenk1
+               Filter: (unique1 = $2)
+(12 rows)
+
+select count(*) from tenk1
+    where tenk1.unique1 = (Select max(tenk2.unique1) from tenk2);
+ count 
+-------
+     1
+(1 row)
+
+reset enable_indexscan;
+reset enable_indexonlyscan;
+reset enable_bitmapscan;
+alter table tenk2 reset (parallel_workers);
+-- test parallel index scans.
+set enable_seqscan to off;
+set enable_bitmapscan to off;
+explain (costs off)
+	select  count((unique1)) from tenk1 where hundred > 1;
+                             QUERY PLAN                             
+--------------------------------------------------------------------
+ Finalize Aggregate
+   ->  Gather
+         Workers Planned: 4
+         ->  Partial Aggregate
+               ->  Parallel Index Scan using tenk1_hundred on tenk1
+                     Index Cond: (hundred > 1)
+(6 rows)
+
+select  count((unique1)) from tenk1 where hundred > 1;
+ count 
+-------
+  9800
+(1 row)
+
+-- test parallel index-only scans.
+explain (costs off)
+	select  count(*) from tenk1 where thousand > 95;
+                                   QUERY PLAN                                   
+--------------------------------------------------------------------------------
+ Finalize Aggregate
+   ->  Gather
+         Workers Planned: 4
+         ->  Partial Aggregate
+               ->  Parallel Index Only Scan using tenk1_thous_tenthous on tenk1
+                     Index Cond: (thousand > 95)
+(6 rows)
+
+select  count(*) from tenk1 where thousand > 95;
+ count 
+-------
+  9040
+(1 row)
+
+-- test rescan cases too
+set enable_material = false;
+explain (costs off)
+select * from
+  (select count(unique1) from tenk1 where hundred > 10) ss
+  right join (values (1),(2),(3)) v(x) on true;
+                                QUERY PLAN                                
+--------------------------------------------------------------------------
+ Nested Loop Left Join
+   ->  Values Scan on "*VALUES*"
+   ->  Finalize Aggregate
+         ->  Gather
+               Workers Planned: 4
+               ->  Partial Aggregate
+                     ->  Parallel Index Scan using tenk1_hundred on tenk1
+                           Index Cond: (hundred > 10)
+(8 rows)
+
+select * from
+  (select count(unique1) from tenk1 where hundred > 10) ss
+  right join (values (1),(2),(3)) v(x) on true;
+ count | x 
+-------+---
+  8900 | 1
+  8900 | 2
+  8900 | 3
+(3 rows)
+
+explain (costs off)
+select * from
+  (select count(*) from tenk1 where thousand > 99) ss
+  right join (values (1),(2),(3)) v(x) on true;
+                                      QUERY PLAN                                      
+--------------------------------------------------------------------------------------
+ Nested Loop Left Join
+   ->  Values Scan on "*VALUES*"
+   ->  Finalize Aggregate
+         ->  Gather
+               Workers Planned: 4
+               ->  Partial Aggregate
+                     ->  Parallel Index Only Scan using tenk1_thous_tenthous on tenk1
+                           Index Cond: (thousand > 99)
+(8 rows)
+
+select * from
+  (select count(*) from tenk1 where thousand > 99) ss
+  right join (values (1),(2),(3)) v(x) on true;
+ count | x 
+-------+---
+  9000 | 1
+  9000 | 2
+  9000 | 3
+(3 rows)
+
+reset enable_material;
+reset enable_seqscan;
+reset enable_bitmapscan;
+-- test parallel bitmap heap scan.
+set enable_seqscan to off;
+set enable_indexscan to off;
+set enable_hashjoin to off;
+set enable_mergejoin to off;
+set enable_material to off;
+-- test prefetching, if the platform allows it
+DO $$
+BEGIN
+ SET effective_io_concurrency = 50;
+EXCEPTION WHEN invalid_parameter_value THEN
+END $$;
+set work_mem='64kB';  --set small work mem to force lossy pages
+explain (costs off)
+	select count(*) from tenk1, tenk2 where tenk1.hundred > 1 and tenk2.thousand=0;
+                         QUERY PLAN                         
+------------------------------------------------------------
+ Aggregate
+   ->  Nested Loop
+         ->  Seq Scan on tenk2
+               Filter: (thousand = 0)
+         ->  Gather
+               Workers Planned: 4
+               ->  Parallel Bitmap Heap Scan on tenk1
+                     Recheck Cond: (hundred > 1)
+                     ->  Bitmap Index Scan on tenk1_hundred
+                           Index Cond: (hundred > 1)
+(10 rows)
+
+select count(*) from tenk1, tenk2 where tenk1.hundred > 1 and tenk2.thousand=0;
+ count 
+-------
+ 98000
+(1 row)
+
+create table bmscantest (a int, t text);
+insert into bmscantest select r, 'fooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo' FROM generate_series(1,100000) r;
+create index i_bmtest ON bmscantest(a);
+select count(*) from bmscantest where a>1;
+ count 
+-------
+ 99999
+(1 row)
+
+-- test accumulation of stats for parallel nodes
+reset enable_seqscan;
+alter table tenk2 set (parallel_workers = 0);
+explain (analyze, timing off, summary off, costs off)
+   select count(*) from tenk1, tenk2 where tenk1.hundred > 1
+        and tenk2.thousand=0;
+                                QUERY PLAN                                
+--------------------------------------------------------------------------
+ Aggregate (actual rows=1 loops=1)
+   ->  Nested Loop (actual rows=98000 loops=1)
+         ->  Seq Scan on tenk2 (actual rows=10 loops=1)
+               Filter: (thousand = 0)
+               Rows Removed by Filter: 9990
+         ->  Gather (actual rows=9800 loops=10)
+               Workers Planned: 4
+               Workers Launched: 4
+               ->  Parallel Seq Scan on tenk1 (actual rows=1960 loops=50)
+                     Filter: (hundred > 1)
+                     Rows Removed by Filter: 40
+(11 rows)
+
+alter table tenk2 reset (parallel_workers);
+reset work_mem;
+create function explain_parallel_sort_stats() returns setof text
+language plpgsql as
+$$
+declare ln text;
+begin
+    for ln in
+        explain (analyze, timing off, summary off, costs off)
+          select * from
+          (select ten from tenk1 where ten < 100 order by ten) ss
+          right join (values (1),(2),(3)) v(x) on true
+    loop
+        ln := regexp_replace(ln, 'Memory: \S*',  'Memory: xxx');
+        return next ln;
+    end loop;
+end;
+$$;
+select * from explain_parallel_sort_stats();
+                       explain_parallel_sort_stats                        
+--------------------------------------------------------------------------
+ Nested Loop Left Join (actual rows=30000 loops=1)
+   ->  Values Scan on "*VALUES*" (actual rows=3 loops=1)
+   ->  Gather Merge (actual rows=10000 loops=3)
+         Workers Planned: 4
+         Workers Launched: 4
+         ->  Sort (actual rows=2000 loops=15)
+               Sort Key: tenk1.ten
+               Sort Method: quicksort  Memory: xxx
+               Worker 0:  Sort Method: quicksort  Memory: xxx
+               Worker 1:  Sort Method: quicksort  Memory: xxx
+               Worker 2:  Sort Method: quicksort  Memory: xxx
+               Worker 3:  Sort Method: quicksort  Memory: xxx
+               ->  Parallel Seq Scan on tenk1 (actual rows=2000 loops=15)
+                     Filter: (ten < 100)
+(14 rows)
+
+reset enable_indexscan;
+reset enable_hashjoin;
+reset enable_mergejoin;
+reset enable_material;
+reset effective_io_concurrency;
+drop table bmscantest;
+drop function explain_parallel_sort_stats();
+-- test parallel merge join path.
+set enable_hashjoin to off;
+set enable_nestloop to off;
+explain (costs off)
+	select  count(*) from tenk1, tenk2 where tenk1.unique1 = tenk2.unique1;
+                                  QUERY PLAN                                   
+-------------------------------------------------------------------------------
+ Finalize Aggregate
+   ->  Gather
+         Workers Planned: 4
+         ->  Partial Aggregate
+               ->  Merge Join
+                     Merge Cond: (tenk1.unique1 = tenk2.unique1)
+                     ->  Parallel Index Only Scan using tenk1_unique1 on tenk1
+                     ->  Index Only Scan using tenk2_unique1 on tenk2
+(8 rows)
+
+select  count(*) from tenk1, tenk2 where tenk1.unique1 = tenk2.unique1;
+ count 
+-------
+ 10000
+(1 row)
+
+reset enable_hashjoin;
+reset enable_nestloop;
+-- test gather merge
+set enable_hashagg = false;
+explain (costs off)
+   select count(*) from tenk1 group by twenty;
+                     QUERY PLAN                     
+----------------------------------------------------
+ Finalize GroupAggregate
+   Group Key: twenty
+   ->  Gather Merge
+         Workers Planned: 4
+         ->  Partial GroupAggregate
+               Group Key: twenty
+               ->  Sort
+                     Sort Key: twenty
+                     ->  Parallel Seq Scan on tenk1
+(9 rows)
+
+select count(*) from tenk1 group by twenty;
+ count 
+-------
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+(20 rows)
+
+--test expressions in targetlist are pushed down for gather merge
+create function sp_simple_func(var1 integer) returns integer
+as $$
+begin
+        return var1 + 10;
+end;
+$$ language plpgsql PARALLEL SAFE;
+explain (costs off, verbose)
+    select ten, sp_simple_func(ten) from tenk1 where ten < 100 order by ten;
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Gather Merge
+   Output: ten, (sp_simple_func(ten))
+   Workers Planned: 4
+   ->  Result
+         Output: ten, sp_simple_func(ten)
+         ->  Sort
+               Output: ten
+               Sort Key: tenk1.ten
+               ->  Parallel Seq Scan on public.tenk1
+                     Output: ten
+                     Filter: (tenk1.ten < 100)
+(11 rows)
+
+drop function sp_simple_func(integer);
+-- test handling of SRFs in targetlist (bug in 10.0)
+explain (costs off)
+   select count(*), generate_series(1,2) from tenk1 group by twenty;
+                        QUERY PLAN                        
+----------------------------------------------------------
+ ProjectSet
+   ->  Finalize GroupAggregate
+         Group Key: twenty
+         ->  Gather Merge
+               Workers Planned: 4
+               ->  Partial GroupAggregate
+                     Group Key: twenty
+                     ->  Sort
+                           Sort Key: twenty
+                           ->  Parallel Seq Scan on tenk1
+(10 rows)
+
+select count(*), generate_series(1,2) from tenk1 group by twenty;
+ count | generate_series 
+-------+-----------------
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+   500 |               1
+   500 |               2
+(40 rows)
+
+-- test gather merge with parallel leader participation disabled
+set parallel_leader_participation = off;
+explain (costs off)
+   select count(*) from tenk1 group by twenty;
+                     QUERY PLAN                     
+----------------------------------------------------
+ Finalize GroupAggregate
+   Group Key: twenty
+   ->  Gather Merge
+         Workers Planned: 4
+         ->  Partial GroupAggregate
+               Group Key: twenty
+               ->  Sort
+                     Sort Key: twenty
+                     ->  Parallel Seq Scan on tenk1
+(9 rows)
+
+select count(*) from tenk1 group by twenty;
+ count 
+-------
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+   500
+(20 rows)
+
+reset parallel_leader_participation;
+--test rescan behavior of gather merge
+set enable_material = false;
+explain (costs off)
+select * from
+  (select string4, count(unique2)
+   from tenk1 group by string4 order by string4) ss
+  right join (values (1),(2),(3)) v(x) on true;
+                        QUERY PLAN                        
+----------------------------------------------------------
+ Nested Loop Left Join
+   ->  Values Scan on "*VALUES*"
+   ->  Finalize GroupAggregate
+         Group Key: tenk1.string4
+         ->  Gather Merge
+               Workers Planned: 4
+               ->  Partial GroupAggregate
+                     Group Key: tenk1.string4
+                     ->  Sort
+                           Sort Key: tenk1.string4
+                           ->  Parallel Seq Scan on tenk1
+(11 rows)
+
+select * from
+  (select string4, count(unique2)
+   from tenk1 group by string4 order by string4) ss
+  right join (values (1),(2),(3)) v(x) on true;
+ string4 | count | x 
+---------+-------+---
+ AAAAxx  |  2500 | 1
+ HHHHxx  |  2500 | 1
+ OOOOxx  |  2500 | 1
+ VVVVxx  |  2500 | 1
+ AAAAxx  |  2500 | 2
+ HHHHxx  |  2500 | 2
+ OOOOxx  |  2500 | 2
+ VVVVxx  |  2500 | 2
+ AAAAxx  |  2500 | 3
+ HHHHxx  |  2500 | 3
+ OOOOxx  |  2500 | 3
+ VVVVxx  |  2500 | 3
+(12 rows)
+
+reset enable_material;
+reset enable_hashagg;
+-- check parallelized int8 aggregate (bug #14897)
+explain (costs off)
+select avg(unique1::int8) from tenk1;
+                               QUERY PLAN                                
+-------------------------------------------------------------------------
+ Finalize Aggregate
+   ->  Gather
+         Workers Planned: 4
+         ->  Partial Aggregate
+               ->  Parallel Index Only Scan using tenk1_unique1 on tenk1
+(5 rows)
+
+select avg(unique1::int8) from tenk1;
+          avg          
+-----------------------
+ 4999.5000000000000000
+(1 row)
+
+-- gather merge test with a LIMIT
+explain (costs off)
+  select fivethous from tenk1 order by fivethous limit 4;
+                  QUERY PLAN                  
+----------------------------------------------
+ Limit
+   ->  Gather Merge
+         Workers Planned: 4
+         ->  Sort
+               Sort Key: fivethous
+               ->  Parallel Seq Scan on tenk1
+(6 rows)
+
+select fivethous from tenk1 order by fivethous limit 4;
+ fivethous 
+-----------
+         0
+         0
+         1
+         1
+(4 rows)
+
+-- gather merge test with 0 worker
+set max_parallel_workers = 0;
+explain (costs off)
+   select string4 from tenk1 order by string4 limit 5;
+                  QUERY PLAN                  
+----------------------------------------------
+ Limit
+   ->  Gather Merge
+         Workers Planned: 4
+         ->  Sort
+               Sort Key: string4
+               ->  Parallel Seq Scan on tenk1
+(6 rows)
+
+select string4 from tenk1 order by string4 limit 5;
+ string4 
+---------
+ AAAAxx
+ AAAAxx
+ AAAAxx
+ AAAAxx
+ AAAAxx
+(5 rows)
+
+-- gather merge test with 0 workers, with parallel leader
+-- participation disabled (the leader will have to run the plan
+-- despite the setting)
+set parallel_leader_participation = off;
+explain (costs off)
+   select string4 from tenk1 order by string4 limit 5;
+                  QUERY PLAN                  
+----------------------------------------------
+ Limit
+   ->  Gather Merge
+         Workers Planned: 4
+         ->  Sort
+               Sort Key: string4
+               ->  Parallel Seq Scan on tenk1
+(6 rows)
+
+select string4 from tenk1 order by string4 limit 5;
+ string4 
+---------
+ AAAAxx
+ AAAAxx
+ AAAAxx
+ AAAAxx
+ AAAAxx
+(5 rows)
+
+reset parallel_leader_participation;
+reset max_parallel_workers;
+SAVEPOINT settings;
+SET LOCAL force_parallel_mode = 1;
+explain (costs off)
+  select stringu1::int2 from tenk1 where unique1 = 1;
+                  QUERY PLAN                   
+-----------------------------------------------
+ Gather
+   Workers Planned: 1
+   Single Copy: true
+   ->  Index Scan using tenk1_unique1 on tenk1
+         Index Cond: (unique1 = 1)
+(5 rows)
+
+ROLLBACK TO SAVEPOINT settings;
+-- exercise record typmod remapping between backends
+CREATE FUNCTION make_record(n int)
+  RETURNS RECORD LANGUAGE plpgsql PARALLEL SAFE AS
+$$
+BEGIN
+  RETURN CASE n
+           WHEN 1 THEN ROW(1)
+           WHEN 2 THEN ROW(1, 2)
+           WHEN 3 THEN ROW(1, 2, 3)
+           WHEN 4 THEN ROW(1, 2, 3, 4)
+           ELSE ROW(1, 2, 3, 4, 5)
+         END;
+END;
+$$;
+SAVEPOINT settings;
+SET LOCAL force_parallel_mode = 1;
+SELECT make_record(x) FROM (SELECT generate_series(1, 5) x) ss ORDER BY x;
+ make_record 
+-------------
+ (1)
+ (1,2)
+ (1,2,3)
+ (1,2,3,4)
+ (1,2,3,4,5)
+(5 rows)
+
+ROLLBACK TO SAVEPOINT settings;
+DROP function make_record(n int);
+-- test the sanity of parallel query after the active role is dropped.
+drop role if exists regress_parallel_worker;
+NOTICE:  role "regress_parallel_worker" does not exist, skipping
+create role regress_parallel_worker;
+set role regress_parallel_worker;
+reset session authorization;
+drop role regress_parallel_worker;
+set force_parallel_mode = 1;
+select count(*) from tenk1;
+ count 
+-------
+ 10000
+(1 row)
+
+reset force_parallel_mode;
+reset role;
+-- Window function calculation can't be pushed to workers.
+explain (costs off, verbose)
+  select count(*) from tenk1 a where (unique1, two) in
+    (select unique1, row_number() over() from tenk1 b);
+                                          QUERY PLAN                                          
+----------------------------------------------------------------------------------------------
+ Aggregate
+   Output: count(*)
+   ->  Hash Semi Join
+         Hash Cond: ((a.unique1 = b.unique1) AND (a.two = (row_number() OVER (?))))
+         ->  Gather
+               Output: a.unique1, a.two
+               Workers Planned: 4
+               ->  Parallel Seq Scan on public.tenk1 a
+                     Output: a.unique1, a.two
+         ->  Hash
+               Output: b.unique1, (row_number() OVER (?))
+               ->  WindowAgg
+                     Output: b.unique1, row_number() OVER (?)
+                     ->  Gather
+                           Output: b.unique1
+                           Workers Planned: 4
+                           ->  Parallel Index Only Scan using tenk1_unique1 on public.tenk1 b
+                                 Output: b.unique1
+(18 rows)
+
+-- LIMIT/OFFSET within sub-selects can't be pushed to workers.
+explain (costs off)
+  select * from tenk1 a where two in
+    (select two from tenk1 b where stringu1 like '%AAAA' limit 3);
+                          QUERY PLAN                           
+---------------------------------------------------------------
+ Hash Semi Join
+   Hash Cond: (a.two = b.two)
+   ->  Gather
+         Workers Planned: 4
+         ->  Parallel Seq Scan on tenk1 a
+   ->  Hash
+         ->  Limit
+               ->  Gather
+                     Workers Planned: 4
+                     ->  Parallel Seq Scan on tenk1 b
+                           Filter: (stringu1 ~~ '%AAAA'::text)
+(11 rows)
+
+-- to increase the parallel query test coverage
+SAVEPOINT settings;
+SET LOCAL force_parallel_mode = 1;
+EXPLAIN (analyze, timing off, summary off, costs off) SELECT * FROM tenk1;
+                         QUERY PLAN                          
+-------------------------------------------------------------
+ Gather (actual rows=10000 loops=1)
+   Workers Planned: 4
+   Workers Launched: 4
+   ->  Parallel Seq Scan on tenk1 (actual rows=2000 loops=5)
+(4 rows)
+
+ROLLBACK TO SAVEPOINT settings;
+-- provoke error in worker
+SAVEPOINT settings;
+SET LOCAL force_parallel_mode = 1;
+select stringu1::int2 from tenk1 where unique1 = 1;
+ERROR:  invalid input syntax for type smallint: "BAAAAA"
+CONTEXT:  parallel worker
+ROLLBACK TO SAVEPOINT settings;
+-- test interaction with set-returning functions
+SAVEPOINT settings;
+-- multiple subqueries under a single Gather node
+-- must set parallel_setup_cost > 0 to discourage multiple Gather nodes
+SET LOCAL parallel_setup_cost = 10;
+EXPLAIN (COSTS OFF)
+SELECT unique1 FROM tenk1 WHERE fivethous = tenthous + 1
+UNION ALL
+SELECT unique1 FROM tenk1 WHERE fivethous = tenthous + 1;
+                     QUERY PLAN                     
+----------------------------------------------------
+ Gather
+   Workers Planned: 4
+   ->  Parallel Append
+         ->  Parallel Seq Scan on tenk1
+               Filter: (fivethous = (tenthous + 1))
+         ->  Parallel Seq Scan on tenk1 tenk1_1
+               Filter: (fivethous = (tenthous + 1))
+(7 rows)
+
+ROLLBACK TO SAVEPOINT settings;
+-- can't use multiple subqueries under a single Gather node due to initPlans
+EXPLAIN (COSTS OFF)
+SELECT unique1 FROM tenk1 WHERE fivethous =
+	(SELECT unique1 FROM tenk1 WHERE fivethous = 1 LIMIT 1)
+UNION ALL
+SELECT unique1 FROM tenk1 WHERE fivethous =
+	(SELECT unique2 FROM tenk1 WHERE fivethous = 1 LIMIT 1)
+ORDER BY 1;
+                             QUERY PLAN                             
+--------------------------------------------------------------------
+ Sort
+   Sort Key: tenk1.unique1
+   ->  Append
+         ->  Gather
+               Workers Planned: 4
+               Params Evaluated: $1
+               InitPlan 1 (returns $1)
+                 ->  Limit
+                       ->  Gather
+                             Workers Planned: 4
+                             ->  Parallel Seq Scan on tenk1 tenk1_2
+                                   Filter: (fivethous = 1)
+               ->  Parallel Seq Scan on tenk1
+                     Filter: (fivethous = $1)
+         ->  Gather
+               Workers Planned: 4
+               Params Evaluated: $3
+               InitPlan 2 (returns $3)
+                 ->  Limit
+                       ->  Gather
+                             Workers Planned: 4
+                             ->  Parallel Seq Scan on tenk1 tenk1_3
+                                   Filter: (fivethous = 1)
+               ->  Parallel Seq Scan on tenk1 tenk1_1
+                     Filter: (fivethous = $3)
+(25 rows)
+
+-- test interaction with SRFs
+SELECT * FROM information_schema.foreign_data_wrapper_options
+ORDER BY 1, 2, 3;
+ foreign_data_wrapper_catalog | foreign_data_wrapper_name | option_name | option_value 
+------------------------------+---------------------------+-------------+--------------
+(0 rows)
+
+-- test passing expanded-value representations to workers
+CREATE FUNCTION make_some_array(int,int) returns int[] as
+$$declare x int[];
+  begin
+    x[1] := $1;
+    x[2] := $2;
+    return x;
+  end$$ language plpgsql parallel safe;
+CREATE TABLE fooarr(f1 text, f2 int[], f3 text);
+INSERT INTO fooarr VALUES('1', ARRAY[1,2], 'one');
+PREPARE pstmt(text, int[]) AS SELECT * FROM fooarr WHERE f1 = $1 AND f2 = $2;
+EXPLAIN (COSTS OFF) EXECUTE pstmt('1', make_some_array(1,2));
+                            QUERY PLAN                            
+------------------------------------------------------------------
+ Gather
+   Workers Planned: 3
+   ->  Parallel Seq Scan on fooarr
+         Filter: ((f1 = '1'::text) AND (f2 = '{1,2}'::integer[]))
+(4 rows)
+
+EXECUTE pstmt('1', make_some_array(1,2));
+ f1 |  f2   | f3  
+----+-------+-----
+ 1  | {1,2} | one
+(1 row)
+
+DEALLOCATE pstmt;
+-- test interaction between subquery and partial_paths
+CREATE VIEW tenk1_vw_sec WITH (security_barrier) AS SELECT * FROM tenk1;
+EXPLAIN (COSTS OFF)
+SELECT 1 FROM tenk1_vw_sec
+  WHERE (SELECT sum(f1) FROM int4_tbl WHERE f1 < unique1) < 100;
+                            QUERY PLAN                             
+-------------------------------------------------------------------
+ Subquery Scan on tenk1_vw_sec
+   Filter: ((SubPlan 1) < 100)
+   ->  Gather
+         Workers Planned: 4
+         ->  Parallel Index Only Scan using tenk1_unique1 on tenk1
+   SubPlan 1
+     ->  Aggregate
+           ->  Seq Scan on int4_tbl
+                 Filter: (f1 < tenk1_vw_sec.unique1)
+(9 rows)
+
+rollback;
diff --git a/src/test/regress/expected/select_views_1.out b/src/test/regress/expected/select_views_1.out
new file mode 100644
index 0000000..e7630e9
--- /dev/null
+++ b/src/test/regress/expected/select_views_1.out
@@ -0,0 +1,1552 @@
+--
+-- SELECT_VIEWS
+-- test the views defined in CREATE_VIEWS
+--
+SELECT * FROM street;
+                name                |                                                                                                                                                                                                                   thepath                                                                                                                                                                                                                    |   cname   
+------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------
+ Access Rd 25                       | [(-121.9283,37.894),(-121.9283,37.9)]                                                                                                                                                                                                                                                                                                                                                                                                        | Oakland
+ Ada                           St   | [(-122.2487,37.398),(-122.2496,37.401)]                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ Agua Fria Creek                    | [(-121.9254,37.922),(-121.9281,37.889)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Allen                         Ct   | [(-122.0131,37.602),(-122.0117,37.597)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Alvarado Niles                Road | [(-122.0325,37.903),(-122.0316,37.9)]                                                                                                                                                                                                                                                                                                                                                                                                        | Berkeley
+ Andrea                        Cir  | [(-121.733218,37.88641),(-121.733286,37.90617)]                                                                                                                                                                                                                                                                                                                                                                                              | Oakland
+ Apricot                       Lane | [(-121.9471,37.401),(-121.9456,37.392)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Apricot                       Lane | [(-121.9471,37.401),(-121.9456,37.392)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Arden                         Road | [(-122.0978,37.177),(-122.1,37.177)]                                                                                                                                                                                                                                                                                                                                                                                                         | Oakland
+ Arizona                       St   | [(-122.0381,37.901),(-122.0367,37.898)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Arlington                     Dr   | [(-121.8802,37.408),(-121.8807,37.394)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Arlington                     Dr   | [(-121.8802,37.408),(-121.8807,37.394)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Arlington                     Road | [(-121.7957,37.898),(-121.7956,37.906)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Arroyo Las Positas                 | [(-121.7973,37.997),(-121.7957,37.005)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Arroyo Las Positas                 | [(-121.7973,37.997),(-121.7957,37.005)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Arroyo Seco                        | [(-121.7073,37.766),(-121.6997,37.729)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Ash                           St   | [(-122.0408,37.31),(-122.04,37.292)]                                                                                                                                                                                                                                                                                                                                                                                                         | Oakland
+ Avenue 134th                       | [(-122.1823,37.002),(-122.1851,37.992)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Avenue 134th                       | [(-122.1823,37.002),(-122.1851,37.992)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Avenue 140th                       | [(-122.1656,37.003),(-122.1691,37.988)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Avenue 140th                       | [(-122.1656,37.003),(-122.1691,37.988)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Avenue D                           | [(-122.298,37.848),(-122.3024,37.849)]                                                                                                                                                                                                                                                                                                                                                                                                       | Berkeley
+ B                             St   | [(-122.1749,37.451),(-122.1743,37.443)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Bancroft                      Ave  | [(-122.15714,37.4242),(-122.156,37.409)]                                                                                                                                                                                                                                                                                                                                                                                                     | Oakland
+ Bancroft                      Ave  | [(-122.1643,37.523),(-122.1631,37.508),(-122.1621,37.493)]                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ Birch                         St   | [(-122.1617,37.425),(-122.1614,37.417)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Birch                         St   | [(-122.1673,37.509),(-122.1661,37.492)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Blacow                        Road | [(-122.0179,37.469),(-122.0167,37.465)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Bridgepointe                  Dr   | [(-122.0514,37.305),(-122.0509,37.299)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Broadmore                     Ave  | [(-122.095,37.522),(-122.0936,37.497)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Broadway                           | [(-122.2409,37.586),(-122.2395,37.601)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Buckingham                    Blvd | [(-122.2231,37.59),(-122.2214,37.606)]                                                                                                                                                                                                                                                                                                                                                                                                       | Berkeley
+ Butterfield                   Dr   | [(-122.0838,37.002),(-122.0834,37.987)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Butterfield                   Dr   | [(-122.0838,37.002),(-122.0834,37.987)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Butterfield                   Dr   | [(-122.0838,37.002),(-122.0834,37.987)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ C                             St   | [(-122.1768,37.46),(-122.1749,37.435)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Calaveras Creek                    | [(-121.8203,37.035),(-121.8207,37.931)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Calaveras Creek                    | [(-121.8203,37.035),(-121.8207,37.931)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ California                    St   | [(-122.2032,37.005),(-122.2016,37.996)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ California                    St   | [(-122.2032,37.005),(-122.2016,37.996)]                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ Cameron                       Ave  | [(-122.1316,37.502),(-122.1327,37.481)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Campus                        Dr   | [(-122.1704,37.905),(-122.1678,37.868),(-122.1671,37.865)]                                                                                                                                                                                                                                                                                                                                                                                   | Berkeley
+ Capricorn                     Ave  | [(-122.2176,37.404),(-122.2164,37.384)]                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ Carson                        St   | [(-122.1846,37.9),(-122.1843,37.901)]                                                                                                                                                                                                                                                                                                                                                                                                        | Berkeley
+ Cedar                         Blvd | [(-122.0282,37.446),(-122.0265,37.43)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Cedar                         St   | [(-122.3011,37.737),(-122.2999,37.739)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Celia                         St   | [(-122.0611,37.3),(-122.0616,37.299)]                                                                                                                                                                                                                                                                                                                                                                                                        | Oakland
+ Central                       Ave  | [(-122.2343,37.602),(-122.2331,37.595)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Chambers                      Dr   | [(-122.2004,37.352),(-122.1972,37.368)]                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ Chambers                      Lane | [(-122.2001,37.359),(-122.1975,37.371)]                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ Champion                      St   | [(-122.214,37.991),(-122.2147,37.002)]                                                                                                                                                                                                                                                                                                                                                                                                       | Berkeley
+ Champion                      St   | [(-122.214,37.991),(-122.2147,37.002)]                                                                                                                                                                                                                                                                                                                                                                                                       | Lafayette
+ Chapman                       Dr   | [(-122.0421,37.504),(-122.0414,37.498)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Charles                       St   | [(-122.0255,37.505),(-122.0252,37.499)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Cherry                        St   | [(-122.0437,37.42),(-122.0434,37.413)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Claremont                     Pl   | [(-122.0542,37.995),(-122.0542,37.008)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Claremont                     Pl   | [(-122.0542,37.995),(-122.0542,37.008)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Claremont                     Pl   | [(-122.0542,37.995),(-122.0542,37.008)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Coliseum                      Way  | [(-122.2001,37.47),(-122.1978,37.516)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Coliseum                      Way  | [(-122.2113,37.626),(-122.2085,37.592),(-122.2063,37.568)]                                                                                                                                                                                                                                                                                                                                                                                   | Berkeley
+ Coolidge                      Ave  | [(-122.2007,37.058),(-122.1992,37.06)]                                                                                                                                                                                                                                                                                                                                                                                                       | Lafayette
+ Cornell                       Ave  | [(-122.2956,37.925),(-122.2949,37.906),(-122.2939,37.875)]                                                                                                                                                                                                                                                                                                                                                                                   | Berkeley
+ Corriea                       Way  | [(-121.9501,37.402),(-121.9505,37.398)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Corriea                       Way  | [(-121.9501,37.402),(-121.9505,37.398)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Cowing                        Road | [(-122.0002,37.934),(-121.9772,37.782)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Creston                       Road | [(-122.2639,37.002),(-122.2613,37.986),(-122.2602,37.978),(-122.2598,37.973)]                                                                                                                                                                                                                                                                                                                                                                | Berkeley
+ Creston                       Road | [(-122.2639,37.002),(-122.2613,37.986),(-122.2602,37.978),(-122.2598,37.973)]                                                                                                                                                                                                                                                                                                                                                                | Lafayette
+ Crow Canyon Creek                  | [(-122.043,37.905),(-122.0368,37.71)]                                                                                                                                                                                                                                                                                                                                                                                                        | Berkeley
+ Crystaline                    Dr   | [(-121.925856,37),(-121.925869,37.00527)]                                                                                                                                                                                                                                                                                                                                                                                                    | Oakland
+ Cull Canyon                   Road | [(-122.0536,37.435),(-122.0499,37.315)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Cull Creek                         | [(-122.0624,37.875),(-122.0582,37.527)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ D                             St   | [(-122.1811,37.505),(-122.1805,37.497)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Decoto                        Road | [(-122.0159,37.006),(-122.016,37.002),(-122.0164,37.993)]                                                                                                                                                                                                                                                                                                                                                                                    | Oakland
+ Decoto                        Road | [(-122.0159,37.006),(-122.016,37.002),(-122.0164,37.993)]                                                                                                                                                                                                                                                                                                                                                                                    | Oakland
+ Decoto                        Road | [(-122.0159,37.006),(-122.016,37.002),(-122.0164,37.993)]                                                                                                                                                                                                                                                                                                                                                                                    | Berkeley
+ Deering                       St   | [(-122.2146,37.904),(-122.2126,37.897)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Dimond                        Ave  | [(-122.2167,37.994),(-122.2162,37.006)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Dimond                        Ave  | [(-122.2167,37.994),(-122.2162,37.006)]                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ Donna                         Way  | [(-122.1333,37.606),(-122.1316,37.599)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Driftwood                     Dr   | [(-122.0109,37.482),(-122.0113,37.477)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Driscoll                      Road | [(-121.9482,37.403),(-121.948451,37.39995)]                                                                                                                                                                                                                                                                                                                                                                                                  | Oakland
+ Driscoll                      Road | [(-121.9482,37.403),(-121.948451,37.39995)]                                                                                                                                                                                                                                                                                                                                                                                                  | Oakland
+ E                             St   | [(-122.1832,37.505),(-122.1826,37.498),(-122.182,37.49)]                                                                                                                                                                                                                                                                                                                                                                                     | Oakland
+ Eden                          Ave  | [(-122.1143,37.505),(-122.1142,37.491)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Eden Creek                         | [(-122.022037,37.00675),(-122.0221,37.998)]                                                                                                                                                                                                                                                                                                                                                                                                  | Oakland
+ Eden Creek                         | [(-122.022037,37.00675),(-122.0221,37.998)]                                                                                                                                                                                                                                                                                                                                                                                                  | Oakland
+ Eden Creek                         | [(-122.022037,37.00675),(-122.0221,37.998)]                                                                                                                                                                                                                                                                                                                                                                                                  | Berkeley
+ Edgewater                     Dr   | [(-122.201,37.379),(-122.2042,37.41)]                                                                                                                                                                                                                                                                                                                                                                                                        | Lafayette
+ Enos                          Way  | [(-121.7677,37.896),(-121.7673,37.91)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Euclid                        Ave  | [(-122.2671,37.009),(-122.2666,37.987)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Euclid                        Ave  | [(-122.2671,37.009),(-122.2666,37.987)]                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ Fairview                      Ave  | [(-121.999,37.428),(-121.9863,37.351)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Fairview                      Ave  | [(-121.999,37.428),(-121.9863,37.351)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Foothill                      Blvd | [(-122.2414,37.9),(-122.2403,37.893)]                                                                                                                                                                                                                                                                                                                                                                                                        | Berkeley
+ Fountain                      St   | [(-122.2306,37.593),(-122.2293,37.605)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Gading                        Road | [(-122.0801,37.343),(-122.08,37.336)]                                                                                                                                                                                                                                                                                                                                                                                                        | Oakland
+ Grizzly Peak                  Blvd | [(-122.2213,37.638),(-122.2127,37.581)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Grove                         Way  | [(-122.0643,37.884),(-122.062679,37.89162),(-122.061796,37.89578),(-122.0609,37.9)]                                                                                                                                                                                                                                                                                                                                                          | Berkeley
+ Harris                        Road | [(-122.0659,37.372),(-122.0675,37.363)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Heartwood                     Dr   | [(-122.2006,37.341),(-122.1992,37.338)]                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ Hegenberger                   Exwy | [(-122.1946,37.52),(-122.1947,37.497)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Herrier                       St   | [(-122.1943,37.006),(-122.1936,37.998)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Herrier                       St   | [(-122.1943,37.006),(-122.1936,37.998)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Hesperian                     Blvd | [(-122.097,37.333),(-122.0956,37.31),(-122.0946,37.293)]                                                                                                                                                                                                                                                                                                                                                                                     | Oakland
+ Hesperian                     Blvd | [(-122.097,37.333),(-122.0956,37.31),(-122.0946,37.293)]                                                                                                                                                                                                                                                                                                                                                                                     | Oakland
+ Hesperian                     Blvd | [(-122.1132,37.6),(-122.1123,37.586)]                                                                                                                                                                                                                                                                                                                                                                                                        | Berkeley
+ Hollis                        St   | [(-122.2885,37.397),(-122.289,37.414)]                                                                                                                                                                                                                                                                                                                                                                                                       | Lafayette
+ I- 580                             | [(-121.727,37.074),(-121.7229,37.093),(-121.722301,37.09522),(-121.721001,37.10005),(-121.7194,37.106),(-121.7188,37.109),(-121.7168,37.12),(-121.7163,37.123),(-121.7145,37.127),(-121.7096,37.148),(-121.707731,37.1568),(-121.7058,37.166),(-121.7055,37.168),(-121.7044,37.174),(-121.7038,37.172),(-121.7037,37.172),(-121.7027,37.175),(-121.7001,37.181),(-121.6957,37.191),(-121.6948,37.192),(-121.6897,37.204),(-121.6697,37.185)] | Oakland
+ I- 580                             | [(-121.9322,37.989),(-121.9243,37.006),(-121.9217,37.014)]                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ I- 580                             | [(-121.9322,37.989),(-121.9243,37.006),(-121.9217,37.014)]                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ I- 580                             | [(-122.018,37.019),(-122.0009,37.032),(-121.9787,37.983),(-121.958,37.984),(-121.9571,37.986)]                                                                                                                                                                                                                                                                                                                                               | Oakland
+ I- 580                             | [(-122.018,37.019),(-122.0009,37.032),(-121.9787,37.983),(-121.958,37.984),(-121.9571,37.986)]                                                                                                                                                                                                                                                                                                                                               | Oakland
+ I- 580                             | [(-122.1108,37.023),(-122.1101,37.02),(-122.108103,37.00764),(-122.108,37.007),(-122.1069,37.998),(-122.1064,37.994),(-122.1053,37.982),(-122.1048,37.977),(-122.1032,37.958),(-122.1026,37.953),(-122.1013,37.938),(-122.0989,37.911),(-122.0984,37.91),(-122.098,37.908)]                                                                                                                                                                  | Oakland
+ I- 580                             | [(-122.1108,37.023),(-122.1101,37.02),(-122.108103,37.00764),(-122.108,37.007),(-122.1069,37.998),(-122.1064,37.994),(-122.1053,37.982),(-122.1048,37.977),(-122.1032,37.958),(-122.1026,37.953),(-122.1013,37.938),(-122.0989,37.911),(-122.0984,37.91),(-122.098,37.908)]                                                                                                                                                                  | Berkeley
+ I- 580                             | [(-122.1543,37.703),(-122.1535,37.694),(-122.1512,37.655),(-122.1475,37.603),(-122.1468,37.583),(-122.1472,37.569),(-122.149044,37.54874),(-122.1493,37.546),(-122.1501,37.532),(-122.1506,37.509),(-122.1495,37.482),(-122.1487,37.467),(-122.1477,37.447),(-122.1414,37.383),(-122.1404,37.376),(-122.1398,37.372),(-122.139,37.356),(-122.1388,37.353),(-122.1385,37.34),(-122.1382,37.33),(-122.1378,37.316)]                            | Oakland
+ I- 580                             | [(-122.1543,37.703),(-122.1535,37.694),(-122.1512,37.655),(-122.1475,37.603),(-122.1468,37.583),(-122.1472,37.569),(-122.149044,37.54874),(-122.1493,37.546),(-122.1501,37.532),(-122.1506,37.509),(-122.1495,37.482),(-122.1487,37.467),(-122.1477,37.447),(-122.1414,37.383),(-122.1404,37.376),(-122.1398,37.372),(-122.139,37.356),(-122.1388,37.353),(-122.1385,37.34),(-122.1382,37.33),(-122.1378,37.316)]                            | Berkeley
+ I- 580                             | [(-122.2197,37.99),(-122.22,37.99),(-122.222092,37.99523),(-122.2232,37.998),(-122.224146,37.99963),(-122.2261,37.003),(-122.2278,37.007),(-122.2302,37.026),(-122.2323,37.043),(-122.2344,37.059),(-122.235405,37.06427),(-122.2365,37.07)]                                                                                                                                                                                                 | Berkeley
+ I- 580                             | [(-122.2197,37.99),(-122.22,37.99),(-122.222092,37.99523),(-122.2232,37.998),(-122.224146,37.99963),(-122.2261,37.003),(-122.2278,37.007),(-122.2302,37.026),(-122.2323,37.043),(-122.2344,37.059),(-122.235405,37.06427),(-122.2365,37.07)]                                                                                                                                                                                                 | Lafayette
+ I- 580                        Ramp | [(-121.8521,37.011),(-121.8479,37.999),(-121.8476,37.999),(-121.8456,37.01),(-121.8455,37.011)]                                                                                                                                                                                                                                                                                                                                              | Oakland
+ I- 580                        Ramp | [(-121.8521,37.011),(-121.8479,37.999),(-121.8476,37.999),(-121.8456,37.01),(-121.8455,37.011)]                                                                                                                                                                                                                                                                                                                                              | Oakland
+ I- 580                        Ramp | [(-121.8743,37.014),(-121.8722,37.999),(-121.8714,37.999)]                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ I- 580                        Ramp | [(-121.8743,37.014),(-121.8722,37.999),(-121.8714,37.999)]                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ I- 580                        Ramp | [(-121.9043,37.998),(-121.9036,37.013),(-121.902632,37.0174),(-121.9025,37.018)]                                                                                                                                                                                                                                                                                                                                                             | Oakland
+ I- 580                        Ramp | [(-121.9043,37.998),(-121.9036,37.013),(-121.902632,37.0174),(-121.9025,37.018)]                                                                                                                                                                                                                                                                                                                                                             | Oakland
+ I- 580                        Ramp | [(-121.9368,37.986),(-121.936483,37.98832),(-121.9353,37.997),(-121.93504,37.00035),(-121.9346,37.006),(-121.933764,37.00031),(-121.9333,37.997),(-121.9322,37.989)]                                                                                                                                                                                                                                                                         | Oakland
+ I- 580                        Ramp | [(-121.9368,37.986),(-121.936483,37.98832),(-121.9353,37.997),(-121.93504,37.00035),(-121.9346,37.006),(-121.933764,37.00031),(-121.9333,37.997),(-121.9322,37.989)]                                                                                                                                                                                                                                                                         | Oakland
+ I- 580                        Ramp | [(-122.093241,37.90351),(-122.09364,37.89634),(-122.093788,37.89212)]                                                                                                                                                                                                                                                                                                                                                                        | Berkeley
+ I- 580                        Ramp | [(-122.0934,37.896),(-122.09257,37.89961),(-122.0911,37.906)]                                                                                                                                                                                                                                                                                                                                                                                | Berkeley
+ I- 580                        Ramp | [(-122.0941,37.897),(-122.0943,37.902)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ I- 580                        Ramp | [(-122.096,37.888),(-122.0962,37.891),(-122.0964,37.9)]                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ I- 580                        Ramp | [(-122.101,37.898),(-122.1005,37.902),(-122.0989,37.911)]                                                                                                                                                                                                                                                                                                                                                                                    | Berkeley
+ I- 580                        Ramp | [(-122.1086,37.003),(-122.1068,37.993),(-122.1066,37.992),(-122.1053,37.982)]                                                                                                                                                                                                                                                                                                                                                                | Oakland
+ I- 580                        Ramp | [(-122.1086,37.003),(-122.1068,37.993),(-122.1066,37.992),(-122.1053,37.982)]                                                                                                                                                                                                                                                                                                                                                                | Berkeley
+ I- 580                        Ramp | [(-122.1414,37.383),(-122.1407,37.376),(-122.1403,37.372),(-122.139,37.356)]                                                                                                                                                                                                                                                                                                                                                                 | Oakland
+ I- 580/I-680                  Ramp | ((-121.9207,37.988),(-121.9192,37.016))                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ I- 580/I-680                  Ramp | ((-121.9207,37.988),(-121.9192,37.016))                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ I- 680                             | ((-121.939,37.15),(-121.9387,37.145),(-121.9373,37.125),(-121.934242,37.07643),(-121.933886,37.0709),(-121.9337,37.068),(-121.933122,37.06139),(-121.932736,37.05698),(-121.93222,37.05108),(-121.931844,37.04678),(-121.930113,37.027),(-121.926829,37),(-121.9265,37.998),(-121.9217,37.96),(-121.9203,37.949),(-121.9184,37.934))                                                                                                         | Oakland
+ I- 680                             | ((-121.939,37.15),(-121.9387,37.145),(-121.9373,37.125),(-121.934242,37.07643),(-121.933886,37.0709),(-121.9337,37.068),(-121.933122,37.06139),(-121.932736,37.05698),(-121.93222,37.05108),(-121.931844,37.04678),(-121.930113,37.027),(-121.926829,37),(-121.9265,37.998),(-121.9217,37.96),(-121.9203,37.949),(-121.9184,37.934))                                                                                                         | Oakland
+ I- 680                             | [(-121.9101,37.715),(-121.911269,37.74682),(-121.9119,37.764),(-121.9124,37.776),(-121.9174,37.905),(-121.9194,37.957),(-121.9207,37.988)]                                                                                                                                                                                                                                                                                                   | Oakland
+ I- 680                             | [(-121.9184,37.934),(-121.917,37.913),(-121.9122,37.83),(-121.9052,37.702)]                                                                                                                                                                                                                                                                                                                                                                  | Oakland
+ I- 680                        Ramp | [(-121.8833,37.376),(-121.8833,37.392),(-121.883,37.4),(-121.8835,37.402),(-121.8852,37.422)]                                                                                                                                                                                                                                                                                                                                                | Oakland
+ I- 680                        Ramp | [(-121.8833,37.376),(-121.8833,37.392),(-121.883,37.4),(-121.8835,37.402),(-121.8852,37.422)]                                                                                                                                                                                                                                                                                                                                                | Oakland
+ I- 680                        Ramp | [(-121.92,37.438),(-121.9218,37.424),(-121.9238,37.408),(-121.9252,37.392)]                                                                                                                                                                                                                                                                                                                                                                  | Oakland
+ I- 680                        Ramp | [(-121.92,37.438),(-121.9218,37.424),(-121.9238,37.408),(-121.9252,37.392)]                                                                                                                                                                                                                                                                                                                                                                  | Oakland
+ I- 680                        Ramp | [(-121.9238,37.402),(-121.9234,37.395),(-121.923,37.399)]                                                                                                                                                                                                                                                                                                                                                                                    | Oakland
+ I- 680                        Ramp | [(-121.9238,37.402),(-121.9234,37.395),(-121.923,37.399)]                                                                                                                                                                                                                                                                                                                                                                                    | Oakland
+ I- 80                              | ((-122.2937,37.277),(-122.3016,37.262))                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ I- 80                              | ((-122.2962,37.273),(-122.3004,37.264))                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ I- 80                         Ramp | [(-122.2962,37.413),(-122.2959,37.382),(-122.2951,37.372)]                                                                                                                                                                                                                                                                                                                                                                                   | Lafayette
+ I- 880                             | ((-121.9669,37.075),(-121.9663,37.071),(-121.9656,37.065),(-121.9618,37.037),(-121.95689,37),(-121.948,37.933))                                                                                                                                                                                                                                                                                                                              | Oakland
+ I- 880                             | ((-121.9669,37.075),(-121.9663,37.071),(-121.9656,37.065),(-121.9618,37.037),(-121.95689,37),(-121.948,37.933))                                                                                                                                                                                                                                                                                                                              | Oakland
+ I- 880                             | [(-121.948,37.933),(-121.9471,37.925),(-121.9467,37.923),(-121.946,37.918),(-121.9452,37.912),(-121.937,37.852)]                                                                                                                                                                                                                                                                                                                             | Oakland
+ I- 880                             | [(-122.0219,37.466),(-122.0205,37.447),(-122.020331,37.44447),(-122.020008,37.43962),(-122.0195,37.432),(-122.0193,37.429),(-122.0164,37.393),(-122.010219,37.34771),(-122.0041,37.313)]                                                                                                                                                                                                                                                     | Oakland
+ I- 880                             | [(-122.0375,37.632),(-122.0359,37.619),(-122.0358,37.616),(-122.034514,37.60409),(-122.031876,37.57965),(-122.031193,37.57332),(-122.03016,37.56375),(-122.02943,37.55698),(-122.028689,37.54929),(-122.027833,37.53908),(-122.025979,37.51698),(-122.0238,37.491)]                                                                                                                                                                          | Oakland
+ I- 880                             | [(-122.0375,37.632),(-122.0359,37.619),(-122.0358,37.616),(-122.034514,37.60409),(-122.031876,37.57965),(-122.031193,37.57332),(-122.03016,37.56375),(-122.02943,37.55698),(-122.028689,37.54929),(-122.027833,37.53908),(-122.025979,37.51698),(-122.0238,37.491)]                                                                                                                                                                          | Berkeley
+ I- 880                             | [(-122.0612,37.003),(-122.0604,37.991),(-122.0596,37.982),(-122.0585,37.967),(-122.0583,37.961),(-122.0553,37.918),(-122.053635,37.89475),(-122.050759,37.8546),(-122.05,37.844),(-122.0485,37.817),(-122.0483,37.813),(-122.0482,37.811)]                                                                                                                                                                                                   | Oakland
+ I- 880                             | [(-122.0612,37.003),(-122.0604,37.991),(-122.0596,37.982),(-122.0585,37.967),(-122.0583,37.961),(-122.0553,37.918),(-122.053635,37.89475),(-122.050759,37.8546),(-122.05,37.844),(-122.0485,37.817),(-122.0483,37.813),(-122.0482,37.811)]                                                                                                                                                                                                   | Oakland
+ I- 880                             | [(-122.0612,37.003),(-122.0604,37.991),(-122.0596,37.982),(-122.0585,37.967),(-122.0583,37.961),(-122.0553,37.918),(-122.053635,37.89475),(-122.050759,37.8546),(-122.05,37.844),(-122.0485,37.817),(-122.0483,37.813),(-122.0482,37.811)]                                                                                                                                                                                                   | Berkeley
+ I- 880                             | [(-122.0831,37.312),(-122.0819,37.296),(-122.081,37.285),(-122.0786,37.248),(-122.078,37.24),(-122.077642,37.23496),(-122.076983,37.22567),(-122.076599,37.22026),(-122.076229,37.21505),(-122.0758,37.209)]                                                                                                                                                                                                                                 | Oakland
+ I- 880                             | [(-122.0978,37.528),(-122.096,37.496),(-122.0931,37.453),(-122.09277,37.4496),(-122.090189,37.41442),(-122.0896,37.405),(-122.085,37.34)]                                                                                                                                                                                                                                                                                                    | Oakland
+ I- 880                             | [(-122.1365,37.902),(-122.1358,37.898),(-122.1333,37.881),(-122.1323,37.874),(-122.1311,37.866),(-122.1308,37.865),(-122.1307,37.864),(-122.1289,37.851),(-122.1277,37.843),(-122.1264,37.834),(-122.1231,37.812),(-122.1165,37.766),(-122.1104,37.72),(-122.109695,37.71094),(-122.109,37.702),(-122.108312,37.69168),(-122.1076,37.681)]                                                                                                   | Berkeley
+ I- 880                             | [(-122.1755,37.185),(-122.1747,37.178),(-122.1742,37.173),(-122.1692,37.126),(-122.167792,37.11594),(-122.16757,37.11435),(-122.1671,37.111),(-122.1655,37.1),(-122.165169,37.09811),(-122.1641,37.092),(-122.1596,37.061),(-122.158381,37.05275),(-122.155991,37.03657),(-122.1531,37.017),(-122.1478,37.98),(-122.1407,37.932),(-122.1394,37.924),(-122.1389,37.92),(-122.1376,37.91)]                                                     | Oakland
+ I- 880                             | [(-122.1755,37.185),(-122.1747,37.178),(-122.1742,37.173),(-122.1692,37.126),(-122.167792,37.11594),(-122.16757,37.11435),(-122.1671,37.111),(-122.1655,37.1),(-122.165169,37.09811),(-122.1641,37.092),(-122.1596,37.061),(-122.158381,37.05275),(-122.155991,37.03657),(-122.1531,37.017),(-122.1478,37.98),(-122.1407,37.932),(-122.1394,37.924),(-122.1389,37.92),(-122.1376,37.91)]                                                     | Berkeley
+ I- 880                             | [(-122.2214,37.711),(-122.2202,37.699),(-122.2199,37.695),(-122.219,37.682),(-122.2184,37.672),(-122.2173,37.652),(-122.2159,37.638),(-122.2144,37.616),(-122.2138,37.612),(-122.2135,37.609),(-122.212,37.592),(-122.2116,37.586),(-122.2111,37.581)]                                                                                                                                                                                       | Berkeley
+ I- 880                             | [(-122.2707,37.975),(-122.2693,37.972),(-122.2681,37.966),(-122.267,37.962),(-122.2659,37.957),(-122.2648,37.952),(-122.2636,37.946),(-122.2625,37.935),(-122.2617,37.927),(-122.2607,37.921),(-122.2593,37.916),(-122.258,37.911),(-122.2536,37.898),(-122.2432,37.858),(-122.2408,37.845),(-122.2386,37.827),(-122.2374,37.811)]                                                                                                           | Berkeley
+ I- 880                        Ramp | [(-122.0019,37.301),(-122.002,37.293)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ I- 880                        Ramp | [(-122.0041,37.313),(-122.0018,37.315),(-122.0007,37.315),(-122.0005,37.313),(-122.0002,37.308),(-121.9995,37.289)]                                                                                                                                                                                                                                                                                                                          | Oakland
+ I- 880                        Ramp | [(-122.0041,37.313),(-122.0038,37.308),(-122.0039,37.284),(-122.0013,37.287),(-121.9995,37.289)]                                                                                                                                                                                                                                                                                                                                             | Oakland
+ I- 880                        Ramp | [(-122.0236,37.488),(-122.0231,37.458),(-122.0227,37.458),(-122.0223,37.452),(-122.0205,37.447)]                                                                                                                                                                                                                                                                                                                                             | Oakland
+ I- 880                        Ramp | [(-122.0238,37.491),(-122.0215,37.483),(-122.0211,37.477),(-122.0205,37.447)]                                                                                                                                                                                                                                                                                                                                                                | Oakland
+ I- 880                        Ramp | [(-122.059,37.982),(-122.0577,37.984),(-122.0612,37.003)]                                                                                                                                                                                                                                                                                                                                                                                    | Oakland
+ I- 880                        Ramp | [(-122.059,37.982),(-122.0577,37.984),(-122.0612,37.003)]                                                                                                                                                                                                                                                                                                                                                                                    | Oakland
+ I- 880                        Ramp | [(-122.059,37.982),(-122.0577,37.984),(-122.0612,37.003)]                                                                                                                                                                                                                                                                                                                                                                                    | Berkeley
+ I- 880                        Ramp | [(-122.0618,37.011),(-122.0631,37.982),(-122.0585,37.967)]                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ I- 880                        Ramp | [(-122.0618,37.011),(-122.0631,37.982),(-122.0585,37.967)]                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ I- 880                        Ramp | [(-122.0618,37.011),(-122.0631,37.982),(-122.0585,37.967)]                                                                                                                                                                                                                                                                                                                                                                                   | Berkeley
+ I- 880                        Ramp | [(-122.085,37.34),(-122.0801,37.316),(-122.081,37.285)]                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ I- 880                        Ramp | [(-122.085,37.34),(-122.0801,37.316),(-122.081,37.285)]                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ I- 880                        Ramp | [(-122.085,37.34),(-122.0866,37.316),(-122.0819,37.296)]                                                                                                                                                                                                                                                                                                                                                                                     | Oakland
+ I- 880                        Ramp | [(-122.085,37.34),(-122.0866,37.316),(-122.0819,37.296)]                                                                                                                                                                                                                                                                                                                                                                                     | Oakland
+ I- 880                        Ramp | [(-122.1029,37.61),(-122.1013,37.587),(-122.0999,37.569)]                                                                                                                                                                                                                                                                                                                                                                                    | Berkeley
+ I- 880                        Ramp | [(-122.1379,37.891),(-122.1383,37.897),(-122.1377,37.902)]                                                                                                                                                                                                                                                                                                                                                                                   | Berkeley
+ I- 880                        Ramp | [(-122.1379,37.931),(-122.137597,37.92736),(-122.1374,37.925),(-122.1373,37.924),(-122.1369,37.914),(-122.1358,37.905),(-122.1365,37.908),(-122.1358,37.898)]                                                                                                                                                                                                                                                                                | Berkeley
+ I- 880                        Ramp | [(-122.2536,37.898),(-122.254,37.902)]                                                                                                                                                                                                                                                                                                                                                                                                       | Berkeley
+ I- 880                        Ramp | [(-122.2771,37.002),(-122.278,37)]                                                                                                                                                                                                                                                                                                                                                                                                           | Lafayette
+ Indian                        Way  | [(-122.2066,37.398),(-122.2045,37.411)]                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ Jackson                       St   | [(-122.0845,37.6),(-122.0842,37.606)]                                                                                                                                                                                                                                                                                                                                                                                                        | Berkeley
+ Johnson                       Dr   | [(-121.9145,37.901),(-121.915,37.877)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Joyce                         St   | [(-122.0792,37.604),(-122.0774,37.581)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Juniper                       St   | [(-121.7823,37.897),(-121.7815,37.9)]                                                                                                                                                                                                                                                                                                                                                                                                        | Oakland
+ Kaiser                        Dr   | [(-122.067163,37.47821),(-122.060402,37.51961)]                                                                                                                                                                                                                                                                                                                                                                                              | Oakland
+ Keeler                        Ave  | [(-122.2578,37.906),(-122.2579,37.899)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Kildare                       Road | [(-122.0968,37.016),(-122.0959,37)]                                                                                                                                                                                                                                                                                                                                                                                                          | Oakland
+ La Playa                      Dr   | [(-122.1039,37.545),(-122.101,37.493)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Laguna                        Ave  | [(-122.2099,37.989),(-122.2089,37)]                                                                                                                                                                                                                                                                                                                                                                                                          | Berkeley
+ Laguna                        Ave  | [(-122.2099,37.989),(-122.2089,37)]                                                                                                                                                                                                                                                                                                                                                                                                          | Lafayette
+ Lakehurst                     Cir  | [(-122.284729,37.89025),(-122.286096,37.90364)]                                                                                                                                                                                                                                                                                                                                                                                              | Berkeley
+ Lakeshore                     Ave  | [(-122.2586,37.99),(-122.2556,37.006)]                                                                                                                                                                                                                                                                                                                                                                                                       | Berkeley
+ Lakeshore                     Ave  | [(-122.2586,37.99),(-122.2556,37.006)]                                                                                                                                                                                                                                                                                                                                                                                                       | Lafayette
+ Las Positas                   Road | [(-121.764488,37.99199),(-121.75569,37.02022)]                                                                                                                                                                                                                                                                                                                                                                                               | Oakland
+ Las Positas                   Road | [(-121.764488,37.99199),(-121.75569,37.02022)]                                                                                                                                                                                                                                                                                                                                                                                               | Oakland
+ Linden                        St   | [(-122.2867,37.998),(-122.2864,37.008)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Linden                        St   | [(-122.2867,37.998),(-122.2864,37.008)]                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ Livermore                     Ave  | [(-121.7687,37.448),(-121.769,37.375)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Livermore                     Ave  | [(-121.7687,37.448),(-121.769,37.375)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Livermore                     Ave  | [(-121.772719,37.99085),(-121.7728,37.001)]                                                                                                                                                                                                                                                                                                                                                                                                  | Oakland
+ Livermore                     Ave  | [(-121.772719,37.99085),(-121.7728,37.001)]                                                                                                                                                                                                                                                                                                                                                                                                  | Oakland
+ Locust                        St   | [(-122.1606,37.007),(-122.1593,37.987)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Locust                        St   | [(-122.1606,37.007),(-122.1593,37.987)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Logan                         Ct   | [(-122.0053,37.492),(-122.0061,37.484)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Magnolia                      St   | [(-122.0971,37.5),(-122.0962,37.484)]                                                                                                                                                                                                                                                                                                                                                                                                        | Oakland
+ Mandalay                      Road | [(-122.2322,37.397),(-122.2321,37.403)]                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ Marin                         Ave  | [(-122.2741,37.894),(-122.272,37.901)]                                                                                                                                                                                                                                                                                                                                                                                                       | Berkeley
+ Martin Luther King Jr         Way  | [(-122.2712,37.608),(-122.2711,37.599)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Mattos                        Dr   | [(-122.0005,37.502),(-122.000898,37.49683)]                                                                                                                                                                                                                                                                                                                                                                                                  | Oakland
+ Maubert                       Ave  | [(-122.1114,37.009),(-122.1096,37.995)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Maubert                       Ave  | [(-122.1114,37.009),(-122.1096,37.995)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ McClure                       Ave  | [(-122.1431,37.001),(-122.1436,37.998)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ McClure                       Ave  | [(-122.1431,37.001),(-122.1436,37.998)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Medlar                        Dr   | [(-122.0627,37.378),(-122.0625,37.375)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Mildred                       Ct   | [(-122.0002,37.388),(-121.9998,37.386)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Miller                        Road | [(-122.0902,37.645),(-122.0865,37.545)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Miramar                       Ave  | [(-122.1009,37.025),(-122.099089,37.03209)]                                                                                                                                                                                                                                                                                                                                                                                                  | Oakland
+ Mission                       Blvd | [(-121.918886,37),(-121.9194,37.976),(-121.9198,37.975)]                                                                                                                                                                                                                                                                                                                                                                                     | Oakland
+ Mission                       Blvd | [(-121.918886,37),(-121.9194,37.976),(-121.9198,37.975)]                                                                                                                                                                                                                                                                                                                                                                                     | Oakland
+ Mission                       Blvd | [(-122.0006,37.896),(-121.9989,37.88)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Mission                       Blvd | [(-122.0006,37.896),(-121.9989,37.88)]                                                                                                                                                                                                                                                                                                                                                                                                       | Berkeley
+ Moores                        Ave  | [(-122.0087,37.301),(-122.0094,37.292)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ National                      Ave  | [(-122.1192,37.5),(-122.1281,37.489)]                                                                                                                                                                                                                                                                                                                                                                                                        | Oakland
+ Navajo                        Ct   | [(-121.8779,37.901),(-121.8783,37.9)]                                                                                                                                                                                                                                                                                                                                                                                                        | Oakland
+ Newark                        Blvd | [(-122.0352,37.438),(-122.0341,37.423)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Oakland Inner Harbor               | [(-122.2625,37.913),(-122.260016,37.89484)]                                                                                                                                                                                                                                                                                                                                                                                                  | Berkeley
+ Oakridge                      Road | [(-121.8316,37.049),(-121.828382,37)]                                                                                                                                                                                                                                                                                                                                                                                                        | Oakland
+ Oneil                         Ave  | [(-122.076754,37.62476),(-122.0745,37.595)]                                                                                                                                                                                                                                                                                                                                                                                                  | Berkeley
+ Parkridge                     Dr   | [(-122.1438,37.884),(-122.1428,37.9)]                                                                                                                                                                                                                                                                                                                                                                                                        | Berkeley
+ Parkside                      Dr   | [(-122.0475,37.603),(-122.0443,37.596)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Paseo Padre                   Pkwy | [(-121.9143,37.005),(-121.913522,37)]                                                                                                                                                                                                                                                                                                                                                                                                        | Oakland
+ Paseo Padre                   Pkwy | [(-122.0021,37.639),(-121.996,37.628)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Paseo Padre                   Pkwy | [(-122.0021,37.639),(-121.996,37.628)]                                                                                                                                                                                                                                                                                                                                                                                                       | Berkeley
+ Pearl                         St   | [(-122.2383,37.594),(-122.2366,37.615)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Periwinkle                    Road | [(-122.0451,37.301),(-122.044758,37.29844)]                                                                                                                                                                                                                                                                                                                                                                                                  | Oakland
+ Pimlico                       Dr   | [(-121.8616,37.998),(-121.8618,37.008)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Pimlico                       Dr   | [(-121.8616,37.998),(-121.8618,37.008)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Portsmouth                    Ave  | [(-122.1064,37.315),(-122.1064,37.308)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Proctor                       Ave  | [(-122.2267,37.406),(-122.2251,37.386)]                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ Railroad                      Ave  | [(-122.0245,37.013),(-122.0234,37.003),(-122.0223,37.993)]                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ Railroad                      Ave  | [(-122.0245,37.013),(-122.0234,37.003),(-122.0223,37.993)]                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ Railroad                      Ave  | [(-122.0245,37.013),(-122.0234,37.003),(-122.0223,37.993)]                                                                                                                                                                                                                                                                                                                                                                                   | Berkeley
+ Ranspot                       Dr   | [(-122.0972,37.999),(-122.0959,37)]                                                                                                                                                                                                                                                                                                                                                                                                          | Oakland
+ Ranspot                       Dr   | [(-122.0972,37.999),(-122.0959,37)]                                                                                                                                                                                                                                                                                                                                                                                                          | Oakland
+ Ranspot                       Dr   | [(-122.0972,37.999),(-122.0959,37)]                                                                                                                                                                                                                                                                                                                                                                                                          | Berkeley
+ Redding                       St   | [(-122.1978,37.901),(-122.1975,37.895)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Redwood                       Road | [(-122.1493,37.98),(-122.1437,37.001)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Redwood                       Road | [(-122.1493,37.98),(-122.1437,37.001)]                                                                                                                                                                                                                                                                                                                                                                                                       | Berkeley
+ Roca                          Dr   | [(-122.0335,37.609),(-122.0314,37.599)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Rosedale                      Ct   | [(-121.9232,37.9),(-121.924,37.897)]                                                                                                                                                                                                                                                                                                                                                                                                         | Oakland
+ Sacramento                    St   | [(-122.2799,37.606),(-122.2797,37.597)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Saddle Brook                  Dr   | [(-122.1478,37.909),(-122.1454,37.904),(-122.1451,37.888)]                                                                                                                                                                                                                                                                                                                                                                                   | Berkeley
+ Saginaw                       Ct   | [(-121.8803,37.898),(-121.8806,37.901)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ San Andreas                   Dr   | [(-122.0609,37.9),(-122.0614,37.895)]                                                                                                                                                                                                                                                                                                                                                                                                        | Berkeley
+ Santa Maria                   Ave  | [(-122.0773,37),(-122.0773,37.98)]                                                                                                                                                                                                                                                                                                                                                                                                           | Oakland
+ Santa Maria                   Ave  | [(-122.0773,37),(-122.0773,37.98)]                                                                                                                                                                                                                                                                                                                                                                                                           | Oakland
+ Santa Maria                   Ave  | [(-122.0773,37),(-122.0773,37.98)]                                                                                                                                                                                                                                                                                                                                                                                                           | Berkeley
+ Shattuck                      Ave  | [(-122.2686,37.904),(-122.2686,37.897)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Sheridan                      Road | [(-122.2279,37.425),(-122.2253,37.411),(-122.2223,37.377)]                                                                                                                                                                                                                                                                                                                                                                                   | Lafayette
+ Shoreline                     Dr   | [(-122.2657,37.603),(-122.2648,37.6)]                                                                                                                                                                                                                                                                                                                                                                                                        | Berkeley
+ Skyline                       Blvd | [(-122.1738,37.01),(-122.1714,37.996)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Skyline                       Blvd | [(-122.1738,37.01),(-122.1714,37.996)]                                                                                                                                                                                                                                                                                                                                                                                                       | Berkeley
+ Skyline                       Dr   | [(-122.0277,37.5),(-122.0284,37.498)]                                                                                                                                                                                                                                                                                                                                                                                                        | Oakland
+ Skywest                       Dr   | [(-122.1161,37.62),(-122.1123,37.586)]                                                                                                                                                                                                                                                                                                                                                                                                       | Berkeley
+ Southern Pacific Railroad          | [(-122.3002,37.674),(-122.2999,37.661)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Sp Railroad                        | [(-121.893564,37.99009),(-121.897,37.016)]                                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ Sp Railroad                        | [(-121.893564,37.99009),(-121.897,37.016)]                                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ Sp Railroad                        | [(-121.9565,37.898),(-121.9562,37.9)]                                                                                                                                                                                                                                                                                                                                                                                                        | Oakland
+ Sp Railroad                        | [(-122.0734,37.001),(-122.0734,37.997)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Sp Railroad                        | [(-122.0734,37.001),(-122.0734,37.997)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Sp Railroad                        | [(-122.0734,37.001),(-122.0734,37.997)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Sp Railroad                        | [(-122.0914,37.601),(-122.087,37.56),(-122.086408,37.5551)]                                                                                                                                                                                                                                                                                                                                                                                  | Berkeley
+ Sp Railroad                        | [(-122.137792,37.003),(-122.1365,37.992),(-122.131257,37.94612)]                                                                                                                                                                                                                                                                                                                                                                             | Oakland
+ Sp Railroad                        | [(-122.137792,37.003),(-122.1365,37.992),(-122.131257,37.94612)]                                                                                                                                                                                                                                                                                                                                                                             | Berkeley
+ Sp Railroad                        | [(-122.1947,37.497),(-122.193328,37.4848)]                                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ Stanton                       Ave  | [(-122.100392,37.0697),(-122.099513,37.06052)]                                                                                                                                                                                                                                                                                                                                                                                               | Oakland
+ State Hwy 123                      | [(-122.3004,37.986),(-122.2998,37.969),(-122.2995,37.962),(-122.2992,37.952),(-122.299,37.942),(-122.2987,37.935),(-122.2984,37.924),(-122.2982,37.92),(-122.2976,37.904),(-122.297,37.88),(-122.2966,37.869),(-122.2959,37.848),(-122.2961,37.843)]                                                                                                                                                                                         | Berkeley
+ State Hwy 13                       | [(-122.1797,37.943),(-122.179871,37.91849),(-122.18,37.9),(-122.179023,37.86615),(-122.1787,37.862),(-122.1781,37.851),(-122.1777,37.845),(-122.1773,37.839),(-122.177,37.833)]                                                                                                                                                                                                                                                              | Berkeley
+ State Hwy 13                       | [(-122.2049,37.2),(-122.20328,37.17975),(-122.1989,37.125),(-122.198078,37.11641),(-122.1975,37.11)]                                                                                                                                                                                                                                                                                                                                         | Lafayette
+ State Hwy 13                  Ramp | [(-122.2244,37.427),(-122.223,37.414),(-122.2214,37.396),(-122.2213,37.388)]                                                                                                                                                                                                                                                                                                                                                                 | Lafayette
+ State Hwy 238                      | ((-122.098,37.908),(-122.0983,37.907),(-122.099,37.905),(-122.101,37.898),(-122.101535,37.89711),(-122.103173,37.89438),(-122.1046,37.892),(-122.106,37.89))                                                                                                                                                                                                                                                                                 | Berkeley
+ State Hwy 238                 Ramp | [(-122.1288,37.9),(-122.1293,37.895),(-122.1296,37.906)]                                                                                                                                                                                                                                                                                                                                                                                     | Berkeley
+ State Hwy 24                       | [(-122.2674,37.246),(-122.2673,37.248),(-122.267,37.261),(-122.2668,37.271),(-122.2663,37.298),(-122.2659,37.315),(-122.2655,37.336),(-122.265007,37.35882),(-122.264443,37.37286),(-122.2641,37.381),(-122.2638,37.388),(-122.2631,37.396),(-122.2617,37.405),(-122.2615,37.407),(-122.2605,37.412)]                                                                                                                                        | Lafayette
+ State Hwy 84                       | [(-121.9565,37.898),(-121.956589,37.89911),(-121.9569,37.903),(-121.956,37.91),(-121.9553,37.919)]                                                                                                                                                                                                                                                                                                                                           | Oakland
+ State Hwy 84                       | [(-122.0671,37.426),(-122.07,37.402),(-122.074,37.37),(-122.0773,37.338)]                                                                                                                                                                                                                                                                                                                                                                    | Oakland
+ State Hwy 92                       | [(-122.1085,37.326),(-122.1095,37.322),(-122.1111,37.316),(-122.1119,37.313),(-122.1125,37.311),(-122.1131,37.308),(-122.1167,37.292),(-122.1187,37.285),(-122.12,37.28)]                                                                                                                                                                                                                                                                    | Oakland
+ State Hwy 92                  Ramp | [(-122.1086,37.321),(-122.1089,37.315),(-122.1111,37.316)]                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ Stuart                        St   | [(-122.2518,37.6),(-122.2507,37.601),(-122.2491,37.606)]                                                                                                                                                                                                                                                                                                                                                                                     | Berkeley
+ Sunol Ridge                   Trl  | [(-121.9419,37.455),(-121.9345,37.38)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Sunol Ridge                   Trl  | [(-121.9419,37.455),(-121.9345,37.38)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Tassajara Creek                    | [(-121.87866,37.98898),(-121.8782,37.015)]                                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ Tassajara Creek                    | [(-121.87866,37.98898),(-121.8782,37.015)]                                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ Taurus                        Ave  | [(-122.2159,37.416),(-122.2128,37.389)]                                                                                                                                                                                                                                                                                                                                                                                                      | Lafayette
+ Tennyson                      Road | [(-122.0891,37.317),(-122.0927,37.317)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Thackeray                     Ave  | [(-122.072,37.305),(-122.0715,37.298)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Theresa                       Way  | [(-121.7289,37.906),(-121.728,37.899)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ Tissiack                      Way  | [(-121.920364,37),(-121.9208,37.995)]                                                                                                                                                                                                                                                                                                                                                                                                        | Oakland
+ Tissiack                      Way  | [(-121.920364,37),(-121.9208,37.995)]                                                                                                                                                                                                                                                                                                                                                                                                        | Oakland
+ Tupelo                        Ter  | [(-122.059087,37.6113),(-122.057021,37.59942)]                                                                                                                                                                                                                                                                                                                                                                                               | Berkeley
+ Vallecitos                    Road | [(-121.8699,37.916),(-121.8703,37.891)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Warm Springs                  Blvd | [(-121.933956,37),(-121.9343,37.97)]                                                                                                                                                                                                                                                                                                                                                                                                         | Oakland
+ Warm Springs                  Blvd | [(-121.933956,37),(-121.9343,37.97)]                                                                                                                                                                                                                                                                                                                                                                                                         | Oakland
+ Welch Creek                   Road | [(-121.7695,37.386),(-121.7737,37.413)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Welch Creek                   Road | [(-121.7695,37.386),(-121.7737,37.413)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ West Loop                     Road | [(-122.0576,37.604),(-122.0602,37.586)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Western Pacific Railroad Spur      | [(-122.0394,37.018),(-122.0394,37.961)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Western Pacific Railroad Spur      | [(-122.0394,37.018),(-122.0394,37.961)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Western Pacific Railroad Spur      | [(-122.0394,37.018),(-122.0394,37.961)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ Whitlock Creek                     | [(-121.74683,37.91276),(-121.733107,37)]                                                                                                                                                                                                                                                                                                                                                                                                     | Oakland
+ Whitlock Creek                     | [(-121.74683,37.91276),(-121.733107,37)]                                                                                                                                                                                                                                                                                                                                                                                                     | Oakland
+ Willimet                      Way  | [(-122.0964,37.517),(-122.0949,37.493)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ Wisconsin                     St   | [(-122.1994,37.017),(-122.1975,37.998),(-122.1971,37.994)]                                                                                                                                                                                                                                                                                                                                                                                   | Oakland
+ Wisconsin                     St   | [(-122.1994,37.017),(-122.1975,37.998),(-122.1971,37.994)]                                                                                                                                                                                                                                                                                                                                                                                   | Berkeley
+ Wp Railroad                        | [(-122.254,37.902),(-122.2506,37.891)]                                                                                                                                                                                                                                                                                                                                                                                                       | Berkeley
+ 100th                         Ave  | [(-122.1657,37.429),(-122.1647,37.432)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ 107th                         Ave  | [(-122.1555,37.403),(-122.1531,37.41)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ 14th                          St   | [(-122.299,37.147),(-122.3,37.148)]                                                                                                                                                                                                                                                                                                                                                                                                          | Lafayette
+ 19th                          Ave  | [(-122.2366,37.897),(-122.2359,37.905)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ 1st                           St   | [(-121.75508,37.89294),(-121.753581,37.90031)]                                                                                                                                                                                                                                                                                                                                                                                               | Oakland
+ 5th                           St   | [(-122.278,37),(-122.2792,37.005),(-122.2803,37.009)]                                                                                                                                                                                                                                                                                                                                                                                        | Lafayette
+ 5th                           St   | [(-122.296,37.615),(-122.2953,37.598)]                                                                                                                                                                                                                                                                                                                                                                                                       | Berkeley
+ 82nd                          Ave  | [(-122.1695,37.596),(-122.1681,37.603)]                                                                                                                                                                                                                                                                                                                                                                                                      | Berkeley
+ 85th                          Ave  | [(-122.1877,37.466),(-122.186,37.476)]                                                                                                                                                                                                                                                                                                                                                                                                       | Oakland
+ 89th                          Ave  | [(-122.1822,37.459),(-122.1803,37.471)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ 98th                          Ave  | [(-122.1568,37.498),(-122.1558,37.502)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ 98th                          Ave  | [(-122.1693,37.438),(-122.1682,37.444)]                                                                                                                                                                                                                                                                                                                                                                                                      | Oakland
+ 98th                          Ave  | [(-122.2001,37.258),(-122.1974,37.27)]                                                                                                                                                                                                                                                                                                                                                                                                       | Lafayette
+(333 rows)
+
+SELECT name, #thepath FROM iexit ORDER BY name COLLATE "C", 2;
+                name                | ?column? 
+------------------------------------+----------
+ I- 580                             |        2
+ I- 580                             |        2
+ I- 580                             |        2
+ I- 580                             |        2
+ I- 580                             |        2
+ I- 580                             |        2
+ I- 580                             |        2
+ I- 580                             |        2
+ I- 580                             |        2
+ I- 580                             |        2
+ I- 580                             |        2
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        3
+ I- 580                             |        4
+ I- 580                             |        4
+ I- 580                             |        4
+ I- 580                             |        4
+ I- 580                             |        5
+ I- 580                             |        5
+ I- 580                             |        5
+ I- 580                             |        5
+ I- 580                             |        5
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        6
+ I- 580                             |        7
+ I- 580                             |        7
+ I- 580                             |        7
+ I- 580                             |        7
+ I- 580                             |        7
+ I- 580                             |        7
+ I- 580                             |        7
+ I- 580                             |        8
+ I- 580                             |        8
+ I- 580                             |        8
+ I- 580                             |        8
+ I- 580                             |        8
+ I- 580                             |        8
+ I- 580                             |        8
+ I- 580                             |        8
+ I- 580                             |        8
+ I- 580                             |        9
+ I- 580                             |        9
+ I- 580                             |        9
+ I- 580                             |        9
+ I- 580                             |        9
+ I- 580                             |       12
+ I- 580                             |       12
+ I- 580                             |       12
+ I- 580                             |       12
+ I- 580                             |       12
+ I- 580                             |       12
+ I- 580                             |       12
+ I- 580                             |       12
+ I- 580                             |       12
+ I- 580                             |       12
+ I- 580                             |       13
+ I- 580                             |       13
+ I- 580                             |       13
+ I- 580                             |       13
+ I- 580                             |       13
+ I- 580                             |       13
+ I- 580                             |       14
+ I- 580                             |       14
+ I- 580                             |       14
+ I- 580                             |       14
+ I- 580                             |       14
+ I- 580                             |       14
+ I- 580                             |       14
+ I- 580                             |       14
+ I- 580                             |       18
+ I- 580                             |       18
+ I- 580                             |       18
+ I- 580                             |       18
+ I- 580                             |       18
+ I- 580                             |       18
+ I- 580                             |       21
+ I- 580                             |       21
+ I- 580                             |       21
+ I- 580                             |       21
+ I- 580                             |       21
+ I- 580                             |       21
+ I- 580                             |       21
+ I- 580                             |       21
+ I- 580                             |       21
+ I- 580                             |       21
+ I- 580                             |       22
+ I- 580                             |       22
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        2
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        3
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        4
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        5
+ I- 580                        Ramp |        6
+ I- 580                        Ramp |        6
+ I- 580                        Ramp |        6
+ I- 580                        Ramp |        7
+ I- 580                        Ramp |        8
+ I- 580                        Ramp |        8
+ I- 580                        Ramp |        8
+ I- 580                        Ramp |        8
+ I- 580                        Ramp |        8
+ I- 580                        Ramp |        8
+ I- 580/I-680                  Ramp |        2
+ I- 580/I-680                  Ramp |        2
+ I- 580/I-680                  Ramp |        2
+ I- 580/I-680                  Ramp |        2
+ I- 580/I-680                  Ramp |        2
+ I- 580/I-680                  Ramp |        2
+ I- 580/I-680                  Ramp |        4
+ I- 580/I-680                  Ramp |        4
+ I- 580/I-680                  Ramp |        4
+ I- 580/I-680                  Ramp |        4
+ I- 580/I-680                  Ramp |        5
+ I- 580/I-680                  Ramp |        6
+ I- 580/I-680                  Ramp |        6
+ I- 580/I-680                  Ramp |        6
+ I- 680                             |        2
+ I- 680                             |        2
+ I- 680                             |        2
+ I- 680                             |        2
+ I- 680                             |        2
+ I- 680                             |        2
+ I- 680                             |        2
+ I- 680                             |        3
+ I- 680                             |        3
+ I- 680                             |        3
+ I- 680                             |        4
+ I- 680                             |        4
+ I- 680                             |        4
+ I- 680                             |        5
+ I- 680                             |        5
+ I- 680                             |        5
+ I- 680                             |        7
+ I- 680                             |        7
+ I- 680                             |        7
+ I- 680                             |        7
+ I- 680                             |        8
+ I- 680                             |        8
+ I- 680                             |        8
+ I- 680                             |        8
+ I- 680                             |       10
+ I- 680                             |       10
+ I- 680                             |       10
+ I- 680                             |       10
+ I- 680                             |       10
+ I- 680                             |       10
+ I- 680                             |       10
+ I- 680                             |       16
+ I- 680                             |       16
+ I- 680                             |       16
+ I- 680                             |       16
+ I- 680                             |       16
+ I- 680                             |       16
+ I- 680                             |       16
+ I- 680                             |       16
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        2
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        3
+ I- 680                        Ramp |        4
+ I- 680                        Ramp |        4
+ I- 680                        Ramp |        4
+ I- 680                        Ramp |        5
+ I- 680                        Ramp |        5
+ I- 680                        Ramp |        5
+ I- 680                        Ramp |        5
+ I- 680                        Ramp |        5
+ I- 680                        Ramp |        5
+ I- 680                        Ramp |        6
+ I- 680                        Ramp |        6
+ I- 680                        Ramp |        6
+ I- 680                        Ramp |        6
+ I- 680                        Ramp |        7
+ I- 680                        Ramp |        7
+ I- 680                        Ramp |        7
+ I- 680                        Ramp |        7
+ I- 680                        Ramp |        8
+ I- 680                        Ramp |        8
+ I- 680                        Ramp |        8
+ I- 680                        Ramp |        8
+ I- 80                              |        2
+ I- 80                              |        2
+ I- 80                              |        2
+ I- 80                              |        2
+ I- 80                              |        2
+ I- 80                              |        2
+ I- 80                              |        2
+ I- 80                              |        2
+ I- 80                              |        2
+ I- 80                              |        2
+ I- 80                              |        2
+ I- 80                              |        2
+ I- 80                              |        2
+ I- 80                              |        2
+ I- 80                              |        3
+ I- 80                              |        3
+ I- 80                              |        3
+ I- 80                              |        4
+ I- 80                              |        4
+ I- 80                              |        4
+ I- 80                              |        4
+ I- 80                              |        4
+ I- 80                              |        5
+ I- 80                              |        5
+ I- 80                              |        5
+ I- 80                              |        5
+ I- 80                              |        5
+ I- 80                              |        5
+ I- 80                              |        5
+ I- 80                              |        5
+ I- 80                              |        5
+ I- 80                              |       11
+ I- 80                              |       11
+ I- 80                              |       11
+ I- 80                              |       11
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        2
+ I- 80                         Ramp |        3
+ I- 80                         Ramp |        3
+ I- 80                         Ramp |        3
+ I- 80                         Ramp |        3
+ I- 80                         Ramp |        3
+ I- 80                         Ramp |        3
+ I- 80                         Ramp |        3
+ I- 80                         Ramp |        3
+ I- 80                         Ramp |        3
+ I- 80                         Ramp |        4
+ I- 80                         Ramp |        4
+ I- 80                         Ramp |        4
+ I- 80                         Ramp |        4
+ I- 80                         Ramp |        5
+ I- 80                         Ramp |        5
+ I- 80                         Ramp |        5
+ I- 80                         Ramp |        5
+ I- 80                         Ramp |        5
+ I- 80                         Ramp |        5
+ I- 80                         Ramp |        5
+ I- 80                         Ramp |        7
+ I- 80                         Ramp |        7
+ I- 80                         Ramp |        7
+ I- 80                         Ramp |        7
+ I- 880                             |        2
+ I- 880                             |        2
+ I- 880                             |        2
+ I- 880                             |        2
+ I- 880                             |        2
+ I- 880                             |        5
+ I- 880                             |        5
+ I- 880                             |        5
+ I- 880                             |        5
+ I- 880                             |        5
+ I- 880                             |        5
+ I- 880                             |        6
+ I- 880                             |        6
+ I- 880                             |        6
+ I- 880                             |        6
+ I- 880                             |        6
+ I- 880                             |        6
+ I- 880                             |        6
+ I- 880                             |        6
+ I- 880                             |        6
+ I- 880                             |        6
+ I- 880                             |        6
+ I- 880                             |        6
+ I- 880                             |        6
+ I- 880                             |        6
+ I- 880                             |        7
+ I- 880                             |        7
+ I- 880                             |        7
+ I- 880                             |        7
+ I- 880                             |        7
+ I- 880                             |        7
+ I- 880                             |        7
+ I- 880                             |        9
+ I- 880                             |        9
+ I- 880                             |        9
+ I- 880                             |        9
+ I- 880                             |        9
+ I- 880                             |        9
+ I- 880                             |        9
+ I- 880                             |       10
+ I- 880                             |       10
+ I- 880                             |       10
+ I- 880                             |       10
+ I- 880                             |       10
+ I- 880                             |       10
+ I- 880                             |       10
+ I- 880                             |       10
+ I- 880                             |       10
+ I- 880                             |       10
+ I- 880                             |       10
+ I- 880                             |       10
+ I- 880                             |       12
+ I- 880                             |       12
+ I- 880                             |       12
+ I- 880                             |       12
+ I- 880                             |       12
+ I- 880                             |       12
+ I- 880                             |       12
+ I- 880                             |       12
+ I- 880                             |       12
+ I- 880                             |       12
+ I- 880                             |       12
+ I- 880                             |       13
+ I- 880                             |       13
+ I- 880                             |       13
+ I- 880                             |       13
+ I- 880                             |       13
+ I- 880                             |       13
+ I- 880                             |       13
+ I- 880                             |       13
+ I- 880                             |       13
+ I- 880                             |       13
+ I- 880                             |       13
+ I- 880                             |       13
+ I- 880                             |       14
+ I- 880                             |       14
+ I- 880                             |       14
+ I- 880                             |       14
+ I- 880                             |       14
+ I- 880                             |       14
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       17
+ I- 880                             |       19
+ I- 880                             |       19
+ I- 880                             |       19
+ I- 880                             |       19
+ I- 880                             |       19
+ I- 880                             |       19
+ I- 880                             |       19
+ I- 880                             |       19
+ I- 880                             |       19
+ I- 880                             |       19
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        2
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        3
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        4
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        5
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        6
+ I- 880                        Ramp |        8
+ I- 880                        Ramp |        8
+ I- 880                        Ramp |        8
+ I- 980                             |        2
+ I- 980                             |        2
+ I- 980                             |        2
+ I- 980                             |        2
+ I- 980                             |        2
+ I- 980                             |        2
+ I- 980                             |        2
+ I- 980                             |        2
+ I- 980                             |        3
+ I- 980                             |        3
+ I- 980                             |        3
+ I- 980                             |        3
+ I- 980                             |        3
+ I- 980                             |        3
+ I- 980                             |        3
+ I- 980                             |        3
+ I- 980                             |        3
+ I- 980                             |        4
+ I- 980                             |        4
+ I- 980                             |        5
+ I- 980                             |        5
+ I- 980                             |        7
+ I- 980                             |        7
+ I- 980                             |        7
+ I- 980                             |        7
+ I- 980                             |       12
+ I- 980                        Ramp |        3
+ I- 980                        Ramp |        3
+ I- 980                        Ramp |        3
+ I- 980                        Ramp |        7
+(896 rows)
+
+SELECT * FROM toyemp WHERE name = 'sharon';
+  name  | age | location | annualsal 
+--------+-----+----------+-----------
+ sharon |  25 | (15,12)  |     12000
+(1 row)
+
+--
+-- Test for Leaky view scenario
+--
+CREATE ROLE regress_alice;
+CREATE FUNCTION f_leak (text)
+       RETURNS bool LANGUAGE 'plpgsql' COST 0.0000001
+       AS 'BEGIN RAISE NOTICE ''f_leak => %'', $1; RETURN true; END';
+CREATE TABLE customer (
+       cid      int primary key,
+       name     text not null,
+       tel      text,
+       passwd	text
+);
+CREATE TABLE credit_card (
+       cid      int references customer(cid),
+       cnum     text,
+       climit   int
+);
+CREATE TABLE credit_usage (
+       cid      int references customer(cid),
+       ymd      date,
+       usage    int
+);
+INSERT INTO customer
+       VALUES (101, 'regress_alice', '+81-12-3456-7890', 'passwd123'),
+              (102, 'regress_bob',   '+01-234-567-8901', 'beafsteak'),
+              (103, 'regress_eve',   '+49-8765-43210',   'hamburger');
+INSERT INTO credit_card
+       VALUES (101, '1111-2222-3333-4444', 4000),
+              (102, '5555-6666-7777-8888', 3000),
+              (103, '9801-2345-6789-0123', 2000);
+INSERT INTO credit_usage
+       VALUES (101, '2011-09-15', 120),
+	      (101, '2011-10-05',  90),
+	      (101, '2011-10-18', 110),
+	      (101, '2011-10-21', 200),
+	      (101, '2011-11-10',  80),
+	      (102, '2011-09-22', 300),
+	      (102, '2011-10-12', 120),
+	      (102, '2011-10-28', 200),
+	      (103, '2011-10-15', 480);
+CREATE VIEW my_property_normal AS
+       SELECT * FROM customer WHERE name = current_user;
+CREATE VIEW my_property_secure WITH (security_barrier) AS
+       SELECT * FROM customer WHERE name = current_user;
+CREATE VIEW my_credit_card_normal AS
+       SELECT * FROM customer l NATURAL JOIN credit_card r
+       WHERE l.name = current_user;
+CREATE VIEW my_credit_card_secure WITH (security_barrier) AS
+       SELECT * FROM customer l NATURAL JOIN credit_card r
+       WHERE l.name = current_user;
+CREATE VIEW my_credit_card_usage_normal AS
+       SELECT * FROM my_credit_card_secure l NATURAL JOIN credit_usage r;
+CREATE VIEW my_credit_card_usage_secure WITH (security_barrier) AS
+       SELECT * FROM my_credit_card_secure l NATURAL JOIN credit_usage r;
+GRANT SELECT ON my_property_normal TO public;
+GRANT SELECT ON my_property_secure TO public;
+GRANT SELECT ON my_credit_card_normal TO public;
+GRANT SELECT ON my_credit_card_secure TO public;
+GRANT SELECT ON my_credit_card_usage_normal TO public;
+GRANT SELECT ON my_credit_card_usage_secure TO public;
+--
+-- Run leaky view scenarios
+--
+SET SESSION AUTHORIZATION regress_alice;
+--
+-- scenario: if a qualifier with tiny-cost is given, it shall be launched
+--           prior to the security policy of the view.
+--
+SELECT * FROM my_property_normal WHERE f_leak(passwd);
+NOTICE:  f_leak => passwd123
+NOTICE:  f_leak => beafsteak
+NOTICE:  f_leak => hamburger
+ cid |     name      |       tel        |  passwd   
+-----+---------------+------------------+-----------
+ 101 | regress_alice | +81-12-3456-7890 | passwd123
+(1 row)
+
+EXPLAIN (COSTS OFF) SELECT * FROM my_property_normal WHERE f_leak(passwd);
+                      QUERY PLAN                      
+------------------------------------------------------
+ Seq Scan on customer
+   Filter: (f_leak(passwd) AND (name = CURRENT_USER))
+(2 rows)
+
+SELECT * FROM my_property_secure WHERE f_leak(passwd);
+NOTICE:  f_leak => passwd123
+ cid |     name      |       tel        |  passwd   
+-----+---------------+------------------+-----------
+ 101 | regress_alice | +81-12-3456-7890 | passwd123
+(1 row)
+
+EXPLAIN (COSTS OFF) SELECT * FROM my_property_secure WHERE f_leak(passwd);
+                 QUERY PLAN                  
+---------------------------------------------
+ Subquery Scan on my_property_secure
+   Filter: f_leak(my_property_secure.passwd)
+   ->  Seq Scan on customer
+         Filter: (name = CURRENT_USER)
+(4 rows)
+
+--
+-- scenario: qualifiers can be pushed down if they contain leaky functions,
+--           provided they aren't passed data from inside the view.
+--
+SELECT * FROM my_property_normal v
+		WHERE f_leak('passwd') AND f_leak(passwd);
+NOTICE:  f_leak => passwd
+NOTICE:  f_leak => passwd123
+NOTICE:  f_leak => passwd
+NOTICE:  f_leak => beafsteak
+NOTICE:  f_leak => passwd
+NOTICE:  f_leak => hamburger
+ cid |     name      |       tel        |  passwd   
+-----+---------------+------------------+-----------
+ 101 | regress_alice | +81-12-3456-7890 | passwd123
+(1 row)
+
+EXPLAIN (COSTS OFF) SELECT * FROM my_property_normal v
+		WHERE f_leak('passwd') AND f_leak(passwd);
+                                   QUERY PLAN                                    
+---------------------------------------------------------------------------------
+ Seq Scan on customer
+   Filter: (f_leak('passwd'::text) AND f_leak(passwd) AND (name = CURRENT_USER))
+(2 rows)
+
+SELECT * FROM my_property_secure v
+		WHERE f_leak('passwd') AND f_leak(passwd);
+NOTICE:  f_leak => passwd
+NOTICE:  f_leak => passwd123
+NOTICE:  f_leak => passwd
+NOTICE:  f_leak => passwd
+ cid |     name      |       tel        |  passwd   
+-----+---------------+------------------+-----------
+ 101 | regress_alice | +81-12-3456-7890 | passwd123
+(1 row)
+
+EXPLAIN (COSTS OFF) SELECT * FROM my_property_secure v
+		WHERE f_leak('passwd') AND f_leak(passwd);
+                             QUERY PLAN                             
+--------------------------------------------------------------------
+ Subquery Scan on v
+   Filter: f_leak(v.passwd)
+   ->  Seq Scan on customer
+         Filter: (f_leak('passwd'::text) AND (name = CURRENT_USER))
+(4 rows)
+
+--
+-- scenario: if a qualifier references only one-side of a particular join-
+--           tree, it shall be distributed to the most deep scan plan as
+--           possible as we can.
+--
+SELECT * FROM my_credit_card_normal WHERE f_leak(cnum);
+NOTICE:  f_leak => 1111-2222-3333-4444
+NOTICE:  f_leak => 5555-6666-7777-8888
+NOTICE:  f_leak => 9801-2345-6789-0123
+ cid |     name      |       tel        |  passwd   |        cnum         | climit 
+-----+---------------+------------------+-----------+---------------------+--------
+ 101 | regress_alice | +81-12-3456-7890 | passwd123 | 1111-2222-3333-4444 |   4000
+(1 row)
+
+EXPLAIN (COSTS OFF) SELECT * FROM my_credit_card_normal WHERE f_leak(cnum);
+                 QUERY PLAN                  
+---------------------------------------------
+ Hash Join
+   Hash Cond: (r.cid = l.cid)
+   ->  Seq Scan on credit_card r
+         Filter: f_leak(cnum)
+   ->  Hash
+         ->  Seq Scan on customer l
+               Filter: (name = CURRENT_USER)
+(7 rows)
+
+SELECT * FROM my_credit_card_secure WHERE f_leak(cnum);
+NOTICE:  f_leak => 1111-2222-3333-4444
+ cid |     name      |       tel        |  passwd   |        cnum         | climit 
+-----+---------------+------------------+-----------+---------------------+--------
+ 101 | regress_alice | +81-12-3456-7890 | passwd123 | 1111-2222-3333-4444 |   4000
+(1 row)
+
+EXPLAIN (COSTS OFF) SELECT * FROM my_credit_card_secure WHERE f_leak(cnum);
+                    QUERY PLAN                     
+---------------------------------------------------
+ Subquery Scan on my_credit_card_secure
+   Filter: f_leak(my_credit_card_secure.cnum)
+   ->  Hash Join
+         Hash Cond: (r.cid = l.cid)
+         ->  Seq Scan on credit_card r
+         ->  Hash
+               ->  Seq Scan on customer l
+                     Filter: (name = CURRENT_USER)
+(8 rows)
+
+--
+-- scenario: an external qualifier can be pushed-down by in-front-of the
+--           views with "security_barrier" attribute, except for operators
+--           implemented with leakproof functions.
+--
+SELECT * FROM my_credit_card_usage_normal
+       WHERE f_leak(cnum) AND ymd >= '2011-10-01' AND ymd < '2011-11-01';
+NOTICE:  f_leak => 1111-2222-3333-4444
+ cid |     name      |       tel        |  passwd   |        cnum         | climit |    ymd     | usage 
+-----+---------------+------------------+-----------+---------------------+--------+------------+-------
+ 101 | regress_alice | +81-12-3456-7890 | passwd123 | 1111-2222-3333-4444 |   4000 | 10-05-2011 |    90
+ 101 | regress_alice | +81-12-3456-7890 | passwd123 | 1111-2222-3333-4444 |   4000 | 10-18-2011 |   110
+ 101 | regress_alice | +81-12-3456-7890 | passwd123 | 1111-2222-3333-4444 |   4000 | 10-21-2011 |   200
+(3 rows)
+
+EXPLAIN (COSTS OFF) SELECT * FROM my_credit_card_usage_normal
+       WHERE f_leak(cnum) AND ymd >= '2011-10-01' AND ymd < '2011-11-01';
+                                  QUERY PLAN                                  
+------------------------------------------------------------------------------
+ Nested Loop
+   Join Filter: (l.cid = r.cid)
+   ->  Seq Scan on credit_usage r
+         Filter: ((ymd >= '10-01-2011'::date) AND (ymd < '11-01-2011'::date))
+   ->  Materialize
+         ->  Subquery Scan on l
+               Filter: f_leak(l.cnum)
+               ->  Hash Join
+                     Hash Cond: (r_1.cid = l_1.cid)
+                     ->  Seq Scan on credit_card r_1
+                     ->  Hash
+                           ->  Seq Scan on customer l_1
+                                 Filter: (name = CURRENT_USER)
+(13 rows)
+
+SELECT * FROM my_credit_card_usage_secure
+       WHERE f_leak(cnum) AND ymd >= '2011-10-01' AND ymd < '2011-11-01';
+NOTICE:  f_leak => 1111-2222-3333-4444
+NOTICE:  f_leak => 1111-2222-3333-4444
+NOTICE:  f_leak => 1111-2222-3333-4444
+ cid |     name      |       tel        |  passwd   |        cnum         | climit |    ymd     | usage 
+-----+---------------+------------------+-----------+---------------------+--------+------------+-------
+ 101 | regress_alice | +81-12-3456-7890 | passwd123 | 1111-2222-3333-4444 |   4000 | 10-05-2011 |    90
+ 101 | regress_alice | +81-12-3456-7890 | passwd123 | 1111-2222-3333-4444 |   4000 | 10-18-2011 |   110
+ 101 | regress_alice | +81-12-3456-7890 | passwd123 | 1111-2222-3333-4444 |   4000 | 10-21-2011 |   200
+(3 rows)
+
+EXPLAIN (COSTS OFF) SELECT * FROM my_credit_card_usage_secure
+       WHERE f_leak(cnum) AND ymd >= '2011-10-01' AND ymd < '2011-11-01';
+                                     QUERY PLAN                                     
+------------------------------------------------------------------------------------
+ Subquery Scan on my_credit_card_usage_secure
+   Filter: f_leak(my_credit_card_usage_secure.cnum)
+   ->  Hash Join
+         Hash Cond: (r.cid = l.cid)
+         ->  Seq Scan on credit_usage r
+               Filter: ((ymd >= '10-01-2011'::date) AND (ymd < '11-01-2011'::date))
+         ->  Hash
+               ->  Hash Join
+                     Hash Cond: (r_1.cid = l.cid)
+                     ->  Seq Scan on credit_card r_1
+                     ->  Hash
+                           ->  Seq Scan on customer l
+                                 Filter: (name = CURRENT_USER)
+(13 rows)
+
+--
+-- Test for the case when security_barrier gets changed between rewriter
+-- and planner stage.
+--
+PREPARE p1 AS SELECT * FROM my_property_normal WHERE f_leak(passwd);
+PREPARE p2 AS SELECT * FROM my_property_secure WHERE f_leak(passwd);
+EXECUTE p1;
+NOTICE:  f_leak => passwd123
+NOTICE:  f_leak => beafsteak
+NOTICE:  f_leak => hamburger
+ cid |     name      |       tel        |  passwd   
+-----+---------------+------------------+-----------
+ 101 | regress_alice | +81-12-3456-7890 | passwd123
+(1 row)
+
+EXECUTE p2;
+NOTICE:  f_leak => passwd123
+ cid |     name      |       tel        |  passwd   
+-----+---------------+------------------+-----------
+ 101 | regress_alice | +81-12-3456-7890 | passwd123
+(1 row)
+
+RESET SESSION AUTHORIZATION;
+ALTER VIEW my_property_normal SET (security_barrier=true);
+ALTER VIEW my_property_secure SET (security_barrier=false);
+SET SESSION AUTHORIZATION regress_alice;
+EXECUTE p1;		-- To be perform as a view with security-barrier
+NOTICE:  f_leak => passwd123
+ cid |     name      |       tel        |  passwd   
+-----+---------------+------------------+-----------
+ 101 | regress_alice | +81-12-3456-7890 | passwd123
+(1 row)
+
+EXECUTE p2;		-- To be perform as a view without security-barrier
+NOTICE:  f_leak => passwd123
+NOTICE:  f_leak => beafsteak
+NOTICE:  f_leak => hamburger
+ cid |     name      |       tel        |  passwd   
+-----+---------------+------------------+-----------
+ 101 | regress_alice | +81-12-3456-7890 | passwd123
+(1 row)
+
+-- Cleanup.
+RESET SESSION AUTHORIZATION;
+DROP ROLE regress_alice;
diff --git a/src/test/regress/expected/stats_1.out b/src/test/regress/expected/stats_1.out
new file mode 100644
index 0000000..5a6c5c7
--- /dev/null
+++ b/src/test/regress/expected/stats_1.out
@@ -0,0 +1,231 @@
+--
+-- Test Statistics Collector
+--
+-- Must be run after tenk2 has been created (by create_table),
+-- populated (by create_misc) and indexed (by create_index).
+--
+-- conditio sine qua non
+SHOW track_counts;  -- must be on
+ track_counts 
+--------------
+ on
+(1 row)
+
+-- ensure that both seqscan and indexscan plans are allowed
+SET enable_seqscan TO on;
+SET enable_indexscan TO on;
+-- for the moment, we don't want index-only scans here
+SET enable_indexonlyscan TO off;
+-- save counters
+CREATE TABLE prevstats AS
+SELECT t.seq_scan, t.seq_tup_read, t.idx_scan, t.idx_tup_fetch,
+       (b.heap_blks_read + b.heap_blks_hit) AS heap_blks,
+       (b.idx_blks_read + b.idx_blks_hit) AS idx_blks,
+       pg_stat_get_snapshot_timestamp() as snap_ts
+  FROM pg_catalog.pg_stat_user_tables AS t,
+       pg_catalog.pg_statio_user_tables AS b
+ WHERE t.relname='tenk2' AND b.relname='tenk2';
+-- function to wait for counters to advance
+create function wait_for_stats() returns void as $$
+declare
+  start_time timestamptz := clock_timestamp();
+  updated1 bool;
+  updated2 bool;
+  updated3 bool;
+  updated4 bool;
+begin
+  -- we don't want to wait forever; loop will exit after 30 seconds
+  for i in 1 .. 300 loop
+
+    -- With parallel query, the seqscan and indexscan on tenk2 might be done
+    -- in parallel worker processes, which will send their stats counters
+    -- asynchronously to what our own session does.  So we must check for
+    -- those counts to be registered separately from the update counts.
+
+    -- check to see if seqscan has been sensed
+    SELECT (st.seq_scan >= pr.seq_scan + 1) INTO updated1
+      FROM pg_stat_user_tables AS st, pg_class AS cl, prevstats AS pr
+     WHERE st.relname='tenk2' AND cl.relname='tenk2';
+
+    -- check to see if indexscan has been sensed
+    SELECT (st.idx_scan >= pr.idx_scan + 1) INTO updated2
+      FROM pg_stat_user_tables AS st, pg_class AS cl, prevstats AS pr
+     WHERE st.relname='tenk2' AND cl.relname='tenk2';
+
+    -- check to see if all updates have been sensed
+    SELECT (n_tup_ins > 0) INTO updated3
+      FROM pg_stat_user_tables WHERE relname='trunc_stats_test4';
+
+    -- We must also check explicitly that pg_stat_get_snapshot_timestamp has
+    -- advanced, because that comes from the global stats file which might
+    -- be older than the per-DB stats file we got the other values from.
+    SELECT (pr.snap_ts < pg_stat_get_snapshot_timestamp()) INTO updated4
+      FROM prevstats AS pr;
+
+    exit when updated1 and updated2 and updated3 and updated4;
+
+    -- wait a little
+    perform pg_sleep_for('100 milliseconds');
+
+    -- reset stats snapshot so we can test again
+    perform pg_stat_clear_snapshot();
+
+  end loop;
+
+  -- report time waited in postmaster log (where it won't change test output)
+  raise log 'wait_for_stats delayed % seconds',
+    extract(epoch from clock_timestamp() - start_time);
+end
+$$ language plpgsql;
+-- test effects of TRUNCATE on n_live_tup/n_dead_tup counters
+CREATE TABLE trunc_stats_test(id serial);
+CREATE TABLE trunc_stats_test1(id serial, stuff text);
+CREATE TABLE trunc_stats_test2(id serial);
+CREATE TABLE trunc_stats_test3(id serial, stuff text);
+CREATE TABLE trunc_stats_test4(id serial);
+-- check that n_live_tup is reset to 0 after truncate
+INSERT INTO trunc_stats_test DEFAULT VALUES;
+INSERT INTO trunc_stats_test DEFAULT VALUES;
+INSERT INTO trunc_stats_test DEFAULT VALUES;
+TRUNCATE trunc_stats_test;
+-- test involving a truncate in a transaction; 4 ins but only 1 live
+INSERT INTO trunc_stats_test1 DEFAULT VALUES;
+INSERT INTO trunc_stats_test1 DEFAULT VALUES;
+INSERT INTO trunc_stats_test1 DEFAULT VALUES;
+UPDATE trunc_stats_test1 SET id = id + 10 WHERE id IN (1, 2);
+DELETE FROM trunc_stats_test1 WHERE id = 3;
+BEGIN;
+UPDATE trunc_stats_test1 SET id = id + 100;
+TRUNCATE trunc_stats_test1;
+INSERT INTO trunc_stats_test1 DEFAULT VALUES;
+COMMIT;
+-- use a savepoint: 1 insert, 1 live
+BEGIN;
+INSERT INTO trunc_stats_test2 DEFAULT VALUES;
+INSERT INTO trunc_stats_test2 DEFAULT VALUES;
+SAVEPOINT p1;
+INSERT INTO trunc_stats_test2 DEFAULT VALUES;
+TRUNCATE trunc_stats_test2;
+INSERT INTO trunc_stats_test2 DEFAULT VALUES;
+RELEASE SAVEPOINT p1;
+COMMIT;
+-- rollback a savepoint: this should count 4 inserts and have 2
+-- live tuples after commit (and 2 dead ones due to aborted subxact)
+BEGIN;
+INSERT INTO trunc_stats_test3 DEFAULT VALUES;
+INSERT INTO trunc_stats_test3 DEFAULT VALUES;
+SAVEPOINT p1;
+INSERT INTO trunc_stats_test3 DEFAULT VALUES;
+INSERT INTO trunc_stats_test3 DEFAULT VALUES;
+TRUNCATE trunc_stats_test3;
+INSERT INTO trunc_stats_test3 DEFAULT VALUES;
+ROLLBACK TO SAVEPOINT p1;
+COMMIT;
+-- rollback a truncate: this should count 2 inserts and produce 2 dead tuples
+BEGIN;
+INSERT INTO trunc_stats_test4 DEFAULT VALUES;
+INSERT INTO trunc_stats_test4 DEFAULT VALUES;
+TRUNCATE trunc_stats_test4;
+INSERT INTO trunc_stats_test4 DEFAULT VALUES;
+ROLLBACK;
+-- do a seqscan
+SELECT count(*) FROM tenk2;
+ count 
+-------
+ 10000
+(1 row)
+
+-- do an indexscan
+-- make sure it is not a bitmap scan, which might skip fetching heap tuples
+SET enable_bitmapscan TO off;
+SELECT count(*) FROM tenk2 WHERE unique1 = 1;
+ count 
+-------
+     1
+(1 row)
+
+RESET enable_bitmapscan;
+-- We can't just call wait_for_stats() at this point, because we only
+-- transmit stats when the session goes idle, and we probably didn't
+-- transmit the last couple of counts yet thanks to the rate-limiting logic
+-- in pgstat_report_stat().  But instead of waiting for the rate limiter's
+-- timeout to elapse, let's just start a new session.  The old one will
+-- then send its stats before dying.
+\c -
+-- wait for stats collector to update
+SELECT wait_for_stats();
+ wait_for_stats 
+----------------
+ 
+(1 row)
+
+-- check effects
+SELECT relname, n_tup_ins, n_tup_upd, n_tup_del, n_live_tup, n_dead_tup
+  FROM pg_stat_user_tables
+ WHERE relname like 'trunc_stats_test%' order by relname;
+      relname      | n_tup_ins | n_tup_upd | n_tup_del | n_live_tup | n_dead_tup 
+-------------------+-----------+-----------+-----------+------------+------------
+ trunc_stats_test  |         3 |         0 |         0 |          0 |          0
+ trunc_stats_test1 |         4 |         2 |         1 |          1 |          0
+ trunc_stats_test2 |         1 |         0 |         0 |          1 |          0
+ trunc_stats_test3 |         4 |         0 |         0 |          2 |          2
+ trunc_stats_test4 |         2 |         0 |         0 |          0 |          2
+(5 rows)
+
+SELECT st.seq_scan >= pr.seq_scan + 1,
+       st.seq_tup_read >= pr.seq_tup_read + cl.reltuples,
+       st.idx_scan >= pr.idx_scan + 1,
+       st.idx_tup_fetch >= pr.idx_tup_fetch + 1
+  FROM pg_stat_user_tables AS st, pg_class AS cl, prevstats AS pr
+ WHERE st.relname='tenk2' AND cl.relname='tenk2';
+ ?column? | ?column? | ?column? | ?column? 
+----------+----------+----------+----------
+ t        | t        | t        | t
+(1 row)
+
+SELECT st.heap_blks_read + st.heap_blks_hit >= pr.heap_blks + cl.relpages,
+       st.idx_blks_read + st.idx_blks_hit >= pr.idx_blks + 1
+  FROM pg_statio_user_tables AS st, pg_class AS cl, prevstats AS pr
+ WHERE st.relname='tenk2' AND cl.relname='tenk2';
+ ?column? | ?column? 
+----------+----------
+ t        | t
+(1 row)
+
+SELECT pr.snap_ts < pg_stat_get_snapshot_timestamp() as snapshot_newer
+FROM prevstats AS pr;
+ snapshot_newer 
+----------------
+ t
+(1 row)
+
+-- Temporary hack to investigate whether extra vacuum/analyze is happening
+select relname, relpages, reltuples
+from pg_class
+where relname like '__star' order by relname;
+ relname | relpages | reltuples 
+---------+----------+-----------
+ a_star  |        2 |         3
+ b_star  |        2 |         4
+ c_star  |        2 |         4
+ d_star  |        2 |        16
+ e_star  |        2 |         7
+ f_star  |        2 |        16
+(6 rows)
+
+select relname, vacuum_count, analyze_count, autovacuum_count, autoanalyze_count
+from pg_stat_all_tables
+where relname like '__star' order by relname;
+ relname | vacuum_count | analyze_count | autovacuum_count | autoanalyze_count 
+---------+--------------+---------------+------------------+-------------------
+ a_star  |            1 |             0 |                0 |                 0
+ b_star  |            1 |             0 |                0 |                 0
+ c_star  |            1 |             0 |                0 |                 0
+ d_star  |            1 |             0 |                0 |                 0
+ e_star  |            1 |             0 |                0 |                 0
+ f_star  |            1 |             0 |                0 |                 0
+(6 rows)
+
+DROP TABLE trunc_stats_test, trunc_stats_test1, trunc_stats_test2, trunc_stats_test3, trunc_stats_test4;
+DROP TABLE prevstats;
+-- End of Stats Test
diff --git a/src/test/regress/expected/strings_1.out b/src/test/regress/expected/strings_1.out
new file mode 100644
index 0000000..1df4460
--- /dev/null
+++ b/src/test/regress/expected/strings_1.out
@@ -0,0 +1,1823 @@
+--
+-- STRINGS
+-- Test various data entry syntaxes.
+--
+-- SQL string continuation syntax
+-- E021-03 character string literals
+SELECT 'first line'
+' - next line'
+	' - third line'
+	AS "Three lines to one";
+         Three lines to one          
+-------------------------------------
+ first line - next line - third line
+(1 row)
+
+-- illegal string continuation syntax
+SELECT 'first line'
+' - next line' /* this comment is not allowed here */
+' - third line'
+	AS "Illegal comment within continuation";
+ERROR:  syntax error at or near "' - third line'"
+LINE 3: ' - third line'
+        ^
+-- Unicode escapes
+SET standard_conforming_strings TO on;
+SELECT U&'d\0061t\+000061' AS U&"d\0061t\+000061";
+ data 
+------
+ data
+(1 row)
+
+SELECT U&'d!0061t\+000061' UESCAPE '!' AS U&"d*0061t\+000061" UESCAPE '*';
+ dat\+000061 
+-------------
+ dat\+000061
+(1 row)
+
+SELECT U&' \' UESCAPE '!' AS "tricky";
+ tricky 
+--------
+  \
+(1 row)
+
+SELECT 'tricky' AS U&"\" UESCAPE '!';
+   \    
+--------
+ tricky
+(1 row)
+
+SELECT U&'wrong: \061';
+ERROR:  invalid Unicode escape value at or near "\061'"
+LINE 1: SELECT U&'wrong: \061';
+                         ^
+SELECT U&'wrong: \+0061';
+ERROR:  invalid Unicode escape value at or near "\+0061'"
+LINE 1: SELECT U&'wrong: \+0061';
+                         ^
+SELECT U&'wrong: +0061' UESCAPE '+';
+ERROR:  invalid Unicode escape character at or near "+'"
+LINE 1: SELECT U&'wrong: +0061' UESCAPE '+';
+                                         ^
+SET standard_conforming_strings TO off;
+SELECT U&'d\0061t\+000061' AS U&"d\0061t\+000061";
+ERROR:  unsafe use of string constant with Unicode escapes
+LINE 1: SELECT U&'d\0061t\+000061' AS U&"d\0061t\+000061";
+               ^
+DETAIL:  String constants with Unicode escapes cannot be used when standard_conforming_strings is off.
+SELECT U&'d!0061t\+000061' UESCAPE '!' AS U&"d*0061t\+000061" UESCAPE '*';
+ERROR:  unsafe use of string constant with Unicode escapes
+LINE 1: SELECT U&'d!0061t\+000061' UESCAPE '!' AS U&"d*0061t\+000061...
+               ^
+DETAIL:  String constants with Unicode escapes cannot be used when standard_conforming_strings is off.
+SELECT U&' \' UESCAPE '!' AS "tricky";
+ERROR:  unsafe use of string constant with Unicode escapes
+LINE 1: SELECT U&' \' UESCAPE '!' AS "tricky";
+               ^
+DETAIL:  String constants with Unicode escapes cannot be used when standard_conforming_strings is off.
+SELECT 'tricky' AS U&"\" UESCAPE '!';
+   \    
+--------
+ tricky
+(1 row)
+
+SELECT U&'wrong: \061';
+ERROR:  unsafe use of string constant with Unicode escapes
+LINE 1: SELECT U&'wrong: \061';
+               ^
+DETAIL:  String constants with Unicode escapes cannot be used when standard_conforming_strings is off.
+SELECT U&'wrong: \+0061';
+ERROR:  unsafe use of string constant with Unicode escapes
+LINE 1: SELECT U&'wrong: \+0061';
+               ^
+DETAIL:  String constants with Unicode escapes cannot be used when standard_conforming_strings is off.
+SELECT U&'wrong: +0061' UESCAPE '+';
+ERROR:  unsafe use of string constant with Unicode escapes
+LINE 1: SELECT U&'wrong: +0061' UESCAPE '+';
+               ^
+DETAIL:  String constants with Unicode escapes cannot be used when standard_conforming_strings is off.
+RESET standard_conforming_strings;
+-- bytea
+SET bytea_output TO hex;
+SELECT E'\\xDeAdBeEf'::bytea;
+   bytea    
+------------
+ \xdeadbeef
+(1 row)
+
+SELECT E'\\x De Ad Be Ef '::bytea;
+   bytea    
+------------
+ \xdeadbeef
+(1 row)
+
+SELECT E'\\xDeAdBeE'::bytea;
+ERROR:  invalid hexadecimal data: odd number of digits
+LINE 1: SELECT E'\\xDeAdBeE'::bytea;
+               ^
+SELECT E'\\xDeAdBeEx'::bytea;
+ERROR:  invalid hexadecimal digit: "x"
+LINE 1: SELECT E'\\xDeAdBeEx'::bytea;
+               ^
+SELECT E'\\xDe00BeEf'::bytea;
+   bytea    
+------------
+ \xde00beef
+(1 row)
+
+SELECT E'DeAdBeEf'::bytea;
+       bytea        
+--------------------
+ \x4465416442654566
+(1 row)
+
+SELECT E'De\\000dBeEf'::bytea;
+       bytea        
+--------------------
+ \x4465006442654566
+(1 row)
+
+SELECT E'De\123dBeEf'::bytea;
+       bytea        
+--------------------
+ \x4465536442654566
+(1 row)
+
+SELECT E'De\\123dBeEf'::bytea;
+       bytea        
+--------------------
+ \x4465536442654566
+(1 row)
+
+SELECT E'De\\678dBeEf'::bytea;
+ERROR:  invalid input syntax for type bytea
+LINE 1: SELECT E'De\\678dBeEf'::bytea;
+               ^
+SET bytea_output TO escape;
+SELECT E'\\xDeAdBeEf'::bytea;
+      bytea       
+------------------
+ \336\255\276\357
+(1 row)
+
+SELECT E'\\x De Ad Be Ef '::bytea;
+      bytea       
+------------------
+ \336\255\276\357
+(1 row)
+
+SELECT E'\\xDe00BeEf'::bytea;
+      bytea       
+------------------
+ \336\000\276\357
+(1 row)
+
+SELECT E'DeAdBeEf'::bytea;
+  bytea   
+----------
+ DeAdBeEf
+(1 row)
+
+SELECT E'De\\000dBeEf'::bytea;
+    bytea    
+-------------
+ De\000dBeEf
+(1 row)
+
+SELECT E'De\\123dBeEf'::bytea;
+  bytea   
+----------
+ DeSdBeEf
+(1 row)
+
+--
+-- test conversions between various string types
+-- E021-10 implicit casting among the character data types
+--
+SELECT CAST(f1 AS text) AS "text(char)" FROM CHAR_TBL;
+ text(char) 
+------------
+ a
+ ab
+ abcd
+ abcd
+(4 rows)
+
+SELECT CAST(f1 AS text) AS "text(varchar)" FROM VARCHAR_TBL;
+ text(varchar) 
+---------------
+ a
+ ab
+ abcd
+ abcd
+(4 rows)
+
+SELECT CAST(name 'namefield' AS text) AS "text(name)";
+ text(name) 
+------------
+ namefield
+(1 row)
+
+-- since this is an explicit cast, it should truncate w/o error:
+SELECT CAST(f1 AS char(10)) AS "char(text)" FROM TEXT_TBL;
+ char(text) 
+------------
+ doh!      
+ hi de ho n
+(2 rows)
+
+-- note: implicit-cast case is tested in char.sql
+SELECT CAST(f1 AS char(20)) AS "char(text)" FROM TEXT_TBL;
+      char(text)      
+----------------------
+ doh!                
+ hi de ho neighbor   
+(2 rows)
+
+SELECT CAST(f1 AS char(10)) AS "char(varchar)" FROM VARCHAR_TBL;
+ char(varchar) 
+---------------
+ a         
+ ab        
+ abcd      
+ abcd      
+(4 rows)
+
+SELECT CAST(name 'namefield' AS char(10)) AS "char(name)";
+ char(name) 
+------------
+ namefield 
+(1 row)
+
+SELECT CAST(f1 AS varchar) AS "varchar(text)" FROM TEXT_TBL;
+   varchar(text)   
+-------------------
+ doh!
+ hi de ho neighbor
+(2 rows)
+
+SELECT CAST(f1 AS varchar) AS "varchar(char)" FROM CHAR_TBL;
+ varchar(char) 
+---------------
+ a
+ ab
+ abcd
+ abcd
+(4 rows)
+
+SELECT CAST(name 'namefield' AS varchar) AS "varchar(name)";
+ varchar(name) 
+---------------
+ namefield
+(1 row)
+
+--
+-- test SQL string functions
+-- E### and T### are feature reference numbers from SQL99
+--
+-- E021-09 trim function
+SELECT TRIM(BOTH FROM '  bunch o blanks  ') = 'bunch o blanks' AS "bunch o blanks";
+ bunch o blanks 
+----------------
+ t
+(1 row)
+
+SELECT TRIM(LEADING FROM '  bunch o blanks  ') = 'bunch o blanks  ' AS "bunch o blanks  ";
+ bunch o blanks   
+------------------
+ t
+(1 row)
+
+SELECT TRIM(TRAILING FROM '  bunch o blanks  ') = '  bunch o blanks' AS "  bunch o blanks";
+   bunch o blanks 
+------------------
+ t
+(1 row)
+
+SELECT TRIM(BOTH 'x' FROM 'xxxxxsome Xsxxxxx') = 'some Xs' AS "some Xs";
+ some Xs 
+---------
+ t
+(1 row)
+
+-- E021-06 substring expression
+SELECT SUBSTRING('1234567890' FROM 3) = '34567890' AS "34567890";
+ 34567890 
+----------
+ t
+(1 row)
+
+SELECT SUBSTRING('1234567890' FROM 4 FOR 3) = '456' AS "456";
+ 456 
+-----
+ t
+(1 row)
+
+-- T581 regular expression substring (with SQL's bizarre regexp syntax)
+SELECT SUBSTRING('abcdefg' FROM 'a#"(b_d)#"%' FOR '#') AS "bcd";
+ bcd 
+-----
+ bcd
+(1 row)
+
+-- No match should return NULL
+SELECT SUBSTRING('abcdefg' FROM '#"(b_d)#"%' FOR '#') IS NULL AS "True";
+ True 
+------
+ t
+(1 row)
+
+-- Null inputs should return NULL
+SELECT SUBSTRING('abcdefg' FROM '%' FOR NULL) IS NULL AS "True";
+ True 
+------
+ t
+(1 row)
+
+SELECT SUBSTRING(NULL FROM '%' FOR '#') IS NULL AS "True";
+ True 
+------
+ t
+(1 row)
+
+SELECT SUBSTRING('abcdefg' FROM NULL FOR '#') IS NULL AS "True";
+ True 
+------
+ t
+(1 row)
+
+-- The first and last parts should act non-greedy
+SELECT SUBSTRING('abcdefg' FROM 'a#"%#"g' FOR '#') AS "bcdef";
+ bcdef 
+-------
+ bcdef
+(1 row)
+
+SELECT SUBSTRING('abcdefg' FROM 'a*#"%#"g*' FOR '#') AS "abcdefg";
+ abcdefg 
+---------
+ abcdefg
+(1 row)
+
+-- Vertical bar in any part affects only that part
+SELECT SUBSTRING('abcdefg' FROM 'a|b#"%#"g' FOR '#') AS "bcdef";
+ bcdef 
+-------
+ bcdef
+(1 row)
+
+SELECT SUBSTRING('abcdefg' FROM 'a#"%#"x|g' FOR '#') AS "bcdef";
+ bcdef 
+-------
+ bcdef
+(1 row)
+
+SELECT SUBSTRING('abcdefg' FROM 'a#"%|ab#"g' FOR '#') AS "bcdef";
+ bcdef 
+-------
+ bcdef
+(1 row)
+
+-- Can't have more than two part separators
+SELECT SUBSTRING('abcdefg' FROM 'a*#"%#"g*#"x' FOR '#') AS "error";
+ERROR:  SQL regular expression may not contain more than two escape-double-quote separators
+CONTEXT:  SQL function "substring" statement 1
+-- Postgres extension: with 0 or 1 separator, assume parts 1 and 3 are empty
+SELECT SUBSTRING('abcdefg' FROM 'a#"%g' FOR '#') AS "bcdefg";
+ bcdefg 
+--------
+ bcdefg
+(1 row)
+
+SELECT SUBSTRING('abcdefg' FROM 'a%g' FOR '#') AS "abcdefg";
+ abcdefg 
+---------
+ abcdefg
+(1 row)
+
+-- substring() with just two arguments is not allowed by SQL spec;
+-- we accept it, but we interpret the pattern as a POSIX regexp not SQL
+SELECT SUBSTRING('abcdefg' FROM 'c.e') AS "cde";
+ cde 
+-----
+ cde
+(1 row)
+
+-- With a parenthesized subexpression, return only what matches the subexpr
+SELECT SUBSTRING('abcdefg' FROM 'b(.*)f') AS "cde";
+ cde 
+-----
+ cde
+(1 row)
+
+-- PostgreSQL extension to allow using back reference in replace string;
+SELECT regexp_replace('1112223333', E'(\\d{3})(\\d{3})(\\d{4})', E'(\\1) \\2-\\3');
+ regexp_replace 
+----------------
+ (111) 222-3333
+(1 row)
+
+SELECT regexp_replace('AAA   BBB   CCC   ', E'\\s+', ' ', 'g');
+ regexp_replace 
+----------------
+ AAA BBB CCC 
+(1 row)
+
+SELECT regexp_replace('AAA', '^|$', 'Z', 'g');
+ regexp_replace 
+----------------
+ ZAAAZ
+(1 row)
+
+SELECT regexp_replace('AAA aaa', 'A+', 'Z', 'gi');
+ regexp_replace 
+----------------
+ Z Z
+(1 row)
+
+-- invalid regexp option
+SELECT regexp_replace('AAA aaa', 'A+', 'Z', 'z');
+ERROR:  invalid regular expression option: "z"
+-- set so we can tell NULL from empty string
+\pset null '\\N'
+-- return all matches from regexp
+SELECT regexp_matches('foobarbequebaz', $re$(bar)(beque)$re$);
+ regexp_matches 
+----------------
+ {bar,beque}
+(1 row)
+
+-- test case insensitive
+SELECT regexp_matches('foObARbEqUEbAz', $re$(bar)(beque)$re$, 'i');
+ regexp_matches 
+----------------
+ {bAR,bEqUE}
+(1 row)
+
+-- global option - more than one match
+SELECT regexp_matches('foobarbequebazilbarfbonk', $re$(b[^b]+)(b[^b]+)$re$, 'g');
+ regexp_matches 
+----------------
+ {bar,beque}
+ {bazil,barf}
+(2 rows)
+
+-- empty capture group (matched empty string)
+SELECT regexp_matches('foobarbequebaz', $re$(bar)(.*)(beque)$re$);
+ regexp_matches 
+----------------
+ {bar,"",beque}
+(1 row)
+
+-- no match
+SELECT regexp_matches('foobarbequebaz', $re$(bar)(.+)(beque)$re$);
+ regexp_matches 
+----------------
+(0 rows)
+
+-- optional capture group did not match, null entry in array
+SELECT regexp_matches('foobarbequebaz', $re$(bar)(.+)?(beque)$re$);
+  regexp_matches  
+------------------
+ {bar,NULL,beque}
+(1 row)
+
+-- no capture groups
+SELECT regexp_matches('foobarbequebaz', $re$barbeque$re$);
+ regexp_matches 
+----------------
+ {barbeque}
+(1 row)
+
+-- start/end-of-line matches are of zero length
+SELECT regexp_matches('foo' || chr(10) || 'bar' || chr(10) || 'bequq' || chr(10) || 'baz', '^', 'mg');
+ regexp_matches 
+----------------
+ {""}
+ {""}
+ {""}
+ {""}
+(4 rows)
+
+SELECT regexp_matches('foo' || chr(10) || 'bar' || chr(10) || 'bequq' || chr(10) || 'baz', '$', 'mg');
+ regexp_matches 
+----------------
+ {""}
+ {""}
+ {""}
+ {""}
+(4 rows)
+
+SELECT regexp_matches('1' || chr(10) || '2' || chr(10) || '3' || chr(10) || '4' || chr(10), '^.?', 'mg');
+ regexp_matches 
+----------------
+ {1}
+ {2}
+ {3}
+ {4}
+ {""}
+(5 rows)
+
+SELECT regexp_matches(chr(10) || '1' || chr(10) || '2' || chr(10) || '3' || chr(10) || '4' || chr(10), '.?$', 'mg');
+ regexp_matches 
+----------------
+ {""}
+ {1}
+ {""}
+ {2}
+ {""}
+ {3}
+ {""}
+ {4}
+ {""}
+ {""}
+(10 rows)
+
+SELECT regexp_matches(chr(10) || '1' || chr(10) || '2' || chr(10) || '3' || chr(10) || '4', '.?$', 'mg');
+ regexp_matches 
+----------------
+ {""}
+ {1}
+ {""}
+ {2}
+ {""}
+ {3}
+ {""}
+ {4}
+ {""}
+(9 rows)
+
+-- give me errors
+SELECT regexp_matches('foobarbequebaz', $re$(bar)(beque)$re$, 'gz');
+ERROR:  invalid regular expression option: "z"
+SELECT regexp_matches('foobarbequebaz', $re$(barbeque$re$);
+ERROR:  invalid regular expression: parentheses () not balanced
+SELECT regexp_matches('foobarbequebaz', $re$(bar)(beque){2,1}$re$);
+ERROR:  invalid regular expression: invalid repetition count(s)
+-- split string on regexp
+SELECT foo, length(foo) FROM regexp_split_to_table('the quick brown fox jumps over the lazy dog', $re$\s+$re$) AS foo;
+  foo  | length 
+-------+--------
+ the   |      3
+ quick |      5
+ brown |      5
+ fox   |      3
+ jumps |      5
+ over  |      4
+ the   |      3
+ lazy  |      4
+ dog   |      3
+(9 rows)
+
+SELECT regexp_split_to_array('the quick brown fox jumps over the lazy dog', $re$\s+$re$);
+             regexp_split_to_array             
+-----------------------------------------------
+ {the,quick,brown,fox,jumps,over,the,lazy,dog}
+(1 row)
+
+SELECT foo, length(foo) FROM regexp_split_to_table('the quick brown fox jumps over the lazy dog', $re$\s*$re$) AS foo;
+ foo | length 
+-----+--------
+ t   |      1
+ h   |      1
+ e   |      1
+ q   |      1
+ u   |      1
+ i   |      1
+ c   |      1
+ k   |      1
+ b   |      1
+ r   |      1
+ o   |      1
+ w   |      1
+ n   |      1
+ f   |      1
+ o   |      1
+ x   |      1
+ j   |      1
+ u   |      1
+ m   |      1
+ p   |      1
+ s   |      1
+ o   |      1
+ v   |      1
+ e   |      1
+ r   |      1
+ t   |      1
+ h   |      1
+ e   |      1
+ l   |      1
+ a   |      1
+ z   |      1
+ y   |      1
+ d   |      1
+ o   |      1
+ g   |      1
+(35 rows)
+
+SELECT regexp_split_to_array('the quick brown fox jumps over the lazy dog', $re$\s*$re$);
+                          regexp_split_to_array                          
+-------------------------------------------------------------------------
+ {t,h,e,q,u,i,c,k,b,r,o,w,n,f,o,x,j,u,m,p,s,o,v,e,r,t,h,e,l,a,z,y,d,o,g}
+(1 row)
+
+SELECT foo, length(foo) FROM regexp_split_to_table('the quick brown fox jumps over the lazy dog', '') AS foo;
+ foo | length 
+-----+--------
+ t   |      1
+ h   |      1
+ e   |      1
+     |      1
+ q   |      1
+ u   |      1
+ i   |      1
+ c   |      1
+ k   |      1
+     |      1
+ b   |      1
+ r   |      1
+ o   |      1
+ w   |      1
+ n   |      1
+     |      1
+ f   |      1
+ o   |      1
+ x   |      1
+     |      1
+ j   |      1
+ u   |      1
+ m   |      1
+ p   |      1
+ s   |      1
+     |      1
+ o   |      1
+ v   |      1
+ e   |      1
+ r   |      1
+     |      1
+ t   |      1
+ h   |      1
+ e   |      1
+     |      1
+ l   |      1
+ a   |      1
+ z   |      1
+ y   |      1
+     |      1
+ d   |      1
+ o   |      1
+ g   |      1
+(43 rows)
+
+SELECT regexp_split_to_array('the quick brown fox jumps over the lazy dog', '');
+                                          regexp_split_to_array                                          
+---------------------------------------------------------------------------------------------------------
+ {t,h,e," ",q,u,i,c,k," ",b,r,o,w,n," ",f,o,x," ",j,u,m,p,s," ",o,v,e,r," ",t,h,e," ",l,a,z,y," ",d,o,g}
+(1 row)
+
+-- case insensitive
+SELECT foo, length(foo) FROM regexp_split_to_table('thE QUick bROWn FOx jUMPs ovEr The lazy dOG', 'e', 'i') AS foo;
+            foo            | length 
+---------------------------+--------
+ th                        |      2
+  QUick bROWn FOx jUMPs ov |     25
+ r Th                      |      4
+  lazy dOG                 |      9
+(4 rows)
+
+SELECT regexp_split_to_array('thE QUick bROWn FOx jUMPs ovEr The lazy dOG', 'e', 'i');
+                regexp_split_to_array                
+-----------------------------------------------------
+ {th," QUick bROWn FOx jUMPs ov","r Th"," lazy dOG"}
+(1 row)
+
+-- no match of pattern
+SELECT foo, length(foo) FROM regexp_split_to_table('the quick brown fox jumps over the lazy dog', 'nomatch') AS foo;
+                     foo                     | length 
+---------------------------------------------+--------
+ the quick brown fox jumps over the lazy dog |     43
+(1 row)
+
+SELECT regexp_split_to_array('the quick brown fox jumps over the lazy dog', 'nomatch');
+              regexp_split_to_array              
+-------------------------------------------------
+ {"the quick brown fox jumps over the lazy dog"}
+(1 row)
+
+-- some corner cases
+SELECT regexp_split_to_array('123456','1');
+ regexp_split_to_array 
+-----------------------
+ {"",23456}
+(1 row)
+
+SELECT regexp_split_to_array('123456','6');
+ regexp_split_to_array 
+-----------------------
+ {12345,""}
+(1 row)
+
+SELECT regexp_split_to_array('123456','.');
+ regexp_split_to_array  
+------------------------
+ {"","","","","","",""}
+(1 row)
+
+SELECT regexp_split_to_array('123456','');
+ regexp_split_to_array 
+-----------------------
+ {1,2,3,4,5,6}
+(1 row)
+
+SELECT regexp_split_to_array('123456','(?:)');
+ regexp_split_to_array 
+-----------------------
+ {1,2,3,4,5,6}
+(1 row)
+
+SELECT regexp_split_to_array('1','');
+ regexp_split_to_array 
+-----------------------
+ {1}
+(1 row)
+
+-- errors
+SELECT foo, length(foo) FROM regexp_split_to_table('thE QUick bROWn FOx jUMPs ovEr The lazy dOG', 'e', 'zippy') AS foo;
+ERROR:  invalid regular expression option: "z"
+SELECT regexp_split_to_array('thE QUick bROWn FOx jUMPs ovEr The lazy dOG', 'e', 'iz');
+ERROR:  invalid regular expression option: "z"
+-- global option meaningless for regexp_split
+SELECT foo, length(foo) FROM regexp_split_to_table('thE QUick bROWn FOx jUMPs ovEr The lazy dOG', 'e', 'g') AS foo;
+ERROR:  regexp_split_to_table() does not support the "global" option
+SELECT regexp_split_to_array('thE QUick bROWn FOx jUMPs ovEr The lazy dOG', 'e', 'g');
+ERROR:  regexp_split_to_array() does not support the "global" option
+-- change NULL-display back
+\pset null ''
+-- E021-11 position expression
+SELECT POSITION('4' IN '1234567890') = '4' AS "4";
+ 4 
+---
+ t
+(1 row)
+
+SELECT POSITION('5' IN '1234567890') = '5' AS "5";
+ 5 
+---
+ t
+(1 row)
+
+-- T312 character overlay function
+SELECT OVERLAY('abcdef' PLACING '45' FROM 4) AS "abc45f";
+ abc45f 
+--------
+ abc45f
+(1 row)
+
+SELECT OVERLAY('yabadoo' PLACING 'daba' FROM 5) AS "yabadaba";
+ yabadaba 
+----------
+ yabadaba
+(1 row)
+
+SELECT OVERLAY('yabadoo' PLACING 'daba' FROM 5 FOR 0) AS "yabadabadoo";
+ yabadabadoo 
+-------------
+ yabadabadoo
+(1 row)
+
+SELECT OVERLAY('babosa' PLACING 'ubb' FROM 2 FOR 4) AS "bubba";
+ bubba 
+-------
+ bubba
+(1 row)
+
+--
+-- test LIKE
+-- Be sure to form every test as a LIKE/NOT LIKE pair.
+--
+-- simplest examples
+-- E061-04 like predicate
+SELECT 'hawkeye' LIKE 'h%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye' NOT LIKE 'h%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'hawkeye' LIKE 'H%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'hawkeye' NOT LIKE 'H%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye' LIKE 'indio%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'hawkeye' NOT LIKE 'indio%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye' LIKE 'h%eye' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye' NOT LIKE 'h%eye' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio' LIKE '_ndio' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'indio' NOT LIKE '_ndio' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio' LIKE 'in__o' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'indio' NOT LIKE 'in__o' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio' LIKE 'in_o' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio' NOT LIKE 'in_o' AS "true";
+ true 
+------
+ t
+(1 row)
+
+-- unused escape character
+SELECT 'hawkeye' LIKE 'h%' ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye' NOT LIKE 'h%' ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio' LIKE 'ind_o' ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'indio' NOT LIKE 'ind_o' ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+-- escape character
+-- E061-05 like predicate with escape clause
+SELECT 'h%' LIKE 'h#%' ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'h%' NOT LIKE 'h#%' ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'h%wkeye' LIKE 'h#%' ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'h%wkeye' NOT LIKE 'h#%' ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'h%wkeye' LIKE 'h#%%' ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'h%wkeye' NOT LIKE 'h#%%' ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'h%awkeye' LIKE 'h#%a%k%e' ESCAPE '#' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'h%awkeye' NOT LIKE 'h#%a%k%e' ESCAPE '#' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'indio' LIKE '_ndio' ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'indio' NOT LIKE '_ndio' ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'i_dio' LIKE 'i$_d_o' ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'i_dio' NOT LIKE 'i$_d_o' ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'i_dio' LIKE 'i$_nd_o' ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'i_dio' NOT LIKE 'i$_nd_o' ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'i_dio' LIKE 'i$_d%o' ESCAPE '$' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'i_dio' NOT LIKE 'i$_d%o' ESCAPE '$' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+-- escape character same as pattern character
+SELECT 'maca' LIKE 'm%aca' ESCAPE '%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'maca' NOT LIKE 'm%aca' ESCAPE '%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'ma%a' LIKE 'm%a%%a' ESCAPE '%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'ma%a' NOT LIKE 'm%a%%a' ESCAPE '%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'bear' LIKE 'b_ear' ESCAPE '_' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'bear' NOT LIKE 'b_ear' ESCAPE '_' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'be_r' LIKE 'b_e__r' ESCAPE '_' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'be_r' NOT LIKE 'b_e__r' ESCAPE '_' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'be_r' LIKE '__e__r' ESCAPE '_' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'be_r' NOT LIKE '__e__r' ESCAPE '_' AS "true";
+ true 
+------
+ t
+(1 row)
+
+--
+-- test ILIKE (case-insensitive LIKE)
+-- Be sure to form every test as an ILIKE/NOT ILIKE pair.
+--
+SELECT 'hawkeye' ILIKE 'h%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye' NOT ILIKE 'h%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'hawkeye' ILIKE 'H%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye' NOT ILIKE 'H%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'hawkeye' ILIKE 'H%Eye' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'hawkeye' NOT ILIKE 'H%Eye' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+SELECT 'Hawkeye' ILIKE 'h%' AS "true";
+ true 
+------
+ t
+(1 row)
+
+SELECT 'Hawkeye' NOT ILIKE 'h%' AS "false";
+ false 
+-------
+ f
+(1 row)
+
+--
+-- test %/_ combination cases, cf bugs #4821 and #5478
+--
+SELECT 'foo' LIKE '_%' as t, 'f' LIKE '_%' as t, '' LIKE '_%' as f;
+ t | t | f 
+---+---+---
+ t | t | f
+(1 row)
+
+SELECT 'foo' LIKE '%_' as t, 'f' LIKE '%_' as t, '' LIKE '%_' as f;
+ t | t | f 
+---+---+---
+ t | t | f
+(1 row)
+
+SELECT 'foo' LIKE '__%' as t, 'foo' LIKE '___%' as t, 'foo' LIKE '____%' as f;
+ t | t | f 
+---+---+---
+ t | t | f
+(1 row)
+
+SELECT 'foo' LIKE '%__' as t, 'foo' LIKE '%___' as t, 'foo' LIKE '%____' as f;
+ t | t | f 
+---+---+---
+ t | t | f
+(1 row)
+
+SELECT 'jack' LIKE '%____%' AS t;
+ t 
+---
+ t
+(1 row)
+
+--
+-- basic tests of LIKE with indexes
+--
+CREATE TABLE texttest (a text PRIMARY KEY, b int);
+SELECT * FROM texttest WHERE a LIKE '%1%';
+ a | b 
+---+---
+(0 rows)
+
+CREATE TABLE byteatest (a bytea PRIMARY KEY, b int);
+SELECT * FROM byteatest WHERE a LIKE '%1%';
+ a | b 
+---+---
+(0 rows)
+
+DROP TABLE texttest, byteatest;
+--
+-- test implicit type conversion
+--
+-- E021-07 character concatenation
+SELECT 'unknown' || ' and unknown' AS "Concat unknown types";
+ Concat unknown types 
+----------------------
+ unknown and unknown
+(1 row)
+
+SELECT text 'text' || ' and unknown' AS "Concat text to unknown type";
+ Concat text to unknown type 
+-----------------------------
+ text and unknown
+(1 row)
+
+SELECT char(20) 'characters' || ' and text' AS "Concat char to unknown type";
+ Concat char to unknown type 
+-----------------------------
+ characters and text
+(1 row)
+
+SELECT text 'text' || char(20) ' and characters' AS "Concat text to char";
+ Concat text to char 
+---------------------
+ text and characters
+(1 row)
+
+SELECT text 'text' || varchar ' and varchar' AS "Concat text to varchar";
+ Concat text to varchar 
+------------------------
+ text and varchar
+(1 row)
+
+--
+-- test substr with toasted text values
+--
+CREATE TABLE toasttest(f1 text);
+insert into toasttest values(repeat('1234567890',10000));
+insert into toasttest values(repeat('1234567890',10000));
+--
+-- Ensure that some values are uncompressed, to test the faster substring
+-- operation used in that case
+--
+alter table toasttest alter column f1 set storage external;
+insert into toasttest values(repeat('1234567890',10000));
+insert into toasttest values(repeat('1234567890',10000));
+-- If the starting position is zero or less, then return from the start of the string
+-- adjusting the length to be consistent with the "negative start" per SQL.
+SELECT substr(f1, -1, 5) from toasttest;
+ substr 
+--------
+ 123
+ 123
+ 123
+ 123
+(4 rows)
+
+-- If the length is less than zero, an ERROR is thrown.
+SELECT substr(f1, 5, -1) from toasttest;
+ERROR:  negative substring length not allowed
+-- If no third argument (length) is provided, the length to the end of the
+-- string is assumed.
+SELECT substr(f1, 99995) from toasttest;
+ substr 
+--------
+ 567890
+ 567890
+ 567890
+ 567890
+(4 rows)
+
+-- If start plus length is > string length, the result is truncated to
+-- string length
+SELECT substr(f1, 99995, 10) from toasttest;
+ substr 
+--------
+ 567890
+ 567890
+ 567890
+ 567890
+(4 rows)
+
+TRUNCATE TABLE toasttest;
+INSERT INTO toasttest values (repeat('1234567890',300));
+INSERT INTO toasttest values (repeat('1234567890',300));
+INSERT INTO toasttest values (repeat('1234567890',300));
+INSERT INTO toasttest values (repeat('1234567890',300));
+-- expect >0 blocks
+SELECT pg_relation_size(reltoastrelid) = 0 AS is_empty
+  FROM pg_class where relname = 'toasttest';
+ is_empty 
+----------
+ f
+(1 row)
+
+TRUNCATE TABLE toasttest;
+ALTER TABLE toasttest set (toast_tuple_target = 4080);
+INSERT INTO toasttest values (repeat('1234567890',300));
+INSERT INTO toasttest values (repeat('1234567890',300));
+INSERT INTO toasttest values (repeat('1234567890',300));
+INSERT INTO toasttest values (repeat('1234567890',300));
+-- expect 0 blocks
+SELECT pg_relation_size(reltoastrelid) = 0 AS is_empty
+  FROM pg_class where relname = 'toasttest';
+ is_empty 
+----------
+ f
+(1 row)
+
+DROP TABLE toasttest;
+--
+-- test substr with toasted bytea values
+--
+CREATE TABLE toasttest(f1 bytea);
+insert into toasttest values(decode(repeat('1234567890',10000),'escape'));
+insert into toasttest values(decode(repeat('1234567890',10000),'escape'));
+--
+-- Ensure that some values are uncompressed, to test the faster substring
+-- operation used in that case
+--
+alter table toasttest alter column f1 set storage external;
+insert into toasttest values(decode(repeat('1234567890',10000),'escape'));
+insert into toasttest values(decode(repeat('1234567890',10000),'escape'));
+-- If the starting position is zero or less, then return from the start of the string
+-- adjusting the length to be consistent with the "negative start" per SQL.
+SELECT substr(f1, -1, 5) from toasttest;
+ substr 
+--------
+ 123
+ 123
+ 123
+ 123
+(4 rows)
+
+-- If the length is less than zero, an ERROR is thrown.
+SELECT substr(f1, 5, -1) from toasttest;
+ERROR:  negative substring length not allowed
+-- If no third argument (length) is provided, the length to the end of the
+-- string is assumed.
+SELECT substr(f1, 99995) from toasttest;
+ substr 
+--------
+ 567890
+ 567890
+ 567890
+ 567890
+(4 rows)
+
+-- If start plus length is > string length, the result is truncated to
+-- string length
+SELECT substr(f1, 99995, 10) from toasttest;
+ substr 
+--------
+ 567890
+ 567890
+ 567890
+ 567890
+(4 rows)
+
+DROP TABLE toasttest;
+-- test internally compressing datums
+-- this tests compressing a datum to a very small size which exercises a
+-- corner case in packed-varlena handling: even though small, the compressed
+-- datum must be given a 4-byte header because there are no bits to indicate
+-- compression in a 1-byte header
+CREATE TABLE toasttest (c char(4096));
+INSERT INTO toasttest VALUES('x');
+SELECT length(c), c::text FROM toasttest;
+ length | c 
+--------+---
+      1 | x
+(1 row)
+
+SELECT c FROM toasttest;
+                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                c                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ x                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
+(1 row)
+
+DROP TABLE toasttest;
+--
+-- test length
+--
+SELECT length('abcdef') AS "length_6";
+ length_6 
+----------
+        6
+(1 row)
+
+--
+-- test strpos
+--
+SELECT strpos('abcdef', 'cd') AS "pos_3";
+ pos_3 
+-------
+     3
+(1 row)
+
+SELECT strpos('abcdef', 'xy') AS "pos_0";
+ pos_0 
+-------
+     0
+(1 row)
+
+--
+-- test replace
+--
+SELECT replace('abcdef', 'de', '45') AS "abc45f";
+ abc45f 
+--------
+ abc45f
+(1 row)
+
+SELECT replace('yabadabadoo', 'ba', '123') AS "ya123da123doo";
+ ya123da123doo 
+---------------
+ ya123da123doo
+(1 row)
+
+SELECT replace('yabadoo', 'bad', '') AS "yaoo";
+ yaoo 
+------
+ yaoo
+(1 row)
+
+--
+-- test split_part
+--
+select split_part('joeuser@mydatabase','@',0) AS "an error";
+ERROR:  field position must be greater than zero
+select split_part('joeuser@mydatabase','@',1) AS "joeuser";
+ joeuser 
+---------
+ joeuser
+(1 row)
+
+select split_part('joeuser@mydatabase','@',2) AS "mydatabase";
+ mydatabase 
+------------
+ mydatabase
+(1 row)
+
+select split_part('joeuser@mydatabase','@',3) AS "empty string";
+ empty string 
+--------------
+ 
+(1 row)
+
+select split_part('@joeuser@mydatabase@','@',2) AS "joeuser";
+ joeuser 
+---------
+ joeuser
+(1 row)
+
+--
+-- test to_hex
+--
+select to_hex(256*256*256 - 1) AS "ffffff";
+ ffffff 
+--------
+ ffffff
+(1 row)
+
+select to_hex(256::bigint*256::bigint*256::bigint*256::bigint - 1) AS "ffffffff";
+ ffffffff 
+----------
+ ffffffff
+(1 row)
+
+--
+-- MD5 test suite - from IETF RFC 1321
+-- (see: ftp://ftp.rfc-editor.org/in-notes/rfc1321.txt)
+--
+select md5('') = 'd41d8cd98f00b204e9800998ecf8427e' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+select md5('a') = '0cc175b9c0f1b6a831c399e269772661' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+select md5('abc') = '900150983cd24fb0d6963f7d28e17f72' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+select md5('message digest') = 'f96b697d7cb7938d525a2f31aaf161d0' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+select md5('abcdefghijklmnopqrstuvwxyz') = 'c3fcd3d76192e4007dfb496cca67e13b' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+select md5('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789') = 'd174ab98d277d9f5a5611c2c9f419d9f' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+select md5('12345678901234567890123456789012345678901234567890123456789012345678901234567890') = '57edf4a22be3c955ac49da2e2107b67a' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+select md5(''::bytea) = 'd41d8cd98f00b204e9800998ecf8427e' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+select md5('a'::bytea) = '0cc175b9c0f1b6a831c399e269772661' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+select md5('abc'::bytea) = '900150983cd24fb0d6963f7d28e17f72' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+select md5('message digest'::bytea) = 'f96b697d7cb7938d525a2f31aaf161d0' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+select md5('abcdefghijklmnopqrstuvwxyz'::bytea) = 'c3fcd3d76192e4007dfb496cca67e13b' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+select md5('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'::bytea) = 'd174ab98d277d9f5a5611c2c9f419d9f' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+select md5('12345678901234567890123456789012345678901234567890123456789012345678901234567890'::bytea) = '57edf4a22be3c955ac49da2e2107b67a' AS "TRUE";
+ TRUE 
+------
+ t
+(1 row)
+
+--
+-- SHA-2
+--
+SET bytea_output TO hex;
+SELECT sha224('');
+                           sha224                           
+------------------------------------------------------------
+ \xd14a028c2a3a2bc9476102bb288234c415a2b01f828ea62ac5b3e42f
+(1 row)
+
+SELECT sha224('The quick brown fox jumps over the lazy dog.');
+                           sha224                           
+------------------------------------------------------------
+ \x619cba8e8e05826e9b8c519c0a5c68f4fb653e8a3d8aa04bb2c8cd4c
+(1 row)
+
+SELECT sha256('');
+                               sha256                               
+--------------------------------------------------------------------
+ \xe3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
+(1 row)
+
+SELECT sha256('The quick brown fox jumps over the lazy dog.');
+                               sha256                               
+--------------------------------------------------------------------
+ \xef537f25c895bfa782526529a9b63d97aa631564d5d789c2b765448c8635fb6c
+(1 row)
+
+SELECT sha384('');
+                                               sha384                                               
+----------------------------------------------------------------------------------------------------
+ \x38b060a751ac96384cd9327eb1b1e36a21fdb71114be07434c0cc7bf63f6e1da274edebfe76f65fbd51ad2f14898b95b
+(1 row)
+
+SELECT sha384('The quick brown fox jumps over the lazy dog.');
+                                               sha384                                               
+----------------------------------------------------------------------------------------------------
+ \xed892481d8272ca6df370bf706e4d7bc1b5739fa2177aae6c50e946678718fc67a7af2819a021c2fc34e91bdb63409d7
+(1 row)
+
+SELECT sha512('');
+                                                               sha512                                                               
+------------------------------------------------------------------------------------------------------------------------------------
+ \xcf83e1357eefb8bdf1542850d66d8007d620e4050b5715dc83f4a921d36ce9ce47d0d13c5d85f2b0ff8318d2877eec2f63b931bd47417a81a538327af927da3e
+(1 row)
+
+SELECT sha512('The quick brown fox jumps over the lazy dog.');
+                                                               sha512                                                               
+------------------------------------------------------------------------------------------------------------------------------------
+ \x91ea1245f20d46ae9a037a989f54f1f790f0a47607eeb8a14d12890cea77a1bbc6c7ed9cf205e67b7f2b8fd4c7dfd3a7a8617e45f3c463d481c7e586c39ac1ed
+(1 row)
+
+--
+-- test behavior of escape_string_warning and standard_conforming_strings options
+--
+set escape_string_warning = off;
+set standard_conforming_strings = off;
+show escape_string_warning;
+ escape_string_warning 
+-----------------------
+ off
+(1 row)
+
+show standard_conforming_strings;
+ standard_conforming_strings 
+-----------------------------
+ off
+(1 row)
+
+set escape_string_warning = on;
+set standard_conforming_strings = on;
+show escape_string_warning;
+ escape_string_warning 
+-----------------------
+ on
+(1 row)
+
+show standard_conforming_strings;
+ standard_conforming_strings 
+-----------------------------
+ on
+(1 row)
+
+select 'a\bcd' as f1, 'a\b''cd' as f2, 'a\b''''cd' as f3, 'abcd\'   as f4, 'ab\''cd' as f5, '\\' as f6;
+  f1   |   f2   |   f3    |  f4   |   f5   | f6 
+-------+--------+---------+-------+--------+----
+ a\bcd | a\b'cd | a\b''cd | abcd\ | ab\'cd | \\
+(1 row)
+
+set standard_conforming_strings = off;
+select 'a\\bcd' as f1, 'a\\b\'cd' as f2, 'a\\b\'''cd' as f3, 'abcd\\'   as f4, 'ab\\\'cd' as f5, '\\\\' as f6;
+WARNING:  nonstandard use of \\ in a string literal
+LINE 1: select 'a\\bcd' as f1, 'a\\b\'cd' as f2, 'a\\b\'''cd' as f3,...
+               ^
+HINT:  Use the escape string syntax for backslashes, e.g., E'\\'.
+WARNING:  nonstandard use of \\ in a string literal
+LINE 1: select 'a\\bcd' as f1, 'a\\b\'cd' as f2, 'a\\b\'''cd' as f3,...
+                               ^
+HINT:  Use the escape string syntax for backslashes, e.g., E'\\'.
+WARNING:  nonstandard use of \\ in a string literal
+LINE 1: select 'a\\bcd' as f1, 'a\\b\'cd' as f2, 'a\\b\'''cd' as f3,...
+                                                 ^
+HINT:  Use the escape string syntax for backslashes, e.g., E'\\'.
+WARNING:  nonstandard use of \\ in a string literal
+LINE 1: ...bcd' as f1, 'a\\b\'cd' as f2, 'a\\b\'''cd' as f3, 'abcd\\'  ...
+                                                             ^
+HINT:  Use the escape string syntax for backslashes, e.g., E'\\'.
+WARNING:  nonstandard use of \\ in a string literal
+LINE 1: ...'cd' as f2, 'a\\b\'''cd' as f3, 'abcd\\'   as f4, 'ab\\\'cd'...
+                                                             ^
+HINT:  Use the escape string syntax for backslashes, e.g., E'\\'.
+WARNING:  nonstandard use of \\ in a string literal
+LINE 1: ...'''cd' as f3, 'abcd\\'   as f4, 'ab\\\'cd' as f5, '\\\\' as ...
+                                                             ^
+HINT:  Use the escape string syntax for backslashes, e.g., E'\\'.
+  f1   |   f2   |   f3    |  f4   |   f5   | f6 
+-------+--------+---------+-------+--------+----
+ a\bcd | a\b'cd | a\b''cd | abcd\ | ab\'cd | \\
+(1 row)
+
+set escape_string_warning = off;
+set standard_conforming_strings = on;
+select 'a\bcd' as f1, 'a\b''cd' as f2, 'a\b''''cd' as f3, 'abcd\'   as f4, 'ab\''cd' as f5, '\\' as f6;
+  f1   |   f2   |   f3    |  f4   |   f5   | f6 
+-------+--------+---------+-------+--------+----
+ a\bcd | a\b'cd | a\b''cd | abcd\ | ab\'cd | \\
+(1 row)
+
+set standard_conforming_strings = off;
+select 'a\\bcd' as f1, 'a\\b\'cd' as f2, 'a\\b\'''cd' as f3, 'abcd\\'   as f4, 'ab\\\'cd' as f5, '\\\\' as f6;
+  f1   |   f2   |   f3    |  f4   |   f5   | f6 
+-------+--------+---------+-------+--------+----
+ a\bcd | a\b'cd | a\b''cd | abcd\ | ab\'cd | \\
+(1 row)
+
+--
+-- Additional string functions
+--
+SET bytea_output TO escape;
+SELECT initcap('hi THOMAS');
+  initcap  
+-----------
+ Hi Thomas
+(1 row)
+
+SELECT lpad('hi', 5, 'xy');
+ lpad  
+-------
+ xyxhi
+(1 row)
+
+SELECT lpad('hi', 5);
+ lpad  
+-------
+    hi
+(1 row)
+
+SELECT lpad('hi', -5, 'xy');
+ lpad 
+------
+ 
+(1 row)
+
+SELECT lpad('hello', 2);
+ lpad 
+------
+ he
+(1 row)
+
+SELECT lpad('hi', 5, '');
+ lpad 
+------
+ hi
+(1 row)
+
+SELECT rpad('hi', 5, 'xy');
+ rpad  
+-------
+ hixyx
+(1 row)
+
+SELECT rpad('hi', 5);
+ rpad  
+-------
+ hi   
+(1 row)
+
+SELECT rpad('hi', -5, 'xy');
+ rpad 
+------
+ 
+(1 row)
+
+SELECT rpad('hello', 2);
+ rpad 
+------
+ he
+(1 row)
+
+SELECT rpad('hi', 5, '');
+ rpad 
+------
+ hi
+(1 row)
+
+SELECT ltrim('zzzytrim', 'xyz');
+ ltrim 
+-------
+ trim
+(1 row)
+
+SELECT translate('', '14', 'ax');
+ translate 
+-----------
+ 
+(1 row)
+
+SELECT translate('12345', '14', 'ax');
+ translate 
+-----------
+ a23x5
+(1 row)
+
+SELECT ascii('x');
+ ascii 
+-------
+   120
+(1 row)
+
+SELECT ascii('');
+ ascii 
+-------
+     0
+(1 row)
+
+SELECT chr(65);
+ chr 
+-----
+ A
+(1 row)
+
+SELECT chr(0);
+ERROR:  null character not permitted
+SELECT repeat('Pg', 4);
+  repeat  
+----------
+ PgPgPgPg
+(1 row)
+
+SELECT repeat('Pg', -4);
+ repeat 
+--------
+ 
+(1 row)
+
+SELECT trim(E'\\000'::bytea from E'\\000Tom\\000'::bytea);
+ btrim 
+-------
+ Tom
+(1 row)
+
+SELECT btrim(E'\\000trim\\000'::bytea, E'\\000'::bytea);
+ btrim 
+-------
+ trim
+(1 row)
+
+SELECT btrim(''::bytea, E'\\000'::bytea);
+ btrim 
+-------
+ 
+(1 row)
+
+SELECT btrim(E'\\000trim\\000'::bytea, ''::bytea);
+    btrim     
+--------------
+ \000trim\000
+(1 row)
+
+SELECT encode(overlay(E'Th\\000omas'::bytea placing E'Th\\001omas'::bytea from 2),'escape');
+   encode    
+-------------
+ TTh\x01omas
+(1 row)
+
+SELECT encode(overlay(E'Th\\000omas'::bytea placing E'\\002\\003'::bytea from 8),'escape');
+       encode       
+--------------------
+ Th\000omas\x02\x03
+(1 row)
+
+SELECT encode(overlay(E'Th\\000omas'::bytea placing E'\\002\\003'::bytea from 5 for 3),'escape');
+     encode      
+-----------------
+ Th\000o\x02\x03
+(1 row)
+
diff --git a/src/test/regress/expected/tablesample_1.out b/src/test/regress/expected/tablesample_1.out
new file mode 100644
index 0000000..826c6db
--- /dev/null
+++ b/src/test/regress/expected/tablesample_1.out
@@ -0,0 +1,336 @@
+CREATE TABLE test_tablesample (id int, name text) WITH (fillfactor=10);
+-- use fillfactor so we don't have to load too much data to get multiple pages
+INSERT INTO test_tablesample
+  SELECT i, repeat(i::text, 200) FROM generate_series(0, 9) s(i);
+SELECT t.id FROM test_tablesample AS t TABLESAMPLE SYSTEM (50) REPEATABLE (0);
+ id 
+----
+  0
+  1
+  2
+  3
+  4
+  5
+  9
+(7 rows)
+
+SELECT id FROM test_tablesample TABLESAMPLE SYSTEM (100.0/11) REPEATABLE (0);
+ id 
+----
+(0 rows)
+
+SELECT id FROM test_tablesample TABLESAMPLE SYSTEM (50) REPEATABLE (0);
+ id 
+----
+  0
+  1
+  2
+  3
+  4
+  5
+  9
+(7 rows)
+
+SELECT id FROM test_tablesample TABLESAMPLE BERNOULLI (50) REPEATABLE (0);
+ id 
+----
+  1
+  2
+  3
+  4
+  5
+  7
+  8
+(7 rows)
+
+SELECT id FROM test_tablesample TABLESAMPLE BERNOULLI (5.5) REPEATABLE (0);
+ id 
+----
+  4
+(1 row)
+
+-- 100% should give repeatable count results (ie, all rows) in any case
+SELECT count(*) FROM test_tablesample TABLESAMPLE SYSTEM (100);
+ count 
+-------
+    10
+(1 row)
+
+SELECT count(*) FROM test_tablesample TABLESAMPLE SYSTEM (100) REPEATABLE (1+2);
+ count 
+-------
+    10
+(1 row)
+
+SELECT count(*) FROM test_tablesample TABLESAMPLE SYSTEM (100) REPEATABLE (0.4);
+ count 
+-------
+    10
+(1 row)
+
+CREATE VIEW test_tablesample_v1 AS
+  SELECT id FROM test_tablesample TABLESAMPLE SYSTEM (10*2) REPEATABLE (2);
+CREATE VIEW test_tablesample_v2 AS
+  SELECT id FROM test_tablesample TABLESAMPLE SYSTEM (99);
+\d+ test_tablesample_v1
+                     View "public.test_tablesample_v1"
+ Column |  Type   | Collation | Nullable | Default | Storage | Description 
+--------+---------+-----------+----------+---------+---------+-------------
+ id     | integer |           |          |         | plain   | 
+View definition:
+ SELECT test_tablesample.id
+   FROM test_tablesample TABLESAMPLE system ((10 * 2)) REPEATABLE (2);
+
+\d+ test_tablesample_v2
+                     View "public.test_tablesample_v2"
+ Column |  Type   | Collation | Nullable | Default | Storage | Description 
+--------+---------+-----------+----------+---------+---------+-------------
+ id     | integer |           |          |         | plain   | 
+View definition:
+ SELECT test_tablesample.id
+   FROM test_tablesample TABLESAMPLE system (99);
+
+-- check a sampled query doesn't affect cursor in progress
+BEGIN;
+DECLARE tablesample_cur CURSOR FOR
+  SELECT id FROM test_tablesample TABLESAMPLE SYSTEM (50) REPEATABLE (0);
+FETCH FIRST FROM tablesample_cur;
+ id 
+----
+  0
+(1 row)
+
+FETCH NEXT FROM tablesample_cur;
+ id 
+----
+  1
+(1 row)
+
+FETCH NEXT FROM tablesample_cur;
+ id 
+----
+  2
+(1 row)
+
+SELECT id FROM test_tablesample TABLESAMPLE SYSTEM (50) REPEATABLE (0);
+ id 
+----
+  0
+  1
+  2
+  3
+  4
+  5
+  9
+(7 rows)
+
+FETCH NEXT FROM tablesample_cur;
+ id 
+----
+  3
+(1 row)
+
+FETCH NEXT FROM tablesample_cur;
+ id 
+----
+  4
+(1 row)
+
+FETCH NEXT FROM tablesample_cur;
+ id 
+----
+  5
+(1 row)
+
+FETCH FIRST FROM tablesample_cur;
+ id 
+----
+  0
+(1 row)
+
+FETCH NEXT FROM tablesample_cur;
+ id 
+----
+  1
+(1 row)
+
+FETCH NEXT FROM tablesample_cur;
+ id 
+----
+  2
+(1 row)
+
+FETCH NEXT FROM tablesample_cur;
+ id 
+----
+  3
+(1 row)
+
+FETCH NEXT FROM tablesample_cur;
+ id 
+----
+  4
+(1 row)
+
+FETCH NEXT FROM tablesample_cur;
+ id 
+----
+  5
+(1 row)
+
+CLOSE tablesample_cur;
+END;
+EXPLAIN (COSTS OFF)
+  SELECT id FROM test_tablesample TABLESAMPLE SYSTEM (50) REPEATABLE (2);
+                             QUERY PLAN                             
+--------------------------------------------------------------------
+ Sample Scan on test_tablesample
+   Sampling: system ('50'::real) REPEATABLE ('2'::double precision)
+(2 rows)
+
+EXPLAIN (COSTS OFF)
+  SELECT * FROM test_tablesample_v1;
+                             QUERY PLAN                             
+--------------------------------------------------------------------
+ Sample Scan on test_tablesample
+   Sampling: system ('20'::real) REPEATABLE ('2'::double precision)
+(2 rows)
+
+-- check inheritance behavior
+explain (costs off)
+  select count(*) from person tablesample bernoulli (100);
+                   QUERY PLAN                    
+-------------------------------------------------
+ Aggregate
+   ->  Append
+         ->  Sample Scan on person
+               Sampling: bernoulli ('100'::real)
+         ->  Sample Scan on emp
+               Sampling: bernoulli ('100'::real)
+         ->  Sample Scan on student
+               Sampling: bernoulli ('100'::real)
+         ->  Sample Scan on stud_emp
+               Sampling: bernoulli ('100'::real)
+(10 rows)
+
+select count(*) from person tablesample bernoulli (100);
+ count 
+-------
+    58
+(1 row)
+
+select count(*) from person;
+ count 
+-------
+    58
+(1 row)
+
+-- check that collations get assigned within the tablesample arguments
+SELECT count(*) FROM test_tablesample TABLESAMPLE bernoulli (('1'::text < '0'::text)::int);
+ count 
+-------
+     0
+(1 row)
+
+-- check behavior during rescans, as well as correct handling of min/max pct
+select * from
+  (values (0),(100)) v(pct),
+  lateral (select count(*) from tenk1 tablesample bernoulli (pct)) ss;
+ pct | count 
+-----+-------
+   0 |     0
+ 100 | 10000
+(2 rows)
+
+select * from
+  (values (0),(100)) v(pct),
+  lateral (select count(*) from tenk1 tablesample system (pct)) ss;
+ pct | count 
+-----+-------
+   0 |     0
+ 100 | 10000
+(2 rows)
+
+explain (costs off)
+select pct, count(unique1) from
+  (values (0),(100)) v(pct),
+  lateral (select * from tenk1 tablesample bernoulli (pct)) ss
+  group by pct;
+                       QUERY PLAN                       
+--------------------------------------------------------
+ HashAggregate
+   Group Key: "*VALUES*".column1
+   ->  Nested Loop
+         ->  Values Scan on "*VALUES*"
+         ->  Sample Scan on tenk1
+               Sampling: bernoulli ("*VALUES*".column1)
+(6 rows)
+
+select pct, count(unique1) from
+  (values (0),(100)) v(pct),
+  lateral (select * from tenk1 tablesample bernoulli (pct)) ss
+  group by pct;
+ pct | count 
+-----+-------
+ 100 | 10000
+(1 row)
+
+select pct, count(unique1) from
+  (values (0),(100)) v(pct),
+  lateral (select * from tenk1 tablesample system (pct)) ss
+  group by pct;
+ pct | count 
+-----+-------
+ 100 | 10000
+(1 row)
+
+-- errors
+SELECT id FROM test_tablesample TABLESAMPLE FOOBAR (1);
+ERROR:  tablesample method foobar does not exist
+LINE 1: SELECT id FROM test_tablesample TABLESAMPLE FOOBAR (1);
+                                                    ^
+SELECT id FROM test_tablesample TABLESAMPLE SYSTEM (NULL);
+ERROR:  TABLESAMPLE parameter cannot be null
+SELECT id FROM test_tablesample TABLESAMPLE SYSTEM (50) REPEATABLE (NULL);
+ERROR:  TABLESAMPLE REPEATABLE parameter cannot be null
+SELECT id FROM test_tablesample TABLESAMPLE BERNOULLI (-1);
+ERROR:  sample percentage must be between 0 and 100
+SELECT id FROM test_tablesample TABLESAMPLE BERNOULLI (200);
+ERROR:  sample percentage must be between 0 and 100
+SELECT id FROM test_tablesample TABLESAMPLE SYSTEM (-1);
+ERROR:  sample percentage must be between 0 and 100
+SELECT id FROM test_tablesample TABLESAMPLE SYSTEM (200);
+ERROR:  sample percentage must be between 0 and 100
+SELECT id FROM test_tablesample_v1 TABLESAMPLE BERNOULLI (1);
+ERROR:  TABLESAMPLE clause can only be applied to tables and materialized views
+LINE 1: SELECT id FROM test_tablesample_v1 TABLESAMPLE BERNOULLI (1)...
+                       ^
+INSERT INTO test_tablesample_v1 VALUES(1);
+ERROR:  cannot insert into view "test_tablesample_v1"
+DETAIL:  Views containing TABLESAMPLE are not automatically updatable.
+HINT:  To enable inserting into the view, provide an INSTEAD OF INSERT trigger or an unconditional ON INSERT DO INSTEAD rule.
+WITH query_select AS (SELECT * FROM test_tablesample)
+SELECT * FROM query_select TABLESAMPLE BERNOULLI (5.5) REPEATABLE (1);
+ERROR:  TABLESAMPLE clause can only be applied to tables and materialized views
+LINE 2: SELECT * FROM query_select TABLESAMPLE BERNOULLI (5.5) REPEA...
+                      ^
+SELECT q.* FROM (SELECT * FROM test_tablesample) as q TABLESAMPLE BERNOULLI (5);
+ERROR:  syntax error at or near "TABLESAMPLE"
+LINE 1: ...CT q.* FROM (SELECT * FROM test_tablesample) as q TABLESAMPL...
+                                                             ^
+-- check partitioned tables support tablesample
+create table parted_sample (a int) partition by list (a);
+create table parted_sample_1 partition of parted_sample for values in (1);
+create table parted_sample_2 partition of parted_sample for values in (2);
+explain (costs off)
+  select * from parted_sample tablesample bernoulli (100);
+                QUERY PLAN                 
+-------------------------------------------
+ Append
+   ->  Sample Scan on parted_sample_1
+         Sampling: bernoulli ('100'::real)
+   ->  Sample Scan on parted_sample_2
+         Sampling: bernoulli ('100'::real)
+(5 rows)
+
+drop table parted_sample, parted_sample_1, parted_sample_2;
diff --git a/src/test/regress/expected/tidscan_1.out b/src/test/regress/expected/tidscan_1.out
new file mode 100644
index 0000000..fd45563
--- /dev/null
+++ b/src/test/regress/expected/tidscan_1.out
@@ -0,0 +1,268 @@
+-- tests for tidscans
+CREATE TABLE tidscan(id integer);
+-- only insert a few rows, we don't want to spill onto a second table page
+INSERT INTO tidscan VALUES (1), (2), (3);
+-- show ctids
+SELECT ctid, * FROM tidscan;
+ ctid  | id 
+-------+----
+ (1,1) |  1
+ (1,2) |  2
+ (1,3) |  3
+(3 rows)
+
+-- ctid equality - implemented as tidscan
+EXPLAIN (COSTS OFF)
+SELECT ctid, * FROM tidscan WHERE ctid = '(0,1)';
+            QUERY PLAN             
+-----------------------------------
+ Tid Scan on tidscan
+   TID Cond: (ctid = '(0,1)'::tid)
+(2 rows)
+
+SELECT ctid, * FROM tidscan WHERE ctid = '(0,1)';
+ ctid | id 
+------+----
+(0 rows)
+
+EXPLAIN (COSTS OFF)
+SELECT ctid, * FROM tidscan WHERE '(0,1)' = ctid;
+            QUERY PLAN             
+-----------------------------------
+ Tid Scan on tidscan
+   TID Cond: ('(0,1)'::tid = ctid)
+(2 rows)
+
+SELECT ctid, * FROM tidscan WHERE '(0,1)' = ctid;
+ ctid | id 
+------+----
+(0 rows)
+
+-- OR'd clauses
+EXPLAIN (COSTS OFF)
+SELECT ctid, * FROM tidscan WHERE ctid = '(0,2)' OR '(0,1)' = ctid;
+                          QUERY PLAN                          
+--------------------------------------------------------------
+ Tid Scan on tidscan
+   TID Cond: ((ctid = '(0,2)'::tid) OR ('(0,1)'::tid = ctid))
+(2 rows)
+
+SELECT ctid, * FROM tidscan WHERE ctid = '(0,2)' OR '(0,1)' = ctid;
+ ctid | id 
+------+----
+(0 rows)
+
+-- ctid = ScalarArrayOp - implemented as tidscan
+EXPLAIN (COSTS OFF)
+SELECT ctid, * FROM tidscan WHERE ctid = ANY(ARRAY['(0,1)', '(0,2)']::tid[]);
+                      QUERY PLAN                       
+-------------------------------------------------------
+ Tid Scan on tidscan
+   TID Cond: (ctid = ANY ('{"(0,1)","(0,2)"}'::tid[]))
+(2 rows)
+
+SELECT ctid, * FROM tidscan WHERE ctid = ANY(ARRAY['(0,1)', '(0,2)']::tid[]);
+ ctid | id 
+------+----
+(0 rows)
+
+-- ctid != ScalarArrayOp - can't be implemented as tidscan
+EXPLAIN (COSTS OFF)
+SELECT ctid, * FROM tidscan WHERE ctid != ANY(ARRAY['(0,1)', '(0,2)']::tid[]);
+                      QUERY PLAN                      
+------------------------------------------------------
+ Seq Scan on tidscan
+   Filter: (ctid <> ANY ('{"(0,1)","(0,2)"}'::tid[]))
+(2 rows)
+
+SELECT ctid, * FROM tidscan WHERE ctid != ANY(ARRAY['(0,1)', '(0,2)']::tid[]);
+ ctid  | id 
+-------+----
+ (1,1) |  1
+ (1,2) |  2
+ (1,3) |  3
+(3 rows)
+
+-- tid equality extracted from sub-AND clauses
+EXPLAIN (COSTS OFF)
+SELECT ctid, * FROM tidscan
+WHERE (id = 3 AND ctid IN ('(0,2)', '(0,3)')) OR (ctid = '(0,1)' AND id = 1);
+                                                  QUERY PLAN                                                  
+--------------------------------------------------------------------------------------------------------------
+ Tid Scan on tidscan
+   TID Cond: ((ctid = ANY ('{"(0,2)","(0,3)"}'::tid[])) OR (ctid = '(0,1)'::tid))
+   Filter: (((id = 3) AND (ctid = ANY ('{"(0,2)","(0,3)"}'::tid[]))) OR ((ctid = '(0,1)'::tid) AND (id = 1)))
+(3 rows)
+
+SELECT ctid, * FROM tidscan
+WHERE (id = 3 AND ctid IN ('(0,2)', '(0,3)')) OR (ctid = '(0,1)' AND id = 1);
+ ctid | id 
+------+----
+(0 rows)
+
+-- nestloop-with-inner-tidscan joins on tid
+SET enable_hashjoin TO off;  -- otherwise hash join might win
+EXPLAIN (COSTS OFF)
+SELECT t1.ctid, t1.*, t2.ctid, t2.*
+FROM tidscan t1 JOIN tidscan t2 ON t1.ctid = t2.ctid WHERE t1.id = 1;
+             QUERY PLAN             
+------------------------------------
+ Nested Loop
+   ->  Seq Scan on tidscan t1
+         Filter: (id = 1)
+   ->  Tid Scan on tidscan t2
+         TID Cond: (ctid = t1.ctid)
+(5 rows)
+
+SELECT t1.ctid, t1.*, t2.ctid, t2.*
+FROM tidscan t1 JOIN tidscan t2 ON t1.ctid = t2.ctid WHERE t1.id = 1;
+ ctid  | id | ctid  | id 
+-------+----+-------+----
+ (1,1) |  1 | (1,1) |  1
+(1 row)
+
+EXPLAIN (COSTS OFF)
+SELECT t1.ctid, t1.*, t2.ctid, t2.*
+FROM tidscan t1 LEFT JOIN tidscan t2 ON t1.ctid = t2.ctid WHERE t1.id = 1;
+             QUERY PLAN             
+------------------------------------
+ Nested Loop Left Join
+   ->  Seq Scan on tidscan t1
+         Filter: (id = 1)
+   ->  Tid Scan on tidscan t2
+         TID Cond: (t1.ctid = ctid)
+(5 rows)
+
+SELECT t1.ctid, t1.*, t2.ctid, t2.*
+FROM tidscan t1 LEFT JOIN tidscan t2 ON t1.ctid = t2.ctid WHERE t1.id = 1;
+ ctid  | id | ctid  | id 
+-------+----+-------+----
+ (1,1) |  1 | (1,1) |  1
+(1 row)
+
+RESET enable_hashjoin;
+-- exercise backward scan and rewind
+BEGIN;
+DECLARE c CURSOR FOR
+SELECT ctid, * FROM tidscan WHERE ctid = ANY(ARRAY['(0,1)', '(0,2)']::tid[]);
+FETCH ALL FROM c;
+ ctid | id 
+------+----
+(0 rows)
+
+FETCH BACKWARD 1 FROM c;
+ ctid | id 
+------+----
+(0 rows)
+
+FETCH FIRST FROM c;
+ ctid | id 
+------+----
+(0 rows)
+
+ROLLBACK;
+-- tidscan via CURRENT OF
+BEGIN;
+DECLARE c CURSOR FOR SELECT ctid, * FROM tidscan;
+FETCH NEXT FROM c; -- skip one row
+ ctid  | id 
+-------+----
+ (1,1) |  1
+(1 row)
+
+FETCH NEXT FROM c;
+ ctid  | id 
+-------+----
+ (1,2) |  2
+(1 row)
+
+-- perform update
+EXPLAIN (ANALYZE, COSTS OFF, SUMMARY OFF, TIMING OFF)
+UPDATE tidscan SET id = -id WHERE CURRENT OF c RETURNING *;
+                    QUERY PLAN                     
+---------------------------------------------------
+ Update on tidscan (actual rows=1 loops=1)
+   ->  Tid Scan on tidscan (actual rows=1 loops=1)
+         TID Cond: CURRENT OF c
+(3 rows)
+
+FETCH NEXT FROM c;
+ ctid  | id 
+-------+----
+ (1,3) |  3
+(1 row)
+
+-- perform update
+EXPLAIN (ANALYZE, COSTS OFF, SUMMARY OFF, TIMING OFF)
+UPDATE tidscan SET id = -id WHERE CURRENT OF c RETURNING *;
+                    QUERY PLAN                     
+---------------------------------------------------
+ Update on tidscan (actual rows=1 loops=1)
+   ->  Tid Scan on tidscan (actual rows=1 loops=1)
+         TID Cond: CURRENT OF c
+(3 rows)
+
+SELECT * FROM tidscan;
+ id 
+----
+  1
+ -2
+ -3
+(3 rows)
+
+-- position cursor past any rows
+FETCH NEXT FROM c;
+ ctid | id 
+------+----
+(0 rows)
+
+-- should error out
+EXPLAIN (ANALYZE, COSTS OFF, SUMMARY OFF, TIMING OFF)
+UPDATE tidscan SET id = -id WHERE CURRENT OF c RETURNING *;
+ERROR:  cursor "c" is not positioned on a row
+ROLLBACK;
+-- bulk joins on CTID
+-- (these plans don't use TID scans, but this still seems like an
+-- appropriate place for these tests)
+EXPLAIN (COSTS OFF)
+SELECT count(*) FROM tenk1 t1 JOIN tenk1 t2 ON t1.ctid = t2.ctid;
+               QUERY PLAN               
+----------------------------------------
+ Aggregate
+   ->  Hash Join
+         Hash Cond: (t1.ctid = t2.ctid)
+         ->  Seq Scan on tenk1 t1
+         ->  Hash
+               ->  Seq Scan on tenk1 t2
+(6 rows)
+
+SELECT count(*) FROM tenk1 t1 JOIN tenk1 t2 ON t1.ctid = t2.ctid;
+ count 
+-------
+ 10000
+(1 row)
+
+SET enable_hashjoin TO off;
+EXPLAIN (COSTS OFF)
+SELECT count(*) FROM tenk1 t1 JOIN tenk1 t2 ON t1.ctid = t2.ctid;
+               QUERY PLAN                
+-----------------------------------------
+ Aggregate
+   ->  Merge Join
+         Merge Cond: (t1.ctid = t2.ctid)
+         ->  Sort
+               Sort Key: t1.ctid
+               ->  Seq Scan on tenk1 t1
+         ->  Sort
+               Sort Key: t2.ctid
+               ->  Seq Scan on tenk1 t2
+(9 rows)
+
+SELECT count(*) FROM tenk1 t1 JOIN tenk1 t2 ON t1.ctid = t2.ctid;
+ count 
+-------
+ 10000
+(1 row)
+
+RESET enable_hashjoin;
+DROP TABLE tidscan;
diff --git a/src/test/regress/expected/transactions.out b/src/test/regress/expected/transactions.out
index 1b316cc..59ed568 100644
--- a/src/test/regress/expected/transactions.out
+++ b/src/test/regress/expected/transactions.out
@@ -476,7 +476,7 @@ create or replace function max_xacttest() returns smallint language sql as
 'select max(a) from xacttest' stable;
 begin;
 update xacttest set a = max_xacttest() + 10 where a > 0;
-select * from xacttest;
+select * from xacttest order by a, b;
   a  |    b    
 -----+---------
    0 | 0.09561
@@ -492,7 +492,7 @@ create or replace function max_xacttest() returns smallint language sql as
 'select max(a) from xacttest' volatile;
 begin;
 update xacttest set a = max_xacttest() + 10 where a > 0;
-select * from xacttest;
+select * from xacttest order by a, b;
   a  |    b    
 -----+---------
    0 | 0.09561
@@ -508,7 +508,7 @@ create or replace function max_xacttest() returns smallint language plpgsql as
 'begin return max(a) from xacttest; end' stable;
 begin;
 update xacttest set a = max_xacttest() + 10 where a > 0;
-select * from xacttest;
+select * from xacttest order by a, b;
   a  |    b    
 -----+---------
    0 | 0.09561
@@ -523,7 +523,7 @@ create or replace function max_xacttest() returns smallint language plpgsql as
 'begin return max(a) from xacttest; end' volatile;
 begin;
 update xacttest set a = max_xacttest() + 10 where a > 0;
-select * from xacttest;
+select * from xacttest order by a, b;
   a  |    b    
 -----+---------
    0 | 0.09561
diff --git a/src/test/regress/expected/transactions_1.out b/src/test/regress/expected/transactions_1.out
new file mode 100644
index 0000000..111678b
--- /dev/null
+++ b/src/test/regress/expected/transactions_1.out
@@ -0,0 +1,944 @@
+--
+-- TRANSACTIONS
+--
+BEGIN;
+SELECT *
+   INTO TABLE xacttest
+   FROM aggtest;
+INSERT INTO xacttest (a, b) VALUES (777, 777.777);
+END;
+-- should retrieve one value--
+SELECT a FROM xacttest WHERE a > 100;
+  a  
+-----
+ 777
+(1 row)
+
+BEGIN;
+CREATE TABLE disappear (a int4);
+DELETE FROM aggtest;
+-- should be empty
+SELECT * FROM aggtest;
+ a | b 
+---+---
+(0 rows)
+
+ABORT;
+-- should not exist
+SELECT oid FROM pg_class WHERE relname = 'disappear';
+ oid 
+-----
+(0 rows)
+
+-- should have members again
+SELECT * FROM aggtest;
+  a  |    b    
+-----+---------
+  56 |     7.8
+ 100 |  99.097
+   0 | 0.09561
+  42 |  324.78
+(4 rows)
+
+-- Read-only tests
+CREATE TABLE writetest (a int);
+CREATE TEMPORARY TABLE temptest (a int);
+BEGIN;
+SET TRANSACTION ISOLATION LEVEL SERIALIZABLE, READ ONLY, DEFERRABLE; -- ok
+SELECT * FROM writetest; -- ok
+ a 
+---
+(0 rows)
+
+SET TRANSACTION READ WRITE; --fail
+ERROR:  transaction read-write mode must be set before any query
+COMMIT;
+BEGIN;
+SET TRANSACTION READ ONLY; -- ok
+SET TRANSACTION READ WRITE; -- ok
+SET TRANSACTION READ ONLY; -- ok
+SELECT * FROM writetest; -- ok
+ a 
+---
+(0 rows)
+
+SAVEPOINT x;
+SET TRANSACTION READ ONLY; -- ok
+SELECT * FROM writetest; -- ok
+ a 
+---
+(0 rows)
+
+SET TRANSACTION READ ONLY; -- ok
+SET TRANSACTION READ WRITE; --fail
+ERROR:  cannot set transaction read-write mode inside a read-only transaction
+COMMIT;
+BEGIN;
+SET TRANSACTION READ WRITE; -- ok
+SAVEPOINT x;
+SET TRANSACTION READ WRITE; -- ok
+SET TRANSACTION READ ONLY; -- ok
+SELECT * FROM writetest; -- ok
+ a 
+---
+(0 rows)
+
+SET TRANSACTION READ ONLY; -- ok
+SET TRANSACTION READ WRITE; --fail
+ERROR:  cannot set transaction read-write mode inside a read-only transaction
+COMMIT;
+BEGIN;
+SET TRANSACTION READ WRITE; -- ok
+SAVEPOINT x;
+SET TRANSACTION READ ONLY; -- ok
+SELECT * FROM writetest; -- ok
+ a 
+---
+(0 rows)
+
+ROLLBACK TO SAVEPOINT x;
+SHOW transaction_read_only;  -- off
+ transaction_read_only 
+-----------------------
+ off
+(1 row)
+
+SAVEPOINT y;
+SET TRANSACTION READ ONLY; -- ok
+SELECT * FROM writetest; -- ok
+ a 
+---
+(0 rows)
+
+RELEASE SAVEPOINT y;
+SHOW transaction_read_only;  -- off
+ transaction_read_only 
+-----------------------
+ off
+(1 row)
+
+COMMIT;
+SET SESSION CHARACTERISTICS AS TRANSACTION READ ONLY;
+DROP TABLE writetest; -- fail
+ERROR:  cannot execute DROP TABLE in a read-only transaction
+INSERT INTO writetest VALUES (1); -- fail
+ERROR:  cannot execute INSERT in a read-only transaction
+SELECT * FROM writetest; -- ok
+ a 
+---
+(0 rows)
+
+DELETE FROM temptest; -- ok
+UPDATE temptest SET a = 0 FROM writetest WHERE temptest.a = 1 AND writetest.a = temptest.a; -- ok
+PREPARE test AS UPDATE writetest SET a = 0; -- ok
+EXECUTE test; -- fail
+ERROR:  cannot execute UPDATE in a read-only transaction
+SELECT * FROM writetest, temptest; -- ok
+ a | a 
+---+---
+(0 rows)
+
+CREATE TABLE test AS SELECT * FROM writetest; -- fail
+ERROR:  cannot execute CREATE TABLE AS in a read-only transaction
+START TRANSACTION READ WRITE;
+DROP TABLE writetest; -- ok
+COMMIT;
+-- Subtransactions, basic tests
+-- create & drop tables
+SET SESSION CHARACTERISTICS AS TRANSACTION READ WRITE;
+CREATE TABLE trans_foobar (a int);
+BEGIN;
+	CREATE TABLE trans_foo (a int);
+	SAVEPOINT one;
+		DROP TABLE trans_foo;
+		CREATE TABLE trans_bar (a int);
+	ROLLBACK TO SAVEPOINT one;
+	RELEASE SAVEPOINT one;
+	SAVEPOINT two;
+		CREATE TABLE trans_baz (a int);
+	RELEASE SAVEPOINT two;
+	drop TABLE trans_foobar;
+	CREATE TABLE trans_barbaz (a int);
+COMMIT;
+-- should exist: trans_barbaz, trans_baz, trans_foo
+SELECT * FROM trans_foo;		-- should be empty
+ a 
+---
+(0 rows)
+
+SELECT * FROM trans_bar;		-- shouldn't exist
+ERROR:  relation "trans_bar" does not exist
+LINE 1: SELECT * FROM trans_bar;
+                      ^
+SELECT * FROM trans_barbaz;	-- should be empty
+ a 
+---
+(0 rows)
+
+SELECT * FROM trans_baz;		-- should be empty
+ a 
+---
+(0 rows)
+
+-- inserts
+BEGIN;
+	INSERT INTO trans_foo VALUES (1);
+	SAVEPOINT one;
+		INSERT into trans_bar VALUES (1);
+ERROR:  relation "trans_bar" does not exist
+LINE 1: INSERT into trans_bar VALUES (1);
+                    ^
+	ROLLBACK TO one;
+	RELEASE SAVEPOINT one;
+	SAVEPOINT two;
+		INSERT into trans_barbaz VALUES (1);
+	RELEASE two;
+	SAVEPOINT three;
+		SAVEPOINT four;
+			INSERT INTO trans_foo VALUES (2);
+		RELEASE SAVEPOINT four;
+	ROLLBACK TO SAVEPOINT three;
+	RELEASE SAVEPOINT three;
+	INSERT INTO trans_foo VALUES (3);
+COMMIT;
+SELECT * FROM trans_foo;		-- should have 1 and 3
+ a 
+---
+ 1
+ 3
+(2 rows)
+
+SELECT * FROM trans_barbaz;	-- should have 1
+ a 
+---
+ 1
+(1 row)
+
+-- test whole-tree commit
+BEGIN;
+	SAVEPOINT one;
+		SELECT trans_foo;
+ERROR:  column "trans_foo" does not exist
+LINE 1: SELECT trans_foo;
+               ^
+	ROLLBACK TO SAVEPOINT one;
+	RELEASE SAVEPOINT one;
+	SAVEPOINT two;
+		CREATE TABLE savepoints (a int);
+		SAVEPOINT three;
+			INSERT INTO savepoints VALUES (1);
+			SAVEPOINT four;
+				INSERT INTO savepoints VALUES (2);
+				SAVEPOINT five;
+					INSERT INTO savepoints VALUES (3);
+				ROLLBACK TO SAVEPOINT five;
+COMMIT;
+COMMIT;		-- should not be in a transaction block
+WARNING:  there is no transaction in progress
+SELECT * FROM savepoints;
+ a 
+---
+ 1
+ 2
+(2 rows)
+
+-- test whole-tree rollback
+BEGIN;
+	SAVEPOINT one;
+		DELETE FROM savepoints WHERE a=1;
+	RELEASE SAVEPOINT one;
+	SAVEPOINT two;
+		DELETE FROM savepoints WHERE a=1;
+		SAVEPOINT three;
+			DELETE FROM savepoints WHERE a=2;
+ROLLBACK;
+COMMIT;		-- should not be in a transaction block
+WARNING:  there is no transaction in progress
+SELECT * FROM savepoints;
+ a 
+---
+ 1
+ 2
+(2 rows)
+
+-- test whole-tree commit on an aborted subtransaction
+BEGIN;
+	INSERT INTO savepoints VALUES (4);
+	SAVEPOINT one;
+		INSERT INTO savepoints VALUES (5);
+		SELECT trans_foo;
+ERROR:  column "trans_foo" does not exist
+LINE 1: SELECT trans_foo;
+               ^
+COMMIT;
+SELECT * FROM savepoints;
+ a 
+---
+ 1
+ 2
+(2 rows)
+
+BEGIN;
+	INSERT INTO savepoints VALUES (6);
+	SAVEPOINT one;
+		INSERT INTO savepoints VALUES (7);
+	RELEASE SAVEPOINT one;
+	INSERT INTO savepoints VALUES (8);
+COMMIT;
+-- rows 6 and 8 should have been created by the same xact
+SELECT a.xmin = b.xmin FROM savepoints a, savepoints b WHERE a.a=6 AND b.a=8;
+ ?column? 
+----------
+ t
+(1 row)
+
+-- rows 6 and 7 should have been created by different xacts
+SELECT a.xmin = b.xmin FROM savepoints a, savepoints b WHERE a.a=6 AND b.a=7;
+ ?column? 
+----------
+ t
+(1 row)
+
+BEGIN;
+	INSERT INTO savepoints VALUES (9);
+	SAVEPOINT one;
+		INSERT INTO savepoints VALUES (10);
+	ROLLBACK TO SAVEPOINT one;
+		INSERT INTO savepoints VALUES (11);
+COMMIT;
+SELECT a FROM savepoints WHERE a in (9, 10, 11);
+ a  
+----
+  9
+ 11
+(2 rows)
+
+-- rows 9 and 11 should have been created by different xacts
+SELECT a.xmin = b.xmin FROM savepoints a, savepoints b WHERE a.a=9 AND b.a=11;
+ ?column? 
+----------
+ t
+(1 row)
+
+BEGIN;
+	INSERT INTO savepoints VALUES (12);
+	SAVEPOINT one;
+		INSERT INTO savepoints VALUES (13);
+		SAVEPOINT two;
+			INSERT INTO savepoints VALUES (14);
+	ROLLBACK TO SAVEPOINT one;
+		INSERT INTO savepoints VALUES (15);
+		SAVEPOINT two;
+			INSERT INTO savepoints VALUES (16);
+			SAVEPOINT three;
+				INSERT INTO savepoints VALUES (17);
+COMMIT;
+SELECT a FROM savepoints WHERE a BETWEEN 12 AND 17;
+ a  
+----
+ 12
+ 15
+ 16
+ 17
+(4 rows)
+
+BEGIN;
+	INSERT INTO savepoints VALUES (18);
+	SAVEPOINT one;
+		INSERT INTO savepoints VALUES (19);
+		SAVEPOINT two;
+			INSERT INTO savepoints VALUES (20);
+	ROLLBACK TO SAVEPOINT one;
+		INSERT INTO savepoints VALUES (21);
+	ROLLBACK TO SAVEPOINT one;
+		INSERT INTO savepoints VALUES (22);
+COMMIT;
+SELECT a FROM savepoints WHERE a BETWEEN 18 AND 22;
+ a  
+----
+ 18
+ 22
+(2 rows)
+
+DROP TABLE savepoints;
+-- only in a transaction block:
+SAVEPOINT one;
+ERROR:  SAVEPOINT can only be used in transaction blocks
+ROLLBACK TO SAVEPOINT one;
+ERROR:  ROLLBACK TO SAVEPOINT can only be used in transaction blocks
+RELEASE SAVEPOINT one;
+ERROR:  RELEASE SAVEPOINT can only be used in transaction blocks
+-- Only "rollback to" allowed in aborted state
+BEGIN;
+  SAVEPOINT one;
+  SELECT 0/0;
+ERROR:  division by zero
+  SAVEPOINT two;    -- ignored till the end of ...
+ERROR:  current transaction is aborted, commands ignored until end of transaction block
+  RELEASE SAVEPOINT one;      -- ignored till the end of ...
+ERROR:  current transaction is aborted, commands ignored until end of transaction block
+  ROLLBACK TO SAVEPOINT one;
+  SELECT 1;
+ ?column? 
+----------
+        1
+(1 row)
+
+COMMIT;
+SELECT 1;			-- this should work
+ ?column? 
+----------
+        1
+(1 row)
+
+-- check non-transactional behavior of cursors
+BEGIN;
+	DECLARE c CURSOR FOR SELECT unique2 FROM tenk1 ORDER BY unique2;
+	SAVEPOINT one;
+		FETCH 10 FROM c;
+ unique2 
+---------
+       0
+       1
+       2
+       3
+       4
+       5
+       6
+       7
+       8
+       9
+(10 rows)
+
+	ROLLBACK TO SAVEPOINT one;
+		FETCH 10 FROM c;
+ unique2 
+---------
+      10
+      11
+      12
+      13
+      14
+      15
+      16
+      17
+      18
+      19
+(10 rows)
+
+	RELEASE SAVEPOINT one;
+	FETCH 10 FROM c;
+ unique2 
+---------
+      20
+      21
+      22
+      23
+      24
+      25
+      26
+      27
+      28
+      29
+(10 rows)
+
+	CLOSE c;
+	DECLARE c CURSOR FOR SELECT unique2/0 FROM tenk1 ORDER BY unique2;
+	SAVEPOINT two;
+		FETCH 10 FROM c;
+ERROR:  division by zero
+	ROLLBACK TO SAVEPOINT two;
+	-- c is now dead to the world ...
+		FETCH 10 FROM c;
+ERROR:  portal "c" cannot be run
+	ROLLBACK TO SAVEPOINT two;
+	RELEASE SAVEPOINT two;
+	FETCH 10 FROM c;
+ERROR:  portal "c" cannot be run
+COMMIT;
+--
+-- Check that "stable" functions are really stable.  They should not be
+-- able to see the partial results of the calling query.  (Ideally we would
+-- also check that they don't see commits of concurrent transactions, but
+-- that's a mite hard to do within the limitations of pg_regress.)
+--
+select * from xacttest;
+  a  |    b    
+-----+---------
+  56 |     7.8
+ 100 |  99.097
+   0 | 0.09561
+  42 |  324.78
+ 777 | 777.777
+(5 rows)
+
+create or replace function max_xacttest() returns smallint language sql as
+'select max(a) from xacttest' stable;
+begin;
+update xacttest set a = max_xacttest() + 10 where a > 0;
+select * from xacttest order by a, b;
+  a  |    b    
+-----+---------
+   0 | 0.09561
+ 787 |     7.8
+ 787 |  99.097
+ 787 |  324.78
+ 787 | 777.777
+(5 rows)
+
+rollback;
+-- But a volatile function can see the partial results of the calling query
+create or replace function max_xacttest() returns smallint language sql as
+'select max(a) from xacttest' volatile;
+begin;
+update xacttest set a = max_xacttest() + 10 where a > 0;
+select * from xacttest order by a, b;
+  a  |    b    
+-----+---------
+   0 | 0.09561
+ 787 |     7.8
+ 797 |  99.097
+ 807 |  324.78
+ 817 | 777.777
+(5 rows)
+
+rollback;
+-- Now the same test with plpgsql (since it depends on SPI which is different)
+create or replace function max_xacttest() returns smallint language plpgsql as
+'begin return max(a) from xacttest; end' stable;
+begin;
+update xacttest set a = max_xacttest() + 10 where a > 0;
+select * from xacttest order by a, b;
+  a  |    b    
+-----+---------
+   0 | 0.09561
+ 787 |     7.8
+ 787 |  99.097
+ 787 |  324.78
+ 787 | 777.777
+(5 rows)
+
+rollback;
+create or replace function max_xacttest() returns smallint language plpgsql as
+'begin return max(a) from xacttest; end' volatile;
+begin;
+update xacttest set a = max_xacttest() + 10 where a > 0;
+select * from xacttest order by a, b;
+  a  |    b    
+-----+---------
+   0 | 0.09561
+ 787 |     7.8
+ 797 |  99.097
+ 807 |  324.78
+ 817 | 777.777
+(5 rows)
+
+rollback;
+-- test case for problems with dropping an open relation during abort
+BEGIN;
+	savepoint x;
+		CREATE TABLE koju (a INT UNIQUE);
+		INSERT INTO koju VALUES (1);
+		INSERT INTO koju VALUES (1);
+ERROR:  duplicate key value violates unique constraint "koju_a_key"
+DETAIL:  Key (a)=(1) already exists.
+	rollback to x;
+	CREATE TABLE koju (a INT UNIQUE);
+	INSERT INTO koju VALUES (1);
+	INSERT INTO koju VALUES (1);
+ERROR:  duplicate key value violates unique constraint "koju_a_key"
+DETAIL:  Key (a)=(1) already exists.
+ROLLBACK;
+DROP TABLE trans_foo;
+DROP TABLE trans_baz;
+DROP TABLE trans_barbaz;
+-- test case for problems with revalidating an open relation during abort
+create function inverse(int) returns float8 as
+$$
+begin
+  analyze revalidate_bug;
+  return 1::float8/$1;
+exception
+  when division_by_zero then return 0;
+end$$ language plpgsql volatile;
+create table revalidate_bug (c float8 unique);
+insert into revalidate_bug values (1);
+insert into revalidate_bug values (inverse(0));
+drop table revalidate_bug;
+drop function inverse(int);
+-- verify that cursors created during an aborted subtransaction are
+-- closed, but that we do not rollback the effect of any FETCHs
+-- performed in the aborted subtransaction
+begin;
+savepoint x;
+create table abc (a int);
+insert into abc values (5);
+insert into abc values (10);
+declare foo cursor for select * from abc;
+fetch from foo;
+ a 
+---
+ 5
+(1 row)
+
+rollback to x;
+-- should fail
+fetch from foo;
+ERROR:  cursor "foo" does not exist
+commit;
+begin;
+create table abc (a int);
+insert into abc values (5);
+insert into abc values (10);
+insert into abc values (15);
+declare foo cursor for select * from abc;
+fetch from foo;
+ a 
+---
+ 5
+(1 row)
+
+savepoint x;
+fetch from foo;
+ a  
+----
+ 10
+(1 row)
+
+rollback to x;
+fetch from foo;
+ a  
+----
+ 15
+(1 row)
+
+abort;
+-- Test for proper cleanup after a failure in a cursor portal
+-- that was created in an outer subtransaction
+CREATE FUNCTION invert(x float8) RETURNS float8 LANGUAGE plpgsql AS
+$$ begin return 1/x; end $$;
+CREATE FUNCTION create_temp_tab() RETURNS text
+LANGUAGE plpgsql AS $$
+BEGIN
+  CREATE TEMP TABLE new_table (f1 float8);
+  -- case of interest is that we fail while holding an open
+  -- relcache reference to new_table
+  INSERT INTO new_table SELECT invert(0.0);
+  RETURN 'foo';
+END $$;
+BEGIN;
+DECLARE ok CURSOR FOR SELECT * FROM int8_tbl;
+DECLARE ctt CURSOR FOR SELECT create_temp_tab();
+FETCH ok;
+ q1  | q2  
+-----+-----
+ 123 | 456
+(1 row)
+
+SAVEPOINT s1;
+FETCH ok;  -- should work
+ q1  |        q2        
+-----+------------------
+ 123 | 4567890123456789
+(1 row)
+
+FETCH ctt; -- error occurs here
+ERROR:  division by zero
+CONTEXT:  PL/pgSQL function invert(double precision) line 1 at RETURN
+SQL statement "INSERT INTO new_table SELECT invert(0.0)"
+PL/pgSQL function create_temp_tab() line 6 at SQL statement
+ROLLBACK TO s1;
+FETCH ok;  -- should work
+        q1        | q2  
+------------------+-----
+ 4567890123456789 | 123
+(1 row)
+
+FETCH ctt; -- must be rejected
+ERROR:  portal "ctt" cannot be run
+COMMIT;
+DROP FUNCTION create_temp_tab();
+DROP FUNCTION invert(x float8);
+-- Tests for AND CHAIN
+CREATE TABLE abc (a int);
+-- set nondefault value so we have something to override below
+SET default_transaction_read_only = on;
+START TRANSACTION ISOLATION LEVEL REPEATABLE READ, READ WRITE, DEFERRABLE;
+SHOW transaction_isolation;
+ transaction_isolation 
+-----------------------
+ repeatable read
+(1 row)
+
+SHOW transaction_read_only;
+ transaction_read_only 
+-----------------------
+ off
+(1 row)
+
+SHOW transaction_deferrable;
+ transaction_deferrable 
+------------------------
+ on
+(1 row)
+
+INSERT INTO abc VALUES (1);
+INSERT INTO abc VALUES (2);
+COMMIT AND CHAIN;  -- TBLOCK_END
+SHOW transaction_isolation;
+ transaction_isolation 
+-----------------------
+ repeatable read
+(1 row)
+
+SHOW transaction_read_only;
+ transaction_read_only 
+-----------------------
+ off
+(1 row)
+
+SHOW transaction_deferrable;
+ transaction_deferrable 
+------------------------
+ on
+(1 row)
+
+INSERT INTO abc VALUES ('error');
+ERROR:  invalid input syntax for type integer: "error"
+LINE 1: INSERT INTO abc VALUES ('error');
+                                ^
+INSERT INTO abc VALUES (3);  -- check it's really aborted
+ERROR:  current transaction is aborted, commands ignored until end of transaction block
+COMMIT AND CHAIN;  -- TBLOCK_ABORT_END
+SHOW transaction_isolation;
+ transaction_isolation 
+-----------------------
+ repeatable read
+(1 row)
+
+SHOW transaction_read_only;
+ transaction_read_only 
+-----------------------
+ off
+(1 row)
+
+SHOW transaction_deferrable;
+ transaction_deferrable 
+------------------------
+ on
+(1 row)
+
+INSERT INTO abc VALUES (4);
+COMMIT;
+START TRANSACTION ISOLATION LEVEL REPEATABLE READ, READ WRITE, DEFERRABLE;
+SHOW transaction_isolation;
+ transaction_isolation 
+-----------------------
+ repeatable read
+(1 row)
+
+SHOW transaction_read_only;
+ transaction_read_only 
+-----------------------
+ off
+(1 row)
+
+SHOW transaction_deferrable;
+ transaction_deferrable 
+------------------------
+ on
+(1 row)
+
+SAVEPOINT x;
+INSERT INTO abc VALUES ('error');
+ERROR:  invalid input syntax for type integer: "error"
+LINE 1: INSERT INTO abc VALUES ('error');
+                                ^
+COMMIT AND CHAIN;  -- TBLOCK_ABORT_PENDING
+SHOW transaction_isolation;
+ transaction_isolation 
+-----------------------
+ repeatable read
+(1 row)
+
+SHOW transaction_read_only;
+ transaction_read_only 
+-----------------------
+ off
+(1 row)
+
+SHOW transaction_deferrable;
+ transaction_deferrable 
+------------------------
+ on
+(1 row)
+
+INSERT INTO abc VALUES (5);
+COMMIT;
+-- different mix of options just for fun
+START TRANSACTION ISOLATION LEVEL SERIALIZABLE, READ WRITE, NOT DEFERRABLE;
+SHOW transaction_isolation;
+ transaction_isolation 
+-----------------------
+ serializable
+(1 row)
+
+SHOW transaction_read_only;
+ transaction_read_only 
+-----------------------
+ off
+(1 row)
+
+SHOW transaction_deferrable;
+ transaction_deferrable 
+------------------------
+ off
+(1 row)
+
+INSERT INTO abc VALUES (6);
+ROLLBACK AND CHAIN;  -- TBLOCK_ABORT_PENDING
+SHOW transaction_isolation;
+ transaction_isolation 
+-----------------------
+ serializable
+(1 row)
+
+SHOW transaction_read_only;
+ transaction_read_only 
+-----------------------
+ off
+(1 row)
+
+SHOW transaction_deferrable;
+ transaction_deferrable 
+------------------------
+ off
+(1 row)
+
+INSERT INTO abc VALUES ('error');
+ERROR:  invalid input syntax for type integer: "error"
+LINE 1: INSERT INTO abc VALUES ('error');
+                                ^
+ROLLBACK AND CHAIN;  -- TBLOCK_ABORT_END
+SHOW transaction_isolation;
+ transaction_isolation 
+-----------------------
+ serializable
+(1 row)
+
+SHOW transaction_read_only;
+ transaction_read_only 
+-----------------------
+ off
+(1 row)
+
+SHOW transaction_deferrable;
+ transaction_deferrable 
+------------------------
+ off
+(1 row)
+
+ROLLBACK;
+SELECT * FROM abc ORDER BY 1;
+ a 
+---
+ 1
+ 2
+ 4
+ 5
+(4 rows)
+
+RESET default_transaction_read_only;
+DROP TABLE abc;
+-- Test assorted behaviors around the implicit transaction block created
+-- when multiple SQL commands are sent in a single Query message.  These
+-- tests rely on the fact that psql will not break SQL commands apart at a
+-- backslash-quoted semicolon, but will send them as one Query.
+create temp table i_table (f1 int);
+-- psql will show only the last result in a multi-statement Query
+SELECT 1\; SELECT 2\; SELECT 3;
+ ?column? 
+----------
+        3
+(1 row)
+
+-- this implicitly commits:
+insert into i_table values(1)\; select * from i_table;
+ f1 
+----
+  1
+(1 row)
+
+-- 1/0 error will cause rolling back the whole implicit transaction
+insert into i_table values(2)\; select * from i_table\; select 1/0;
+ERROR:  division by zero
+select * from i_table;
+ f1 
+----
+  1
+(1 row)
+
+rollback;  -- we are not in a transaction at this point
+WARNING:  there is no transaction in progress
+-- can use regular begin/commit/rollback within a single Query
+begin\; insert into i_table values(3)\; commit;
+rollback;  -- we are not in a transaction at this point
+WARNING:  there is no transaction in progress
+begin\; insert into i_table values(4)\; rollback;
+rollback;  -- we are not in a transaction at this point
+WARNING:  there is no transaction in progress
+-- begin converts implicit transaction into a regular one that
+-- can extend past the end of the Query
+select 1\; begin\; insert into i_table values(5);
+commit;
+select 1\; begin\; insert into i_table values(6);
+rollback;
+-- commit in implicit-transaction state commits but issues a warning.
+insert into i_table values(7)\; commit\; insert into i_table values(8)\; select 1/0;
+WARNING:  there is no transaction in progress
+ERROR:  division by zero
+-- similarly, rollback aborts but issues a warning.
+insert into i_table values(9)\; rollback\; select 2;
+WARNING:  there is no transaction in progress
+ ?column? 
+----------
+        2
+(1 row)
+
+select * from i_table;
+ f1 
+----
+  1
+  3
+  5
+  7
+(4 rows)
+
+rollback;  -- we are not in a transaction at this point
+WARNING:  there is no transaction in progress
+-- implicit transaction block is still a transaction block, for e.g. VACUUM
+SELECT 1\; VACUUM;
+ERROR:  VACUUM cannot run inside a transaction block
+SELECT 1\; COMMIT\; VACUUM;
+WARNING:  there is no transaction in progress
+ERROR:  VACUUM cannot run inside a transaction block
+-- we disallow savepoint-related commands in implicit-transaction state
+SELECT 1\; SAVEPOINT sp;
+ERROR:  SAVEPOINT can only be used in transaction blocks
+SELECT 1\; COMMIT\; SAVEPOINT sp;
+WARNING:  there is no transaction in progress
+ERROR:  SAVEPOINT can only be used in transaction blocks
+ROLLBACK TO SAVEPOINT sp\; SELECT 2;
+ERROR:  ROLLBACK TO SAVEPOINT can only be used in transaction blocks
+SELECT 2\; RELEASE SAVEPOINT sp\; SELECT 3;
+ERROR:  RELEASE SAVEPOINT can only be used in transaction blocks
+-- but this is OK, because the BEGIN converts it to a regular xact
+SELECT 1\; BEGIN\; SAVEPOINT sp\; ROLLBACK TO SAVEPOINT sp\; COMMIT;
+-- Test for successful cleanup of an aborted transaction at session exit.
+-- THIS MUST BE THE LAST TEST IN THIS FILE.
+begin;
+select 1/0;
+ERROR:  division by zero
+rollback to X;
+ERROR:  savepoint "x" does not exist
+-- DO NOT ADD ANYTHING HERE.
diff --git a/src/test/regress/expected/triggers.out b/src/test/regress/expected/triggers.out
index c64151b..8820d5d 100644
--- a/src/test/regress/expected/triggers.out
+++ b/src/test/regress/expected/triggers.out
@@ -4,6 +4,7 @@
 create table pkeys (pkey1 int4 not null, pkey2 text not null);
 create table fkeys (fkey1 int4, fkey2 text, fkey3 int);
 create table fkeys2 (fkey21 int4, fkey22 text, pkey23 int not null);
+create temp table tmp_del_table (a text);
 create index fkeys_i on fkeys (fkey1, fkey2);
 create index fkeys2_i on fkeys2 (fkey21, fkey22);
 create index fkeys2p_i on fkeys2 (pkey23);
@@ -193,26 +194,26 @@ select * from tttest where price_off = 999999;
 
 -- change price for price_id == 3
 update tttest set price_val = 30 where price_id = 3;
-select * from tttest;
+select * from tttest order by price_id, price_val;
  price_id | price_val | price_on | price_off 
 ----------+-----------+----------+-----------
         1 |         1 |       10 |    999999
         2 |         2 |       20 |        40
-        3 |        30 |       50 |    999999
         3 |         3 |       30 |        50
+        3 |        30 |       50 |    999999
 (4 rows)
 
 -- now we want to change pric_id in ALL tuples
 -- this gets us not what we need
 update tttest set price_id = 5 where price_id = 3;
-select * from tttest;
+select * from tttest order by price_id, price_val;
  price_id | price_val | price_on | price_off 
 ----------+-----------+----------+-----------
         1 |         1 |       10 |    999999
         2 |         2 |       20 |        40
         3 |         3 |       30 |        50
-        5 |        30 |       60 |    999999
         3 |        30 |       50 |        60
+        5 |        30 |       60 |    999999
 (5 rows)
 
 -- restore data as before last update:
@@ -224,7 +225,7 @@ select set_ttdummy(0);
 
 delete from tttest where price_id = 5;
 update tttest set price_off = 999999 where price_val = 30;
-select * from tttest;
+select * from tttest order by price_id, price_val;
  price_id | price_val | price_on | price_off 
 ----------+-----------+----------+-----------
         1 |         1 |       10 |    999999
@@ -235,7 +236,7 @@ select * from tttest;
 
 -- and try change price_id now!
 update tttest set price_id = 5 where price_id = 3;
-select * from tttest;
+select * from tttest order by price_id, price_val;
  price_id | price_val | price_on | price_off 
 ----------+-----------+----------+-----------
         1 |         1 |       10 |    999999
@@ -263,13 +264,13 @@ select set_ttdummy(0);
 (1 row)
 
 update tttest set price_on = -1 where price_id = 1;
-select * from tttest;
+select * from tttest order by price_id, price_val;
  price_id | price_val | price_on | price_off 
 ----------+-----------+----------+-----------
+        1 |         1 |       -1 |    999999
         2 |         2 |       20 |        40
         5 |         3 |       30 |        50
         5 |        30 |       50 |    999999
-        1 |         1 |       -1 |    999999
 (4 rows)
 
 -- isn't it what we need ?
@@ -902,7 +903,7 @@ begin
         end if;
 
         if TG_OP = 'DELETE' then
-            raise NOTICE 'OLD: %', OLD;
+            insert into tmp_del_table values (OLD);
             DELETE FROM main_table WHERE a = OLD.a AND b = OLD.b;
             if NOT FOUND then RETURN NULL; end if;
             RETURN OLD;
@@ -1080,17 +1081,23 @@ UPDATE 0
 DELETE FROM main_view WHERE a IN (20,21);
 NOTICE:  main_view BEFORE DELETE STATEMENT (before_view_del_stmt)
 NOTICE:  main_view INSTEAD OF DELETE ROW (instead_of_del)
-NOTICE:  OLD: (21,10)
 NOTICE:  main_view INSTEAD OF DELETE ROW (instead_of_del)
-NOTICE:  OLD: (20,31)
 NOTICE:  main_view INSTEAD OF DELETE ROW (instead_of_del)
-NOTICE:  OLD: (21,32)
 NOTICE:  main_view AFTER DELETE STATEMENT (after_view_del_stmt)
 DELETE 3
+select * from tmp_del_table order by 1;
+    a    
+---------
+ (20,31)
+ (21,10)
+ (21,32)
+(3 rows)
+
+truncate table tmp_del_table;
+TRUNCATE TABLE
 DELETE FROM main_view WHERE a = 31 RETURNING a, b;
 NOTICE:  main_view BEFORE DELETE STATEMENT (before_view_del_stmt)
 NOTICE:  main_view INSTEAD OF DELETE ROW (instead_of_del)
-NOTICE:  OLD: (31,10)
 NOTICE:  main_view AFTER DELETE STATEMENT (after_view_del_stmt)
  a  | b  
 ----+----
@@ -1098,6 +1105,14 @@ NOTICE:  main_view AFTER DELETE STATEMENT (after_view_del_stmt)
 (1 row)
 
 DELETE 1
+select * from tmp_del_table order by 1;
+    a    
+---------
+ (31,10)
+(1 row)
+
+truncate table tmp_del_table;
+TRUNCATE TABLE
 \set QUIET true
 -- Describe view should list triggers
 \d main_view
@@ -1418,13 +1433,13 @@ UPDATE city_view v SET population = 599657
 
 UPDATE 1
 \set QUIET true
-SELECT * FROM city_view;
+SELECT * FROM city_view ORDER BY city_id;
  city_id |   city_name   | population | country_name |   continent   
 ---------+---------------+------------+--------------+---------------
        1 | Tokyo         |   13010279 | Japan        | Asia
-  123456 | New York      |    8391881 | USA          | North America
        2 | London        |    7556900 | UK           | Europe
        3 | Washington DC |     599657 | USA          | North America
+  123456 | New York      |    8391881 | USA          | North America
 (4 rows)
 
 DROP TABLE city_table CASCADE;
@@ -1689,14 +1704,14 @@ insert into self_ref_trigger values (3, 1, 'root child B');
 insert into self_ref_trigger values (4, 2, 'grandchild 1');
 insert into self_ref_trigger values (5, 3, 'grandchild 2');
 update self_ref_trigger set data = 'root!' where id = 1;
-select * from self_ref_trigger;
+select * from self_ref_trigger order by id;
  id | parent |     data     | nchildren 
 ----+--------+--------------+-----------
+  1 |        | root!        |         2
   2 |      1 | root child A |         1
-  4 |      2 | grandchild 1 |         0
   3 |      1 | root child B |         1
+  4 |      2 | grandchild 1 |         0
   5 |      3 | grandchild 2 |         0
-  1 |        | root!        |         2
 (5 rows)
 
 delete from self_ref_trigger;
@@ -2792,7 +2807,7 @@ NOTICE:  trigger = trig_table_insert_trig, new table = (1,"one a"), (1,"one b"),
 update refd_table set a = 11 where b = 'one';
 NOTICE:  trigger_func(trig_table) called: action = UPDATE, when = BEFORE, level = STATEMENT
 NOTICE:  trigger = trig_table_update_trig, old table = (1,"one a"), (1,"one b"), new table = (11,"one a"), (11,"one b")
-select * from trig_table;
+select * from trig_table order by a, b;
  a  |    b    
 ----+---------
   2 | two a
diff --git a/src/test/regress/expected/triggers_1.out b/src/test/regress/expected/triggers_1.out
new file mode 100644
index 0000000..cdae5e4
--- /dev/null
+++ b/src/test/regress/expected/triggers_1.out
@@ -0,0 +1,2834 @@
+--
+-- TRIGGERS
+--
+create table pkeys (pkey1 int4 not null, pkey2 text not null);
+create table fkeys (fkey1 int4, fkey2 text, fkey3 int);
+create table fkeys2 (fkey21 int4, fkey22 text, pkey23 int not null);
+create temp table tmp_del_table (a text);
+create index fkeys_i on fkeys (fkey1, fkey2);
+create index fkeys2_i on fkeys2 (fkey21, fkey22);
+create index fkeys2p_i on fkeys2 (pkey23);
+insert into pkeys values (10, '1');
+insert into pkeys values (20, '2');
+insert into pkeys values (30, '3');
+insert into pkeys values (40, '4');
+insert into pkeys values (50, '5');
+insert into pkeys values (60, '6');
+create unique index pkeys_i on pkeys (pkey1, pkey2);
+--
+-- For fkeys:
+-- 	(fkey1, fkey2)	--> pkeys (pkey1, pkey2)
+-- 	(fkey3)		--> fkeys2 (pkey23)
+--
+create trigger check_fkeys_pkey_exist
+	before insert or update on fkeys
+	for each row
+	execute function
+	check_primary_key ('fkey1', 'fkey2', 'pkeys', 'pkey1', 'pkey2');
+create trigger check_fkeys_pkey2_exist
+	before insert or update on fkeys
+	for each row
+	execute function check_primary_key ('fkey3', 'fkeys2', 'pkey23');
+--
+-- For fkeys2:
+-- 	(fkey21, fkey22)	--> pkeys (pkey1, pkey2)
+--
+create trigger check_fkeys2_pkey_exist
+	before insert or update on fkeys2
+	for each row
+	execute procedure
+	check_primary_key ('fkey21', 'fkey22', 'pkeys', 'pkey1', 'pkey2');
+-- Test comments
+COMMENT ON TRIGGER check_fkeys2_pkey_bad ON fkeys2 IS 'wrong';
+ERROR:  trigger "check_fkeys2_pkey_bad" for table "fkeys2" does not exist
+COMMENT ON TRIGGER check_fkeys2_pkey_exist ON fkeys2 IS 'right';
+COMMENT ON TRIGGER check_fkeys2_pkey_exist ON fkeys2 IS NULL;
+--
+-- For pkeys:
+-- 	ON DELETE/UPDATE (pkey1, pkey2) CASCADE:
+-- 		fkeys (fkey1, fkey2) and fkeys2 (fkey21, fkey22)
+--
+create trigger check_pkeys_fkey_cascade
+	before delete or update on pkeys
+	for each row
+	execute procedure
+	check_foreign_key (2, 'cascade', 'pkey1', 'pkey2',
+	'fkeys', 'fkey1', 'fkey2', 'fkeys2', 'fkey21', 'fkey22');
+--
+-- For fkeys2:
+-- 	ON DELETE/UPDATE (pkey23) RESTRICT:
+-- 		fkeys (fkey3)
+--
+create trigger check_fkeys2_fkey_restrict
+	before delete or update on fkeys2
+	for each row
+	execute procedure check_foreign_key (1, 'restrict', 'pkey23', 'fkeys', 'fkey3');
+insert into fkeys2 values (10, '1', 1);
+insert into fkeys2 values (30, '3', 2);
+insert into fkeys2 values (40, '4', 5);
+insert into fkeys2 values (50, '5', 3);
+-- no key in pkeys
+insert into fkeys2 values (70, '5', 3);
+ERROR:  tuple references non-existent key
+DETAIL:  Trigger "check_fkeys2_pkey_exist" found tuple referencing non-existent key in "pkeys".
+insert into fkeys values (10, '1', 2);
+insert into fkeys values (30, '3', 3);
+insert into fkeys values (40, '4', 2);
+insert into fkeys values (50, '5', 2);
+-- no key in pkeys
+insert into fkeys values (70, '5', 1);
+ERROR:  tuple references non-existent key
+DETAIL:  Trigger "check_fkeys_pkey_exist" found tuple referencing non-existent key in "pkeys".
+-- no key in fkeys2
+insert into fkeys values (60, '6', 4);
+ERROR:  tuple references non-existent key
+DETAIL:  Trigger "check_fkeys_pkey2_exist" found tuple referencing non-existent key in "fkeys2".
+delete from pkeys where pkey1 = 30 and pkey2 = '3';
+NOTICE:  check_pkeys_fkey_cascade: 1 tuple(s) of fkeys are deleted
+ERROR:  "check_fkeys2_fkey_restrict": tuple is referenced in "fkeys"
+CONTEXT:  SQL statement "delete from fkeys2 where fkey21 = $1 and fkey22 = $2 "
+delete from pkeys where pkey1 = 40 and pkey2 = '4';
+NOTICE:  check_pkeys_fkey_cascade: 1 tuple(s) of fkeys are deleted
+NOTICE:  check_pkeys_fkey_cascade: 1 tuple(s) of fkeys2 are deleted
+update pkeys set pkey1 = 7, pkey2 = '70' where pkey1 = 50 and pkey2 = '5';
+NOTICE:  check_pkeys_fkey_cascade: 1 tuple(s) of fkeys are deleted
+ERROR:  "check_fkeys2_fkey_restrict": tuple is referenced in "fkeys"
+CONTEXT:  SQL statement "delete from fkeys2 where fkey21 = $1 and fkey22 = $2 "
+update pkeys set pkey1 = 7, pkey2 = '70' where pkey1 = 10 and pkey2 = '1';
+NOTICE:  check_pkeys_fkey_cascade: 1 tuple(s) of fkeys are deleted
+NOTICE:  check_pkeys_fkey_cascade: 1 tuple(s) of fkeys2 are deleted
+SELECT trigger_name, event_manipulation, event_object_schema, event_object_table,
+       action_order, action_condition, action_orientation, action_timing,
+       action_reference_old_table, action_reference_new_table
+  FROM information_schema.triggers
+  WHERE event_object_table in ('pkeys', 'fkeys', 'fkeys2')
+  ORDER BY trigger_name COLLATE "C", 2;
+        trigger_name        | event_manipulation | event_object_schema | event_object_table | action_order | action_condition | action_orientation | action_timing | action_reference_old_table | action_reference_new_table 
+----------------------------+--------------------+---------------------+--------------------+--------------+------------------+--------------------+---------------+----------------------------+----------------------------
+ check_fkeys2_fkey_restrict | DELETE             | public              | fkeys2             |            1 |                  | ROW                | BEFORE        |                            | 
+ check_fkeys2_fkey_restrict | UPDATE             | public              | fkeys2             |            1 |                  | ROW                | BEFORE        |                            | 
+ check_fkeys2_pkey_exist    | INSERT             | public              | fkeys2             |            1 |                  | ROW                | BEFORE        |                            | 
+ check_fkeys2_pkey_exist    | UPDATE             | public              | fkeys2             |            2 |                  | ROW                | BEFORE        |                            | 
+ check_fkeys_pkey2_exist    | INSERT             | public              | fkeys              |            1 |                  | ROW                | BEFORE        |                            | 
+ check_fkeys_pkey2_exist    | UPDATE             | public              | fkeys              |            1 |                  | ROW                | BEFORE        |                            | 
+ check_fkeys_pkey_exist     | INSERT             | public              | fkeys              |            2 |                  | ROW                | BEFORE        |                            | 
+ check_fkeys_pkey_exist     | UPDATE             | public              | fkeys              |            2 |                  | ROW                | BEFORE        |                            | 
+ check_pkeys_fkey_cascade   | DELETE             | public              | pkeys              |            1 |                  | ROW                | BEFORE        |                            | 
+ check_pkeys_fkey_cascade   | UPDATE             | public              | pkeys              |            1 |                  | ROW                | BEFORE        |                            | 
+(10 rows)
+
+DROP TABLE pkeys;
+DROP TABLE fkeys;
+DROP TABLE fkeys2;
+-- Check behavior when trigger returns unmodified trigtuple
+create table trigtest (f1 int, f2 text);
+create trigger trigger_return_old
+	before insert or delete or update on trigtest
+	for each row execute procedure trigger_return_old();
+insert into trigtest values(1, 'foo');
+select * from trigtest;
+ f1 | f2  
+----+-----
+  1 | foo
+(1 row)
+
+update trigtest set f2 = f2 || 'bar';
+select * from trigtest;
+ f1 | f2  
+----+-----
+  1 | foo
+(1 row)
+
+delete from trigtest;
+select * from trigtest;
+ f1 | f2 
+----+----
+(0 rows)
+
+drop table trigtest;
+create sequence ttdummy_seq increment 10 start 0 minvalue 0;
+create table tttest (
+	price_id	int4,
+	price_val	int4,
+	price_on	int4,
+	price_off	int4 default 999999
+);
+create trigger ttdummy
+	before delete or update on tttest
+	for each row
+	execute procedure
+	ttdummy (price_on, price_off);
+create trigger ttserial
+	before insert or update on tttest
+	for each row
+	execute procedure
+	autoinc (price_on, ttdummy_seq);
+insert into tttest values (1, 1, null);
+insert into tttest values (2, 2, null);
+insert into tttest values (3, 3, 0);
+select * from tttest;
+ price_id | price_val | price_on | price_off 
+----------+-----------+----------+-----------
+        1 |         1 |       10 |    999999
+        2 |         2 |       20 |    999999
+        3 |         3 |       30 |    999999
+(3 rows)
+
+delete from tttest where price_id = 2;
+select * from tttest;
+ price_id | price_val | price_on | price_off 
+----------+-----------+----------+-----------
+        1 |         1 |       10 |    999999
+        3 |         3 |       30 |    999999
+        2 |         2 |       20 |        40
+(3 rows)
+
+-- what do we see ?
+-- get current prices
+select * from tttest where price_off = 999999;
+ price_id | price_val | price_on | price_off 
+----------+-----------+----------+-----------
+        1 |         1 |       10 |    999999
+        3 |         3 |       30 |    999999
+(2 rows)
+
+-- change price for price_id == 3
+update tttest set price_val = 30 where price_id = 3;
+select * from tttest order by price_id, price_val;
+ price_id | price_val | price_on | price_off 
+----------+-----------+----------+-----------
+        1 |         1 |       10 |    999999
+        2 |         2 |       20 |        40
+        3 |         3 |       30 |        50
+        3 |        30 |       50 |    999999
+(4 rows)
+
+-- now we want to change pric_id in ALL tuples
+-- this gets us not what we need
+update tttest set price_id = 5 where price_id = 3;
+select * from tttest order by price_id, price_val;
+ price_id | price_val | price_on | price_off 
+----------+-----------+----------+-----------
+        1 |         1 |       10 |    999999
+        2 |         2 |       20 |        40
+        3 |         3 |       30 |        50
+        3 |        30 |       50 |        60
+        5 |        30 |       60 |    999999
+(5 rows)
+
+-- restore data as before last update:
+select set_ttdummy(0);
+ set_ttdummy 
+-------------
+           1
+(1 row)
+
+delete from tttest where price_id = 5;
+update tttest set price_off = 999999 where price_val = 30;
+select * from tttest order by price_id, price_val;
+ price_id | price_val | price_on | price_off 
+----------+-----------+----------+-----------
+        1 |         1 |       10 |    999999
+        2 |         2 |       20 |        40
+        3 |         3 |       30 |        50
+        3 |        30 |       50 |    999999
+(4 rows)
+
+-- and try change price_id now!
+update tttest set price_id = 5 where price_id = 3;
+select * from tttest order by price_id, price_val;
+ price_id | price_val | price_on | price_off 
+----------+-----------+----------+-----------
+        1 |         1 |       10 |    999999
+        2 |         2 |       20 |        40
+        5 |         3 |       30 |        50
+        5 |        30 |       50 |    999999
+(4 rows)
+
+-- isn't it what we need ?
+select set_ttdummy(1);
+ set_ttdummy 
+-------------
+           0
+(1 row)
+
+-- we want to correct some "date"
+update tttest set price_on = -1 where price_id = 1;
+ERROR:  ttdummy (tttest): you cannot change price_on and/or price_off columns (use set_ttdummy)
+-- but this doesn't work
+-- try in this way
+select set_ttdummy(0);
+ set_ttdummy 
+-------------
+           1
+(1 row)
+
+update tttest set price_on = -1 where price_id = 1;
+select * from tttest order by price_id, price_val;
+ price_id | price_val | price_on | price_off 
+----------+-----------+----------+-----------
+        1 |         1 |       -1 |    999999
+        2 |         2 |       20 |        40
+        5 |         3 |       30 |        50
+        5 |        30 |       50 |    999999
+(4 rows)
+
+-- isn't it what we need ?
+-- get price for price_id == 5 as it was @ "date" 35
+select * from tttest where price_on <= 35 and price_off > 35 and price_id = 5;
+ price_id | price_val | price_on | price_off 
+----------+-----------+----------+-----------
+        5 |         3 |       30 |        50
+(1 row)
+
+drop table tttest;
+drop sequence ttdummy_seq;
+--
+-- tests for per-statement triggers
+--
+CREATE TABLE log_table (tstamp timestamp default timeofday()::timestamp);
+CREATE TABLE main_table (a int unique, b int);
+COPY main_table (a,b) FROM stdin;
+CREATE FUNCTION trigger_func() RETURNS trigger LANGUAGE plpgsql AS '
+BEGIN
+	RAISE NOTICE ''trigger_func(%) called: action = %, when = %, level = %'', TG_ARGV[0], TG_OP, TG_WHEN, TG_LEVEL;
+	RETURN NULL;
+END;';
+CREATE TRIGGER before_ins_stmt_trig BEFORE INSERT ON main_table
+FOR EACH STATEMENT EXECUTE PROCEDURE trigger_func('before_ins_stmt');
+CREATE TRIGGER after_ins_stmt_trig AFTER INSERT ON main_table
+FOR EACH STATEMENT EXECUTE PROCEDURE trigger_func('after_ins_stmt');
+--
+-- if neither 'FOR EACH ROW' nor 'FOR EACH STATEMENT' was specified,
+-- CREATE TRIGGER should default to 'FOR EACH STATEMENT'
+--
+CREATE TRIGGER after_upd_stmt_trig AFTER UPDATE ON main_table
+EXECUTE PROCEDURE trigger_func('after_upd_stmt');
+-- Both insert and update statement level triggers (before and after) should
+-- fire.  Doesn't fire UPDATE before trigger, but only because one isn't
+-- defined.
+INSERT INTO main_table (a, b) VALUES (5, 10) ON CONFLICT (a)
+  DO UPDATE SET b = EXCLUDED.b;
+NOTICE:  trigger_func(before_ins_stmt) called: action = INSERT, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(after_upd_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+NOTICE:  trigger_func(after_ins_stmt) called: action = INSERT, when = AFTER, level = STATEMENT
+CREATE TRIGGER after_upd_row_trig AFTER UPDATE ON main_table
+FOR EACH ROW EXECUTE PROCEDURE trigger_func('after_upd_row');
+INSERT INTO main_table DEFAULT VALUES;
+NOTICE:  trigger_func(before_ins_stmt) called: action = INSERT, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(after_ins_stmt) called: action = INSERT, when = AFTER, level = STATEMENT
+UPDATE main_table SET a = a + 1 WHERE b < 30;
+NOTICE:  trigger_func(after_upd_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+-- UPDATE that effects zero rows should still call per-statement trigger
+UPDATE main_table SET a = a + 2 WHERE b > 100;
+NOTICE:  trigger_func(after_upd_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+-- constraint now unneeded
+ALTER TABLE main_table DROP CONSTRAINT main_table_a_key;
+-- COPY should fire per-row and per-statement INSERT triggers
+COPY main_table (a, b) FROM stdin;
+NOTICE:  trigger_func(before_ins_stmt) called: action = INSERT, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(after_ins_stmt) called: action = INSERT, when = AFTER, level = STATEMENT
+SELECT * FROM main_table ORDER BY a, b;
+ a  | b  
+----+----
+  6 | 10
+ 21 | 20
+ 30 | 40
+ 31 | 10
+ 50 | 35
+ 50 | 60
+ 81 | 15
+    |   
+(8 rows)
+
+--
+-- test triggers with WHEN clause
+--
+CREATE TRIGGER modified_a BEFORE UPDATE OF a ON main_table
+FOR EACH ROW WHEN (OLD.a <> NEW.a) EXECUTE PROCEDURE trigger_func('modified_a');
+CREATE TRIGGER modified_any BEFORE UPDATE OF a ON main_table
+FOR EACH ROW WHEN (OLD.* IS DISTINCT FROM NEW.*) EXECUTE PROCEDURE trigger_func('modified_any');
+CREATE TRIGGER insert_a AFTER INSERT ON main_table
+FOR EACH ROW WHEN (NEW.a = 123) EXECUTE PROCEDURE trigger_func('insert_a');
+CREATE TRIGGER delete_a AFTER DELETE ON main_table
+FOR EACH ROW WHEN (OLD.a = 123) EXECUTE PROCEDURE trigger_func('delete_a');
+CREATE TRIGGER insert_when BEFORE INSERT ON main_table
+FOR EACH STATEMENT WHEN (true) EXECUTE PROCEDURE trigger_func('insert_when');
+CREATE TRIGGER delete_when AFTER DELETE ON main_table
+FOR EACH STATEMENT WHEN (true) EXECUTE PROCEDURE trigger_func('delete_when');
+SELECT trigger_name, event_manipulation, event_object_schema, event_object_table,
+       action_order, action_condition, action_orientation, action_timing,
+       action_reference_old_table, action_reference_new_table
+  FROM information_schema.triggers
+  WHERE event_object_table IN ('main_table')
+  ORDER BY trigger_name COLLATE "C", 2;
+     trigger_name     | event_manipulation | event_object_schema | event_object_table | action_order |        action_condition        | action_orientation | action_timing | action_reference_old_table | action_reference_new_table 
+----------------------+--------------------+---------------------+--------------------+--------------+--------------------------------+--------------------+---------------+----------------------------+----------------------------
+ after_ins_stmt_trig  | INSERT             | public              | main_table         |            1 |                                | STATEMENT          | AFTER         |                            | 
+ after_upd_row_trig   | UPDATE             | public              | main_table         |            1 |                                | ROW                | AFTER         |                            | 
+ after_upd_stmt_trig  | UPDATE             | public              | main_table         |            1 |                                | STATEMENT          | AFTER         |                            | 
+ before_ins_stmt_trig | INSERT             | public              | main_table         |            1 |                                | STATEMENT          | BEFORE        |                            | 
+ delete_a             | DELETE             | public              | main_table         |            1 | (old.a = 123)                  | ROW                | AFTER         |                            | 
+ delete_when          | DELETE             | public              | main_table         |            1 | true                           | STATEMENT          | AFTER         |                            | 
+ insert_a             | INSERT             | public              | main_table         |            1 | (new.a = 123)                  | ROW                | AFTER         |                            | 
+ insert_when          | INSERT             | public              | main_table         |            2 | true                           | STATEMENT          | BEFORE        |                            | 
+ modified_a           | UPDATE             | public              | main_table         |            1 | (old.a <> new.a)               | ROW                | BEFORE        |                            | 
+ modified_any         | UPDATE             | public              | main_table         |            2 | (old.* IS DISTINCT FROM new.*) | ROW                | BEFORE        |                            | 
+(10 rows)
+
+INSERT INTO main_table (a) VALUES (123), (456);
+NOTICE:  trigger_func(before_ins_stmt) called: action = INSERT, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(insert_when) called: action = INSERT, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(insert_a) called: action = INSERT, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_ins_stmt) called: action = INSERT, when = AFTER, level = STATEMENT
+COPY main_table FROM stdin;
+NOTICE:  trigger_func(before_ins_stmt) called: action = INSERT, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(insert_when) called: action = INSERT, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(insert_a) called: action = INSERT, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_ins_stmt) called: action = INSERT, when = AFTER, level = STATEMENT
+DELETE FROM main_table WHERE a IN (123, 456);
+NOTICE:  trigger_func(delete_a) called: action = DELETE, when = AFTER, level = ROW
+NOTICE:  trigger_func(delete_a) called: action = DELETE, when = AFTER, level = ROW
+NOTICE:  trigger_func(delete_when) called: action = DELETE, when = AFTER, level = STATEMENT
+UPDATE main_table SET a = 50, b = 60;
+NOTICE:  trigger_func(modified_any) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(modified_any) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(modified_a) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(modified_a) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(modified_a) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(modified_a) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(modified_a) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(after_upd_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+SELECT * FROM main_table ORDER BY a, b;
+ a  | b  
+----+----
+  6 | 10
+ 21 | 20
+ 30 | 40
+ 31 | 10
+ 50 | 35
+ 50 | 60
+ 81 | 15
+    |   
+(8 rows)
+
+SELECT pg_get_triggerdef(oid, true) FROM pg_trigger WHERE tgrelid = 'main_table'::regclass AND tgname = 'modified_a';
+                                                             pg_get_triggerdef                                                             
+-------------------------------------------------------------------------------------------------------------------------------------------
+ CREATE TRIGGER modified_a BEFORE UPDATE OF a ON main_table FOR EACH ROW WHEN (old.a <> new.a) EXECUTE FUNCTION trigger_func('modified_a')
+(1 row)
+
+SELECT pg_get_triggerdef(oid, false) FROM pg_trigger WHERE tgrelid = 'main_table'::regclass AND tgname = 'modified_a';
+                                                                 pg_get_triggerdef                                                                  
+----------------------------------------------------------------------------------------------------------------------------------------------------
+ CREATE TRIGGER modified_a BEFORE UPDATE OF a ON public.main_table FOR EACH ROW WHEN ((old.a <> new.a)) EXECUTE FUNCTION trigger_func('modified_a')
+(1 row)
+
+SELECT pg_get_triggerdef(oid, true) FROM pg_trigger WHERE tgrelid = 'main_table'::regclass AND tgname = 'modified_any';
+                                                                      pg_get_triggerdef                                                                      
+-------------------------------------------------------------------------------------------------------------------------------------------------------------
+ CREATE TRIGGER modified_any BEFORE UPDATE OF a ON main_table FOR EACH ROW WHEN (old.* IS DISTINCT FROM new.*) EXECUTE FUNCTION trigger_func('modified_any')
+(1 row)
+
+-- Test RENAME TRIGGER
+ALTER TRIGGER modified_a ON main_table RENAME TO modified_modified_a;
+SELECT count(*) FROM pg_trigger WHERE tgrelid = 'main_table'::regclass AND tgname = 'modified_a';
+ count 
+-------
+     0
+(1 row)
+
+SELECT count(*) FROM pg_trigger WHERE tgrelid = 'main_table'::regclass AND tgname = 'modified_modified_a';
+ count 
+-------
+     1
+(1 row)
+
+DROP TRIGGER modified_modified_a ON main_table;
+DROP TRIGGER modified_any ON main_table;
+DROP TRIGGER insert_a ON main_table;
+DROP TRIGGER delete_a ON main_table;
+DROP TRIGGER insert_when ON main_table;
+DROP TRIGGER delete_when ON main_table;
+-- Test WHEN condition accessing system columns.
+create table table_with_oids(a int);
+insert into table_with_oids values (1);
+create trigger oid_unchanged_trig after update on table_with_oids
+	for each row
+	when (new.tableoid = old.tableoid AND new.tableoid <> 0)
+	execute procedure trigger_func('after_upd_oid_unchanged');
+update table_with_oids set a = a + 1;
+NOTICE:  trigger_func(after_upd_oid_unchanged) called: action = UPDATE, when = AFTER, level = ROW
+drop table table_with_oids;
+-- Test column-level triggers
+DROP TRIGGER after_upd_row_trig ON main_table;
+CREATE TRIGGER before_upd_a_row_trig BEFORE UPDATE OF a ON main_table
+FOR EACH ROW EXECUTE PROCEDURE trigger_func('before_upd_a_row');
+CREATE TRIGGER after_upd_b_row_trig AFTER UPDATE OF b ON main_table
+FOR EACH ROW EXECUTE PROCEDURE trigger_func('after_upd_b_row');
+CREATE TRIGGER after_upd_a_b_row_trig AFTER UPDATE OF a, b ON main_table
+FOR EACH ROW EXECUTE PROCEDURE trigger_func('after_upd_a_b_row');
+CREATE TRIGGER before_upd_a_stmt_trig BEFORE UPDATE OF a ON main_table
+FOR EACH STATEMENT EXECUTE PROCEDURE trigger_func('before_upd_a_stmt');
+CREATE TRIGGER after_upd_b_stmt_trig AFTER UPDATE OF b ON main_table
+FOR EACH STATEMENT EXECUTE PROCEDURE trigger_func('after_upd_b_stmt');
+SELECT pg_get_triggerdef(oid) FROM pg_trigger WHERE tgrelid = 'main_table'::regclass AND tgname = 'after_upd_a_b_row_trig';
+                                                                pg_get_triggerdef                                                                
+-------------------------------------------------------------------------------------------------------------------------------------------------
+ CREATE TRIGGER after_upd_a_b_row_trig AFTER UPDATE OF a, b ON public.main_table FOR EACH ROW EXECUTE FUNCTION trigger_func('after_upd_a_b_row')
+(1 row)
+
+UPDATE main_table SET a = 50;
+NOTICE:  trigger_func(before_upd_a_stmt) called: action = UPDATE, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(before_upd_a_row) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(before_upd_a_row) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(before_upd_a_row) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(before_upd_a_row) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(before_upd_a_row) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(before_upd_a_row) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(before_upd_a_row) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(before_upd_a_row) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(after_upd_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+UPDATE main_table SET b = 10;
+NOTICE:  trigger_func(after_upd_a_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_a_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_a_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_a_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_a_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_a_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_a_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_a_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_b_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+NOTICE:  trigger_func(after_upd_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+--
+-- Test case for bug with BEFORE trigger followed by AFTER trigger with WHEN
+--
+CREATE TABLE some_t (some_col boolean NOT NULL);
+CREATE FUNCTION dummy_update_func() RETURNS trigger AS $$
+BEGIN
+  RAISE NOTICE 'dummy_update_func(%) called: action = %, old = %, new = %',
+    TG_ARGV[0], TG_OP, OLD, NEW;
+  RETURN NEW;
+END;
+$$ LANGUAGE plpgsql;
+CREATE TRIGGER some_trig_before BEFORE UPDATE ON some_t FOR EACH ROW
+  EXECUTE PROCEDURE dummy_update_func('before');
+CREATE TRIGGER some_trig_aftera AFTER UPDATE ON some_t FOR EACH ROW
+  WHEN (NOT OLD.some_col AND NEW.some_col)
+  EXECUTE PROCEDURE dummy_update_func('aftera');
+CREATE TRIGGER some_trig_afterb AFTER UPDATE ON some_t FOR EACH ROW
+  WHEN (NOT NEW.some_col)
+  EXECUTE PROCEDURE dummy_update_func('afterb');
+INSERT INTO some_t VALUES (TRUE);
+UPDATE some_t SET some_col = TRUE;
+NOTICE:  dummy_update_func(before) called: action = UPDATE, old = (t), new = (t)
+UPDATE some_t SET some_col = FALSE;
+NOTICE:  dummy_update_func(before) called: action = UPDATE, old = (t), new = (f)
+NOTICE:  dummy_update_func(afterb) called: action = UPDATE, old = (t), new = (f)
+UPDATE some_t SET some_col = TRUE;
+NOTICE:  dummy_update_func(before) called: action = UPDATE, old = (f), new = (t)
+NOTICE:  dummy_update_func(aftera) called: action = UPDATE, old = (f), new = (t)
+DROP TABLE some_t;
+-- bogus cases
+CREATE TRIGGER error_upd_and_col BEFORE UPDATE OR UPDATE OF a ON main_table
+FOR EACH ROW EXECUTE PROCEDURE trigger_func('error_upd_and_col');
+ERROR:  duplicate trigger events specified at or near "ON"
+LINE 1: ...ER error_upd_and_col BEFORE UPDATE OR UPDATE OF a ON main_ta...
+                                                             ^
+CREATE TRIGGER error_upd_a_a BEFORE UPDATE OF a, a ON main_table
+FOR EACH ROW EXECUTE PROCEDURE trigger_func('error_upd_a_a');
+ERROR:  column "a" specified more than once
+CREATE TRIGGER error_ins_a BEFORE INSERT OF a ON main_table
+FOR EACH ROW EXECUTE PROCEDURE trigger_func('error_ins_a');
+ERROR:  syntax error at or near "OF"
+LINE 1: CREATE TRIGGER error_ins_a BEFORE INSERT OF a ON main_table
+                                                 ^
+CREATE TRIGGER error_ins_when BEFORE INSERT OR UPDATE ON main_table
+FOR EACH ROW WHEN (OLD.a <> NEW.a)
+EXECUTE PROCEDURE trigger_func('error_ins_old');
+ERROR:  INSERT trigger's WHEN condition cannot reference OLD values
+LINE 2: FOR EACH ROW WHEN (OLD.a <> NEW.a)
+                           ^
+CREATE TRIGGER error_del_when BEFORE DELETE OR UPDATE ON main_table
+FOR EACH ROW WHEN (OLD.a <> NEW.a)
+EXECUTE PROCEDURE trigger_func('error_del_new');
+ERROR:  DELETE trigger's WHEN condition cannot reference NEW values
+LINE 2: FOR EACH ROW WHEN (OLD.a <> NEW.a)
+                                    ^
+CREATE TRIGGER error_del_when BEFORE INSERT OR UPDATE ON main_table
+FOR EACH ROW WHEN (NEW.tableoid <> 0)
+EXECUTE PROCEDURE trigger_func('error_when_sys_column');
+ERROR:  BEFORE trigger's WHEN condition cannot reference NEW system columns
+LINE 2: FOR EACH ROW WHEN (NEW.tableoid <> 0)
+                           ^
+CREATE TRIGGER error_stmt_when BEFORE UPDATE OF a ON main_table
+FOR EACH STATEMENT WHEN (OLD.* IS DISTINCT FROM NEW.*)
+EXECUTE PROCEDURE trigger_func('error_stmt_when');
+ERROR:  statement trigger's WHEN condition cannot reference column values
+LINE 2: FOR EACH STATEMENT WHEN (OLD.* IS DISTINCT FROM NEW.*)
+                                 ^
+-- check dependency restrictions
+ALTER TABLE main_table DROP COLUMN b;
+ERROR:  cannot drop column b of table main_table because other objects depend on it
+DETAIL:  trigger after_upd_b_row_trig on table main_table depends on column b of table main_table
+trigger after_upd_a_b_row_trig on table main_table depends on column b of table main_table
+trigger after_upd_b_stmt_trig on table main_table depends on column b of table main_table
+HINT:  Use DROP ... CASCADE to drop the dependent objects too.
+-- this should succeed, but we'll roll it back to keep the triggers around
+begin;
+DROP TRIGGER after_upd_a_b_row_trig ON main_table;
+DROP TRIGGER after_upd_b_row_trig ON main_table;
+DROP TRIGGER after_upd_b_stmt_trig ON main_table;
+ALTER TABLE main_table DROP COLUMN b;
+rollback;
+-- Test enable/disable triggers
+create table trigtest (i serial primary key);
+-- test that disabling RI triggers works
+create table trigtest2 (i int references trigtest(i) on delete cascade);
+create function trigtest() returns trigger as $$
+begin
+	raise notice '% % % %', TG_RELNAME, TG_OP, TG_WHEN, TG_LEVEL;
+	return new;
+end;$$ language plpgsql;
+create trigger trigtest_b_row_tg before insert or update or delete on trigtest
+for each row execute procedure trigtest();
+create trigger trigtest_a_row_tg after insert or update or delete on trigtest
+for each row execute procedure trigtest();
+create trigger trigtest_b_stmt_tg before insert or update or delete on trigtest
+for each statement execute procedure trigtest();
+create trigger trigtest_a_stmt_tg after insert or update or delete on trigtest
+for each statement execute procedure trigtest();
+insert into trigtest default values;
+NOTICE:  trigtest INSERT BEFORE STATEMENT
+NOTICE:  trigtest INSERT BEFORE ROW
+NOTICE:  trigtest INSERT AFTER ROW
+NOTICE:  trigtest INSERT AFTER STATEMENT
+alter table trigtest disable trigger trigtest_b_row_tg;
+insert into trigtest default values;
+NOTICE:  trigtest INSERT BEFORE STATEMENT
+NOTICE:  trigtest INSERT AFTER ROW
+NOTICE:  trigtest INSERT AFTER STATEMENT
+alter table trigtest disable trigger user;
+insert into trigtest default values;
+alter table trigtest enable trigger trigtest_a_stmt_tg;
+insert into trigtest default values;
+NOTICE:  trigtest INSERT AFTER STATEMENT
+set session_replication_role = replica;
+insert into trigtest default values;  -- does not trigger
+alter table trigtest enable always trigger trigtest_a_stmt_tg;
+insert into trigtest default values;  -- now it does
+NOTICE:  trigtest INSERT AFTER STATEMENT
+reset session_replication_role;
+insert into trigtest2 values(1);
+insert into trigtest2 values(2);
+delete from trigtest where i=2;
+NOTICE:  trigtest DELETE AFTER STATEMENT
+select * from trigtest2;
+ i 
+---
+ 1
+(1 row)
+
+alter table trigtest disable trigger all;
+delete from trigtest where i=1;
+select * from trigtest2;
+ i 
+---
+ 1
+(1 row)
+
+-- ensure we still insert, even when all triggers are disabled
+insert into trigtest default values;
+select *  from trigtest;
+ i 
+---
+ 3
+ 4
+ 5
+ 6
+ 7
+(5 rows)
+
+drop table trigtest2;
+drop table trigtest;
+-- dump trigger data
+CREATE TABLE trigger_test (
+        i int,
+        v varchar
+);
+CREATE OR REPLACE FUNCTION trigger_data()  RETURNS trigger
+LANGUAGE plpgsql AS $$
+
+declare
+
+	argstr text;
+	relid text;
+
+begin
+
+	relid := TG_relid::regclass;
+
+	-- plpgsql can't discover its trigger data in a hash like perl and python
+	-- can, or by a sort of reflection like tcl can,
+	-- so we have to hard code the names.
+	raise NOTICE 'TG_NAME: %', TG_name;
+	raise NOTICE 'TG_WHEN: %', TG_when;
+	raise NOTICE 'TG_LEVEL: %', TG_level;
+	raise NOTICE 'TG_OP: %', TG_op;
+	raise NOTICE 'TG_RELID::regclass: %', relid;
+	raise NOTICE 'TG_RELNAME: %', TG_relname;
+	raise NOTICE 'TG_TABLE_NAME: %', TG_table_name;
+	raise NOTICE 'TG_TABLE_SCHEMA: %', TG_table_schema;
+	raise NOTICE 'TG_NARGS: %', TG_nargs;
+
+	argstr := '[';
+	for i in 0 .. TG_nargs - 1 loop
+		if i > 0 then
+			argstr := argstr || ', ';
+		end if;
+		argstr := argstr || TG_argv[i];
+	end loop;
+	argstr := argstr || ']';
+	raise NOTICE 'TG_ARGV: %', argstr;
+
+	if TG_OP != 'INSERT' then
+		raise NOTICE 'OLD: %', OLD;
+	end if;
+
+	if TG_OP != 'DELETE' then
+		raise NOTICE 'NEW: %', NEW;
+	end if;
+
+	if TG_OP = 'DELETE' then
+		return OLD;
+	else
+		return NEW;
+	end if;
+
+end;
+$$;
+CREATE TRIGGER show_trigger_data_trig
+BEFORE INSERT OR UPDATE OR DELETE ON trigger_test
+FOR EACH ROW EXECUTE PROCEDURE trigger_data(23,'skidoo');
+insert into trigger_test values(1,'insert');
+NOTICE:  TG_NAME: show_trigger_data_trig
+NOTICE:  TG_WHEN: BEFORE
+NOTICE:  TG_LEVEL: ROW
+NOTICE:  TG_OP: INSERT
+NOTICE:  TG_RELID::regclass: trigger_test
+NOTICE:  TG_RELNAME: trigger_test
+NOTICE:  TG_TABLE_NAME: trigger_test
+NOTICE:  TG_TABLE_SCHEMA: public
+NOTICE:  TG_NARGS: 2
+NOTICE:  TG_ARGV: [23, skidoo]
+NOTICE:  NEW: (1,insert)
+update trigger_test set v = 'update' where i = 1;
+NOTICE:  TG_NAME: show_trigger_data_trig
+NOTICE:  TG_WHEN: BEFORE
+NOTICE:  TG_LEVEL: ROW
+NOTICE:  TG_OP: UPDATE
+NOTICE:  TG_RELID::regclass: trigger_test
+NOTICE:  TG_RELNAME: trigger_test
+NOTICE:  TG_TABLE_NAME: trigger_test
+NOTICE:  TG_TABLE_SCHEMA: public
+NOTICE:  TG_NARGS: 2
+NOTICE:  TG_ARGV: [23, skidoo]
+NOTICE:  OLD: (1,insert)
+NOTICE:  NEW: (1,update)
+delete from trigger_test;
+NOTICE:  TG_NAME: show_trigger_data_trig
+NOTICE:  TG_WHEN: BEFORE
+NOTICE:  TG_LEVEL: ROW
+NOTICE:  TG_OP: DELETE
+NOTICE:  TG_RELID::regclass: trigger_test
+NOTICE:  TG_RELNAME: trigger_test
+NOTICE:  TG_TABLE_NAME: trigger_test
+NOTICE:  TG_TABLE_SCHEMA: public
+NOTICE:  TG_NARGS: 2
+NOTICE:  TG_ARGV: [23, skidoo]
+NOTICE:  OLD: (1,update)
+DROP TRIGGER show_trigger_data_trig on trigger_test;
+DROP FUNCTION trigger_data();
+DROP TABLE trigger_test;
+--
+-- Test use of row comparisons on OLD/NEW
+--
+CREATE TABLE trigger_test (f1 int, f2 text, f3 text);
+-- this is the obvious (and wrong...) way to compare rows
+CREATE FUNCTION mytrigger() RETURNS trigger LANGUAGE plpgsql as $$
+begin
+	if row(old.*) = row(new.*) then
+		raise notice 'row % not changed', new.f1;
+	else
+		raise notice 'row % changed', new.f1;
+	end if;
+	return new;
+end$$;
+CREATE TRIGGER t
+BEFORE UPDATE ON trigger_test
+FOR EACH ROW EXECUTE PROCEDURE mytrigger();
+INSERT INTO trigger_test VALUES(1, 'foo', 'bar');
+INSERT INTO trigger_test VALUES(2, 'baz', 'quux');
+UPDATE trigger_test SET f3 = 'bar';
+NOTICE:  row 1 not changed
+NOTICE:  row 2 changed
+UPDATE trigger_test SET f3 = NULL;
+NOTICE:  row 1 changed
+NOTICE:  row 2 changed
+-- this demonstrates that the above isn't really working as desired:
+UPDATE trigger_test SET f3 = NULL;
+NOTICE:  row 1 changed
+NOTICE:  row 2 changed
+-- the right way when considering nulls is
+CREATE OR REPLACE FUNCTION mytrigger() RETURNS trigger LANGUAGE plpgsql as $$
+begin
+	if row(old.*) is distinct from row(new.*) then
+		raise notice 'row % changed', new.f1;
+	else
+		raise notice 'row % not changed', new.f1;
+	end if;
+	return new;
+end$$;
+UPDATE trigger_test SET f3 = 'bar';
+NOTICE:  row 1 changed
+NOTICE:  row 2 changed
+UPDATE trigger_test SET f3 = NULL;
+NOTICE:  row 1 changed
+NOTICE:  row 2 changed
+UPDATE trigger_test SET f3 = NULL;
+NOTICE:  row 1 not changed
+NOTICE:  row 2 not changed
+DROP TABLE trigger_test;
+DROP FUNCTION mytrigger();
+-- Test snapshot management in serializable transactions involving triggers
+-- per bug report in 6bc73d4c0910042358k3d1adff3qa36f8df75198ecea@mail.gmail.com
+CREATE FUNCTION serializable_update_trig() RETURNS trigger LANGUAGE plpgsql AS
+$$
+declare
+	rec record;
+begin
+	new.description = 'updated in trigger';
+	return new;
+end;
+$$;
+CREATE TABLE serializable_update_tab (
+	id int,
+	filler  text,
+	description text
+);
+CREATE TRIGGER serializable_update_trig BEFORE UPDATE ON serializable_update_tab
+	FOR EACH ROW EXECUTE PROCEDURE serializable_update_trig();
+INSERT INTO serializable_update_tab SELECT a, repeat('xyzxz', 100), 'new'
+	FROM generate_series(1, 50) a;
+BEGIN;
+SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;
+UPDATE serializable_update_tab SET description = 'no no', id = 1 WHERE id = 1;
+COMMIT;
+SELECT description FROM serializable_update_tab WHERE id = 1;
+    description     
+--------------------
+ updated in trigger
+(1 row)
+
+DROP TABLE serializable_update_tab;
+-- minimal update trigger
+CREATE TABLE min_updates_test (
+	f1	text,
+	f2 int,
+	f3 int);
+INSERT INTO min_updates_test VALUES ('a',1,2),('b','2',null);
+CREATE TRIGGER z_min_update
+BEFORE UPDATE ON min_updates_test
+FOR EACH ROW EXECUTE PROCEDURE suppress_redundant_updates_trigger();
+\set QUIET false
+UPDATE min_updates_test SET f1 = f1;
+UPDATE 0
+UPDATE min_updates_test SET f2 = f2 + 1;
+UPDATE 2
+UPDATE min_updates_test SET f3 = 2 WHERE f3 is null;
+UPDATE 1
+\set QUIET true
+SELECT * FROM min_updates_test;
+ f1 | f2 | f3 
+----+----+----
+ a  |  2 |  2
+ b  |  3 |  2
+(2 rows)
+
+DROP TABLE min_updates_test;
+--
+-- Test triggers on views
+--
+CREATE VIEW main_view AS SELECT a, b FROM main_table;
+-- VIEW trigger function
+CREATE OR REPLACE FUNCTION view_trigger() RETURNS trigger
+LANGUAGE plpgsql AS $$
+declare
+    argstr text := '';
+begin
+    for i in 0 .. TG_nargs - 1 loop
+        if i > 0 then
+            argstr := argstr || ', ';
+        end if;
+        argstr := argstr || TG_argv[i];
+    end loop;
+
+    raise notice '% % % % (%)', TG_RELNAME, TG_WHEN, TG_OP, TG_LEVEL, argstr;
+
+    if TG_LEVEL = 'ROW' then
+        if TG_OP = 'INSERT' then
+            raise NOTICE 'NEW: %', NEW;
+            INSERT INTO main_table VALUES (NEW.a, NEW.b);
+            RETURN NEW;
+        end if;
+
+        if TG_OP = 'UPDATE' then
+            raise NOTICE 'OLD: %, NEW: %', OLD, NEW;
+            UPDATE main_table SET a = NEW.a, b = NEW.b WHERE a = OLD.a AND b = OLD.b;
+            if NOT FOUND then RETURN NULL; end if;
+            RETURN NEW;
+        end if;
+
+        if TG_OP = 'DELETE' then
+            insert into tmp_del_table values (OLD);
+            DELETE FROM main_table WHERE a = OLD.a AND b = OLD.b;
+            if NOT FOUND then RETURN NULL; end if;
+            RETURN OLD;
+        end if;
+    end if;
+
+    RETURN NULL;
+end;
+$$;
+-- Before row triggers aren't allowed on views
+CREATE TRIGGER invalid_trig BEFORE INSERT ON main_view
+FOR EACH ROW EXECUTE PROCEDURE trigger_func('before_ins_row');
+ERROR:  "main_view" is a view
+DETAIL:  Views cannot have row-level BEFORE or AFTER triggers.
+CREATE TRIGGER invalid_trig BEFORE UPDATE ON main_view
+FOR EACH ROW EXECUTE PROCEDURE trigger_func('before_upd_row');
+ERROR:  "main_view" is a view
+DETAIL:  Views cannot have row-level BEFORE or AFTER triggers.
+CREATE TRIGGER invalid_trig BEFORE DELETE ON main_view
+FOR EACH ROW EXECUTE PROCEDURE trigger_func('before_del_row');
+ERROR:  "main_view" is a view
+DETAIL:  Views cannot have row-level BEFORE or AFTER triggers.
+-- After row triggers aren't allowed on views
+CREATE TRIGGER invalid_trig AFTER INSERT ON main_view
+FOR EACH ROW EXECUTE PROCEDURE trigger_func('before_ins_row');
+ERROR:  "main_view" is a view
+DETAIL:  Views cannot have row-level BEFORE or AFTER triggers.
+CREATE TRIGGER invalid_trig AFTER UPDATE ON main_view
+FOR EACH ROW EXECUTE PROCEDURE trigger_func('before_upd_row');
+ERROR:  "main_view" is a view
+DETAIL:  Views cannot have row-level BEFORE or AFTER triggers.
+CREATE TRIGGER invalid_trig AFTER DELETE ON main_view
+FOR EACH ROW EXECUTE PROCEDURE trigger_func('before_del_row');
+ERROR:  "main_view" is a view
+DETAIL:  Views cannot have row-level BEFORE or AFTER triggers.
+-- Truncate triggers aren't allowed on views
+CREATE TRIGGER invalid_trig BEFORE TRUNCATE ON main_view
+EXECUTE PROCEDURE trigger_func('before_tru_row');
+ERROR:  "main_view" is a view
+DETAIL:  Views cannot have TRUNCATE triggers.
+CREATE TRIGGER invalid_trig AFTER TRUNCATE ON main_view
+EXECUTE PROCEDURE trigger_func('before_tru_row');
+ERROR:  "main_view" is a view
+DETAIL:  Views cannot have TRUNCATE triggers.
+-- INSTEAD OF triggers aren't allowed on tables
+CREATE TRIGGER invalid_trig INSTEAD OF INSERT ON main_table
+FOR EACH ROW EXECUTE PROCEDURE view_trigger('instead_of_ins');
+ERROR:  "main_table" is a table
+DETAIL:  Tables cannot have INSTEAD OF triggers.
+CREATE TRIGGER invalid_trig INSTEAD OF UPDATE ON main_table
+FOR EACH ROW EXECUTE PROCEDURE view_trigger('instead_of_upd');
+ERROR:  "main_table" is a table
+DETAIL:  Tables cannot have INSTEAD OF triggers.
+CREATE TRIGGER invalid_trig INSTEAD OF DELETE ON main_table
+FOR EACH ROW EXECUTE PROCEDURE view_trigger('instead_of_del');
+ERROR:  "main_table" is a table
+DETAIL:  Tables cannot have INSTEAD OF triggers.
+-- Don't support WHEN clauses with INSTEAD OF triggers
+CREATE TRIGGER invalid_trig INSTEAD OF UPDATE ON main_view
+FOR EACH ROW WHEN (OLD.a <> NEW.a) EXECUTE PROCEDURE view_trigger('instead_of_upd');
+ERROR:  INSTEAD OF triggers cannot have WHEN conditions
+-- Don't support column-level INSTEAD OF triggers
+CREATE TRIGGER invalid_trig INSTEAD OF UPDATE OF a ON main_view
+FOR EACH ROW EXECUTE PROCEDURE view_trigger('instead_of_upd');
+ERROR:  INSTEAD OF triggers cannot have column lists
+-- Don't support statement-level INSTEAD OF triggers
+CREATE TRIGGER invalid_trig INSTEAD OF UPDATE ON main_view
+EXECUTE PROCEDURE view_trigger('instead_of_upd');
+ERROR:  INSTEAD OF triggers must be FOR EACH ROW
+-- Valid INSTEAD OF triggers
+CREATE TRIGGER instead_of_insert_trig INSTEAD OF INSERT ON main_view
+FOR EACH ROW EXECUTE PROCEDURE view_trigger('instead_of_ins');
+CREATE TRIGGER instead_of_update_trig INSTEAD OF UPDATE ON main_view
+FOR EACH ROW EXECUTE PROCEDURE view_trigger('instead_of_upd');
+CREATE TRIGGER instead_of_delete_trig INSTEAD OF DELETE ON main_view
+FOR EACH ROW EXECUTE PROCEDURE view_trigger('instead_of_del');
+-- Valid BEFORE statement VIEW triggers
+CREATE TRIGGER before_ins_stmt_trig BEFORE INSERT ON main_view
+FOR EACH STATEMENT EXECUTE PROCEDURE view_trigger('before_view_ins_stmt');
+CREATE TRIGGER before_upd_stmt_trig BEFORE UPDATE ON main_view
+FOR EACH STATEMENT EXECUTE PROCEDURE view_trigger('before_view_upd_stmt');
+CREATE TRIGGER before_del_stmt_trig BEFORE DELETE ON main_view
+FOR EACH STATEMENT EXECUTE PROCEDURE view_trigger('before_view_del_stmt');
+-- Valid AFTER statement VIEW triggers
+CREATE TRIGGER after_ins_stmt_trig AFTER INSERT ON main_view
+FOR EACH STATEMENT EXECUTE PROCEDURE view_trigger('after_view_ins_stmt');
+CREATE TRIGGER after_upd_stmt_trig AFTER UPDATE ON main_view
+FOR EACH STATEMENT EXECUTE PROCEDURE view_trigger('after_view_upd_stmt');
+CREATE TRIGGER after_del_stmt_trig AFTER DELETE ON main_view
+FOR EACH STATEMENT EXECUTE PROCEDURE view_trigger('after_view_del_stmt');
+\set QUIET false
+-- Insert into view using trigger
+INSERT INTO main_view VALUES (20, 30);
+NOTICE:  main_view BEFORE INSERT STATEMENT (before_view_ins_stmt)
+NOTICE:  main_view INSTEAD OF INSERT ROW (instead_of_ins)
+NOTICE:  NEW: (20,30)
+NOTICE:  trigger_func(before_ins_stmt) called: action = INSERT, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(after_ins_stmt) called: action = INSERT, when = AFTER, level = STATEMENT
+NOTICE:  main_view AFTER INSERT STATEMENT (after_view_ins_stmt)
+INSERT 0 1
+INSERT INTO main_view VALUES (21, 31) RETURNING a, b;
+NOTICE:  main_view BEFORE INSERT STATEMENT (before_view_ins_stmt)
+NOTICE:  main_view INSTEAD OF INSERT ROW (instead_of_ins)
+NOTICE:  NEW: (21,31)
+NOTICE:  trigger_func(before_ins_stmt) called: action = INSERT, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(after_ins_stmt) called: action = INSERT, when = AFTER, level = STATEMENT
+NOTICE:  main_view AFTER INSERT STATEMENT (after_view_ins_stmt)
+ a  | b  
+----+----
+ 21 | 31
+(1 row)
+
+INSERT 0 1
+-- Table trigger will prevent updates
+UPDATE main_view SET b = 31 WHERE a = 20;
+NOTICE:  main_view BEFORE UPDATE STATEMENT (before_view_upd_stmt)
+NOTICE:  main_view INSTEAD OF UPDATE ROW (instead_of_upd)
+NOTICE:  OLD: (20,30), NEW: (20,31)
+NOTICE:  trigger_func(before_upd_a_stmt) called: action = UPDATE, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(before_upd_a_row) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(after_upd_b_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+NOTICE:  trigger_func(after_upd_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+NOTICE:  main_view AFTER UPDATE STATEMENT (after_view_upd_stmt)
+UPDATE 0
+UPDATE main_view SET b = 32 WHERE a = 21 AND b = 31 RETURNING a, b;
+NOTICE:  main_view BEFORE UPDATE STATEMENT (before_view_upd_stmt)
+NOTICE:  main_view INSTEAD OF UPDATE ROW (instead_of_upd)
+NOTICE:  OLD: (21,31), NEW: (21,32)
+NOTICE:  trigger_func(before_upd_a_stmt) called: action = UPDATE, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(before_upd_a_row) called: action = UPDATE, when = BEFORE, level = ROW
+NOTICE:  trigger_func(after_upd_b_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+NOTICE:  trigger_func(after_upd_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+NOTICE:  main_view AFTER UPDATE STATEMENT (after_view_upd_stmt)
+ a | b 
+---+---
+(0 rows)
+
+UPDATE 0
+-- Remove table trigger to allow updates
+DROP TRIGGER before_upd_a_row_trig ON main_table;
+DROP TRIGGER
+UPDATE main_view SET b = 31 WHERE a = 20;
+NOTICE:  main_view BEFORE UPDATE STATEMENT (before_view_upd_stmt)
+NOTICE:  main_view INSTEAD OF UPDATE ROW (instead_of_upd)
+NOTICE:  OLD: (20,30), NEW: (20,31)
+NOTICE:  trigger_func(before_upd_a_stmt) called: action = UPDATE, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(after_upd_a_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_b_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+NOTICE:  trigger_func(after_upd_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+NOTICE:  main_view AFTER UPDATE STATEMENT (after_view_upd_stmt)
+UPDATE 1
+UPDATE main_view SET b = 32 WHERE a = 21 AND b = 31 RETURNING a, b;
+NOTICE:  main_view BEFORE UPDATE STATEMENT (before_view_upd_stmt)
+NOTICE:  main_view INSTEAD OF UPDATE ROW (instead_of_upd)
+NOTICE:  OLD: (21,31), NEW: (21,32)
+NOTICE:  trigger_func(before_upd_a_stmt) called: action = UPDATE, when = BEFORE, level = STATEMENT
+NOTICE:  trigger_func(after_upd_a_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_b_row) called: action = UPDATE, when = AFTER, level = ROW
+NOTICE:  trigger_func(after_upd_b_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+NOTICE:  trigger_func(after_upd_stmt) called: action = UPDATE, when = AFTER, level = STATEMENT
+NOTICE:  main_view AFTER UPDATE STATEMENT (after_view_upd_stmt)
+ a  | b  
+----+----
+ 21 | 32
+(1 row)
+
+UPDATE 1
+-- Before and after stmt triggers should fire even when no rows are affected
+UPDATE main_view SET b = 0 WHERE false;
+NOTICE:  main_view BEFORE UPDATE STATEMENT (before_view_upd_stmt)
+NOTICE:  main_view AFTER UPDATE STATEMENT (after_view_upd_stmt)
+UPDATE 0
+-- Delete from view using trigger
+DELETE FROM main_view WHERE a IN (20,21);
+NOTICE:  main_view BEFORE DELETE STATEMENT (before_view_del_stmt)
+NOTICE:  main_view INSTEAD OF DELETE ROW (instead_of_del)
+NOTICE:  main_view INSTEAD OF DELETE ROW (instead_of_del)
+NOTICE:  main_view INSTEAD OF DELETE ROW (instead_of_del)
+NOTICE:  main_view AFTER DELETE STATEMENT (after_view_del_stmt)
+DELETE 3
+select * from tmp_del_table order by 1;
+    a    
+---------
+ (20,31)
+ (21,10)
+ (21,32)
+(3 rows)
+
+truncate table tmp_del_table;
+TRUNCATE TABLE
+DELETE FROM main_view WHERE a = 31 RETURNING a, b;
+NOTICE:  main_view BEFORE DELETE STATEMENT (before_view_del_stmt)
+NOTICE:  main_view INSTEAD OF DELETE ROW (instead_of_del)
+NOTICE:  main_view AFTER DELETE STATEMENT (after_view_del_stmt)
+ a  | b  
+----+----
+ 31 | 10
+(1 row)
+
+DELETE 1
+select * from tmp_del_table order by 1;
+    a    
+---------
+ (31,10)
+(1 row)
+
+truncate table tmp_del_table;
+TRUNCATE TABLE
+\set QUIET true
+-- Describe view should list triggers
+\d main_view
+              View "public.main_view"
+ Column |  Type   | Collation | Nullable | Default 
+--------+---------+-----------+----------+---------
+ a      | integer |           |          | 
+ b      | integer |           |          | 
+Triggers:
+    after_del_stmt_trig AFTER DELETE ON main_view FOR EACH STATEMENT EXECUTE FUNCTION view_trigger('after_view_del_stmt')
+    after_ins_stmt_trig AFTER INSERT ON main_view FOR EACH STATEMENT EXECUTE FUNCTION view_trigger('after_view_ins_stmt')
+    after_upd_stmt_trig AFTER UPDATE ON main_view FOR EACH STATEMENT EXECUTE FUNCTION view_trigger('after_view_upd_stmt')
+    before_del_stmt_trig BEFORE DELETE ON main_view FOR EACH STATEMENT EXECUTE FUNCTION view_trigger('before_view_del_stmt')
+    before_ins_stmt_trig BEFORE INSERT ON main_view FOR EACH STATEMENT EXECUTE FUNCTION view_trigger('before_view_ins_stmt')
+    before_upd_stmt_trig BEFORE UPDATE ON main_view FOR EACH STATEMENT EXECUTE FUNCTION view_trigger('before_view_upd_stmt')
+    instead_of_delete_trig INSTEAD OF DELETE ON main_view FOR EACH ROW EXECUTE FUNCTION view_trigger('instead_of_del')
+    instead_of_insert_trig INSTEAD OF INSERT ON main_view FOR EACH ROW EXECUTE FUNCTION view_trigger('instead_of_ins')
+    instead_of_update_trig INSTEAD OF UPDATE ON main_view FOR EACH ROW EXECUTE FUNCTION view_trigger('instead_of_upd')
+
+-- Test dropping view triggers
+DROP TRIGGER instead_of_insert_trig ON main_view;
+DROP TRIGGER instead_of_delete_trig ON main_view;
+\d+ main_view
+                          View "public.main_view"
+ Column |  Type   | Collation | Nullable | Default | Storage | Description 
+--------+---------+-----------+----------+---------+---------+-------------
+ a      | integer |           |          |         | plain   | 
+ b      | integer |           |          |         | plain   | 
+View definition:
+ SELECT main_table.a,
+    main_table.b
+   FROM main_table;
+Triggers:
+    after_del_stmt_trig AFTER DELETE ON main_view FOR EACH STATEMENT EXECUTE FUNCTION view_trigger('after_view_del_stmt')
+    after_ins_stmt_trig AFTER INSERT ON main_view FOR EACH STATEMENT EXECUTE FUNCTION view_trigger('after_view_ins_stmt')
+    after_upd_stmt_trig AFTER UPDATE ON main_view FOR EACH STATEMENT EXECUTE FUNCTION view_trigger('after_view_upd_stmt')
+    before_del_stmt_trig BEFORE DELETE ON main_view FOR EACH STATEMENT EXECUTE FUNCTION view_trigger('before_view_del_stmt')
+    before_ins_stmt_trig BEFORE INSERT ON main_view FOR EACH STATEMENT EXECUTE FUNCTION view_trigger('before_view_ins_stmt')
+    before_upd_stmt_trig BEFORE UPDATE ON main_view FOR EACH STATEMENT EXECUTE FUNCTION view_trigger('before_view_upd_stmt')
+    instead_of_update_trig INSTEAD OF UPDATE ON main_view FOR EACH ROW EXECUTE FUNCTION view_trigger('instead_of_upd')
+
+DROP VIEW main_view;
+--
+-- Test triggers on a join view
+--
+CREATE TABLE country_table (
+    country_id        serial primary key,
+    country_name    text unique not null,
+    continent        text not null
+);
+INSERT INTO country_table (country_name, continent)
+    VALUES ('Japan', 'Asia'),
+           ('UK', 'Europe'),
+           ('USA', 'North America')
+    RETURNING *;
+ country_id | country_name |   continent   
+------------+--------------+---------------
+          1 | Japan        | Asia
+          2 | UK           | Europe
+          3 | USA          | North America
+(3 rows)
+
+CREATE TABLE city_table (
+    city_id        serial primary key,
+    city_name    text not null,
+    population    bigint,
+    country_id    int references country_table
+);
+CREATE VIEW city_view AS
+    SELECT city_id, city_name, population, country_name, continent
+    FROM city_table ci
+    LEFT JOIN country_table co ON co.country_id = ci.country_id;
+CREATE FUNCTION city_insert() RETURNS trigger LANGUAGE plpgsql AS $$
+declare
+    ctry_id int;
+begin
+    if NEW.country_name IS NOT NULL then
+        SELECT country_id, continent INTO ctry_id, NEW.continent
+            FROM country_table WHERE country_name = NEW.country_name;
+        if NOT FOUND then
+            raise exception 'No such country: "%"', NEW.country_name;
+        end if;
+    else
+        NEW.continent := NULL;
+    end if;
+
+    if NEW.city_id IS NOT NULL then
+        INSERT INTO city_table
+            VALUES(NEW.city_id, NEW.city_name, NEW.population, ctry_id);
+    else
+        INSERT INTO city_table(city_name, population, country_id)
+            VALUES(NEW.city_name, NEW.population, ctry_id)
+            RETURNING city_id INTO NEW.city_id;
+    end if;
+
+    RETURN NEW;
+end;
+$$;
+CREATE TRIGGER city_insert_trig INSTEAD OF INSERT ON city_view
+FOR EACH ROW EXECUTE PROCEDURE city_insert();
+CREATE FUNCTION city_delete() RETURNS trigger LANGUAGE plpgsql AS $$
+begin
+    DELETE FROM city_table WHERE city_id = OLD.city_id;
+    if NOT FOUND then RETURN NULL; end if;
+    RETURN OLD;
+end;
+$$;
+CREATE TRIGGER city_delete_trig INSTEAD OF DELETE ON city_view
+FOR EACH ROW EXECUTE PROCEDURE city_delete();
+CREATE FUNCTION city_update() RETURNS trigger LANGUAGE plpgsql AS $$
+declare
+    ctry_id int;
+begin
+    if NEW.country_name IS DISTINCT FROM OLD.country_name then
+        SELECT country_id, continent INTO ctry_id, NEW.continent
+            FROM country_table WHERE country_name = NEW.country_name;
+        if NOT FOUND then
+            raise exception 'No such country: "%"', NEW.country_name;
+        end if;
+
+        UPDATE city_table SET city_name = NEW.city_name,
+                              population = NEW.population,
+                              country_id = ctry_id
+            WHERE city_id = OLD.city_id;
+    else
+        UPDATE city_table SET city_name = NEW.city_name,
+                              population = NEW.population
+            WHERE city_id = OLD.city_id;
+        NEW.continent := OLD.continent;
+    end if;
+
+    if NOT FOUND then RETURN NULL; end if;
+    RETURN NEW;
+end;
+$$;
+CREATE TRIGGER city_update_trig INSTEAD OF UPDATE ON city_view
+FOR EACH ROW EXECUTE PROCEDURE city_update();
+\set QUIET false
+-- INSERT .. RETURNING
+INSERT INTO city_view(city_name) VALUES('Tokyo') RETURNING *;
+ city_id | city_name | population | country_name | continent 
+---------+-----------+------------+--------------+-----------
+       1 | Tokyo     |            |              | 
+(1 row)
+
+INSERT 0 1
+INSERT INTO city_view(city_name, population) VALUES('London', 7556900) RETURNING *;
+ city_id | city_name | population | country_name | continent 
+---------+-----------+------------+--------------+-----------
+       2 | London    |    7556900 |              | 
+(1 row)
+
+INSERT 0 1
+INSERT INTO city_view(city_name, country_name) VALUES('Washington DC', 'USA') RETURNING *;
+ city_id |   city_name   | population | country_name |   continent   
+---------+---------------+------------+--------------+---------------
+       3 | Washington DC |            | USA          | North America
+(1 row)
+
+INSERT 0 1
+INSERT INTO city_view(city_id, city_name) VALUES(123456, 'New York') RETURNING *;
+ city_id | city_name | population | country_name | continent 
+---------+-----------+------------+--------------+-----------
+  123456 | New York  |            |              | 
+(1 row)
+
+INSERT 0 1
+INSERT INTO city_view VALUES(234567, 'Birmingham', 1016800, 'UK', 'EU') RETURNING *;
+ city_id | city_name  | population | country_name | continent 
+---------+------------+------------+--------------+-----------
+  234567 | Birmingham |    1016800 | UK           | Europe
+(1 row)
+
+INSERT 0 1
+-- UPDATE .. RETURNING
+UPDATE city_view SET country_name = 'Japon' WHERE city_name = 'Tokyo'; -- error
+ERROR:  No such country: "Japon"
+CONTEXT:  PL/pgSQL function city_update() line 9 at RAISE
+UPDATE city_view SET country_name = 'Japan' WHERE city_name = 'Takyo'; -- no match
+UPDATE 0
+UPDATE city_view SET country_name = 'Japan' WHERE city_name = 'Tokyo' RETURNING *; -- OK
+ city_id | city_name | population | country_name | continent 
+---------+-----------+------------+--------------+-----------
+       1 | Tokyo     |            | Japan        | Asia
+(1 row)
+
+UPDATE 1
+UPDATE city_view SET population = 13010279 WHERE city_name = 'Tokyo' RETURNING *;
+ city_id | city_name | population | country_name | continent 
+---------+-----------+------------+--------------+-----------
+       1 | Tokyo     |   13010279 | Japan        | Asia
+(1 row)
+
+UPDATE 1
+UPDATE city_view SET country_name = 'UK' WHERE city_name = 'New York' RETURNING *;
+ city_id | city_name | population | country_name | continent 
+---------+-----------+------------+--------------+-----------
+  123456 | New York  |            | UK           | Europe
+(1 row)
+
+UPDATE 1
+UPDATE city_view SET country_name = 'USA', population = 8391881 WHERE city_name = 'New York' RETURNING *;
+ city_id | city_name | population | country_name |   continent   
+---------+-----------+------------+--------------+---------------
+  123456 | New York  |    8391881 | USA          | North America
+(1 row)
+
+UPDATE 1
+UPDATE city_view SET continent = 'EU' WHERE continent = 'Europe' RETURNING *;
+ city_id | city_name  | population | country_name | continent 
+---------+------------+------------+--------------+-----------
+  234567 | Birmingham |    1016800 | UK           | Europe
+(1 row)
+
+UPDATE 1
+UPDATE city_view v1 SET country_name = v2.country_name FROM city_view v2
+    WHERE v2.city_name = 'Birmingham' AND v1.city_name = 'London' RETURNING *;
+ city_id | city_name | population | country_name | continent | city_id | city_name  | population | country_name | continent 
+---------+-----------+------------+--------------+-----------+---------+------------+------------+--------------+-----------
+       2 | London    |    7556900 | UK           | Europe    |  234567 | Birmingham |    1016800 | UK           | Europe
+(1 row)
+
+UPDATE 1
+-- DELETE .. RETURNING
+DELETE FROM city_view WHERE city_name = 'Birmingham' RETURNING *;
+ city_id | city_name  | population | country_name | continent 
+---------+------------+------------+--------------+-----------
+  234567 | Birmingham |    1016800 | UK           | Europe
+(1 row)
+
+DELETE 1
+\set QUIET true
+-- read-only view with WHERE clause
+CREATE VIEW european_city_view AS
+    SELECT * FROM city_view WHERE continent = 'Europe';
+SELECT count(*) FROM european_city_view;
+ count 
+-------
+     1
+(1 row)
+
+CREATE FUNCTION no_op_trig_fn() RETURNS trigger LANGUAGE plpgsql
+AS 'begin RETURN NULL; end';
+CREATE TRIGGER no_op_trig INSTEAD OF INSERT OR UPDATE OR DELETE
+ON european_city_view FOR EACH ROW EXECUTE PROCEDURE no_op_trig_fn();
+\set QUIET false
+INSERT INTO european_city_view VALUES (0, 'x', 10000, 'y', 'z');
+INSERT 0 0
+UPDATE european_city_view SET population = 10000;
+UPDATE 0
+DELETE FROM european_city_view;
+DELETE 0
+\set QUIET true
+-- rules bypassing no-op triggers
+CREATE RULE european_city_insert_rule AS ON INSERT TO european_city_view
+DO INSTEAD INSERT INTO city_view
+VALUES (NEW.city_id, NEW.city_name, NEW.population, NEW.country_name, NEW.continent)
+RETURNING *;
+CREATE RULE european_city_update_rule AS ON UPDATE TO european_city_view
+DO INSTEAD UPDATE city_view SET
+    city_name = NEW.city_name,
+    population = NEW.population,
+    country_name = NEW.country_name
+WHERE city_id = OLD.city_id
+RETURNING NEW.*;
+CREATE RULE european_city_delete_rule AS ON DELETE TO european_city_view
+DO INSTEAD DELETE FROM city_view WHERE city_id = OLD.city_id RETURNING *;
+\set QUIET false
+-- INSERT not limited by view's WHERE clause, but UPDATE AND DELETE are
+INSERT INTO european_city_view(city_name, country_name)
+    VALUES ('Cambridge', 'USA') RETURNING *;
+ city_id | city_name | population | country_name |   continent   
+---------+-----------+------------+--------------+---------------
+       4 | Cambridge |            | USA          | North America
+(1 row)
+
+INSERT 0 1
+UPDATE european_city_view SET country_name = 'UK'
+    WHERE city_name = 'Cambridge';
+UPDATE 0
+DELETE FROM european_city_view WHERE city_name = 'Cambridge';
+DELETE 0
+-- UPDATE and DELETE via rule and trigger
+UPDATE city_view SET country_name = 'UK'
+    WHERE city_name = 'Cambridge' RETURNING *;
+ city_id | city_name | population | country_name | continent 
+---------+-----------+------------+--------------+-----------
+       4 | Cambridge |            | UK           | Europe
+(1 row)
+
+UPDATE 1
+UPDATE european_city_view SET population = 122800
+    WHERE city_name = 'Cambridge' RETURNING *;
+ city_id | city_name | population | country_name | continent 
+---------+-----------+------------+--------------+-----------
+       4 | Cambridge |     122800 | UK           | Europe
+(1 row)
+
+UPDATE 1
+DELETE FROM european_city_view WHERE city_name = 'Cambridge' RETURNING *;
+ city_id | city_name | population | country_name | continent 
+---------+-----------+------------+--------------+-----------
+       4 | Cambridge |     122800 | UK           | Europe
+(1 row)
+
+DELETE 1
+-- join UPDATE test
+UPDATE city_view v SET population = 599657
+    FROM city_table ci, country_table co
+    WHERE ci.city_name = 'Washington DC' and co.country_name = 'USA'
+    AND v.city_id = ci.city_id AND v.country_name = co.country_name
+    RETURNING co.country_id, v.country_name,
+              v.city_id, v.city_name, v.population;
+ country_id | country_name | city_id |   city_name   | population 
+------------+--------------+---------+---------------+------------
+          3 | USA          |       3 | Washington DC |     599657
+(1 row)
+
+UPDATE 1
+\set QUIET true
+SELECT * FROM city_view ORDER BY city_id;
+ city_id |   city_name   | population | country_name |   continent   
+---------+---------------+------------+--------------+---------------
+       1 | Tokyo         |   13010279 | Japan        | Asia
+       2 | London        |    7556900 | UK           | Europe
+       3 | Washington DC |     599657 | USA          | North America
+  123456 | New York      |    8391881 | USA          | North America
+(4 rows)
+
+DROP TABLE city_table CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to view city_view
+drop cascades to view european_city_view
+DROP TABLE country_table;
+-- Test pg_trigger_depth()
+create table depth_a (id int not null primary key);
+create table depth_b (id int not null primary key);
+create table depth_c (id int not null primary key);
+create function depth_a_tf() returns trigger
+  language plpgsql as $$
+begin
+  raise notice '%: depth = %', tg_name, pg_trigger_depth();
+  insert into depth_b values (new.id);
+  raise notice '%: depth = %', tg_name, pg_trigger_depth();
+  return new;
+end;
+$$;
+create trigger depth_a_tr before insert on depth_a
+  for each row execute procedure depth_a_tf();
+create function depth_b_tf() returns trigger
+  language plpgsql as $$
+begin
+  raise notice '%: depth = %', tg_name, pg_trigger_depth();
+  begin
+    execute 'insert into depth_c values (' || new.id::text || ')';
+  exception
+    when sqlstate 'U9999' then
+      raise notice 'SQLSTATE = U9999: depth = %', pg_trigger_depth();
+  end;
+  raise notice '%: depth = %', tg_name, pg_trigger_depth();
+  if new.id = 1 then
+    execute 'insert into depth_c values (' || new.id::text || ')';
+  end if;
+  return new;
+end;
+$$;
+create trigger depth_b_tr before insert on depth_b
+  for each row execute procedure depth_b_tf();
+create function depth_c_tf() returns trigger
+  language plpgsql as $$
+begin
+  raise notice '%: depth = %', tg_name, pg_trigger_depth();
+  if new.id = 1 then
+    raise exception sqlstate 'U9999';
+  end if;
+  raise notice '%: depth = %', tg_name, pg_trigger_depth();
+  return new;
+end;
+$$;
+create trigger depth_c_tr before insert on depth_c
+  for each row execute procedure depth_c_tf();
+select pg_trigger_depth();
+ pg_trigger_depth 
+------------------
+                0
+(1 row)
+
+insert into depth_a values (1);
+NOTICE:  depth_a_tr: depth = 1
+NOTICE:  depth_b_tr: depth = 2
+NOTICE:  depth_c_tr: depth = 3
+NOTICE:  SQLSTATE = U9999: depth = 2
+NOTICE:  depth_b_tr: depth = 2
+NOTICE:  depth_c_tr: depth = 3
+ERROR:  U9999
+CONTEXT:  PL/pgSQL function depth_c_tf() line 5 at RAISE
+SQL statement "insert into depth_c values (1)"
+PL/pgSQL function depth_b_tf() line 12 at EXECUTE
+SQL statement "insert into depth_b values (new.id)"
+PL/pgSQL function depth_a_tf() line 4 at SQL statement
+select pg_trigger_depth();
+ pg_trigger_depth 
+------------------
+                0
+(1 row)
+
+insert into depth_a values (2);
+NOTICE:  depth_a_tr: depth = 1
+NOTICE:  depth_b_tr: depth = 2
+NOTICE:  depth_c_tr: depth = 3
+NOTICE:  depth_c_tr: depth = 3
+NOTICE:  depth_b_tr: depth = 2
+NOTICE:  depth_a_tr: depth = 1
+select pg_trigger_depth();
+ pg_trigger_depth 
+------------------
+                0
+(1 row)
+
+drop table depth_a, depth_b, depth_c;
+drop function depth_a_tf();
+drop function depth_b_tf();
+drop function depth_c_tf();
+--
+-- Test updates to rows during firing of BEFORE ROW triggers.
+-- As of 9.2, such cases should be rejected (see bug #6123).
+--
+create temp table parent (
+    aid int not null primary key,
+    val1 text,
+    val2 text,
+    val3 text,
+    val4 text,
+    bcnt int not null default 0);
+create temp table child (
+    bid int not null primary key,
+    aid int not null,
+    val1 text);
+create function parent_upd_func()
+  returns trigger language plpgsql as
+$$
+begin
+  if old.val1 <> new.val1 then
+    new.val2 = new.val1;
+    delete from child where child.aid = new.aid and child.val1 = new.val1;
+  end if;
+  return new;
+end;
+$$;
+create trigger parent_upd_trig before update on parent
+  for each row execute procedure parent_upd_func();
+create function parent_del_func()
+  returns trigger language plpgsql as
+$$
+begin
+  delete from child where aid = old.aid;
+  return old;
+end;
+$$;
+create trigger parent_del_trig before delete on parent
+  for each row execute procedure parent_del_func();
+create function child_ins_func()
+  returns trigger language plpgsql as
+$$
+begin
+  update parent set bcnt = bcnt + 1 where aid = new.aid;
+  return new;
+end;
+$$;
+create trigger child_ins_trig after insert on child
+  for each row execute procedure child_ins_func();
+create function child_del_func()
+  returns trigger language plpgsql as
+$$
+begin
+  update parent set bcnt = bcnt - 1 where aid = old.aid;
+  return old;
+end;
+$$;
+create trigger child_del_trig after delete on child
+  for each row execute procedure child_del_func();
+insert into parent values (1, 'a', 'a', 'a', 'a', 0);
+insert into child values (10, 1, 'b');
+select * from parent; select * from child;
+ aid | val1 | val2 | val3 | val4 | bcnt 
+-----+------+------+------+------+------
+   1 | a    | a    | a    | a    |    1
+(1 row)
+
+ bid | aid | val1 
+-----+-----+------
+  10 |   1 | b
+(1 row)
+
+update parent set val1 = 'b' where aid = 1; -- should fail
+ERROR:  tuple to be updated was already modified by an operation triggered by the current command
+HINT:  Consider using an AFTER trigger instead of a BEFORE trigger to propagate changes to other rows.
+select * from parent; select * from child;
+ aid | val1 | val2 | val3 | val4 | bcnt 
+-----+------+------+------+------+------
+   1 | a    | a    | a    | a    |    1
+(1 row)
+
+ bid | aid | val1 
+-----+-----+------
+  10 |   1 | b
+(1 row)
+
+delete from parent where aid = 1; -- should fail
+ERROR:  tuple to be deleted was already modified by an operation triggered by the current command
+HINT:  Consider using an AFTER trigger instead of a BEFORE trigger to propagate changes to other rows.
+select * from parent; select * from child;
+ aid | val1 | val2 | val3 | val4 | bcnt 
+-----+------+------+------+------+------
+   1 | a    | a    | a    | a    |    1
+(1 row)
+
+ bid | aid | val1 
+-----+-----+------
+  10 |   1 | b
+(1 row)
+
+-- replace the trigger function with one that restarts the deletion after
+-- having modified a child
+create or replace function parent_del_func()
+  returns trigger language plpgsql as
+$$
+begin
+  delete from child where aid = old.aid;
+  if found then
+    delete from parent where aid = old.aid;
+    return null; -- cancel outer deletion
+  end if;
+  return old;
+end;
+$$;
+delete from parent where aid = 1;
+select * from parent; select * from child;
+ aid | val1 | val2 | val3 | val4 | bcnt 
+-----+------+------+------+------+------
+(0 rows)
+
+ bid | aid | val1 
+-----+-----+------
+(0 rows)
+
+drop table parent, child;
+drop function parent_upd_func();
+drop function parent_del_func();
+drop function child_ins_func();
+drop function child_del_func();
+-- similar case, but with a self-referencing FK so that parent and child
+-- rows can be affected by a single operation
+create temp table self_ref_trigger (
+    id int primary key,
+    parent int references self_ref_trigger,
+    data text,
+    nchildren int not null default 0
+);
+create function self_ref_trigger_ins_func()
+  returns trigger language plpgsql as
+$$
+begin
+  if new.parent is not null then
+    update self_ref_trigger set nchildren = nchildren + 1
+      where id = new.parent;
+  end if;
+  return new;
+end;
+$$;
+create trigger self_ref_trigger_ins_trig before insert on self_ref_trigger
+  for each row execute procedure self_ref_trigger_ins_func();
+create function self_ref_trigger_del_func()
+  returns trigger language plpgsql as
+$$
+begin
+  if old.parent is not null then
+    update self_ref_trigger set nchildren = nchildren - 1
+      where id = old.parent;
+  end if;
+  return old;
+end;
+$$;
+create trigger self_ref_trigger_del_trig before delete on self_ref_trigger
+  for each row execute procedure self_ref_trigger_del_func();
+insert into self_ref_trigger values (1, null, 'root');
+insert into self_ref_trigger values (2, 1, 'root child A');
+insert into self_ref_trigger values (3, 1, 'root child B');
+insert into self_ref_trigger values (4, 2, 'grandchild 1');
+insert into self_ref_trigger values (5, 3, 'grandchild 2');
+update self_ref_trigger set data = 'root!' where id = 1;
+select * from self_ref_trigger order by id;
+ id | parent |     data     | nchildren 
+----+--------+--------------+-----------
+  1 |        | root!        |         2
+  2 |      1 | root child A |         1
+  3 |      1 | root child B |         1
+  4 |      2 | grandchild 1 |         0
+  5 |      3 | grandchild 2 |         0
+(5 rows)
+
+delete from self_ref_trigger;
+select * from self_ref_trigger;
+ id | parent | data | nchildren 
+----+--------+------+-----------
+(0 rows)
+
+drop table self_ref_trigger;
+drop function self_ref_trigger_ins_func();
+drop function self_ref_trigger_del_func();
+--
+-- Check that statement triggers work correctly even with all children excluded
+--
+create table stmt_trig_on_empty_upd (a int);
+create table stmt_trig_on_empty_upd1 () inherits (stmt_trig_on_empty_upd);
+create function update_stmt_notice() returns trigger as $$
+begin
+	raise notice 'updating %', TG_TABLE_NAME;
+	return null;
+end;
+$$ language plpgsql;
+create trigger before_stmt_trigger
+	before update on stmt_trig_on_empty_upd
+	execute procedure update_stmt_notice();
+create trigger before_stmt_trigger
+	before update on stmt_trig_on_empty_upd1
+	execute procedure update_stmt_notice();
+-- inherited no-op update
+update stmt_trig_on_empty_upd set a = a where false returning a+1 as aa;
+NOTICE:  updating stmt_trig_on_empty_upd
+ aa 
+----
+(0 rows)
+
+-- simple no-op update
+update stmt_trig_on_empty_upd1 set a = a where false returning a+1 as aa;
+NOTICE:  updating stmt_trig_on_empty_upd1
+ aa 
+----
+(0 rows)
+
+drop table stmt_trig_on_empty_upd cascade;
+NOTICE:  drop cascades to table stmt_trig_on_empty_upd1
+drop function update_stmt_notice();
+--
+-- Check that index creation (or DDL in general) is prohibited in a trigger
+--
+create table trigger_ddl_table (
+   col1 integer,
+   col2 integer
+);
+create function trigger_ddl_func() returns trigger as $$
+begin
+  alter table trigger_ddl_table add primary key (col1);
+  return new;
+end$$ language plpgsql;
+create trigger trigger_ddl_func before insert on trigger_ddl_table for each row
+  execute procedure trigger_ddl_func();
+insert into trigger_ddl_table values (1, 42);  -- fail
+ERROR:  cannot ALTER TABLE "trigger_ddl_table" because it is being used by active queries in this session
+CONTEXT:  SQL statement "alter table trigger_ddl_table add primary key (col1)"
+PL/pgSQL function trigger_ddl_func() line 3 at SQL statement
+create or replace function trigger_ddl_func() returns trigger as $$
+begin
+  create index on trigger_ddl_table (col2);
+  return new;
+end$$ language plpgsql;
+insert into trigger_ddl_table values (1, 42);  -- fail
+ERROR:  cannot CREATE INDEX "trigger_ddl_table" because it is being used by active queries in this session
+CONTEXT:  SQL statement "create index on trigger_ddl_table (col2)"
+PL/pgSQL function trigger_ddl_func() line 3 at SQL statement
+drop table trigger_ddl_table;
+drop function trigger_ddl_func();
+--
+-- Verify behavior of before and after triggers with INSERT...ON CONFLICT
+-- DO UPDATE
+--
+create table upsert (key int4 primary key, color text);
+create function upsert_before_func()
+  returns trigger language plpgsql as
+$$
+begin
+  if (TG_OP = 'UPDATE') then
+    raise warning 'before update (old): %', old.*::text;
+    raise warning 'before update (new): %', new.*::text;
+  elsif (TG_OP = 'INSERT') then
+    raise warning 'before insert (new): %', new.*::text;
+    if new.key % 2 = 0 then
+      new.key := new.key + 1;
+      new.color := new.color || ' trig modified';
+      raise warning 'before insert (new, modified): %', new.*::text;
+    end if;
+  end if;
+  return new;
+end;
+$$;
+create trigger upsert_before_trig before insert or update on upsert
+  for each row execute procedure upsert_before_func();
+create function upsert_after_func()
+  returns trigger language plpgsql as
+$$
+begin
+  if (TG_OP = 'UPDATE') then
+    raise warning 'after update (old): %', old.*::text;
+    raise warning 'after update (new): %', new.*::text;
+  elsif (TG_OP = 'INSERT') then
+    raise warning 'after insert (new): %', new.*::text;
+  end if;
+  return null;
+end;
+$$;
+create trigger upsert_after_trig after insert or update on upsert
+  for each row execute procedure upsert_after_func();
+insert into upsert values(1, 'black') on conflict (key) do update set color = 'updated ' || upsert.color;
+WARNING:  before insert (new): (1,black)
+WARNING:  after insert (new): (1,black)
+insert into upsert values(2, 'red') on conflict (key) do update set color = 'updated ' || upsert.color;
+WARNING:  before insert (new): (2,red)
+WARNING:  before insert (new, modified): (3,"red trig modified")
+WARNING:  after insert (new): (3,"red trig modified")
+insert into upsert values(3, 'orange') on conflict (key) do update set color = 'updated ' || upsert.color;
+WARNING:  before insert (new): (3,orange)
+WARNING:  before update (old): (3,"red trig modified")
+WARNING:  before update (new): (3,"updated red trig modified")
+WARNING:  after update (old): (3,"red trig modified")
+WARNING:  after update (new): (3,"updated red trig modified")
+insert into upsert values(4, 'green') on conflict (key) do update set color = 'updated ' || upsert.color;
+WARNING:  before insert (new): (4,green)
+WARNING:  before insert (new, modified): (5,"green trig modified")
+WARNING:  after insert (new): (5,"green trig modified")
+insert into upsert values(5, 'purple') on conflict (key) do update set color = 'updated ' || upsert.color;
+WARNING:  before insert (new): (5,purple)
+WARNING:  before update (old): (5,"green trig modified")
+WARNING:  before update (new): (5,"updated green trig modified")
+WARNING:  after update (old): (5,"green trig modified")
+WARNING:  after update (new): (5,"updated green trig modified")
+insert into upsert values(6, 'white') on conflict (key) do update set color = 'updated ' || upsert.color;
+WARNING:  before insert (new): (6,white)
+WARNING:  before insert (new, modified): (7,"white trig modified")
+WARNING:  after insert (new): (7,"white trig modified")
+insert into upsert values(7, 'pink') on conflict (key) do update set color = 'updated ' || upsert.color;
+WARNING:  before insert (new): (7,pink)
+WARNING:  before update (old): (7,"white trig modified")
+WARNING:  before update (new): (7,"updated white trig modified")
+WARNING:  after update (old): (7,"white trig modified")
+WARNING:  after update (new): (7,"updated white trig modified")
+insert into upsert values(8, 'yellow') on conflict (key) do update set color = 'updated ' || upsert.color;
+WARNING:  before insert (new): (8,yellow)
+WARNING:  before insert (new, modified): (9,"yellow trig modified")
+WARNING:  after insert (new): (9,"yellow trig modified")
+select * from upsert;
+ key |            color            
+-----+-----------------------------
+   1 | black
+   3 | updated red trig modified
+   5 | updated green trig modified
+   7 | updated white trig modified
+   9 | yellow trig modified
+(5 rows)
+
+drop table upsert;
+drop function upsert_before_func();
+drop function upsert_after_func();
+--
+-- Verify that triggers with transition tables are not allowed on
+-- views
+--
+create table my_table (i int);
+create view my_view as select * from my_table;
+create function my_trigger_function() returns trigger as $$ begin end; $$ language plpgsql;
+create trigger my_trigger after update on my_view referencing old table as old_table
+   for each statement execute procedure my_trigger_function();
+ERROR:  "my_view" is a view
+DETAIL:  Triggers on views cannot have transition tables.
+drop function my_trigger_function();
+drop view my_view;
+drop table my_table;
+--
+-- Verify cases that are unsupported with partitioned tables
+--
+create table parted_trig (a int) partition by list (a);
+create function trigger_nothing() returns trigger
+  language plpgsql as $$ begin end; $$;
+create trigger failed before insert or update or delete on parted_trig
+  for each row execute procedure trigger_nothing();
+ERROR:  "parted_trig" is a partitioned table
+DETAIL:  Partitioned tables cannot have BEFORE / FOR EACH ROW triggers.
+create trigger failed instead of update on parted_trig
+  for each row execute procedure trigger_nothing();
+ERROR:  "parted_trig" is a table
+DETAIL:  Tables cannot have INSTEAD OF triggers.
+create trigger failed after update on parted_trig
+  referencing old table as old_table
+  for each row execute procedure trigger_nothing();
+ERROR:  "parted_trig" is a partitioned table
+DETAIL:  Triggers on partitioned tables cannot have transition tables.
+drop table parted_trig;
+--
+-- Verify trigger creation for partitioned tables, and drop behavior
+--
+create table trigpart (a int, b int) partition by range (a);
+create table trigpart1 partition of trigpart for values from (0) to (1000);
+create trigger trg1 after insert on trigpart for each row execute procedure trigger_nothing();
+create table trigpart2 partition of trigpart for values from (1000) to (2000);
+create table trigpart3 (like trigpart);
+alter table trigpart attach partition trigpart3 for values from (2000) to (3000);
+select tgrelid::regclass, tgname, tgfoid::regproc from pg_trigger
+  where tgrelid::regclass::text like 'trigpart%' order by tgrelid::regclass::text;
+  tgrelid  | tgname |     tgfoid      
+-----------+--------+-----------------
+ trigpart  | trg1   | trigger_nothing
+ trigpart1 | trg1   | trigger_nothing
+ trigpart2 | trg1   | trigger_nothing
+ trigpart3 | trg1   | trigger_nothing
+(4 rows)
+
+drop trigger trg1 on trigpart1;	-- fail
+ERROR:  cannot drop trigger trg1 on table trigpart1 because trigger trg1 on table trigpart requires it
+HINT:  You can drop trigger trg1 on table trigpart instead.
+drop trigger trg1 on trigpart2;	-- fail
+ERROR:  cannot drop trigger trg1 on table trigpart2 because trigger trg1 on table trigpart requires it
+HINT:  You can drop trigger trg1 on table trigpart instead.
+drop trigger trg1 on trigpart3;	-- fail
+ERROR:  cannot drop trigger trg1 on table trigpart3 because trigger trg1 on table trigpart requires it
+HINT:  You can drop trigger trg1 on table trigpart instead.
+drop table trigpart2;			-- ok, trigger should be gone in that partition
+select tgrelid::regclass, tgname, tgfoid::regproc from pg_trigger
+  where tgrelid::regclass::text like 'trigpart%' order by tgrelid::regclass::text;
+  tgrelid  | tgname |     tgfoid      
+-----------+--------+-----------------
+ trigpart  | trg1   | trigger_nothing
+ trigpart1 | trg1   | trigger_nothing
+ trigpart3 | trg1   | trigger_nothing
+(3 rows)
+
+drop trigger trg1 on trigpart;		-- ok, all gone
+select tgrelid::regclass, tgname, tgfoid::regproc from pg_trigger
+  where tgrelid::regclass::text like 'trigpart%' order by tgrelid::regclass::text;
+ tgrelid | tgname | tgfoid 
+---------+--------+--------
+(0 rows)
+
+drop table trigpart;
+drop function trigger_nothing();
+--
+-- Verify that triggers are fired for partitioned tables
+--
+create table parted_stmt_trig (a int) partition by list (a);
+create table parted_stmt_trig1 partition of parted_stmt_trig for values in (1);
+create table parted_stmt_trig2 partition of parted_stmt_trig for values in (2);
+create table parted2_stmt_trig (a int) partition by list (a);
+create table parted2_stmt_trig1 partition of parted2_stmt_trig for values in (1);
+create table parted2_stmt_trig2 partition of parted2_stmt_trig for values in (2);
+create or replace function trigger_notice() returns trigger as $$
+  begin
+    raise notice 'trigger % on % % % for %', TG_NAME, TG_TABLE_NAME, TG_WHEN, TG_OP, TG_LEVEL;
+    if TG_LEVEL = 'ROW' then
+       return NEW;
+    end if;
+    return null;
+  end;
+  $$ language plpgsql;
+-- insert/update/delete statement-level triggers on the parent
+create trigger trig_ins_before before insert on parted_stmt_trig
+  for each statement execute procedure trigger_notice();
+create trigger trig_ins_after after insert on parted_stmt_trig
+  for each statement execute procedure trigger_notice();
+create trigger trig_upd_before before update on parted_stmt_trig
+  for each statement execute procedure trigger_notice();
+create trigger trig_upd_after after update on parted_stmt_trig
+  for each statement execute procedure trigger_notice();
+create trigger trig_del_before before delete on parted_stmt_trig
+  for each statement execute procedure trigger_notice();
+create trigger trig_del_after after delete on parted_stmt_trig
+  for each statement execute procedure trigger_notice();
+-- insert/update/delete row-level triggers on the parent
+create trigger trig_ins_after_parent after insert on parted_stmt_trig
+  for each row execute procedure trigger_notice();
+create trigger trig_upd_after_parent after update on parted_stmt_trig
+  for each row execute procedure trigger_notice();
+create trigger trig_del_after_parent after delete on parted_stmt_trig
+  for each row execute procedure trigger_notice();
+-- insert/update/delete row-level triggers on the first partition
+create trigger trig_ins_before_child before insert on parted_stmt_trig1
+  for each row execute procedure trigger_notice();
+create trigger trig_ins_after_child after insert on parted_stmt_trig1
+  for each row execute procedure trigger_notice();
+create trigger trig_upd_before_child before update on parted_stmt_trig1
+  for each row execute procedure trigger_notice();
+create trigger trig_upd_after_child after update on parted_stmt_trig1
+  for each row execute procedure trigger_notice();
+create trigger trig_del_before_child before delete on parted_stmt_trig1
+  for each row execute procedure trigger_notice();
+create trigger trig_del_after_child after delete on parted_stmt_trig1
+  for each row execute procedure trigger_notice();
+-- insert/update/delete statement-level triggers on the parent
+create trigger trig_ins_before_3 before insert on parted2_stmt_trig
+  for each statement execute procedure trigger_notice();
+create trigger trig_ins_after_3 after insert on parted2_stmt_trig
+  for each statement execute procedure trigger_notice();
+create trigger trig_upd_before_3 before update on parted2_stmt_trig
+  for each statement execute procedure trigger_notice();
+create trigger trig_upd_after_3 after update on parted2_stmt_trig
+  for each statement execute procedure trigger_notice();
+create trigger trig_del_before_3 before delete on parted2_stmt_trig
+  for each statement execute procedure trigger_notice();
+create trigger trig_del_after_3 after delete on parted2_stmt_trig
+  for each statement execute procedure trigger_notice();
+with ins (a) as (
+  insert into parted2_stmt_trig values (1), (2) returning a
+) insert into parted_stmt_trig select a from ins returning tableoid::regclass, a;
+NOTICE:  trigger trig_ins_before on parted_stmt_trig BEFORE INSERT for STATEMENT
+NOTICE:  trigger trig_ins_before_3 on parted2_stmt_trig BEFORE INSERT for STATEMENT
+NOTICE:  trigger trig_ins_before_child on parted_stmt_trig1 BEFORE INSERT for ROW
+NOTICE:  trigger trig_ins_after_child on parted_stmt_trig1 AFTER INSERT for ROW
+NOTICE:  trigger trig_ins_after_parent on parted_stmt_trig1 AFTER INSERT for ROW
+NOTICE:  trigger trig_ins_after_parent on parted_stmt_trig2 AFTER INSERT for ROW
+NOTICE:  trigger trig_ins_after_3 on parted2_stmt_trig AFTER INSERT for STATEMENT
+NOTICE:  trigger trig_ins_after on parted_stmt_trig AFTER INSERT for STATEMENT
+     tableoid      | a 
+-------------------+---
+ parted_stmt_trig1 | 1
+ parted_stmt_trig2 | 2
+(2 rows)
+
+with upd as (
+  update parted2_stmt_trig set a = a
+) update parted_stmt_trig  set a = a;
+NOTICE:  trigger trig_upd_before on parted_stmt_trig BEFORE UPDATE for STATEMENT
+NOTICE:  trigger trig_upd_before_child on parted_stmt_trig1 BEFORE UPDATE for ROW
+NOTICE:  trigger trig_upd_before_3 on parted2_stmt_trig BEFORE UPDATE for STATEMENT
+NOTICE:  trigger trig_upd_after_child on parted_stmt_trig1 AFTER UPDATE for ROW
+NOTICE:  trigger trig_upd_after_parent on parted_stmt_trig1 AFTER UPDATE for ROW
+NOTICE:  trigger trig_upd_after_parent on parted_stmt_trig2 AFTER UPDATE for ROW
+NOTICE:  trigger trig_upd_after on parted_stmt_trig AFTER UPDATE for STATEMENT
+NOTICE:  trigger trig_upd_after_3 on parted2_stmt_trig AFTER UPDATE for STATEMENT
+delete from parted_stmt_trig;
+NOTICE:  trigger trig_del_before on parted_stmt_trig BEFORE DELETE for STATEMENT
+NOTICE:  trigger trig_del_before_child on parted_stmt_trig1 BEFORE DELETE for ROW
+NOTICE:  trigger trig_del_after_parent on parted_stmt_trig2 AFTER DELETE for ROW
+NOTICE:  trigger trig_del_after on parted_stmt_trig AFTER DELETE for STATEMENT
+-- insert via copy on the parent
+copy parted_stmt_trig(a) from stdin;
+NOTICE:  trigger trig_ins_before on parted_stmt_trig BEFORE INSERT for STATEMENT
+NOTICE:  trigger trig_ins_before_child on parted_stmt_trig1 BEFORE INSERT for ROW
+NOTICE:  trigger trig_ins_after_child on parted_stmt_trig1 AFTER INSERT for ROW
+NOTICE:  trigger trig_ins_after_parent on parted_stmt_trig1 AFTER INSERT for ROW
+NOTICE:  trigger trig_ins_after_parent on parted_stmt_trig2 AFTER INSERT for ROW
+NOTICE:  trigger trig_ins_after on parted_stmt_trig AFTER INSERT for STATEMENT
+-- insert via copy on the first partition
+copy parted_stmt_trig1(a) from stdin;
+NOTICE:  trigger trig_ins_before_child on parted_stmt_trig1 BEFORE INSERT for ROW
+NOTICE:  trigger trig_ins_after_child on parted_stmt_trig1 AFTER INSERT for ROW
+NOTICE:  trigger trig_ins_after_parent on parted_stmt_trig1 AFTER INSERT for ROW
+-- Disabling a trigger in the parent table should disable children triggers too
+alter table parted_stmt_trig disable trigger trig_ins_after_parent;
+insert into parted_stmt_trig values (1);
+NOTICE:  trigger trig_ins_before on parted_stmt_trig BEFORE INSERT for STATEMENT
+NOTICE:  trigger trig_ins_before_child on parted_stmt_trig1 BEFORE INSERT for ROW
+NOTICE:  trigger trig_ins_after_child on parted_stmt_trig1 AFTER INSERT for ROW
+NOTICE:  trigger trig_ins_after on parted_stmt_trig AFTER INSERT for STATEMENT
+alter table parted_stmt_trig enable trigger trig_ins_after_parent;
+insert into parted_stmt_trig values (1);
+NOTICE:  trigger trig_ins_before on parted_stmt_trig BEFORE INSERT for STATEMENT
+NOTICE:  trigger trig_ins_before_child on parted_stmt_trig1 BEFORE INSERT for ROW
+NOTICE:  trigger trig_ins_after_child on parted_stmt_trig1 AFTER INSERT for ROW
+NOTICE:  trigger trig_ins_after_parent on parted_stmt_trig1 AFTER INSERT for ROW
+NOTICE:  trigger trig_ins_after on parted_stmt_trig AFTER INSERT for STATEMENT
+drop table parted_stmt_trig, parted2_stmt_trig;
+-- Verify that triggers fire in alphabetical order
+create table parted_trig (a int) partition by range (a);
+create table parted_trig_1 partition of parted_trig for values from (0) to (1000)
+   partition by range (a);
+create table parted_trig_1_1 partition of parted_trig_1 for values from (0) to (100);
+create table parted_trig_2 partition of parted_trig for values from (1000) to (2000);
+create trigger zzz after insert on parted_trig for each row execute procedure trigger_notice();
+create trigger mmm after insert on parted_trig_1_1 for each row execute procedure trigger_notice();
+create trigger aaa after insert on parted_trig_1 for each row execute procedure trigger_notice();
+create trigger bbb after insert on parted_trig for each row execute procedure trigger_notice();
+create trigger qqq after insert on parted_trig_1_1 for each row execute procedure trigger_notice();
+insert into parted_trig values (50), (1500);
+NOTICE:  trigger aaa on parted_trig_1_1 AFTER INSERT for ROW
+NOTICE:  trigger bbb on parted_trig_1_1 AFTER INSERT for ROW
+NOTICE:  trigger mmm on parted_trig_1_1 AFTER INSERT for ROW
+NOTICE:  trigger qqq on parted_trig_1_1 AFTER INSERT for ROW
+NOTICE:  trigger zzz on parted_trig_1_1 AFTER INSERT for ROW
+NOTICE:  trigger bbb on parted_trig_2 AFTER INSERT for ROW
+NOTICE:  trigger zzz on parted_trig_2 AFTER INSERT for ROW
+drop table parted_trig;
+-- test irregular partitions (i.e., different column definitions),
+-- including that the WHEN clause works
+create function bark(text) returns bool language plpgsql immutable
+  as $$ begin raise notice '% <- woof!', $1; return true; end; $$;
+create or replace function trigger_notice_ab() returns trigger as $$
+  begin
+    raise notice 'trigger % on % % % for %: (a,b)=(%,%)',
+		TG_NAME, TG_TABLE_NAME, TG_WHEN, TG_OP, TG_LEVEL,
+		NEW.a, NEW.b;
+    if TG_LEVEL = 'ROW' then
+       return NEW;
+    end if;
+    return null;
+  end;
+  $$ language plpgsql;
+create table parted_irreg_ancestor (fd text, b text, fd2 int, fd3 int, a int)
+  partition by range (b);
+alter table parted_irreg_ancestor drop column fd,
+  drop column fd2, drop column fd3;
+create table parted_irreg (fd int, a int, fd2 int, b text)
+  partition by range (b);
+alter table parted_irreg drop column fd, drop column fd2;
+alter table parted_irreg_ancestor attach partition parted_irreg
+  for values from ('aaaa') to ('zzzz');
+create table parted1_irreg (b text, fd int, a int);
+alter table parted1_irreg drop column fd;
+alter table parted_irreg attach partition parted1_irreg
+  for values from ('aaaa') to ('bbbb');
+create trigger parted_trig after insert on parted_irreg
+  for each row execute procedure trigger_notice_ab();
+create trigger parted_trig_odd after insert on parted_irreg for each row
+  when (bark(new.b) AND new.a % 2 = 1) execute procedure trigger_notice_ab();
+-- we should hear barking for every insert, but parted_trig_odd only emits
+-- noise for odd values of a. parted_trig does it for all inserts.
+insert into parted_irreg values (1, 'aardvark'), (2, 'aanimals');
+NOTICE:  aardvark <- woof!
+NOTICE:  aanimals <- woof!
+NOTICE:  trigger parted_trig on parted1_irreg AFTER INSERT for ROW: (a,b)=(1,aardvark)
+NOTICE:  trigger parted_trig_odd on parted1_irreg AFTER INSERT for ROW: (a,b)=(1,aardvark)
+NOTICE:  trigger parted_trig on parted1_irreg AFTER INSERT for ROW: (a,b)=(2,aanimals)
+insert into parted1_irreg values ('aardwolf', 2);
+NOTICE:  aardwolf <- woof!
+NOTICE:  trigger parted_trig on parted1_irreg AFTER INSERT for ROW: (a,b)=(2,aardwolf)
+insert into parted_irreg_ancestor values ('aasvogel', 3);
+NOTICE:  aasvogel <- woof!
+NOTICE:  trigger parted_trig on parted1_irreg AFTER INSERT for ROW: (a,b)=(3,aasvogel)
+NOTICE:  trigger parted_trig_odd on parted1_irreg AFTER INSERT for ROW: (a,b)=(3,aasvogel)
+drop table parted_irreg_ancestor;
+--
+-- Constraint triggers and partitioned tables
+create table parted_constr_ancestor (a int, b text)
+  partition by range (b);
+create table parted_constr (a int, b text)
+  partition by range (b);
+alter table parted_constr_ancestor attach partition parted_constr
+  for values from ('aaaa') to ('zzzz');
+create table parted1_constr (a int, b text);
+alter table parted_constr attach partition parted1_constr
+  for values from ('aaaa') to ('bbbb');
+create constraint trigger parted_trig after insert on parted_constr_ancestor
+  deferrable
+  for each row execute procedure trigger_notice_ab();
+create constraint trigger parted_trig_two after insert on parted_constr
+  deferrable initially deferred
+  for each row when (bark(new.b) AND new.a % 2 = 1)
+  execute procedure trigger_notice_ab();
+-- The immediate constraint is fired immediately; the WHEN clause of the
+-- deferred constraint is also called immediately.  The deferred constraint
+-- is fired at commit time.
+begin;
+insert into parted_constr values (1, 'aardvark');
+NOTICE:  aardvark <- woof!
+NOTICE:  trigger parted_trig on parted1_constr AFTER INSERT for ROW: (a,b)=(1,aardvark)
+insert into parted1_constr values (2, 'aardwolf');
+NOTICE:  aardwolf <- woof!
+NOTICE:  trigger parted_trig on parted1_constr AFTER INSERT for ROW: (a,b)=(2,aardwolf)
+insert into parted_constr_ancestor values (3, 'aasvogel');
+NOTICE:  aasvogel <- woof!
+NOTICE:  trigger parted_trig on parted1_constr AFTER INSERT for ROW: (a,b)=(3,aasvogel)
+commit;
+NOTICE:  trigger parted_trig_two on parted1_constr AFTER INSERT for ROW: (a,b)=(1,aardvark)
+NOTICE:  trigger parted_trig_two on parted1_constr AFTER INSERT for ROW: (a,b)=(3,aasvogel)
+-- The WHEN clause is immediate, and both constraint triggers are fired at
+-- commit time.
+begin;
+set constraints parted_trig deferred;
+insert into parted_constr values (1, 'aardvark');
+NOTICE:  aardvark <- woof!
+insert into parted1_constr values (2, 'aardwolf'), (3, 'aasvogel');
+NOTICE:  aardwolf <- woof!
+NOTICE:  aasvogel <- woof!
+commit;
+NOTICE:  trigger parted_trig on parted1_constr AFTER INSERT for ROW: (a,b)=(1,aardvark)
+NOTICE:  trigger parted_trig_two on parted1_constr AFTER INSERT for ROW: (a,b)=(1,aardvark)
+NOTICE:  trigger parted_trig on parted1_constr AFTER INSERT for ROW: (a,b)=(2,aardwolf)
+NOTICE:  trigger parted_trig on parted1_constr AFTER INSERT for ROW: (a,b)=(3,aasvogel)
+NOTICE:  trigger parted_trig_two on parted1_constr AFTER INSERT for ROW: (a,b)=(3,aasvogel)
+drop table parted_constr_ancestor;
+drop function bark(text);
+-- Test that the WHEN clause is set properly to partitions
+create table parted_trigger (a int, b text) partition by range (a);
+create table parted_trigger_1 partition of parted_trigger for values from (0) to (1000);
+create table parted_trigger_2 (drp int, a int, b text);
+alter table parted_trigger_2 drop column drp;
+alter table parted_trigger attach partition parted_trigger_2 for values from (1000) to (2000);
+create trigger parted_trigger after update on parted_trigger
+  for each row when (new.a % 2 = 1 and length(old.b) >= 2) execute procedure trigger_notice_ab();
+create table parted_trigger_3 (b text, a int) partition by range (length(b));
+create table parted_trigger_3_1 partition of parted_trigger_3 for values from (1) to (3);
+create table parted_trigger_3_2 partition of parted_trigger_3 for values from (3) to (5);
+alter table parted_trigger attach partition parted_trigger_3 for values from (2000) to (3000);
+insert into parted_trigger values
+    (0, 'a'), (1, 'bbb'), (2, 'bcd'), (3, 'c'),
+	(1000, 'c'), (1001, 'ddd'), (1002, 'efg'), (1003, 'f'),
+	(2000, 'e'), (2001, 'fff'), (2002, 'ghi'), (2003, 'h');
+update parted_trigger set a = a + 2; -- notice for odd 'a' values, long 'b' values
+NOTICE:  trigger parted_trigger on parted_trigger_1 AFTER UPDATE for ROW: (a,b)=(3,bbb)
+NOTICE:  trigger parted_trigger on parted_trigger_2 AFTER UPDATE for ROW: (a,b)=(1003,ddd)
+NOTICE:  trigger parted_trigger on parted_trigger_3_2 AFTER UPDATE for ROW: (a,b)=(2003,fff)
+drop table parted_trigger;
+-- try a constraint trigger, also
+create table parted_referenced (a int);
+create table unparted_trigger (a int, b text);	-- for comparison purposes
+create table parted_trigger (a int, b text) partition by range (a);
+create table parted_trigger_1 partition of parted_trigger for values from (0) to (1000);
+create table parted_trigger_2 (drp int, a int, b text);
+alter table parted_trigger_2 drop column drp;
+alter table parted_trigger attach partition parted_trigger_2 for values from (1000) to (2000);
+create constraint trigger parted_trigger after update on parted_trigger
+  from parted_referenced
+  for each row execute procedure trigger_notice_ab();
+create constraint trigger parted_trigger after update on unparted_trigger
+  from parted_referenced
+  for each row execute procedure trigger_notice_ab();
+create table parted_trigger_3 (b text, a int) partition by range (length(b));
+create table parted_trigger_3_1 partition of parted_trigger_3 for values from (1) to (3);
+create table parted_trigger_3_2 partition of parted_trigger_3 for values from (3) to (5);
+alter table parted_trigger attach partition parted_trigger_3 for values from (2000) to (3000);
+select tgname, conname, t.tgrelid::regclass, t.tgconstrrelid::regclass,
+  c.conrelid::regclass, c.confrelid::regclass
+  from pg_trigger t join pg_constraint c on (t.tgconstraint = c.oid)
+  where tgname = 'parted_trigger'
+  order by t.tgrelid::regclass::text;
+     tgname     |    conname     |      tgrelid       |   tgconstrrelid   |      conrelid      | confrelid 
+----------------+----------------+--------------------+-------------------+--------------------+-----------
+ parted_trigger | parted_trigger | parted_trigger     | parted_referenced | parted_trigger     | -
+ parted_trigger | parted_trigger | parted_trigger_1   | parted_referenced | parted_trigger_1   | -
+ parted_trigger | parted_trigger | parted_trigger_2   | parted_referenced | parted_trigger_2   | -
+ parted_trigger | parted_trigger | parted_trigger_3   | parted_referenced | parted_trigger_3   | -
+ parted_trigger | parted_trigger | parted_trigger_3_1 | parted_referenced | parted_trigger_3_1 | -
+ parted_trigger | parted_trigger | parted_trigger_3_2 | parted_referenced | parted_trigger_3_2 | -
+ parted_trigger | parted_trigger | unparted_trigger   | parted_referenced | unparted_trigger   | -
+(7 rows)
+
+drop table parted_referenced, parted_trigger, unparted_trigger;
+-- verify that the "AFTER UPDATE OF columns" event is propagated correctly
+create table parted_trigger (a int, b text) partition by range (a);
+create table parted_trigger_1 partition of parted_trigger for values from (0) to (1000);
+create table parted_trigger_2 (drp int, a int, b text);
+alter table parted_trigger_2 drop column drp;
+alter table parted_trigger attach partition parted_trigger_2 for values from (1000) to (2000);
+create trigger parted_trigger after update of b on parted_trigger
+  for each row execute procedure trigger_notice_ab();
+create table parted_trigger_3 (b text, a int) partition by range (length(b));
+create table parted_trigger_3_1 partition of parted_trigger_3 for values from (1) to (4);
+create table parted_trigger_3_2 partition of parted_trigger_3 for values from (4) to (8);
+alter table parted_trigger attach partition parted_trigger_3 for values from (2000) to (3000);
+insert into parted_trigger values (0, 'a'), (1000, 'c'), (2000, 'e'), (2001, 'eeee');
+update parted_trigger set a = a + 2;	-- no notices here
+update parted_trigger set b = b || 'b';	-- all triggers should fire
+NOTICE:  trigger parted_trigger on parted_trigger_1 AFTER UPDATE for ROW: (a,b)=(2,ab)
+NOTICE:  trigger parted_trigger on parted_trigger_2 AFTER UPDATE for ROW: (a,b)=(1002,cb)
+NOTICE:  trigger parted_trigger on parted_trigger_3_1 AFTER UPDATE for ROW: (a,b)=(2002,eb)
+NOTICE:  trigger parted_trigger on parted_trigger_3_2 AFTER UPDATE for ROW: (a,b)=(2003,eeeeb)
+drop table parted_trigger;
+drop function trigger_notice_ab();
+-- Make sure we don't end up with unnecessary copies of triggers, when
+-- cloning them.
+create table trg_clone (a int) partition by range (a);
+create table trg_clone1 partition of trg_clone for values from (0) to (1000);
+alter table trg_clone add constraint uniq unique (a) deferrable;
+create table trg_clone2 partition of trg_clone for values from (1000) to (2000);
+create table trg_clone3 partition of trg_clone for values from (2000) to (3000)
+  partition by range (a);
+create table trg_clone_3_3 partition of trg_clone3 for values from (2000) to (2100);
+select tgrelid::regclass, count(*) from pg_trigger
+  where tgrelid::regclass in ('trg_clone', 'trg_clone1', 'trg_clone2',
+	'trg_clone3', 'trg_clone_3_3')
+  group by tgrelid::regclass order by tgrelid::regclass;
+    tgrelid    | count 
+---------------+-------
+ trg_clone     |     1
+ trg_clone1    |     1
+ trg_clone2    |     1
+ trg_clone3    |     1
+ trg_clone_3_3 |     1
+(5 rows)
+
+drop table trg_clone;
+--
+-- Test the interaction between transition tables and both kinds of
+-- inheritance.  We'll dump the contents of the transition tables in a
+-- format that shows the attribute order, so that we can distinguish
+-- tuple formats (though not dropped attributes).
+--
+create or replace function dump_insert() returns trigger language plpgsql as
+$$
+  begin
+    raise notice 'trigger = %, new table = %',
+                 TG_NAME,
+                 (select string_agg(new_table::text, ', ' order by a) from new_table);
+    return null;
+  end;
+$$;
+create or replace function dump_update() returns trigger language plpgsql as
+$$
+  begin
+    raise notice 'trigger = %, old table = %, new table = %',
+                 TG_NAME,
+                 (select string_agg(old_table::text, ', ' order by a) from old_table),
+                 (select string_agg(new_table::text, ', ' order by a) from new_table);
+    return null;
+  end;
+$$;
+create or replace function dump_delete() returns trigger language plpgsql as
+$$
+  begin
+    raise notice 'trigger = %, old table = %',
+                 TG_NAME,
+                 (select string_agg(old_table::text, ', ' order by a) from old_table);
+    return null;
+  end;
+$$;
+--
+-- Verify behavior of statement triggers on partition hierarchy with
+-- transition tables.  Tuples should appear to each trigger in the
+-- format of the relation the trigger is attached to.
+--
+-- set up a partition hierarchy with some different TupleDescriptors
+create table parent (a text, b int) partition by list (a);
+-- a child matching parent
+create table child1 partition of parent for values in ('AAA');
+-- a child with a dropped column
+create table child2 (x int, a text, b int);
+alter table child2 drop column x;
+alter table parent attach partition child2 for values in ('BBB');
+-- a child with a different column order
+create table child3 (b int, a text);
+alter table parent attach partition child3 for values in ('CCC');
+create trigger parent_insert_trig
+  after insert on parent referencing new table as new_table
+  for each statement execute procedure dump_insert();
+create trigger parent_update_trig
+  after update on parent referencing old table as old_table new table as new_table
+  for each statement execute procedure dump_update();
+create trigger parent_delete_trig
+  after delete on parent referencing old table as old_table
+  for each statement execute procedure dump_delete();
+create trigger child1_insert_trig
+  after insert on child1 referencing new table as new_table
+  for each statement execute procedure dump_insert();
+create trigger child1_update_trig
+  after update on child1 referencing old table as old_table new table as new_table
+  for each statement execute procedure dump_update();
+create trigger child1_delete_trig
+  after delete on child1 referencing old table as old_table
+  for each statement execute procedure dump_delete();
+create trigger child2_insert_trig
+  after insert on child2 referencing new table as new_table
+  for each statement execute procedure dump_insert();
+create trigger child2_update_trig
+  after update on child2 referencing old table as old_table new table as new_table
+  for each statement execute procedure dump_update();
+create trigger child2_delete_trig
+  after delete on child2 referencing old table as old_table
+  for each statement execute procedure dump_delete();
+create trigger child3_insert_trig
+  after insert on child3 referencing new table as new_table
+  for each statement execute procedure dump_insert();
+create trigger child3_update_trig
+  after update on child3 referencing old table as old_table new table as new_table
+  for each statement execute procedure dump_update();
+create trigger child3_delete_trig
+  after delete on child3 referencing old table as old_table
+  for each statement execute procedure dump_delete();
+SELECT trigger_name, event_manipulation, event_object_schema, event_object_table,
+       action_order, action_condition, action_orientation, action_timing,
+       action_reference_old_table, action_reference_new_table
+  FROM information_schema.triggers
+  WHERE event_object_table IN ('parent', 'child1', 'child2', 'child3')
+  ORDER BY trigger_name COLLATE "C", 2;
+    trigger_name    | event_manipulation | event_object_schema | event_object_table | action_order | action_condition | action_orientation | action_timing | action_reference_old_table | action_reference_new_table 
+--------------------+--------------------+---------------------+--------------------+--------------+------------------+--------------------+---------------+----------------------------+----------------------------
+ child1_delete_trig | DELETE             | public              | child1             |            1 |                  | STATEMENT          | AFTER         | old_table                  | 
+ child1_insert_trig | INSERT             | public              | child1             |            1 |                  | STATEMENT          | AFTER         |                            | new_table
+ child1_update_trig | UPDATE             | public              | child1             |            1 |                  | STATEMENT          | AFTER         | old_table                  | new_table
+ child2_delete_trig | DELETE             | public              | child2             |            1 |                  | STATEMENT          | AFTER         | old_table                  | 
+ child2_insert_trig | INSERT             | public              | child2             |            1 |                  | STATEMENT          | AFTER         |                            | new_table
+ child2_update_trig | UPDATE             | public              | child2             |            1 |                  | STATEMENT          | AFTER         | old_table                  | new_table
+ child3_delete_trig | DELETE             | public              | child3             |            1 |                  | STATEMENT          | AFTER         | old_table                  | 
+ child3_insert_trig | INSERT             | public              | child3             |            1 |                  | STATEMENT          | AFTER         |                            | new_table
+ child3_update_trig | UPDATE             | public              | child3             |            1 |                  | STATEMENT          | AFTER         | old_table                  | new_table
+ parent_delete_trig | DELETE             | public              | parent             |            1 |                  | STATEMENT          | AFTER         | old_table                  | 
+ parent_insert_trig | INSERT             | public              | parent             |            1 |                  | STATEMENT          | AFTER         |                            | new_table
+ parent_update_trig | UPDATE             | public              | parent             |            1 |                  | STATEMENT          | AFTER         | old_table                  | new_table
+(12 rows)
+
+-- insert directly into children sees respective child-format tuples
+insert into child1 values ('AAA', 42);
+NOTICE:  trigger = child1_insert_trig, new table = (AAA,42)
+insert into child2 values ('BBB', 42);
+NOTICE:  trigger = child2_insert_trig, new table = (BBB,42)
+insert into child3 values (42, 'CCC');
+NOTICE:  trigger = child3_insert_trig, new table = (42,CCC)
+-- update via parent sees parent-format tuples
+update parent set b = b + 1;
+NOTICE:  trigger = parent_update_trig, old table = (AAA,42), (BBB,42), (CCC,42), new table = (AAA,43), (BBB,43), (CCC,43)
+-- delete via parent sees parent-format tuples
+delete from parent;
+NOTICE:  trigger = parent_delete_trig, old table = (AAA,43), (BBB,43), (CCC,43)
+-- insert into parent sees parent-format tuples
+insert into parent values ('AAA', 42);
+NOTICE:  trigger = parent_insert_trig, new table = (AAA,42)
+insert into parent values ('BBB', 42);
+NOTICE:  trigger = parent_insert_trig, new table = (BBB,42)
+insert into parent values ('CCC', 42);
+NOTICE:  trigger = parent_insert_trig, new table = (CCC,42)
+-- delete from children sees respective child-format tuples
+delete from child1;
+NOTICE:  trigger = child1_delete_trig, old table = (AAA,42)
+delete from child2;
+NOTICE:  trigger = child2_delete_trig, old table = (BBB,42)
+delete from child3;
+NOTICE:  trigger = child3_delete_trig, old table = (42,CCC)
+-- copy into parent sees parent-format tuples
+copy parent (a, b) from stdin;
+NOTICE:  trigger = parent_insert_trig, new table = (AAA,42), (BBB,42), (CCC,42)
+-- DML affecting parent sees tuples collected from children even if
+-- there is no transition table trigger on the children
+drop trigger child1_insert_trig on child1;
+drop trigger child1_update_trig on child1;
+drop trigger child1_delete_trig on child1;
+drop trigger child2_insert_trig on child2;
+drop trigger child2_update_trig on child2;
+drop trigger child2_delete_trig on child2;
+drop trigger child3_insert_trig on child3;
+drop trigger child3_update_trig on child3;
+drop trigger child3_delete_trig on child3;
+delete from parent;
+NOTICE:  trigger = parent_delete_trig, old table = (AAA,42), (BBB,42), (CCC,42)
+-- copy into parent sees tuples collected from children even if there
+-- is no transition-table trigger on the children
+copy parent (a, b) from stdin;
+NOTICE:  trigger = parent_insert_trig, new table = (AAA,42), (BBB,42), (CCC,42)
+-- insert into parent with a before trigger on a child tuple before
+-- insertion, and we capture the newly modified row in parent format
+create or replace function intercept_insert() returns trigger language plpgsql as
+$$
+  begin
+    new.b = new.b + 1000;
+    return new;
+  end;
+$$;
+create trigger intercept_insert_child3
+  before insert on child3
+  for each row execute procedure intercept_insert();
+-- insert, parent trigger sees post-modification parent-format tuple
+insert into parent values ('AAA', 42), ('BBB', 42), ('CCC', 66);
+NOTICE:  trigger = parent_insert_trig, new table = (AAA,42), (BBB,42), (CCC,1066)
+-- copy, parent trigger sees post-modification parent-format tuple
+copy parent (a, b) from stdin;
+NOTICE:  trigger = parent_insert_trig, new table = (AAA,42), (BBB,42), (CCC,1234)
+drop table child1, child2, child3, parent;
+drop function intercept_insert();
+--
+-- Verify prohibition of row triggers with transition triggers on
+-- partitions
+--
+create table parent (a text, b int) partition by list (a);
+create table child partition of parent for values in ('AAA');
+-- adding row trigger with transition table fails
+create trigger child_row_trig
+  after insert on child referencing new table as new_table
+  for each row execute procedure dump_insert();
+ERROR:  ROW triggers with transition tables are not supported on partitions
+-- detaching it first works
+alter table parent detach partition child;
+create trigger child_row_trig
+  after insert on child referencing new table as new_table
+  for each row execute procedure dump_insert();
+-- but now we're not allowed to reattach it
+alter table parent attach partition child for values in ('AAA');
+ERROR:  trigger "child_row_trig" prevents table "child" from becoming a partition
+DETAIL:  ROW triggers with transition tables are not supported on partitions
+-- drop the trigger, and now we're allowed to attach it again
+drop trigger child_row_trig on child;
+alter table parent attach partition child for values in ('AAA');
+drop table child, parent;
+--
+-- Verify behavior of statement triggers on (non-partition)
+-- inheritance hierarchy with transition tables; similar to the
+-- partition case, except there is no rerouting on insertion and child
+-- tables can have extra columns
+--
+-- set up inheritance hierarchy with different TupleDescriptors
+create table parent (a text, b int);
+-- a child matching parent
+create table child1 () inherits (parent);
+-- a child with a different column order
+create table child2 (b int, a text);
+alter table child2 inherit parent;
+-- a child with an extra column
+create table child3 (c text) inherits (parent);
+create trigger parent_insert_trig
+  after insert on parent referencing new table as new_table
+  for each statement execute procedure dump_insert();
+create trigger parent_update_trig
+  after update on parent referencing old table as old_table new table as new_table
+  for each statement execute procedure dump_update();
+create trigger parent_delete_trig
+  after delete on parent referencing old table as old_table
+  for each statement execute procedure dump_delete();
+create trigger child1_insert_trig
+  after insert on child1 referencing new table as new_table
+  for each statement execute procedure dump_insert();
+create trigger child1_update_trig
+  after update on child1 referencing old table as old_table new table as new_table
+  for each statement execute procedure dump_update();
+create trigger child1_delete_trig
+  after delete on child1 referencing old table as old_table
+  for each statement execute procedure dump_delete();
+create trigger child2_insert_trig
+  after insert on child2 referencing new table as new_table
+  for each statement execute procedure dump_insert();
+create trigger child2_update_trig
+  after update on child2 referencing old table as old_table new table as new_table
+  for each statement execute procedure dump_update();
+create trigger child2_delete_trig
+  after delete on child2 referencing old table as old_table
+  for each statement execute procedure dump_delete();
+create trigger child3_insert_trig
+  after insert on child3 referencing new table as new_table
+  for each statement execute procedure dump_insert();
+create trigger child3_update_trig
+  after update on child3 referencing old table as old_table new table as new_table
+  for each statement execute procedure dump_update();
+create trigger child3_delete_trig
+  after delete on child3 referencing old table as old_table
+  for each statement execute procedure dump_delete();
+-- insert directly into children sees respective child-format tuples
+insert into child1 values ('AAA', 42);
+NOTICE:  trigger = child1_insert_trig, new table = (AAA,42)
+insert into child2 values (42, 'BBB');
+NOTICE:  trigger = child2_insert_trig, new table = (42,BBB)
+insert into child3 values ('CCC', 42, 'foo');
+NOTICE:  trigger = child3_insert_trig, new table = (CCC,42,foo)
+-- update via parent sees parent-format tuples
+update parent set b = b + 1;
+NOTICE:  trigger = parent_update_trig, old table = (AAA,42), (BBB,42), (CCC,42), new table = (AAA,43), (BBB,43), (CCC,43)
+-- delete via parent sees parent-format tuples
+delete from parent;
+NOTICE:  trigger = parent_delete_trig, old table = (AAA,43), (BBB,43), (CCC,43)
+-- reinsert values into children for next test...
+insert into child1 values ('AAA', 42);
+NOTICE:  trigger = child1_insert_trig, new table = (AAA,42)
+insert into child2 values (42, 'BBB');
+NOTICE:  trigger = child2_insert_trig, new table = (42,BBB)
+insert into child3 values ('CCC', 42, 'foo');
+NOTICE:  trigger = child3_insert_trig, new table = (CCC,42,foo)
+-- delete from children sees respective child-format tuples
+delete from child1;
+NOTICE:  trigger = child1_delete_trig, old table = (AAA,42)
+delete from child2;
+NOTICE:  trigger = child2_delete_trig, old table = (42,BBB)
+delete from child3;
+NOTICE:  trigger = child3_delete_trig, old table = (CCC,42,foo)
+-- copy into parent sees parent-format tuples (no rerouting, so these
+-- are really inserted into the parent)
+copy parent (a, b) from stdin;
+NOTICE:  trigger = parent_insert_trig, new table = (AAA,42), (BBB,42), (CCC,42)
+-- same behavior for copy if there is an index (interesting because rows are
+-- captured by a different code path in copy.c if there are indexes)
+create index on parent(b);
+copy parent (a, b) from stdin;
+NOTICE:  trigger = parent_insert_trig, new table = (DDD,42)
+-- DML affecting parent sees tuples collected from children even if
+-- there is no transition table trigger on the children
+drop trigger child1_insert_trig on child1;
+drop trigger child1_update_trig on child1;
+drop trigger child1_delete_trig on child1;
+drop trigger child2_insert_trig on child2;
+drop trigger child2_update_trig on child2;
+drop trigger child2_delete_trig on child2;
+drop trigger child3_insert_trig on child3;
+drop trigger child3_update_trig on child3;
+drop trigger child3_delete_trig on child3;
+delete from parent;
+NOTICE:  trigger = parent_delete_trig, old table = (AAA,42), (BBB,42), (CCC,42), (DDD,42)
+drop table child1, child2, child3, parent;
+--
+-- Verify prohibition of row triggers with transition triggers on
+-- inheritance children
+--
+create table parent (a text, b int);
+create table child () inherits (parent);
+-- adding row trigger with transition table fails
+create trigger child_row_trig
+  after insert on child referencing new table as new_table
+  for each row execute procedure dump_insert();
+ERROR:  ROW triggers with transition tables are not supported on inheritance children
+-- disinheriting it first works
+alter table child no inherit parent;
+create trigger child_row_trig
+  after insert on child referencing new table as new_table
+  for each row execute procedure dump_insert();
+-- but now we're not allowed to make it inherit anymore
+alter table child inherit parent;
+ERROR:  trigger "child_row_trig" prevents table "child" from becoming an inheritance child
+DETAIL:  ROW triggers with transition tables are not supported in inheritance hierarchies.
+-- drop the trigger, and now we're allowed to make it inherit again
+drop trigger child_row_trig on child;
+alter table child inherit parent;
+drop table child, parent;
+--
+-- Verify behavior of queries with wCTEs, where multiple transition
+-- tuplestores can be active at the same time because there are
+-- multiple DML statements that might fire triggers with transition
+-- tables
+--
+create table table1 (a int);
+create table table2 (a text);
+create trigger table1_trig
+  after insert on table1 referencing new table as new_table
+  for each statement execute procedure dump_insert();
+create trigger table2_trig
+  after insert on table2 referencing new table as new_table
+  for each statement execute procedure dump_insert();
+with wcte as (insert into table1 values (42))
+  insert into table2 values ('hello world');
+NOTICE:  trigger = table2_trig, new table = ("hello world")
+NOTICE:  trigger = table1_trig, new table = (42)
+with wcte as (insert into table1 values (43))
+  insert into table1 values (44);
+NOTICE:  trigger = table1_trig, new table = (43), (44)
+select * from table1;
+ a  
+----
+ 42
+ 44
+ 43
+(3 rows)
+
+select * from table2;
+      a      
+-------------
+ hello world
+(1 row)
+
+drop table table1;
+drop table table2;
+--
+-- Verify behavior of INSERT ... ON CONFLICT DO UPDATE ... with
+-- transition tables.
+--
+create table my_table (a int primary key, b text);
+create trigger my_table_insert_trig
+  after insert on my_table referencing new table as new_table
+  for each statement execute procedure dump_insert();
+create trigger my_table_update_trig
+  after update on my_table referencing old table as old_table new table as new_table
+  for each statement execute procedure dump_update();
+-- inserts only
+insert into my_table values (1, 'AAA'), (2, 'BBB')
+  on conflict (a) do
+  update set b = my_table.b || ':' || excluded.b;
+NOTICE:  trigger = my_table_update_trig, old table = <NULL>, new table = <NULL>
+NOTICE:  trigger = my_table_insert_trig, new table = (1,AAA), (2,BBB)
+-- mixture of inserts and updates
+insert into my_table values (1, 'AAA'), (2, 'BBB'), (3, 'CCC'), (4, 'DDD')
+  on conflict (a) do
+  update set b = my_table.b || ':' || excluded.b;
+NOTICE:  trigger = my_table_update_trig, old table = (1,AAA), (2,BBB), new table = (1,AAA:AAA), (2,BBB:BBB)
+NOTICE:  trigger = my_table_insert_trig, new table = (3,CCC), (4,DDD)
+-- updates only
+insert into my_table values (3, 'CCC'), (4, 'DDD')
+  on conflict (a) do
+  update set b = my_table.b || ':' || excluded.b;
+NOTICE:  trigger = my_table_update_trig, old table = (3,CCC), (4,DDD), new table = (3,CCC:CCC), (4,DDD:DDD)
+NOTICE:  trigger = my_table_insert_trig, new table = <NULL>
+--
+-- now using a partitioned table
+--
+create table iocdu_tt_parted (a int primary key, b text) partition by list (a);
+create table iocdu_tt_parted1 partition of iocdu_tt_parted for values in (1);
+create table iocdu_tt_parted2 partition of iocdu_tt_parted for values in (2);
+create table iocdu_tt_parted3 partition of iocdu_tt_parted for values in (3);
+create table iocdu_tt_parted4 partition of iocdu_tt_parted for values in (4);
+create trigger iocdu_tt_parted_insert_trig
+  after insert on iocdu_tt_parted referencing new table as new_table
+  for each statement execute procedure dump_insert();
+create trigger iocdu_tt_parted_update_trig
+  after update on iocdu_tt_parted referencing old table as old_table new table as new_table
+  for each statement execute procedure dump_update();
+-- inserts only
+insert into iocdu_tt_parted values (1, 'AAA'), (2, 'BBB')
+  on conflict (a) do
+  update set b = iocdu_tt_parted.b || ':' || excluded.b;
+NOTICE:  trigger = iocdu_tt_parted_update_trig, old table = <NULL>, new table = <NULL>
+NOTICE:  trigger = iocdu_tt_parted_insert_trig, new table = (1,AAA), (2,BBB)
+-- mixture of inserts and updates
+insert into iocdu_tt_parted values (1, 'AAA'), (2, 'BBB'), (3, 'CCC'), (4, 'DDD')
+  on conflict (a) do
+  update set b = iocdu_tt_parted.b || ':' || excluded.b;
+NOTICE:  trigger = iocdu_tt_parted_update_trig, old table = (1,AAA), (2,BBB), new table = (1,AAA:AAA), (2,BBB:BBB)
+NOTICE:  trigger = iocdu_tt_parted_insert_trig, new table = (3,CCC), (4,DDD)
+-- updates only
+insert into iocdu_tt_parted values (3, 'CCC'), (4, 'DDD')
+  on conflict (a) do
+  update set b = iocdu_tt_parted.b || ':' || excluded.b;
+NOTICE:  trigger = iocdu_tt_parted_update_trig, old table = (3,CCC), (4,DDD), new table = (3,CCC:CCC), (4,DDD:DDD)
+NOTICE:  trigger = iocdu_tt_parted_insert_trig, new table = <NULL>
+drop table iocdu_tt_parted;
+--
+-- Verify that you can't create a trigger with transition tables for
+-- more than one event.
+--
+create trigger my_table_multievent_trig
+  after insert or update on my_table referencing new table as new_table
+  for each statement execute procedure dump_insert();
+ERROR:  transition tables cannot be specified for triggers with more than one event
+--
+-- Verify that you can't create a trigger with transition tables with
+-- a column list.
+--
+create trigger my_table_col_update_trig
+  after update of b on my_table referencing new table as new_table
+  for each statement execute procedure dump_insert();
+ERROR:  transition tables cannot be specified for triggers with column lists
+drop table my_table;
+--
+-- Test firing of triggers with transition tables by foreign key cascades
+--
+create table refd_table (a int primary key, b text);
+create table trig_table (a int, b text,
+  foreign key (a) references refd_table on update cascade on delete cascade
+);
+create trigger trig_table_before_trig
+  before insert or update or delete on trig_table
+  for each statement execute procedure trigger_func('trig_table');
+create trigger trig_table_insert_trig
+  after insert on trig_table referencing new table as new_table
+  for each statement execute procedure dump_insert();
+create trigger trig_table_update_trig
+  after update on trig_table referencing old table as old_table new table as new_table
+  for each statement execute procedure dump_update();
+create trigger trig_table_delete_trig
+  after delete on trig_table referencing old table as old_table
+  for each statement execute procedure dump_delete();
+insert into refd_table values
+  (1, 'one'),
+  (2, 'two'),
+  (3, 'three');
+insert into trig_table values
+  (1, 'one a'),
+  (1, 'one b'),
+  (2, 'two a'),
+  (2, 'two b'),
+  (3, 'three a'),
+  (3, 'three b');
+NOTICE:  trigger_func(trig_table) called: action = INSERT, when = BEFORE, level = STATEMENT
+NOTICE:  trigger = trig_table_insert_trig, new table = (1,"one a"), (1,"one b"), (2,"two a"), (2,"two b"), (3,"three a"), (3,"three b")
+update refd_table set a = 11 where b = 'one';
+NOTICE:  trigger_func(trig_table) called: action = UPDATE, when = BEFORE, level = STATEMENT
+NOTICE:  trigger = trig_table_update_trig, old table = (1,"one a"), (1,"one b"), new table = (11,"one a"), (11,"one b")
+select * from trig_table order by a, b;
+ a  |    b    
+----+---------
+  2 | two a
+  2 | two b
+  3 | three a
+  3 | three b
+ 11 | one a
+ 11 | one b
+(6 rows)
+
+delete from refd_table where length(b) = 3;
+NOTICE:  trigger_func(trig_table) called: action = DELETE, when = BEFORE, level = STATEMENT
+NOTICE:  trigger = trig_table_delete_trig, old table = (2,"two a"), (2,"two b"), (11,"one a"), (11,"one b")
+select * from trig_table;
+ a |    b    
+---+---------
+ 3 | three a
+ 3 | three b
+(2 rows)
+
+drop table refd_table, trig_table;
+--
+-- self-referential FKs are even more fun
+--
+create table self_ref (a int primary key,
+                       b int references self_ref(a) on delete cascade);
+create trigger self_ref_before_trig
+  before delete on self_ref
+  for each statement execute procedure trigger_func('self_ref');
+create trigger self_ref_r_trig
+  after delete on self_ref referencing old table as old_table
+  for each row execute procedure dump_delete();
+create trigger self_ref_s_trig
+  after delete on self_ref referencing old table as old_table
+  for each statement execute procedure dump_delete();
+insert into self_ref values (1, null), (2, 1), (3, 2);
+delete from self_ref where a = 1;
+NOTICE:  trigger_func(self_ref) called: action = DELETE, when = BEFORE, level = STATEMENT
+NOTICE:  trigger = self_ref_r_trig, old table = (1,), (2,1)
+NOTICE:  trigger_func(self_ref) called: action = DELETE, when = BEFORE, level = STATEMENT
+NOTICE:  trigger = self_ref_r_trig, old table = (1,), (2,1)
+NOTICE:  trigger = self_ref_s_trig, old table = (1,), (2,1)
+NOTICE:  trigger = self_ref_r_trig, old table = (3,2)
+NOTICE:  trigger = self_ref_s_trig, old table = (3,2)
+-- without AR trigger, cascaded deletes all end up in one transition table
+drop trigger self_ref_r_trig on self_ref;
+insert into self_ref values (1, null), (2, 1), (3, 2), (4, 3);
+delete from self_ref where a = 1;
+NOTICE:  trigger_func(self_ref) called: action = DELETE, when = BEFORE, level = STATEMENT
+NOTICE:  trigger = self_ref_s_trig, old table = (1,), (2,1), (3,2), (4,3)
+drop table self_ref;
+-- cleanup
+drop function dump_insert();
+drop function dump_update();
+drop function dump_delete();
diff --git a/src/test/regress/expected/updatable_views.out b/src/test/regress/expected/updatable_views.out
index 86a2642..6659e4e 100644
--- a/src/test/regress/expected/updatable_views.out
+++ b/src/test/regress/expected/updatable_views.out
@@ -1227,12 +1227,12 @@ CREATE TRIGGER rw_view1_ins_trig AFTER INSERT ON base_tbl
   FOR EACH ROW EXECUTE PROCEDURE rw_view1_trig_fn();
 CREATE VIEW rw_view1 AS SELECT a AS aa, b AS bb FROM base_tbl;
 INSERT INTO rw_view1 VALUES (3, 'Row 3');
-select * from base_tbl;
+select * from base_tbl ORDER BY a;
  a |   b   
 ---+-------
+ 1 | Row 3
  2 | Row 2
  3 | Row 3
- 1 | Row 3
 (3 rows)
 
 DROP VIEW rw_view1;
@@ -1645,12 +1645,12 @@ INSERT INTO rw_view1(a) VALUES (9); -- ok
 INSERT INTO rw_view1(a) VALUES (10); -- should fail
 ERROR:  new row violates check option for view "rw_view1"
 DETAIL:  Failing row contains (10, 10).
-SELECT * FROM base_tbl;
+SELECT * FROM base_tbl order by a, b;
  a | b  
 ---+----
+ 1 | -1
  1 |  2
  2 |  3
- 1 | -1
  3 |  5
  9 | 10
 (5 rows)
@@ -1725,11 +1725,11 @@ INSERT INTO rw_view2 VALUES (-10); -- ok, but not in view
 INSERT INTO rw_view2 VALUES (20); -- should fail
 ERROR:  new row violates check option for view "rw_view2"
 DETAIL:  Failing row contains (20).
-SELECT * FROM base_tbl;
+SELECT * FROM base_tbl order by a;
   a  
 -----
-   5
  -10
+   5
 (2 rows)
 
 ALTER VIEW rw_view1 SET (check_option=here); -- invalid
@@ -1762,11 +1762,11 @@ SELECT * FROM information_schema.views WHERE table_name = 'rw_view2';
 (1 row)
 
 INSERT INTO rw_view2 VALUES (30); -- ok, but not in view
-SELECT * FROM base_tbl;
+SELECT * FROM base_tbl order by a;
   a  
 -----
-   5
  -10
+   5
   30
 (3 rows)
 
@@ -1927,7 +1927,7 @@ INSERT INTO rw_view2 VALUES (50); -- ok, but not in view
 UPDATE rw_view2 SET a = a - 10; -- should fail
 ERROR:  new row violates check option for view "rw_view2"
 DETAIL:  Failing row contains (-5).
-SELECT * FROM base_tbl;
+SELECT * FROM base_tbl order by a, b;
  a  | b  
 ----+----
   5 | 10
@@ -1938,7 +1938,7 @@ SELECT * FROM base_tbl;
 ALTER VIEW rw_view2 SET (check_option=cascaded);
 INSERT INTO rw_view2 VALUES (100); -- ok, but not in view (doesn't fail rw_view1's check)
 UPDATE rw_view2 SET a = 200 WHERE a = 5; -- ok, but not in view (doesn't fail rw_view1's check)
-SELECT * FROM base_tbl;
+SELECT * FROM base_tbl ORDER BY a;
   a  | b  
 -----+----
   50 | 10
@@ -1958,16 +1958,16 @@ INSERT INTO rw_view2 VALUES (20); -- ok, but not in view (doesn't fail rw_view1'
 UPDATE rw_view2 SET a = 30 WHERE a = 5; -- ok, but not in view (doesn't fail rw_view1's check)
 INSERT INTO rw_view2 VALUES (5); -- ok
 UPDATE rw_view2 SET a = -5 WHERE a = 5; -- ok, but not in view (doesn't fail rw_view2's check)
-SELECT * FROM base_tbl;
+SELECT * FROM base_tbl ORDER BY a;
   a  | b  
 -----+----
-  50 | 10
- 100 | 10
- 200 | 10
  -10 | 10
+  -5 | 10
   20 | 10
   30 | 10
-  -5 | 10
+  50 | 10
+ 100 | 10
+ 200 | 10
 (7 rows)
 
 DROP TABLE base_tbl CASCADE;
diff --git a/src/test/regress/expected/updatable_views_1.out b/src/test/regress/expected/updatable_views_1.out
new file mode 100644
index 0000000..e97064d
--- /dev/null
+++ b/src/test/regress/expected/updatable_views_1.out
@@ -0,0 +1,3015 @@
+--
+-- UPDATABLE VIEWS
+--
+-- avoid bit-exact output here because operations may not be bit-exact.
+SET extra_float_digits = 0;
+-- check that non-updatable views and columns are rejected with useful error
+-- messages
+CREATE TABLE base_tbl (a int PRIMARY KEY, b text DEFAULT 'Unspecified');
+INSERT INTO base_tbl SELECT i, 'Row ' || i FROM generate_series(-2, 2) g(i);
+CREATE VIEW ro_view1 AS SELECT DISTINCT a, b FROM base_tbl; -- DISTINCT not supported
+CREATE VIEW ro_view2 AS SELECT a, b FROM base_tbl GROUP BY a, b; -- GROUP BY not supported
+CREATE VIEW ro_view3 AS SELECT 1 FROM base_tbl HAVING max(a) > 0; -- HAVING not supported
+CREATE VIEW ro_view4 AS SELECT count(*) FROM base_tbl; -- Aggregate functions not supported
+CREATE VIEW ro_view5 AS SELECT a, rank() OVER() FROM base_tbl; -- Window functions not supported
+CREATE VIEW ro_view6 AS SELECT a, b FROM base_tbl UNION SELECT -a, b FROM base_tbl; -- Set ops not supported
+CREATE VIEW ro_view7 AS WITH t AS (SELECT a, b FROM base_tbl) SELECT * FROM t; -- WITH not supported
+CREATE VIEW ro_view8 AS SELECT a, b FROM base_tbl ORDER BY a OFFSET 1; -- OFFSET not supported
+CREATE VIEW ro_view9 AS SELECT a, b FROM base_tbl ORDER BY a LIMIT 1; -- LIMIT not supported
+CREATE VIEW ro_view10 AS SELECT 1 AS a; -- No base relations
+CREATE VIEW ro_view11 AS SELECT b1.a, b2.b FROM base_tbl b1, base_tbl b2; -- Multiple base relations
+CREATE VIEW ro_view12 AS SELECT * FROM generate_series(1, 10) AS g(a); -- SRF in rangetable
+CREATE VIEW ro_view13 AS SELECT a, b FROM (SELECT * FROM base_tbl) AS t; -- Subselect in rangetable
+CREATE VIEW rw_view14 AS SELECT ctid, a, b FROM base_tbl; -- System columns may be part of an updatable view
+CREATE VIEW rw_view15 AS SELECT a, upper(b) FROM base_tbl; -- Expression/function may be part of an updatable view
+CREATE VIEW rw_view16 AS SELECT a, b, a AS aa FROM base_tbl; -- Repeated column may be part of an updatable view
+CREATE VIEW ro_view17 AS SELECT * FROM ro_view1; -- Base relation not updatable
+CREATE VIEW ro_view18 AS SELECT * FROM (VALUES(1)) AS tmp(a); -- VALUES in rangetable
+CREATE SEQUENCE uv_seq;
+CREATE VIEW ro_view19 AS SELECT * FROM uv_seq; -- View based on a sequence
+CREATE VIEW ro_view20 AS SELECT a, b, generate_series(1, a) g FROM base_tbl; -- SRF in targetlist not supported
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name LIKE E'r_\\_view%'
+ ORDER BY table_name;
+ table_name | is_insertable_into 
+------------+--------------------
+ ro_view1   | NO
+ ro_view10  | NO
+ ro_view11  | NO
+ ro_view12  | NO
+ ro_view13  | NO
+ ro_view17  | NO
+ ro_view18  | NO
+ ro_view19  | NO
+ ro_view2   | NO
+ ro_view20  | NO
+ ro_view3   | NO
+ ro_view4   | NO
+ ro_view5   | NO
+ ro_view6   | NO
+ ro_view7   | NO
+ ro_view8   | NO
+ ro_view9   | NO
+ rw_view14  | YES
+ rw_view15  | YES
+ rw_view16  | YES
+(20 rows)
+
+SELECT table_name, is_updatable, is_insertable_into
+  FROM information_schema.views
+ WHERE table_name LIKE E'r_\\_view%'
+ ORDER BY table_name;
+ table_name | is_updatable | is_insertable_into 
+------------+--------------+--------------------
+ ro_view1   | NO           | NO
+ ro_view10  | NO           | NO
+ ro_view11  | NO           | NO
+ ro_view12  | NO           | NO
+ ro_view13  | NO           | NO
+ ro_view17  | NO           | NO
+ ro_view18  | NO           | NO
+ ro_view19  | NO           | NO
+ ro_view2   | NO           | NO
+ ro_view20  | NO           | NO
+ ro_view3   | NO           | NO
+ ro_view4   | NO           | NO
+ ro_view5   | NO           | NO
+ ro_view6   | NO           | NO
+ ro_view7   | NO           | NO
+ ro_view8   | NO           | NO
+ ro_view9   | NO           | NO
+ rw_view14  | YES          | YES
+ rw_view15  | YES          | YES
+ rw_view16  | YES          | YES
+(20 rows)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name LIKE E'r_\\_view%'
+ ORDER BY table_name, ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ ro_view1   | a           | NO
+ ro_view1   | b           | NO
+ ro_view10  | a           | NO
+ ro_view11  | a           | NO
+ ro_view11  | b           | NO
+ ro_view12  | a           | NO
+ ro_view13  | a           | NO
+ ro_view13  | b           | NO
+ ro_view17  | a           | NO
+ ro_view17  | b           | NO
+ ro_view18  | a           | NO
+ ro_view19  | last_value  | NO
+ ro_view19  | log_cnt     | NO
+ ro_view19  | is_called   | NO
+ ro_view2   | a           | NO
+ ro_view2   | b           | NO
+ ro_view20  | a           | NO
+ ro_view20  | b           | NO
+ ro_view20  | g           | NO
+ ro_view3   | ?column?    | NO
+ ro_view4   | count       | NO
+ ro_view5   | a           | NO
+ ro_view5   | rank        | NO
+ ro_view6   | a           | NO
+ ro_view6   | b           | NO
+ ro_view7   | a           | NO
+ ro_view7   | b           | NO
+ ro_view8   | a           | NO
+ ro_view8   | b           | NO
+ ro_view9   | a           | NO
+ ro_view9   | b           | NO
+ rw_view14  | ctid        | NO
+ rw_view14  | a           | YES
+ rw_view14  | b           | YES
+ rw_view15  | a           | YES
+ rw_view15  | upper       | NO
+ rw_view16  | a           | YES
+ rw_view16  | b           | YES
+ rw_view16  | aa          | YES
+(39 rows)
+
+-- Read-only views
+DELETE FROM ro_view1;
+ERROR:  cannot delete from view "ro_view1"
+DETAIL:  Views containing DISTINCT are not automatically updatable.
+HINT:  To enable deleting from the view, provide an INSTEAD OF DELETE trigger or an unconditional ON DELETE DO INSTEAD rule.
+DELETE FROM ro_view2;
+ERROR:  cannot delete from view "ro_view2"
+DETAIL:  Views containing GROUP BY are not automatically updatable.
+HINT:  To enable deleting from the view, provide an INSTEAD OF DELETE trigger or an unconditional ON DELETE DO INSTEAD rule.
+DELETE FROM ro_view3;
+ERROR:  cannot delete from view "ro_view3"
+DETAIL:  Views containing HAVING are not automatically updatable.
+HINT:  To enable deleting from the view, provide an INSTEAD OF DELETE trigger or an unconditional ON DELETE DO INSTEAD rule.
+DELETE FROM ro_view4;
+ERROR:  cannot delete from view "ro_view4"
+DETAIL:  Views that return aggregate functions are not automatically updatable.
+HINT:  To enable deleting from the view, provide an INSTEAD OF DELETE trigger or an unconditional ON DELETE DO INSTEAD rule.
+DELETE FROM ro_view5;
+ERROR:  cannot delete from view "ro_view5"
+DETAIL:  Views that return window functions are not automatically updatable.
+HINT:  To enable deleting from the view, provide an INSTEAD OF DELETE trigger or an unconditional ON DELETE DO INSTEAD rule.
+DELETE FROM ro_view6;
+ERROR:  cannot delete from view "ro_view6"
+DETAIL:  Views containing UNION, INTERSECT, or EXCEPT are not automatically updatable.
+HINT:  To enable deleting from the view, provide an INSTEAD OF DELETE trigger or an unconditional ON DELETE DO INSTEAD rule.
+UPDATE ro_view7 SET a=a+1;
+ERROR:  cannot update view "ro_view7"
+DETAIL:  Views containing WITH are not automatically updatable.
+HINT:  To enable updating the view, provide an INSTEAD OF UPDATE trigger or an unconditional ON UPDATE DO INSTEAD rule.
+UPDATE ro_view8 SET a=a+1;
+ERROR:  cannot update view "ro_view8"
+DETAIL:  Views containing LIMIT or OFFSET are not automatically updatable.
+HINT:  To enable updating the view, provide an INSTEAD OF UPDATE trigger or an unconditional ON UPDATE DO INSTEAD rule.
+UPDATE ro_view9 SET a=a+1;
+ERROR:  cannot update view "ro_view9"
+DETAIL:  Views containing LIMIT or OFFSET are not automatically updatable.
+HINT:  To enable updating the view, provide an INSTEAD OF UPDATE trigger or an unconditional ON UPDATE DO INSTEAD rule.
+UPDATE ro_view10 SET a=a+1;
+ERROR:  cannot update view "ro_view10"
+DETAIL:  Views that do not select from a single table or view are not automatically updatable.
+HINT:  To enable updating the view, provide an INSTEAD OF UPDATE trigger or an unconditional ON UPDATE DO INSTEAD rule.
+UPDATE ro_view11 SET a=a+1;
+ERROR:  cannot update view "ro_view11"
+DETAIL:  Views that do not select from a single table or view are not automatically updatable.
+HINT:  To enable updating the view, provide an INSTEAD OF UPDATE trigger or an unconditional ON UPDATE DO INSTEAD rule.
+UPDATE ro_view12 SET a=a+1;
+ERROR:  cannot update view "ro_view12"
+DETAIL:  Views that do not select from a single table or view are not automatically updatable.
+HINT:  To enable updating the view, provide an INSTEAD OF UPDATE trigger or an unconditional ON UPDATE DO INSTEAD rule.
+INSERT INTO ro_view13 VALUES (3, 'Row 3');
+ERROR:  cannot insert into view "ro_view13"
+DETAIL:  Views that do not select from a single table or view are not automatically updatable.
+HINT:  To enable inserting into the view, provide an INSTEAD OF INSERT trigger or an unconditional ON INSERT DO INSTEAD rule.
+-- Partially updatable view
+INSERT INTO rw_view14 VALUES (null, 3, 'Row 3'); -- should fail
+ERROR:  cannot insert into column "ctid" of view "rw_view14"
+DETAIL:  View columns that refer to system columns are not updatable.
+INSERT INTO rw_view14 (a, b) VALUES (3, 'Row 3'); -- should be OK
+UPDATE rw_view14 SET ctid=null WHERE a=3; -- should fail
+ERROR:  cannot update column "ctid" of view "rw_view14"
+DETAIL:  View columns that refer to system columns are not updatable.
+UPDATE rw_view14 SET b='ROW 3' WHERE a=3; -- should be OK
+SELECT * FROM base_tbl;
+ a  |   b    
+----+--------
+ -2 | Row -2
+ -1 | Row -1
+  0 | Row 0
+  1 | Row 1
+  2 | Row 2
+  3 | ROW 3
+(6 rows)
+
+DELETE FROM rw_view14 WHERE a=3; -- should be OK
+-- Partially updatable view
+INSERT INTO rw_view15 VALUES (3, 'ROW 3'); -- should fail
+ERROR:  cannot insert into column "upper" of view "rw_view15"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+INSERT INTO rw_view15 (a) VALUES (3); -- should be OK
+INSERT INTO rw_view15 (a) VALUES (3) ON CONFLICT DO NOTHING; -- succeeds
+SELECT * FROM rw_view15;
+ a  |    upper    
+----+-------------
+ -2 | ROW -2
+ -1 | ROW -1
+  0 | ROW 0
+  1 | ROW 1
+  2 | ROW 2
+  3 | UNSPECIFIED
+(6 rows)
+
+INSERT INTO rw_view15 (a) VALUES (3) ON CONFLICT (a) DO NOTHING; -- succeeds
+SELECT * FROM rw_view15;
+ a  |    upper    
+----+-------------
+ -2 | ROW -2
+ -1 | ROW -1
+  0 | ROW 0
+  1 | ROW 1
+  2 | ROW 2
+  3 | UNSPECIFIED
+(6 rows)
+
+INSERT INTO rw_view15 (a) VALUES (3) ON CONFLICT (a) DO UPDATE set a = excluded.a; -- succeeds
+SELECT * FROM rw_view15;
+ a  |    upper    
+----+-------------
+ -2 | ROW -2
+ -1 | ROW -1
+  0 | ROW 0
+  1 | ROW 1
+  2 | ROW 2
+  3 | UNSPECIFIED
+(6 rows)
+
+INSERT INTO rw_view15 (a) VALUES (3) ON CONFLICT (a) DO UPDATE set upper = 'blarg'; -- fails
+ERROR:  cannot insert into column "upper" of view "rw_view15"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+SELECT * FROM rw_view15;
+ a  |    upper    
+----+-------------
+ -2 | ROW -2
+ -1 | ROW -1
+  0 | ROW 0
+  1 | ROW 1
+  2 | ROW 2
+  3 | UNSPECIFIED
+(6 rows)
+
+SELECT * FROM rw_view15;
+ a  |    upper    
+----+-------------
+ -2 | ROW -2
+ -1 | ROW -1
+  0 | ROW 0
+  1 | ROW 1
+  2 | ROW 2
+  3 | UNSPECIFIED
+(6 rows)
+
+ALTER VIEW rw_view15 ALTER COLUMN upper SET DEFAULT 'NOT SET';
+INSERT INTO rw_view15 (a) VALUES (4); -- should fail
+ERROR:  cannot insert into column "upper" of view "rw_view15"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+UPDATE rw_view15 SET upper='ROW 3' WHERE a=3; -- should fail
+ERROR:  cannot update column "upper" of view "rw_view15"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+UPDATE rw_view15 SET upper=DEFAULT WHERE a=3; -- should fail
+ERROR:  cannot update column "upper" of view "rw_view15"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+UPDATE rw_view15 SET a=4 WHERE a=3; -- should be OK
+SELECT * FROM base_tbl;
+ a  |      b      
+----+-------------
+ -2 | Row -2
+ -1 | Row -1
+  0 | Row 0
+  1 | Row 1
+  2 | Row 2
+  4 | Unspecified
+(6 rows)
+
+DELETE FROM rw_view15 WHERE a=4; -- should be OK
+-- Partially updatable view
+INSERT INTO rw_view16 VALUES (3, 'Row 3', 3); -- should fail
+ERROR:  multiple assignments to same column "a"
+INSERT INTO rw_view16 (a, b) VALUES (3, 'Row 3'); -- should be OK
+UPDATE rw_view16 SET a=3, aa=-3 WHERE a=3; -- should fail
+ERROR:  multiple assignments to same column "a"
+UPDATE rw_view16 SET aa=-3 WHERE a=3; -- should be OK
+SELECT * FROM base_tbl;
+ a  |   b    
+----+--------
+ -2 | Row -2
+ -1 | Row -1
+  0 | Row 0
+  1 | Row 1
+  2 | Row 2
+ -3 | Row 3
+(6 rows)
+
+DELETE FROM rw_view16 WHERE a=-3; -- should be OK
+-- Read-only views
+INSERT INTO ro_view17 VALUES (3, 'ROW 3');
+ERROR:  cannot insert into view "ro_view1"
+DETAIL:  Views containing DISTINCT are not automatically updatable.
+HINT:  To enable inserting into the view, provide an INSTEAD OF INSERT trigger or an unconditional ON INSERT DO INSTEAD rule.
+DELETE FROM ro_view18;
+ERROR:  cannot delete from view "ro_view18"
+DETAIL:  Views that do not select from a single table or view are not automatically updatable.
+HINT:  To enable deleting from the view, provide an INSTEAD OF DELETE trigger or an unconditional ON DELETE DO INSTEAD rule.
+UPDATE ro_view19 SET last_value=1000;
+ERROR:  cannot update view "ro_view19"
+DETAIL:  Views that do not select from a single table or view are not automatically updatable.
+HINT:  To enable updating the view, provide an INSTEAD OF UPDATE trigger or an unconditional ON UPDATE DO INSTEAD rule.
+UPDATE ro_view20 SET b=upper(b);
+ERROR:  cannot update view "ro_view20"
+DETAIL:  Views that return set-returning functions are not automatically updatable.
+HINT:  To enable updating the view, provide an INSTEAD OF UPDATE trigger or an unconditional ON UPDATE DO INSTEAD rule.
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to 16 other objects
+DETAIL:  drop cascades to view ro_view1
+drop cascades to view ro_view17
+drop cascades to view ro_view2
+drop cascades to view ro_view3
+drop cascades to view ro_view4
+drop cascades to view ro_view5
+drop cascades to view ro_view6
+drop cascades to view ro_view7
+drop cascades to view ro_view8
+drop cascades to view ro_view9
+drop cascades to view ro_view11
+drop cascades to view ro_view13
+drop cascades to view rw_view14
+drop cascades to view rw_view15
+drop cascades to view rw_view16
+drop cascades to view ro_view20
+DROP VIEW ro_view10, ro_view12, ro_view18;
+DROP SEQUENCE uv_seq CASCADE;
+NOTICE:  drop cascades to view ro_view19
+-- simple updatable view
+CREATE TABLE base_tbl (a int PRIMARY KEY, b text DEFAULT 'Unspecified');
+INSERT INTO base_tbl SELECT i, 'Row ' || i FROM generate_series(-2, 2) g(i);
+CREATE VIEW rw_view1 AS SELECT * FROM base_tbl WHERE a>0;
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name = 'rw_view1';
+ table_name | is_insertable_into 
+------------+--------------------
+ rw_view1   | YES
+(1 row)
+
+SELECT table_name, is_updatable, is_insertable_into
+  FROM information_schema.views
+ WHERE table_name = 'rw_view1';
+ table_name | is_updatable | is_insertable_into 
+------------+--------------+--------------------
+ rw_view1   | YES          | YES
+(1 row)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name = 'rw_view1'
+ ORDER BY ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ rw_view1   | a           | YES
+ rw_view1   | b           | YES
+(2 rows)
+
+INSERT INTO rw_view1 VALUES (3, 'Row 3');
+INSERT INTO rw_view1 (a) VALUES (4);
+UPDATE rw_view1 SET a=5 WHERE a=4;
+DELETE FROM rw_view1 WHERE b='Row 2';
+SELECT * FROM base_tbl;
+ a  |      b      
+----+-------------
+ -2 | Row -2
+ -1 | Row -1
+  0 | Row 0
+  1 | Row 1
+  3 | Row 3
+  5 | Unspecified
+(6 rows)
+
+EXPLAIN (costs off) UPDATE rw_view1 SET a=6 WHERE a=5;
+                    QUERY PLAN                    
+--------------------------------------------------
+ Update on base_tbl
+   ->  Index Scan using base_tbl_pkey on base_tbl
+         Index Cond: ((a > 0) AND (a = 5))
+(3 rows)
+
+EXPLAIN (costs off) DELETE FROM rw_view1 WHERE a=5;
+                    QUERY PLAN                    
+--------------------------------------------------
+ Delete on base_tbl
+   ->  Index Scan using base_tbl_pkey on base_tbl
+         Index Cond: ((a > 0) AND (a = 5))
+(3 rows)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to view rw_view1
+-- view on top of view
+CREATE TABLE base_tbl (a int PRIMARY KEY, b text DEFAULT 'Unspecified');
+INSERT INTO base_tbl SELECT i, 'Row ' || i FROM generate_series(-2, 2) g(i);
+CREATE VIEW rw_view1 AS SELECT b AS bb, a AS aa FROM base_tbl WHERE a>0;
+CREATE VIEW rw_view2 AS SELECT aa AS aaa, bb AS bbb FROM rw_view1 WHERE aa<10;
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name = 'rw_view2';
+ table_name | is_insertable_into 
+------------+--------------------
+ rw_view2   | YES
+(1 row)
+
+SELECT table_name, is_updatable, is_insertable_into
+  FROM information_schema.views
+ WHERE table_name = 'rw_view2';
+ table_name | is_updatable | is_insertable_into 
+------------+--------------+--------------------
+ rw_view2   | YES          | YES
+(1 row)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name = 'rw_view2'
+ ORDER BY ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ rw_view2   | aaa         | YES
+ rw_view2   | bbb         | YES
+(2 rows)
+
+INSERT INTO rw_view2 VALUES (3, 'Row 3');
+INSERT INTO rw_view2 (aaa) VALUES (4);
+SELECT * FROM rw_view2;
+ aaa |     bbb     
+-----+-------------
+   1 | Row 1
+   2 | Row 2
+   3 | Row 3
+   4 | Unspecified
+(4 rows)
+
+UPDATE rw_view2 SET bbb='Row 4' WHERE aaa=4;
+DELETE FROM rw_view2 WHERE aaa=2;
+SELECT * FROM rw_view2;
+ aaa |  bbb  
+-----+-------
+   1 | Row 1
+   3 | Row 3
+   4 | Row 4
+(3 rows)
+
+EXPLAIN (costs off) UPDATE rw_view2 SET aaa=5 WHERE aaa=4;
+                       QUERY PLAN                       
+--------------------------------------------------------
+ Update on base_tbl
+   ->  Index Scan using base_tbl_pkey on base_tbl
+         Index Cond: ((a < 10) AND (a > 0) AND (a = 4))
+(3 rows)
+
+EXPLAIN (costs off) DELETE FROM rw_view2 WHERE aaa=4;
+                       QUERY PLAN                       
+--------------------------------------------------------
+ Delete on base_tbl
+   ->  Index Scan using base_tbl_pkey on base_tbl
+         Index Cond: ((a < 10) AND (a > 0) AND (a = 4))
+(3 rows)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to view rw_view1
+drop cascades to view rw_view2
+-- view on top of view with rules
+CREATE TABLE base_tbl (a int PRIMARY KEY, b text DEFAULT 'Unspecified');
+INSERT INTO base_tbl SELECT i, 'Row ' || i FROM generate_series(-2, 2) g(i);
+CREATE VIEW rw_view1 AS SELECT * FROM base_tbl WHERE a>0 OFFSET 0; -- not updatable without rules/triggers
+CREATE VIEW rw_view2 AS SELECT * FROM rw_view1 WHERE a<10;
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_insertable_into 
+------------+--------------------
+ rw_view1   | NO
+ rw_view2   | NO
+(2 rows)
+
+SELECT table_name, is_updatable, is_insertable_into
+  FROM information_schema.views
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_updatable | is_insertable_into 
+------------+--------------+--------------------
+ rw_view1   | NO           | NO
+ rw_view2   | NO           | NO
+(2 rows)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name, ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ rw_view1   | a           | NO
+ rw_view1   | b           | NO
+ rw_view2   | a           | NO
+ rw_view2   | b           | NO
+(4 rows)
+
+CREATE RULE rw_view1_ins_rule AS ON INSERT TO rw_view1
+  DO INSTEAD INSERT INTO base_tbl VALUES (NEW.a, NEW.b) RETURNING *;
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_insertable_into 
+------------+--------------------
+ rw_view1   | YES
+ rw_view2   | YES
+(2 rows)
+
+SELECT table_name, is_updatable, is_insertable_into
+  FROM information_schema.views
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_updatable | is_insertable_into 
+------------+--------------+--------------------
+ rw_view1   | NO           | YES
+ rw_view2   | NO           | YES
+(2 rows)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name, ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ rw_view1   | a           | NO
+ rw_view1   | b           | NO
+ rw_view2   | a           | NO
+ rw_view2   | b           | NO
+(4 rows)
+
+CREATE RULE rw_view1_upd_rule AS ON UPDATE TO rw_view1
+  DO INSTEAD UPDATE base_tbl SET b=NEW.b WHERE a=OLD.a RETURNING NEW.*;
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_insertable_into 
+------------+--------------------
+ rw_view1   | YES
+ rw_view2   | YES
+(2 rows)
+
+SELECT table_name, is_updatable, is_insertable_into
+  FROM information_schema.views
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_updatable | is_insertable_into 
+------------+--------------+--------------------
+ rw_view1   | NO           | YES
+ rw_view2   | NO           | YES
+(2 rows)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name, ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ rw_view1   | a           | NO
+ rw_view1   | b           | NO
+ rw_view2   | a           | NO
+ rw_view2   | b           | NO
+(4 rows)
+
+CREATE RULE rw_view1_del_rule AS ON DELETE TO rw_view1
+  DO INSTEAD DELETE FROM base_tbl WHERE a=OLD.a RETURNING OLD.*;
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_insertable_into 
+------------+--------------------
+ rw_view1   | YES
+ rw_view2   | YES
+(2 rows)
+
+SELECT table_name, is_updatable, is_insertable_into
+  FROM information_schema.views
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_updatable | is_insertable_into 
+------------+--------------+--------------------
+ rw_view1   | YES          | YES
+ rw_view2   | YES          | YES
+(2 rows)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name, ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ rw_view1   | a           | YES
+ rw_view1   | b           | YES
+ rw_view2   | a           | YES
+ rw_view2   | b           | YES
+(4 rows)
+
+INSERT INTO rw_view2 VALUES (3, 'Row 3') RETURNING *;
+ a |   b   
+---+-------
+ 3 | Row 3
+(1 row)
+
+UPDATE rw_view2 SET b='Row three' WHERE a=3 RETURNING *;
+ a |     b     
+---+-----------
+ 3 | Row three
+(1 row)
+
+SELECT * FROM rw_view2;
+ a |     b     
+---+-----------
+ 1 | Row 1
+ 2 | Row 2
+ 3 | Row three
+(3 rows)
+
+DELETE FROM rw_view2 WHERE a=3 RETURNING *;
+ a |     b     
+---+-----------
+ 3 | Row three
+(1 row)
+
+SELECT * FROM rw_view2;
+ a |   b   
+---+-------
+ 1 | Row 1
+ 2 | Row 2
+(2 rows)
+
+EXPLAIN (costs off) UPDATE rw_view2 SET a=3 WHERE a=2;
+                           QUERY PLAN                           
+----------------------------------------------------------------
+ Update on base_tbl
+   ->  Nested Loop
+         ->  Index Scan using base_tbl_pkey on base_tbl
+               Index Cond: (a = 2)
+         ->  Subquery Scan on rw_view1
+               Filter: ((rw_view1.a < 10) AND (rw_view1.a = 2))
+               ->  Bitmap Heap Scan on base_tbl base_tbl_1
+                     Recheck Cond: (a > 0)
+                     ->  Bitmap Index Scan on base_tbl_pkey
+                           Index Cond: (a > 0)
+(10 rows)
+
+EXPLAIN (costs off) DELETE FROM rw_view2 WHERE a=2;
+                           QUERY PLAN                           
+----------------------------------------------------------------
+ Delete on base_tbl
+   ->  Nested Loop
+         ->  Index Scan using base_tbl_pkey on base_tbl
+               Index Cond: (a = 2)
+         ->  Subquery Scan on rw_view1
+               Filter: ((rw_view1.a < 10) AND (rw_view1.a = 2))
+               ->  Bitmap Heap Scan on base_tbl base_tbl_1
+                     Recheck Cond: (a > 0)
+                     ->  Bitmap Index Scan on base_tbl_pkey
+                           Index Cond: (a > 0)
+(10 rows)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to view rw_view1
+drop cascades to view rw_view2
+-- view on top of view with triggers
+CREATE TABLE base_tbl (a int PRIMARY KEY, b text DEFAULT 'Unspecified');
+INSERT INTO base_tbl SELECT i, 'Row ' || i FROM generate_series(-2, 2) g(i);
+CREATE VIEW rw_view1 AS SELECT * FROM base_tbl WHERE a>0 OFFSET 0; -- not updatable without rules/triggers
+CREATE VIEW rw_view2 AS SELECT * FROM rw_view1 WHERE a<10;
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_insertable_into 
+------------+--------------------
+ rw_view1   | NO
+ rw_view2   | NO
+(2 rows)
+
+SELECT table_name, is_updatable, is_insertable_into,
+       is_trigger_updatable, is_trigger_deletable,
+       is_trigger_insertable_into
+  FROM information_schema.views
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_updatable | is_insertable_into | is_trigger_updatable | is_trigger_deletable | is_trigger_insertable_into 
+------------+--------------+--------------------+----------------------+----------------------+----------------------------
+ rw_view1   | NO           | NO                 | NO                   | NO                   | NO
+ rw_view2   | NO           | NO                 | NO                   | NO                   | NO
+(2 rows)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name, ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ rw_view1   | a           | NO
+ rw_view1   | b           | NO
+ rw_view2   | a           | NO
+ rw_view2   | b           | NO
+(4 rows)
+
+CREATE FUNCTION rw_view1_trig_fn()
+RETURNS trigger AS
+$$
+BEGIN
+  IF TG_OP = 'INSERT' THEN
+    INSERT INTO base_tbl VALUES (NEW.a, NEW.b);
+    RETURN NEW;
+  ELSIF TG_OP = 'UPDATE' THEN
+    UPDATE base_tbl SET b=NEW.b WHERE a=OLD.a;
+    RETURN NEW;
+  ELSIF TG_OP = 'DELETE' THEN
+    DELETE FROM base_tbl WHERE a=OLD.a;
+    RETURN OLD;
+  END IF;
+END;
+$$
+LANGUAGE plpgsql;
+CREATE TRIGGER rw_view1_ins_trig INSTEAD OF INSERT ON rw_view1
+  FOR EACH ROW EXECUTE PROCEDURE rw_view1_trig_fn();
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_insertable_into 
+------------+--------------------
+ rw_view1   | NO
+ rw_view2   | NO
+(2 rows)
+
+SELECT table_name, is_updatable, is_insertable_into,
+       is_trigger_updatable, is_trigger_deletable,
+       is_trigger_insertable_into
+  FROM information_schema.views
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_updatable | is_insertable_into | is_trigger_updatable | is_trigger_deletable | is_trigger_insertable_into 
+------------+--------------+--------------------+----------------------+----------------------+----------------------------
+ rw_view1   | NO           | NO                 | NO                   | NO                   | YES
+ rw_view2   | NO           | NO                 | NO                   | NO                   | NO
+(2 rows)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name, ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ rw_view1   | a           | NO
+ rw_view1   | b           | NO
+ rw_view2   | a           | NO
+ rw_view2   | b           | NO
+(4 rows)
+
+CREATE TRIGGER rw_view1_upd_trig INSTEAD OF UPDATE ON rw_view1
+  FOR EACH ROW EXECUTE PROCEDURE rw_view1_trig_fn();
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_insertable_into 
+------------+--------------------
+ rw_view1   | NO
+ rw_view2   | NO
+(2 rows)
+
+SELECT table_name, is_updatable, is_insertable_into,
+       is_trigger_updatable, is_trigger_deletable,
+       is_trigger_insertable_into
+  FROM information_schema.views
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_updatable | is_insertable_into | is_trigger_updatable | is_trigger_deletable | is_trigger_insertable_into 
+------------+--------------+--------------------+----------------------+----------------------+----------------------------
+ rw_view1   | NO           | NO                 | YES                  | NO                   | YES
+ rw_view2   | NO           | NO                 | NO                   | NO                   | NO
+(2 rows)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name, ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ rw_view1   | a           | NO
+ rw_view1   | b           | NO
+ rw_view2   | a           | NO
+ rw_view2   | b           | NO
+(4 rows)
+
+CREATE TRIGGER rw_view1_del_trig INSTEAD OF DELETE ON rw_view1
+  FOR EACH ROW EXECUTE PROCEDURE rw_view1_trig_fn();
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_insertable_into 
+------------+--------------------
+ rw_view1   | NO
+ rw_view2   | NO
+(2 rows)
+
+SELECT table_name, is_updatable, is_insertable_into,
+       is_trigger_updatable, is_trigger_deletable,
+       is_trigger_insertable_into
+  FROM information_schema.views
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name;
+ table_name | is_updatable | is_insertable_into | is_trigger_updatable | is_trigger_deletable | is_trigger_insertable_into 
+------------+--------------+--------------------+----------------------+----------------------+----------------------------
+ rw_view1   | NO           | NO                 | YES                  | YES                  | YES
+ rw_view2   | NO           | NO                 | NO                   | NO                   | NO
+(2 rows)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name LIKE 'rw_view%'
+ ORDER BY table_name, ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ rw_view1   | a           | NO
+ rw_view1   | b           | NO
+ rw_view2   | a           | NO
+ rw_view2   | b           | NO
+(4 rows)
+
+INSERT INTO rw_view2 VALUES (3, 'Row 3') RETURNING *;
+ a |   b   
+---+-------
+ 3 | Row 3
+(1 row)
+
+UPDATE rw_view2 SET b='Row three' WHERE a=3 RETURNING *;
+ a |     b     
+---+-----------
+ 3 | Row three
+(1 row)
+
+SELECT * FROM rw_view2;
+ a |     b     
+---+-----------
+ 1 | Row 1
+ 2 | Row 2
+ 3 | Row three
+(3 rows)
+
+DELETE FROM rw_view2 WHERE a=3 RETURNING *;
+ a |     b     
+---+-----------
+ 3 | Row three
+(1 row)
+
+SELECT * FROM rw_view2;
+ a |   b   
+---+-------
+ 1 | Row 1
+ 2 | Row 2
+(2 rows)
+
+EXPLAIN (costs off) UPDATE rw_view2 SET a=3 WHERE a=2;
+                        QUERY PLAN                        
+----------------------------------------------------------
+ Update on rw_view1 rw_view1_1
+   ->  Subquery Scan on rw_view1
+         Filter: ((rw_view1.a < 10) AND (rw_view1.a = 2))
+         ->  Bitmap Heap Scan on base_tbl
+               Recheck Cond: (a > 0)
+               ->  Bitmap Index Scan on base_tbl_pkey
+                     Index Cond: (a > 0)
+(7 rows)
+
+EXPLAIN (costs off) DELETE FROM rw_view2 WHERE a=2;
+                        QUERY PLAN                        
+----------------------------------------------------------
+ Delete on rw_view1 rw_view1_1
+   ->  Subquery Scan on rw_view1
+         Filter: ((rw_view1.a < 10) AND (rw_view1.a = 2))
+         ->  Bitmap Heap Scan on base_tbl
+               Recheck Cond: (a > 0)
+               ->  Bitmap Index Scan on base_tbl_pkey
+                     Index Cond: (a > 0)
+(7 rows)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to view rw_view1
+drop cascades to view rw_view2
+DROP FUNCTION rw_view1_trig_fn();
+-- update using whole row from view
+CREATE TABLE base_tbl (a int PRIMARY KEY, b text DEFAULT 'Unspecified');
+INSERT INTO base_tbl SELECT i, 'Row ' || i FROM generate_series(-2, 2) g(i);
+CREATE VIEW rw_view1 AS SELECT b AS bb, a AS aa FROM base_tbl;
+CREATE FUNCTION rw_view1_aa(x rw_view1)
+  RETURNS int AS $$ SELECT x.aa $$ LANGUAGE sql;
+UPDATE rw_view1 v SET bb='Updated row 2' WHERE rw_view1_aa(v)=2
+  RETURNING rw_view1_aa(v), v.bb;
+ rw_view1_aa |      bb       
+-------------+---------------
+           2 | Updated row 2
+(1 row)
+
+SELECT * FROM base_tbl;
+ a  |       b       
+----+---------------
+ -2 | Row -2
+ -1 | Row -1
+  0 | Row 0
+  1 | Row 1
+  2 | Updated row 2
+(5 rows)
+
+EXPLAIN (costs off)
+UPDATE rw_view1 v SET bb='Updated row 2' WHERE rw_view1_aa(v)=2
+  RETURNING rw_view1_aa(v), v.bb;
+                    QUERY PLAN                    
+--------------------------------------------------
+ Update on base_tbl
+   ->  Index Scan using base_tbl_pkey on base_tbl
+         Index Cond: (a = 2)
+(3 rows)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to view rw_view1
+drop cascades to function rw_view1_aa(rw_view1)
+-- permissions checks
+CREATE USER regress_view_user1;
+CREATE USER regress_view_user2;
+SET SESSION AUTHORIZATION regress_view_user1;
+CREATE TABLE base_tbl(a int, b text, c float);
+INSERT INTO base_tbl VALUES (1, 'Row 1', 1.0);
+CREATE VIEW rw_view1 AS SELECT b AS bb, c AS cc, a AS aa FROM base_tbl;
+INSERT INTO rw_view1 VALUES ('Row 2', 2.0, 2);
+GRANT SELECT ON base_tbl TO regress_view_user2;
+GRANT SELECT ON rw_view1 TO regress_view_user2;
+GRANT UPDATE (a,c) ON base_tbl TO regress_view_user2;
+GRANT UPDATE (bb,cc) ON rw_view1 TO regress_view_user2;
+RESET SESSION AUTHORIZATION;
+SET SESSION AUTHORIZATION regress_view_user2;
+CREATE VIEW rw_view2 AS SELECT b AS bb, c AS cc, a AS aa FROM base_tbl;
+SELECT * FROM base_tbl; -- ok
+ a |   b   | c 
+---+-------+---
+ 1 | Row 1 | 1
+ 2 | Row 2 | 2
+(2 rows)
+
+SELECT * FROM rw_view1; -- ok
+  bb   | cc | aa 
+-------+----+----
+ Row 1 |  1 |  1
+ Row 2 |  2 |  2
+(2 rows)
+
+SELECT * FROM rw_view2; -- ok
+  bb   | cc | aa 
+-------+----+----
+ Row 1 |  1 |  1
+ Row 2 |  2 |  2
+(2 rows)
+
+INSERT INTO base_tbl VALUES (3, 'Row 3', 3.0); -- not allowed
+ERROR:  permission denied for table base_tbl
+INSERT INTO rw_view1 VALUES ('Row 3', 3.0, 3); -- not allowed
+ERROR:  permission denied for view rw_view1
+INSERT INTO rw_view2 VALUES ('Row 3', 3.0, 3); -- not allowed
+ERROR:  permission denied for table base_tbl
+UPDATE base_tbl SET a=a, c=c; -- ok
+UPDATE base_tbl SET b=b; -- not allowed
+ERROR:  permission denied for table base_tbl
+UPDATE rw_view1 SET bb=bb, cc=cc; -- ok
+UPDATE rw_view1 SET aa=aa; -- not allowed
+ERROR:  permission denied for view rw_view1
+UPDATE rw_view2 SET aa=aa, cc=cc; -- ok
+UPDATE rw_view2 SET bb=bb; -- not allowed
+ERROR:  permission denied for table base_tbl
+DELETE FROM base_tbl; -- not allowed
+ERROR:  permission denied for table base_tbl
+DELETE FROM rw_view1; -- not allowed
+ERROR:  permission denied for view rw_view1
+DELETE FROM rw_view2; -- not allowed
+ERROR:  permission denied for table base_tbl
+RESET SESSION AUTHORIZATION;
+SET SESSION AUTHORIZATION regress_view_user1;
+GRANT INSERT, DELETE ON base_tbl TO regress_view_user2;
+RESET SESSION AUTHORIZATION;
+SET SESSION AUTHORIZATION regress_view_user2;
+INSERT INTO base_tbl VALUES (3, 'Row 3', 3.0); -- ok
+INSERT INTO rw_view1 VALUES ('Row 4', 4.0, 4); -- not allowed
+ERROR:  permission denied for view rw_view1
+INSERT INTO rw_view2 VALUES ('Row 4', 4.0, 4); -- ok
+DELETE FROM base_tbl WHERE a=1; -- ok
+DELETE FROM rw_view1 WHERE aa=2; -- not allowed
+ERROR:  permission denied for view rw_view1
+DELETE FROM rw_view2 WHERE aa=2; -- ok
+SELECT * FROM base_tbl;
+ a |   b   | c 
+---+-------+---
+ 3 | Row 3 | 3
+ 4 | Row 4 | 4
+(2 rows)
+
+RESET SESSION AUTHORIZATION;
+SET SESSION AUTHORIZATION regress_view_user1;
+REVOKE INSERT, DELETE ON base_tbl FROM regress_view_user2;
+GRANT INSERT, DELETE ON rw_view1 TO regress_view_user2;
+RESET SESSION AUTHORIZATION;
+SET SESSION AUTHORIZATION regress_view_user2;
+INSERT INTO base_tbl VALUES (5, 'Row 5', 5.0); -- not allowed
+ERROR:  permission denied for table base_tbl
+INSERT INTO rw_view1 VALUES ('Row 5', 5.0, 5); -- ok
+INSERT INTO rw_view2 VALUES ('Row 6', 6.0, 6); -- not allowed
+ERROR:  permission denied for table base_tbl
+DELETE FROM base_tbl WHERE a=3; -- not allowed
+ERROR:  permission denied for table base_tbl
+DELETE FROM rw_view1 WHERE aa=3; -- ok
+DELETE FROM rw_view2 WHERE aa=4; -- not allowed
+ERROR:  permission denied for table base_tbl
+SELECT * FROM base_tbl;
+ a |   b   | c 
+---+-------+---
+ 4 | Row 4 | 4
+ 5 | Row 5 | 5
+(2 rows)
+
+RESET SESSION AUTHORIZATION;
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to view rw_view1
+drop cascades to view rw_view2
+-- nested-view permissions
+CREATE TABLE base_tbl(a int, b text, c float);
+INSERT INTO base_tbl VALUES (1, 'Row 1', 1.0);
+SET SESSION AUTHORIZATION regress_view_user1;
+CREATE VIEW rw_view1 AS SELECT * FROM base_tbl;
+SELECT * FROM rw_view1;  -- not allowed
+ERROR:  permission denied for table base_tbl
+SELECT * FROM rw_view1 FOR UPDATE;  -- not allowed
+ERROR:  permission denied for table base_tbl
+UPDATE rw_view1 SET b = 'foo' WHERE a = 1;  -- not allowed
+ERROR:  permission denied for table base_tbl
+SET SESSION AUTHORIZATION regress_view_user2;
+CREATE VIEW rw_view2 AS SELECT * FROM rw_view1;
+SELECT * FROM rw_view2;  -- not allowed
+ERROR:  permission denied for view rw_view1
+SELECT * FROM rw_view2 FOR UPDATE;  -- not allowed
+ERROR:  permission denied for view rw_view1
+UPDATE rw_view2 SET b = 'bar' WHERE a = 1;  -- not allowed
+ERROR:  permission denied for view rw_view1
+RESET SESSION AUTHORIZATION;
+GRANT SELECT ON base_tbl TO regress_view_user1;
+SET SESSION AUTHORIZATION regress_view_user1;
+SELECT * FROM rw_view1;
+ a |   b   | c 
+---+-------+---
+ 1 | Row 1 | 1
+(1 row)
+
+SELECT * FROM rw_view1 FOR UPDATE;  -- not allowed
+ERROR:  permission denied for table base_tbl
+UPDATE rw_view1 SET b = 'foo' WHERE a = 1;  -- not allowed
+ERROR:  permission denied for table base_tbl
+SET SESSION AUTHORIZATION regress_view_user2;
+SELECT * FROM rw_view2;  -- not allowed
+ERROR:  permission denied for view rw_view1
+SELECT * FROM rw_view2 FOR UPDATE;  -- not allowed
+ERROR:  permission denied for view rw_view1
+UPDATE rw_view2 SET b = 'bar' WHERE a = 1;  -- not allowed
+ERROR:  permission denied for view rw_view1
+SET SESSION AUTHORIZATION regress_view_user1;
+GRANT SELECT ON rw_view1 TO regress_view_user2;
+SET SESSION AUTHORIZATION regress_view_user2;
+SELECT * FROM rw_view2;
+ a |   b   | c 
+---+-------+---
+ 1 | Row 1 | 1
+(1 row)
+
+SELECT * FROM rw_view2 FOR UPDATE;  -- not allowed
+ERROR:  permission denied for view rw_view1
+UPDATE rw_view2 SET b = 'bar' WHERE a = 1;  -- not allowed
+ERROR:  permission denied for view rw_view1
+RESET SESSION AUTHORIZATION;
+GRANT UPDATE ON base_tbl TO regress_view_user1;
+SET SESSION AUTHORIZATION regress_view_user1;
+SELECT * FROM rw_view1;
+ a |   b   | c 
+---+-------+---
+ 1 | Row 1 | 1
+(1 row)
+
+SELECT * FROM rw_view1 FOR UPDATE;
+ a |   b   | c 
+---+-------+---
+ 1 | Row 1 | 1
+(1 row)
+
+UPDATE rw_view1 SET b = 'foo' WHERE a = 1;
+SET SESSION AUTHORIZATION regress_view_user2;
+SELECT * FROM rw_view2;
+ a |  b  | c 
+---+-----+---
+ 1 | foo | 1
+(1 row)
+
+SELECT * FROM rw_view2 FOR UPDATE;  -- not allowed
+ERROR:  permission denied for view rw_view1
+UPDATE rw_view2 SET b = 'bar' WHERE a = 1;  -- not allowed
+ERROR:  permission denied for view rw_view1
+SET SESSION AUTHORIZATION regress_view_user1;
+GRANT UPDATE ON rw_view1 TO regress_view_user2;
+SET SESSION AUTHORIZATION regress_view_user2;
+SELECT * FROM rw_view2;
+ a |  b  | c 
+---+-----+---
+ 1 | foo | 1
+(1 row)
+
+SELECT * FROM rw_view2 FOR UPDATE;
+ a |  b  | c 
+---+-----+---
+ 1 | foo | 1
+(1 row)
+
+UPDATE rw_view2 SET b = 'bar' WHERE a = 1;
+RESET SESSION AUTHORIZATION;
+REVOKE UPDATE ON base_tbl FROM regress_view_user1;
+SET SESSION AUTHORIZATION regress_view_user1;
+SELECT * FROM rw_view1;
+ a |  b  | c 
+---+-----+---
+ 1 | bar | 1
+(1 row)
+
+SELECT * FROM rw_view1 FOR UPDATE;  -- not allowed
+ERROR:  permission denied for table base_tbl
+UPDATE rw_view1 SET b = 'foo' WHERE a = 1;  -- not allowed
+ERROR:  permission denied for table base_tbl
+SET SESSION AUTHORIZATION regress_view_user2;
+SELECT * FROM rw_view2;
+ a |  b  | c 
+---+-----+---
+ 1 | bar | 1
+(1 row)
+
+SELECT * FROM rw_view2 FOR UPDATE;  -- not allowed
+ERROR:  permission denied for table base_tbl
+UPDATE rw_view2 SET b = 'bar' WHERE a = 1;  -- not allowed
+ERROR:  permission denied for table base_tbl
+RESET SESSION AUTHORIZATION;
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to view rw_view1
+drop cascades to view rw_view2
+DROP USER regress_view_user1;
+DROP USER regress_view_user2;
+-- column defaults
+CREATE TABLE base_tbl (a int PRIMARY KEY, b text DEFAULT 'Unspecified', c serial);
+INSERT INTO base_tbl VALUES (1, 'Row 1');
+INSERT INTO base_tbl VALUES (2, 'Row 2');
+INSERT INTO base_tbl VALUES (3);
+CREATE VIEW rw_view1 AS SELECT a AS aa, b AS bb FROM base_tbl;
+ALTER VIEW rw_view1 ALTER COLUMN bb SET DEFAULT 'View default';
+INSERT INTO rw_view1 VALUES (4, 'Row 4');
+INSERT INTO rw_view1 (aa) VALUES (5);
+SELECT * FROM base_tbl;
+ a |      b       | c 
+---+--------------+---
+ 1 | Row 1        | 1
+ 2 | Row 2        | 2
+ 3 | Unspecified  | 3
+ 4 | Row 4        | 4
+ 5 | View default | 5
+(5 rows)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to view rw_view1
+-- Table having triggers
+CREATE TABLE base_tbl (a int PRIMARY KEY, b text DEFAULT 'Unspecified');
+INSERT INTO base_tbl VALUES (1, 'Row 1');
+INSERT INTO base_tbl VALUES (2, 'Row 2');
+CREATE FUNCTION rw_view1_trig_fn()
+RETURNS trigger AS
+$$
+BEGIN
+  IF TG_OP = 'INSERT' THEN
+    UPDATE base_tbl SET b=NEW.b WHERE a=1;
+    RETURN NULL;
+  END IF;
+  RETURN NULL;
+END;
+$$
+LANGUAGE plpgsql;
+CREATE TRIGGER rw_view1_ins_trig AFTER INSERT ON base_tbl
+  FOR EACH ROW EXECUTE PROCEDURE rw_view1_trig_fn();
+CREATE VIEW rw_view1 AS SELECT a AS aa, b AS bb FROM base_tbl;
+INSERT INTO rw_view1 VALUES (3, 'Row 3');
+select * from base_tbl ORDER BY a;
+ a |   b   
+---+-------
+ 1 | Row 3
+ 2 | Row 2
+ 3 | Row 3
+(3 rows)
+
+DROP VIEW rw_view1;
+DROP TRIGGER rw_view1_ins_trig on base_tbl;
+DROP FUNCTION rw_view1_trig_fn();
+DROP TABLE base_tbl;
+-- view with ORDER BY
+CREATE TABLE base_tbl (a int, b int);
+INSERT INTO base_tbl VALUES (1,2), (4,5), (3,-3);
+CREATE VIEW rw_view1 AS SELECT * FROM base_tbl ORDER BY a+b;
+SELECT * FROM rw_view1;
+ a | b  
+---+----
+ 3 | -3
+ 1 |  2
+ 4 |  5
+(3 rows)
+
+INSERT INTO rw_view1 VALUES (7,-8);
+SELECT * FROM rw_view1;
+ a | b  
+---+----
+ 7 | -8
+ 3 | -3
+ 1 |  2
+ 4 |  5
+(4 rows)
+
+EXPLAIN (verbose, costs off) UPDATE rw_view1 SET b = b + 1 RETURNING *;
+                         QUERY PLAN                          
+-------------------------------------------------------------
+ Update on public.base_tbl
+   Output: base_tbl.a, base_tbl.b
+   ->  Seq Scan on public.base_tbl
+         Output: base_tbl.a, (base_tbl.b + 1), base_tbl.ctid
+(4 rows)
+
+UPDATE rw_view1 SET b = b + 1 RETURNING *;
+ a | b  
+---+----
+ 1 |  3
+ 4 |  6
+ 3 | -2
+ 7 | -7
+(4 rows)
+
+SELECT * FROM rw_view1;
+ a | b  
+---+----
+ 7 | -7
+ 3 | -2
+ 1 |  3
+ 4 |  6
+(4 rows)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to view rw_view1
+-- multiple array-column updates
+CREATE TABLE base_tbl (a int, arr int[]);
+INSERT INTO base_tbl VALUES (1,ARRAY[2]), (3,ARRAY[4]);
+CREATE VIEW rw_view1 AS SELECT * FROM base_tbl;
+UPDATE rw_view1 SET arr[1] = 42, arr[2] = 77 WHERE a = 3;
+SELECT * FROM rw_view1;
+ a |   arr   
+---+---------
+ 1 | {2}
+ 3 | {42,77}
+(2 rows)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to view rw_view1
+-- views with updatable and non-updatable columns
+CREATE TABLE base_tbl(a float);
+INSERT INTO base_tbl SELECT i/10.0 FROM generate_series(1,10) g(i);
+CREATE VIEW rw_view1 AS
+  SELECT ctid, sin(a) s, a, cos(a) c
+  FROM base_tbl
+  WHERE a != 0
+  ORDER BY abs(a);
+INSERT INTO rw_view1 VALUES (null, null, 1.1, null); -- should fail
+ERROR:  cannot insert into column "ctid" of view "rw_view1"
+DETAIL:  View columns that refer to system columns are not updatable.
+INSERT INTO rw_view1 (s, c, a) VALUES (null, null, 1.1); -- should fail
+ERROR:  cannot insert into column "s" of view "rw_view1"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+INSERT INTO rw_view1 (a) VALUES (1.1) RETURNING a, s, c; -- OK
+  a  |         s         |         c         
+-----+-------------------+-------------------
+ 1.1 | 0.891207360061435 | 0.453596121425577
+(1 row)
+
+UPDATE rw_view1 SET s = s WHERE a = 1.1; -- should fail
+ERROR:  cannot update column "s" of view "rw_view1"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+UPDATE rw_view1 SET a = 1.05 WHERE a = 1.1 RETURNING s; -- OK
+         s         
+-------------------
+ 0.867423225594017
+(1 row)
+
+DELETE FROM rw_view1 WHERE a = 1.05; -- OK
+CREATE VIEW rw_view2 AS
+  SELECT s, c, s/c t, a base_a, ctid
+  FROM rw_view1;
+INSERT INTO rw_view2 VALUES (null, null, null, 1.1, null); -- should fail
+ERROR:  cannot insert into column "t" of view "rw_view2"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+INSERT INTO rw_view2(s, c, base_a) VALUES (null, null, 1.1); -- should fail
+ERROR:  cannot insert into column "s" of view "rw_view1"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+INSERT INTO rw_view2(base_a) VALUES (1.1) RETURNING t; -- OK
+        t         
+------------------
+ 1.96475965724865
+(1 row)
+
+UPDATE rw_view2 SET s = s WHERE base_a = 1.1; -- should fail
+ERROR:  cannot update column "s" of view "rw_view1"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+UPDATE rw_view2 SET t = t WHERE base_a = 1.1; -- should fail
+ERROR:  cannot update column "t" of view "rw_view2"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+UPDATE rw_view2 SET base_a = 1.05 WHERE base_a = 1.1; -- OK
+DELETE FROM rw_view2 WHERE base_a = 1.05 RETURNING base_a, s, c, t; -- OK
+ base_a |         s         |         c         |        t         
+--------+-------------------+-------------------+------------------
+   1.05 | 0.867423225594017 | 0.497571047891727 | 1.74331530998317
+(1 row)
+
+CREATE VIEW rw_view3 AS
+  SELECT s, c, s/c t, ctid
+  FROM rw_view1;
+INSERT INTO rw_view3 VALUES (null, null, null, null); -- should fail
+ERROR:  cannot insert into column "t" of view "rw_view3"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+INSERT INTO rw_view3(s) VALUES (null); -- should fail
+ERROR:  cannot insert into column "s" of view "rw_view1"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+UPDATE rw_view3 SET s = s; -- should fail
+ERROR:  cannot update column "s" of view "rw_view1"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+DELETE FROM rw_view3 WHERE s = sin(0.1); -- should be OK
+SELECT * FROM base_tbl ORDER BY a;
+  a  
+-----
+ 0.2
+ 0.3
+ 0.4
+ 0.5
+ 0.6
+ 0.7
+ 0.8
+ 0.9
+   1
+(9 rows)
+
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name LIKE E'r_\\_view%'
+ ORDER BY table_name;
+ table_name | is_insertable_into 
+------------+--------------------
+ rw_view1   | YES
+ rw_view2   | YES
+ rw_view3   | NO
+(3 rows)
+
+SELECT table_name, is_updatable, is_insertable_into
+  FROM information_schema.views
+ WHERE table_name LIKE E'r_\\_view%'
+ ORDER BY table_name;
+ table_name | is_updatable | is_insertable_into 
+------------+--------------+--------------------
+ rw_view1   | YES          | YES
+ rw_view2   | YES          | YES
+ rw_view3   | NO           | NO
+(3 rows)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name LIKE E'r_\\_view%'
+ ORDER BY table_name, ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ rw_view1   | ctid        | NO
+ rw_view1   | s           | NO
+ rw_view1   | a           | YES
+ rw_view1   | c           | NO
+ rw_view2   | s           | NO
+ rw_view2   | c           | NO
+ rw_view2   | t           | NO
+ rw_view2   | base_a      | YES
+ rw_view2   | ctid        | NO
+ rw_view3   | s           | NO
+ rw_view3   | c           | NO
+ rw_view3   | t           | NO
+ rw_view3   | ctid        | NO
+(13 rows)
+
+SELECT events & 4 != 0 AS upd,
+       events & 8 != 0 AS ins,
+       events & 16 != 0 AS del
+  FROM pg_catalog.pg_relation_is_updatable('rw_view3'::regclass, false) t(events);
+ upd | ins | del 
+-----+-----+-----
+ f   | f   | t
+(1 row)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to 3 other objects
+DETAIL:  drop cascades to view rw_view1
+drop cascades to view rw_view2
+drop cascades to view rw_view3
+-- inheritance tests
+CREATE TABLE base_tbl_parent (a int);
+CREATE TABLE base_tbl_child (CHECK (a > 0)) INHERITS (base_tbl_parent);
+INSERT INTO base_tbl_parent SELECT * FROM generate_series(-8, -1);
+INSERT INTO base_tbl_child SELECT * FROM generate_series(1, 8);
+CREATE VIEW rw_view1 AS SELECT * FROM base_tbl_parent;
+CREATE VIEW rw_view2 AS SELECT * FROM ONLY base_tbl_parent;
+SELECT * FROM rw_view1 ORDER BY a;
+ a  
+----
+ -8
+ -7
+ -6
+ -5
+ -4
+ -3
+ -2
+ -1
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+(16 rows)
+
+SELECT * FROM ONLY rw_view1 ORDER BY a;
+ a  
+----
+ -8
+ -7
+ -6
+ -5
+ -4
+ -3
+ -2
+ -1
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+(16 rows)
+
+SELECT * FROM rw_view2 ORDER BY a;
+ a  
+----
+ -8
+ -7
+ -6
+ -5
+ -4
+ -3
+ -2
+ -1
+(8 rows)
+
+INSERT INTO rw_view1 VALUES (-100), (100);
+INSERT INTO rw_view2 VALUES (-200), (200);
+UPDATE rw_view1 SET a = a*10 WHERE a IN (-1, 1); -- Should produce -10 and 10
+UPDATE ONLY rw_view1 SET a = a*10 WHERE a IN (-2, 2); -- Should produce -20 and 20
+UPDATE rw_view2 SET a = a*10 WHERE a IN (-3, 3); -- Should produce -30 only
+UPDATE ONLY rw_view2 SET a = a*10 WHERE a IN (-4, 4); -- Should produce -40 only
+DELETE FROM rw_view1 WHERE a IN (-5, 5); -- Should delete -5 and 5
+DELETE FROM ONLY rw_view1 WHERE a IN (-6, 6); -- Should delete -6 and 6
+DELETE FROM rw_view2 WHERE a IN (-7, 7); -- Should delete -7 only
+DELETE FROM ONLY rw_view2 WHERE a IN (-8, 8); -- Should delete -8 only
+SELECT * FROM ONLY base_tbl_parent ORDER BY a;
+  a   
+------
+ -200
+ -100
+  -40
+  -30
+  -20
+  -10
+  100
+  200
+(8 rows)
+
+SELECT * FROM base_tbl_child ORDER BY a;
+ a  
+----
+  3
+  4
+  7
+  8
+ 10
+ 20
+(6 rows)
+
+CREATE TABLE other_tbl_parent (id int);
+CREATE TABLE other_tbl_child () INHERITS (other_tbl_parent);
+INSERT INTO other_tbl_parent VALUES (7),(200);
+INSERT INTO other_tbl_child VALUES (8),(100);
+EXPLAIN (costs off)
+UPDATE rw_view1 SET a = a + 1000 FROM other_tbl_parent WHERE a = id;
+                          QUERY PLAN                          
+--------------------------------------------------------------
+ Update on base_tbl_parent
+   Update on base_tbl_parent
+   Update on base_tbl_child
+   ->  Hash Join
+         Hash Cond: (other_tbl_parent.id = base_tbl_parent.a)
+         ->  Append
+               ->  Seq Scan on other_tbl_parent
+               ->  Seq Scan on other_tbl_child
+         ->  Hash
+               ->  Seq Scan on base_tbl_parent
+   ->  Merge Join
+         Merge Cond: (base_tbl_child.a = other_tbl_parent.id)
+         ->  Sort
+               Sort Key: base_tbl_child.a
+               ->  Seq Scan on base_tbl_child
+         ->  Sort
+               Sort Key: other_tbl_parent.id
+               ->  Append
+                     ->  Seq Scan on other_tbl_parent
+                     ->  Seq Scan on other_tbl_child
+(20 rows)
+
+UPDATE rw_view1 SET a = a + 1000 FROM other_tbl_parent WHERE a = id;
+SELECT * FROM ONLY base_tbl_parent ORDER BY a;
+  a   
+------
+ -200
+ -100
+  -40
+  -30
+  -20
+  -10
+ 1100
+ 1200
+(8 rows)
+
+SELECT * FROM base_tbl_child ORDER BY a;
+  a   
+------
+    3
+    4
+   10
+   20
+ 1007
+ 1008
+(6 rows)
+
+DROP TABLE base_tbl_parent, base_tbl_child CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to view rw_view1
+drop cascades to view rw_view2
+DROP TABLE other_tbl_parent CASCADE;
+NOTICE:  drop cascades to table other_tbl_child
+-- simple WITH CHECK OPTION
+CREATE TABLE base_tbl (a int, b int DEFAULT 10);
+INSERT INTO base_tbl VALUES (1,2), (2,3), (1,-1);
+CREATE VIEW rw_view1 AS SELECT * FROM base_tbl WHERE a < b
+  WITH LOCAL CHECK OPTION;
+\d+ rw_view1
+                          View "public.rw_view1"
+ Column |  Type   | Collation | Nullable | Default | Storage | Description 
+--------+---------+-----------+----------+---------+---------+-------------
+ a      | integer |           |          |         | plain   | 
+ b      | integer |           |          |         | plain   | 
+View definition:
+ SELECT base_tbl.a,
+    base_tbl.b
+   FROM base_tbl
+  WHERE base_tbl.a < base_tbl.b;
+Options: check_option=local
+
+SELECT * FROM information_schema.views WHERE table_name = 'rw_view1';
+ table_catalog | table_schema | table_name |          view_definition           | check_option | is_updatable | is_insertable_into | is_trigger_updatable | is_trigger_deletable | is_trigger_insertable_into 
+---------------+--------------+------------+------------------------------------+--------------+--------------+--------------------+----------------------+----------------------+----------------------------
+ regression    | public       | rw_view1   |  SELECT base_tbl.a,               +| LOCAL        | YES          | YES                | NO                   | NO                   | NO
+               |              |            |     base_tbl.b                    +|              |              |                    |                      |                      | 
+               |              |            |    FROM base_tbl                  +|              |              |                    |                      |                      | 
+               |              |            |   WHERE (base_tbl.a < base_tbl.b); |              |              |                    |                      |                      | 
+(1 row)
+
+INSERT INTO rw_view1 VALUES(3,4); -- ok
+INSERT INTO rw_view1 VALUES(4,3); -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (4, 3).
+INSERT INTO rw_view1 VALUES(5,null); -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (5, null).
+UPDATE rw_view1 SET b = 5 WHERE a = 3; -- ok
+UPDATE rw_view1 SET b = -5 WHERE a = 3; -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (3, -5).
+INSERT INTO rw_view1(a) VALUES (9); -- ok
+INSERT INTO rw_view1(a) VALUES (10); -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (10, 10).
+SELECT * FROM base_tbl order by a, b;
+ a | b  
+---+----
+ 1 | -1
+ 1 |  2
+ 2 |  3
+ 3 |  5
+ 9 | 10
+(5 rows)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to view rw_view1
+-- WITH LOCAL/CASCADED CHECK OPTION
+CREATE TABLE base_tbl (a int);
+CREATE VIEW rw_view1 AS SELECT * FROM base_tbl WHERE a > 0;
+CREATE VIEW rw_view2 AS SELECT * FROM rw_view1 WHERE a < 10
+  WITH CHECK OPTION; -- implicitly cascaded
+\d+ rw_view2
+                          View "public.rw_view2"
+ Column |  Type   | Collation | Nullable | Default | Storage | Description 
+--------+---------+-----------+----------+---------+---------+-------------
+ a      | integer |           |          |         | plain   | 
+View definition:
+ SELECT rw_view1.a
+   FROM rw_view1
+  WHERE rw_view1.a < 10;
+Options: check_option=cascaded
+
+SELECT * FROM information_schema.views WHERE table_name = 'rw_view2';
+ table_catalog | table_schema | table_name |      view_definition       | check_option | is_updatable | is_insertable_into | is_trigger_updatable | is_trigger_deletable | is_trigger_insertable_into 
+---------------+--------------+------------+----------------------------+--------------+--------------+--------------------+----------------------+----------------------+----------------------------
+ regression    | public       | rw_view2   |  SELECT rw_view1.a        +| CASCADED     | YES          | YES                | NO                   | NO                   | NO
+               |              |            |    FROM rw_view1          +|              |              |                    |                      |                      | 
+               |              |            |   WHERE (rw_view1.a < 10); |              |              |                    |                      |                      | 
+(1 row)
+
+INSERT INTO rw_view2 VALUES (-5); -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (-5).
+INSERT INTO rw_view2 VALUES (5); -- ok
+INSERT INTO rw_view2 VALUES (15); -- should fail
+ERROR:  new row violates check option for view "rw_view2"
+DETAIL:  Failing row contains (15).
+SELECT * FROM base_tbl;
+ a 
+---
+ 5
+(1 row)
+
+UPDATE rw_view2 SET a = a - 10; -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (-5).
+UPDATE rw_view2 SET a = a + 10; -- should fail
+ERROR:  new row violates check option for view "rw_view2"
+DETAIL:  Failing row contains (15).
+CREATE OR REPLACE VIEW rw_view2 AS SELECT * FROM rw_view1 WHERE a < 10
+  WITH LOCAL CHECK OPTION;
+\d+ rw_view2
+                          View "public.rw_view2"
+ Column |  Type   | Collation | Nullable | Default | Storage | Description 
+--------+---------+-----------+----------+---------+---------+-------------
+ a      | integer |           |          |         | plain   | 
+View definition:
+ SELECT rw_view1.a
+   FROM rw_view1
+  WHERE rw_view1.a < 10;
+Options: check_option=local
+
+SELECT * FROM information_schema.views WHERE table_name = 'rw_view2';
+ table_catalog | table_schema | table_name |      view_definition       | check_option | is_updatable | is_insertable_into | is_trigger_updatable | is_trigger_deletable | is_trigger_insertable_into 
+---------------+--------------+------------+----------------------------+--------------+--------------+--------------------+----------------------+----------------------+----------------------------
+ regression    | public       | rw_view2   |  SELECT rw_view1.a        +| LOCAL        | YES          | YES                | NO                   | NO                   | NO
+               |              |            |    FROM rw_view1          +|              |              |                    |                      |                      | 
+               |              |            |   WHERE (rw_view1.a < 10); |              |              |                    |                      |                      | 
+(1 row)
+
+INSERT INTO rw_view2 VALUES (-10); -- ok, but not in view
+INSERT INTO rw_view2 VALUES (20); -- should fail
+ERROR:  new row violates check option for view "rw_view2"
+DETAIL:  Failing row contains (20).
+SELECT * FROM base_tbl order by a;
+  a  
+-----
+ -10
+   5
+(2 rows)
+
+ALTER VIEW rw_view1 SET (check_option=here); -- invalid
+ERROR:  invalid value for "check_option" option
+DETAIL:  Valid values are "local" and "cascaded".
+ALTER VIEW rw_view1 SET (check_option=local);
+INSERT INTO rw_view2 VALUES (-20); -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (-20).
+INSERT INTO rw_view2 VALUES (30); -- should fail
+ERROR:  new row violates check option for view "rw_view2"
+DETAIL:  Failing row contains (30).
+ALTER VIEW rw_view2 RESET (check_option);
+\d+ rw_view2
+                          View "public.rw_view2"
+ Column |  Type   | Collation | Nullable | Default | Storage | Description 
+--------+---------+-----------+----------+---------+---------+-------------
+ a      | integer |           |          |         | plain   | 
+View definition:
+ SELECT rw_view1.a
+   FROM rw_view1
+  WHERE rw_view1.a < 10;
+
+SELECT * FROM information_schema.views WHERE table_name = 'rw_view2';
+ table_catalog | table_schema | table_name |      view_definition       | check_option | is_updatable | is_insertable_into | is_trigger_updatable | is_trigger_deletable | is_trigger_insertable_into 
+---------------+--------------+------------+----------------------------+--------------+--------------+--------------------+----------------------+----------------------+----------------------------
+ regression    | public       | rw_view2   |  SELECT rw_view1.a        +| NONE         | YES          | YES                | NO                   | NO                   | NO
+               |              |            |    FROM rw_view1          +|              |              |                    |                      |                      | 
+               |              |            |   WHERE (rw_view1.a < 10); |              |              |                    |                      |                      | 
+(1 row)
+
+INSERT INTO rw_view2 VALUES (30); -- ok, but not in view
+SELECT * FROM base_tbl order by a;
+  a  
+-----
+ -10
+   5
+  30
+(3 rows)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to view rw_view1
+drop cascades to view rw_view2
+-- WITH CHECK OPTION with no local view qual
+CREATE TABLE base_tbl (a int);
+CREATE VIEW rw_view1 AS SELECT * FROM base_tbl WITH CHECK OPTION;
+CREATE VIEW rw_view2 AS SELECT * FROM rw_view1 WHERE a > 0;
+CREATE VIEW rw_view3 AS SELECT * FROM rw_view2 WITH CHECK OPTION;
+SELECT * FROM information_schema.views WHERE table_name LIKE E'rw\\_view_' ORDER BY table_name;
+ table_catalog | table_schema | table_name |      view_definition      | check_option | is_updatable | is_insertable_into | is_trigger_updatable | is_trigger_deletable | is_trigger_insertable_into 
+---------------+--------------+------------+---------------------------+--------------+--------------+--------------------+----------------------+----------------------+----------------------------
+ regression    | public       | rw_view1   |  SELECT base_tbl.a       +| CASCADED     | YES          | YES                | NO                   | NO                   | NO
+               |              |            |    FROM base_tbl;         |              |              |                    |                      |                      | 
+ regression    | public       | rw_view2   |  SELECT rw_view1.a       +| NONE         | YES          | YES                | NO                   | NO                   | NO
+               |              |            |    FROM rw_view1         +|              |              |                    |                      |                      | 
+               |              |            |   WHERE (rw_view1.a > 0); |              |              |                    |                      |                      | 
+ regression    | public       | rw_view3   |  SELECT rw_view2.a       +| CASCADED     | YES          | YES                | NO                   | NO                   | NO
+               |              |            |    FROM rw_view2;         |              |              |                    |                      |                      | 
+(3 rows)
+
+INSERT INTO rw_view1 VALUES (-1); -- ok
+INSERT INTO rw_view1 VALUES (1); -- ok
+INSERT INTO rw_view2 VALUES (-2); -- ok, but not in view
+INSERT INTO rw_view2 VALUES (2); -- ok
+INSERT INTO rw_view3 VALUES (-3); -- should fail
+ERROR:  new row violates check option for view "rw_view2"
+DETAIL:  Failing row contains (-3).
+INSERT INTO rw_view3 VALUES (3); -- ok
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to 3 other objects
+DETAIL:  drop cascades to view rw_view1
+drop cascades to view rw_view2
+drop cascades to view rw_view3
+-- WITH CHECK OPTION with scalar array ops
+CREATE TABLE base_tbl (a int, b int[]);
+CREATE VIEW rw_view1 AS SELECT * FROM base_tbl WHERE a = ANY (b)
+  WITH CHECK OPTION;
+INSERT INTO rw_view1 VALUES (1, ARRAY[1,2,3]); -- ok
+INSERT INTO rw_view1 VALUES (10, ARRAY[4,5]); -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (10, {4,5}).
+UPDATE rw_view1 SET b[2] = -b[2] WHERE a = 1; -- ok
+UPDATE rw_view1 SET b[1] = -b[1] WHERE a = 1; -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (1, {-1,-2,3}).
+PREPARE ins(int, int[]) AS INSERT INTO rw_view1 VALUES($1, $2);
+EXECUTE ins(2, ARRAY[1,2,3]); -- ok
+EXECUTE ins(10, ARRAY[4,5]); -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (10, {4,5}).
+DEALLOCATE PREPARE ins;
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to view rw_view1
+-- WITH CHECK OPTION with subquery
+CREATE TABLE base_tbl (a int);
+CREATE TABLE ref_tbl (a int PRIMARY KEY);
+INSERT INTO ref_tbl SELECT * FROM generate_series(1,10);
+CREATE VIEW rw_view1 AS
+  SELECT * FROM base_tbl b
+  WHERE EXISTS(SELECT 1 FROM ref_tbl r WHERE r.a = b.a)
+  WITH CHECK OPTION;
+INSERT INTO rw_view1 VALUES (5); -- ok
+INSERT INTO rw_view1 VALUES (15); -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (15).
+UPDATE rw_view1 SET a = a + 5; -- ok
+UPDATE rw_view1 SET a = a + 5; -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (15).
+EXPLAIN (costs off) INSERT INTO rw_view1 VALUES (5);
+                       QUERY PLAN                        
+---------------------------------------------------------
+ Insert on base_tbl b
+   ->  Result
+   SubPlan 1
+     ->  Index Only Scan using ref_tbl_pkey on ref_tbl r
+           Index Cond: (a = b.a)
+   SubPlan 2
+     ->  Seq Scan on ref_tbl r_1
+(7 rows)
+
+EXPLAIN (costs off) UPDATE rw_view1 SET a = a + 5;
+                        QUERY PLAN                         
+-----------------------------------------------------------
+ Update on base_tbl b
+   ->  Hash Join
+         Hash Cond: (b.a = r.a)
+         ->  Seq Scan on base_tbl b
+         ->  Hash
+               ->  Seq Scan on ref_tbl r
+   SubPlan 1
+     ->  Index Only Scan using ref_tbl_pkey on ref_tbl r_1
+           Index Cond: (a = b.a)
+   SubPlan 2
+     ->  Seq Scan on ref_tbl r_2
+(11 rows)
+
+DROP TABLE base_tbl, ref_tbl CASCADE;
+NOTICE:  drop cascades to view rw_view1
+-- WITH CHECK OPTION with BEFORE trigger on base table
+CREATE TABLE base_tbl (a int, b int);
+CREATE FUNCTION base_tbl_trig_fn()
+RETURNS trigger AS
+$$
+BEGIN
+  NEW.b := 10;
+  RETURN NEW;
+END;
+$$
+LANGUAGE plpgsql;
+CREATE TRIGGER base_tbl_trig BEFORE INSERT OR UPDATE ON base_tbl
+  FOR EACH ROW EXECUTE PROCEDURE base_tbl_trig_fn();
+CREATE VIEW rw_view1 AS SELECT * FROM base_tbl WHERE a < b WITH CHECK OPTION;
+INSERT INTO rw_view1 VALUES (5,0); -- ok
+INSERT INTO rw_view1 VALUES (15, 20); -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (15, 10).
+UPDATE rw_view1 SET a = 20, b = 30; -- should fail
+ERROR:  new row violates check option for view "rw_view1"
+DETAIL:  Failing row contains (20, 10).
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to view rw_view1
+DROP FUNCTION base_tbl_trig_fn();
+-- WITH LOCAL CHECK OPTION with INSTEAD OF trigger on base view
+CREATE TABLE base_tbl (a int, b int);
+CREATE VIEW rw_view1 AS SELECT a FROM base_tbl WHERE a < b;
+CREATE FUNCTION rw_view1_trig_fn()
+RETURNS trigger AS
+$$
+BEGIN
+  IF TG_OP = 'INSERT' THEN
+    INSERT INTO base_tbl VALUES (NEW.a, 10);
+    RETURN NEW;
+  ELSIF TG_OP = 'UPDATE' THEN
+    UPDATE base_tbl SET a=NEW.a WHERE a=OLD.a;
+    RETURN NEW;
+  ELSIF TG_OP = 'DELETE' THEN
+    DELETE FROM base_tbl WHERE a=OLD.a;
+    RETURN OLD;
+  END IF;
+END;
+$$
+LANGUAGE plpgsql;
+CREATE TRIGGER rw_view1_trig
+  INSTEAD OF INSERT OR UPDATE OR DELETE ON rw_view1
+  FOR EACH ROW EXECUTE PROCEDURE rw_view1_trig_fn();
+CREATE VIEW rw_view2 AS
+  SELECT * FROM rw_view1 WHERE a > 0 WITH LOCAL CHECK OPTION;
+INSERT INTO rw_view2 VALUES (-5); -- should fail
+ERROR:  new row violates check option for view "rw_view2"
+DETAIL:  Failing row contains (-5).
+INSERT INTO rw_view2 VALUES (5); -- ok
+INSERT INTO rw_view2 VALUES (50); -- ok, but not in view
+UPDATE rw_view2 SET a = a - 10; -- should fail
+ERROR:  new row violates check option for view "rw_view2"
+DETAIL:  Failing row contains (-5).
+SELECT * FROM base_tbl order by a, b;
+ a  | b  
+----+----
+  5 | 10
+ 50 | 10
+(2 rows)
+
+-- Check option won't cascade down to base view with INSTEAD OF triggers
+ALTER VIEW rw_view2 SET (check_option=cascaded);
+INSERT INTO rw_view2 VALUES (100); -- ok, but not in view (doesn't fail rw_view1's check)
+UPDATE rw_view2 SET a = 200 WHERE a = 5; -- ok, but not in view (doesn't fail rw_view1's check)
+SELECT * FROM base_tbl ORDER BY a;
+  a  | b  
+-----+----
+  50 | 10
+ 100 | 10
+ 200 | 10
+(3 rows)
+
+-- Neither local nor cascaded check options work with INSTEAD rules
+DROP TRIGGER rw_view1_trig ON rw_view1;
+CREATE RULE rw_view1_ins_rule AS ON INSERT TO rw_view1
+  DO INSTEAD INSERT INTO base_tbl VALUES (NEW.a, 10);
+CREATE RULE rw_view1_upd_rule AS ON UPDATE TO rw_view1
+  DO INSTEAD UPDATE base_tbl SET a=NEW.a WHERE a=OLD.a;
+INSERT INTO rw_view2 VALUES (-10); -- ok, but not in view (doesn't fail rw_view2's check)
+INSERT INTO rw_view2 VALUES (5); -- ok
+INSERT INTO rw_view2 VALUES (20); -- ok, but not in view (doesn't fail rw_view1's check)
+UPDATE rw_view2 SET a = 30 WHERE a = 5; -- ok, but not in view (doesn't fail rw_view1's check)
+INSERT INTO rw_view2 VALUES (5); -- ok
+UPDATE rw_view2 SET a = -5 WHERE a = 5; -- ok, but not in view (doesn't fail rw_view2's check)
+SELECT * FROM base_tbl ORDER BY a;
+  a  | b  
+-----+----
+ -10 | 10
+  -5 | 10
+  20 | 10
+  30 | 10
+  50 | 10
+ 100 | 10
+ 200 | 10
+(7 rows)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to view rw_view1
+drop cascades to view rw_view2
+DROP FUNCTION rw_view1_trig_fn();
+CREATE TABLE base_tbl (a int);
+CREATE VIEW rw_view1 AS SELECT a,10 AS b FROM base_tbl;
+CREATE RULE rw_view1_ins_rule AS ON INSERT TO rw_view1
+  DO INSTEAD INSERT INTO base_tbl VALUES (NEW.a);
+CREATE VIEW rw_view2 AS
+  SELECT * FROM rw_view1 WHERE a > b WITH LOCAL CHECK OPTION;
+INSERT INTO rw_view2 VALUES (2,3); -- ok, but not in view (doesn't fail rw_view2's check)
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to view rw_view1
+drop cascades to view rw_view2
+-- security barrier view
+CREATE TABLE base_tbl (person text, visibility text);
+INSERT INTO base_tbl VALUES ('Tom', 'public'),
+                            ('Dick', 'private'),
+                            ('Harry', 'public');
+CREATE VIEW rw_view1 AS
+  SELECT person FROM base_tbl WHERE visibility = 'public';
+CREATE FUNCTION snoop(anyelement)
+RETURNS boolean AS
+$$
+BEGIN
+  RAISE NOTICE 'snooped value: %', $1;
+  RETURN true;
+END;
+$$
+LANGUAGE plpgsql COST 0.000001;
+CREATE OR REPLACE FUNCTION leakproof(anyelement)
+RETURNS boolean AS
+$$
+BEGIN
+  RETURN true;
+END;
+$$
+LANGUAGE plpgsql STRICT IMMUTABLE LEAKPROOF;
+SELECT * FROM rw_view1 WHERE snoop(person);
+NOTICE:  snooped value: Tom
+NOTICE:  snooped value: Dick
+NOTICE:  snooped value: Harry
+ person 
+--------
+ Tom
+ Harry
+(2 rows)
+
+UPDATE rw_view1 SET person=person WHERE snoop(person);
+NOTICE:  snooped value: Tom
+NOTICE:  snooped value: Dick
+NOTICE:  snooped value: Harry
+DELETE FROM rw_view1 WHERE NOT snoop(person);
+NOTICE:  snooped value: Tom
+NOTICE:  snooped value: Dick
+NOTICE:  snooped value: Harry
+ALTER VIEW rw_view1 SET (security_barrier = true);
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name = 'rw_view1';
+ table_name | is_insertable_into 
+------------+--------------------
+ rw_view1   | YES
+(1 row)
+
+SELECT table_name, is_updatable, is_insertable_into
+  FROM information_schema.views
+ WHERE table_name = 'rw_view1';
+ table_name | is_updatable | is_insertable_into 
+------------+--------------+--------------------
+ rw_view1   | YES          | YES
+(1 row)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name = 'rw_view1'
+ ORDER BY ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ rw_view1   | person      | YES
+(1 row)
+
+SELECT * FROM rw_view1 WHERE snoop(person);
+NOTICE:  snooped value: Tom
+NOTICE:  snooped value: Harry
+ person 
+--------
+ Tom
+ Harry
+(2 rows)
+
+UPDATE rw_view1 SET person=person WHERE snoop(person);
+NOTICE:  snooped value: Tom
+NOTICE:  snooped value: Harry
+DELETE FROM rw_view1 WHERE NOT snoop(person);
+NOTICE:  snooped value: Tom
+NOTICE:  snooped value: Harry
+EXPLAIN (costs off) SELECT * FROM rw_view1 WHERE snoop(person);
+                  QUERY PLAN                   
+-----------------------------------------------
+ Subquery Scan on rw_view1
+   Filter: snoop(rw_view1.person)
+   ->  Seq Scan on base_tbl
+         Filter: (visibility = 'public'::text)
+(4 rows)
+
+EXPLAIN (costs off) UPDATE rw_view1 SET person=person WHERE snoop(person);
+                            QUERY PLAN                             
+-------------------------------------------------------------------
+ Update on base_tbl
+   ->  Seq Scan on base_tbl
+         Filter: ((visibility = 'public'::text) AND snoop(person))
+(3 rows)
+
+EXPLAIN (costs off) DELETE FROM rw_view1 WHERE NOT snoop(person);
+                               QUERY PLAN                                
+-------------------------------------------------------------------------
+ Delete on base_tbl
+   ->  Seq Scan on base_tbl
+         Filter: ((visibility = 'public'::text) AND (NOT snoop(person)))
+(3 rows)
+
+-- security barrier view on top of security barrier view
+CREATE VIEW rw_view2 WITH (security_barrier = true) AS
+  SELECT * FROM rw_view1 WHERE snoop(person);
+SELECT table_name, is_insertable_into
+  FROM information_schema.tables
+ WHERE table_name = 'rw_view2';
+ table_name | is_insertable_into 
+------------+--------------------
+ rw_view2   | YES
+(1 row)
+
+SELECT table_name, is_updatable, is_insertable_into
+  FROM information_schema.views
+ WHERE table_name = 'rw_view2';
+ table_name | is_updatable | is_insertable_into 
+------------+--------------+--------------------
+ rw_view2   | YES          | YES
+(1 row)
+
+SELECT table_name, column_name, is_updatable
+  FROM information_schema.columns
+ WHERE table_name = 'rw_view2'
+ ORDER BY ordinal_position;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ rw_view2   | person      | YES
+(1 row)
+
+SELECT * FROM rw_view2 WHERE snoop(person);
+NOTICE:  snooped value: Tom
+NOTICE:  snooped value: Tom
+NOTICE:  snooped value: Harry
+NOTICE:  snooped value: Harry
+ person 
+--------
+ Tom
+ Harry
+(2 rows)
+
+UPDATE rw_view2 SET person=person WHERE snoop(person);
+NOTICE:  snooped value: Tom
+NOTICE:  snooped value: Tom
+NOTICE:  snooped value: Harry
+NOTICE:  snooped value: Harry
+DELETE FROM rw_view2 WHERE NOT snoop(person);
+NOTICE:  snooped value: Tom
+NOTICE:  snooped value: Tom
+NOTICE:  snooped value: Harry
+NOTICE:  snooped value: Harry
+EXPLAIN (costs off) SELECT * FROM rw_view2 WHERE snoop(person);
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Subquery Scan on rw_view2
+   Filter: snoop(rw_view2.person)
+   ->  Subquery Scan on rw_view1
+         Filter: snoop(rw_view1.person)
+         ->  Seq Scan on base_tbl
+               Filter: (visibility = 'public'::text)
+(6 rows)
+
+EXPLAIN (costs off) UPDATE rw_view2 SET person=person WHERE snoop(person);
+                                     QUERY PLAN                                      
+-------------------------------------------------------------------------------------
+ Update on base_tbl
+   ->  Seq Scan on base_tbl
+         Filter: ((visibility = 'public'::text) AND snoop(person) AND snoop(person))
+(3 rows)
+
+EXPLAIN (costs off) DELETE FROM rw_view2 WHERE NOT snoop(person);
+                                        QUERY PLAN                                         
+-------------------------------------------------------------------------------------------
+ Delete on base_tbl
+   ->  Seq Scan on base_tbl
+         Filter: ((visibility = 'public'::text) AND snoop(person) AND (NOT snoop(person)))
+(3 rows)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to view rw_view1
+drop cascades to view rw_view2
+-- security barrier view on top of table with rules
+CREATE TABLE base_tbl(id int PRIMARY KEY, data text, deleted boolean);
+INSERT INTO base_tbl VALUES (1, 'Row 1', false), (2, 'Row 2', true);
+CREATE RULE base_tbl_ins_rule AS ON INSERT TO base_tbl
+  WHERE EXISTS (SELECT 1 FROM base_tbl t WHERE t.id = new.id)
+  DO INSTEAD
+    UPDATE base_tbl SET data = new.data, deleted = false WHERE id = new.id;
+CREATE RULE base_tbl_del_rule AS ON DELETE TO base_tbl
+  DO INSTEAD
+    UPDATE base_tbl SET deleted = true WHERE id = old.id;
+CREATE VIEW rw_view1 WITH (security_barrier=true) AS
+  SELECT id, data FROM base_tbl WHERE NOT deleted;
+SELECT * FROM rw_view1;
+ id | data  
+----+-------
+  1 | Row 1
+(1 row)
+
+EXPLAIN (costs off) DELETE FROM rw_view1 WHERE id = 1 AND snoop(data);
+                            QUERY PLAN                             
+-------------------------------------------------------------------
+ Update on base_tbl base_tbl_1
+   ->  Nested Loop
+         ->  Index Scan using base_tbl_pkey on base_tbl base_tbl_1
+               Index Cond: (id = 1)
+         ->  Index Scan using base_tbl_pkey on base_tbl
+               Index Cond: (id = 1)
+               Filter: ((NOT deleted) AND snoop(data))
+(7 rows)
+
+DELETE FROM rw_view1 WHERE id = 1 AND snoop(data);
+NOTICE:  snooped value: Row 1
+EXPLAIN (costs off) INSERT INTO rw_view1 VALUES (2, 'New row 2');
+                        QUERY PLAN                         
+-----------------------------------------------------------
+ Insert on base_tbl
+   InitPlan 1 (returns $0)
+     ->  Index Only Scan using base_tbl_pkey on base_tbl t
+           Index Cond: (id = 2)
+   ->  Result
+         One-Time Filter: ($0 IS NOT TRUE)
+ 
+ Update on base_tbl
+   InitPlan 1 (returns $0)
+     ->  Index Only Scan using base_tbl_pkey on base_tbl t
+           Index Cond: (id = 2)
+   ->  Result
+         One-Time Filter: $0
+         ->  Index Scan using base_tbl_pkey on base_tbl
+               Index Cond: (id = 2)
+(15 rows)
+
+INSERT INTO rw_view1 VALUES (2, 'New row 2');
+SELECT * FROM base_tbl;
+ id |   data    | deleted 
+----+-----------+---------
+  1 | Row 1     | t
+  2 | New row 2 | f
+(2 rows)
+
+DROP TABLE base_tbl CASCADE;
+NOTICE:  drop cascades to view rw_view1
+-- security barrier view based on inheritance set
+CREATE TABLE t1 (a int, b float, c text);
+CREATE INDEX t1_a_idx ON t1(a);
+INSERT INTO t1
+SELECT i,i,'t1' FROM generate_series(1,10) g(i);
+ANALYZE t1;
+CREATE TABLE t11 (d text) INHERITS (t1);
+CREATE INDEX t11_a_idx ON t11(a);
+INSERT INTO t11
+SELECT i,i,'t11','t11d' FROM generate_series(1,10) g(i);
+ANALYZE t11;
+CREATE TABLE t12 (e int[]) INHERITS (t1);
+CREATE INDEX t12_a_idx ON t12(a);
+INSERT INTO t12
+SELECT i,i,'t12','{1,2}'::int[] FROM generate_series(1,10) g(i);
+ANALYZE t12;
+CREATE TABLE t111 () INHERITS (t11, t12);
+NOTICE:  merging multiple inherited definitions of column "a"
+NOTICE:  merging multiple inherited definitions of column "b"
+NOTICE:  merging multiple inherited definitions of column "c"
+CREATE INDEX t111_a_idx ON t111(a);
+INSERT INTO t111
+SELECT i,i,'t111','t111d','{1,1,1}'::int[] FROM generate_series(1,10) g(i);
+ANALYZE t111;
+CREATE VIEW v1 WITH (security_barrier=true) AS
+SELECT *, (SELECT d FROM t11 WHERE t11.a = t1.a LIMIT 1) AS d
+FROM t1
+WHERE a > 5 AND EXISTS(SELECT 1 FROM t12 WHERE t12.a = t1.a);
+SELECT * FROM v1 WHERE a=3; -- should not see anything
+ a | b | c | d 
+---+---+---+---
+(0 rows)
+
+SELECT * FROM v1 WHERE a=8;
+ a | b |  c   |  d   
+---+---+------+------
+ 8 | 8 | t1   | t11d
+ 8 | 8 | t11  | t11d
+ 8 | 8 | t12  | t11d
+ 8 | 8 | t111 | t11d
+(4 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+UPDATE v1 SET a=100 WHERE snoop(a) AND leakproof(a) AND a < 7 AND a != 6;
+                                                        QUERY PLAN                                                         
+---------------------------------------------------------------------------------------------------------------------------
+ Update on public.t1
+   Update on public.t1
+   Update on public.t11
+   Update on public.t12
+   Update on public.t111
+   ->  Index Scan using t1_a_idx on public.t1
+         Output: 100, t1.b, t1.c, t1.ctid
+         Index Cond: ((t1.a > 5) AND (t1.a < 7))
+         Filter: ((t1.a <> 6) AND (alternatives: SubPlan 1 or hashed SubPlan 2) AND snoop(t1.a) AND leakproof(t1.a))
+         SubPlan 1
+           ->  Append
+                 ->  Seq Scan on public.t12 t12_1
+                       Filter: (t12_1.a = t1.a)
+                 ->  Seq Scan on public.t111 t111_1
+                       Filter: (t111_1.a = t1.a)
+         SubPlan 2
+           ->  Append
+                 ->  Seq Scan on public.t12 t12_2
+                       Output: t12_2.a
+                 ->  Seq Scan on public.t111 t111_2
+                       Output: t111_2.a
+   ->  Index Scan using t11_a_idx on public.t11
+         Output: 100, t11.b, t11.c, t11.d, t11.ctid
+         Index Cond: ((t11.a > 5) AND (t11.a < 7))
+         Filter: ((t11.a <> 6) AND (alternatives: SubPlan 1 or hashed SubPlan 2) AND snoop(t11.a) AND leakproof(t11.a))
+   ->  Index Scan using t12_a_idx on public.t12
+         Output: 100, t12.b, t12.c, t12.e, t12.ctid
+         Index Cond: ((t12.a > 5) AND (t12.a < 7))
+         Filter: ((t12.a <> 6) AND (alternatives: SubPlan 1 or hashed SubPlan 2) AND snoop(t12.a) AND leakproof(t12.a))
+   ->  Index Scan using t111_a_idx on public.t111
+         Output: 100, t111.b, t111.c, t111.d, t111.e, t111.ctid
+         Index Cond: ((t111.a > 5) AND (t111.a < 7))
+         Filter: ((t111.a <> 6) AND (alternatives: SubPlan 1 or hashed SubPlan 2) AND snoop(t111.a) AND leakproof(t111.a))
+(33 rows)
+
+UPDATE v1 SET a=100 WHERE snoop(a) AND leakproof(a) AND a < 7 AND a != 6;
+SELECT * FROM v1 WHERE a=100; -- Nothing should have been changed to 100
+ a | b | c | d 
+---+---+---+---
+(0 rows)
+
+SELECT * FROM t1 WHERE a=100; -- Nothing should have been changed to 100
+ a | b | c 
+---+---+---
+(0 rows)
+
+EXPLAIN (VERBOSE, COSTS OFF)
+UPDATE v1 SET a=a+1 WHERE snoop(a) AND leakproof(a) AND a = 8;
+                                               QUERY PLAN                                                
+---------------------------------------------------------------------------------------------------------
+ Update on public.t1
+   Update on public.t1
+   Update on public.t11
+   Update on public.t12
+   Update on public.t111
+   ->  Index Scan using t1_a_idx on public.t1
+         Output: (t1.a + 1), t1.b, t1.c, t1.ctid
+         Index Cond: ((t1.a > 5) AND (t1.a = 8))
+         Filter: ((alternatives: SubPlan 1 or hashed SubPlan 2) AND snoop(t1.a) AND leakproof(t1.a))
+         SubPlan 1
+           ->  Append
+                 ->  Seq Scan on public.t12 t12_1
+                       Filter: (t12_1.a = t1.a)
+                 ->  Seq Scan on public.t111 t111_1
+                       Filter: (t111_1.a = t1.a)
+         SubPlan 2
+           ->  Append
+                 ->  Seq Scan on public.t12 t12_2
+                       Output: t12_2.a
+                 ->  Seq Scan on public.t111 t111_2
+                       Output: t111_2.a
+   ->  Index Scan using t11_a_idx on public.t11
+         Output: (t11.a + 1), t11.b, t11.c, t11.d, t11.ctid
+         Index Cond: ((t11.a > 5) AND (t11.a = 8))
+         Filter: ((alternatives: SubPlan 1 or hashed SubPlan 2) AND snoop(t11.a) AND leakproof(t11.a))
+   ->  Index Scan using t12_a_idx on public.t12
+         Output: (t12.a + 1), t12.b, t12.c, t12.e, t12.ctid
+         Index Cond: ((t12.a > 5) AND (t12.a = 8))
+         Filter: ((alternatives: SubPlan 1 or hashed SubPlan 2) AND snoop(t12.a) AND leakproof(t12.a))
+   ->  Index Scan using t111_a_idx on public.t111
+         Output: (t111.a + 1), t111.b, t111.c, t111.d, t111.e, t111.ctid
+         Index Cond: ((t111.a > 5) AND (t111.a = 8))
+         Filter: ((alternatives: SubPlan 1 or hashed SubPlan 2) AND snoop(t111.a) AND leakproof(t111.a))
+(33 rows)
+
+UPDATE v1 SET a=a+1 WHERE snoop(a) AND leakproof(a) AND a = 8;
+NOTICE:  snooped value: 8
+NOTICE:  snooped value: 8
+NOTICE:  snooped value: 8
+NOTICE:  snooped value: 8
+SELECT * FROM v1 WHERE b=8;
+ a | b |  c   |  d   
+---+---+------+------
+ 9 | 8 | t1   | t11d
+ 9 | 8 | t11  | t11d
+ 9 | 8 | t12  | t11d
+ 9 | 8 | t111 | t11d
+(4 rows)
+
+DELETE FROM v1 WHERE snoop(a) AND leakproof(a); -- should not delete everything, just where a>5
+NOTICE:  snooped value: 6
+NOTICE:  snooped value: 7
+NOTICE:  snooped value: 9
+NOTICE:  snooped value: 10
+NOTICE:  snooped value: 9
+NOTICE:  snooped value: 6
+NOTICE:  snooped value: 7
+NOTICE:  snooped value: 9
+NOTICE:  snooped value: 10
+NOTICE:  snooped value: 9
+NOTICE:  snooped value: 6
+NOTICE:  snooped value: 7
+NOTICE:  snooped value: 9
+NOTICE:  snooped value: 10
+NOTICE:  snooped value: 9
+NOTICE:  snooped value: 6
+NOTICE:  snooped value: 7
+NOTICE:  snooped value: 9
+NOTICE:  snooped value: 10
+NOTICE:  snooped value: 9
+TABLE t1; -- verify all a<=5 are intact
+ a | b |  c   
+---+---+------
+ 1 | 1 | t1
+ 2 | 2 | t1
+ 3 | 3 | t1
+ 4 | 4 | t1
+ 5 | 5 | t1
+ 1 | 1 | t11
+ 2 | 2 | t11
+ 3 | 3 | t11
+ 4 | 4 | t11
+ 5 | 5 | t11
+ 1 | 1 | t12
+ 2 | 2 | t12
+ 3 | 3 | t12
+ 4 | 4 | t12
+ 5 | 5 | t12
+ 1 | 1 | t111
+ 2 | 2 | t111
+ 3 | 3 | t111
+ 4 | 4 | t111
+ 5 | 5 | t111
+(20 rows)
+
+DROP TABLE t1, t11, t12, t111 CASCADE;
+NOTICE:  drop cascades to view v1
+DROP FUNCTION snoop(anyelement);
+DROP FUNCTION leakproof(anyelement);
+CREATE TABLE tx1 (a integer);
+CREATE TABLE tx2 (b integer);
+CREATE TABLE tx3 (c integer);
+CREATE VIEW vx1 AS SELECT a FROM tx1 WHERE EXISTS(SELECT 1 FROM tx2 JOIN tx3 ON b=c);
+INSERT INTO vx1 values (1);
+SELECT * FROM tx1;
+ a 
+---
+ 1
+(1 row)
+
+SELECT * FROM vx1;
+ a 
+---
+(0 rows)
+
+DROP VIEW vx1;
+DROP TABLE tx1;
+DROP TABLE tx2;
+DROP TABLE tx3;
+CREATE TABLE tx1 (a integer);
+CREATE TABLE tx2 (b integer);
+CREATE TABLE tx3 (c integer);
+CREATE VIEW vx1 AS SELECT a FROM tx1 WHERE EXISTS(SELECT 1 FROM tx2 JOIN tx3 ON b=c);
+INSERT INTO vx1 VALUES (1);
+INSERT INTO vx1 VALUES (1);
+SELECT * FROM tx1;
+ a 
+---
+ 1
+ 1
+(2 rows)
+
+SELECT * FROM vx1;
+ a 
+---
+(0 rows)
+
+DROP VIEW vx1;
+DROP TABLE tx1;
+DROP TABLE tx2;
+DROP TABLE tx3;
+CREATE TABLE tx1 (a integer, b integer);
+CREATE TABLE tx2 (b integer, c integer);
+CREATE TABLE tx3 (c integer, d integer);
+ALTER TABLE tx1 DROP COLUMN b;
+ALTER TABLE tx2 DROP COLUMN c;
+ALTER TABLE tx3 DROP COLUMN d;
+CREATE VIEW vx1 AS SELECT a FROM tx1 WHERE EXISTS(SELECT 1 FROM tx2 JOIN tx3 ON b=c);
+INSERT INTO vx1 VALUES (1);
+INSERT INTO vx1 VALUES (1);
+SELECT * FROM tx1;
+ a 
+---
+ 1
+ 1
+(2 rows)
+
+SELECT * FROM vx1;
+ a 
+---
+(0 rows)
+
+DROP VIEW vx1;
+DROP TABLE tx1;
+DROP TABLE tx2;
+DROP TABLE tx3;
+--
+-- Test handling of vars from correlated subqueries in quals from outer
+-- security barrier views, per bug #13988
+--
+CREATE TABLE t1 (a int, b text, c int);
+INSERT INTO t1 VALUES (1, 'one', 10);
+CREATE TABLE t2 (cc int);
+INSERT INTO t2 VALUES (10), (20);
+CREATE VIEW v1 WITH (security_barrier = true) AS
+  SELECT * FROM t1 WHERE (a > 0)
+  WITH CHECK OPTION;
+CREATE VIEW v2 WITH (security_barrier = true) AS
+  SELECT * FROM v1 WHERE EXISTS (SELECT 1 FROM t2 WHERE t2.cc = v1.c)
+  WITH CHECK OPTION;
+INSERT INTO v2 VALUES (2, 'two', 20); -- ok
+INSERT INTO v2 VALUES (-2, 'minus two', 20); -- not allowed
+ERROR:  new row violates check option for view "v1"
+DETAIL:  Failing row contains (-2, minus two, 20).
+INSERT INTO v2 VALUES (3, 'three', 30); -- not allowed
+ERROR:  new row violates check option for view "v2"
+DETAIL:  Failing row contains (3, three, 30).
+UPDATE v2 SET b = 'ONE' WHERE a = 1; -- ok
+UPDATE v2 SET a = -1 WHERE a = 1; -- not allowed
+ERROR:  new row violates check option for view "v1"
+DETAIL:  Failing row contains (-1, ONE, 10).
+UPDATE v2 SET c = 30 WHERE a = 1; -- not allowed
+ERROR:  new row violates check option for view "v2"
+DETAIL:  Failing row contains (1, ONE, 30).
+DELETE FROM v2 WHERE a = 2; -- ok
+SELECT * FROM v2;
+ a |  b  | c  
+---+-----+----
+ 1 | ONE | 10
+(1 row)
+
+DROP VIEW v2;
+DROP VIEW v1;
+DROP TABLE t2;
+DROP TABLE t1;
+--
+-- Test CREATE OR REPLACE VIEW turning a non-updatable view into an
+-- auto-updatable view and adding check options in a single step
+--
+CREATE TABLE t1 (a int, b text);
+CREATE VIEW v1 AS SELECT null::int AS a;
+CREATE OR REPLACE VIEW v1 AS SELECT * FROM t1 WHERE a > 0 WITH CHECK OPTION;
+INSERT INTO v1 VALUES (1, 'ok'); -- ok
+INSERT INTO v1 VALUES (-1, 'invalid'); -- should fail
+ERROR:  new row violates check option for view "v1"
+DETAIL:  Failing row contains (-1, invalid).
+DROP VIEW v1;
+DROP TABLE t1;
+-- check that an auto-updatable view on a partitioned table works correctly
+create table uv_pt (a int, b int, v varchar) partition by range (a, b);
+create table uv_pt1 (b int not null, v varchar, a int not null) partition by range (b);
+create table uv_pt11 (like uv_pt1);
+alter table uv_pt11 drop a;
+alter table uv_pt11 add a int;
+alter table uv_pt11 drop a;
+alter table uv_pt11 add a int not null;
+alter table uv_pt1 attach partition uv_pt11 for values from (2) to (5);
+alter table uv_pt attach partition uv_pt1 for values from (1, 2) to (1, 10);
+create view uv_ptv as select * from uv_pt;
+select events & 4 != 0 AS upd,
+       events & 8 != 0 AS ins,
+       events & 16 != 0 AS del
+  from pg_catalog.pg_relation_is_updatable('uv_pt'::regclass, false) t(events);
+ upd | ins | del 
+-----+-----+-----
+ t   | t   | t
+(1 row)
+
+select pg_catalog.pg_column_is_updatable('uv_pt'::regclass, 1::smallint, false);
+ pg_column_is_updatable 
+------------------------
+ t
+(1 row)
+
+select pg_catalog.pg_column_is_updatable('uv_pt'::regclass, 2::smallint, false);
+ pg_column_is_updatable 
+------------------------
+ t
+(1 row)
+
+select table_name, is_updatable, is_insertable_into
+  from information_schema.views where table_name = 'uv_ptv';
+ table_name | is_updatable | is_insertable_into 
+------------+--------------+--------------------
+ uv_ptv     | YES          | YES
+(1 row)
+
+select table_name, column_name, is_updatable
+  from information_schema.columns where table_name = 'uv_ptv' order by column_name;
+ table_name | column_name | is_updatable 
+------------+-------------+--------------
+ uv_ptv     | a           | YES
+ uv_ptv     | b           | YES
+ uv_ptv     | v           | YES
+(3 rows)
+
+insert into uv_ptv values (1, 2);
+select tableoid::regclass, * from uv_pt;
+ tableoid | a | b | v 
+----------+---+---+---
+ uv_pt11  | 1 | 2 | 
+(1 row)
+
+create view uv_ptv_wco as select * from uv_pt where a = 0 with check option;
+insert into uv_ptv_wco values (1, 2);
+ERROR:  new row violates check option for view "uv_ptv_wco"
+DETAIL:  Failing row contains (1, 2, null).
+drop view uv_ptv, uv_ptv_wco;
+drop table uv_pt, uv_pt1, uv_pt11;
+-- check that wholerow vars appearing in WITH CHECK OPTION constraint expressions
+-- work fine with partitioned tables
+create table wcowrtest (a int) partition by list (a);
+create table wcowrtest1 partition of wcowrtest for values in (1);
+create view wcowrtest_v as select * from wcowrtest where wcowrtest = '(2)'::wcowrtest with check option;
+insert into wcowrtest_v values (1);
+ERROR:  new row violates check option for view "wcowrtest_v"
+DETAIL:  Failing row contains (1).
+alter table wcowrtest add b text;
+create table wcowrtest2 (b text, c int, a int);
+alter table wcowrtest2 drop c;
+alter table wcowrtest attach partition wcowrtest2 for values in (2);
+create table sometable (a int, b text);
+insert into sometable values (1, 'a'), (2, 'b');
+create view wcowrtest_v2 as
+    select *
+      from wcowrtest r
+      where r in (select s from sometable s where r.a = s.a)
+with check option;
+-- WITH CHECK qual will be processed with wcowrtest2's
+-- rowtype after tuple-routing
+insert into wcowrtest_v2 values (2, 'no such row in sometable');
+ERROR:  new row violates check option for view "wcowrtest_v2"
+DETAIL:  Failing row contains (2, no such row in sometable).
+drop view wcowrtest_v, wcowrtest_v2;
+drop table wcowrtest, sometable;
+-- Check INSERT .. ON CONFLICT DO UPDATE works correctly when the view's
+-- columns are named and ordered differently than the underlying table's.
+create table uv_iocu_tab (a text unique, b float);
+insert into uv_iocu_tab values ('xyxyxy', 0);
+create view uv_iocu_view as
+   select b, b+1 as c, a, '2.0'::text as two from uv_iocu_tab;
+insert into uv_iocu_view (a, b) values ('xyxyxy', 1)
+   on conflict (a) do update set b = uv_iocu_view.b;
+select * from uv_iocu_tab;
+   a    | b 
+--------+---
+ xyxyxy | 0
+(1 row)
+
+insert into uv_iocu_view (a, b) values ('xyxyxy', 1)
+   on conflict (a) do update set b = excluded.b;
+select * from uv_iocu_tab;
+   a    | b 
+--------+---
+ xyxyxy | 1
+(1 row)
+
+-- OK to access view columns that are not present in underlying base
+-- relation in the ON CONFLICT portion of the query
+insert into uv_iocu_view (a, b) values ('xyxyxy', 3)
+   on conflict (a) do update set b = cast(excluded.two as float);
+select * from uv_iocu_tab;
+   a    | b 
+--------+---
+ xyxyxy | 2
+(1 row)
+
+explain (costs off)
+insert into uv_iocu_view (a, b) values ('xyxyxy', 3)
+   on conflict (a) do update set b = excluded.b where excluded.c > 0;
+                                    QUERY PLAN                                     
+-----------------------------------------------------------------------------------
+ Insert on uv_iocu_tab
+   Conflict Resolution: UPDATE
+   Conflict Arbiter Indexes: uv_iocu_tab_a_key
+   Conflict Filter: ((excluded.b + '1'::double precision) > '0'::double precision)
+   ->  Result
+(5 rows)
+
+insert into uv_iocu_view (a, b) values ('xyxyxy', 3)
+   on conflict (a) do update set b = excluded.b where excluded.c > 0;
+select * from uv_iocu_tab;
+   a    | b 
+--------+---
+ xyxyxy | 3
+(1 row)
+
+drop view uv_iocu_view;
+drop table uv_iocu_tab;
+-- Test whole-row references to the view
+create table uv_iocu_tab (a int unique, b text);
+create view uv_iocu_view as
+    select b as bb, a as aa, uv_iocu_tab::text as cc from uv_iocu_tab;
+insert into uv_iocu_view (aa,bb) values (1,'x');
+explain (costs off)
+insert into uv_iocu_view (aa,bb) values (1,'y')
+   on conflict (aa) do update set bb = 'Rejected: '||excluded.*
+   where excluded.aa > 0
+   and excluded.bb != ''
+   and excluded.cc is not null;
+                                               QUERY PLAN                                                
+---------------------------------------------------------------------------------------------------------
+ Insert on uv_iocu_tab
+   Conflict Resolution: UPDATE
+   Conflict Arbiter Indexes: uv_iocu_tab_a_key
+   Conflict Filter: ((excluded.a > 0) AND (excluded.b <> ''::text) AND ((excluded.*)::text IS NOT NULL))
+   ->  Result
+(5 rows)
+
+insert into uv_iocu_view (aa,bb) values (1,'y')
+   on conflict (aa) do update set bb = 'Rejected: '||excluded.*
+   where excluded.aa > 0
+   and excluded.bb != ''
+   and excluded.cc is not null;
+select * from uv_iocu_view;
+           bb            | aa |               cc                
+-------------------------+----+---------------------------------
+ Rejected: (y,1,"(1,y)") |  1 | (1,"Rejected: (y,1,""(1,y)"")")
+(1 row)
+
+-- Test omitting a column of the base relation
+delete from uv_iocu_view;
+insert into uv_iocu_view (aa,bb) values (1,'x');
+insert into uv_iocu_view (aa) values (1)
+   on conflict (aa) do update set bb = 'Rejected: '||excluded.*;
+select * from uv_iocu_view;
+          bb           | aa |              cc               
+-----------------------+----+-------------------------------
+ Rejected: (,1,"(1,)") |  1 | (1,"Rejected: (,1,""(1,)"")")
+(1 row)
+
+alter table uv_iocu_tab alter column b set default 'table default';
+insert into uv_iocu_view (aa) values (1)
+   on conflict (aa) do update set bb = 'Rejected: '||excluded.*;
+select * from uv_iocu_view;
+                          bb                           | aa |                                 cc                                  
+-------------------------------------------------------+----+---------------------------------------------------------------------
+ Rejected: ("table default",1,"(1,""table default"")") |  1 | (1,"Rejected: (""table default"",1,""(1,""""table default"""")"")")
+(1 row)
+
+alter view uv_iocu_view alter column bb set default 'view default';
+insert into uv_iocu_view (aa) values (1)
+   on conflict (aa) do update set bb = 'Rejected: '||excluded.*;
+select * from uv_iocu_view;
+                         bb                          | aa |                                cc                                 
+-----------------------------------------------------+----+-------------------------------------------------------------------
+ Rejected: ("view default",1,"(1,""view default"")") |  1 | (1,"Rejected: (""view default"",1,""(1,""""view default"""")"")")
+(1 row)
+
+-- Should fail to update non-updatable columns
+insert into uv_iocu_view (aa) values (1)
+   on conflict (aa) do update set cc = 'XXX';
+ERROR:  cannot insert into column "cc" of view "uv_iocu_view"
+DETAIL:  View columns that are not columns of their base relation are not updatable.
+drop view uv_iocu_view;
+drop table uv_iocu_tab;
+-- ON CONFLICT DO UPDATE permissions checks
+create user regress_view_user1;
+create user regress_view_user2;
+set session authorization regress_view_user1;
+create table base_tbl(a int unique, b text, c float);
+insert into base_tbl values (1,'xxx',1.0);
+create view rw_view1 as select b as bb, c as cc, a as aa from base_tbl;
+grant select (aa,bb) on rw_view1 to regress_view_user2;
+grant insert on rw_view1 to regress_view_user2;
+grant update (bb) on rw_view1 to regress_view_user2;
+set session authorization regress_view_user2;
+insert into rw_view1 values ('yyy',2.0,1)
+  on conflict (aa) do update set bb = excluded.cc; -- Not allowed
+ERROR:  permission denied for view rw_view1
+insert into rw_view1 values ('yyy',2.0,1)
+  on conflict (aa) do update set bb = rw_view1.cc; -- Not allowed
+ERROR:  permission denied for view rw_view1
+insert into rw_view1 values ('yyy',2.0,1)
+  on conflict (aa) do update set bb = excluded.bb; -- OK
+insert into rw_view1 values ('zzz',2.0,1)
+  on conflict (aa) do update set bb = rw_view1.bb||'xxx'; -- OK
+insert into rw_view1 values ('zzz',2.0,1)
+  on conflict (aa) do update set cc = 3.0; -- Not allowed
+ERROR:  permission denied for view rw_view1
+reset session authorization;
+select * from base_tbl;
+ a |   b    | c 
+---+--------+---
+ 1 | yyyxxx | 1
+(1 row)
+
+set session authorization regress_view_user1;
+grant select (a,b) on base_tbl to regress_view_user2;
+grant insert (a,b) on base_tbl to regress_view_user2;
+grant update (a,b) on base_tbl to regress_view_user2;
+set session authorization regress_view_user2;
+create view rw_view2 as select b as bb, c as cc, a as aa from base_tbl;
+insert into rw_view2 (aa,bb) values (1,'xxx')
+  on conflict (aa) do update set bb = excluded.bb; -- Not allowed
+ERROR:  permission denied for table base_tbl
+create view rw_view3 as select b as bb, a as aa from base_tbl;
+insert into rw_view3 (aa,bb) values (1,'xxx')
+  on conflict (aa) do update set bb = excluded.bb; -- OK
+reset session authorization;
+select * from base_tbl;
+ a |  b  | c 
+---+-----+---
+ 1 | xxx | 1
+(1 row)
+
+set session authorization regress_view_user2;
+create view rw_view4 as select aa, bb, cc FROM rw_view1;
+insert into rw_view4 (aa,bb) values (1,'yyy')
+  on conflict (aa) do update set bb = excluded.bb; -- Not allowed
+ERROR:  permission denied for view rw_view1
+create view rw_view5 as select aa, bb FROM rw_view1;
+insert into rw_view5 (aa,bb) values (1,'yyy')
+  on conflict (aa) do update set bb = excluded.bb; -- OK
+reset session authorization;
+select * from base_tbl;
+ a |  b  | c 
+---+-----+---
+ 1 | yyy | 1
+(1 row)
+
+drop view rw_view5;
+drop view rw_view4;
+drop view rw_view3;
+drop view rw_view2;
+drop view rw_view1;
+drop table base_tbl;
+drop user regress_view_user1;
+drop user regress_view_user2;
+-- Test single- and multi-row inserts with table and view defaults.
+-- Table defaults should be used, unless overridden by view defaults.
+create table base_tab_def (a int, b text default 'Table default',
+                           c text default 'Table default', d text, e text);
+create view base_tab_def_view as select * from base_tab_def;
+alter view base_tab_def_view alter b set default 'View default';
+alter view base_tab_def_view alter d set default 'View default';
+insert into base_tab_def values (1);
+insert into base_tab_def values (2), (3);
+insert into base_tab_def values (4, default, default, default, default);
+insert into base_tab_def values (5, default, default, default, default),
+                                (6, default, default, default, default);
+insert into base_tab_def_view values (11);
+insert into base_tab_def_view values (12), (13);
+insert into base_tab_def_view values (14, default, default, default, default);
+insert into base_tab_def_view values (15, default, default, default, default),
+                                     (16, default, default, default, default);
+insert into base_tab_def_view values (17), (default);
+select * from base_tab_def order by a;
+ a  |       b       |       c       |      d       | e 
+----+---------------+---------------+--------------+---
+  1 | Table default | Table default |              | 
+  2 | Table default | Table default |              | 
+  3 | Table default | Table default |              | 
+  4 | Table default | Table default |              | 
+  5 | Table default | Table default |              | 
+  6 | Table default | Table default |              | 
+ 11 | View default  | Table default | View default | 
+ 12 | View default  | Table default | View default | 
+ 13 | View default  | Table default | View default | 
+ 14 | View default  | Table default | View default | 
+ 15 | View default  | Table default | View default | 
+ 16 | View default  | Table default | View default | 
+ 17 | View default  | Table default | View default | 
+    | View default  | Table default | View default | 
+(14 rows)
+
+-- Adding an INSTEAD OF trigger should cause NULLs to be inserted instead of
+-- table defaults, where there are no view defaults.
+create function base_tab_def_view_instrig_func() returns trigger
+as
+$$
+begin
+  insert into base_tab_def values (new.a, new.b, new.c, new.d, new.e);
+  return new;
+end;
+$$
+language plpgsql;
+create trigger base_tab_def_view_instrig instead of insert on base_tab_def_view
+  for each row execute function base_tab_def_view_instrig_func();
+truncate base_tab_def;
+insert into base_tab_def values (1);
+insert into base_tab_def values (2), (3);
+insert into base_tab_def values (4, default, default, default, default);
+insert into base_tab_def values (5, default, default, default, default),
+                                (6, default, default, default, default);
+insert into base_tab_def_view values (11);
+insert into base_tab_def_view values (12), (13);
+insert into base_tab_def_view values (14, default, default, default, default);
+insert into base_tab_def_view values (15, default, default, default, default),
+                                     (16, default, default, default, default);
+insert into base_tab_def_view values (17), (default);
+select * from base_tab_def order by a;
+ a  |       b       |       c       |      d       | e 
+----+---------------+---------------+--------------+---
+  1 | Table default | Table default |              | 
+  2 | Table default | Table default |              | 
+  3 | Table default | Table default |              | 
+  4 | Table default | Table default |              | 
+  5 | Table default | Table default |              | 
+  6 | Table default | Table default |              | 
+ 11 | View default  |               | View default | 
+ 12 | View default  |               | View default | 
+ 13 | View default  |               | View default | 
+ 14 | View default  |               | View default | 
+ 15 | View default  |               | View default | 
+ 16 | View default  |               | View default | 
+ 17 | View default  |               | View default | 
+    | View default  |               | View default | 
+(14 rows)
+
+-- Using an unconditional DO INSTEAD rule should also cause NULLs to be
+-- inserted where there are no view defaults.
+drop trigger base_tab_def_view_instrig on base_tab_def_view;
+drop function base_tab_def_view_instrig_func;
+create rule base_tab_def_view_ins_rule as on insert to base_tab_def_view
+  do instead insert into base_tab_def values (new.a, new.b, new.c, new.d, new.e);
+truncate base_tab_def;
+insert into base_tab_def values (1);
+insert into base_tab_def values (2), (3);
+insert into base_tab_def values (4, default, default, default, default);
+insert into base_tab_def values (5, default, default, default, default),
+                                (6, default, default, default, default);
+insert into base_tab_def_view values (11);
+insert into base_tab_def_view values (12), (13);
+insert into base_tab_def_view values (14, default, default, default, default);
+insert into base_tab_def_view values (15, default, default, default, default),
+                                     (16, default, default, default, default);
+insert into base_tab_def_view values (17), (default);
+select * from base_tab_def order by a;
+ a  |       b       |       c       |      d       | e 
+----+---------------+---------------+--------------+---
+  1 | Table default | Table default |              | 
+  2 | Table default | Table default |              | 
+  3 | Table default | Table default |              | 
+  4 | Table default | Table default |              | 
+  5 | Table default | Table default |              | 
+  6 | Table default | Table default |              | 
+ 11 | View default  |               | View default | 
+ 12 | View default  |               | View default | 
+ 13 | View default  |               | View default | 
+ 14 | View default  |               | View default | 
+ 15 | View default  |               | View default | 
+ 16 | View default  |               | View default | 
+ 17 | View default  |               | View default | 
+    | View default  |               | View default | 
+(14 rows)
+
+-- A DO ALSO rule should cause each row to be inserted twice. The first
+-- insert should behave the same as an auto-updatable view (using table
+-- defaults, unless overridden by view defaults). The second insert should
+-- behave the same as a rule-updatable view (inserting NULLs where there are
+-- no view defaults).
+drop rule base_tab_def_view_ins_rule on base_tab_def_view;
+create rule base_tab_def_view_ins_rule as on insert to base_tab_def_view
+  do also insert into base_tab_def values (new.a, new.b, new.c, new.d, new.e);
+truncate base_tab_def;
+insert into base_tab_def values (1);
+insert into base_tab_def values (2), (3);
+insert into base_tab_def values (4, default, default, default, default);
+insert into base_tab_def values (5, default, default, default, default),
+                                (6, default, default, default, default);
+insert into base_tab_def_view values (11);
+insert into base_tab_def_view values (12), (13);
+insert into base_tab_def_view values (14, default, default, default, default);
+insert into base_tab_def_view values (15, default, default, default, default),
+                                     (16, default, default, default, default);
+insert into base_tab_def_view values (17), (default);
+select * from base_tab_def order by a, c NULLS LAST;
+ a  |       b       |       c       |      d       | e 
+----+---------------+---------------+--------------+---
+  1 | Table default | Table default |              | 
+  2 | Table default | Table default |              | 
+  3 | Table default | Table default |              | 
+  4 | Table default | Table default |              | 
+  5 | Table default | Table default |              | 
+  6 | Table default | Table default |              | 
+ 11 | View default  | Table default | View default | 
+ 11 | View default  |               | View default | 
+ 12 | View default  | Table default | View default | 
+ 12 | View default  |               | View default | 
+ 13 | View default  | Table default | View default | 
+ 13 | View default  |               | View default | 
+ 14 | View default  | Table default | View default | 
+ 14 | View default  |               | View default | 
+ 15 | View default  | Table default | View default | 
+ 15 | View default  |               | View default | 
+ 16 | View default  | Table default | View default | 
+ 16 | View default  |               | View default | 
+ 17 | View default  | Table default | View default | 
+ 17 | View default  |               | View default | 
+    | View default  | Table default | View default | 
+    | View default  |               | View default | 
+(22 rows)
+
+drop view base_tab_def_view;
+drop table base_tab_def;
+-- Test defaults with array assignments
+create table base_tab (a serial, b int[], c text, d text default 'Table default');
+create view base_tab_view as select c, a, b from base_tab;
+alter view base_tab_view alter column c set default 'View default';
+insert into base_tab_view (b[1], b[2], c, b[5], b[4], a, b[3])
+values (1, 2, default, 5, 4, default, 3), (10, 11, 'C value', 14, 13, 100, 12);
+select * from base_tab order by a;
+  a  |        b         |      c       |       d       
+-----+------------------+--------------+---------------
+   1 | {1,2,3,4,5}      | View default | Table default
+ 100 | {10,11,12,13,14} | C value      | Table default
+(2 rows)
+
+drop view base_tab_view;
+drop table base_tab;
diff --git a/src/test/regress/expected/update.out b/src/test/regress/expected/update.out
index 2083345..71b19cc 100644
--- a/src/test/regress/expected/update.out
+++ b/src/test/regress/expected/update.out
@@ -12,7 +12,7 @@ CREATE TABLE upsert_test (
 );
 INSERT INTO update_test VALUES (5, 10, 'foo');
 INSERT INTO update_test(b, a) VALUES (15, 10);
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
  a  | b  |  c  
 ----+----+-----
   5 | 10 | foo
@@ -20,7 +20,7 @@ SELECT * FROM update_test;
 (2 rows)
 
 UPDATE update_test SET a = DEFAULT, b = DEFAULT;
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
  a  | b |  c  
 ----+---+-----
  10 |   | foo
@@ -29,7 +29,7 @@ SELECT * FROM update_test;
 
 -- aliases for the UPDATE target table
 UPDATE update_test AS t SET b = 10 WHERE t.a = 10;
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
  a  | b  |  c  
 ----+----+-----
  10 | 10 | foo
@@ -37,7 +37,7 @@ SELECT * FROM update_test;
 (2 rows)
 
 UPDATE update_test t SET b = t.b + 10 WHERE t.a = 10;
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
  a  | b  |  c  
 ----+----+-----
  10 | 20 | foo
@@ -49,7 +49,7 @@ SELECT * FROM update_test;
 --
 UPDATE update_test SET a=v.i FROM (VALUES(100, 20)) AS v(i, j)
   WHERE update_test.b = v.j;
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
   a  | b  |  c  
 -----+----+-----
  100 | 20 | foo
@@ -67,7 +67,7 @@ HINT:  You will need to rewrite or cast the expression.
 -- Test multiple-set-clause syntax
 --
 INSERT INTO update_test SELECT a,b+1,c FROM update_test;
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
   a  | b  |  c  
 -----+----+-----
  100 | 20 | foo
@@ -77,23 +77,23 @@ SELECT * FROM update_test;
 (4 rows)
 
 UPDATE update_test SET (c,b,a) = ('bugle', b+11, DEFAULT) WHERE c = 'foo';
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
   a  | b  |   c   
 -----+----+-------
- 100 | 20 | 
- 100 | 21 | 
   10 | 31 | bugle
   10 | 32 | bugle
+ 100 | 20 | 
+ 100 | 21 | 
 (4 rows)
 
 UPDATE update_test SET (c,b) = ('car', a+b), a = a + 1 WHERE a = 10;
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
   a  | b  |  c  
 -----+----+-----
- 100 | 20 | 
- 100 | 21 | 
   11 | 41 | car
   11 | 42 | car
+ 100 | 20 | 
+ 100 | 21 | 
 (4 rows)
 
 -- fail, multi assignment to same column:
@@ -103,26 +103,26 @@ ERROR:  multiple assignments to same column "b"
 UPDATE update_test
   SET (b,a) = (select a,b from update_test where b = 41 and c = 'car')
   WHERE a = 100 AND b = 20;
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
   a  | b  |  c  
 -----+----+-----
- 100 | 21 | 
   11 | 41 | car
   11 | 42 | car
   41 | 11 | 
+ 100 | 21 | 
 (4 rows)
 
 -- correlated sub-select:
 UPDATE update_test o
   SET (b,a) = (select a+1,b from update_test i
                where i.a=o.a and i.b=o.b and i.c is not distinct from o.c);
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
  a  |  b  |  c  
 ----+-----+-----
+ 11 |  42 | 
  21 | 101 | 
  41 |  12 | car
  42 |  12 | car
- 11 |  42 | 
 (4 rows)
 
 -- fail, multiple rows supplied:
@@ -131,7 +131,7 @@ ERROR:  more than one row returned by a subquery used as an expression
 -- set to null if no rows supplied:
 UPDATE update_test SET (b,a) = (select a+1,b from update_test where a = 1000)
   WHERE a = 11;
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
  a  |  b  |  c  
 ----+-----+-----
  21 | 101 | 
@@ -158,13 +158,13 @@ LINE 1: UPDATE update_test AS t SET b = update_test.b + 10 WHERE t.a...
 HINT:  Perhaps you meant to reference the table alias "t".
 -- Make sure that we can update to a TOASTed value.
 UPDATE update_test SET c = repeat('x', 10000) WHERE c = 'car';
-SELECT a, b, char_length(c) FROM update_test;
+SELECT a, b, char_length(c) FROM update_test ORDER BY 1, 2, 3;
  a  |  b  | char_length 
 ----+-----+-------------
-    |     |            
  21 | 100 |            
  41 |  12 |       10000
  42 |  12 |       10000
+    |     |            
 (4 rows)
 
 -- Check multi-assignment with a Result node to handle a one-time filter.
@@ -189,13 +189,13 @@ UPDATE update_test t
 UPDATE update_test t
   SET (a, b) = (SELECT b, a FROM update_test s WHERE s.a = t.a)
   WHERE CURRENT_USER = SESSION_USER;
-SELECT a, b, char_length(c) FROM update_test;
+SELECT a, b, char_length(c) FROM update_test ORDER BY a, b;
   a  | b  | char_length 
 -----+----+-------------
-     |    |            
- 100 | 21 |            
   12 | 41 |       10000
   12 | 42 |       10000
+ 100 | 21 |            
+     |    |            
 (4 rows)
 
 -- Test ON CONFLICT DO UPDATE
@@ -329,7 +329,9 @@ UPDATE range_parted set e = d;
 -- No row found
 UPDATE part_c_1_100 set c = c + 20 WHERE c = 98;
 -- ok, row movement
-UPDATE part_b_10_b_20 set c = c + 20 returning c, b, a;
+WITH updated as
+   (UPDATE part_b_10_b_20 set c = c + 20 returning c, b, a)
+   SELECT * FROM updated ORDER BY 1, 2, 3;
   c  | b  | a 
 -----+----+---
  116 | 12 | b
@@ -354,7 +356,9 @@ UPDATE part_b_10_b_20 set b = b - 6 WHERE c > 116 returning *;
 ERROR:  new row for relation "part_d_1_15" violates partition constraint
 DETAIL:  Failing row contains (2, 117, 2, b, 7).
 -- ok, row movement, with subset of rows moved into different partition.
-UPDATE range_parted set b = b - 6 WHERE c > 116 returning a, b + c;
+WITH updated as
+   (UPDATE range_parted set b = b - 6 WHERE c > 116 returning a, b + c)
+   SELECT * FROM updated ORDER BY 1, 2;
  a | ?column? 
 ---+----------
  a |      204
@@ -406,7 +410,9 @@ UPDATE upview set a = 'b', b = 15 WHERE b = 4;
 DROP VIEW upview;
 -- RETURNING having whole-row vars.
 :init_range_parted;
-UPDATE range_parted set c = 95 WHERE a = 'b' and b > 10 and c > 100 returning (range_parted), *;
+WITH updated as
+   (UPDATE range_parted set c = 95 WHERE a = 'b' and b > 10 and c > 100 returning (range_parted), *)
+   SELECT * FROM updated ORDER BY 1, 2, 3, 4;
  range_parted  | a | b  | c  | d  | e 
 ---------------+---+----+----+----+---
  (b,15,95,16,) | b | 15 | 95 | 16 | 
diff --git a/src/test/regress/expected/update_1.out b/src/test/regress/expected/update_1.out
new file mode 100644
index 0000000..48e15bb
--- /dev/null
+++ b/src/test/regress/expected/update_1.out
@@ -0,0 +1,928 @@
+--
+-- UPDATE syntax tests
+--
+CREATE TABLE update_test (
+    a   INT DEFAULT 10,
+    b   INT,
+    c   TEXT
+);
+CREATE TABLE upsert_test (
+    a   INT PRIMARY KEY,
+    b   TEXT
+);
+INSERT INTO update_test VALUES (5, 10, 'foo');
+INSERT INTO update_test(b, a) VALUES (15, 10);
+SELECT * FROM update_test ORDER BY 1, 2, 3;
+ a  | b  |  c  
+----+----+-----
+  5 | 10 | foo
+ 10 | 15 | 
+(2 rows)
+
+UPDATE update_test SET a = DEFAULT, b = DEFAULT;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
+ a  | b |  c  
+----+---+-----
+ 10 |   | foo
+ 10 |   | 
+(2 rows)
+
+-- aliases for the UPDATE target table
+UPDATE update_test AS t SET b = 10 WHERE t.a = 10;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
+ a  | b  |  c  
+----+----+-----
+ 10 | 10 | foo
+ 10 | 10 | 
+(2 rows)
+
+UPDATE update_test t SET b = t.b + 10 WHERE t.a = 10;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
+ a  | b  |  c  
+----+----+-----
+ 10 | 20 | foo
+ 10 | 20 | 
+(2 rows)
+
+--
+-- Test VALUES in FROM
+--
+UPDATE update_test SET a=v.i FROM (VALUES(100, 20)) AS v(i, j)
+  WHERE update_test.b = v.j;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
+  a  | b  |  c  
+-----+----+-----
+ 100 | 20 | foo
+ 100 | 20 | 
+(2 rows)
+
+-- fail, wrong data type:
+UPDATE update_test SET a = v.* FROM (VALUES(100, 20)) AS v(i, j)
+  WHERE update_test.b = v.j;
+ERROR:  column "a" is of type integer but expression is of type record
+LINE 1: UPDATE update_test SET a = v.* FROM (VALUES(100, 20)) AS v(i...
+                                   ^
+HINT:  You will need to rewrite or cast the expression.
+--
+-- Test multiple-set-clause syntax
+--
+INSERT INTO update_test SELECT a,b+1,c FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
+  a  | b  |  c  
+-----+----+-----
+ 100 | 20 | foo
+ 100 | 20 | 
+ 100 | 21 | foo
+ 100 | 21 | 
+(4 rows)
+
+UPDATE update_test SET (c,b,a) = ('bugle', b+11, DEFAULT) WHERE c = 'foo';
+SELECT * FROM update_test ORDER BY 1, 2, 3;
+  a  | b  |   c   
+-----+----+-------
+  10 | 31 | bugle
+  10 | 32 | bugle
+ 100 | 20 | 
+ 100 | 21 | 
+(4 rows)
+
+UPDATE update_test SET (c,b) = ('car', a+b), a = a + 1 WHERE a = 10;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
+  a  | b  |  c  
+-----+----+-----
+  11 | 41 | car
+  11 | 42 | car
+ 100 | 20 | 
+ 100 | 21 | 
+(4 rows)
+
+-- fail, multi assignment to same column:
+UPDATE update_test SET (c,b) = ('car', a+b), b = a + 1 WHERE a = 10;
+ERROR:  multiple assignments to same column "b"
+-- uncorrelated sub-select:
+UPDATE update_test
+  SET (b,a) = (select a,b from update_test where b = 41 and c = 'car')
+  WHERE a = 100 AND b = 20;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
+  a  | b  |  c  
+-----+----+-----
+  11 | 41 | car
+  11 | 42 | car
+  41 | 11 | 
+ 100 | 21 | 
+(4 rows)
+
+-- correlated sub-select:
+UPDATE update_test o
+  SET (b,a) = (select a+1,b from update_test i
+               where i.a=o.a and i.b=o.b and i.c is not distinct from o.c);
+SELECT * FROM update_test ORDER BY 1, 2, 3;
+ a  |  b  |  c  
+----+-----+-----
+ 11 |  42 | 
+ 21 | 101 | 
+ 41 |  12 | car
+ 42 |  12 | car
+(4 rows)
+
+-- fail, multiple rows supplied:
+UPDATE update_test SET (b,a) = (select a+1,b from update_test);
+ERROR:  more than one row returned by a subquery used as an expression
+-- set to null if no rows supplied:
+UPDATE update_test SET (b,a) = (select a+1,b from update_test where a = 1000)
+  WHERE a = 11;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
+ a  |  b  |  c  
+----+-----+-----
+ 21 | 101 | 
+ 41 |  12 | car
+ 42 |  12 | car
+    |     | 
+(4 rows)
+
+-- *-expansion should work in this context:
+UPDATE update_test SET (a,b) = ROW(v.*) FROM (VALUES(21, 100)) AS v(i, j)
+  WHERE update_test.a = v.i;
+-- you might expect this to work, but syntactically it's not a RowExpr:
+UPDATE update_test SET (a,b) = (v.*) FROM (VALUES(21, 101)) AS v(i, j)
+  WHERE update_test.a = v.i;
+ERROR:  source for a multiple-column UPDATE item must be a sub-SELECT or ROW() expression
+LINE 1: UPDATE update_test SET (a,b) = (v.*) FROM (VALUES(21, 101)) ...
+                                        ^
+-- if an alias for the target table is specified, don't allow references
+-- to the original table name
+UPDATE update_test AS t SET b = update_test.b + 10 WHERE t.a = 10;
+ERROR:  invalid reference to FROM-clause entry for table "update_test"
+LINE 1: UPDATE update_test AS t SET b = update_test.b + 10 WHERE t.a...
+                                        ^
+HINT:  Perhaps you meant to reference the table alias "t".
+-- Make sure that we can update to a TOASTed value.
+UPDATE update_test SET c = repeat('x', 10000) WHERE c = 'car';
+SELECT a, b, char_length(c) FROM update_test ORDER BY 1, 2, 3;
+ a  |  b  | char_length 
+----+-----+-------------
+ 21 | 100 |            
+ 41 |  12 |       10000
+ 42 |  12 |       10000
+    |     |            
+(4 rows)
+
+-- Check multi-assignment with a Result node to handle a one-time filter.
+EXPLAIN (VERBOSE, COSTS OFF)
+UPDATE update_test t
+  SET (a, b) = (SELECT b, a FROM update_test s WHERE s.a = t.a)
+  WHERE CURRENT_USER = SESSION_USER;
+                            QUERY PLAN                            
+------------------------------------------------------------------
+ Update on public.update_test t
+   ->  Result
+         Output: $1, $2, t.c, (SubPlan 1 (returns $1,$2)), t.ctid
+         One-Time Filter: (CURRENT_USER = SESSION_USER)
+         ->  Seq Scan on public.update_test t
+               Output: t.c, t.a, t.ctid
+         SubPlan 1 (returns $1,$2)
+           ->  Seq Scan on public.update_test s
+                 Output: s.b, s.a
+                 Filter: (s.a = t.a)
+(10 rows)
+
+UPDATE update_test t
+  SET (a, b) = (SELECT b, a FROM update_test s WHERE s.a = t.a)
+  WHERE CURRENT_USER = SESSION_USER;
+SELECT a, b, char_length(c) FROM update_test ORDER BY a, b;
+  a  | b  | char_length 
+-----+----+-------------
+  12 | 41 |       10000
+  12 | 42 |       10000
+ 100 | 21 |            
+     |    |            
+(4 rows)
+
+-- Test ON CONFLICT DO UPDATE
+INSERT INTO upsert_test VALUES(1, 'Boo');
+-- uncorrelated  sub-select:
+WITH aaa AS (SELECT 1 AS a, 'Foo' AS b) INSERT INTO upsert_test
+  VALUES (1, 'Bar') ON CONFLICT(a)
+  DO UPDATE SET (b, a) = (SELECT b, a FROM aaa) RETURNING *;
+ a |  b  
+---+-----
+ 1 | Foo
+(1 row)
+
+-- correlated sub-select:
+INSERT INTO upsert_test VALUES (1, 'Baz') ON CONFLICT(a)
+  DO UPDATE SET (b, a) = (SELECT b || ', Correlated', a from upsert_test i WHERE i.a = upsert_test.a)
+  RETURNING *;
+ a |        b        
+---+-----------------
+ 1 | Foo, Correlated
+(1 row)
+
+-- correlated sub-select (EXCLUDED.* alias):
+INSERT INTO upsert_test VALUES (1, 'Bat') ON CONFLICT(a)
+  DO UPDATE SET (b, a) = (SELECT b || ', Excluded', a from upsert_test i WHERE i.a = excluded.a)
+  RETURNING *;
+ a |             b             
+---+---------------------------
+ 1 | Foo, Correlated, Excluded
+(1 row)
+
+DROP TABLE update_test;
+DROP TABLE upsert_test;
+---------------------------
+-- UPDATE with row movement
+---------------------------
+-- When a partitioned table receives an UPDATE to the partitioned key and the
+-- new values no longer meet the partition's bound, the row must be moved to
+-- the correct partition for the new partition key (if one exists). We must
+-- also ensure that updatable views on partitioned tables properly enforce any
+-- WITH CHECK OPTION that is defined. The situation with triggers in this case
+-- also requires thorough testing as partition key updates causing row
+-- movement convert UPDATEs into DELETE+INSERT.
+CREATE TABLE range_parted (
+	a text,
+	b bigint,
+	c numeric,
+	d int,
+	e varchar
+) PARTITION BY RANGE (a, b);
+-- Create partitions intentionally in descending bound order, so as to test
+-- that update-row-movement works with the leaf partitions not in bound order.
+CREATE TABLE part_b_20_b_30 (e varchar, c numeric, a text, b bigint, d int);
+ALTER TABLE range_parted ATTACH PARTITION part_b_20_b_30 FOR VALUES FROM ('b', 20) TO ('b', 30);
+CREATE TABLE part_b_10_b_20 (e varchar, c numeric, a text, b bigint, d int) PARTITION BY RANGE (c);
+CREATE TABLE part_b_1_b_10 PARTITION OF range_parted FOR VALUES FROM ('b', 1) TO ('b', 10);
+ALTER TABLE range_parted ATTACH PARTITION part_b_10_b_20 FOR VALUES FROM ('b', 10) TO ('b', 20);
+CREATE TABLE part_a_10_a_20 PARTITION OF range_parted FOR VALUES FROM ('a', 10) TO ('a', 20);
+CREATE TABLE part_a_1_a_10 PARTITION OF range_parted FOR VALUES FROM ('a', 1) TO ('a', 10);
+-- Check that partition-key UPDATE works sanely on a partitioned table that
+-- does not have any child partitions.
+UPDATE part_b_10_b_20 set b = b - 6;
+-- Create some more partitions following the above pattern of descending bound
+-- order, but let's make the situation a bit more complex by having the
+-- attribute numbers of the columns vary from their parent partition.
+CREATE TABLE part_c_100_200 (e varchar, c numeric, a text, b bigint, d int) PARTITION BY range (abs(d));
+ALTER TABLE part_c_100_200 DROP COLUMN e, DROP COLUMN c, DROP COLUMN a;
+ALTER TABLE part_c_100_200 ADD COLUMN c numeric, ADD COLUMN e varchar, ADD COLUMN a text;
+ALTER TABLE part_c_100_200 DROP COLUMN b;
+ALTER TABLE part_c_100_200 ADD COLUMN b bigint;
+CREATE TABLE part_d_1_15 PARTITION OF part_c_100_200 FOR VALUES FROM (1) TO (15);
+CREATE TABLE part_d_15_20 PARTITION OF part_c_100_200 FOR VALUES FROM (15) TO (20);
+ALTER TABLE part_b_10_b_20 ATTACH PARTITION part_c_100_200 FOR VALUES FROM (100) TO (200);
+CREATE TABLE part_c_1_100 (e varchar, d int, c numeric, b bigint, a text);
+ALTER TABLE part_b_10_b_20 ATTACH PARTITION part_c_1_100 FOR VALUES FROM (1) TO (100);
+\set init_range_parted 'truncate range_parted; insert into range_parted VALUES (''a'', 1, 1, 1), (''a'', 10, 200, 1), (''b'', 12, 96, 1), (''b'', 13, 97, 2), (''b'', 15, 105, 16), (''b'', 17, 105, 19)'
+\set show_data 'select tableoid::regclass::text COLLATE "C" partname, * from range_parted ORDER BY 1, 2, 3, 4, 5, 6'
+:init_range_parted;
+:show_data;
+    partname    | a | b  |  c  | d  | e 
+----------------+---+----+-----+----+---
+ part_a_10_a_20 | a | 10 | 200 |  1 | 
+ part_a_1_a_10  | a |  1 |   1 |  1 | 
+ part_c_1_100   | b | 12 |  96 |  1 | 
+ part_c_1_100   | b | 13 |  97 |  2 | 
+ part_d_15_20   | b | 15 | 105 | 16 | 
+ part_d_15_20   | b | 17 | 105 | 19 | 
+(6 rows)
+
+-- The order of subplans should be in bound order
+EXPLAIN (costs off) UPDATE range_parted set c = c - 50 WHERE c > 97;
+             QUERY PLAN              
+-------------------------------------
+ Update on range_parted
+   Update on part_a_1_a_10
+   Update on part_a_10_a_20
+   Update on part_b_1_b_10
+   Update on part_c_1_100
+   Update on part_d_1_15
+   Update on part_d_15_20
+   Update on part_b_20_b_30
+   ->  Seq Scan on part_a_1_a_10
+         Filter: (c > '97'::numeric)
+   ->  Seq Scan on part_a_10_a_20
+         Filter: (c > '97'::numeric)
+   ->  Seq Scan on part_b_1_b_10
+         Filter: (c > '97'::numeric)
+   ->  Seq Scan on part_c_1_100
+         Filter: (c > '97'::numeric)
+   ->  Seq Scan on part_d_1_15
+         Filter: (c > '97'::numeric)
+   ->  Seq Scan on part_d_15_20
+         Filter: (c > '97'::numeric)
+   ->  Seq Scan on part_b_20_b_30
+         Filter: (c > '97'::numeric)
+(22 rows)
+
+-- fail, row movement happens only within the partition subtree.
+UPDATE part_c_100_200 set c = c - 20, d = c WHERE c = 105;
+ERROR:  new row for relation "part_c_100_200" violates partition constraint
+DETAIL:  Failing row contains (105, 85, null, b, 15).
+-- fail, no partition key update, so no attempt to move tuple,
+-- but "a = 'a'" violates partition constraint enforced by root partition)
+UPDATE part_b_10_b_20 set a = 'a';
+ERROR:  new row for relation "part_c_1_100" violates partition constraint
+DETAIL:  Failing row contains (null, 1, 96, 12, a).
+-- ok, partition key update, no constraint violation
+UPDATE range_parted set d = d - 10 WHERE d > 10;
+-- ok, no partition key update, no constraint violation
+UPDATE range_parted set e = d;
+-- No row found
+UPDATE part_c_1_100 set c = c + 20 WHERE c = 98;
+-- ok, row movement
+WITH updated as
+   (UPDATE part_b_10_b_20 set c = c + 20 returning c, b, a)
+   SELECT * FROM updated ORDER BY 1, 2, 3;
+  c  | b  | a 
+-----+----+---
+ 116 | 12 | b
+ 117 | 13 | b
+ 125 | 15 | b
+ 125 | 17 | b
+(4 rows)
+
+:show_data;
+    partname    | a | b  |  c  | d | e 
+----------------+---+----+-----+---+---
+ part_a_10_a_20 | a | 10 | 200 | 1 | 1
+ part_a_1_a_10  | a |  1 |   1 | 1 | 1
+ part_d_1_15    | b | 12 | 116 | 1 | 1
+ part_d_1_15    | b | 13 | 117 | 2 | 2
+ part_d_1_15    | b | 15 | 125 | 6 | 6
+ part_d_1_15    | b | 17 | 125 | 9 | 9
+(6 rows)
+
+-- fail, row movement happens only within the partition subtree.
+UPDATE part_b_10_b_20 set b = b - 6 WHERE c > 116 returning *;
+ERROR:  new row for relation "part_d_1_15" violates partition constraint
+DETAIL:  Failing row contains (6, 125, 6, b, 9).
+-- ok, row movement, with subset of rows moved into different partition.
+WITH updated as
+   (UPDATE range_parted set b = b - 6 WHERE c > 116 returning a, b + c)
+   SELECT * FROM updated ORDER BY 1, 2;
+ a | ?column? 
+---+----------
+ a |      204
+ b |      124
+ b |      134
+ b |      136
+(4 rows)
+
+:show_data;
+   partname    | a | b  |  c  | d | e 
+---------------+---+----+-----+---+---
+ part_a_1_a_10 | a |  1 |   1 | 1 | 1
+ part_a_1_a_10 | a |  4 | 200 | 1 | 1
+ part_b_1_b_10 | b |  7 | 117 | 2 | 2
+ part_b_1_b_10 | b |  9 | 125 | 6 | 6
+ part_d_1_15   | b | 11 | 125 | 9 | 9
+ part_d_1_15   | b | 12 | 116 | 1 | 1
+(6 rows)
+
+-- Common table needed for multiple test scenarios.
+CREATE TABLE mintab(c1 int);
+INSERT into mintab VALUES (120);
+-- update partition key using updatable view.
+CREATE VIEW upview AS SELECT * FROM range_parted WHERE (select c > c1 FROM mintab) WITH CHECK OPTION;
+-- ok
+UPDATE upview set c = 199 WHERE b = 4;
+-- fail, check option violation
+UPDATE upview set c = 120 WHERE b = 4;
+ERROR:  new row violates check option for view "upview"
+DETAIL:  Failing row contains (a, 4, 120, 1, 1).
+-- fail, row movement with check option violation
+UPDATE upview set a = 'b', b = 15, c = 120 WHERE b = 4;
+ERROR:  new row violates check option for view "upview"
+DETAIL:  Failing row contains (b, 15, 120, 1, 1).
+-- ok, row movement, check option passes
+UPDATE upview set a = 'b', b = 15 WHERE b = 4;
+:show_data;
+   partname    | a | b  |  c  | d | e 
+---------------+---+----+-----+---+---
+ part_a_1_a_10 | a |  1 |   1 | 1 | 1
+ part_b_1_b_10 | b |  7 | 117 | 2 | 2
+ part_b_1_b_10 | b |  9 | 125 | 6 | 6
+ part_d_1_15   | b | 11 | 125 | 9 | 9
+ part_d_1_15   | b | 12 | 116 | 1 | 1
+ part_d_1_15   | b | 15 | 199 | 1 | 1
+(6 rows)
+
+-- cleanup
+DROP VIEW upview;
+-- RETURNING having whole-row vars.
+:init_range_parted;
+WITH updated as
+   (UPDATE range_parted set c = 95 WHERE a = 'b' and b > 10 and c > 100 returning (range_parted), *)
+   SELECT * FROM updated ORDER BY 1, 2, 3, 4;
+ range_parted  | a | b  | c  | d  | e 
+---------------+---+----+----+----+---
+ (b,15,95,16,) | b | 15 | 95 | 16 | 
+ (b,17,95,19,) | b | 17 | 95 | 19 | 
+(2 rows)
+
+:show_data;
+    partname    | a | b  |  c  | d  | e 
+----------------+---+----+-----+----+---
+ part_a_10_a_20 | a | 10 | 200 |  1 | 
+ part_a_1_a_10  | a |  1 |   1 |  1 | 
+ part_c_1_100   | b | 12 |  96 |  1 | 
+ part_c_1_100   | b | 13 |  97 |  2 | 
+ part_c_1_100   | b | 15 |  95 | 16 | 
+ part_c_1_100   | b | 17 |  95 | 19 | 
+(6 rows)
+
+-- Transition tables with update row movement
+:init_range_parted;
+CREATE FUNCTION trans_updatetrigfunc() RETURNS trigger LANGUAGE plpgsql AS
+$$
+  begin
+    raise notice 'trigger = %, old table = %, new table = %',
+                 TG_NAME,
+                 (select string_agg(old_table::text, ', ' ORDER BY a) FROM old_table),
+                 (select string_agg(new_table::text, ', ' ORDER BY a) FROM new_table);
+    return null;
+  end;
+$$;
+CREATE TRIGGER trans_updatetrig
+  AFTER UPDATE ON range_parted REFERENCING OLD TABLE AS old_table NEW TABLE AS new_table
+  FOR EACH STATEMENT EXECUTE PROCEDURE trans_updatetrigfunc();
+UPDATE range_parted set c = (case when c = 96 then 110 else c + 1 end ) WHERE a = 'b' and b > 10 and c >= 96;
+NOTICE:  trigger = trans_updatetrig, old table = (b,12,96,1,), (b,13,97,2,), (b,15,105,16,), (b,17,105,19,), new table = (b,12,110,1,), (b,13,98,2,), (b,15,106,16,), (b,17,106,19,)
+:show_data;
+    partname    | a | b  |  c  | d  | e 
+----------------+---+----+-----+----+---
+ part_a_10_a_20 | a | 10 | 200 |  1 | 
+ part_a_1_a_10  | a |  1 |   1 |  1 | 
+ part_c_1_100   | b | 13 |  98 |  2 | 
+ part_d_15_20   | b | 15 | 106 | 16 | 
+ part_d_15_20   | b | 17 | 106 | 19 | 
+ part_d_1_15    | b | 12 | 110 |  1 | 
+(6 rows)
+
+:init_range_parted;
+-- Enabling OLD TABLE capture for both DELETE as well as UPDATE stmt triggers
+-- should not cause DELETEd rows to be captured twice. Similar thing for
+-- INSERT triggers and inserted rows.
+CREATE TRIGGER trans_deletetrig
+  AFTER DELETE ON range_parted REFERENCING OLD TABLE AS old_table
+  FOR EACH STATEMENT EXECUTE PROCEDURE trans_updatetrigfunc();
+CREATE TRIGGER trans_inserttrig
+  AFTER INSERT ON range_parted REFERENCING NEW TABLE AS new_table
+  FOR EACH STATEMENT EXECUTE PROCEDURE trans_updatetrigfunc();
+UPDATE range_parted set c = c + 50 WHERE a = 'b' and b > 10 and c >= 96;
+NOTICE:  trigger = trans_updatetrig, old table = (b,12,96,1,), (b,13,97,2,), (b,15,105,16,), (b,17,105,19,), new table = (b,12,146,1,), (b,13,147,2,), (b,15,155,16,), (b,17,155,19,)
+:show_data;
+    partname    | a | b  |  c  | d  | e 
+----------------+---+----+-----+----+---
+ part_a_10_a_20 | a | 10 | 200 |  1 | 
+ part_a_1_a_10  | a |  1 |   1 |  1 | 
+ part_d_15_20   | b | 15 | 155 | 16 | 
+ part_d_15_20   | b | 17 | 155 | 19 | 
+ part_d_1_15    | b | 12 | 146 |  1 | 
+ part_d_1_15    | b | 13 | 147 |  2 | 
+(6 rows)
+
+DROP TRIGGER trans_deletetrig ON range_parted;
+DROP TRIGGER trans_inserttrig ON range_parted;
+-- Don't drop trans_updatetrig yet. It is required below.
+-- Test with transition tuple conversion happening for rows moved into the
+-- new partition. This requires a trigger that references transition table
+-- (we already have trans_updatetrig). For inserted rows, the conversion
+-- is not usually needed, because the original tuple is already compatible with
+-- the desired transition tuple format. But conversion happens when there is a
+-- BR trigger because the trigger can change the inserted row. So install a
+-- BR triggers on those child partitions where the rows will be moved.
+CREATE FUNCTION func_parted_mod_b() RETURNS trigger AS $$
+BEGIN
+   NEW.b = NEW.b + 1;
+   return NEW;
+END $$ language plpgsql;
+CREATE TRIGGER trig_c1_100 BEFORE UPDATE OR INSERT ON part_c_1_100
+   FOR EACH ROW EXECUTE PROCEDURE func_parted_mod_b();
+CREATE TRIGGER trig_d1_15 BEFORE UPDATE OR INSERT ON part_d_1_15
+   FOR EACH ROW EXECUTE PROCEDURE func_parted_mod_b();
+CREATE TRIGGER trig_d15_20 BEFORE UPDATE OR INSERT ON part_d_15_20
+   FOR EACH ROW EXECUTE PROCEDURE func_parted_mod_b();
+:init_range_parted;
+UPDATE range_parted set c = (case when c = 96 then 110 else c + 1 end) WHERE a = 'b' and b > 10 and c >= 96;
+NOTICE:  trigger = trans_updatetrig, old table = (b,13,96,1,), (b,14,97,2,), (b,16,105,16,), (b,18,105,19,), new table = (b,15,110,1,), (b,15,98,2,), (b,17,106,16,), (b,19,106,19,)
+:show_data;
+    partname    | a | b  |  c  | d  | e 
+----------------+---+----+-----+----+---
+ part_a_10_a_20 | a | 10 | 200 |  1 | 
+ part_a_1_a_10  | a |  1 |   1 |  1 | 
+ part_c_1_100   | b | 15 |  98 |  2 | 
+ part_d_15_20   | b | 17 | 106 | 16 | 
+ part_d_15_20   | b | 19 | 106 | 19 | 
+ part_d_1_15    | b | 15 | 110 |  1 | 
+(6 rows)
+
+:init_range_parted;
+UPDATE range_parted set c = c + 50 WHERE a = 'b' and b > 10 and c >= 96;
+NOTICE:  trigger = trans_updatetrig, old table = (b,13,96,1,), (b,14,97,2,), (b,16,105,16,), (b,18,105,19,), new table = (b,15,146,1,), (b,16,147,2,), (b,17,155,16,), (b,19,155,19,)
+:show_data;
+    partname    | a | b  |  c  | d  | e 
+----------------+---+----+-----+----+---
+ part_a_10_a_20 | a | 10 | 200 |  1 | 
+ part_a_1_a_10  | a |  1 |   1 |  1 | 
+ part_d_15_20   | b | 17 | 155 | 16 | 
+ part_d_15_20   | b | 19 | 155 | 19 | 
+ part_d_1_15    | b | 15 | 146 |  1 | 
+ part_d_1_15    | b | 16 | 147 |  2 | 
+(6 rows)
+
+-- Case where per-partition tuple conversion map array is allocated, but the
+-- map is not required for the particular tuple that is routed, thanks to
+-- matching table attributes of the partition and the target table.
+:init_range_parted;
+UPDATE range_parted set b = 15 WHERE b = 1;
+NOTICE:  trigger = trans_updatetrig, old table = (a,1,1,1,), new table = (a,15,1,1,)
+:show_data;
+    partname    | a | b  |  c  | d  | e 
+----------------+---+----+-----+----+---
+ part_a_10_a_20 | a | 10 | 200 |  1 | 
+ part_a_10_a_20 | a | 15 |   1 |  1 | 
+ part_c_1_100   | b | 13 |  96 |  1 | 
+ part_c_1_100   | b | 14 |  97 |  2 | 
+ part_d_15_20   | b | 16 | 105 | 16 | 
+ part_d_15_20   | b | 18 | 105 | 19 | 
+(6 rows)
+
+DROP TRIGGER trans_updatetrig ON range_parted;
+DROP TRIGGER trig_c1_100 ON part_c_1_100;
+DROP TRIGGER trig_d1_15 ON part_d_1_15;
+DROP TRIGGER trig_d15_20 ON part_d_15_20;
+DROP FUNCTION func_parted_mod_b();
+-- RLS policies with update-row-movement
+-----------------------------------------
+ALTER TABLE range_parted ENABLE ROW LEVEL SECURITY;
+CREATE USER regress_range_parted_user;
+GRANT ALL ON range_parted, mintab TO regress_range_parted_user;
+CREATE POLICY seeall ON range_parted AS PERMISSIVE FOR SELECT USING (true);
+CREATE POLICY policy_range_parted ON range_parted for UPDATE USING (true) WITH CHECK (c % 2 = 0);
+:init_range_parted;
+SET SESSION AUTHORIZATION regress_range_parted_user;
+-- This should fail with RLS violation error while moving row from
+-- part_a_10_a_20 to part_d_1_15, because we are setting 'c' to an odd number.
+UPDATE range_parted set a = 'b', c = 151 WHERE a = 'a' and c = 200;
+ERROR:  new row violates row-level security policy for table "range_parted"
+RESET SESSION AUTHORIZATION;
+-- Create a trigger on part_d_1_15
+CREATE FUNCTION func_d_1_15() RETURNS trigger AS $$
+BEGIN
+   NEW.c = NEW.c + 1; -- Make even numbers odd, or vice versa
+   return NEW;
+END $$ LANGUAGE plpgsql;
+CREATE TRIGGER trig_d_1_15 BEFORE INSERT ON part_d_1_15
+   FOR EACH ROW EXECUTE PROCEDURE func_d_1_15();
+:init_range_parted;
+SET SESSION AUTHORIZATION regress_range_parted_user;
+-- Here, RLS checks should succeed while moving row from part_a_10_a_20 to
+-- part_d_1_15. Even though the UPDATE is setting 'c' to an odd number, the
+-- trigger at the destination partition again makes it an even number.
+UPDATE range_parted set a = 'b', c = 151 WHERE a = 'a' and c = 200;
+RESET SESSION AUTHORIZATION;
+:init_range_parted;
+SET SESSION AUTHORIZATION regress_range_parted_user;
+-- This should fail with RLS violation error. Even though the UPDATE is setting
+-- 'c' to an even number, the trigger at the destination partition again makes
+-- it an odd number.
+UPDATE range_parted set a = 'b', c = 150 WHERE a = 'a' and c = 200;
+ERROR:  new row violates row-level security policy for table "range_parted"
+-- Cleanup
+RESET SESSION AUTHORIZATION;
+DROP TRIGGER trig_d_1_15 ON part_d_1_15;
+DROP FUNCTION func_d_1_15();
+-- Policy expression contains SubPlan
+RESET SESSION AUTHORIZATION;
+:init_range_parted;
+CREATE POLICY policy_range_parted_subplan on range_parted
+    AS RESTRICTIVE for UPDATE USING (true)
+    WITH CHECK ((SELECT range_parted.c <= c1 FROM mintab));
+SET SESSION AUTHORIZATION regress_range_parted_user;
+-- fail, mintab has row with c1 = 120
+UPDATE range_parted set a = 'b', c = 122 WHERE a = 'a' and c = 200;
+ERROR:  new row violates row-level security policy "policy_range_parted_subplan" for table "range_parted"
+-- ok
+UPDATE range_parted set a = 'b', c = 120 WHERE a = 'a' and c = 200;
+-- RLS policy expression contains whole row.
+RESET SESSION AUTHORIZATION;
+:init_range_parted;
+CREATE POLICY policy_range_parted_wholerow on range_parted AS RESTRICTIVE for UPDATE USING (true)
+   WITH CHECK (range_parted = row('b', 10, 112, 1, NULL)::range_parted);
+SET SESSION AUTHORIZATION regress_range_parted_user;
+-- ok, should pass the RLS check
+UPDATE range_parted set a = 'b', c = 112 WHERE a = 'a' and c = 200;
+RESET SESSION AUTHORIZATION;
+:init_range_parted;
+SET SESSION AUTHORIZATION regress_range_parted_user;
+-- fail, the whole row RLS check should fail
+UPDATE range_parted set a = 'b', c = 116 WHERE a = 'a' and c = 200;
+ERROR:  new row violates row-level security policy "policy_range_parted_wholerow" for table "range_parted"
+-- Cleanup
+RESET SESSION AUTHORIZATION;
+DROP POLICY policy_range_parted ON range_parted;
+DROP POLICY policy_range_parted_subplan ON range_parted;
+DROP POLICY policy_range_parted_wholerow ON range_parted;
+REVOKE ALL ON range_parted, mintab FROM regress_range_parted_user;
+DROP USER regress_range_parted_user;
+DROP TABLE mintab;
+-- statement triggers with update row movement
+---------------------------------------------------
+:init_range_parted;
+CREATE FUNCTION trigfunc() returns trigger language plpgsql as
+$$
+  begin
+    raise notice 'trigger = % fired on table % during %',
+                 TG_NAME, TG_TABLE_NAME, TG_OP;
+    return null;
+  end;
+$$;
+-- Triggers on root partition
+CREATE TRIGGER parent_delete_trig
+  AFTER DELETE ON range_parted for each statement execute procedure trigfunc();
+CREATE TRIGGER parent_update_trig
+  AFTER UPDATE ON range_parted for each statement execute procedure trigfunc();
+CREATE TRIGGER parent_insert_trig
+  AFTER INSERT ON range_parted for each statement execute procedure trigfunc();
+-- Triggers on leaf partition part_c_1_100
+CREATE TRIGGER c1_delete_trig
+  AFTER DELETE ON part_c_1_100 for each statement execute procedure trigfunc();
+CREATE TRIGGER c1_update_trig
+  AFTER UPDATE ON part_c_1_100 for each statement execute procedure trigfunc();
+CREATE TRIGGER c1_insert_trig
+  AFTER INSERT ON part_c_1_100 for each statement execute procedure trigfunc();
+-- Triggers on leaf partition part_d_1_15
+CREATE TRIGGER d1_delete_trig
+  AFTER DELETE ON part_d_1_15 for each statement execute procedure trigfunc();
+CREATE TRIGGER d1_update_trig
+  AFTER UPDATE ON part_d_1_15 for each statement execute procedure trigfunc();
+CREATE TRIGGER d1_insert_trig
+  AFTER INSERT ON part_d_1_15 for each statement execute procedure trigfunc();
+-- Triggers on leaf partition part_d_15_20
+CREATE TRIGGER d15_delete_trig
+  AFTER DELETE ON part_d_15_20 for each statement execute procedure trigfunc();
+CREATE TRIGGER d15_update_trig
+  AFTER UPDATE ON part_d_15_20 for each statement execute procedure trigfunc();
+CREATE TRIGGER d15_insert_trig
+  AFTER INSERT ON part_d_15_20 for each statement execute procedure trigfunc();
+-- Move all rows from part_c_100_200 to part_c_1_100. None of the delete or
+-- insert statement triggers should be fired.
+UPDATE range_parted set c = c - 50 WHERE c > 97;
+NOTICE:  trigger = parent_update_trig fired on table range_parted during UPDATE
+:show_data;
+    partname    | a | b  |  c  | d  | e 
+----------------+---+----+-----+----+---
+ part_a_10_a_20 | a | 10 | 150 |  1 | 
+ part_a_1_a_10  | a |  1 |   1 |  1 | 
+ part_c_1_100   | b | 12 |  96 |  1 | 
+ part_c_1_100   | b | 13 |  97 |  2 | 
+ part_c_1_100   | b | 15 |  55 | 16 | 
+ part_c_1_100   | b | 17 |  55 | 19 | 
+(6 rows)
+
+DROP TRIGGER parent_delete_trig ON range_parted;
+DROP TRIGGER parent_update_trig ON range_parted;
+DROP TRIGGER parent_insert_trig ON range_parted;
+DROP TRIGGER c1_delete_trig ON part_c_1_100;
+DROP TRIGGER c1_update_trig ON part_c_1_100;
+DROP TRIGGER c1_insert_trig ON part_c_1_100;
+DROP TRIGGER d1_delete_trig ON part_d_1_15;
+DROP TRIGGER d1_update_trig ON part_d_1_15;
+DROP TRIGGER d1_insert_trig ON part_d_1_15;
+DROP TRIGGER d15_delete_trig ON part_d_15_20;
+DROP TRIGGER d15_update_trig ON part_d_15_20;
+DROP TRIGGER d15_insert_trig ON part_d_15_20;
+-- Creating default partition for range
+:init_range_parted;
+create table part_def partition of range_parted default;
+\d+ part_def
+                                       Table "public.part_def"
+ Column |       Type        | Collation | Nullable | Default | Storage  | Stats target | Description 
+--------+-------------------+-----------+----------+---------+----------+--------------+-------------
+ a      | text              |           |          |         | extended |              | 
+ b      | bigint            |           |          |         | plain    |              | 
+ c      | numeric           |           |          |         | main     |              | 
+ d      | integer           |           |          |         | plain    |              | 
+ e      | character varying |           |          |         | extended |              | 
+Partition of: range_parted DEFAULT
+Partition constraint: (NOT ((a IS NOT NULL) AND (b IS NOT NULL) AND (((a = 'a'::text) AND (b >= '1'::bigint) AND (b < '10'::bigint)) OR ((a = 'a'::text) AND (b >= '10'::bigint) AND (b < '20'::bigint)) OR ((a = 'b'::text) AND (b >= '1'::bigint) AND (b < '10'::bigint)) OR ((a = 'b'::text) AND (b >= '10'::bigint) AND (b < '20'::bigint)) OR ((a = 'b'::text) AND (b >= '20'::bigint) AND (b < '30'::bigint)))))
+
+insert into range_parted values ('c', 9);
+-- ok
+update part_def set a = 'd' where a = 'c';
+-- fail
+update part_def set a = 'a' where a = 'd';
+ERROR:  new row for relation "part_def" violates partition constraint
+DETAIL:  Failing row contains (a, 9, null, null, null).
+:show_data;
+    partname    | a | b  |  c  | d  | e 
+----------------+---+----+-----+----+---
+ part_a_10_a_20 | a | 10 | 200 |  1 | 
+ part_a_1_a_10  | a |  1 |   1 |  1 | 
+ part_c_1_100   | b | 12 |  96 |  1 | 
+ part_c_1_100   | b | 13 |  97 |  2 | 
+ part_d_15_20   | b | 15 | 105 | 16 | 
+ part_d_15_20   | b | 17 | 105 | 19 | 
+ part_def       | d |  9 |     |    | 
+(7 rows)
+
+-- Update row movement from non-default to default partition.
+-- fail, default partition is not under part_a_10_a_20;
+UPDATE part_a_10_a_20 set a = 'ad' WHERE a = 'a';
+ERROR:  new row for relation "part_a_10_a_20" violates partition constraint
+DETAIL:  Failing row contains (ad, 10, 200, 1, null).
+-- ok
+UPDATE range_parted set a = 'ad' WHERE a = 'a';
+UPDATE range_parted set a = 'bd' WHERE a = 'b';
+:show_data;
+ partname | a  | b  |  c  | d  | e 
+----------+----+----+-----+----+---
+ part_def | ad |  1 |   1 |  1 | 
+ part_def | ad | 10 | 200 |  1 | 
+ part_def | bd | 12 |  96 |  1 | 
+ part_def | bd | 13 |  97 |  2 | 
+ part_def | bd | 15 | 105 | 16 | 
+ part_def | bd | 17 | 105 | 19 | 
+ part_def | d  |  9 |     |    | 
+(7 rows)
+
+-- Update row movement from default to non-default partitions.
+-- ok
+UPDATE range_parted set a = 'a' WHERE a = 'ad';
+UPDATE range_parted set a = 'b' WHERE a = 'bd';
+:show_data;
+    partname    | a | b  |  c  | d  | e 
+----------------+---+----+-----+----+---
+ part_a_10_a_20 | a | 10 | 200 |  1 | 
+ part_a_1_a_10  | a |  1 |   1 |  1 | 
+ part_c_1_100   | b | 12 |  96 |  1 | 
+ part_c_1_100   | b | 13 |  97 |  2 | 
+ part_d_15_20   | b | 15 | 105 | 16 | 
+ part_d_15_20   | b | 17 | 105 | 19 | 
+ part_def       | d |  9 |     |    | 
+(7 rows)
+
+-- Cleanup: range_parted no longer needed.
+DROP TABLE range_parted;
+CREATE TABLE list_parted (
+	a text,
+	b int
+) PARTITION BY list (a);
+CREATE TABLE list_part1  PARTITION OF list_parted for VALUES in ('a', 'b');
+CREATE TABLE list_default PARTITION OF list_parted default;
+INSERT into list_part1 VALUES ('a', 1);
+INSERT into list_default VALUES ('d', 10);
+-- fail
+UPDATE list_default set a = 'a' WHERE a = 'd';
+ERROR:  new row for relation "list_default" violates partition constraint
+DETAIL:  Failing row contains (a, 10).
+-- ok
+UPDATE list_default set a = 'x' WHERE a = 'd';
+DROP TABLE list_parted;
+--------------
+-- Some more update-partition-key test scenarios below. This time use list
+-- partitions.
+--------------
+-- Setup for list partitions
+CREATE TABLE list_parted (a numeric, b int, c int8) PARTITION BY list (a);
+CREATE TABLE sub_parted PARTITION OF list_parted for VALUES in (1) PARTITION BY list (b);
+CREATE TABLE sub_part1(b int, c int8, a numeric);
+ALTER TABLE sub_parted ATTACH PARTITION sub_part1 for VALUES in (1);
+CREATE TABLE sub_part2(b int, c int8, a numeric);
+ALTER TABLE sub_parted ATTACH PARTITION sub_part2 for VALUES in (2);
+CREATE TABLE list_part1(a numeric, b int, c int8);
+ALTER TABLE list_parted ATTACH PARTITION list_part1 for VALUES in (2,3);
+INSERT into list_parted VALUES (2,5,50);
+INSERT into list_parted VALUES (3,6,60);
+INSERT into sub_parted VALUES (1,1,60);
+INSERT into sub_parted VALUES (1,2,10);
+-- Test partition constraint violation when intermediate ancestor is used and
+-- constraint is inherited from upper root.
+UPDATE sub_parted set a = 2 WHERE c = 10;
+ERROR:  new row for relation "sub_part2" violates partition constraint
+DETAIL:  Failing row contains (2, 10, 2).
+-- Test update-partition-key, where the unpruned partitions do not have their
+-- partition keys updated.
+SELECT tableoid::regclass::text, * FROM list_parted WHERE a = 2 ORDER BY 1;
+  tableoid  | a | b | c  
+------------+---+---+----
+ list_part1 | 2 | 5 | 50
+(1 row)
+
+UPDATE list_parted set b = c + a WHERE a = 2;
+SELECT tableoid::regclass::text, * FROM list_parted WHERE a = 2 ORDER BY 1;
+  tableoid  | a | b  | c  
+------------+---+----+----
+ list_part1 | 2 | 52 | 50
+(1 row)
+
+-- Test the case where BR UPDATE triggers change the partition key.
+CREATE FUNCTION func_parted_mod_b() returns trigger as $$
+BEGIN
+   NEW.b = 2; -- This is changing partition key column.
+   return NEW;
+END $$ LANGUAGE plpgsql;
+CREATE TRIGGER parted_mod_b before update on sub_part1
+   for each row execute procedure func_parted_mod_b();
+SELECT tableoid::regclass::text, * FROM list_parted ORDER BY 1, 2, 3, 4;
+  tableoid  | a | b  | c  
+------------+---+----+----
+ list_part1 | 2 | 52 | 50
+ list_part1 | 3 |  6 | 60
+ sub_part1  | 1 |  1 | 60
+ sub_part2  | 1 |  2 | 10
+(4 rows)
+
+-- This should do the tuple routing even though there is no explicit
+-- partition-key update, because there is a trigger on sub_part1.
+UPDATE list_parted set c = 70 WHERE b  = 1;
+SELECT tableoid::regclass::text, * FROM list_parted ORDER BY 1, 2, 3, 4;
+  tableoid  | a | b  | c  
+------------+---+----+----
+ list_part1 | 2 | 52 | 50
+ list_part1 | 3 |  6 | 60
+ sub_part2  | 1 |  2 | 10
+ sub_part2  | 1 |  2 | 70
+(4 rows)
+
+DROP TRIGGER parted_mod_b ON sub_part1;
+-- If BR DELETE trigger prevented DELETE from happening, we should also skip
+-- the INSERT if that delete is part of UPDATE=>DELETE+INSERT.
+CREATE OR REPLACE FUNCTION func_parted_mod_b() returns trigger as $$
+BEGIN
+   raise notice 'Trigger: Got OLD row %, but returning NULL', OLD;
+   return NULL;
+END $$ LANGUAGE plpgsql;
+CREATE TRIGGER trig_skip_delete before delete on sub_part2
+   for each row execute procedure func_parted_mod_b();
+UPDATE list_parted set b = 1 WHERE c = 70;
+NOTICE:  Trigger: Got OLD row (2,70,1), but returning NULL
+SELECT tableoid::regclass::text, * FROM list_parted ORDER BY 1, 2, 3, 4;
+  tableoid  | a | b  | c  
+------------+---+----+----
+ list_part1 | 2 | 52 | 50
+ list_part1 | 3 |  6 | 60
+ sub_part2  | 1 |  2 | 10
+ sub_part2  | 1 |  2 | 70
+(4 rows)
+
+-- Drop the trigger. Now the row should be moved.
+DROP TRIGGER trig_skip_delete ON sub_part2;
+UPDATE list_parted set b = 1 WHERE c = 70;
+SELECT tableoid::regclass::text, * FROM list_parted ORDER BY 1, 2, 3, 4;
+  tableoid  | a | b  | c  
+------------+---+----+----
+ list_part1 | 2 | 52 | 50
+ list_part1 | 3 |  6 | 60
+ sub_part1  | 1 |  1 | 70
+ sub_part2  | 1 |  2 | 10
+(4 rows)
+
+DROP FUNCTION func_parted_mod_b();
+-- UPDATE partition-key with FROM clause. If join produces multiple output
+-- rows for the same row to be modified, we should tuple-route the row only
+-- once. There should not be any rows inserted.
+CREATE TABLE non_parted (id int);
+INSERT into non_parted VALUES (1), (1), (1), (2), (2), (2), (3), (3), (3);
+UPDATE list_parted t1 set a = 2 FROM non_parted t2 WHERE t1.a = t2.id and a = 1;
+SELECT tableoid::regclass::text, * FROM list_parted ORDER BY 1, 2, 3, 4;
+  tableoid  | a | b  | c  
+------------+---+----+----
+ list_part1 | 2 |  1 | 70
+ list_part1 | 2 |  2 | 10
+ list_part1 | 2 | 52 | 50
+ list_part1 | 3 |  6 | 60
+(4 rows)
+
+DROP TABLE non_parted;
+-- Cleanup: list_parted no longer needed.
+DROP TABLE list_parted;
+-- create custom operator class and hash function, for the same reason
+-- explained in alter_table.sql
+create or replace function dummy_hashint4(a int4, seed int8) returns int8 as
+$$ begin return (a + seed); end; $$ language 'plpgsql' immutable;
+create operator class custom_opclass for type int4 using hash as
+operator 1 = , function 2 dummy_hashint4(int4, int8);
+create table hash_parted (
+	a int,
+	b int
+) partition by hash (a custom_opclass, b custom_opclass);
+create table hpart1 partition of hash_parted for values with (modulus 2, remainder 1);
+create table hpart2 partition of hash_parted for values with (modulus 4, remainder 2);
+create table hpart3 partition of hash_parted for values with (modulus 8, remainder 0);
+create table hpart4 partition of hash_parted for values with (modulus 8, remainder 4);
+insert into hpart1 values (1, 1);
+insert into hpart2 values (2, 5);
+insert into hpart4 values (3, 4);
+-- fail
+update hpart1 set a = 3, b=4 where a = 1;
+ERROR:  new row for relation "hpart1" violates partition constraint
+DETAIL:  Failing row contains (3, 4).
+-- ok, row movement
+update hash_parted set b = b - 1 where b = 1;
+-- ok
+update hash_parted set b = b + 8 where b = 1;
+-- cleanup
+drop table hash_parted;
+drop operator class custom_opclass using hash;
+drop function dummy_hashint4(a int4, seed int8);
diff --git a/src/test/regress/expected/vacuum.out b/src/test/regress/expected/vacuum.out
index 02c53e3..fb74ec2 100644
--- a/src/test/regress/expected/vacuum.out
+++ b/src/test/regress/expected/vacuum.out
@@ -127,20 +127,21 @@ VACUUM (INDEX_CLEANUP FALSE) vaccluster;
 VACUUM (INDEX_CLEANUP FALSE) vactst; -- index cleanup option is ignored if no indexes
 VACUUM (INDEX_CLEANUP FALSE, FREEZE TRUE) vaccluster;
 -- TRUNCATE option
+CREATE TABLE vac_truncate_test_empty(i INT NOT NULL, j text);
 CREATE TABLE vac_truncate_test(i INT NOT NULL, j text)
 	WITH (vacuum_truncate=true, autovacuum_enabled=false);
 INSERT INTO vac_truncate_test VALUES (1, NULL), (NULL, NULL);
 ERROR:  null value in column "i" violates not-null constraint
 DETAIL:  Failing row contains (null, null).
 VACUUM (TRUNCATE FALSE) vac_truncate_test;
-SELECT pg_relation_size('vac_truncate_test') > 0;
+SELECT pg_relation_size('vac_truncate_test') > pg_relation_size('vac_truncate_test_empty');
  ?column? 
 ----------
  t
 (1 row)
 
 VACUUM vac_truncate_test;
-SELECT pg_relation_size('vac_truncate_test') = 0;
+SELECT pg_relation_size('vac_truncate_test') = pg_relation_size('vac_truncate_test_empty');
  ?column? 
 ----------
  t
@@ -148,6 +149,7 @@ SELECT pg_relation_size('vac_truncate_test') = 0;
 
 VACUUM (TRUNCATE FALSE, FULL TRUE) vac_truncate_test;
 DROP TABLE vac_truncate_test;
+DROP TABLE vac_truncate_test_empty;
 -- partitioned table
 CREATE TABLE vacparted (a int, b char) PARTITION BY LIST (a);
 CREATE TABLE vacparted1 PARTITION OF vacparted FOR VALUES IN (1);
diff --git a/src/test/regress/expected/with_1.out b/src/test/regress/expected/with_1.out
new file mode 100644
index 0000000..de2f4b2
--- /dev/null
+++ b/src/test/regress/expected/with_1.out
@@ -0,0 +1,2291 @@
+--
+-- Tests for common table expressions (WITH query, ... SELECT ...)
+--
+-- Basic WITH
+WITH q1(x,y) AS (SELECT 1,2)
+SELECT * FROM q1, q1 AS q2;
+ x | y | x | y 
+---+---+---+---
+ 1 | 2 | 1 | 2
+(1 row)
+
+-- Multiple uses are evaluated only once
+SELECT count(*) FROM (
+  WITH q1(x) AS (SELECT random() FROM generate_series(1, 5))
+    SELECT * FROM q1
+  UNION
+    SELECT * FROM q1
+) ss;
+ count 
+-------
+     5
+(1 row)
+
+-- WITH RECURSIVE
+-- sum of 1..100
+WITH RECURSIVE t(n) AS (
+    VALUES (1)
+UNION ALL
+    SELECT n+1 FROM t WHERE n < 100
+)
+SELECT sum(n) FROM t;
+ sum  
+------
+ 5050
+(1 row)
+
+WITH RECURSIVE t(n) AS (
+    SELECT (VALUES(1))
+UNION ALL
+    SELECT n+1 FROM t WHERE n < 5
+)
+SELECT * FROM t;
+ n 
+---
+ 1
+ 2
+ 3
+ 4
+ 5
+(5 rows)
+
+-- recursive view
+CREATE RECURSIVE VIEW nums (n) AS
+    VALUES (1)
+UNION ALL
+    SELECT n+1 FROM nums WHERE n < 5;
+SELECT * FROM nums;
+ n 
+---
+ 1
+ 2
+ 3
+ 4
+ 5
+(5 rows)
+
+CREATE OR REPLACE RECURSIVE VIEW nums (n) AS
+    VALUES (1)
+UNION ALL
+    SELECT n+1 FROM nums WHERE n < 6;
+SELECT * FROM nums;
+ n 
+---
+ 1
+ 2
+ 3
+ 4
+ 5
+ 6
+(6 rows)
+
+-- This is an infinite loop with UNION ALL, but not with UNION
+WITH RECURSIVE t(n) AS (
+    SELECT 1
+UNION
+    SELECT 10-n FROM t)
+SELECT * FROM t;
+ n 
+---
+ 1
+ 9
+(2 rows)
+
+-- This'd be an infinite loop, but outside query reads only as much as needed
+WITH RECURSIVE t(n) AS (
+    VALUES (1)
+UNION ALL
+    SELECT n+1 FROM t)
+SELECT * FROM t LIMIT 10;
+ n  
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+(10 rows)
+
+-- UNION case should have same property
+WITH RECURSIVE t(n) AS (
+    SELECT 1
+UNION
+    SELECT n+1 FROM t)
+SELECT * FROM t LIMIT 10;
+ n  
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+(10 rows)
+
+-- Test behavior with an unknown-type literal in the WITH
+WITH q AS (SELECT 'foo' AS x)
+SELECT x, x IS OF (text) AS is_text FROM q;
+  x  | is_text 
+-----+---------
+ foo | t
+(1 row)
+
+WITH RECURSIVE t(n) AS (
+    SELECT 'foo'
+UNION ALL
+    SELECT n || ' bar' FROM t WHERE length(n) < 20
+)
+SELECT n, n IS OF (text) AS is_text FROM t;
+            n            | is_text 
+-------------------------+---------
+ foo                     | t
+ foo bar                 | t
+ foo bar bar             | t
+ foo bar bar bar         | t
+ foo bar bar bar bar     | t
+ foo bar bar bar bar bar | t
+(6 rows)
+
+-- In a perfect world, this would work and resolve the literal as int ...
+-- but for now, we have to be content with resolving to text too soon.
+WITH RECURSIVE t(n) AS (
+    SELECT '7'
+UNION ALL
+    SELECT n+1 FROM t WHERE n < 10
+)
+SELECT n, n IS OF (int) AS is_int FROM t;
+ERROR:  operator does not exist: text + integer
+LINE 4:     SELECT n+1 FROM t WHERE n < 10
+                    ^
+HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
+--
+-- Some examples with a tree
+--
+-- department structure represented here is as follows:
+--
+-- ROOT-+->A-+->B-+->C
+--      |         |
+--      |         +->D-+->F
+--      +->E-+->G
+CREATE TEMP TABLE department (
+	id INTEGER PRIMARY KEY,  -- department ID
+	parent_department INTEGER REFERENCES department, -- upper department ID
+	name TEXT -- department name
+);
+INSERT INTO department VALUES (0, NULL, 'ROOT');
+INSERT INTO department VALUES (1, 0, 'A');
+INSERT INTO department VALUES (2, 1, 'B');
+INSERT INTO department VALUES (3, 2, 'C');
+INSERT INTO department VALUES (4, 2, 'D');
+INSERT INTO department VALUES (5, 0, 'E');
+INSERT INTO department VALUES (6, 4, 'F');
+INSERT INTO department VALUES (7, 5, 'G');
+-- extract all departments under 'A'. Result should be A, B, C, D and F
+WITH RECURSIVE subdepartment AS
+(
+	-- non recursive term
+	SELECT name as root_name, * FROM department WHERE name = 'A'
+	UNION ALL
+	-- recursive term
+	SELECT sd.root_name, d.* FROM department AS d, subdepartment AS sd
+		WHERE d.parent_department = sd.id
+)
+SELECT * FROM subdepartment ORDER BY name;
+ root_name | id | parent_department | name 
+-----------+----+-------------------+------
+ A         |  1 |                 0 | A
+ A         |  2 |                 1 | B
+ A         |  3 |                 2 | C
+ A         |  4 |                 2 | D
+ A         |  6 |                 4 | F
+(5 rows)
+
+-- extract all departments under 'A' with "level" number
+WITH RECURSIVE subdepartment(level, id, parent_department, name) AS
+(
+	-- non recursive term
+	SELECT 1, * FROM department WHERE name = 'A'
+	UNION ALL
+	-- recursive term
+	SELECT sd.level + 1, d.* FROM department AS d, subdepartment AS sd
+		WHERE d.parent_department = sd.id
+)
+SELECT * FROM subdepartment ORDER BY name;
+ level | id | parent_department | name 
+-------+----+-------------------+------
+     1 |  1 |                 0 | A
+     2 |  2 |                 1 | B
+     3 |  3 |                 2 | C
+     3 |  4 |                 2 | D
+     4 |  6 |                 4 | F
+(5 rows)
+
+-- extract all departments under 'A' with "level" number.
+-- Only shows level 2 or more
+WITH RECURSIVE subdepartment(level, id, parent_department, name) AS
+(
+	-- non recursive term
+	SELECT 1, * FROM department WHERE name = 'A'
+	UNION ALL
+	-- recursive term
+	SELECT sd.level + 1, d.* FROM department AS d, subdepartment AS sd
+		WHERE d.parent_department = sd.id
+)
+SELECT * FROM subdepartment WHERE level >= 2 ORDER BY name;
+ level | id | parent_department | name 
+-------+----+-------------------+------
+     2 |  2 |                 1 | B
+     3 |  3 |                 2 | C
+     3 |  4 |                 2 | D
+     4 |  6 |                 4 | F
+(4 rows)
+
+-- "RECURSIVE" is ignored if the query has no self-reference
+WITH RECURSIVE subdepartment AS
+(
+	-- note lack of recursive UNION structure
+	SELECT * FROM department WHERE name = 'A'
+)
+SELECT * FROM subdepartment ORDER BY name;
+ id | parent_department | name 
+----+-------------------+------
+  1 |                 0 | A
+(1 row)
+
+-- inside subqueries
+SELECT count(*) FROM (
+    WITH RECURSIVE t(n) AS (
+        SELECT 1 UNION ALL SELECT n + 1 FROM t WHERE n < 500
+    )
+    SELECT * FROM t) AS t WHERE n < (
+        SELECT count(*) FROM (
+            WITH RECURSIVE t(n) AS (
+                   SELECT 1 UNION ALL SELECT n + 1 FROM t WHERE n < 100
+                )
+            SELECT * FROM t WHERE n < 50000
+         ) AS t WHERE n < 100);
+ count 
+-------
+    98
+(1 row)
+
+-- use same CTE twice at different subquery levels
+WITH q1(x,y) AS (
+    SELECT hundred, sum(ten) FROM tenk1 GROUP BY hundred
+  )
+SELECT count(*) FROM q1 WHERE y > (SELECT sum(y)/100 FROM q1 qsub);
+ count 
+-------
+    50
+(1 row)
+
+-- via a VIEW
+CREATE TEMPORARY VIEW vsubdepartment AS
+	WITH RECURSIVE subdepartment AS
+	(
+		 -- non recursive term
+		SELECT * FROM department WHERE name = 'A'
+		UNION ALL
+		-- recursive term
+		SELECT d.* FROM department AS d, subdepartment AS sd
+			WHERE d.parent_department = sd.id
+	)
+	SELECT * FROM subdepartment;
+SELECT * FROM vsubdepartment ORDER BY name;
+ id | parent_department | name 
+----+-------------------+------
+  1 |                 0 | A
+  2 |                 1 | B
+  3 |                 2 | C
+  4 |                 2 | D
+  6 |                 4 | F
+(5 rows)
+
+-- Check reverse listing
+SELECT pg_get_viewdef('vsubdepartment'::regclass);
+                pg_get_viewdef                 
+-----------------------------------------------
+  WITH RECURSIVE subdepartment AS (           +
+          SELECT department.id,               +
+             department.parent_department,    +
+             department.name                  +
+            FROM department                   +
+           WHERE (department.name = 'A'::text)+
+         UNION ALL                            +
+          SELECT d.id,                        +
+             d.parent_department,             +
+             d.name                           +
+            FROM department d,                +
+             subdepartment sd                 +
+           WHERE (d.parent_department = sd.id)+
+         )                                    +
+  SELECT subdepartment.id,                    +
+     subdepartment.parent_department,         +
+     subdepartment.name                       +
+    FROM subdepartment;
+(1 row)
+
+SELECT pg_get_viewdef('vsubdepartment'::regclass, true);
+               pg_get_viewdef                
+---------------------------------------------
+  WITH RECURSIVE subdepartment AS (         +
+          SELECT department.id,             +
+             department.parent_department,  +
+             department.name                +
+            FROM department                 +
+           WHERE department.name = 'A'::text+
+         UNION ALL                          +
+          SELECT d.id,                      +
+             d.parent_department,           +
+             d.name                         +
+            FROM department d,              +
+             subdepartment sd               +
+           WHERE d.parent_department = sd.id+
+         )                                  +
+  SELECT subdepartment.id,                  +
+     subdepartment.parent_department,       +
+     subdepartment.name                     +
+    FROM subdepartment;
+(1 row)
+
+-- Another reverse-listing example
+CREATE VIEW sums_1_100 AS
+WITH RECURSIVE t(n) AS (
+    VALUES (1)
+UNION ALL
+    SELECT n+1 FROM t WHERE n < 100
+)
+SELECT sum(n) FROM t;
+\d+ sums_1_100
+                         View "public.sums_1_100"
+ Column |  Type  | Collation | Nullable | Default | Storage | Description 
+--------+--------+-----------+----------+---------+---------+-------------
+ sum    | bigint |           |          |         | plain   | 
+View definition:
+ WITH RECURSIVE t(n) AS (
+         VALUES (1)
+        UNION ALL
+         SELECT t_1.n + 1
+           FROM t t_1
+          WHERE t_1.n < 100
+        )
+ SELECT sum(t.n) AS sum
+   FROM t;
+
+-- corner case in which sub-WITH gets initialized first
+with recursive q as (
+      select * from department
+    union all
+      (with x as (select * from q)
+       select * from x)
+    )
+select * from q limit 24;
+ id | parent_department | name 
+----+-------------------+------
+  0 |                   | ROOT
+  1 |                 0 | A
+  2 |                 1 | B
+  3 |                 2 | C
+  4 |                 2 | D
+  5 |                 0 | E
+  6 |                 4 | F
+  7 |                 5 | G
+  0 |                   | ROOT
+  1 |                 0 | A
+  2 |                 1 | B
+  3 |                 2 | C
+  4 |                 2 | D
+  5 |                 0 | E
+  6 |                 4 | F
+  7 |                 5 | G
+  0 |                   | ROOT
+  1 |                 0 | A
+  2 |                 1 | B
+  3 |                 2 | C
+  4 |                 2 | D
+  5 |                 0 | E
+  6 |                 4 | F
+  7 |                 5 | G
+(24 rows)
+
+with recursive q as (
+      select * from department
+    union all
+      (with recursive x as (
+           select * from department
+         union all
+           (select * from q union all select * from x)
+        )
+       select * from x)
+    )
+select * from q limit 32;
+ id | parent_department | name 
+----+-------------------+------
+  0 |                   | ROOT
+  1 |                 0 | A
+  2 |                 1 | B
+  3 |                 2 | C
+  4 |                 2 | D
+  5 |                 0 | E
+  6 |                 4 | F
+  7 |                 5 | G
+  0 |                   | ROOT
+  1 |                 0 | A
+  2 |                 1 | B
+  3 |                 2 | C
+  4 |                 2 | D
+  5 |                 0 | E
+  6 |                 4 | F
+  7 |                 5 | G
+  0 |                   | ROOT
+  1 |                 0 | A
+  2 |                 1 | B
+  3 |                 2 | C
+  4 |                 2 | D
+  5 |                 0 | E
+  6 |                 4 | F
+  7 |                 5 | G
+  0 |                   | ROOT
+  1 |                 0 | A
+  2 |                 1 | B
+  3 |                 2 | C
+  4 |                 2 | D
+  5 |                 0 | E
+  6 |                 4 | F
+  7 |                 5 | G
+(32 rows)
+
+-- recursive term has sub-UNION
+WITH RECURSIVE t(i,j) AS (
+	VALUES (1,2)
+	UNION ALL
+	SELECT t2.i, t.j+1 FROM
+		(SELECT 2 AS i UNION ALL SELECT 3 AS i) AS t2
+		JOIN t ON (t2.i = t.i+1))
+	SELECT * FROM t;
+ i | j 
+---+---
+ 1 | 2
+ 2 | 3
+ 3 | 4
+(3 rows)
+
+--
+-- different tree example
+--
+CREATE TEMPORARY TABLE tree(
+    id INTEGER PRIMARY KEY,
+    parent_id INTEGER REFERENCES tree(id)
+);
+INSERT INTO tree
+VALUES (1, NULL), (2, 1), (3,1), (4,2), (5,2), (6,2), (7,3), (8,3),
+       (9,4), (10,4), (11,7), (12,7), (13,7), (14, 9), (15,11), (16,11);
+--
+-- get all paths from "second level" nodes to leaf nodes
+--
+WITH RECURSIVE t(id, path) AS (
+    VALUES(1,ARRAY[]::integer[])
+UNION ALL
+    SELECT tree.id, t.path || tree.id
+    FROM tree JOIN t ON (tree.parent_id = t.id)
+)
+SELECT t1.*, t2.* FROM t AS t1 JOIN t AS t2 ON
+	(t1.path[1] = t2.path[1] AND
+	array_upper(t1.path,1) = 1 AND
+	array_upper(t2.path,1) > 1)
+	ORDER BY t1.id, t2.id;
+ id | path | id |    path     
+----+------+----+-------------
+  2 | {2}  |  4 | {2,4}
+  2 | {2}  |  5 | {2,5}
+  2 | {2}  |  6 | {2,6}
+  2 | {2}  |  9 | {2,4,9}
+  2 | {2}  | 10 | {2,4,10}
+  2 | {2}  | 14 | {2,4,9,14}
+  3 | {3}  |  7 | {3,7}
+  3 | {3}  |  8 | {3,8}
+  3 | {3}  | 11 | {3,7,11}
+  3 | {3}  | 12 | {3,7,12}
+  3 | {3}  | 13 | {3,7,13}
+  3 | {3}  | 15 | {3,7,11,15}
+  3 | {3}  | 16 | {3,7,11,16}
+(13 rows)
+
+-- just count 'em
+WITH RECURSIVE t(id, path) AS (
+    VALUES(1,ARRAY[]::integer[])
+UNION ALL
+    SELECT tree.id, t.path || tree.id
+    FROM tree JOIN t ON (tree.parent_id = t.id)
+)
+SELECT t1.id, count(t2.*) FROM t AS t1 JOIN t AS t2 ON
+	(t1.path[1] = t2.path[1] AND
+	array_upper(t1.path,1) = 1 AND
+	array_upper(t2.path,1) > 1)
+	GROUP BY t1.id
+	ORDER BY t1.id;
+ id | count 
+----+-------
+  2 |     6
+  3 |     7
+(2 rows)
+
+-- this variant tickled a whole-row-variable bug in 8.4devel
+WITH RECURSIVE t(id, path) AS (
+    VALUES(1,ARRAY[]::integer[])
+UNION ALL
+    SELECT tree.id, t.path || tree.id
+    FROM tree JOIN t ON (tree.parent_id = t.id)
+)
+SELECT t1.id, t2.path, t2 FROM t AS t1 JOIN t AS t2 ON
+(t1.id=t2.id);
+ id |    path     |         t2         
+----+-------------+--------------------
+  1 | {}          | (1,{})
+  2 | {2}         | (2,{2})
+  3 | {3}         | (3,{3})
+  4 | {2,4}       | (4,"{2,4}")
+  5 | {2,5}       | (5,"{2,5}")
+  6 | {2,6}       | (6,"{2,6}")
+  7 | {3,7}       | (7,"{3,7}")
+  8 | {3,8}       | (8,"{3,8}")
+  9 | {2,4,9}     | (9,"{2,4,9}")
+ 10 | {2,4,10}    | (10,"{2,4,10}")
+ 11 | {3,7,11}    | (11,"{3,7,11}")
+ 12 | {3,7,12}    | (12,"{3,7,12}")
+ 13 | {3,7,13}    | (13,"{3,7,13}")
+ 14 | {2,4,9,14}  | (14,"{2,4,9,14}")
+ 15 | {3,7,11,15} | (15,"{3,7,11,15}")
+ 16 | {3,7,11,16} | (16,"{3,7,11,16}")
+(16 rows)
+
+--
+-- test cycle detection
+--
+create temp table graph( f int, t int, label text );
+insert into graph values
+	(1, 2, 'arc 1 -> 2'),
+	(1, 3, 'arc 1 -> 3'),
+	(2, 3, 'arc 2 -> 3'),
+	(1, 4, 'arc 1 -> 4'),
+	(4, 5, 'arc 4 -> 5'),
+	(5, 1, 'arc 5 -> 1');
+with recursive search_graph(f, t, label, path, cycle) as (
+	select *, array[row(g.f, g.t)], false from graph g
+	union all
+	select g.*, path || row(g.f, g.t), row(g.f, g.t) = any(path)
+	from graph g, search_graph sg
+	where g.f = sg.t and not cycle
+)
+select * from search_graph;
+ f | t |   label    |                   path                    | cycle 
+---+---+------------+-------------------------------------------+-------
+ 1 | 2 | arc 1 -> 2 | {"(1,2)"}                                 | f
+ 1 | 3 | arc 1 -> 3 | {"(1,3)"}                                 | f
+ 2 | 3 | arc 2 -> 3 | {"(2,3)"}                                 | f
+ 1 | 4 | arc 1 -> 4 | {"(1,4)"}                                 | f
+ 4 | 5 | arc 4 -> 5 | {"(4,5)"}                                 | f
+ 5 | 1 | arc 5 -> 1 | {"(5,1)"}                                 | f
+ 1 | 2 | arc 1 -> 2 | {"(5,1)","(1,2)"}                         | f
+ 1 | 3 | arc 1 -> 3 | {"(5,1)","(1,3)"}                         | f
+ 1 | 4 | arc 1 -> 4 | {"(5,1)","(1,4)"}                         | f
+ 2 | 3 | arc 2 -> 3 | {"(1,2)","(2,3)"}                         | f
+ 4 | 5 | arc 4 -> 5 | {"(1,4)","(4,5)"}                         | f
+ 5 | 1 | arc 5 -> 1 | {"(4,5)","(5,1)"}                         | f
+ 1 | 2 | arc 1 -> 2 | {"(4,5)","(5,1)","(1,2)"}                 | f
+ 1 | 3 | arc 1 -> 3 | {"(4,5)","(5,1)","(1,3)"}                 | f
+ 1 | 4 | arc 1 -> 4 | {"(4,5)","(5,1)","(1,4)"}                 | f
+ 2 | 3 | arc 2 -> 3 | {"(5,1)","(1,2)","(2,3)"}                 | f
+ 4 | 5 | arc 4 -> 5 | {"(5,1)","(1,4)","(4,5)"}                 | f
+ 5 | 1 | arc 5 -> 1 | {"(1,4)","(4,5)","(5,1)"}                 | f
+ 1 | 2 | arc 1 -> 2 | {"(1,4)","(4,5)","(5,1)","(1,2)"}         | f
+ 1 | 3 | arc 1 -> 3 | {"(1,4)","(4,5)","(5,1)","(1,3)"}         | f
+ 1 | 4 | arc 1 -> 4 | {"(1,4)","(4,5)","(5,1)","(1,4)"}         | t
+ 2 | 3 | arc 2 -> 3 | {"(4,5)","(5,1)","(1,2)","(2,3)"}         | f
+ 4 | 5 | arc 4 -> 5 | {"(4,5)","(5,1)","(1,4)","(4,5)"}         | t
+ 5 | 1 | arc 5 -> 1 | {"(5,1)","(1,4)","(4,5)","(5,1)"}         | t
+ 2 | 3 | arc 2 -> 3 | {"(1,4)","(4,5)","(5,1)","(1,2)","(2,3)"} | f
+(25 rows)
+
+-- ordering by the path column has same effect as SEARCH DEPTH FIRST
+with recursive search_graph(f, t, label, path, cycle) as (
+	select *, array[row(g.f, g.t)], false from graph g
+	union all
+	select g.*, path || row(g.f, g.t), row(g.f, g.t) = any(path)
+	from graph g, search_graph sg
+	where g.f = sg.t and not cycle
+)
+select * from search_graph order by path;
+ f | t |   label    |                   path                    | cycle 
+---+---+------------+-------------------------------------------+-------
+ 1 | 2 | arc 1 -> 2 | {"(1,2)"}                                 | f
+ 2 | 3 | arc 2 -> 3 | {"(1,2)","(2,3)"}                         | f
+ 1 | 3 | arc 1 -> 3 | {"(1,3)"}                                 | f
+ 1 | 4 | arc 1 -> 4 | {"(1,4)"}                                 | f
+ 4 | 5 | arc 4 -> 5 | {"(1,4)","(4,5)"}                         | f
+ 5 | 1 | arc 5 -> 1 | {"(1,4)","(4,5)","(5,1)"}                 | f
+ 1 | 2 | arc 1 -> 2 | {"(1,4)","(4,5)","(5,1)","(1,2)"}         | f
+ 2 | 3 | arc 2 -> 3 | {"(1,4)","(4,5)","(5,1)","(1,2)","(2,3)"} | f
+ 1 | 3 | arc 1 -> 3 | {"(1,4)","(4,5)","(5,1)","(1,3)"}         | f
+ 1 | 4 | arc 1 -> 4 | {"(1,4)","(4,5)","(5,1)","(1,4)"}         | t
+ 2 | 3 | arc 2 -> 3 | {"(2,3)"}                                 | f
+ 4 | 5 | arc 4 -> 5 | {"(4,5)"}                                 | f
+ 5 | 1 | arc 5 -> 1 | {"(4,5)","(5,1)"}                         | f
+ 1 | 2 | arc 1 -> 2 | {"(4,5)","(5,1)","(1,2)"}                 | f
+ 2 | 3 | arc 2 -> 3 | {"(4,5)","(5,1)","(1,2)","(2,3)"}         | f
+ 1 | 3 | arc 1 -> 3 | {"(4,5)","(5,1)","(1,3)"}                 | f
+ 1 | 4 | arc 1 -> 4 | {"(4,5)","(5,1)","(1,4)"}                 | f
+ 4 | 5 | arc 4 -> 5 | {"(4,5)","(5,1)","(1,4)","(4,5)"}         | t
+ 5 | 1 | arc 5 -> 1 | {"(5,1)"}                                 | f
+ 1 | 2 | arc 1 -> 2 | {"(5,1)","(1,2)"}                         | f
+ 2 | 3 | arc 2 -> 3 | {"(5,1)","(1,2)","(2,3)"}                 | f
+ 1 | 3 | arc 1 -> 3 | {"(5,1)","(1,3)"}                         | f
+ 1 | 4 | arc 1 -> 4 | {"(5,1)","(1,4)"}                         | f
+ 4 | 5 | arc 4 -> 5 | {"(5,1)","(1,4)","(4,5)"}                 | f
+ 5 | 1 | arc 5 -> 1 | {"(5,1)","(1,4)","(4,5)","(5,1)"}         | t
+(25 rows)
+
+--
+-- test multiple WITH queries
+--
+WITH RECURSIVE
+  y (id) AS (VALUES (1)),
+  x (id) AS (SELECT * FROM y UNION ALL SELECT id+1 FROM x WHERE id < 5)
+SELECT * FROM x;
+ id 
+----
+  1
+  2
+  3
+  4
+  5
+(5 rows)
+
+-- forward reference OK
+WITH RECURSIVE
+    x(id) AS (SELECT * FROM y UNION ALL SELECT id+1 FROM x WHERE id < 5),
+    y(id) AS (values (1))
+ SELECT * FROM x;
+ id 
+----
+  1
+  2
+  3
+  4
+  5
+(5 rows)
+
+WITH RECURSIVE
+   x(id) AS
+     (VALUES (1) UNION ALL SELECT id+1 FROM x WHERE id < 5),
+   y(id) AS
+     (VALUES (1) UNION ALL SELECT id+1 FROM y WHERE id < 10)
+ SELECT y.*, x.* FROM y LEFT JOIN x USING (id);
+ id | id 
+----+----
+  1 |  1
+  2 |  2
+  3 |  3
+  4 |  4
+  5 |  5
+  6 |   
+  7 |   
+  8 |   
+  9 |   
+ 10 |   
+(10 rows)
+
+WITH RECURSIVE
+   x(id) AS
+     (VALUES (1) UNION ALL SELECT id+1 FROM x WHERE id < 5),
+   y(id) AS
+     (VALUES (1) UNION ALL SELECT id+1 FROM x WHERE id < 10)
+ SELECT y.*, x.* FROM y LEFT JOIN x USING (id);
+ id | id 
+----+----
+  1 |  1
+  2 |  2
+  3 |  3
+  4 |  4
+  5 |  5
+  6 |   
+(6 rows)
+
+WITH RECURSIVE
+   x(id) AS
+     (SELECT 1 UNION ALL SELECT id+1 FROM x WHERE id < 3 ),
+   y(id) AS
+     (SELECT * FROM x UNION ALL SELECT * FROM x),
+   z(id) AS
+     (SELECT * FROM x UNION ALL SELECT id+1 FROM z WHERE id < 10)
+ SELECT * FROM z;
+ id 
+----
+  1
+  2
+  3
+  2
+  3
+  4
+  3
+  4
+  5
+  4
+  5
+  6
+  5
+  6
+  7
+  6
+  7
+  8
+  7
+  8
+  9
+  8
+  9
+ 10
+  9
+ 10
+ 10
+(27 rows)
+
+WITH RECURSIVE
+   x(id) AS
+     (SELECT 1 UNION ALL SELECT id+1 FROM x WHERE id < 3 ),
+   y(id) AS
+     (SELECT * FROM x UNION ALL SELECT * FROM x),
+   z(id) AS
+     (SELECT * FROM y UNION ALL SELECT id+1 FROM z WHERE id < 10)
+ SELECT * FROM z;
+ id 
+----
+  1
+  2
+  3
+  1
+  2
+  3
+  2
+  3
+  4
+  2
+  3
+  4
+  3
+  4
+  5
+  3
+  4
+  5
+  4
+  5
+  6
+  4
+  5
+  6
+  5
+  6
+  7
+  5
+  6
+  7
+  6
+  7
+  8
+  6
+  7
+  8
+  7
+  8
+  9
+  7
+  8
+  9
+  8
+  9
+ 10
+  8
+  9
+ 10
+  9
+ 10
+  9
+ 10
+ 10
+ 10
+(54 rows)
+
+--
+-- Test WITH attached to a data-modifying statement
+--
+CREATE TEMPORARY TABLE y (a INTEGER);
+INSERT INTO y SELECT generate_series(1, 10);
+WITH t AS (
+	SELECT a FROM y
+)
+INSERT INTO y
+SELECT a+20 FROM t RETURNING *;
+ a  
+----
+ 21
+ 22
+ 23
+ 24
+ 25
+ 26
+ 27
+ 28
+ 29
+ 30
+(10 rows)
+
+SELECT * FROM y;
+ a  
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+ 21
+ 22
+ 23
+ 24
+ 25
+ 26
+ 27
+ 28
+ 29
+ 30
+(20 rows)
+
+WITH t AS (
+	SELECT a FROM y
+)
+UPDATE y SET a = y.a-10 FROM t WHERE y.a > 20 AND t.a = y.a RETURNING y.a;
+ a  
+----
+ 11
+ 12
+ 13
+ 14
+ 15
+ 16
+ 17
+ 18
+ 19
+ 20
+(10 rows)
+
+SELECT * FROM y;
+ a  
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+ 11
+ 12
+ 13
+ 14
+ 15
+ 16
+ 17
+ 18
+ 19
+ 20
+(20 rows)
+
+WITH RECURSIVE t(a) AS (
+	SELECT 11
+	UNION ALL
+	SELECT a+1 FROM t WHERE a < 50
+)
+DELETE FROM y USING t WHERE t.a = y.a RETURNING y.a;
+ a  
+----
+ 11
+ 12
+ 13
+ 14
+ 15
+ 16
+ 17
+ 18
+ 19
+ 20
+(10 rows)
+
+SELECT * FROM y;
+ a  
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+(10 rows)
+
+DROP TABLE y;
+--
+-- error cases
+--
+-- INTERSECT
+WITH RECURSIVE x(n) AS (SELECT 1 INTERSECT SELECT n+1 FROM x)
+	SELECT * FROM x;
+ERROR:  recursive query "x" does not have the form non-recursive-term UNION [ALL] recursive-term
+LINE 1: WITH RECURSIVE x(n) AS (SELECT 1 INTERSECT SELECT n+1 FROM x...
+                       ^
+WITH RECURSIVE x(n) AS (SELECT 1 INTERSECT ALL SELECT n+1 FROM x)
+	SELECT * FROM x;
+ERROR:  recursive query "x" does not have the form non-recursive-term UNION [ALL] recursive-term
+LINE 1: WITH RECURSIVE x(n) AS (SELECT 1 INTERSECT ALL SELECT n+1 FR...
+                       ^
+-- EXCEPT
+WITH RECURSIVE x(n) AS (SELECT 1 EXCEPT SELECT n+1 FROM x)
+	SELECT * FROM x;
+ERROR:  recursive query "x" does not have the form non-recursive-term UNION [ALL] recursive-term
+LINE 1: WITH RECURSIVE x(n) AS (SELECT 1 EXCEPT SELECT n+1 FROM x)
+                       ^
+WITH RECURSIVE x(n) AS (SELECT 1 EXCEPT ALL SELECT n+1 FROM x)
+	SELECT * FROM x;
+ERROR:  recursive query "x" does not have the form non-recursive-term UNION [ALL] recursive-term
+LINE 1: WITH RECURSIVE x(n) AS (SELECT 1 EXCEPT ALL SELECT n+1 FROM ...
+                       ^
+-- no non-recursive term
+WITH RECURSIVE x(n) AS (SELECT n FROM x)
+	SELECT * FROM x;
+ERROR:  recursive query "x" does not have the form non-recursive-term UNION [ALL] recursive-term
+LINE 1: WITH RECURSIVE x(n) AS (SELECT n FROM x)
+                       ^
+-- recursive term in the left hand side (strictly speaking, should allow this)
+WITH RECURSIVE x(n) AS (SELECT n FROM x UNION ALL SELECT 1)
+	SELECT * FROM x;
+ERROR:  recursive reference to query "x" must not appear within its non-recursive term
+LINE 1: WITH RECURSIVE x(n) AS (SELECT n FROM x UNION ALL SELECT 1)
+                                              ^
+CREATE TEMPORARY TABLE y (a INTEGER);
+INSERT INTO y SELECT generate_series(1, 10);
+-- LEFT JOIN
+WITH RECURSIVE x(n) AS (SELECT a FROM y WHERE a = 1
+	UNION ALL
+	SELECT x.n+1 FROM y LEFT JOIN x ON x.n = y.a WHERE n < 10)
+SELECT * FROM x;
+ERROR:  recursive reference to query "x" must not appear within an outer join
+LINE 3:  SELECT x.n+1 FROM y LEFT JOIN x ON x.n = y.a WHERE n < 10)
+                                       ^
+-- RIGHT JOIN
+WITH RECURSIVE x(n) AS (SELECT a FROM y WHERE a = 1
+	UNION ALL
+	SELECT x.n+1 FROM x RIGHT JOIN y ON x.n = y.a WHERE n < 10)
+SELECT * FROM x;
+ERROR:  recursive reference to query "x" must not appear within an outer join
+LINE 3:  SELECT x.n+1 FROM x RIGHT JOIN y ON x.n = y.a WHERE n < 10)
+                           ^
+-- FULL JOIN
+WITH RECURSIVE x(n) AS (SELECT a FROM y WHERE a = 1
+	UNION ALL
+	SELECT x.n+1 FROM x FULL JOIN y ON x.n = y.a WHERE n < 10)
+SELECT * FROM x;
+ERROR:  recursive reference to query "x" must not appear within an outer join
+LINE 3:  SELECT x.n+1 FROM x FULL JOIN y ON x.n = y.a WHERE n < 10)
+                           ^
+-- subquery
+WITH RECURSIVE x(n) AS (SELECT 1 UNION ALL SELECT n+1 FROM x
+                          WHERE n IN (SELECT * FROM x))
+  SELECT * FROM x;
+ERROR:  recursive reference to query "x" must not appear within a subquery
+LINE 2:                           WHERE n IN (SELECT * FROM x))
+                                                            ^
+-- aggregate functions
+WITH RECURSIVE x(n) AS (SELECT 1 UNION ALL SELECT count(*) FROM x)
+  SELECT * FROM x;
+ERROR:  aggregate functions are not allowed in a recursive query's recursive term
+LINE 1: WITH RECURSIVE x(n) AS (SELECT 1 UNION ALL SELECT count(*) F...
+                                                          ^
+WITH RECURSIVE x(n) AS (SELECT 1 UNION ALL SELECT sum(n) FROM x)
+  SELECT * FROM x;
+ERROR:  aggregate functions are not allowed in a recursive query's recursive term
+LINE 1: WITH RECURSIVE x(n) AS (SELECT 1 UNION ALL SELECT sum(n) FRO...
+                                                          ^
+-- ORDER BY
+WITH RECURSIVE x(n) AS (SELECT 1 UNION ALL SELECT n+1 FROM x ORDER BY 1)
+  SELECT * FROM x;
+ERROR:  ORDER BY in a recursive query is not implemented
+LINE 1: ...VE x(n) AS (SELECT 1 UNION ALL SELECT n+1 FROM x ORDER BY 1)
+                                                                     ^
+-- LIMIT/OFFSET
+WITH RECURSIVE x(n) AS (SELECT 1 UNION ALL SELECT n+1 FROM x LIMIT 10 OFFSET 1)
+  SELECT * FROM x;
+ERROR:  OFFSET in a recursive query is not implemented
+LINE 1: ... AS (SELECT 1 UNION ALL SELECT n+1 FROM x LIMIT 10 OFFSET 1)
+                                                                     ^
+-- FOR UPDATE
+WITH RECURSIVE x(n) AS (SELECT 1 UNION ALL SELECT n+1 FROM x FOR UPDATE)
+  SELECT * FROM x;
+ERROR:  FOR UPDATE/SHARE in a recursive query is not implemented
+-- target list has a recursive query name
+WITH RECURSIVE x(id) AS (values (1)
+    UNION ALL
+    SELECT (SELECT * FROM x) FROM x WHERE id < 5
+) SELECT * FROM x;
+ERROR:  recursive reference to query "x" must not appear within a subquery
+LINE 3:     SELECT (SELECT * FROM x) FROM x WHERE id < 5
+                                  ^
+-- mutual recursive query (not implemented)
+WITH RECURSIVE
+  x (id) AS (SELECT 1 UNION ALL SELECT id+1 FROM y WHERE id < 5),
+  y (id) AS (SELECT 1 UNION ALL SELECT id+1 FROM x WHERE id < 5)
+SELECT * FROM x;
+ERROR:  mutual recursion between WITH items is not implemented
+LINE 2:   x (id) AS (SELECT 1 UNION ALL SELECT id+1 FROM y WHERE id ...
+          ^
+-- non-linear recursion is not allowed
+WITH RECURSIVE foo(i) AS
+    (values (1)
+    UNION ALL
+       (SELECT i+1 FROM foo WHERE i < 10
+          UNION ALL
+       SELECT i+1 FROM foo WHERE i < 5)
+) SELECT * FROM foo;
+ERROR:  recursive reference to query "foo" must not appear more than once
+LINE 6:        SELECT i+1 FROM foo WHERE i < 5)
+                               ^
+WITH RECURSIVE foo(i) AS
+    (values (1)
+    UNION ALL
+	   SELECT * FROM
+       (SELECT i+1 FROM foo WHERE i < 10
+          UNION ALL
+       SELECT i+1 FROM foo WHERE i < 5) AS t
+) SELECT * FROM foo;
+ERROR:  recursive reference to query "foo" must not appear more than once
+LINE 7:        SELECT i+1 FROM foo WHERE i < 5) AS t
+                               ^
+WITH RECURSIVE foo(i) AS
+    (values (1)
+    UNION ALL
+       (SELECT i+1 FROM foo WHERE i < 10
+          EXCEPT
+       SELECT i+1 FROM foo WHERE i < 5)
+) SELECT * FROM foo;
+ERROR:  recursive reference to query "foo" must not appear within EXCEPT
+LINE 6:        SELECT i+1 FROM foo WHERE i < 5)
+                               ^
+WITH RECURSIVE foo(i) AS
+    (values (1)
+    UNION ALL
+       (SELECT i+1 FROM foo WHERE i < 10
+          INTERSECT
+       SELECT i+1 FROM foo WHERE i < 5)
+) SELECT * FROM foo;
+ERROR:  recursive reference to query "foo" must not appear more than once
+LINE 6:        SELECT i+1 FROM foo WHERE i < 5)
+                               ^
+-- Wrong type induced from non-recursive term
+WITH RECURSIVE foo(i) AS
+   (SELECT i FROM (VALUES(1),(2)) t(i)
+   UNION ALL
+   SELECT (i+1)::numeric(10,0) FROM foo WHERE i < 10)
+SELECT * FROM foo;
+ERROR:  recursive query "foo" column 1 has type integer in non-recursive term but type numeric overall
+LINE 2:    (SELECT i FROM (VALUES(1),(2)) t(i)
+                   ^
+HINT:  Cast the output of the non-recursive term to the correct type.
+-- rejects different typmod, too (should we allow this?)
+WITH RECURSIVE foo(i) AS
+   (SELECT i::numeric(3,0) FROM (VALUES(1),(2)) t(i)
+   UNION ALL
+   SELECT (i+1)::numeric(10,0) FROM foo WHERE i < 10)
+SELECT * FROM foo;
+ERROR:  recursive query "foo" column 1 has type numeric(3,0) in non-recursive term but type numeric overall
+LINE 2:    (SELECT i::numeric(3,0) FROM (VALUES(1),(2)) t(i)
+                   ^
+HINT:  Cast the output of the non-recursive term to the correct type.
+-- disallow OLD/NEW reference in CTE
+CREATE TEMPORARY TABLE x (n integer);
+CREATE RULE r2 AS ON UPDATE TO x DO INSTEAD
+    WITH t AS (SELECT OLD.*) UPDATE y SET a = t.n FROM t;
+ERROR:  cannot refer to OLD within WITH query
+--
+-- test for bug #4902
+--
+with cte(foo) as ( values(42) ) values((select foo from cte));
+ column1 
+---------
+      42
+(1 row)
+
+with cte(foo) as ( select 42 ) select * from ((select foo from cte)) q;
+ foo 
+-----
+  42
+(1 row)
+
+-- test CTE referencing an outer-level variable (to see that changed-parameter
+-- signaling still works properly after fixing this bug)
+select ( with cte(foo) as ( values(f1) )
+         select (select foo from cte) )
+from int4_tbl;
+     foo     
+-------------
+           0
+      123456
+     -123456
+  2147483647
+ -2147483647
+(5 rows)
+
+select ( with cte(foo) as ( values(f1) )
+          values((select foo from cte)) )
+from int4_tbl;
+   column1   
+-------------
+           0
+      123456
+     -123456
+  2147483647
+ -2147483647
+(5 rows)
+
+--
+-- test for nested-recursive-WITH bug
+--
+WITH RECURSIVE t(j) AS (
+    WITH RECURSIVE s(i) AS (
+        VALUES (1)
+        UNION ALL
+        SELECT i+1 FROM s WHERE i < 10
+    )
+    SELECT i FROM s
+    UNION ALL
+    SELECT j+1 FROM t WHERE j < 10
+)
+SELECT * FROM t;
+ j  
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+  5
+  6
+  7
+  8
+  9
+ 10
+  6
+  7
+  8
+  9
+ 10
+  7
+  8
+  9
+ 10
+  8
+  9
+ 10
+  9
+ 10
+ 10
+(55 rows)
+
+--
+-- test WITH attached to intermediate-level set operation
+--
+WITH outermost(x) AS (
+  SELECT 1
+  UNION (WITH innermost as (SELECT 2)
+         SELECT * FROM innermost
+         UNION SELECT 3)
+)
+SELECT * FROM outermost ORDER BY 1;
+ x 
+---
+ 1
+ 2
+ 3
+(3 rows)
+
+WITH outermost(x) AS (
+  SELECT 1
+  UNION (WITH innermost as (SELECT 2)
+         SELECT * FROM outermost  -- fail
+         UNION SELECT * FROM innermost)
+)
+SELECT * FROM outermost ORDER BY 1;
+ERROR:  relation "outermost" does not exist
+LINE 4:          SELECT * FROM outermost  
+                               ^
+DETAIL:  There is a WITH item named "outermost", but it cannot be referenced from this part of the query.
+HINT:  Use WITH RECURSIVE, or re-order the WITH items to remove forward references.
+WITH RECURSIVE outermost(x) AS (
+  SELECT 1
+  UNION (WITH innermost as (SELECT 2)
+         SELECT * FROM outermost
+         UNION SELECT * FROM innermost)
+)
+SELECT * FROM outermost ORDER BY 1;
+ x 
+---
+ 1
+ 2
+(2 rows)
+
+WITH RECURSIVE outermost(x) AS (
+  WITH innermost as (SELECT 2 FROM outermost) -- fail
+    SELECT * FROM innermost
+    UNION SELECT * from outermost
+)
+SELECT * FROM outermost ORDER BY 1;
+ERROR:  recursive reference to query "outermost" must not appear within a subquery
+LINE 2:   WITH innermost as (SELECT 2 FROM outermost) 
+                                           ^
+--
+-- This test will fail with the old implementation of PARAM_EXEC parameter
+-- assignment, because the "q1" Var passed down to A's targetlist subselect
+-- looks exactly like the "A.id" Var passed down to C's subselect, causing
+-- the old code to give them the same runtime PARAM_EXEC slot.  But the
+-- lifespans of the two parameters overlap, thanks to B also reading A.
+--
+with
+A as ( select q2 as id, (select q1) as x from int8_tbl ),
+B as ( select id, row_number() over (partition by id) as r from A ),
+C as ( select A.id, array(select B.id from B where B.id = A.id) from A )
+select * from C;
+        id         |                array                
+-------------------+-------------------------------------
+               456 | {456}
+  4567890123456789 | {4567890123456789,4567890123456789}
+               123 | {123}
+  4567890123456789 | {4567890123456789,4567890123456789}
+ -4567890123456789 | {-4567890123456789}
+(5 rows)
+
+--
+-- Test CTEs read in non-initialization orders
+--
+WITH RECURSIVE
+  tab(id_key,link) AS (VALUES (1,17), (2,17), (3,17), (4,17), (6,17), (5,17)),
+  iter (id_key, row_type, link) AS (
+      SELECT 0, 'base', 17
+    UNION ALL (
+      WITH remaining(id_key, row_type, link, min) AS (
+        SELECT tab.id_key, 'true'::text, iter.link, MIN(tab.id_key) OVER ()
+        FROM tab INNER JOIN iter USING (link)
+        WHERE tab.id_key > iter.id_key
+      ),
+      first_remaining AS (
+        SELECT id_key, row_type, link
+        FROM remaining
+        WHERE id_key=min
+      ),
+      effect AS (
+        SELECT tab.id_key, 'new'::text, tab.link
+        FROM first_remaining e INNER JOIN tab ON e.id_key=tab.id_key
+        WHERE e.row_type = 'false'
+      )
+      SELECT * FROM first_remaining
+      UNION ALL SELECT * FROM effect
+    )
+  )
+SELECT * FROM iter;
+ id_key | row_type | link 
+--------+----------+------
+      0 | base     |   17
+      1 | true     |   17
+      2 | true     |   17
+      3 | true     |   17
+      4 | true     |   17
+      5 | true     |   17
+      6 | true     |   17
+(7 rows)
+
+WITH RECURSIVE
+  tab(id_key,link) AS (VALUES (1,17), (2,17), (3,17), (4,17), (6,17), (5,17)),
+  iter (id_key, row_type, link) AS (
+      SELECT 0, 'base', 17
+    UNION (
+      WITH remaining(id_key, row_type, link, min) AS (
+        SELECT tab.id_key, 'true'::text, iter.link, MIN(tab.id_key) OVER ()
+        FROM tab INNER JOIN iter USING (link)
+        WHERE tab.id_key > iter.id_key
+      ),
+      first_remaining AS (
+        SELECT id_key, row_type, link
+        FROM remaining
+        WHERE id_key=min
+      ),
+      effect AS (
+        SELECT tab.id_key, 'new'::text, tab.link
+        FROM first_remaining e INNER JOIN tab ON e.id_key=tab.id_key
+        WHERE e.row_type = 'false'
+      )
+      SELECT * FROM first_remaining
+      UNION ALL SELECT * FROM effect
+    )
+  )
+SELECT * FROM iter;
+ id_key | row_type | link 
+--------+----------+------
+      0 | base     |   17
+      1 | true     |   17
+      2 | true     |   17
+      3 | true     |   17
+      4 | true     |   17
+      5 | true     |   17
+      6 | true     |   17
+(7 rows)
+
+--
+-- Data-modifying statements in WITH
+--
+-- INSERT ... RETURNING
+WITH t AS (
+    INSERT INTO y
+    VALUES
+        (11),
+        (12),
+        (13),
+        (14),
+        (15),
+        (16),
+        (17),
+        (18),
+        (19),
+        (20)
+    RETURNING *
+)
+SELECT * FROM t;
+ a  
+----
+ 11
+ 12
+ 13
+ 14
+ 15
+ 16
+ 17
+ 18
+ 19
+ 20
+(10 rows)
+
+SELECT * FROM y;
+ a  
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+ 11
+ 12
+ 13
+ 14
+ 15
+ 16
+ 17
+ 18
+ 19
+ 20
+(20 rows)
+
+-- UPDATE ... RETURNING
+WITH t AS (
+    UPDATE y
+    SET a=a+1
+    RETURNING *
+)
+SELECT * FROM t;
+ a  
+----
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+ 11
+ 12
+ 13
+ 14
+ 15
+ 16
+ 17
+ 18
+ 19
+ 20
+ 21
+(20 rows)
+
+SELECT * FROM y;
+ a  
+----
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+ 11
+ 12
+ 13
+ 14
+ 15
+ 16
+ 17
+ 18
+ 19
+ 20
+ 21
+(20 rows)
+
+-- DELETE ... RETURNING
+WITH t AS (
+    DELETE FROM y
+    WHERE a <= 10
+    RETURNING *
+)
+SELECT * FROM t;
+ a  
+----
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+(9 rows)
+
+SELECT * FROM y;
+ a  
+----
+ 11
+ 12
+ 13
+ 14
+ 15
+ 16
+ 17
+ 18
+ 19
+ 20
+ 21
+(11 rows)
+
+-- forward reference
+WITH RECURSIVE t AS (
+	INSERT INTO y
+		SELECT a+5 FROM t2 WHERE a > 5
+	RETURNING *
+), t2 AS (
+	UPDATE y SET a=a-11 RETURNING *
+)
+SELECT * FROM t
+UNION ALL
+SELECT * FROM t2;
+ a  
+----
+ 11
+ 12
+ 13
+ 14
+ 15
+  0
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+(16 rows)
+
+SELECT * FROM y;
+ a  
+----
+  0
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+ 11
+ 12
+ 13
+ 14
+ 15
+(16 rows)
+
+-- unconditional DO INSTEAD rule
+CREATE RULE y_rule AS ON DELETE TO y DO INSTEAD
+  INSERT INTO y VALUES(42) RETURNING *;
+WITH t AS (
+	DELETE FROM y RETURNING *
+)
+SELECT * FROM t;
+ a  
+----
+ 42
+(1 row)
+
+SELECT * FROM y;
+ a  
+----
+  0
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+ 11
+ 12
+ 13
+ 14
+ 15
+ 42
+(17 rows)
+
+DROP RULE y_rule ON y;
+-- check merging of outer CTE with CTE in a rule action
+CREATE TEMP TABLE bug6051 AS
+  select i from generate_series(1,3) as t(i);
+SELECT * FROM bug6051;
+ i 
+---
+ 1
+ 2
+ 3
+(3 rows)
+
+WITH t1 AS ( DELETE FROM bug6051 RETURNING * )
+INSERT INTO bug6051 SELECT * FROM t1;
+SELECT * FROM bug6051;
+ i 
+---
+ 1
+ 2
+ 3
+(3 rows)
+
+CREATE TEMP TABLE bug6051_2 (i int);
+CREATE RULE bug6051_ins AS ON INSERT TO bug6051 DO INSTEAD
+ INSERT INTO bug6051_2
+ SELECT NEW.i;
+WITH t1 AS ( DELETE FROM bug6051 RETURNING * )
+INSERT INTO bug6051 SELECT * FROM t1;
+SELECT * FROM bug6051;
+ i 
+---
+(0 rows)
+
+SELECT * FROM bug6051_2;
+ i 
+---
+ 1
+ 2
+ 3
+(3 rows)
+
+-- a truly recursive CTE in the same list
+WITH RECURSIVE t(a) AS (
+	SELECT 0
+		UNION ALL
+	SELECT a+1 FROM t WHERE a+1 < 5
+), t2 as (
+	INSERT INTO y
+		SELECT * FROM t RETURNING *
+)
+SELECT * FROM t2 JOIN y USING (a) ORDER BY a;
+ a 
+---
+ 0
+ 1
+ 2
+ 3
+ 4
+(5 rows)
+
+SELECT * FROM y;
+ a  
+----
+  0
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+ 11
+ 12
+ 13
+ 14
+ 15
+ 42
+  0
+  1
+  2
+  3
+  4
+(22 rows)
+
+-- data-modifying WITH in a modifying statement
+WITH t AS (
+    DELETE FROM y
+    WHERE a <= 10
+    RETURNING *
+)
+INSERT INTO y SELECT -a FROM t RETURNING *;
+  a  
+-----
+   0
+  -1
+  -2
+  -3
+  -4
+  -5
+  -6
+  -7
+  -8
+  -9
+ -10
+   0
+  -1
+  -2
+  -3
+  -4
+(16 rows)
+
+SELECT * FROM y;
+  a  
+-----
+  11
+  12
+  13
+  14
+  15
+  42
+   0
+  -1
+  -2
+  -3
+  -4
+  -5
+  -6
+  -7
+  -8
+  -9
+ -10
+   0
+  -1
+  -2
+  -3
+  -4
+(22 rows)
+
+-- check that WITH query is run to completion even if outer query isn't
+WITH t AS (
+    UPDATE y SET a = a * 100 RETURNING *
+)
+SELECT * FROM t LIMIT 10;
+  a   
+------
+ 1100
+ 1200
+ 1300
+ 1400
+ 1500
+ 4200
+    0
+ -100
+ -200
+ -300
+(10 rows)
+
+SELECT * FROM y;
+   a   
+-------
+  1100
+  1200
+  1300
+  1400
+  1500
+  4200
+     0
+  -100
+  -200
+  -300
+  -400
+  -500
+  -600
+  -700
+  -800
+  -900
+ -1000
+     0
+  -100
+  -200
+  -300
+  -400
+(22 rows)
+
+-- data-modifying WITH containing INSERT...ON CONFLICT DO UPDATE
+CREATE TABLE withz AS SELECT i AS k, (i || ' v')::text v FROM generate_series(1, 16, 3) i;
+ALTER TABLE withz ADD UNIQUE (k);
+WITH t AS (
+    INSERT INTO withz SELECT i, 'insert'
+    FROM generate_series(0, 16) i
+    ON CONFLICT (k) DO UPDATE SET v = withz.v || ', now update'
+    RETURNING *
+)
+SELECT * FROM t JOIN y ON t.k = y.a ORDER BY a, k;
+ k |   v    | a 
+---+--------+---
+ 0 | insert | 0
+ 0 | insert | 0
+(2 rows)
+
+-- Test EXCLUDED.* reference within CTE
+WITH aa AS (
+    INSERT INTO withz VALUES(1, 5) ON CONFLICT (k) DO UPDATE SET v = EXCLUDED.v
+    WHERE withz.k != EXCLUDED.k
+    RETURNING *
+)
+SELECT * FROM aa;
+ k | v 
+---+---
+(0 rows)
+
+-- New query/snapshot demonstrates side-effects of previous query.
+SELECT * FROM withz ORDER BY k;
+ k  |        v         
+----+------------------
+  0 | insert
+  1 | 1 v, now update
+  2 | insert
+  3 | insert
+  4 | 4 v, now update
+  5 | insert
+  6 | insert
+  7 | 7 v, now update
+  8 | insert
+  9 | insert
+ 10 | 10 v, now update
+ 11 | insert
+ 12 | insert
+ 13 | 13 v, now update
+ 14 | insert
+ 15 | insert
+ 16 | 16 v, now update
+(17 rows)
+
+--
+-- Ensure subqueries within the update clause work, even if they
+-- reference outside values
+--
+WITH aa AS (SELECT 1 a, 2 b)
+INSERT INTO withz VALUES(1, 'insert')
+ON CONFLICT (k) DO UPDATE SET v = (SELECT b || ' update' FROM aa WHERE a = 1 LIMIT 1);
+WITH aa AS (SELECT 1 a, 2 b)
+INSERT INTO withz VALUES(1, 'insert')
+ON CONFLICT (k) DO UPDATE SET v = ' update' WHERE withz.k = (SELECT a FROM aa);
+WITH aa AS (SELECT 1 a, 2 b)
+INSERT INTO withz VALUES(1, 'insert')
+ON CONFLICT (k) DO UPDATE SET v = (SELECT b || ' update' FROM aa WHERE a = 1 LIMIT 1);
+WITH aa AS (SELECT 'a' a, 'b' b UNION ALL SELECT 'a' a, 'b' b)
+INSERT INTO withz VALUES(1, 'insert')
+ON CONFLICT (k) DO UPDATE SET v = (SELECT b || ' update' FROM aa WHERE a = 'a' LIMIT 1);
+WITH aa AS (SELECT 1 a, 2 b)
+INSERT INTO withz VALUES(1, (SELECT b || ' insert' FROM aa WHERE a = 1 ))
+ON CONFLICT (k) DO UPDATE SET v = (SELECT b || ' update' FROM aa WHERE a = 1 LIMIT 1);
+-- Update a row more than once, in different parts of a wCTE. That is
+-- an allowed, presumably very rare, edge case, but since it was
+-- broken in the past, having a test seems worthwhile.
+WITH simpletup AS (
+  SELECT 2 k, 'Green' v),
+upsert_cte AS (
+  INSERT INTO withz VALUES(2, 'Blue') ON CONFLICT (k) DO
+    UPDATE SET (k, v) = (SELECT k, v FROM simpletup WHERE simpletup.k = withz.k)
+    RETURNING k, v)
+INSERT INTO withz VALUES(2, 'Red') ON CONFLICT (k) DO
+UPDATE SET (k, v) = (SELECT k, v FROM upsert_cte WHERE upsert_cte.k = withz.k)
+RETURNING k, v;
+ k | v 
+---+---
+(0 rows)
+
+DROP TABLE withz;
+-- check that run to completion happens in proper ordering
+TRUNCATE TABLE y;
+INSERT INTO y SELECT generate_series(1, 3);
+CREATE TEMPORARY TABLE yy (a INTEGER);
+WITH RECURSIVE t1 AS (
+  INSERT INTO y SELECT * FROM y RETURNING *
+), t2 AS (
+  INSERT INTO yy SELECT * FROM t1 RETURNING *
+)
+SELECT 1;
+ ?column? 
+----------
+        1
+(1 row)
+
+SELECT * FROM y;
+ a 
+---
+ 1
+ 2
+ 3
+ 1
+ 2
+ 3
+(6 rows)
+
+SELECT * FROM yy;
+ a 
+---
+ 1
+ 2
+ 3
+(3 rows)
+
+WITH RECURSIVE t1 AS (
+  INSERT INTO yy SELECT * FROM t2 RETURNING *
+), t2 AS (
+  INSERT INTO y SELECT * FROM y RETURNING *
+)
+SELECT 1;
+ ?column? 
+----------
+        1
+(1 row)
+
+SELECT * FROM y;
+ a 
+---
+ 1
+ 2
+ 3
+ 1
+ 2
+ 3
+ 1
+ 2
+ 3
+ 1
+ 2
+ 3
+(12 rows)
+
+SELECT * FROM yy;
+ a 
+---
+ 1
+ 2
+ 3
+ 1
+ 2
+ 3
+ 1
+ 2
+ 3
+(9 rows)
+
+-- triggers
+TRUNCATE TABLE y;
+INSERT INTO y SELECT generate_series(1, 10);
+CREATE FUNCTION y_trigger() RETURNS trigger AS $$
+begin
+  raise notice 'y_trigger: a = %', new.a;
+  return new;
+end;
+$$ LANGUAGE plpgsql;
+CREATE TRIGGER y_trig BEFORE INSERT ON y FOR EACH ROW
+    EXECUTE PROCEDURE y_trigger();
+WITH t AS (
+    INSERT INTO y
+    VALUES
+        (21),
+        (22),
+        (23)
+    RETURNING *
+)
+SELECT * FROM t;
+NOTICE:  y_trigger: a = 21
+NOTICE:  y_trigger: a = 22
+NOTICE:  y_trigger: a = 23
+ a  
+----
+ 21
+ 22
+ 23
+(3 rows)
+
+SELECT * FROM y;
+ a  
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+ 21
+ 22
+ 23
+(13 rows)
+
+DROP TRIGGER y_trig ON y;
+CREATE TRIGGER y_trig AFTER INSERT ON y FOR EACH ROW
+    EXECUTE PROCEDURE y_trigger();
+WITH t AS (
+    INSERT INTO y
+    VALUES
+        (31),
+        (32),
+        (33)
+    RETURNING *
+)
+SELECT * FROM t LIMIT 1;
+NOTICE:  y_trigger: a = 31
+NOTICE:  y_trigger: a = 32
+NOTICE:  y_trigger: a = 33
+ a  
+----
+ 31
+(1 row)
+
+SELECT * FROM y;
+ a  
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+ 21
+ 22
+ 23
+ 31
+ 32
+ 33
+(16 rows)
+
+DROP TRIGGER y_trig ON y;
+CREATE OR REPLACE FUNCTION y_trigger() RETURNS trigger AS $$
+begin
+  raise notice 'y_trigger';
+  return null;
+end;
+$$ LANGUAGE plpgsql;
+CREATE TRIGGER y_trig AFTER INSERT ON y FOR EACH STATEMENT
+    EXECUTE PROCEDURE y_trigger();
+WITH t AS (
+    INSERT INTO y
+    VALUES
+        (41),
+        (42),
+        (43)
+    RETURNING *
+)
+SELECT * FROM t;
+NOTICE:  y_trigger
+ a  
+----
+ 41
+ 42
+ 43
+(3 rows)
+
+SELECT * FROM y;
+ a  
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+  8
+  9
+ 10
+ 21
+ 22
+ 23
+ 31
+ 32
+ 33
+ 41
+ 42
+ 43
+(19 rows)
+
+DROP TRIGGER y_trig ON y;
+DROP FUNCTION y_trigger();
+-- WITH attached to inherited UPDATE or DELETE
+CREATE TEMP TABLE parent ( id int, val text );
+CREATE TEMP TABLE child1 ( ) INHERITS ( parent );
+CREATE TEMP TABLE child2 ( ) INHERITS ( parent );
+INSERT INTO parent VALUES ( 1, 'p1' );
+INSERT INTO child1 VALUES ( 11, 'c11' ),( 12, 'c12' );
+INSERT INTO child2 VALUES ( 23, 'c21' ),( 24, 'c22' );
+WITH rcte AS ( SELECT sum(id) AS totalid FROM parent )
+UPDATE parent SET id = id + totalid FROM rcte;
+SELECT * FROM parent;
+ id | val 
+----+-----
+ 72 | p1
+ 82 | c11
+ 83 | c12
+ 94 | c21
+ 95 | c22
+(5 rows)
+
+WITH wcte AS ( INSERT INTO child1 VALUES ( 42, 'new' ) RETURNING id AS newid )
+UPDATE parent SET id = id + newid FROM wcte;
+SELECT * FROM parent;
+ id  | val 
+-----+-----
+ 114 | p1
+ 124 | c11
+ 125 | c12
+  42 | new
+ 136 | c21
+ 137 | c22
+(6 rows)
+
+WITH rcte AS ( SELECT max(id) AS maxid FROM parent )
+DELETE FROM parent USING rcte WHERE id = maxid;
+SELECT * FROM parent;
+ id  | val 
+-----+-----
+ 114 | p1
+ 124 | c11
+ 125 | c12
+  42 | new
+ 136 | c21
+(5 rows)
+
+WITH wcte AS ( INSERT INTO child2 VALUES ( 42, 'new2' ) RETURNING id AS newid )
+DELETE FROM parent USING wcte WHERE id = newid;
+SELECT * FROM parent;
+ id  | val  
+-----+------
+ 114 | p1
+ 124 | c11
+ 125 | c12
+ 136 | c21
+  42 | new2
+(5 rows)
+
+-- check EXPLAIN VERBOSE for a wCTE with RETURNING
+EXPLAIN (VERBOSE, COSTS OFF)
+WITH wcte AS ( INSERT INTO int8_tbl VALUES ( 42, 47 ) RETURNING q2 )
+DELETE FROM a USING wcte WHERE aa = q2;
+                     QUERY PLAN                     
+----------------------------------------------------
+ Delete on public.a
+   Delete on public.a
+   Delete on public.b
+   Delete on public.c
+   Delete on public.d
+   CTE wcte
+     ->  Insert on public.int8_tbl
+           Output: int8_tbl.q2
+           ->  Result
+                 Output: '42'::bigint, '47'::bigint
+   ->  Nested Loop
+         Output: a.ctid, wcte.*
+         Join Filter: (a.aa = wcte.q2)
+         ->  Seq Scan on public.a
+               Output: a.ctid, a.aa
+         ->  CTE Scan on wcte
+               Output: wcte.*, wcte.q2
+   ->  Nested Loop
+         Output: b.ctid, wcte.*
+         Join Filter: (b.aa = wcte.q2)
+         ->  Seq Scan on public.b
+               Output: b.ctid, b.aa
+         ->  CTE Scan on wcte
+               Output: wcte.*, wcte.q2
+   ->  Nested Loop
+         Output: c.ctid, wcte.*
+         Join Filter: (c.aa = wcte.q2)
+         ->  Seq Scan on public.c
+               Output: c.ctid, c.aa
+         ->  CTE Scan on wcte
+               Output: wcte.*, wcte.q2
+   ->  Nested Loop
+         Output: d.ctid, wcte.*
+         Join Filter: (d.aa = wcte.q2)
+         ->  Seq Scan on public.d
+               Output: d.ctid, d.aa
+         ->  CTE Scan on wcte
+               Output: wcte.*, wcte.q2
+(38 rows)
+
+-- error cases
+-- data-modifying WITH tries to use its own output
+WITH RECURSIVE t AS (
+	INSERT INTO y
+		SELECT * FROM t
+)
+VALUES(FALSE);
+ERROR:  recursive query "t" must not contain data-modifying statements
+LINE 1: WITH RECURSIVE t AS (
+                       ^
+-- no RETURNING in a referenced data-modifying WITH
+WITH t AS (
+	INSERT INTO y VALUES(0)
+)
+SELECT * FROM t;
+ERROR:  WITH query "t" does not have a RETURNING clause
+LINE 4: SELECT * FROM t;
+                      ^
+-- data-modifying WITH allowed only at the top level
+SELECT * FROM (
+	WITH t AS (UPDATE y SET a=a+1 RETURNING *)
+	SELECT * FROM t
+) ss;
+ERROR:  WITH clause containing a data-modifying statement must be at the top level
+LINE 2:  WITH t AS (UPDATE y SET a=a+1 RETURNING *)
+              ^
+-- most variants of rules aren't allowed
+CREATE RULE y_rule AS ON INSERT TO y WHERE a=0 DO INSTEAD DELETE FROM y;
+WITH t AS (
+	INSERT INTO y VALUES(0)
+)
+VALUES(FALSE);
+ERROR:  conditional DO INSTEAD rules are not supported for data-modifying statements in WITH
+DROP RULE y_rule ON y;
+-- check that parser lookahead for WITH doesn't cause any odd behavior
+create table foo (with baz);  -- fail, WITH is a reserved word
+ERROR:  syntax error at or near "with"
+LINE 1: create table foo (with baz);
+                          ^
+create table foo (with ordinality);  -- fail, WITH is a reserved word
+ERROR:  syntax error at or near "with"
+LINE 1: create table foo (with ordinality);
+                          ^
+with ordinality as (select 1 as x) select * from ordinality;
+ x 
+---
+ 1
+(1 row)
+
+-- check sane response to attempt to modify CTE relation
+WITH test AS (SELECT 42) INSERT INTO test VALUES (1);
+ERROR:  relation "test" does not exist
+LINE 1: WITH test AS (SELECT 42) INSERT INTO test VALUES (1);
+                                             ^
+-- check response to attempt to modify table with same name as a CTE (perhaps
+-- surprisingly it works, because CTEs don't hide tables from data-modifying
+-- statements)
+create temp table test (i int);
+with test as (select 42) insert into test select * from test;
+select * from test;
+ i  
+----
+ 42
+(1 row)
+
+drop table test;
diff --git a/src/test/regress/expected/zheap.out b/src/test/regress/expected/zheap.out
new file mode 100644
index 0000000..afc544c
--- /dev/null
+++ b/src/test/regress/expected/zheap.out
@@ -0,0 +1,557 @@
+--
+-- Test cases for ZHeap
+--
+set client_min_messages = warning;
+--
+-- 1. Test for storage engine
+--
+-- Normal heap
+CREATE TABLE t1_heap
+(
+ a int
+);
+\d+ t1_heap;
+                                  Table "public.t1_heap"
+ Column |  Type   | Collation | Nullable | Default | Storage | Stats target | Description 
+--------+---------+-----------+----------+---------+---------+--------------+-------------
+ a      | integer |           |          |         | plain   |              | 
+
+-- Zheap heap
+CREATE TABLE t1_zheap
+(
+ a int
+) USING zheap;
+\d+ t1_zheap;
+                                 Table "public.t1_zheap"
+ Column |  Type   | Collation | Nullable | Default | Storage | Stats target | Description 
+--------+---------+-----------+----------+---------+---------+--------------+-------------
+ a      | integer |           |          |         | plain   |              | 
+
+DROP TABLE t1_heap;
+DROP TABLE t1_zheap;
+--
+-- 2. Test for Index Scan on zheap
+--
+set enable_seqscan to false;
+set enable_indexonlyscan to false;
+set enable_indexscan to true;
+set enable_bitmapscan to false;
+create table btree_zheap_tbl(id int4, t text) USING zheap WITH (autovacuum_enabled=false) ;
+insert into btree_zheap_tbl
+  select g, g::text || '_' ||
+            (select string_agg(md5(i::text), '_') from generate_series(1, 50) i)
+			from generate_series(1, 100) g;
+create index btree_zheap_idx on btree_zheap_tbl (id);
+-- check the plan with index scan
+explain (costs false) select * from btree_zheap_tbl where id=1;
+                     QUERY PLAN                      
+-----------------------------------------------------
+ Index Scan using btree_zheap_idx on btree_zheap_tbl
+   Index Cond: (id = 1)
+(2 rows)
+
+select id from btree_zheap_tbl where id=1;
+ id 
+----
+  1
+(1 row)
+
+-- update a non-key column and delete a row
+update btree_zheap_tbl set t='modified' where id=1;
+select * from btree_zheap_tbl where id = 1;
+ id |    t     
+----+----------
+  1 | modified
+(1 row)
+
+delete from btree_zheap_tbl where id=2;
+select * from btree_zheap_tbl where id = 2;
+ id | t 
+----+---
+(0 rows)
+
+drop table btree_zheap_tbl;
+--
+--3. Test for aggregate nodes
+--
+CREATE TABLE aggtest_zheap
+(
+ a int,
+ b int
+) USING zheap;
+INSERT INTO aggtest_zheap SELECT g,g FROM generate_series(1,1000) g;
+SELECT sum(a) AS sum_198 FROM aggtest_zheap;
+ sum_198 
+---------
+  500500
+(1 row)
+
+SELECT max(aggtest_zheap.a) AS max_3 FROM aggtest_zheap;
+ max_3 
+-------
+  1000
+(1 row)
+
+SELECT stddev_pop(b) FROM aggtest_zheap;
+    stddev_pop    
+------------------
+ 288.674990257210
+(1 row)
+
+SELECT stddev_samp(b) FROM aggtest_zheap;
+   stddev_samp    
+------------------
+ 288.819436095749
+(1 row)
+
+SELECT var_pop(b) FROM aggtest_zheap;
+      var_pop       
+--------------------
+ 83333.250000000000
+(1 row)
+
+SELECT var_samp(b) FROM aggtest_zheap;
+      var_samp      
+--------------------
+ 83416.666666666667
+(1 row)
+
+SELECT stddev_pop(b::numeric) FROM aggtest_zheap;
+    stddev_pop    
+------------------
+ 288.674990257210
+(1 row)
+
+SELECT stddev_samp(b::numeric) FROM aggtest_zheap;
+   stddev_samp    
+------------------
+ 288.819436095749
+(1 row)
+
+SELECT var_pop(b::numeric) FROM aggtest_zheap;
+      var_pop       
+--------------------
+ 83333.250000000000
+(1 row)
+
+SELECT var_samp(b::numeric) FROM aggtest_zheap;
+      var_samp      
+--------------------
+ 83416.666666666667
+(1 row)
+
+DROP TABLE aggtest_zheap;
+set client_min_messages = notice;
+--
+--4. Test for PRIMARY KEY on zheap tables.
+--
+CREATE TABLE pkey_test_zheap
+(
+ a int PRIMARY KEY,
+ b int
+) USING zheap;
+-- should run suucessfully.
+INSERT INTO pkey_test_zheap VALUES (10, 30);
+-- should error out, primary key doesn't allow NULL value.
+INSERT INTO pkey_test_zheap(b) VALUES (30);
+ERROR:  null value in column "a" violates not-null constraint
+DETAIL:  Failing row contains (null, 30).
+-- should error out, primary key doesn't allow duplicate value.
+INSERT INTO pkey_test_zheap VALUES (10, 30);
+ERROR:  duplicate key value violates unique constraint "pkey_test_zheap_pkey"
+DETAIL:  Key (a)=(10) already exists.
+SELECT * FROM pkey_test_zheap;
+ a  | b  
+----+----
+ 10 | 30
+(1 row)
+
+DROP TABLE pkey_test_zheap;
+--
+-- 5.1. Test of non-inlace-update where new update goes to new page.
+--
+CREATE TABLE update_test_zheap(c1 int,c2 char(1000),c3 varchar(10));
+INSERT INTO update_test_zheap VALUES(generate_series(1,7), 'aaa', 'aaa');
+UPDATE update_test_zheap SET c3 = 'bbbb' WHERE c1=1;
+-- verify the update
+SELECT c3 FROM update_test_zheap WHERE c1=1;
+  c3  
+------
+ bbbb
+(1 row)
+
+DROP TABLE update_test_zheap;
+--
+-- 5.2. Test of non-inlace-update on same page and for index key updates.
+--
+set enable_indexonlyscan to false;
+set enable_bitmapscan to false;
+CREATE TABLE update_test_zheap(c1 int PRIMARY KEY, c2 int);
+INSERT INTO update_test_zheap VALUES(generate_series(1,7), 1);
+UPDATE update_test_zheap SET c2 = 100 WHERE c1 = 1;
+UPDATE update_test_zheap SET c2 = 101 WHERE c1 = 2;
+-- verify the update
+SELECT c2 FROM update_test_zheap WHERE c1 IN (1,2);
+ c2  
+-----
+ 100
+ 101
+(2 rows)
+
+DROP TABLE update_test_zheap;
+--
+-- 6. Test for bitmap heap scan - taken from bitmapops.sql
+--
+CREATE TABLE bmscantest (a int, b int, t text) USING zheap;
+INSERT INTO bmscantest
+  SELECT (r%53), (r%59), 'foooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo'
+  FROM generate_series(1,70000) r;
+CREATE INDEX i_bmtest_a ON bmscantest(a);
+CREATE INDEX i_bmtest_b ON bmscantest(b);
+-- We want to use bitmapscans. With default settings, the planner currently
+-- chooses a bitmap scan for the queries below anyway, but let's make sure.
+set enable_indexscan=false;
+set enable_seqscan=false;
+-- Lower work_mem to trigger use of lossy bitmaps
+set work_mem = 64;
+-- Test bitmap-and.
+SELECT count(*) FROM bmscantest WHERE a = 1 AND b = 1;
+ count 
+-------
+    23
+(1 row)
+
+-- Test bitmap-or.
+SELECT count(*) FROM bmscantest WHERE a = 1 OR b = 1;
+ count 
+-------
+  2485
+(1 row)
+
+-- clean up
+DROP TABLE bmscantest;
+--
+-- 7. Test page pruning after a non-inplace-update
+--
+CREATE TABLE update_test_zheap(c1 int,c2 char(1000),c3 varchar(10))
+							   USING zheap;
+INSERT INTO update_test_zheap VALUES(generate_series(1,7), 'aaa', 'aaa');
+UPDATE update_test_zheap SET c3 = 'bbbbb' WHERE c1=1;
+SELECT c1 from update_test_zheap ORDER BY c1;
+ c1 
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+(7 rows)
+
+UPDATE update_test_zheap SET c3 = 'bbbbb' WHERE c1 = 2;
+-- record c1 = 2 should come before c1 = 1 because prune should have
+-- reclaimed space of moved c1 = 1 and hence new c1 = 2 will be inserted
+-- in same page.
+SELECT c1 from update_test_zheap ORDER BY c1;
+ c1 
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+(7 rows)
+
+-- update last record c1 = 2 such that it can be inplace extended.
+UPDATE update_test_zheap SET c3 = 'cccccc' WHERE c1 = 2;
+SELECT c1 from update_test_zheap ORDER BY c1;
+ c1 
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+(7 rows)
+
+-- update another record in the page to force pruning.
+UPDATE update_test_zheap SET c3 = 'bbbbb' WHERE c1 = 7;
+SELECT c1 from update_test_zheap ORDER BY c1;
+ c1 
+----
+  1
+  2
+  3
+  4
+  5
+  6
+  7
+(7 rows)
+
+DROP TABLE update_test_zheap;
+--
+-- 8. verify basic cursor fetch.
+--
+CREATE TABLE cursor_zheap
+(
+	a int
+) USING zheap;
+INSERT INTO cursor_zheap SELECT * FROM generate_series(1, 5);
+SELECT * FROM cursor_zheap;
+ a 
+---
+ 1
+ 2
+ 3
+ 4
+ 5
+(5 rows)
+
+BEGIN;
+	DECLARE cur1 SCROLL CURSOR FOR SELECT * FROM cursor_zheap;
+	FETCH 2 in cur1;
+ a 
+---
+ 1
+ 2
+(2 rows)
+
+	FETCH BACKWARD 2 in cur1;
+ a 
+---
+ 1
+(1 row)
+
+END;
+CREATE MATERIALIZED VIEW mvtest_mv AS SELECT * FROM cursor_zheap;
+DROP MATERIALIZED VIEW mvtest_mv;
+DROP TABLE cursor_zheap;
+-------------------------------------------
+-- Test cases for commit/rollback in SPI --
+-------------------------------------------
+CREATE TABLE test1 (a int, b text) USING zheap;
+CREATE TABLE test2 (x int);
+INSERT INTO test2 VALUES (0), (1), (2), (3), (4);
+TRUNCATE test1;
+DO LANGUAGE plpgsql $$
+DECLARE
+    r RECORD;
+BEGIN
+    FOR r IN SELECT * FROM test2 ORDER BY x LOOP
+        INSERT INTO test1 (a) VALUES (r.x);
+        COMMIT;
+    END LOOP;
+END;
+$$;
+SELECT * FROM test1 order by a, b;
+ a | b 
+---+---
+ 0 | 
+ 1 | 
+ 2 | 
+ 3 | 
+ 4 | 
+(5 rows)
+
+-- error in cursor loop with commit
+TRUNCATE test1;
+DO LANGUAGE plpgsql $$
+DECLARE
+    r RECORD;
+BEGIN
+    FOR r IN SELECT * FROM test2 ORDER BY x LOOP
+        INSERT INTO test1 (a) VALUES (12/(r.x-2));
+        COMMIT;
+    END LOOP;
+END;
+$$;
+ERROR:  division by zero
+CONTEXT:  SQL statement "INSERT INTO test1 (a) VALUES (12/(r.x-2))"
+PL/pgSQL function inline_code_block line 6 at SQL statement
+SELECT * FROM test1 order by a, b;
+  a  | b 
+-----+---
+ -12 | 
+  -6 | 
+(2 rows)
+
+-- rollback inside cursor loop
+TRUNCATE test1;
+DO LANGUAGE plpgsql $$
+DECLARE
+    r RECORD;
+BEGIN
+    FOR r IN SELECT * FROM test2 ORDER BY x LOOP
+        INSERT INTO test1 (a) VALUES (r.x);
+        ROLLBACK;
+    END LOOP;
+END;
+$$;
+SELECT * FROM test1 order by a, b;
+ a | b 
+---+---
+(0 rows)
+
+-- first commit then rollback inside cursor loop
+TRUNCATE test1;
+DO LANGUAGE plpgsql $$
+DECLARE
+    r RECORD;
+BEGIN
+    FOR r IN SELECT * FROM test2 ORDER BY x LOOP
+        INSERT INTO test1 (a) VALUES (r.x);
+        IF r.x % 2 = 0 THEN
+            COMMIT;
+        ELSE
+            ROLLBACK;
+        END IF;
+    END LOOP;
+END;
+$$;
+SELECT * FROM test1 order by a, b;
+ a | b 
+---+---
+ 0 | 
+ 2 | 
+ 4 | 
+(3 rows)
+
+SELECT * FROM pg_cursors;
+ name | statement | is_holdable | is_binary | is_scrollable | creation_time 
+------+-----------+-------------+-----------+---------------+---------------
+(0 rows)
+
+-- commit/rollback with begin exception case
+-- should throw error
+TRUNCATE test1;
+DO LANGUAGE plpgsql $$
+DECLARE
+    r RECORD;
+BEGIN
+    FOR r IN SELECT * FROM test2 ORDER BY x LOOP
+        INSERT INTO test1 (a) VALUES (r.x);
+        IF r.x % 2 = 0 THEN
+            COMMIT;
+        ELSE
+            ROLLBACK;
+        END IF;
+    END LOOP;
+EXCEPTION WHEN OTHERS THEN
+	RAISE NOTICE '% %', SQLERRM, SQLSTATE;
+END;
+$$;
+NOTICE:  cannot commit while a subtransaction is active 2D000
+SELECT * FROM test1 order by a, b;
+ a | b 
+---+---
+(0 rows)
+
+SELECT * FROM test2 order by x;
+ x 
+---
+ 0
+ 1
+ 2
+ 3
+ 4
+(5 rows)
+
+DROP TABLE test1;
+DROP TABLE test2;
+-- rollback of toast table insertion
+CREATE TABLE ctoast (key int primary key, val text) USING zheap;
+CREATE OR REPLACE FUNCTION ctoast_large_val() RETURNS TEXT LANGUAGE SQL AS
+'select array_agg(md5(g::text))::text from generate_series(1, 256) g';
+BEGIN;
+INSERT INTO ctoast (key, val) VALUES (1, ctoast_large_val());
+ROLLBACK;
+DROP TABLE ctoast;
+DROP FUNCTION ctoast_large_val;
+-- check that new relations have no relfrozenxid/relminmxid and that
+-- that's not changed by VACUUM, VACUUM FULL and CLUSTER
+-- new relation
+CREATE TABLE testvacuum(id serial) USING zheap;
+SELECT relfrozenxid, relminmxid FROM pg_class WHERE oid = 'testvacuum'::regclass;
+ relfrozenxid | relminmxid 
+--------------+------------
+            0 |          0
+(1 row)
+
+INSERT INTO testvacuum DEFAULT VALUES;
+SELECT relfrozenxid, relminmxid FROM pg_class WHERE oid = 'testvacuum'::regclass;
+ relfrozenxid | relminmxid 
+--------------+------------
+            0 |          0
+(1 row)
+
+-- plain VACUUM
+VACUUM testvacuum;
+SELECT relfrozenxid, relminmxid FROM pg_class WHERE oid = 'testvacuum'::regclass;
+ relfrozenxid | relminmxid 
+--------------+------------
+            0 |          0
+(1 row)
+
+-- VACUUM FULL
+VACUUM FULL testvacuum;
+SELECT relfrozenxid, relminmxid FROM pg_class WHERE oid = 'testvacuum'::regclass;
+ relfrozenxid | relminmxid 
+--------------+------------
+            0 |          0
+(1 row)
+
+-- CLUSTER
+CREATE INDEX testvacuum_id ON testvacuum(id);
+CLUSTER testvacuum USING testvacuum_id;
+SELECT relfrozenxid, relminmxid FROM pg_class WHERE oid = 'testvacuum'::regclass;
+ relfrozenxid | relminmxid 
+--------------+------------
+            0 |          0
+(1 row)
+
+-- and that there's still content after this ordeal
+SELECT * FROM testvacuum ORDER BY id;
+ id 
+----
+  1
+(1 row)
+
+-- Test multi insert
+CREATE TABLE test_multi_insert(id int) USING zheap;
+INSERT INTO test_multi_insert SELECT generate_series(1,10);
+DELETE FROM test_multi_insert WHERE id%2=0;
+VACUUM test_multi_insert;
+BEGIN;
+COPY test_multi_insert FROM STDIN;
+SELECT * FROM test_multi_insert;
+ id 
+----
+  1
+ 11
+  3
+ 12
+  5
+ 13
+  7
+ 14
+  9
+ 15
+(10 rows)
+
+ROLLBACK;
+SELECT * FROM test_multi_insert;
+ id 
+----
+  1
+  3
+  5
+  7
+  9
+(5 rows)
+
+DROP TABLE test_multi_insert;
diff --git a/src/test/regress/input/constraints.source b/src/test/regress/input/constraints.source
index c325b27..8adde74 100644
--- a/src/test/regress/input/constraints.source
+++ b/src/test/regress/input/constraints.source
@@ -225,9 +225,9 @@ DROP TABLE tmp;
 UPDATE INSERT_TBL SET x = NULL WHERE x = 5;
 UPDATE INSERT_TBL SET x = 6 WHERE x = 6;
 UPDATE INSERT_TBL SET x = -z, z = -x;
-UPDATE INSERT_TBL SET x = z, z = x;
+UPDATE INSERT_TBL SET x = z, z = x WHERE x = 4;
 
-SELECT * FROM INSERT_TBL;
+SELECT * FROM INSERT_TBL ORDER BY x;
 
 -- DROP TABLE INSERT_TBL;
 
@@ -297,7 +297,7 @@ INSERT INTO UNIQUE_TBL VALUES (6, 'six-upsert-insert') ON CONFLICT (i) DO UPDATE
 -- should fail
 INSERT INTO UNIQUE_TBL VALUES (1, 'a'), (2, 'b'), (2, 'b') ON CONFLICT (i) DO UPDATE SET t = 'fails';
 
-SELECT '' AS five, * FROM UNIQUE_TBL;
+SELECT '' AS five, * FROM UNIQUE_TBL ORDER BY i, t;
 
 DROP TABLE UNIQUE_TBL;
 
diff --git a/src/test/regress/input/misc.source b/src/test/regress/input/misc.source
index b1dbc57..b10f8c4 100644
--- a/src/test/regress/input/misc.source
+++ b/src/test/regress/input/misc.source
@@ -149,7 +149,7 @@ ALTER TABLE e_star* ADD COLUMN e int4;
 
 --UPDATE e_star* SET e = 42;
 
-SELECT * FROM e_star*;
+SELECT * FROM e_star* ORDER BY class, aa, cc, ee;
 
 ALTER TABLE a_star* ADD COLUMN a text;
 
@@ -163,7 +163,7 @@ SELECT relname, reltoastrelid <> 0 AS has_toast_table
 --   SET a = text 'gazpacho'
 --   WHERE aa > 4;
 
-SELECT class, aa, a FROM a_star*;
+SELECT class, aa, a FROM a_star* ORDER BY class, aa, a;
 
 
 --
diff --git a/src/test/regress/output/constraints.source b/src/test/regress/output/constraints.source
index e27caed..46814d5 100644
--- a/src/test/regress/output/constraints.source
+++ b/src/test/regress/output/constraints.source
@@ -326,17 +326,17 @@ DROP TABLE tmp;
 UPDATE INSERT_TBL SET x = NULL WHERE x = 5;
 UPDATE INSERT_TBL SET x = 6 WHERE x = 6;
 UPDATE INSERT_TBL SET x = -z, z = -x;
-UPDATE INSERT_TBL SET x = z, z = x;
+UPDATE INSERT_TBL SET x = z, z = x WHERE x = 4;
 ERROR:  new row for relation "insert_tbl" violates check constraint "insert_tbl_con"
 DETAIL:  Failing row contains (-4, Y, 4).
-SELECT * FROM INSERT_TBL;
+SELECT * FROM INSERT_TBL ORDER BY x;
  x |       y       | z  
 ---+---------------+----
  4 | Y             | -4
-   | try again     |   
- 7 | try again     | -7
  5 | !check failed |   
  6 | try again     | -6
+ 7 | try again     | -7
+   | try again     |   
 (5 rows)
 
 -- DROP TABLE INSERT_TBL;
@@ -429,16 +429,16 @@ INSERT INTO UNIQUE_TBL VALUES (6, 'six-upsert-insert') ON CONFLICT (i) DO UPDATE
 INSERT INTO UNIQUE_TBL VALUES (1, 'a'), (2, 'b'), (2, 'b') ON CONFLICT (i) DO UPDATE SET t = 'fails';
 ERROR:  ON CONFLICT DO UPDATE command cannot affect row a second time
 HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.
-SELECT '' AS five, * FROM UNIQUE_TBL;
+SELECT '' AS five, * FROM UNIQUE_TBL ORDER BY i, t;
  five | i |         t          
 ------+---+--------------------
       | 1 | one
       | 2 | two
       | 4 | four
-      |   | six
-      |   | seven
       | 5 | five-upsert-update
       | 6 | six-upsert-insert
+      |   | seven
+      |   | six
 (7 rows)
 
 DROP TABLE UNIQUE_TBL;
diff --git a/src/test/regress/output/misc.source b/src/test/regress/output/misc.source
index b9595cc..d84debe 100644
--- a/src/test/regress/output/misc.source
+++ b/src/test/regress/output/misc.source
@@ -346,30 +346,30 @@ ALTER TABLE f_star ADD COLUMN f int4;
 UPDATE f_star SET f = 10;
 ALTER TABLE e_star* ADD COLUMN e int4;
 --UPDATE e_star* SET e = 42;
-SELECT * FROM e_star*;
+SELECT * FROM e_star* ORDER BY class, aa, cc, ee;
  class | aa |     cc      | ee  | e 
 -------+----+-------------+-----+---
  e     | 15 | hi carol    |  -1 |  
  e     | 16 | hi bob      |     |  
  e     | 17 |             |  -2 |  
- e     |    | hi michelle |  -3 |  
  e     | 18 |             |     |  
  e     |    | hi elisa    |     |  
+ e     |    | hi michelle |  -3 |  
  e     |    |             |  -4 |  
  f     | 19 | hi claire   |  -5 |  
  f     | 20 | hi mike     |  -6 |  
  f     | 21 | hi marcel   |     |  
  f     | 22 |             |  -7 |  
- f     |    | hi keith    |  -8 |  
  f     | 24 | hi marc     |     |  
  f     | 25 |             |  -9 |  
  f     | 26 |             |     |  
- f     |    | hi allison  | -10 |  
- f     |    | hi jeff     |     |  
- f     |    |             | -11 |  
  f     | 27 |             |     |  
+ f     |    | hi allison  | -10 |  
  f     |    | hi carl     |     |  
+ f     |    | hi jeff     |     |  
+ f     |    | hi keith    |  -8 |  
  f     |    |             | -12 |  
+ f     |    |             | -11 |  
  f     |    |             |     |  
  f     |    |             |     |  
 (23 rows)
@@ -390,7 +390,7 @@ SELECT relname, reltoastrelid <> 0 AS has_toast_table
 --UPDATE b_star*
 --   SET a = text 'gazpacho'
 --   WHERE aa > 4;
-SELECT class, aa, a FROM a_star*;
+SELECT class, aa, a FROM a_star* ORDER BY class, aa, a;
  class | aa | a 
 -------+----+---
  a     |  1 | 
@@ -408,14 +408,14 @@ SELECT class, aa, a FROM a_star*;
  d     |  8 | 
  d     |  9 | 
  d     | 10 | 
- d     |    | 
  d     | 11 | 
  d     | 12 | 
  d     | 13 | 
+ d     | 14 | 
+ d     |    | 
  d     |    | 
  d     |    | 
  d     |    | 
- d     | 14 | 
  d     |    | 
  d     |    | 
  d     |    | 
@@ -423,22 +423,22 @@ SELECT class, aa, a FROM a_star*;
  e     | 15 | 
  e     | 16 | 
  e     | 17 | 
- e     |    | 
  e     | 18 | 
  e     |    | 
  e     |    | 
+ e     |    | 
  f     | 19 | 
  f     | 20 | 
  f     | 21 | 
  f     | 22 | 
- f     |    | 
  f     | 24 | 
  f     | 25 | 
  f     | 26 | 
+ f     | 27 | 
+ f     |    | 
  f     |    | 
  f     |    | 
  f     |    | 
- f     | 27 | 
  f     |    | 
  f     |    | 
  f     |    | 
diff --git a/src/test/regress/parallel_schedule b/src/test/regress/parallel_schedule
index 8fb55f0..2b5326e 100644
--- a/src/test/regress/parallel_schedule
+++ b/src/test/regress/parallel_schedule
@@ -120,3 +120,6 @@ test: fast_default
 
 # run stats by itself because its delay may be insufficient under heavy load
 test: stats
+
+# zheap stuffs
+test: zheap
diff --git a/src/test/regress/serial_schedule b/src/test/regress/serial_schedule
index a39ca10..3758031 100644
--- a/src/test/regress/serial_schedule
+++ b/src/test/regress/serial_schedule
@@ -193,3 +193,4 @@ test: partition_info
 test: event_trigger
 test: fast_default
 test: stats
+test: zheap
diff --git a/src/test/regress/sql/arrays.sql b/src/test/regress/sql/arrays.sql
index 25dd4e2..40596c6 100644
--- a/src/test/regress/sql/arrays.sql
+++ b/src/test/regress/sql/arrays.sql
@@ -78,24 +78,24 @@ UPDATE arrtest
   SET c[2:2] = '{"new_word"}'
   WHERE array_dims(c) is not null;
 
-SELECT a,b,c FROM arrtest;
+SELECT a,b,c FROM arrtest ORDER BY a;
 
 SELECT a[1:3],
           b[1:1][1:2][1:2],
           c[1:2],
           d[1:1][2:2]
-   FROM arrtest;
+   FROM arrtest ORDER BY a;
 
 SELECT b[1:1][2][2],
        d[1:1][2]
-   FROM arrtest;
+   FROM arrtest ORDER BY b, d;
 
 INSERT INTO arrtest(a) VALUES('{1,null,3}');
-SELECT a FROM arrtest;
+SELECT a FROM arrtest ORDER BY a;
 UPDATE arrtest SET a[4] = NULL WHERE a[2] IS NULL;
-SELECT a FROM arrtest WHERE a[2] IS NULL;
+SELECT a FROM arrtest WHERE a[2] IS NULL ORDER BY a;
 DELETE FROM arrtest WHERE a[2] IS NULL AND b IS NULL;
-SELECT a,b,c FROM arrtest;
+SELECT a,b,c FROM arrtest ORDER BY a,b,c;
 
 -- test mixed slice/scalar subscripting
 select '{{1,2,3},{4,5,6},{7,8,9}}'::int[];
@@ -139,11 +139,11 @@ SELECT a[:], b[:] FROM arrtest_s;
 -- updates
 UPDATE arrtest_s SET a[:3] = '{11, 12, 13}', b[:2][:2] = '{{11,12}, {14,15}}'
   WHERE array_lower(a,1) = 1;
-SELECT * FROM arrtest_s;
+SELECT * FROM arrtest_s ORDER BY 1;
 UPDATE arrtest_s SET a[3:] = '{23, 24, 25}', b[2:][2:] = '{{25,26}, {28,29}}';
-SELECT * FROM arrtest_s;
+SELECT * FROM arrtest_s ORDER BY 1;
 UPDATE arrtest_s SET a[:] = '{11, 12, 13, 14, 15}';
-SELECT * FROM arrtest_s;
+SELECT * FROM arrtest_s ORDER BY 1;
 UPDATE arrtest_s SET a[:] = '{23, 24, 25}';  -- fail, too small
 INSERT INTO arrtest_s VALUES(NULL, NULL);
 UPDATE arrtest_s SET a[:] = '{11, 12, 13, 14, 15}';  -- fail, no good with null
diff --git a/src/test/regress/sql/box.sql b/src/test/regress/sql/box.sql
index cd3e002..1326a8b 100644
--- a/src/test/regress/sql/box.sql
+++ b/src/test/regress/sql/box.sql
@@ -148,6 +148,7 @@ INSERT INTO box_temp
 		   ('(-infinity,-infinity)(infinity,infinity)');
 
 SET enable_seqscan = false;
+SET enable_bitmapscan = false;
 
 SELECT * FROM box_temp WHERE f1 << '(10,20),(30,40)';
 EXPLAIN (COSTS OFF) SELECT * FROM box_temp WHERE f1 << '(10,20),(30,40)';
diff --git a/src/test/regress/sql/case.sql b/src/test/regress/sql/case.sql
index 17436c5..c79ff85 100644
--- a/src/test/regress/sql/case.sql
+++ b/src/test/regress/sql/case.sql
@@ -145,13 +145,13 @@ UPDATE CASE_TBL
   SET i = CASE WHEN i >= 3 THEN (- i)
                 ELSE (2 * i) END;
 
-SELECT * FROM CASE_TBL;
+SELECT * FROM CASE_TBL ORDER BY i;
 
 UPDATE CASE_TBL
   SET i = CASE WHEN i >= 2 THEN (2 * i)
                 ELSE (3 * i) END;
 
-SELECT * FROM CASE_TBL;
+SELECT * FROM CASE_TBL ORDER BY i;
 
 UPDATE CASE_TBL
   SET i = CASE WHEN b.i >= 2 THEN (2 * j)
@@ -159,7 +159,7 @@ UPDATE CASE_TBL
   FROM CASE2_TBL b
   WHERE j = -CASE_TBL.i;
 
-SELECT * FROM CASE_TBL;
+SELECT * FROM CASE_TBL ORDER BY i;
 
 --
 -- Nested CASE expressions
diff --git a/src/test/regress/sql/float4.sql b/src/test/regress/sql/float4.sql
index afdb469..928a14b 100644
--- a/src/test/regress/sql/float4.sql
+++ b/src/test/regress/sql/float4.sql
@@ -85,7 +85,7 @@ UPDATE FLOAT4_TBL
    SET f1 = FLOAT4_TBL.f1 * '-1'
    WHERE FLOAT4_TBL.f1 > '0.0';
 
-SELECT '' AS five, * FROM FLOAT4_TBL;
+SELECT '' AS five, * FROM FLOAT4_TBL ORDER BY f1 DESC;
 
 -- test edge-case coercions to integer
 SELECT '32767.4'::float4::int2;
diff --git a/src/test/regress/sql/float8.sql b/src/test/regress/sql/float8.sql
index e540f03..fb729f3 100644
--- a/src/test/regress/sql/float8.sql
+++ b/src/test/regress/sql/float8.sql
@@ -152,7 +152,7 @@ SELECT '' AS bad, exp(f.f1) from FLOAT8_TBL f;
 
 SELECT '' AS bad, f.f1 / '0.0' from FLOAT8_TBL f;
 
-SELECT '' AS five, * FROM FLOAT8_TBL;
+SELECT '' AS five, * FROM FLOAT8_TBL ORDER BY f1 DESC;
 
 -- hyperbolic functions
 -- we run these with extra_float_digits = 0 too, since different platforms
diff --git a/src/test/regress/sql/foreign_key.sql b/src/test/regress/sql/foreign_key.sql
index 9c28285..0d3ab22 100644
--- a/src/test/regress/sql/foreign_key.sql
+++ b/src/test/regress/sql/foreign_key.sql
@@ -38,7 +38,7 @@ SELECT * FROM FKTABLE;
 UPDATE PKTABLE SET ptest1=1 WHERE ptest1=2;
 
 -- Check FKTABLE for update of matched row
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2;
 
 DROP TABLE FKTABLE;
 DROP TABLE PKTABLE;
@@ -83,19 +83,19 @@ SELECT * FROM FKTABLE;
 DELETE FROM PKTABLE WHERE ptest1=1 and ptest2=2;
 
 -- Check FKTABLE for removal of matched row
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
 
 -- Delete another row from PK TABLE
 DELETE FROM PKTABLE WHERE ptest1=5 and ptest2=10;
 
 -- Check FKTABLE (should be no change)
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
 
 -- Update a row from PK TABLE
 UPDATE PKTABLE SET ptest1=1 WHERE ptest1=2;
 
 -- Check FKTABLE for update of matched row
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
 
 -- Check update with part of key null
 UPDATE FKTABLE SET ftest1 = NULL WHERE ftest1 = 1;
@@ -107,7 +107,7 @@ UPDATE FKTABLE SET ftest1 = 1 WHERE ftest1 = 1;
 ALTER TABLE PKTABLE ALTER COLUMN ptest1 TYPE bigint;
 ALTER TABLE FKTABLE ALTER COLUMN ftest1 TYPE bigint;
 SELECT * FROM PKTABLE;
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
 
 DROP TABLE PKTABLE CASCADE;
 DROP TABLE FKTABLE;
@@ -150,19 +150,19 @@ SELECT * FROM FKTABLE;
 DELETE FROM PKTABLE WHERE ptest1=1 and ptest2=2;
 
 -- Check FKTABLE to check for removal
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
 
 -- Delete another row from PK TABLE
 DELETE FROM PKTABLE WHERE ptest1=5 and ptest2=10;
 
 -- Check FKTABLE (should be no change)
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
 
 -- Update a row from PK TABLE
 UPDATE PKTABLE SET ptest1=1 WHERE ptest1=2;
 
 -- Check FKTABLE for update of matched row
-SELECT * FROM FKTABLE;
+SELECT * FROM FKTABLE ORDER BY ftest1, ftest2, ftest3;
 
 -- this should fail for lack of CASCADE
 DROP TABLE PKTABLE;
@@ -331,14 +331,14 @@ UPDATE PKTABLE set ptest2=5 where ptest2=2;
 UPDATE PKTABLE set ptest1=1 WHERE ptest2=3;
 
 -- Show PKTABLE and FKTABLE
-SELECT * from PKTABLE;
-SELECT * from FKTABLE;
+SELECT * from PKTABLE ORDER BY ptest1, ptest2, ptest3;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3;
 
 -- Try to delete something that should cascade
 DELETE FROM PKTABLE where ptest1=1 and ptest2=5 and ptest3=3;
 
 -- Show PKTABLE and FKTABLE
-SELECT * from PKTABLE;
+SELECT * from PKTABLE ORDER BY ptest1, ptest2, ptest3;
 SELECT * from FKTABLE;
 
 -- Try to delete something that should not have a cascade
@@ -385,21 +385,21 @@ UPDATE PKTABLE set ptest2=2 WHERE ptest2=3 and ptest1=1;
 
 -- Show PKTABLE and FKTABLE
 SELECT * from PKTABLE;
-SELECT * from FKTABLE;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3, ftest4;
 
 -- Try to delete something that should set default
 DELETE FROM PKTABLE where ptest1=2 and ptest2=3 and ptest3=4;
 
 -- Show PKTABLE and FKTABLE
 SELECT * from PKTABLE;
-SELECT * from FKTABLE;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3, ftest4;
 
 -- Try to delete something that should not set default
 DELETE FROM PKTABLE where ptest2=5;
 
 -- Show PKTABLE and FKTABLE
 SELECT * from PKTABLE;
-SELECT * from FKTABLE;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3, ftest4;
 
 DROP TABLE FKTABLE;
 DROP TABLE PKTABLE;
@@ -444,21 +444,21 @@ UPDATE PKTABLE set ptest2=2 WHERE ptest2=3 and ptest1=1;
 
 -- Show PKTABLE and FKTABLE
 SELECT * from PKTABLE;
-SELECT * from FKTABLE;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3, ftest4;
 
 -- Try to delete something that should set null
 DELETE FROM PKTABLE where ptest1=2 and ptest2=3 and ptest3=4;
 
 -- Show PKTABLE and FKTABLE
 SELECT * from PKTABLE;
-SELECT * from FKTABLE;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3, ftest4;
 
 -- Try to delete something that should not set null
 DELETE FROM PKTABLE where ptest2=-1 and ptest3=5;
 
 -- Show PKTABLE and FKTABLE
 SELECT * from PKTABLE;
-SELECT * from FKTABLE;
+SELECT * from FKTABLE ORDER BY ftest1, ftest2, ftest3, ftest4;
 
 DROP TABLE FKTABLE;
 DROP TABLE PKTABLE;
@@ -982,9 +982,9 @@ SELECT * FROM tasks;
 -- could fail with only 2 changes to make, if row was already updated
 BEGIN;
 UPDATE tasks set id=id WHERE id=2;
-SELECT * FROM tasks;
+SELECT * FROM tasks ORDER BY id;
 DELETE FROM users WHERE id = 2;
-SELECT * FROM tasks;
+SELECT * FROM tasks ORDER BY id;
 COMMIT;
 
 --
diff --git a/src/test/regress/sql/generated.sql b/src/test/regress/sql/generated.sql
index 6a56ae2..b9b312a 100644
--- a/src/test/regress/sql/generated.sql
+++ b/src/test/regress/sql/generated.sql
@@ -56,7 +56,7 @@ SELECT a, b FROM gtest1 WHERE b = 4 ORDER BY a;
 
 -- test that overflow error happens on write
 INSERT INTO gtest1 VALUES (2000000000);
-SELECT * FROM gtest1;
+SELECT * FROM gtest1 ORDER BY a, b;
 DELETE FROM gtest1 WHERE a = 2000000000;
 
 -- test with joins
diff --git a/src/test/regress/sql/identity.sql b/src/test/regress/sql/identity.sql
index 8dcfdf3..7706847 100644
--- a/src/test/regress/sql/identity.sql
+++ b/src/test/regress/sql/identity.sql
@@ -79,11 +79,11 @@ SELECT * FROM itest2;
 
 UPDATE itest1 SET a = 101 WHERE a = 1;
 UPDATE itest1 SET a = DEFAULT WHERE a = 2;
-SELECT * FROM itest1;
+SELECT * FROM itest1 ORDER BY a;
 
 UPDATE itest2 SET a = 101 WHERE a = 1;
 UPDATE itest2 SET a = DEFAULT WHERE a = 2;
-SELECT * FROM itest2;
+SELECT * FROM itest2 ORDER BY a;
 
 
 -- COPY tests
diff --git a/src/test/regress/sql/indirect_toast.sql b/src/test/regress/sql/indirect_toast.sql
index efb1eb4..062e4b0 100644
--- a/src/test/regress/sql/indirect_toast.sql
+++ b/src/test/regress/sql/indirect_toast.sql
@@ -12,17 +12,23 @@ SELECT descr, substring(make_tuple_indirect(indtoasttest)::text, 1, 200) FROM in
 UPDATE indtoasttest SET cnt = cnt +1 RETURNING substring(indtoasttest::text, 1, 200);
 
 -- modification without modifying assigned value
-UPDATE indtoasttest SET cnt = cnt +1, f1 = f1 RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1, f1 = f1 RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
 
 -- modification modifying, but effectively not changing
-UPDATE indtoasttest SET cnt = cnt +1, f1 = f1||'' RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1, f1 = f1||'' RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
 
-UPDATE indtoasttest SET cnt = cnt +1, f1 = '-'||f1||'-' RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1, f1 = '-'||f1||'-' RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
 
-SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest;
+SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest ORDER BY 1;
 -- check we didn't screw with main/toast tuple visibility
 VACUUM FREEZE indtoasttest;
-SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest;
+SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest ORDER BY 1;
 
 -- now create a trigger that forces all Datums to be indirect ones
 CREATE FUNCTION update_using_indirect()
@@ -40,22 +46,30 @@ CREATE TRIGGER indtoasttest_update_indirect
         EXECUTE PROCEDURE update_using_indirect();
 
 -- modification without changing varlenas
-UPDATE indtoasttest SET cnt = cnt +1 RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1 RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
 
 -- modification without modifying assigned value
-UPDATE indtoasttest SET cnt = cnt +1, f1 = f1 RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1, f1 = f1 RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
 
 -- modification modifying, but effectively not changing
-UPDATE indtoasttest SET cnt = cnt +1, f1 = f1||'' RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1, f1 = f1||'' RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
 
-UPDATE indtoasttest SET cnt = cnt +1, f1 = '-'||f1||'-' RETURNING substring(indtoasttest::text, 1, 200);
+WITH updated AS (
+	UPDATE indtoasttest SET cnt = cnt +1, f1 = '-'||f1||'-' RETURNING substring(indtoasttest::text, 1, 200))
+	SELECT * FROM updated ORDER BY substring;
 
 INSERT INTO indtoasttest(descr, f1, f2) VALUES('one-toasted,one-null, via indirect', repeat('1234567890',30000), NULL);
 
-SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest;
+SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest ORDER BY 1;
 -- check we didn't screw with main/toast tuple visibility
 VACUUM FREEZE indtoasttest;
-SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest;
+SELECT substring(indtoasttest::text, 1, 200) FROM indtoasttest ORDER BY 1;
 
 DROP TABLE indtoasttest;
 DROP FUNCTION update_using_indirect();
diff --git a/src/test/regress/sql/inherit.sql b/src/test/regress/sql/inherit.sql
index ae43585..8fc0597 100644
--- a/src/test/regress/sql/inherit.sql
+++ b/src/test/regress/sql/inherit.sql
@@ -49,22 +49,22 @@ UPDATE b SET aa='zzz' WHERE aa='aaa';
 UPDATE ONLY b SET aa='zzz' WHERE aa='aaa';
 UPDATE a SET aa='zzzzzz' WHERE aa LIKE 'aaa%';
 
-SELECT relname, a.* FROM a, pg_class where a.tableoid = pg_class.oid;
+SELECT relname, a.* FROM a, pg_class where a.tableoid = pg_class.oid order by relname, aa;
 SELECT relname, b.* FROM b, pg_class where b.tableoid = pg_class.oid;
 SELECT relname, c.* FROM c, pg_class where c.tableoid = pg_class.oid;
 SELECT relname, d.* FROM d, pg_class where d.tableoid = pg_class.oid;
-SELECT relname, a.* FROM ONLY a, pg_class where a.tableoid = pg_class.oid;
+SELECT relname, a.* FROM ONLY a, pg_class where a.tableoid = pg_class.oid order by relname, aa;
 SELECT relname, b.* FROM ONLY b, pg_class where b.tableoid = pg_class.oid;
 SELECT relname, c.* FROM ONLY c, pg_class where c.tableoid = pg_class.oid;
 SELECT relname, d.* FROM ONLY d, pg_class where d.tableoid = pg_class.oid;
 
 UPDATE b SET aa='new';
 
-SELECT relname, a.* FROM a, pg_class where a.tableoid = pg_class.oid;
+SELECT relname, a.* FROM a, pg_class where a.tableoid = pg_class.oid order by relname, aa;
 SELECT relname, b.* FROM b, pg_class where b.tableoid = pg_class.oid;
 SELECT relname, c.* FROM c, pg_class where c.tableoid = pg_class.oid;
 SELECT relname, d.* FROM d, pg_class where d.tableoid = pg_class.oid;
-SELECT relname, a.* FROM ONLY a, pg_class where a.tableoid = pg_class.oid;
+SELECT relname, a.* FROM ONLY a, pg_class where a.tableoid = pg_class.oid order by relname, aa;
 SELECT relname, b.* FROM ONLY b, pg_class where b.tableoid = pg_class.oid;
 SELECT relname, c.* FROM ONLY c, pg_class where c.tableoid = pg_class.oid;
 SELECT relname, d.* FROM ONLY d, pg_class where d.tableoid = pg_class.oid;
diff --git a/src/test/regress/sql/insert_conflict.sql b/src/test/regress/sql/insert_conflict.sql
index 43691cd..fb73d40 100644
--- a/src/test/regress/sql/insert_conflict.sql
+++ b/src/test/regress/sql/insert_conflict.sql
@@ -338,18 +338,18 @@ insert into cities values ('Las Vegas', 2.583E+5, 2174) on conflict do nothing;
 insert into capitals values ('Sacramento', 4664.E+5, 30, 'CA') on conflict (name) do update set population = excluded.population;
 -- Wrong "Sacramento", so do nothing:
 insert into capitals values ('Sacramento', 50, 2267, 'NE') on conflict (name) do nothing;
-select * from capitals;
+select * from capitals order by name;
 insert into cities values ('Las Vegas', 5.83E+5, 2001) on conflict (name) do update set population = excluded.population, altitude = excluded.altitude;
-select tableoid::regclass, * from cities;
+select tableoid::regclass, * from cities order by name;
 insert into capitals values ('Las Vegas', 5.83E+5, 2222, 'NV') on conflict (name) do update set population = excluded.population;
 -- Capitals will contain new capital, Las Vegas:
-select * from capitals;
+select * from capitals order by name;
 -- Cities contains two instances of "Las Vegas", since unique constraints don't
 -- work across inheritance:
-select tableoid::regclass, * from cities;
+select tableoid::regclass, * from cities order by name;
 -- This only affects "cities" version of "Las Vegas":
 insert into cities values ('Las Vegas', 5.86E+5, 2223) on conflict (name) do update set population = excluded.population, altitude = excluded.altitude;
-select tableoid::regclass, * from cities;
+select tableoid::regclass, * from cities order by name;
 
 -- clean up
 drop table capitals;
diff --git a/src/test/regress/sql/plpgsql.sql b/src/test/regress/sql/plpgsql.sql
index 70deadf..a03b244 100644
--- a/src/test/regress/sql/plpgsql.sql
+++ b/src/test/regress/sql/plpgsql.sql
@@ -1481,7 +1481,7 @@ create function test_found()
   end;' language plpgsql;
 
 select test_found();
-select * from found_test_tbl;
+select * from found_test_tbl order by a;
 
 --
 -- Test set-returning functions for PL/pgSQL
@@ -1497,7 +1497,7 @@ BEGIN
 	RETURN;
 END;' language plpgsql;
 
-select * from test_table_func_rec();
+select * from test_table_func_rec() order by a;
 
 create function test_table_func_row() returns setof found_test_tbl as '
 DECLARE
@@ -1509,7 +1509,7 @@ BEGIN
 	RETURN;
 END;' language plpgsql;
 
-select * from test_table_func_row();
+select * from test_table_func_row() order by a;
 
 create function test_ret_set_scalar(int,int) returns setof int as '
 DECLARE
diff --git a/src/test/regress/sql/portals.sql b/src/test/regress/sql/portals.sql
index 52560ac..15fffe4 100644
--- a/src/test/regress/sql/portals.sql
+++ b/src/test/regress/sql/portals.sql
@@ -345,55 +345,55 @@ BEGIN;
 DECLARE c1 CURSOR FOR SELECT * FROM uctest FOR UPDATE;
 FETCH c1;
 UPDATE uctest SET f1 = 8 WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 COMMIT;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 
 -- Check repeated-update and update-then-delete cases
 BEGIN;
-DECLARE c1 CURSOR FOR SELECT * FROM uctest;
+DECLARE c1 CURSOR FOR SELECT * FROM uctest WHERE f1 = 3;
 FETCH c1;
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 -- insensitive cursor should not show effects of updates or deletes
 FETCH RELATIVE 0 FROM c1;
 DELETE FROM uctest WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 DELETE FROM uctest WHERE CURRENT OF c1; -- no-op
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1; -- no-op
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 FETCH RELATIVE 0 FROM c1;
 ROLLBACK;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 
 BEGIN;
-DECLARE c1 CURSOR FOR SELECT * FROM uctest FOR UPDATE;
+DECLARE c1 CURSOR FOR SELECT * FROM uctest ORDER BY 1 FOR UPDATE;
 FETCH c1;
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 DELETE FROM uctest WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 DELETE FROM uctest WHERE CURRENT OF c1; -- no-op
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1; -- no-op
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 --- sensitive cursors can't currently scroll back, so this is an error:
 FETCH RELATIVE 0 FROM c1;
 ROLLBACK;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 
 -- Check inheritance cases
 CREATE TEMP TABLE ucchild () inherits (uctest);
 INSERT INTO ucchild values(100, 'hundred');
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 
 BEGIN;
-DECLARE c1 CURSOR FOR SELECT * FROM uctest FOR UPDATE;
+DECLARE c1 CURSOR FOR SELECT * FROM uctest ORDER BY 1 FOR UPDATE;
 FETCH 1 FROM c1;
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1;
 FETCH 1 FROM c1;
@@ -402,7 +402,7 @@ FETCH 1 FROM c1;
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1;
 FETCH 1 FROM c1;
 COMMIT;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 
 -- Can update from a self-join, but only if FOR UPDATE says which to use
 BEGIN;
@@ -419,7 +419,7 @@ BEGIN;
 DECLARE c1 CURSOR FOR SELECT * FROM uctest a, uctest b WHERE a.f1 = b.f1 + 5 FOR SHARE OF a;
 FETCH 1 FROM c1;
 UPDATE uctest SET f1 = f1 + 10 WHERE CURRENT OF c1;
-SELECT * FROM uctest;
+SELECT * FROM uctest ORDER BY 1;
 ROLLBACK;
 
 -- Check various error cases
@@ -457,7 +457,7 @@ CREATE TEMP VIEW ucview AS SELECT * FROM uctest;
 CREATE RULE ucrule AS ON DELETE TO ucview DO INSTEAD
   DELETE FROM uctest WHERE f1 = OLD.f1;
 BEGIN;
-DECLARE c1 CURSOR FOR SELECT * FROM ucview;
+DECLARE c1 CURSOR FOR SELECT * FROM ucview ORDER BY 1;
 FETCH FROM c1;
 DELETE FROM ucview WHERE CURRENT OF c1; -- fail, views not supported
 ROLLBACK;
diff --git a/src/test/regress/sql/reloptions.sql b/src/test/regress/sql/reloptions.sql
index cac5b0b..34abc22 100644
--- a/src/test/regress/sql/reloptions.sql
+++ b/src/test/regress/sql/reloptions.sql
@@ -1,5 +1,7 @@
 
 -- Simple create
+CREATE TABLE reloptions_empty(i INT);
+
 CREATE TABLE reloptions_test(i INT) WITH (FiLLFaCToR=30,
 	autovacuum_enabled = false, autovacuum_analyze_scale_factor = 0.2);
 SELECT reloptions FROM pg_class WHERE oid = 'reloptions_test'::regclass;
@@ -62,7 +64,7 @@ CREATE TABLE reloptions_test(i INT NOT NULL, j text)
 SELECT reloptions FROM pg_class WHERE oid = 'reloptions_test'::regclass;
 INSERT INTO reloptions_test VALUES (1, NULL), (NULL, NULL);
 VACUUM reloptions_test;
-SELECT pg_relation_size('reloptions_test') > 0;
+SELECT pg_relation_size('reloptions_test') > pg_relation_size('reloptions_empty');
 
 SELECT reloptions FROM pg_class WHERE oid =
 	(SELECT reltoastrelid FROM pg_class
@@ -72,7 +74,7 @@ ALTER TABLE reloptions_test RESET (vacuum_truncate);
 SELECT reloptions FROM pg_class WHERE oid = 'reloptions_test'::regclass;
 INSERT INTO reloptions_test VALUES (1, NULL), (NULL, NULL);
 VACUUM reloptions_test;
-SELECT pg_relation_size('reloptions_test') = 0;
+SELECT pg_relation_size('reloptions_test') = pg_relation_size('reloptions_empty');
 
 -- Test toast.* options
 DROP TABLE reloptions_test;
diff --git a/src/test/regress/sql/rowsecurity.sql b/src/test/regress/sql/rowsecurity.sql
index 6797330..370f2ed 100644
--- a/src/test/regress/sql/rowsecurity.sql
+++ b/src/test/regress/sql/rowsecurity.sql
@@ -36,11 +36,15 @@ GRANT ALL ON SCHEMA regress_rls_schema to public;
 SET search_path = regress_rls_schema;
 
 -- setup of malicious function
+
+CREATE TEMP TABLE f_leak_table(a text);
 CREATE OR REPLACE FUNCTION f_leak(text) RETURNS bool
     COST 0.0000001 LANGUAGE plpgsql
-    AS 'BEGIN RAISE NOTICE ''f_leak => %'', $1; RETURN true; END';
+    AS 'BEGIN INSERT INTO f_leak_table values($1); RETURN true; END';
+GRANT INSERT, SELECT,TRUNCATE ON TABLE f_leak_table TO public;
 GRANT EXECUTE ON FUNCTION f_leak(text) TO public;
 
+
 -- BASIC Row-Level Security Scenario
 
 SET SESSION AUTHORIZATION regress_rls_alice;
@@ -115,20 +119,34 @@ SELECT * FROM pg_policies WHERE schemaname = 'regress_rls_schema' AND tablename
 SET SESSION AUTHORIZATION regress_rls_bob;
 SET row_security TO ON;
 SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 -- try a sampled version
 SELECT * FROM document TABLESAMPLE BERNOULLI(50) REPEATABLE(0)
   WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 -- viewpoint from regress_rls_carol
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 -- try a sampled version
 SELECT * FROM document TABLESAMPLE BERNOULLI(50) REPEATABLE(0)
   WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 EXPLAIN (COSTS OFF) SELECT * FROM document WHERE f_leak(dtitle);
 EXPLAIN (COSTS OFF) SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle);
@@ -136,7 +154,12 @@ EXPLAIN (COSTS OFF) SELECT * FROM document NATURAL JOIN category WHERE f_leak(dt
 -- viewpoint from regress_rls_dave
 SET SESSION AUTHORIZATION regress_rls_dave;
 SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 EXPLAIN (COSTS OFF) SELECT * FROM document WHERE f_leak(dtitle);
 EXPLAIN (COSTS OFF) SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle);
@@ -157,12 +180,22 @@ ALTER POLICY p1 ON document USING (dauthor = current_user);
 -- viewpoint from regress_rls_bob again
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER by did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 -- viewpoint from rls_regres_carol again
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM document WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle) ORDER by did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 EXPLAIN (COSTS OFF) SELECT * FROM document WHERE f_leak(dtitle);
 EXPLAIN (COSTS OFF) SELECT * FROM document NATURAL JOIN category WHERE f_leak(dtitle);
@@ -275,6 +308,9 @@ SELECT * FROM t1;
 EXPLAIN (COSTS OFF) SELECT * FROM t1;
 
 SELECT * FROM t1 WHERE f_leak(b);
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b);
 
 -- reference to system column
@@ -290,6 +326,9 @@ SELECT * FROM t1 FOR SHARE;
 EXPLAIN (COSTS OFF) SELECT * FROM t1 FOR SHARE;
 
 SELECT * FROM t1 WHERE f_leak(b) FOR SHARE;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b) FOR SHARE;
 
 -- union all query
@@ -300,12 +339,18 @@ EXPLAIN (COSTS OFF) SELECT a, b, tableoid::regclass FROM t2 UNION ALL SELECT a,
 RESET SESSION AUTHORIZATION;
 SET row_security TO OFF;
 SELECT * FROM t1 WHERE f_leak(b);
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b);
 
 -- non-superuser with bypass privilege can bypass RLS policy when disabled
 SET SESSION AUTHORIZATION regress_rls_exempt_user;
 SET row_security TO OFF;
 SELECT * FROM t1 WHERE f_leak(b);
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b);
 
 --
@@ -362,16 +407,25 @@ SELECT * FROM pg_policies WHERE schemaname = 'regress_rls_schema' AND tablename
 SET SESSION AUTHORIZATION regress_rls_bob;
 SET row_security TO ON;
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
 
 -- viewpoint from regress_rls_carol
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
 
 -- viewpoint from regress_rls_dave
 SET SESSION AUTHORIZATION regress_rls_dave;
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
 
 -- pp1 ERROR
@@ -386,8 +440,13 @@ INSERT INTO part_document VALUES (100, 55, 1, 'regress_rls_dave', 'testing RLS w
 INSERT INTO part_document_satire VALUES (100, 55, 1, 'regress_rls_dave', 'testing RLS with partitions'); -- success
 -- We still cannot see the row using the parent
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 -- But we can if we look directly
 SELECT * FROM part_document_satire WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 -- Turn on RLS and create policy on child to show RLS is checked before constraints
 SET SESSION AUTHORIZATION regress_rls_alice;
@@ -399,14 +458,23 @@ SET SESSION AUTHORIZATION regress_rls_dave;
 INSERT INTO part_document_satire VALUES (101, 55, 1, 'regress_rls_dave', 'testing RLS with partitions'); -- fail
 -- And now we cannot see directly into the partition either, due to RLS
 SELECT * FROM part_document_satire WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 -- The parent looks same as before
 -- viewpoint from regress_rls_dave
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
 
 -- viewpoint from regress_rls_carol
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
 
 -- only owner can change policies
@@ -419,10 +487,14 @@ ALTER POLICY pp1 ON part_document USING (dauthor = current_user);
 -- viewpoint from regress_rls_bob again
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 -- viewpoint from rls_regres_carol again
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM part_document WHERE f_leak(dtitle) ORDER BY did;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 EXPLAIN (COSTS OFF) SELECT * FROM part_document WHERE f_leak(dtitle);
 
@@ -551,6 +623,8 @@ ALTER TABLE s2 ENABLE ROW LEVEL SECURITY;
 SET SESSION AUTHORIZATION regress_rls_bob;
 CREATE VIEW v2 AS SELECT * FROM s2 WHERE y like '%af%';
 SELECT * FROM s1 WHERE f_leak(b); -- fail (infinite recursion)
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 INSERT INTO s1 VALUES (1, 'foo'); -- fail (infinite recursion)
 
@@ -560,12 +634,18 @@ ALTER POLICY p2 ON s2 USING (x % 2 = 0);
 
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM s1 WHERE f_leak(b);	-- OK
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM only s1 WHERE f_leak(b);
 
 SET SESSION AUTHORIZATION regress_rls_alice;
 ALTER POLICY p1 ON s1 USING (a in (select x from v2)); -- using VIEW in RLS policy
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM s1 WHERE f_leak(b);	-- OK
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM s1 WHERE f_leak(b);
 
 SELECT (SELECT x FROM s1 LIMIT 1) xx, * FROM s2 WHERE y like '%28%';
@@ -575,6 +655,8 @@ SET SESSION AUTHORIZATION regress_rls_alice;
 ALTER POLICY p2 ON s2 USING (x in (select a from s1 where b like '%d2%'));
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM s1 WHERE f_leak(b);	-- fail (infinite recursion via view)
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 -- prepared statement with regress_rls_alice privilege
 PREPARE p1(int) AS SELECT * FROM t1 WHERE a <= $1;
@@ -585,6 +667,9 @@ EXPLAIN (COSTS OFF) EXECUTE p1(2);
 RESET SESSION AUTHORIZATION;
 SET row_security TO OFF;
 SELECT * FROM t1 WHERE f_leak(b);
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM t1 WHERE f_leak(b);
 
 -- plan cache should be invalidated
@@ -607,14 +692,30 @@ EXPLAIN (COSTS OFF) EXECUTE p2(2);
 SET SESSION AUTHORIZATION regress_rls_bob;
 EXPLAIN (COSTS OFF) UPDATE t1 SET b = b || b WHERE f_leak(b);
 UPDATE t1 SET b = b || b WHERE f_leak(b);
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 EXPLAIN (COSTS OFF) UPDATE only t1 SET b = b || '_updt' WHERE f_leak(b);
 UPDATE only t1 SET b = b || '_updt' WHERE f_leak(b);
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
 -- returning clause with system column
-UPDATE only t1 SET b = b WHERE f_leak(b) RETURNING tableoid::regclass, *, t1;
-UPDATE t1 SET b = b WHERE f_leak(b) RETURNING *;
-UPDATE t1 SET b = b WHERE f_leak(b) RETURNING tableoid::regclass, *, t1;
+WITH UPDATED AS (UPDATE only t1 SET b = b WHERE f_leak(b)
+RETURNING tableoid::regclass, *, t1) SELECT * FROM UPDATED ORDER BY (a,b);
+
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
+WITH UPDATED AS (UPDATE t1 SET b = b WHERE f_leak(b)
+RETURNING *) SELECT * FROM UPDATED ORDER BY (a,b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
+WITH UPDATED AS (UPDATE t1 SET b = b WHERE f_leak(b)
+RETURNING tableoid::regclass, *, t1) SELECT * FROM UPDATED ORDER BY (a,b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
 
 -- updates with from clause
 EXPLAIN (COSTS OFF) UPDATE t2 SET b=t2.b FROM t3
@@ -622,35 +723,45 @@ WHERE t2.a = 3 and t3.a = 2 AND f_leak(t2.b) AND f_leak(t3.b);
 
 UPDATE t2 SET b=t2.b FROM t3
 WHERE t2.a = 3 and t3.a = 2 AND f_leak(t2.b) AND f_leak(t3.b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
 
 EXPLAIN (COSTS OFF) UPDATE t1 SET b=t1.b FROM t2
 WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
 
 UPDATE t1 SET b=t1.b FROM t2
 WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
 
 EXPLAIN (COSTS OFF) UPDATE t2 SET b=t2.b FROM t1
 WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
 
 UPDATE t2 SET b=t2.b FROM t1
 WHERE t1.a = 3 and t2.a = 3 AND f_leak(t1.b) AND f_leak(t2.b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
 
 -- updates with from clause self join
 EXPLAIN (COSTS OFF) UPDATE t2 t2_1 SET b = t2_2.b FROM t2 t2_2
 WHERE t2_1.a = 3 AND t2_2.a = t2_1.a AND t2_2.b = t2_1.b
 AND f_leak(t2_1.b) AND f_leak(t2_2.b) RETURNING *, t2_1, t2_2;
 
-UPDATE t2 t2_1 SET b = t2_2.b FROM t2 t2_2
+WITH UPDATED AS (UPDATE t2 t2_1 SET b = t2_2.b FROM t2 t2_2
 WHERE t2_1.a = 3 AND t2_2.a = t2_1.a AND t2_2.b = t2_1.b
-AND f_leak(t2_1.b) AND f_leak(t2_2.b) RETURNING *, t2_1, t2_2;
+AND f_leak(t2_1.b) AND f_leak(t2_2.b) RETURNING *, t2_1.a d, t2_2.b e) SELECT * FROM UPDATED ORDER BY (d,e);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
 
 EXPLAIN (COSTS OFF) UPDATE t1 t1_1 SET b = t1_2.b FROM t1 t1_2
 WHERE t1_1.a = 4 AND t1_2.a = t1_1.a AND t1_2.b = t1_1.b
 AND f_leak(t1_1.b) AND f_leak(t1_2.b) RETURNING *, t1_1, t1_2;
 
-UPDATE t1 t1_1 SET b = t1_2.b FROM t1 t1_2
+WITH UPDATED AS (UPDATE t1 t1_1 SET b = t1_2.b FROM t1 t1_2
 WHERE t1_1.a = 4 AND t1_2.a = t1_1.a AND t1_2.b = t1_1.b
-AND f_leak(t1_1.b) AND f_leak(t1_2.b) RETURNING *, t1_1, t1_2;
+AND f_leak(t1_1.b) AND f_leak(t1_2.b) RETURNING *, t1_1.a d, t1_2.b e) SELECT * FROM UPDATED ORDER BY (d,e);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
 
 RESET SESSION AUTHORIZATION;
 SET row_security TO OFF;
@@ -661,9 +772,13 @@ SET row_security TO ON;
 EXPLAIN (COSTS OFF) DELETE FROM only t1 WHERE f_leak(b);
 EXPLAIN (COSTS OFF) DELETE FROM t1 WHERE f_leak(b);
 
-DELETE FROM only t1 WHERE f_leak(b) RETURNING tableoid::regclass, *, t1;
-DELETE FROM t1 WHERE f_leak(b) RETURNING tableoid::regclass, *, t1;
+WITH CTE1 AS (DELETE FROM only t1 WHERE f_leak(b) RETURNING tableoid::regclass, *, t1) SELECT * FROM CTE1 ORDER BY (a,b);
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 
+WITH CTE1 AS (DELETE FROM t1 WHERE f_leak(b) RETURNING tableoid::regclass, *, t1) SELECT * FROM CTE1 ORDER BY (a,b);
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 --
 -- S.b. view on top of Row-level security
 --
@@ -683,6 +798,8 @@ SET SESSION AUTHORIZATION regress_rls_carol;
 
 EXPLAIN (COSTS OFF) SELECT * FROM bv1 WHERE f_leak(b);
 SELECT * FROM bv1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
 
 INSERT INTO bv1 VALUES (-1, 'xxx'); -- should fail view WCO
 INSERT INTO bv1 VALUES (11, 'xxx'); -- should fail RLS check
@@ -690,12 +807,16 @@ INSERT INTO bv1 VALUES (12, 'xxx'); -- ok
 
 EXPLAIN (COSTS OFF) UPDATE bv1 SET b = 'yyy' WHERE a = 4 AND f_leak(b);
 UPDATE bv1 SET b = 'yyy' WHERE a = 4 AND f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
 
 EXPLAIN (COSTS OFF) DELETE FROM bv1 WHERE a = 6 AND f_leak(b);
 DELETE FROM bv1 WHERE a = 6 AND f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
 
 SET SESSION AUTHORIZATION regress_rls_alice;
-SELECT * FROM b1;
+SELECT * FROM b1 ORDER BY a;
 --
 -- INSERT ... ON CONFLICT DO UPDATE and Row-level security
 --
@@ -833,19 +954,34 @@ ALTER TABLE z1 ENABLE ROW LEVEL SECURITY;
 
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM z1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM z1 WHERE f_leak(b);
 
 PREPARE plancache_test AS SELECT * FROM z1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF) EXECUTE plancache_test;
 
 PREPARE plancache_test2 AS WITH q AS MATERIALIZED (SELECT * FROM z1 WHERE f_leak(b)) SELECT * FROM q,z2;
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF) EXECUTE plancache_test2;
 
 PREPARE plancache_test3 AS WITH q AS MATERIALIZED (SELECT * FROM z2) SELECT * FROM q,z1 WHERE f_leak(z1.b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF) EXECUTE plancache_test3;
 
 SET ROLE regress_rls_group1;
 SELECT * FROM z1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM z1 WHERE f_leak(b);
 
 EXPLAIN (COSTS OFF) EXECUTE plancache_test;
@@ -854,6 +990,9 @@ EXPLAIN (COSTS OFF) EXECUTE plancache_test3;
 
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM z1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM z1 WHERE f_leak(b);
 
 EXPLAIN (COSTS OFF) EXECUTE plancache_test;
@@ -862,6 +1001,9 @@ EXPLAIN (COSTS OFF) EXECUTE plancache_test3;
 
 SET ROLE regress_rls_group2;
 SELECT * FROM z1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM z1 WHERE f_leak(b);
 
 EXPLAIN (COSTS OFF) EXECUTE plancache_test;
@@ -879,11 +1021,17 @@ GRANT SELECT ON rls_view TO regress_rls_bob;
 -- Query as role that is not owner of view or table.  Should return all records.
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM rls_view;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
 
 -- Query as view/table owner.  Should return all records.
 SET SESSION AUTHORIZATION regress_rls_alice;
 SELECT * FROM rls_view;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
 DROP VIEW rls_view;
 
@@ -896,23 +1044,35 @@ GRANT SELECT ON rls_view TO regress_rls_alice;
 -- Should return records based on view owner policies.
 SET SESSION AUTHORIZATION regress_rls_alice;
 SELECT * FROM rls_view;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
 
 -- Query as role that is not owner of table but is owner of view.
 -- Should return records based on view owner policies.
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM rls_view;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
 
 -- Query as role that is not the owner of the table or view without permissions.
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM rls_view; --fail - permission denied.
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM rls_view; --fail - permission denied.
 
 -- Query as role that is not the owner of the table or view with permissions.
 SET SESSION AUTHORIZATION regress_rls_bob;
 GRANT SELECT ON rls_view TO regress_rls_carol;
 SELECT * FROM rls_view;
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM rls_view;
 
 SET SESSION AUTHORIZATION regress_rls_bob;
@@ -946,12 +1106,27 @@ ALTER TABLE x1 ENABLE ROW LEVEL SECURITY;
 
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM x1 WHERE f_leak(b) ORDER BY a ASC;
-UPDATE x1 SET b = b || '_updt' WHERE f_leak(b) RETURNING *;
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
+WITH UPDATED AS (UPDATE x1 SET b = b || '_updt' WHERE f_leak(b)
+RETURNING *) SELECT * FROM UPDATED ORDER BY (a,b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
 
 SET SESSION AUTHORIZATION regress_rls_carol;
 SELECT * FROM x1 WHERE f_leak(b) ORDER BY a ASC;
-UPDATE x1 SET b = b || '_updt' WHERE f_leak(b) RETURNING *;
-DELETE FROM x1 WHERE f_leak(b) RETURNING *;
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
+WITH UPDATED AS (UPDATE x1 SET b = b || '_updt' WHERE f_leak(b)
+RETURNING *) SELECT * FROM UPDATED ORDER BY (a,b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
+WITH cte1 AS (DELETE FROM x1 WHERE f_leak(b) RETURNING *) SELECT * FROM cte1 ORDER BY (a,b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
 
 --
 -- Duplicate Policy Names
@@ -977,6 +1152,9 @@ ALTER TABLE y2 ENABLE ROW LEVEL SECURITY;
 SET SESSION AUTHORIZATION regress_rls_alice;
 CREATE VIEW rls_sbv WITH (security_barrier) AS
     SELECT * FROM y1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM rls_sbv WHERE (a = 1);
 DROP VIEW rls_sbv;
 
@@ -984,6 +1162,9 @@ DROP VIEW rls_sbv;
 SET SESSION AUTHORIZATION regress_rls_bob;
 CREATE VIEW rls_sbv WITH (security_barrier) AS
     SELECT * FROM y1 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM rls_sbv WHERE (a = 1);
 DROP VIEW rls_sbv;
 
@@ -997,12 +1178,18 @@ CREATE POLICY p3 ON y2 USING (a % 4 = 0);
 
 SET SESSION AUTHORIZATION regress_rls_bob;
 SELECT * FROM y2 WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM y2 WHERE f_leak(b);
 
 --
 -- Qual push-down of leaky functions, when not referring to table
 --
 SELECT * FROM y2 WHERE f_leak('abc');
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM y2 WHERE f_leak('abc');
 
 CREATE TABLE test_qual_pushdown (
@@ -1012,9 +1199,15 @@ CREATE TABLE test_qual_pushdown (
 INSERT INTO test_qual_pushdown VALUES ('abc'),('def');
 
 SELECT * FROM y2 JOIN test_qual_pushdown ON (b = abc) WHERE f_leak(abc);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM y2 JOIN test_qual_pushdown ON (b = abc) WHERE f_leak(abc);
 
 SELECT * FROM y2 JOIN test_qual_pushdown ON (b = abc) WHERE f_leak(b);
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF) SELECT * FROM y2 JOIN test_qual_pushdown ON (b = abc) WHERE f_leak(b);
 
 DROP TABLE test_qual_pushdown;
@@ -1068,6 +1261,9 @@ INSERT INTO t1 (SELECT x, md5(x::text) FROM generate_series(0,20) x);
 SET SESSION AUTHORIZATION regress_rls_bob;
 
 WITH cte1 AS MATERIALIZED (SELECT * FROM t1 WHERE f_leak(b)) SELECT * FROM cte1;
+SELECT * from f_leak_table ORDER BY a;
+TRUNCATE table f_leak_table;
+
 EXPLAIN (COSTS OFF)
 WITH cte1 AS MATERIALIZED (SELECT * FROM t1 WHERE f_leak(b)) SELECT * FROM cte1;
 
@@ -1165,12 +1361,12 @@ ALTER TABLE t1 OWNER TO regress_rls_alice;
 
 -- Check that default deny does not apply to superuser.
 RESET SESSION AUTHORIZATION;
-SELECT * FROM t1;
+SELECT * FROM t1 ORDER BY a;
 EXPLAIN (COSTS OFF) SELECT * FROM t1;
 
 -- Check that default deny does not apply to table owner.
 SET SESSION AUTHORIZATION regress_rls_alice;
-SELECT * FROM t1;
+SELECT * FROM t1 ORDER BY a;
 EXPLAIN (COSTS OFF) SELECT * FROM t1;
 
 -- Check that default deny applies to non-owner/non-superuser when RLS on.
@@ -1784,6 +1980,8 @@ SET SESSION AUTHORIZATION regress_rls_alice;
 SELECT * FROM ref_tbl; -- Permission denied
 SELECT * FROM rls_tbl; -- Permission denied
 SELECT * FROM rls_view; -- OK
+SELECT * FROM f_leak_table ORDER BY a;
+TRUNCATE TABLE f_leak_table;
 RESET SESSION AUTHORIZATION;
 
 DROP VIEW rls_view;
diff --git a/src/test/regress/sql/rules.sql b/src/test/regress/sql/rules.sql
index a042e59..629c3cf 100644
--- a/src/test/regress/sql/rules.sql
+++ b/src/test/regress/sql/rules.sql
@@ -212,11 +212,11 @@ select * from rtest_v1;
 
 -- now updates with constant expression
 update rtest_v1 set b = 42 where a = 2;
-select * from rtest_v1;
+select * from rtest_v1 order by a;
 update rtest_v1 set b = 99 where b = 42;
-select * from rtest_v1;
+select * from rtest_v1 order by a;
 update rtest_v1 set b = 88 where b < 50;
-select * from rtest_v1;
+select * from rtest_v1 order by a;
 delete from rtest_v1;
 insert into rtest_v1 select rtest_t2.a, rtest_t3.b
     from rtest_t2, rtest_t3
@@ -225,13 +225,13 @@ select * from rtest_v1;
 
 -- updates in a mergejoin
 update rtest_v1 set b = rtest_t2.b from rtest_t2 where rtest_v1.a = rtest_t2.a;
-select * from rtest_v1;
+select * from rtest_v1 order by a;
 insert into rtest_v1 select * from rtest_t3;
-select * from rtest_v1;
+select * from rtest_v1 order by a, b;
 update rtest_t1 set a = a + 10 where b > 30;
-select * from rtest_v1;
+select * from rtest_v1 order by a;
 update rtest_v1 set a = rtest_t3.a + 20 from rtest_t3 where rtest_v1.b = rtest_t3.b;
-select * from rtest_v1;
+select * from rtest_v1 order by a, b;
 
 --
 -- Test for constraint updates/deletes
@@ -268,7 +268,7 @@ select * from rtest_admin order by pname, sysname;
 delete from rtest_system where sysname = 'orion';
 
 select * from rtest_interface;
-select * from rtest_admin;
+select * from rtest_admin order by pname, sysname;
 
 --
 -- Rule qualification test
@@ -975,8 +975,8 @@ insert into t1 select * from generate_series(5,19,1) g;
 update t1 set a = 4 where a = 5;
 
 select * from only t1;
-select * from only t1_1;
-select * from only t1_2;
+select * from only t1_1 order by a;
+select * from only t1_2 order by a;
 
 reset constraint_exclusion;
 
diff --git a/src/test/regress/sql/transactions.sql b/src/test/regress/sql/transactions.sql
index 812e40a..f5e7f8c 100644
--- a/src/test/regress/sql/transactions.sql
+++ b/src/test/regress/sql/transactions.sql
@@ -286,7 +286,7 @@ create or replace function max_xacttest() returns smallint language sql as
 
 begin;
 update xacttest set a = max_xacttest() + 10 where a > 0;
-select * from xacttest;
+select * from xacttest order by a, b;
 rollback;
 
 -- But a volatile function can see the partial results of the calling query
@@ -295,7 +295,7 @@ create or replace function max_xacttest() returns smallint language sql as
 
 begin;
 update xacttest set a = max_xacttest() + 10 where a > 0;
-select * from xacttest;
+select * from xacttest order by a, b;
 rollback;
 
 -- Now the same test with plpgsql (since it depends on SPI which is different)
@@ -304,7 +304,7 @@ create or replace function max_xacttest() returns smallint language plpgsql as
 
 begin;
 update xacttest set a = max_xacttest() + 10 where a > 0;
-select * from xacttest;
+select * from xacttest order by a, b;
 rollback;
 
 create or replace function max_xacttest() returns smallint language plpgsql as
@@ -312,7 +312,7 @@ create or replace function max_xacttest() returns smallint language plpgsql as
 
 begin;
 update xacttest set a = max_xacttest() + 10 where a > 0;
-select * from xacttest;
+select * from xacttest order by a, b;
 rollback;
 
 
diff --git a/src/test/regress/sql/triggers.sql b/src/test/regress/sql/triggers.sql
index 4534dc9..903bb95 100644
--- a/src/test/regress/sql/triggers.sql
+++ b/src/test/regress/sql/triggers.sql
@@ -5,7 +5,7 @@
 create table pkeys (pkey1 int4 not null, pkey2 text not null);
 create table fkeys (fkey1 int4, fkey2 text, fkey3 int);
 create table fkeys2 (fkey21 int4, fkey22 text, pkey23 int not null);
-
+create temp table tmp_del_table (a text);
 create index fkeys_i on fkeys (fkey1, fkey2);
 create index fkeys2_i on fkeys2 (fkey21, fkey22);
 create index fkeys2p_i on fkeys2 (pkey23);
@@ -154,22 +154,22 @@ select * from tttest where price_off = 999999;
 
 -- change price for price_id == 3
 update tttest set price_val = 30 where price_id = 3;
-select * from tttest;
+select * from tttest order by price_id, price_val;
 
 -- now we want to change pric_id in ALL tuples
 -- this gets us not what we need
 update tttest set price_id = 5 where price_id = 3;
-select * from tttest;
+select * from tttest order by price_id, price_val;
 
 -- restore data as before last update:
 select set_ttdummy(0);
 delete from tttest where price_id = 5;
 update tttest set price_off = 999999 where price_val = 30;
-select * from tttest;
+select * from tttest order by price_id, price_val;
 
 -- and try change price_id now!
 update tttest set price_id = 5 where price_id = 3;
-select * from tttest;
+select * from tttest order by price_id, price_val;
 -- isn't it what we need ?
 
 select set_ttdummy(1);
@@ -181,7 +181,7 @@ update tttest set price_on = -1 where price_id = 1;
 -- try in this way
 select set_ttdummy(0);
 update tttest set price_on = -1 where price_id = 1;
-select * from tttest;
+select * from tttest order by price_id, price_val;
 -- isn't it what we need ?
 
 -- get price for price_id == 5 as it was @ "date" 35
@@ -644,7 +644,7 @@ begin
         end if;
 
         if TG_OP = 'DELETE' then
-            raise NOTICE 'OLD: %', OLD;
+            insert into tmp_del_table values (OLD);
             DELETE FROM main_table WHERE a = OLD.a AND b = OLD.b;
             if NOT FOUND then RETURN NULL; end if;
             RETURN OLD;
@@ -654,7 +654,6 @@ begin
     RETURN NULL;
 end;
 $$;
-
 -- Before row triggers aren't allowed on views
 CREATE TRIGGER invalid_trig BEFORE INSERT ON main_view
 FOR EACH ROW EXECUTE PROCEDURE trigger_func('before_ins_row');
@@ -754,7 +753,11 @@ UPDATE main_view SET b = 0 WHERE false;
 
 -- Delete from view using trigger
 DELETE FROM main_view WHERE a IN (20,21);
+select * from tmp_del_table order by 1;
+truncate table tmp_del_table;
 DELETE FROM main_view WHERE a = 31 RETURNING a, b;
+select * from tmp_del_table order by 1;
+truncate table tmp_del_table;
 
 \set QUIET true
 
@@ -953,7 +956,7 @@ UPDATE city_view v SET population = 599657
 
 \set QUIET true
 
-SELECT * FROM city_view;
+SELECT * FROM city_view ORDER BY city_id;
 
 DROP TABLE city_table CASCADE;
 DROP TABLE country_table;
@@ -1167,7 +1170,7 @@ insert into self_ref_trigger values (5, 3, 'grandchild 2');
 
 update self_ref_trigger set data = 'root!' where id = 1;
 
-select * from self_ref_trigger;
+select * from self_ref_trigger order by id;
 
 delete from self_ref_trigger;
 
@@ -2132,7 +2135,7 @@ insert into trig_table values
 
 update refd_table set a = 11 where b = 'one';
 
-select * from trig_table;
+select * from trig_table order by a, b;
 
 delete from refd_table where length(b) = 3;
 
diff --git a/src/test/regress/sql/updatable_views.sql b/src/test/regress/sql/updatable_views.sql
index e50a4c5..b731fbe 100644
--- a/src/test/regress/sql/updatable_views.sql
+++ b/src/test/regress/sql/updatable_views.sql
@@ -583,7 +583,7 @@ CREATE TRIGGER rw_view1_ins_trig AFTER INSERT ON base_tbl
 CREATE VIEW rw_view1 AS SELECT a AS aa, b AS bb FROM base_tbl;
 
 INSERT INTO rw_view1 VALUES (3, 'Row 3');
-select * from base_tbl;
+select * from base_tbl ORDER BY a;
 
 DROP VIEW rw_view1;
 DROP TRIGGER rw_view1_ins_trig on base_tbl;
@@ -745,7 +745,7 @@ UPDATE rw_view1 SET b = 5 WHERE a = 3; -- ok
 UPDATE rw_view1 SET b = -5 WHERE a = 3; -- should fail
 INSERT INTO rw_view1(a) VALUES (9); -- ok
 INSERT INTO rw_view1(a) VALUES (10); -- should fail
-SELECT * FROM base_tbl;
+SELECT * FROM base_tbl order by a, b;
 
 DROP TABLE base_tbl CASCADE;
 
@@ -774,7 +774,7 @@ SELECT * FROM information_schema.views WHERE table_name = 'rw_view2';
 
 INSERT INTO rw_view2 VALUES (-10); -- ok, but not in view
 INSERT INTO rw_view2 VALUES (20); -- should fail
-SELECT * FROM base_tbl;
+SELECT * FROM base_tbl order by a;
 
 ALTER VIEW rw_view1 SET (check_option=here); -- invalid
 ALTER VIEW rw_view1 SET (check_option=local);
@@ -786,7 +786,7 @@ ALTER VIEW rw_view2 RESET (check_option);
 \d+ rw_view2
 SELECT * FROM information_schema.views WHERE table_name = 'rw_view2';
 INSERT INTO rw_view2 VALUES (30); -- ok, but not in view
-SELECT * FROM base_tbl;
+SELECT * FROM base_tbl order by a;
 
 DROP TABLE base_tbl CASCADE;
 
@@ -910,14 +910,14 @@ INSERT INTO rw_view2 VALUES (-5); -- should fail
 INSERT INTO rw_view2 VALUES (5); -- ok
 INSERT INTO rw_view2 VALUES (50); -- ok, but not in view
 UPDATE rw_view2 SET a = a - 10; -- should fail
-SELECT * FROM base_tbl;
+SELECT * FROM base_tbl order by a, b;
 
 -- Check option won't cascade down to base view with INSTEAD OF triggers
 
 ALTER VIEW rw_view2 SET (check_option=cascaded);
 INSERT INTO rw_view2 VALUES (100); -- ok, but not in view (doesn't fail rw_view1's check)
 UPDATE rw_view2 SET a = 200 WHERE a = 5; -- ok, but not in view (doesn't fail rw_view1's check)
-SELECT * FROM base_tbl;
+SELECT * FROM base_tbl ORDER BY a;
 
 -- Neither local nor cascaded check options work with INSTEAD rules
 
@@ -932,7 +932,7 @@ INSERT INTO rw_view2 VALUES (20); -- ok, but not in view (doesn't fail rw_view1'
 UPDATE rw_view2 SET a = 30 WHERE a = 5; -- ok, but not in view (doesn't fail rw_view1's check)
 INSERT INTO rw_view2 VALUES (5); -- ok
 UPDATE rw_view2 SET a = -5 WHERE a = 5; -- ok, but not in view (doesn't fail rw_view2's check)
-SELECT * FROM base_tbl;
+SELECT * FROM base_tbl ORDER BY a;
 
 DROP TABLE base_tbl CASCADE;
 DROP FUNCTION rw_view1_trig_fn();
diff --git a/src/test/regress/sql/update.sql b/src/test/regress/sql/update.sql
index 8754ccb..f95b076 100644
--- a/src/test/regress/sql/update.sql
+++ b/src/test/regress/sql/update.sql
@@ -16,20 +16,20 @@ CREATE TABLE upsert_test (
 INSERT INTO update_test VALUES (5, 10, 'foo');
 INSERT INTO update_test(b, a) VALUES (15, 10);
 
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
 
 UPDATE update_test SET a = DEFAULT, b = DEFAULT;
 
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
 
 -- aliases for the UPDATE target table
 UPDATE update_test AS t SET b = 10 WHERE t.a = 10;
 
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
 
 UPDATE update_test t SET b = t.b + 10 WHERE t.a = 10;
 
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
 
 --
 -- Test VALUES in FROM
@@ -38,7 +38,7 @@ SELECT * FROM update_test;
 UPDATE update_test SET a=v.i FROM (VALUES(100, 20)) AS v(i, j)
   WHERE update_test.b = v.j;
 
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
 
 -- fail, wrong data type:
 UPDATE update_test SET a = v.* FROM (VALUES(100, 20)) AS v(i, j)
@@ -49,12 +49,12 @@ UPDATE update_test SET a = v.* FROM (VALUES(100, 20)) AS v(i, j)
 --
 
 INSERT INTO update_test SELECT a,b+1,c FROM update_test;
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
 
 UPDATE update_test SET (c,b,a) = ('bugle', b+11, DEFAULT) WHERE c = 'foo';
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
 UPDATE update_test SET (c,b) = ('car', a+b), a = a + 1 WHERE a = 10;
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
 -- fail, multi assignment to same column:
 UPDATE update_test SET (c,b) = ('car', a+b), b = a + 1 WHERE a = 10;
 
@@ -62,18 +62,18 @@ UPDATE update_test SET (c,b) = ('car', a+b), b = a + 1 WHERE a = 10;
 UPDATE update_test
   SET (b,a) = (select a,b from update_test where b = 41 and c = 'car')
   WHERE a = 100 AND b = 20;
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
 -- correlated sub-select:
 UPDATE update_test o
   SET (b,a) = (select a+1,b from update_test i
                where i.a=o.a and i.b=o.b and i.c is not distinct from o.c);
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
 -- fail, multiple rows supplied:
 UPDATE update_test SET (b,a) = (select a+1,b from update_test);
 -- set to null if no rows supplied:
 UPDATE update_test SET (b,a) = (select a+1,b from update_test where a = 1000)
   WHERE a = 11;
-SELECT * FROM update_test;
+SELECT * FROM update_test ORDER BY 1, 2, 3;
 -- *-expansion should work in this context:
 UPDATE update_test SET (a,b) = ROW(v.*) FROM (VALUES(21, 100)) AS v(i, j)
   WHERE update_test.a = v.i;
@@ -87,7 +87,7 @@ UPDATE update_test AS t SET b = update_test.b + 10 WHERE t.a = 10;
 
 -- Make sure that we can update to a TOASTed value.
 UPDATE update_test SET c = repeat('x', 10000) WHERE c = 'car';
-SELECT a, b, char_length(c) FROM update_test;
+SELECT a, b, char_length(c) FROM update_test ORDER BY 1, 2, 3;
 
 -- Check multi-assignment with a Result node to handle a one-time filter.
 EXPLAIN (VERBOSE, COSTS OFF)
@@ -97,7 +97,7 @@ UPDATE update_test t
 UPDATE update_test t
   SET (a, b) = (SELECT b, a FROM update_test s WHERE s.a = t.a)
   WHERE CURRENT_USER = SESSION_USER;
-SELECT a, b, char_length(c) FROM update_test;
+SELECT a, b, char_length(c) FROM update_test ORDER BY a, b;
 
 -- Test ON CONFLICT DO UPDATE
 INSERT INTO upsert_test VALUES(1, 'Boo');
@@ -188,13 +188,17 @@ UPDATE range_parted set e = d;
 -- No row found
 UPDATE part_c_1_100 set c = c + 20 WHERE c = 98;
 -- ok, row movement
-UPDATE part_b_10_b_20 set c = c + 20 returning c, b, a;
+WITH updated as
+   (UPDATE part_b_10_b_20 set c = c + 20 returning c, b, a)
+   SELECT * FROM updated ORDER BY 1, 2, 3;
 :show_data;
 
 -- fail, row movement happens only within the partition subtree.
 UPDATE part_b_10_b_20 set b = b - 6 WHERE c > 116 returning *;
 -- ok, row movement, with subset of rows moved into different partition.
-UPDATE range_parted set b = b - 6 WHERE c > 116 returning a, b + c;
+WITH updated as
+   (UPDATE range_parted set b = b - 6 WHERE c > 116 returning a, b + c)
+   SELECT * FROM updated ORDER BY 1, 2;
 
 :show_data;
 
@@ -220,7 +224,9 @@ DROP VIEW upview;
 
 -- RETURNING having whole-row vars.
 :init_range_parted;
-UPDATE range_parted set c = 95 WHERE a = 'b' and b > 10 and c > 100 returning (range_parted), *;
+WITH updated as
+   (UPDATE range_parted set c = 95 WHERE a = 'b' and b > 10 and c > 100 returning (range_parted), *)
+   SELECT * FROM updated ORDER BY 1, 2, 3, 4;
 :show_data;
 
 
diff --git a/src/test/regress/sql/vacuum.sql b/src/test/regress/sql/vacuum.sql
index 6ffb495..532636b 100644
--- a/src/test/regress/sql/vacuum.sql
+++ b/src/test/regress/sql/vacuum.sql
@@ -111,15 +111,17 @@ VACUUM (INDEX_CLEANUP FALSE) vactst; -- index cleanup option is ignored if no in
 VACUUM (INDEX_CLEANUP FALSE, FREEZE TRUE) vaccluster;
 
 -- TRUNCATE option
+CREATE TABLE vac_truncate_test_empty(i INT NOT NULL, j text);
 CREATE TABLE vac_truncate_test(i INT NOT NULL, j text)
 	WITH (vacuum_truncate=true, autovacuum_enabled=false);
 INSERT INTO vac_truncate_test VALUES (1, NULL), (NULL, NULL);
 VACUUM (TRUNCATE FALSE) vac_truncate_test;
-SELECT pg_relation_size('vac_truncate_test') > 0;
+SELECT pg_relation_size('vac_truncate_test') > pg_relation_size('vac_truncate_test_empty');
 VACUUM vac_truncate_test;
-SELECT pg_relation_size('vac_truncate_test') = 0;
+SELECT pg_relation_size('vac_truncate_test') = pg_relation_size('vac_truncate_test_empty');
 VACUUM (TRUNCATE FALSE, FULL TRUE) vac_truncate_test;
 DROP TABLE vac_truncate_test;
+DROP TABLE vac_truncate_test_empty;
 
 -- partitioned table
 CREATE TABLE vacparted (a int, b char) PARTITION BY LIST (a);
diff --git a/src/test/regress/sql/zheap.sql b/src/test/regress/sql/zheap.sql
new file mode 100644
index 0000000..2221e95
--- /dev/null
+++ b/src/test/regress/sql/zheap.sql
@@ -0,0 +1,362 @@
+--
+-- Test cases for ZHeap
+--
+set client_min_messages = warning;
+--
+-- 1. Test for storage engine
+--
+
+-- Normal heap
+CREATE TABLE t1_heap
+(
+ a int
+);
+\d+ t1_heap;
+
+-- Zheap heap
+CREATE TABLE t1_zheap
+(
+ a int
+) USING zheap;
+\d+ t1_zheap;
+
+DROP TABLE t1_heap;
+DROP TABLE t1_zheap;
+
+--
+-- 2. Test for Index Scan on zheap
+--
+set enable_seqscan to false;
+set enable_indexonlyscan to false;
+set enable_indexscan to true;
+set enable_bitmapscan to false;
+
+create table btree_zheap_tbl(id int4, t text) USING zheap WITH (autovacuum_enabled=false) ;
+insert into btree_zheap_tbl
+  select g, g::text || '_' ||
+            (select string_agg(md5(i::text), '_') from generate_series(1, 50) i)
+			from generate_series(1, 100) g;
+create index btree_zheap_idx on btree_zheap_tbl (id);
+
+-- check the plan with index scan
+explain (costs false) select * from btree_zheap_tbl where id=1;
+select id from btree_zheap_tbl where id=1;
+
+-- update a non-key column and delete a row
+update btree_zheap_tbl set t='modified' where id=1;
+select * from btree_zheap_tbl where id = 1;
+delete from btree_zheap_tbl where id=2;
+select * from btree_zheap_tbl where id = 2;
+
+drop table btree_zheap_tbl;
+
+
+--
+--3. Test for aggregate nodes
+--
+CREATE TABLE aggtest_zheap
+(
+ a int,
+ b int
+) USING zheap;
+INSERT INTO aggtest_zheap SELECT g,g FROM generate_series(1,1000) g;
+
+SELECT sum(a) AS sum_198 FROM aggtest_zheap;
+SELECT max(aggtest_zheap.a) AS max_3 FROM aggtest_zheap;
+SELECT stddev_pop(b) FROM aggtest_zheap;
+SELECT stddev_samp(b) FROM aggtest_zheap;
+SELECT var_pop(b) FROM aggtest_zheap;
+SELECT var_samp(b) FROM aggtest_zheap;
+SELECT stddev_pop(b::numeric) FROM aggtest_zheap;
+SELECT stddev_samp(b::numeric) FROM aggtest_zheap;
+SELECT var_pop(b::numeric) FROM aggtest_zheap;
+SELECT var_samp(b::numeric) FROM aggtest_zheap;
+
+DROP TABLE aggtest_zheap;
+set client_min_messages = notice;
+
+--
+--4. Test for PRIMARY KEY on zheap tables.
+--
+CREATE TABLE pkey_test_zheap
+(
+ a int PRIMARY KEY,
+ b int
+) USING zheap;
+
+-- should run suucessfully.
+INSERT INTO pkey_test_zheap VALUES (10, 30);
+
+-- should error out, primary key doesn't allow NULL value.
+INSERT INTO pkey_test_zheap(b) VALUES (30);
+
+-- should error out, primary key doesn't allow duplicate value.
+INSERT INTO pkey_test_zheap VALUES (10, 30);
+
+SELECT * FROM pkey_test_zheap;
+
+DROP TABLE pkey_test_zheap;
+
+--
+-- 5.1. Test of non-inlace-update where new update goes to new page.
+--
+CREATE TABLE update_test_zheap(c1 int,c2 char(1000),c3 varchar(10));
+INSERT INTO update_test_zheap VALUES(generate_series(1,7), 'aaa', 'aaa');
+UPDATE update_test_zheap SET c3 = 'bbbb' WHERE c1=1;
+
+-- verify the update
+SELECT c3 FROM update_test_zheap WHERE c1=1;
+DROP TABLE update_test_zheap;
+
+--
+-- 5.2. Test of non-inlace-update on same page and for index key updates.
+--
+set enable_indexonlyscan to false;
+set enable_bitmapscan to false;
+CREATE TABLE update_test_zheap(c1 int PRIMARY KEY, c2 int);
+INSERT INTO update_test_zheap VALUES(generate_series(1,7), 1);
+UPDATE update_test_zheap SET c2 = 100 WHERE c1 = 1;
+UPDATE update_test_zheap SET c2 = 101 WHERE c1 = 2;
+
+-- verify the update
+SELECT c2 FROM update_test_zheap WHERE c1 IN (1,2);
+DROP TABLE update_test_zheap;
+
+--
+-- 6. Test for bitmap heap scan - taken from bitmapops.sql
+--
+
+CREATE TABLE bmscantest (a int, b int, t text) USING zheap;
+
+INSERT INTO bmscantest
+  SELECT (r%53), (r%59), 'foooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo'
+  FROM generate_series(1,70000) r;
+
+CREATE INDEX i_bmtest_a ON bmscantest(a);
+CREATE INDEX i_bmtest_b ON bmscantest(b);
+
+-- We want to use bitmapscans. With default settings, the planner currently
+-- chooses a bitmap scan for the queries below anyway, but let's make sure.
+set enable_indexscan=false;
+set enable_seqscan=false;
+
+-- Lower work_mem to trigger use of lossy bitmaps
+set work_mem = 64;
+
+
+-- Test bitmap-and.
+SELECT count(*) FROM bmscantest WHERE a = 1 AND b = 1;
+
+-- Test bitmap-or.
+SELECT count(*) FROM bmscantest WHERE a = 1 OR b = 1;
+
+
+-- clean up
+DROP TABLE bmscantest;
+
+--
+-- 7. Test page pruning after a non-inplace-update
+--
+CREATE TABLE update_test_zheap(c1 int,c2 char(1000),c3 varchar(10))
+							   USING zheap;
+INSERT INTO update_test_zheap VALUES(generate_series(1,7), 'aaa', 'aaa');
+UPDATE update_test_zheap SET c3 = 'bbbbb' WHERE c1=1;
+
+SELECT c1 from update_test_zheap ORDER BY c1;
+
+UPDATE update_test_zheap SET c3 = 'bbbbb' WHERE c1 = 2;
+
+-- record c1 = 2 should come before c1 = 1 because prune should have
+-- reclaimed space of moved c1 = 1 and hence new c1 = 2 will be inserted
+-- in same page.
+SELECT c1 from update_test_zheap ORDER BY c1;
+
+-- update last record c1 = 2 such that it can be inplace extended.
+UPDATE update_test_zheap SET c3 = 'cccccc' WHERE c1 = 2;
+SELECT c1 from update_test_zheap ORDER BY c1;
+
+-- update another record in the page to force pruning.
+UPDATE update_test_zheap SET c3 = 'bbbbb' WHERE c1 = 7;
+SELECT c1 from update_test_zheap ORDER BY c1;
+
+DROP TABLE update_test_zheap;
+
+--
+-- 8. verify basic cursor fetch.
+--
+CREATE TABLE cursor_zheap
+(
+	a int
+) USING zheap;
+
+INSERT INTO cursor_zheap SELECT * FROM generate_series(1, 5);
+
+SELECT * FROM cursor_zheap;
+
+BEGIN;
+	DECLARE cur1 SCROLL CURSOR FOR SELECT * FROM cursor_zheap;
+	FETCH 2 in cur1;
+	FETCH BACKWARD 2 in cur1;
+END;
+
+CREATE MATERIALIZED VIEW mvtest_mv AS SELECT * FROM cursor_zheap;
+
+DROP MATERIALIZED VIEW mvtest_mv;
+DROP TABLE cursor_zheap;
+
+-------------------------------------------
+-- Test cases for commit/rollback in SPI --
+-------------------------------------------
+
+CREATE TABLE test1 (a int, b text) USING zheap;
+CREATE TABLE test2 (x int);
+INSERT INTO test2 VALUES (0), (1), (2), (3), (4);
+
+TRUNCATE test1;
+
+DO LANGUAGE plpgsql $$
+DECLARE
+    r RECORD;
+BEGIN
+    FOR r IN SELECT * FROM test2 ORDER BY x LOOP
+        INSERT INTO test1 (a) VALUES (r.x);
+        COMMIT;
+    END LOOP;
+END;
+$$;
+
+SELECT * FROM test1 order by a, b;
+
+-- error in cursor loop with commit
+TRUNCATE test1;
+
+DO LANGUAGE plpgsql $$
+DECLARE
+    r RECORD;
+BEGIN
+    FOR r IN SELECT * FROM test2 ORDER BY x LOOP
+        INSERT INTO test1 (a) VALUES (12/(r.x-2));
+        COMMIT;
+    END LOOP;
+END;
+$$;
+
+SELECT * FROM test1 order by a, b;
+
+-- rollback inside cursor loop
+TRUNCATE test1;
+
+DO LANGUAGE plpgsql $$
+DECLARE
+    r RECORD;
+BEGIN
+    FOR r IN SELECT * FROM test2 ORDER BY x LOOP
+        INSERT INTO test1 (a) VALUES (r.x);
+        ROLLBACK;
+    END LOOP;
+END;
+$$;
+
+SELECT * FROM test1 order by a, b;
+
+-- first commit then rollback inside cursor loop
+TRUNCATE test1;
+
+DO LANGUAGE plpgsql $$
+DECLARE
+    r RECORD;
+BEGIN
+    FOR r IN SELECT * FROM test2 ORDER BY x LOOP
+        INSERT INTO test1 (a) VALUES (r.x);
+        IF r.x % 2 = 0 THEN
+            COMMIT;
+        ELSE
+            ROLLBACK;
+        END IF;
+    END LOOP;
+END;
+$$;
+
+SELECT * FROM test1 order by a, b;
+
+SELECT * FROM pg_cursors;
+
+-- commit/rollback with begin exception case
+-- should throw error
+TRUNCATE test1;
+
+DO LANGUAGE plpgsql $$
+DECLARE
+    r RECORD;
+BEGIN
+    FOR r IN SELECT * FROM test2 ORDER BY x LOOP
+        INSERT INTO test1 (a) VALUES (r.x);
+        IF r.x % 2 = 0 THEN
+            COMMIT;
+        ELSE
+            ROLLBACK;
+        END IF;
+    END LOOP;
+EXCEPTION WHEN OTHERS THEN
+	RAISE NOTICE '% %', SQLERRM, SQLSTATE;
+END;
+$$;
+
+SELECT * FROM test1 order by a, b;
+SELECT * FROM test2 order by x;
+
+DROP TABLE test1;
+DROP TABLE test2;
+
+-- rollback of toast table insertion
+CREATE TABLE ctoast (key int primary key, val text) USING zheap;
+CREATE OR REPLACE FUNCTION ctoast_large_val() RETURNS TEXT LANGUAGE SQL AS
+'select array_agg(md5(g::text))::text from generate_series(1, 256) g';
+BEGIN;
+INSERT INTO ctoast (key, val) VALUES (1, ctoast_large_val());
+ROLLBACK;
+DROP TABLE ctoast;
+DROP FUNCTION ctoast_large_val;
+
+-- check that new relations have no relfrozenxid/relminmxid and that
+-- that's not changed by VACUUM, VACUUM FULL and CLUSTER
+
+-- new relation
+CREATE TABLE testvacuum(id serial) USING zheap;
+SELECT relfrozenxid, relminmxid FROM pg_class WHERE oid = 'testvacuum'::regclass;
+INSERT INTO testvacuum DEFAULT VALUES;
+SELECT relfrozenxid, relminmxid FROM pg_class WHERE oid = 'testvacuum'::regclass;
+
+-- plain VACUUM
+VACUUM testvacuum;
+SELECT relfrozenxid, relminmxid FROM pg_class WHERE oid = 'testvacuum'::regclass;
+
+-- VACUUM FULL
+VACUUM FULL testvacuum;
+SELECT relfrozenxid, relminmxid FROM pg_class WHERE oid = 'testvacuum'::regclass;
+
+-- CLUSTER
+CREATE INDEX testvacuum_id ON testvacuum(id);
+CLUSTER testvacuum USING testvacuum_id;
+SELECT relfrozenxid, relminmxid FROM pg_class WHERE oid = 'testvacuum'::regclass;
+
+-- and that there's still content after this ordeal
+SELECT * FROM testvacuum ORDER BY id;
+
+-- Test multi insert
+CREATE TABLE test_multi_insert(id int) USING zheap;
+INSERT INTO test_multi_insert SELECT generate_series(1,10);
+DELETE FROM test_multi_insert WHERE id%2=0;
+VACUUM test_multi_insert;
+BEGIN;
+COPY test_multi_insert FROM STDIN;
+11
+12
+13
+14
+15
+\.
+SELECT * FROM test_multi_insert;
+ROLLBACK;
+SELECT * FROM test_multi_insert;
+DROP TABLE test_multi_insert;
diff --git a/src/tools/msvc/Mkvcbuild.pm b/src/tools/msvc/Mkvcbuild.pm
index d1d0aed..120d7d5 100644
--- a/src/tools/msvc/Mkvcbuild.pm
+++ b/src/tools/msvc/Mkvcbuild.pm
@@ -48,7 +48,8 @@ my @contrib_excludes = (
 	'ltree_plpython',   'pgcrypto',
 	'sepgsql',          'brin',
 	'test_extensions',  'test_pg_dump',
-	'snapshot_too_old', 'unsafe_tests');
+	'snapshot_too_old', 'unsafe_tests',
+	'test_alter_tablespace_zheap');
 
 # Set of variables for frontend modules
 my $frontend_defines = { 'initdb' => 'FRONTEND' };
diff --git a/src/tools/msvc/Solution.pm b/src/tools/msvc/Solution.pm
index 318594d..08891d5 100644
--- a/src/tools/msvc/Solution.pm
+++ b/src/tools/msvc/Solution.pm
@@ -55,6 +55,11 @@ sub _new
 	die "Bad wal_blocksize $options->{wal_blocksize}"
 	  unless grep { $_ == $options->{wal_blocksize} }
 	  (1, 2, 4, 8, 16, 32, 64);
+	$options->{trans_slots_per_page} = 4
+	  unless $options->{trans_slots_per_page};    # undef or 0 means default
+	die "Bad trans_slots_per_page $options->{trans_slots_per_page}"
+	  unless grep { $_ == $options->{trans_slots_per_page} }
+		  (2, 4, 8, 16, 31);
 
 	return $self;
 }
@@ -207,6 +212,8 @@ sub GenerateFiles
 		  $self->{options}->{segsize} * 1024, "\n";
 		print $o "#define XLOG_BLCKSZ ",
 		  1024 * $self->{options}->{wal_blocksize}, "\n";
+		print $o "#define ZHEAP_PAGE_TRANS_SLOTS ",
+		  $self->{options}->{trans_slots_per_page}, "\n";
 
 		if ($self->{options}->{float4byval})
 		{
diff --git a/src/tools/msvc/config_default.pl b/src/tools/msvc/config_default.pl
index 043df4c..3006827 100644
--- a/src/tools/msvc/config_default.pl
+++ b/src/tools/msvc/config_default.pl
@@ -11,6 +11,7 @@ our $config = {
 
 	# blocksize => 8,         # --with-blocksize, 8kB by default
 	# wal_blocksize => 8,     # --with-wal-blocksize, 8kB by default
+	# trans_slots_per_page => 4, # --with-trans_slots_per_page, 4 by default
 	ldap      => 1,        # --with-ldap
 	extraver  => undef,    # --with-extra-version=<string>
 	gss       => undef,    # --with-gssapi=<path>
diff --git a/src/tools/pgindent/typedefs.list b/src/tools/pgindent/typedefs.list
index 432d2d8..f19bd36 100644
--- a/src/tools/pgindent/typedefs.list
+++ b/src/tools/pgindent/typedefs.list
@@ -1253,6 +1253,7 @@ LockInfoData
 LockInstanceData
 LockMethod
 LockMethodData
+LockOper
 LockRelId
 LockRows
 LockRowsPath
@@ -1346,6 +1347,7 @@ MultiXactOffset
 MultiXactStateData
 MultiXactStatus
 MyData
+MyUndoLogState
 NDBOX
 NODE
 NUMCacheEntry
@@ -1848,6 +1850,7 @@ PrepParallelRestorePtrType
 PrepareStmt
 PreparedParamsData
 PreparedStatement
+PreparedUndoSpace
 PrewarmType
 PrintExtraTocPtrType
 PrintTocDataPtrType
@@ -2066,6 +2069,8 @@ RmgrIds
 RoleSpec
 RoleSpecType
 RoleStmtType
+RollbackHashEntry
+RollbackHashKey
 RollupData
 RowCompareExpr
 RowCompareType
@@ -2353,6 +2358,11 @@ TOKEN_DEFAULT_DACL
 TOKEN_INFORMATION_CLASS
 TOKEN_PRIVILEGES
 TOKEN_USER
+TPDACTION
+TPDEntryHeaderData
+TPDBuffers
+TPDPageOpaqueData
+TPDPruneState
 TParser
 TParserCharTest
 TParserPosition
@@ -2457,6 +2467,7 @@ TransactionStmt
 TransactionStmtKind
 TransformInfo
 TransformJsonStringValuesState
+TransInfo
 TransitionCaptureState
 TrgmArc
 TrgmArcInfo
@@ -2549,6 +2560,23 @@ UpperUniquePath
 UserAuth
 UserMapping
 UserOpts
+UndoBuffers
+UndoErrorQueue
+UndoLogControl
+UndoLogMetaData
+UndoLogStatus
+UndoRecInfo
+UndoRecPtr
+UndoRecordHeader
+UndoRecordRelationDetails
+UndoRecordBlock
+UndoRecordTransaction
+UndoRecordPayload
+UndoRequestInfo
+UndoSizeQueue
+UndoWorkerQueueType
+UndoXidQueue
+UnpackedUndoRecord
 VacAttrStats
 VacAttrStatsP
 VacOptTernaryValue
@@ -2694,6 +2722,7 @@ XactCallback
 XactCallbackItem
 XactEvent
 XactLockTableWaitInfo
+XactUndoRecordInfo
 XidHorizonPrefetchState
 XidStatus
 XmlExpr
@@ -2704,6 +2733,26 @@ XmlTableBuilderData
 YYLTYPE
 YYSTYPE
 YY_BUFFER_STATE
+ZHTSV_Result
+ZHeapFreeOffsetRanges
+ZHeapMetaPageData
+ZHeapMultiInsertWALInfo
+ZHeapPageOpaqueData
+ZHeapPrepareLockUndoInfo
+ZHeapPrepareUndoInfo
+ZHeapPrepareUpdateUndoInfo
+ZHeapScanDescData
+ZHeapTuple
+ZHeapTupleData
+ZHeapTupleHeaderData
+ZHeapTupleTableSlot
+ZHeapTupleTransInfo
+ZHeapUndoActionWALInfo
+ZHeapWALInfo
+ZMultiLockMember
+ZPruneState
+ZTupleTidOp
+ZVersionSelector
 _SPI_connection
 _SPI_plan
 __AssignProcessToJobObject
@@ -3307,6 +3356,7 @@ uint64_t
 uint8
 uint8_t
 uintptr_t
+undorectype
 unicodeStyleBorderFormat
 unicodeStyleColumnFormat
 unicodeStyleFormat
@@ -3403,6 +3453,7 @@ xl_invalid_page_key
 xl_invalidations
 xl_logical_message
 xl_multi_insert_tuple
+xl_multi_insert_ztuple
 xl_multixact_create
 xl_multixact_truncate
 xl_parameter_change
@@ -3418,6 +3469,17 @@ xl_standby_lock
 xl_standby_locks
 xl_tblspc_create_rec
 xl_tblspc_drop_rec
+xl_tpd_allocate_entry
+xl_tpd_clean
+xl_tpd_free_page
+xl_undo_header
+xl_undoapply_progress
+xl_undolog_attach
+xl_undolog_create
+xl_undolog_discard
+xl_undolog_extend
+xl_undolog_meta
+xl_undolog_rewind
 xl_xact_abort
 xl_xact_assignment
 xl_xact_commit
@@ -3431,6 +3493,20 @@ xl_xact_relfilenodes
 xl_xact_subxacts
 xl_xact_twophase
 xl_xact_xinfo
+xl_zheap_clean
+xl_zheap_confirm
+xl_zheap_delete
+xl_zheap_freeze_xact_slot
+xl_zheap_header
+xl_zheap_insert
+xl_zheap_lock
+xl_zheap_metadata
+xl_zheap_multi_insert
+xl_zheap_unused
+xl_zheap_update
+xl_zheap_visible
+xl_zundo_page
+xl_zundo_reset_slot
 xmlBuffer
 xmlBufferPtr
 xmlChar
@@ -3458,4 +3534,6 @@ yy_size_t
 yyscan_t
 z_stream
 z_streamp
+zheap_page_items_state
+zheap_page_slots_state
 zic_t
-- 
1.8.3.1

